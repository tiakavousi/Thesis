id,pr_number,body,distilbert_sentiment_label,codebert_sentiment_label,deberta_sentiment_label,distilbert_confidence,codebert_confidence,deberta_confidence,majority_label,final_decision,decision_reason
1065964439,11695,add a short documentation comment for each of these added functions (and possibly for the group of functions for iterating over dicts in a db). it makes reviewing easier too.,0,0,0,0.9796521067619324,0.988043487071991,0.9926565289497375,0.0,accept,unanimous_agreement
1065970620,11695,"for dbrandomkey (used by randomkey and rm_randomkey), i think it's important to try to return a more fair random key. that's why dictgetfairrandomkey was used in the first place. it samples 15 buckets to compensate for the different sizes of the buckets. perhaps we can do something similar, e.g. sample 15 slots and select a weighted random slot of these based on the number of keys in each of them? [code block]",0,0,0,0.9777418971061708,0.9916802048683168,0.9833877086639404,0.0,accept,unanimous_agreement
1065975522,11695,"is this more efficient, or why this change?",0,0,0,0.9671197533607484,0.9826489686965942,0.9919643402099608,0.0,accept,unanimous_agreement
1065981207,11695,isn't this prototype is in server.h and therefore already available here?,0,0,0,0.9882228970527648,0.9918249249458312,0.9932938814163208,0.0,accept,unanimous_agreement
1066003182,11695,this creates an array of *dict pointers*. why not create an array of *dicts* in a single allocation? then we can avoid one extra memory hop when accessing a dict and the pointer in redisdb struct can remain a `dict *` instead of changing it to `dict **`. each dict is then accessed as `&db->dict[slot]` (or just `db->dict` for slot 0). [code block],0,0,0,0.987293004989624,0.9946357607841492,0.9947317838668824,0.0,accept,unanimous_agreement
1066009746,11695,"add this prototype to server.h instead? (if it's not already added there, i didn't check)",0,0,0,0.9759160876274108,0.989971399307251,0.9930610060691832,0.0,accept,unanimous_agreement
1066021504,11695,"is 48 bits guaranteed to be enough for a single dict cursor? is there any hard limit in redis for the number of keys? not that it matters that much but i believe we get huge cursors with this scheme and that we get smaller cursors if we use the 14 lsb for the slot and shift the dict cursor by 14 bits. iirc, the dict cursor is always small for small dicts.",0,0,0,0.9678208827972412,0.9434242844581604,0.9829524755477904,0.0,accept,unanimous_agreement
1066153736,11695,"i've initially done it as an array, but after discussion with we've decided that dict** is cleaner as it provides better static error checking. with dict*, there is a chance you could accidentally pass an array where specific dict is expected and dict[0] will be used instead of the slot specific dict. in fact i've done this error couple times myself and corrected it only after changing the type to dict**.",0,0,0,0.9641661643981934,0.9841475486755372,0.9773522019386292,0.0,accept,unanimous_agreement
1066159989,11695,"i think 48 bits should be enough, it's 2^16 times more than advertised max number of keys that redis can hold. i like your suggestion of using lsb for slot instead of the cursor, it should indeed result in smaller nominal cursor values as bits will be shifted by 14 instead of 48 and cursor values are usually not that big.",0,0,0,0.8573567271232605,0.986420512199402,0.5509477853775024,0.0,accept,unanimous_agreement
1066162849,11695,"you are right, this must be some junk left during refactoring. removed.",0,0,0,0.985081136226654,0.9705668091773988,0.9878107309341432,0.0,accept,unanimous_agreement
1066164553,11695,"yes, this actually gives 1ms of time, while older implementation was giving a fraction of the ms (time left to the next clock ms).",0,0,0,0.9863335490226746,0.983167827129364,0.9908981919288636,0.0,accept,unanimous_agreement
1066169793,11695,"yeah, i wanted to get a second opinion before going to deep into this as it's going to be a heuristic anyways. i agree we can make it more fair with respect to slot sizes. perhaps we can modify the algorithm such that it keeps track of the average slot size seen so far while it's iterating through slots and adjusts probability based on that value and the size of the given slot.",0,0,0,0.9521179795265198,0.9201224446296692,0.9604840278625488,0.0,accept,unanimous_agreement
1066172690,11695,"already there, cleaned up redundant declaration.",0,0,0,0.9590639472007751,0.9672114849090576,0.98847895860672,0.0,accept,unanimous_agreement
1066233433,11695,"ah, that's true; pros and cons. it's unfortunate if performance suffers due to this though. another way to prevent that kind of errors could be to make redisdb opaque and only access the fields using accessor functions. let's see if other reviewers have any opinions about it. [edit] ... or create an opaque type in dict `dictarray` (which is just a flat array, but with better type safety) with an accessor function `dict *dictarrayget(dictarray *dicts, int index);`",0,0,-1,0.5190786123275757,0.4319524466991424,0.7538063526153564,0.0,accept,majority_agreement
1066237318,11695,"ok, good.",1,1,1,0.9155471324920654,0.7346771955490112,0.5645142197608948,1.0,accept,unanimous_agreement
1066363233,11695,will do.,0,0,0,0.9548023343086244,0.9864637851715088,0.9465230703353882,0.0,accept,unanimous_agreement
1066368870,11695,"i don't think there is a performance hit, given that array size is relatively large it wouldn't be pre-fetched, so we'll probably end up with extra memory reads anyways. from brief benchmarking that i've done, crc hash sum calculation (from `getdict`) was the only clear place where we've introduced some slowdown. once we eliminate that, i'm going to run more thorough benchmarks, and we can discuss results and see if anything else is an issue. do you agree with this plan?",0,0,0,0.9546886682510376,0.9624393582344056,0.9352161288261414,0.0,accept,unanimous_agreement
1066406350,11695,"good plan. measuring is what matters. theoretically though (and since thinking about it is more fun than actually measuring) i believe accessing some field in the dict, let's say rehashidx, in `dict_pointers[slot]->rehashidx` it is two reads (one to fetch the pointer and one to follow it and fetch the dict struct) while in `dict_array[slot].rehashidx` it is only one read.",1,1,1,0.939667582511902,0.803849995136261,0.9514197707176208,1.0,accept,unanimous_agreement
1066426933,11695,"would it worth to run some benchmarks? with this change, key lookup and mutations would need to do a crc16 calculation in order to find which slot it is in. for write, i understand it is the same because there's logic to add the key to the linked list before this change, but for read, we introduced an additional crc16 calculation. i'm not saying it would be blocking. i really like this change and the benefits/future benefits come with it, but i think understand the performance impact would be helpful.",1,1,1,0.9152849912643432,0.8659921884536743,0.9728037118911744,1.0,accept,unanimous_agreement
1066451242,11695,"+1 that 48 bits should be good enough, the public doc suggested max number of keys is 2^32 (though i didn't find this hard limit in the code, i guess it is the limit in a 32 bit system) i'm curious where the other 2 bits goes. we should have 64 bits in the unsigned long long, if cursor takes 48 bits and slot takes 14 bits, that adds up to 62 bits.",0,0,0,0.943673610687256,0.9362678527832032,0.9779869914054872,0.0,accept,unanimous_agreement
1066458888,11695,"i believe the intention of `slot > 0` is for checking whether we are in cluster modes. can we check that directly or use db->dict_count to do the check? we may hit a corner case by the current impl. imagine we are scanning slot 0 in cluster mode, and we finished slot 0. cursor would be 0 and slot was also 0, we quit. however, we shouldn't end here, we should continue with next slot.",0,0,0,0.961711883544922,0.986459732055664,0.9896522164344788,0.0,accept,unanimous_agreement
1066460349,11695,nit: can we use db->dict_count > 1? i know current impl also works but i think using `db->dict_count` could be a better indicator.,0,0,0,0.9749780893325806,0.9862796068191528,0.9884124398231506,0.0,accept,unanimous_agreement
1066481111,11695,apologize that i didn't read the pr description. great to hear there's no perf downgrade.,1,1,-1,0.8616898655891418,0.9286453723907472,0.9712631106376648,1.0,accept,majority_agreement
1066646831,11695,"this check essentially tells you that there are more unvisited slots. special case that you've described at slot 0 should work fine, as at the end of slot 0 iteration we'll find next non-empty slot, if there is one. there is also special case for the last slot, where -1 is returned, which stops the loop. this is why we have a check for `slot>0` in `addslotidtocursor`, to not include slot id into cursor when iteration has finished. i can make it slightly more readable, but that would require a separate variable for holding ""has more unvisited slots"" status and would take couple more loc. would you prefer that, or does my explanation make sense?",0,0,0,0.976774275302887,0.989980399608612,0.9918713569641112,0.0,accept,unanimous_agreement
1066647872,11695,explained motivation in the comment above.,0,0,0,0.9776850342750548,0.9850996136665344,0.9917824268341064,0.0,accept,unanimous_agreement
1066648905,11695,"i'm working on finding a way to get rid of extra hash calculations. there is no clear solution just yet, but i plan on addressing it either as part of this pr or short after, depending on the mechanism that we choose and whether or not it requires larger refactoring.",0,0,0,0.957251250743866,0.956684410572052,0.9609227776527404,0.0,accept,unanimous_agreement
1067398831,11695,"thanks for the explanation, it makes total sense now. i missed the fact that dbgetnextunvisitedslot() will update the slots. it's okay i don't think we need the refactor.",1,1,1,0.7503902316093445,0.979346513748169,0.9929566383361816,1.0,accept,unanimous_agreement
1067400474,11695,can we add a comment indicating that slot could be -1 if we have no slot left? that would help people to understand the `slot > 1` condition check,0,0,0,0.9866070747375488,0.9942139983177184,0.9953227639198304,0.0,accept,unanimous_agreement
1067532741,11695,"not very familiar about this source file but from the code logic should this section go outside of the while loop? [code block] if for some reason it needs to be here, then the `werr` section also need to release `dbit`",0,0,0,0.9863929152488708,0.9901214838027954,0.9844344258308412,0.0,accept,unanimous_agreement
1067533312,11695,nit: replace db with dict,0,0,0,0.9866238832473756,0.9868481755256652,0.9946041703224182,0.0,accept,unanimous_agreement
1067597072,11695,"although we ""advertise"" 2^32, we did make the needed changes to support 2^64 in several cases. we had some clusters in aws with more than 2^32 keys. i think we should consider bumping that number to 2^48.",0,0,0,0.9828317761421204,0.987975299358368,0.986697256565094,0.0,accept,unanimous_agreement
1067737553,11695,perhaps i should also add a comment to make it more clear when reading the code.,0,0,0,0.9830533862113952,0.9886205792427064,0.9795698523521424,0.0,accept,unanimous_agreement
1067737827,11695,absolutely.,0,0,0,0.8953989744186401,0.7786356806755066,0.963522732257843,0.0,accept,unanimous_agreement
1067778005,11695,"i think i might have found a way to avoid redundant crc hash calculations, for that we could add a separate field into redisdb that would hold a reference to the current slot specific dictionary. we could populate it in the same place where we determine current command's slot. [a link] it should work as long as entire command operates only on one slot, which is a case currently. this would save us from doing a lot of plumbing, and pushing slot id around through db.c apis. wdyt?",0,0,0,0.9587154984474182,0.9529340863227844,0.9071270227432252,0.0,accept,unanimous_agreement
1069544389,11695,is `c->db` always the same before and after executing the command? do we need to consider temb dbs and do something there? (swapmaindbwithtempdb) hopefully not but i'm not sure...,0,0,0,0.9349792003631592,0.9366376996040344,0.9621408581733704,0.0,accept,unanimous_agreement
1069554625,11695,the relation between cluster slots and slot_mask_shift is... cluster_slots == 1 << slot_mask_shift perhaps we could use that in the defines or a static assert? not sure if it's worth it though.,0,0,0,0.9800859689712524,0.98816978931427,0.9099062085151672,0.0,accept,unanimous_agreement
1072891188,11695,how about this instead: [code block],0,0,0,0.98580002784729,0.9914824962615968,0.9911850094795228,0.0,accept,unanimous_agreement
1073323680,11695,lgtm. good to put these together and use the cluster prefix. only drawback is if some tries to grep for 16384. :),1,1,1,0.9874102473258972,0.9951706528663636,0.9956488013267516,1.0,accept,unanimous_agreement
1073347135,11695,#11465 moved the struct definition to dict.c and kept only `typedef struct dictentry dictentry; /* opaque */` here. putting it back here is a merge-conflict mistake.,0,0,0,0.9755880236625672,0.9925716519355774,0.9355916380882264,0.0,accept,unanimous_agreement
1080830204,11695,"will revert. was it done mostly for encapsulation, to ensure that entry fields aren't used directly?",0,0,0,0.9533507823944092,0.9834718704223632,0.990233302116394,0.0,accept,unanimous_agreement
1080830679,11695,"haha, right? i can put that in comments to make it easier to find.",1,0,1,0.7070901989936829,0.6022741198539734,0.9500083327293396,1.0,accept,majority_agreement
1080965143,11695,exactly. then we can do refactoring and optimization within dict.c without affecting anything else.,0,0,0,0.9855604767799376,0.99084210395813,0.9928989410400392,0.0,accept,unanimous_agreement
1082120456,11695,added.,0,0,0,0.9763525128364564,0.9822506308555604,0.9917559623718262,0.0,accept,unanimous_agreement
1082122728,11695,"i think it's still accurate, except we've now added one more layer in this iteration.",0,0,0,0.9768623113632202,0.9700585007667542,0.965518057346344,0.0,accept,unanimous_agreement
1082123990,11695,"i'm not aware of any scenario when it would be an issue, main processing loop is single threaded and next command is not starting until previous one completes. if you know any use case when this might be an issue, please let me know.",0,0,0,0.9754737615585328,0.5529801249504089,0.968786597251892,0.0,accept,unanimous_agreement
1082130851,11695,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1082287913,11695,"you're probably right. there's no way for the client to change db either (select not possible in cluster mode). it just looks risky somehow. if the db changes, the old db may stick around somewhere with a current_dict set. can we add some assert to check that db hasn't changed? e.g. if (c->slot >= 0) serverassert(c->db->current_dict == c->db->dict[c->slot]; possibly check that it's null before we set it too? not sure if this makes sense. perhaps i'm paranoid.",0,-1,-1,0.8532462120056152,0.6810871362686157,0.5124778747558594,-1.0,accept,majority_agreement
1082295103,11695,"nice! though in redis, these documentation comments are normally in the `.c` files.",1,1,1,0.9870482087135316,0.9889529943466188,0.9943091869354248,1.0,accept,unanimous_agreement
1082302700,11695,it looks like it would be possible to put the dbiterator on the stack to save one zmalloc/zfree. the get functions would need to be replaced by init functions like so: [code block],0,0,0,0.9847168922424316,0.9941101670265198,0.9924519658088684,0.0,accept,unanimous_agreement
1083203785,11695,"okay, will move.",0,0,0,0.9581106901168824,0.947358250617981,0.9821467995643616,0.0,accept,unanimous_agreement
1084403642,11695,good idea. done.,1,1,1,0.9577327966690063,0.9777364134788512,0.9912089109420776,1.0,accept,unanimous_agreement
1086257507,11695,"i've added this check, and also to make it nicer, i've cached slot id, instead of dict, this way we can simply compare integers in the assert. i've found a couple of interesting things related to scripts though: * it's possible that some keys were not declared by the script, in which case slot is set in the client during script execution, hence cached slot id will be -1, but actual slot will be different (see `scriptverifyclusterstate` function). to avoid this we can add a simple check before the assert to only perform assertion when the slot was cached. * scripts allow multi slot commands, when appropriate flags are set, which means that caching single slot id is inappropriate. i think best we can do is to identify this situation during script execution and clear cached slot id so that fallback logic that calculates key hash is used in the `getdict` function.",0,0,0,0.8475099205970764,0.9861242771148682,0.96060049533844,0.0,accept,unanimous_agreement
1086262969,11695,"yeah, you are right, we should move it out.",0,0,0,0.9459241628646852,0.9313045144081116,0.96297687292099,0.0,accept,unanimous_agreement
1088633422,11695,"i made a pretty straightforward implementation that is fair for slots of different size, it takes a target random key index [0..keycount), and finds a dictionary that contains that key. the only inefficiency is that it needs to use `dbsize`, which is o(slot count) operation, but we can make it o(1) by storing key counter at the `redisdb` level.",0,0,0,0.9700035452842712,0.9823549389839172,0.9630616903305054,0.0,accept,unanimous_agreement
1096045935,11695,"there are a couple of places where need to iterate every key, do we want to come up with a ""multidbiterator"" that will return every key from every database. partially to preserve the git history of this file. will also make it much easier to review.",0,0,0,0.9821857810020448,0.9834455847740172,0.9921818971633912,0.0,accept,unanimous_agreement
1096051515,11695,"a benefit of the pointer approach is we don't need to initialize the dictionaries for unused slots. it saves at least 250kb on a 2 shard system, since each dict is 40 bytes * 8192. it seems like a big enough chunk of memory to care.",0,0,0,0.9125485420227052,0.962883710861206,0.9293093681335448,0.0,accept,unanimous_agreement
1096166881,11695,i wouldn't change this signature.,0,0,0,0.9076206684112548,0.9119989275932312,0.8807896375656128,0.0,accept,unanimous_agreement
1096168213,11695,"we already have a slot at the client level which is being tracked, we could just use server.current_client->slot. i don't really want to support multiple places we stuff the slot.",0,0,0,0.93279230594635,0.9770789742469788,0.9608529210090636,0.0,accept,unanimous_agreement
1096433726,11695,don't we have a 64bit random in mt199937-64? i believe that is as fast as rand.,0,0,0,0.9298508167266846,0.9811830520629884,0.9915074110031128,0.0,accept,unanimous_agreement
1096436428,11695,"yes, but remember not all pointers are created equal. the multiple pointer bit is important for normal keys and values because they probably aren't in any of the cpu caches, so you have to pay a full dram miss, whereas there is a *good* chance that some of these dictionaries will be in cache. still worth doing performance checking though.",1,0,0,0.772495687007904,0.8530365824699402,0.9753177165985109,0.0,accept,majority_agreement
1096436669,11695,"if you can , it would probably be a good time to go through and remove all of these unnecessary touch points.",0,0,0,0.9377893209457396,0.9420124888420104,0.9858137965202332,0.0,accept,unanimous_agreement
1096438411,11695,"i might be missing something, but i don't see why this is exposed.",0,0,0,0.5888293385505676,0.7424787282943726,0.9055263996124268,0.0,accept,unanimous_agreement
1096552034,11695,"if they can be null, we need to check for null in a lot of places. perhaps it's worth it.",0,0,0,0.9379865527153016,0.9717484712600708,0.972606122493744,0.0,accept,unanimous_agreement
1097850773,11695,"yes viktor, also it would complicate situations like slot migration and temp db swap. i felt like extra complexity is not worth it (at least as part of this pr), and be better left for future optimizations. madelyn, do you feel strongly about this one?",-1,0,0,0.4667423963546753,0.9299213886260986,0.9612664580345154,0.0,accept,majority_agreement
1097886971,11695,"practically speaking, future optimizations don't happen. i would like to decide if we want it or not now. if we decide later is useful, we can create an issue for later.",0,0,0,0.9666219353675842,0.9622650146484376,0.9647379517555236,0.0,accept,unanimous_agreement
1098737518,11695,maybe we better store the dict size of each dict in the rdb and use that instead of the total count when available?,0,0,0,0.9850617051124572,0.9946309328079224,0.9889708757400512,0.0,accept,unanimous_agreement
1098748902,11695,"i think we're taking a hit in the fairness here. severely, since evictionpoolpopulate can populate multiple keys (now they all come from the same slot)",-1,-1,-1,0.776836633682251,0.5498877763748169,0.8266437649726868,-1.0,accept,unanimous_agreement
1098751500,11695,"we're taking some fairness hit here as well, but it's a silly eviction policy, maybe we don't care.",-1,-1,-1,0.9761707186698914,0.8920331001281738,0.9810802340507508,-1.0,accept,unanimous_agreement
1098756684,11695,"the fact we now have another mechanism serving cluster slots, doesn't necessarily means we want to remove this metadata feature.",0,0,0,0.9800606966018676,0.983673930168152,0.9888424873352052,0.0,accept,unanimous_agreement
1098763065,11695,"maybe it doesn't matter on cluster mode (if we have an array of dicts or array of pointers, since the array is big), but note that in non-cluster mode, this adds another indirection.",0,0,0,0.984163224697113,0.9906873106956482,0.9746376872062684,0.0,accept,unanimous_agreement
1099281696,11695,"will clean it up. it was used in one of the previous revisions, left out during refactoring.",0,0,0,0.9794352054595948,0.9906564950942992,0.99321049451828,0.0,accept,unanimous_agreement
1099283435,11695,"it would be nice, let me check that.",1,1,1,0.5167034864425659,0.5496092438697815,0.8580344319343567,1.0,accept,unanimous_agreement
1099295425,11695,can you please clarify what you mean exactly?,0,0,0,0.9800775051116944,0.9887031316757202,0.9907783269882202,0.0,accept,unanimous_agreement
1099299470,11695,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
1099831221,11695,whitespace changes on otherwise untouched lines.,0,0,0,0.9854825735092164,0.9672808647155762,0.9875933527946472,0.0,accept,unanimous_agreement
1100527133,11695,"of course, my ide seem to be overly eager at removing unnecessary spaces at the eol.",-1,-1,0,0.5996143817901611,0.7647565007209778,0.8388499021530151,-1.0,accept,majority_agreement
1100527671,11695,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1100529581,11695,"my line of thinking was that it's very unlikely that static price of couple hundred kb per deployment wouldn't matter to anyone who is running redis in cluster mode, and that it's not worth extra complexity to go ahead and try to eliminate this. let me know if there are any use cases when that actually matters.",0,0,0,0.8775021433830261,0.922718584537506,0.9805454015731812,0.0,accept,unanimous_agreement
1100752472,11695,"changed to randomulong, i think that should be sufficient.",0,0,0,0.983676016330719,0.9838826656341552,0.9922131896018982,0.0,accept,unanimous_agreement
1101220706,11695,"we can pass the dict as an argument to this function, no need to recompute it",0,0,0,0.982484757900238,0.9702302813529968,0.9928257465362548,0.0,accept,unanimous_agreement
1101221987,11695,"maybe defraglater can be per-dict and not per-db, and we'll avoid this lookup",0,0,0,0.9789025783538818,0.9927518367767334,0.9840769171714784,0.0,accept,unanimous_agreement
1101241147,11695,stale comment?,-1,0,0,0.8963266015052795,0.9554073214530944,0.9893359541893004,0.0,accept,majority_agreement
1101244201,11695,"same as database cron iterates on the databases, trying a different one in each cron, i don't think we should have a loop here on all slots, and instead incrementally scan them",0,0,0,0.9799514412879944,0.93698650598526,0.9837321639060974,0.0,accept,unanimous_agreement
1101251947,11695,"these changes in multi.c have a mitigation in cluster mode? i.e. the optimization of assuming it's the same slot again and again kicks in here, right? and in non-cluster mode this extra call is very quick, correct?",0,0,0,0.9651286602020264,0.9871646165847778,0.991295337677002,0.0,accept,unanimous_agreement
1101353470,11695,"maybe this would be nicer if we add a multi-dict scan function in dict.c or db.c? so this code (and others that do the same) will just remain as it was and start to use an `mdictscan()` (taking a dict array pointer and count), or `dbscan()` (doesn't need to take any additional input).",0,0,0,0.9757015705108644,0.9948031306266784,0.9809440970420836,0.0,accept,unanimous_agreement
1101362662,11695,why did you drop allvolatile?,0,0,0,0.9696187376976012,0.9496246576309204,0.990326464176178,0.0,accept,unanimous_agreement
1101365466,11695,"i'm probably missing something. it looks to me as if the first function shifts the cursor only in cluster mode, and leave it low in non-cluster mode. but in the other function it looks like we always shift. if it's not already like it, i suggest that for non-cluster scan, we'll leave the cursor unaffected.",0,0,0,0.8876161575317383,0.9707122445106506,0.9066744446754456,0.0,accept,unanimous_agreement
1101372614,11695,"note that since each dict goes to the next power of two, they're all getting a little bit over allocated. it's likely that this pr has higher dict related memory overheads compared to before. it may still be worthwhile since on average we could be wasting about 1/2 - 1 pointer pointer per key (e.g. 8 bytes), and we save 16 bytes.",0,0,0,0.9760889410972596,0.9841533303260804,0.9789041876792908,0.0,accept,unanimous_agreement
1102394803,11695,one of my goals with this change is to unblock [a link] which would likely require different metadata format. i was thinking about removing existing metadata and then adding new appropriate format that will allow other memory efficiency improvements. i'm open for a discussion here though.,0,0,0,0.8990606665611267,0.9532418251037598,0.9811107516288756,0.0,accept,unanimous_agreement
1102395896,11695,correct,0,0,0,0.9691285490989684,0.8340582847595215,0.98023784160614,0.0,accept,unanimous_agreement
1102396913,11695,must be a merge issue,0,0,0,0.9824041128158568,0.98434978723526,0.9931055903434752,0.0,accept,unanimous_agreement
1102399548,11695,"cursor in non-cluster mode should not be affected at all. as you said, first function will never touch it, and the second one will always return 0 when cluster mode is disabled. we can add defensive code that would check for `cluster_enabled` status explicitly, but i think it would be an overkill.",0,0,0,0.8594717979431152,0.9767202734947203,0.9789014458656312,0.0,accept,unanimous_agreement
1102404602,11695,"number of free hash slots in dictionaries should be same before and after this change, statistically speaking. can you explain how you've come up with 1/2 - 1 pointer estimate, cause i don't see this?",0,0,0,0.9792725443840028,0.978242576122284,0.9927104711532592,0.0,accept,unanimous_agreement
1102407174,11695,"we can certainly do that, if there is enough appetite to change rdb format. wouldn't it be backward incompatible change though? (e.g. new rdb would not be readable by an older version of redis) or are new fields not an issue?",0,0,0,0.9854333996772766,0.9923833012580872,0.9926314353942872,0.0,accept,unanimous_agreement
1102448267,11695,i agree with here. let's get rid of that metadata feature.,0,0,0,0.9691799283027648,0.9065866470336914,0.9780204892158508,0.0,accept,unanimous_agreement
1102516980,11695,"how about deferring the increment of dbit->index, maybe one day we need to traverse backwards. [code block]",0,0,0,0.9830028414726256,0.991458773612976,0.9921169877052308,0.0,accept,unanimous_agreement
1102976529,11695,"+1, unless we explicitly need it. maybe we can do this revert it a second commit though so it's easy to revert if we need it?",0,0,0,0.9714576601982116,0.9789450764656068,0.9876412749290466,0.0,accept,unanimous_agreement
1103263136,11695,"to be clear, in non-cluster mode, the cursor is shifted by 14 bits too and slot is encoded in the cursor, but slot is always 0. (during scan, dbgetnextunvisitedslot returns the next dict and slot, which is never more than 0 in non-cluster mode since it uses `db->dict_count`. btw, it's not necessary to store `dict_count` in the db struct. it is always `server.cluster_enabled ? cluster_slots : 1` and `cluster_enabled` cannot be changed at runtime.)",0,0,0,0.9667705297470092,0.9939316511154176,0.992949604988098,0.0,accept,unanimous_agreement
1103753954,11695,"new rdb versions are always unreadable by older versions. p.s. in 7.0 we already have a few other rdb format changes anyway. anyway, this is just a suggestion, could be handy if the db is unevenly distributed.",0,0,0,0.9832274913787842,0.988339900970459,0.981842279434204,0.0,accept,unanimous_agreement
1103755888,11695,"ok. i was thinking that this mechanism can be useful for something else in the future, but if it stands in the way of something else, we can drop it. however, since these two mechanisms don't touch the same areas in the code, it would be easier to review the changes in this one, if we leave this revert for later.",0,0,0,0.978469729423523,0.9733803272247314,0.9785974621772766,0.0,accept,unanimous_agreement
1103756699,11695,"aren't you contradicting each other? anyway, i didn't bother to look too deeply as to when `int slot` would be negative, but the first one seems to only shift the cursor when slot is non-negative, and the second one always shifts it. so either something is wrong here, or maybe some comments can clear it up. in any case, i think that we should aim for the non-cluster mode to have unshifted cursors.",0,0,0,0.9443429708480836,0.928637683391571,0.9143526554107666,0.0,accept,unanimous_agreement
1103759451,11695,"maybe i'm wrong. let's take a few examples to see. 1. small db db with 1000 keys, would have used a lut of 1024 (wasting 24 pointers), will now have 16384 dbs, each of 4 entries (the minimum), so we have 65536 entries (wasting 64,513 pointers). 2. big db with 1m keys, perfectly evenly distributed, would have used 1048576 (wasting 48,576 pointers), would now have 16384 dbs, each of 64 entries (wasting 48,576 pointers, exactly the same). 3. let's imagine a database that's not evenly distributed, for simplicity let's assume there are only 2 cluster slots. so if before we had 1m keys in one dict (wasting 64,513 pointers), and let's assume they're split 1/3 + 2/3, so 524288 slots in one, and 1048576 slots in the other (wasting a sum of 572,864 pointers). so it's clear that we have a problem with small databases, not sure what we wanna do about it if any. as for the uneven distribution, maybe we wanna ignore it, and maybe on average it won't happen, and as i said in the previous message, maybe it's still worthwhile considering the savings in this pr.",-1,0,0,0.6572243571281433,0.9863018989562988,0.8667065501213074,0.0,accept,majority_agreement
1103884757,11695,"yes, i'm contradicting. :d i shouldn't have said ""to be clear"", but sometging else. i understand it differently but please correct me if i'm wrong. slot is -1 when scan is finished. i believe cursor is always zero in this case. i think we should add an assert here. btw, i think dbgetnextunvisitedslot could set slot to 0 instead of -1 when there are no more slots. i don't see why we need the -1 value.",1,-1,1,0.8253051042556763,0.8929476141929626,0.9894164204597472,1.0,accept,majority_agreement
1104699723,11695,i like this idea since i think we should stick slot information into the rdb as part of: [a link],1,1,1,0.8766601085662842,0.9633784294128418,0.8342182040214539,1.0,accept,unanimous_agreement
1104724947,11695,"an empty dict has no allocated hashtable. it's only the dict struct itself (7 words). in a small db with 1000 keys in 1000 different slots, the other 15384 dicts are empty.",0,0,0,0.9853824377059937,0.9866985082626344,0.9849449992179872,0.0,accept,unanimous_agreement
1105416959,11695,"ohh, right, so just the ones with a key will have 4 entries, so this makes it: 1. small db db with 1000 keys, would have used a lut of 1024 (wasting 24 pointers), will now have 1024 dbs (the rest will be empty), each of 4 entries (the minimum), so we have 4096 entries (wasting 3,072 pointers).",0,0,0,0.9450748562812804,0.9705706238746644,0.9782662987709044,0.0,accept,unanimous_agreement
1105433805,11695,"worst case 1000 non-empty dicts, 3000 wasted pointers. best case 1 non-empty dict of capacity 1024, wasting 24 pointers. dict entry metadata was 2 pointers per key. for 1000 keys we save 2000 pointers.",0,0,0,0.9774895310401917,0.9811455607414246,0.9135996699333192,0.0,accept,unanimous_agreement
1105752484,11695,"ok, there's also the other case i described above of uneven distribution, which in the past would't have matter, and now each slot has it's own power of two overhead..",0,0,0,0.9627383947372437,0.9823383092880248,0.9815270304679872,0.0,accept,unanimous_agreement
1105818250,11695,"yes, but instead of one big power-of-two, there are multiple small power-of-two overheads, but they sum up to roughly the same number (assuming there are no dicts with only 1-2 keys). | | unstable | this pr | |----------------------------------------|----------|---------| | three slots with 1000 keys in each | 4096 = 4*1024 | 3*1024 | | three slots with 1000, 2000, 3000 keys | 8192 = 8*1024 | 1024+2048+4096 = 7*1024 |",0,0,0,0.7409514784812927,0.981592059135437,0.9879029393196106,0.0,accept,unanimous_agreement
1107555986,11695,"exactly, power of 2 will be much smaller, proportional to the number of dictionaries. besides small (<1mb) static overhead for dict structures themselves, there should be no overhead really. and when cluster mode is disabled it should be same as before this change as we allocate only one dict.",0,0,0,0.9849116802215576,0.9853024482727052,0.9885801672935486,0.0,accept,unanimous_agreement
1107561055,11695,i see there is some confusion. let me take another look at this code and try to make it a bit more readable and easy to understand.,0,0,0,0.946897029876709,0.6773641705513,0.887891411781311,0.0,accept,unanimous_agreement
1113679249,11695,"it's a good point, current implementation will be very inefficient (and possibly broken) when maxmemory is low (when there are few keys per slot). i think we'll need to include more dictionaries into the sample until we reach desired number of keys to sample from. let me use test-lru util that we have to measure lru performance on this branch comparing to unstable branch, and update implementation to make sure we don't degrade quality of the eviction pool.",0,0,1,0.5352980494499207,0.9257102012634276,0.604859471321106,0.0,accept,majority_agreement
1116629319,11695,"updated implementation: * improved eviction pool population for small dbs. * added faster version of random dictionary selection. * fixed a bug with cached command slot being used during eviction. with that in place, measured both performance (using bench) and fairness (using lru util). i no longer see any regressions there.",0,0,0,0.926694393157959,0.9913020133972168,0.8348135948181152,0.0,accept,unanimous_agreement
1117390612,11695,"i don't see any measurable performance degradation from this, my assumption is that because in non-cluster mode there is only one pointer per db, it can stay in cpu cache.",0,0,0,0.9460001587867736,0.9819601774215698,0.9734684228897096,0.0,accept,unanimous_agreement
1117764323,11695,"one downside of this is that on large clusters. (~1000 nodes), most nodes are only assigned 16 slots. so they will on average scan through 999 empty slots before finding any slot with keys in it. what's worse, if the cluster is correctly configured and has continuous ranges, they might have to consistently scan 16k empty slots (for example if the node has slots 16358 - 16383). i have to imagine this will take some amount of time. i still think we might want to maintain a vector of the dictionaries *owned* by this node we can iterate through. this list will not change often.",-1,0,0,0.563450813293457,0.8430222272872925,0.7418042421340942,0.0,accept,majority_agreement
1117776912,11695,"practically speaking, won't this invalidate most of the l1 cache as we are bringing in on average 8k value to do the size check. if most commands are evicting items out of the lru, this seems really inefficient.",0,0,-1,0.6101365685462952,0.7830054759979248,0.7815297245979309,0.0,accept,majority_agreement
1119220889,11695,"i think that's a good idea, it would help us speed up iteration and random dict selection at a relatively small cost of <128kb.",0,0,1,0.57973712682724,0.7052292823791504,0.979584574699402,0.0,accept,majority_agreement
1119554930,11695,can we use the bitmap `myself->slots` for this?,0,0,0,0.9886237382888794,0.9941786527633668,0.9951423406600952,0.0,accept,unanimous_agreement
1119638724,11695,"there is a difference between non-empty and owned. if we're interested in owned slots, we should instead check e.g. `clusternodegetslotbit(myself, slot)` in cluster.c.",0,0,0,0.9879283308982848,0.9950413107872008,0.9950990080833436,0.0,accept,unanimous_agreement
1119647918,11695,"it's a smart idea, slot bitmap could speed up iteration, as we can isolate all non zero bits from each byte in the mask quite easily. there are two issues with it though: 1. similarly to the previous approach, you'd have to skip a bunch of 0s in the bitmap if node owns few slots (although it will be 8 times faster as bitmask array's size is `cluster_slots/8`, making it a worthwhile improvement, but not as good as having slots in a vector) 2. it won't be possible to get random non-empty slot in `o(1)` time using this approach. so, unfortunately, i don't think it's quite as good as having non empty slots in a vector.",0,0,1,0.4872011542320251,0.8406619429588318,0.7479325532913208,0.0,accept,majority_agreement
1119650042,11695,"the comment mentions ""iteration across all owned slots"" but it actually includes non-owned slots (e.g. importing slots not yet owned). what do we want here, owned non-empty or all non-empty?",0,0,0,0.98779034614563,0.9884545803070068,0.9904462099075316,0.0,accept,unanimous_agreement
1119652585,11695,"a cache line is 64 bytes, so we have 512 bits (slots) in one cold memory read.",0,0,0,0.9867042303085328,0.9902655482292176,0.9893910884857178,0.0,accept,unanimous_agreement
1119658761,11695,"i think we want owned and non-empty, however i believe that existing implementation of scan api in the unstable branch doesn't check for owned vs not owned either (this is why i've ignored check here). we should fix that perhaps.",0,0,0,0.9802423119544984,0.98298442363739,0.9896770119667052,0.0,accept,unanimous_agreement
1119662436,11695,"i remember there was some use case related to replication, when data was imported before slots were assigned. i'll need to look into it again and see where we can enforce ownership check and where we'll have to ignore it.",0,0,0,0.9860601425170898,0.9827418923377992,0.9912220239639282,0.0,accept,unanimous_agreement
1119669057,11695,"* iterating those 512 bits will require some cpu cycles, even if there isn't much random memory access. * you may still need multiple reads from memory in order to find a slot if very few slots are owned. * no way to skip empty slots. that being said, it can be good enough for iteration use case, but it doesn't provide ability to find a random non empty slot in o(1) time (important for eviction use case). on the other hand one benefit of using this approach would be that we wouldn't need to add any code on the hot path (db add/remove). i can prototype and benchmark it to see what actual performance would be if i manage to find a solution to finding random slot quickly.",0,0,0,0.937121331691742,0.9776024222373962,0.9551328420639038,0.0,accept,unanimous_agreement
1124087725,11695,"i've reworked eviction logic slightly, please take a look at the most recent version and let me know if you have any concerns.",0,0,0,0.9643368124961852,0.9602279663085938,0.984455943107605,0.0,accept,unanimous_agreement
1124167364,11695,"it's true that the number of tables increased, but total amount of work needed to resize the dictionary remains the same. the only overhead should be iterating through slots, but it shouldn't take much time to become a concern for cron.",0,0,0,0.9757476449012756,0.9883916974067688,0.9875904321670532,0.0,accept,unanimous_agreement
1124177339,11695,"correct, in non cluster mode getting slot is trivial, as we always need dictionary 0. in cluster mode, there should be no cached slot for commands like flushdb, which is what we want as we'll need to calculate crc hash for each key in order to find correct slot where it is located.",0,0,0,0.9693713188171388,0.990281581878662,0.9886397123336792,0.0,accept,unanimous_agreement
1125614453,11695,"i don't understand what work do you refer to. all the ""work"" of htneedsresize, dictresize, and dictexpand is repeated for each slot rather than just being done once. the only thing that remains roughly the same volume is of zcalloc (many small callocs rather than one that's bigger), so it's true that the amount of memory being zeroed may not change much, but the overhead per allocation call is likely to be large.",0,0,0,0.951749861240387,0.7345498204231262,0.7309470176696777,0.0,accept,unanimous_agreement
1125616361,11695,"for the record, i still don't get it. getandclearslotidfromcursor always shifts the cursor by 14 bits, even in non-cluster mode.",0,0,0,0.9246047735214232,0.9588940143585204,0.8021125197410583,0.0,accept,unanimous_agreement
1125616605,11695,"let's try to stick to the common styling, `{` in the same line of a single line function declaration of `if`",0,0,0,0.986935257911682,0.9926711320877076,0.9912697076797484,0.0,accept,unanimous_agreement
1125622762,11695,"it's a little odd that the code above uses db->key_count directly, and the code below it calls dbsize(). also, after caching it on the stack, it calls it again...",-1,-1,-1,0.5806617140769958,0.8819002509117126,0.6085188984870911,-1.0,accept,unanimous_agreement
1125623721,11695,"it's not just clusters with a lot of nodes skipping a lot of slots in this long loop, it could also be a cluster with just a few nodes, will also have a long loop. i suppose maintaining some grouping could help to skip roughly the right place. it doesn't have to be a bitmap, we can just maintain sums of total keys of each group of 64 slots.",0,0,0,0.9720474481582642,0.9817513823509216,0.9888870120048524,0.0,accept,unanimous_agreement
1125646038,11695,"the eviction is (usually?) running when current_client is null, so if feels a bit odd to see it here. what code below users the current_client? i fail to see it. if we have some assertion, maybe a better solution is to nullify current_client?",0,-1,0,0.622024416923523,0.807959794998169,0.5665092468261719,0.0,accept,majority_agreement
1125650580,11695,"i still think there's a fairness issue here. each call to to evictionpoolpopulate will populate the entire pull (if it finds keys). the existing mechanism for multi-db deployments are unfair as well (always starting from db 0), we may not care because not many are using the combination of eviction and multi-db. but for cluster and per-slot dict i think we want each key in the pool to come from a random dict.",-1,0,0,0.729704737663269,0.934187650680542,0.8952130079269409,0.0,accept,majority_agreement
1125650756,11695,temporary change that should be reverted?,0,0,0,0.9697497487068176,0.9854984283447266,0.9781262278556824,0.0,accept,unanimous_agreement
1125655103,11695,maybe the comment goes to to the different terms (just fix the variable name from `owned_slots` to `non_empty_dicts`,0,0,0,0.9866765737533568,0.992842435836792,0.9903364181518556,0.0,accept,unanimous_agreement
1125655666,11695,i think we should not allocate and populate that data structure (intset) in case we only have one dict (non-cluster mode),0,0,0,0.983751654624939,0.9846948981285096,0.9841061234474182,0.0,accept,unanimous_agreement
1129046167,11695,"if we read an old rdb, it may still be beneficial not to ignore this opcode and assume even distribution.",0,0,0,0.9825775027275084,0.983856201171875,0.9855127930641174,0.0,accept,unanimous_agreement
1129086529,11695,"done. one challenge was how to avoid resizing db if slot info was present (since db size opcode comes before slot info, but it should be no-op if slot info has more specific instructions). to achieve this, i moved db resizing after opcode loading phase.",0,0,0,0.977748155593872,0.9893144369125366,0.9654077887535096,0.0,accept,unanimous_agreement
1129910948,11695,"yeah, i was testing lru fairness, will revert it back.",0,0,0,0.8827517628669739,0.945068895816803,0.9794705510139464,0.0,accept,unanimous_agreement
1129916258,11695,"in the average case, when keys are randomly distributed across slots, it shouldn't matter if we pick multiple keys from one slot or different slots for sampling. the fact that keys have same crc hash should not matter for lru algorithm efficiency. i think current implementation makes a good tradeoff between general case performance and edge case efficiency. do you have any ideas on how to improve fairness at a reasonable cost?",0,0,0,0.944921612739563,0.973977506160736,0.646053671836853,0.0,accept,unanimous_agreement
1129922409,11695,"there are cases when current client is not null, when we hit max memory in `processcommand`, in that case we need to temporary null out the slot (or client) for the duration of eviction. would you prefer to nullify the client temporarily instead of juggling with the slot?",0,0,0,0.9720351696014404,0.9912508726119996,0.993051052093506,0.0,accept,unanimous_agreement
1129925493,11695,"i believe this is outdated, can't find this code anymore.",-1,0,0,0.9419753551483154,0.5851307511329651,0.7814277410507202,0.0,accept,majority_agreement
1129928462,11695,this function no longer exists.,0,0,0,0.7567071914672852,0.9783656597137452,0.9877884984016418,0.0,accept,unanimous_agreement
1129937469,11695,"i would love to use this bit mask and not have to add/maintain another data structure. however, i fail to see how we can get a random non empty dictionary in o(1) time without additional information of some sort. as oran said, if node owns few slots (say 1% for example), there will be a lot of guess work involved, unless we have some type of indexed data structure that contains owned slots.",0,0,0,0.8603980541229248,0.68551105260849,0.7134060263633728,0.0,accept,unanimous_agreement
1130234744,11695,"ok, i'll change it. the reason why i did it this way, was to avoid custom logic (for cluster mode disabled) in the iterator, but it's quite easy to do it either way.",0,0,0,0.9669987559318542,0.9294072985649108,0.988554060459137,0.0,accept,unanimous_agreement
1131987157,11695,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1131988496,11695,we should use cached slot id here as key is same as from the client's request. so there is no need to recompute hashes.,0,0,0,0.9884653091430664,0.9940098524093628,0.9949427247047424,0.0,accept,unanimous_agreement
1132001291,11695,"you are correct, there is certainly some overhead from the slot iteration, by ""work"" i meant useful work e.g. actual resizing of dictionaries, as you said, amount of memory that should be allocated, zeroed out should be roughly the same. i've added a timer around this loop and it takes less than 0.5ms on average to run this loop on the node with 16k slots, i think you right, this might be a bit too much. i've added an upper limit of 1024 dictionaries per cron iteration and it went down to 30-40 micro seconds under load. how does that sound?",0,0,0,0.8122915625572205,0.9271965026855468,0.9513872861862184,0.0,accept,unanimous_agreement
1132023295,11695,"to be honest, i don't think this would add much value or convenience as there is not much logic to hide there. let me know if you feel strongly about this.",0,0,0,0.7153761386871338,0.6886342763900757,0.7077312469482422,0.0,accept,unanimous_agreement
1132705128,11695,i've added specific checks to keep behavior of cluster mode cursor unaffected.,0,0,0,0.9874474406242372,0.988794445991516,0.9939210414886476,0.0,accept,unanimous_agreement
1132707465,11695,"this function has changed since the comment was posted, i think it should no longer be a concern.",0,0,0,0.9592221975326538,0.9604827165603638,0.9905977845191956,0.0,accept,unanimous_agreement
1132709895,11695,random dict code has been refactored and this should no longer be an issue.,0,0,0,0.985020399093628,0.9898589253425598,0.99321448802948,0.0,accept,unanimous_agreement
1132710214,11695,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1134669565,11695,why isn't this in cluster.h?,0,0,0,0.9369252920150756,0.986668348312378,0.9820038676261902,0.0,accept,unanimous_agreement
1134683110,11695,"we might have issues nulling out the client, since we rely on that for some logic related to client side tracking evictions. i suppose this is what we get for using globals too often. i think we probably don't want to rely on the server.current_client optimization here though, since we're sampling random slots, we should have the slot we want to operate on though and can use it directly. this will mean we need getrandomdict(db) to maybe instead return the slot id.",0,0,0,0.9683245420455932,0.984534502029419,0.9783705472946168,0.0,accept,unanimous_agreement
1134697861,11695,is there a reason we don't use the intset here to get the next slot?,0,0,0,0.97336745262146,0.9927202463150024,0.9925165772438048,0.0,accept,unanimous_agreement
1135008640,11695,moved to cluster.h,0,0,0,0.9563905000686646,0.9877973198890686,0.9841890931129456,0.0,accept,unanimous_agreement
1135011118,11695,changed,0,0,0,0.9773849844932556,0.9270829558372498,0.7968646287918091,0.0,accept,unanimous_agreement
1135051542,11695,"the reason i was thinking about originally doesn't apply anymore, let me just change it.",0,0,0,0.9415457844734192,0.8554867506027222,0.9896113872528076,0.0,accept,unanimous_agreement
1135061726,11695,removed,0,0,0,0.9654131531715392,0.9801433682441713,0.9591778516769408,0.0,accept,unanimous_agreement
1136643746,11695,"well, truth be told, even before that, dictgetsomekeys would keep getting more and more keys from the same dict bucket, and then move to the next one (without calling random again). but in case it hits a stride of empty buckets, it'll then re-random for a different bucket. so first, maybe with the new approach, we should have it exit and re-random for another slot? secondly, to my original point, you're right that for lru related efficiency it doesn't matter much, but it could cause some full slots to be emptied (finding the best lru just from within these slots), and then after eviction, keys will not be evenly distributed across the slots. i suppose this is mainly a concern on small databases, with not many keys per slot. maybe considering that we take only 5 keys from each slot and then re-random, it's not that bad on a common case.",0,0,0,0.8883377313613892,0.9590296149253844,0.9765608906745912,0.0,accept,unanimous_agreement
1136653329,11695,"we still only maintain this intset when cluster is disabled, so: 1. let's avoid allocating it (set it to null), so if there's any code path that reaches it, it'll segfault and we'll fix it. 2. let's add a comment on that var in the header file.",0,0,0,0.9839026927947998,0.989728569984436,0.99415522813797,0.0,accept,unanimous_agreement
1137851877,11695,sounds good.,1,1,1,0.920201539993286,0.9417163729667664,0.857205867767334,1.0,accept,unanimous_agreement
1142226169,11695,[code block] this is actually what we are checking against right?,0,0,0,0.9844020009040833,0.9891937375068665,0.9928507804870604,0.0,accept,unanimous_agreement
1142253805,11695,does this actually work? won't it stick all the keys in the wrong db since it will use the key slot optimization?,0,0,0,0.9602136611938475,0.986072301864624,0.9911609888076782,0.0,accept,unanimous_agreement
1142271855,11695,note. we've decided to not do this.,0,0,0,0.6334485411643982,0.9644116759300232,0.9693999290466307,0.0,accept,unanimous_agreement
1142327784,11695,"i think we could easily modify this so that the iterator can iterate both the keys and the dictionaries together, so there is one interface that can grab both.",0,0,0,0.9863953590393066,0.97866952419281,0.9858497381210328,0.0,accept,unanimous_agreement
1143791798,11695,"yes, i think that the number of slots is an optimal value here. i still like having a separate constant for this as technically we might want to tweak this in the future. would you prefer to make it simpler and just use cluster_slots instead?",0,0,0,0.8797757625579834,0.8828384280204773,0.8885053992271423,0.0,accept,unanimous_agreement
1143794707,11695,"it's fine, perhaps `keys` is a confusing name, in fact it's just a key count, this function call doesn't add anything to the dictionary, and instead just resizes the db. as to populate command itself, it will work fine because as a not key command it doesn't populate slot id, so keys will go to correct dictionaries.",0,0,0,0.9788001775741576,0.98592871427536,0.8795204162597656,0.0,accept,unanimous_agreement
1143803729,11695,"i didn't touch this line, besides current form is how ide prefers to format it, perhaps we should reformat other strings instead, but we should probably do that as a separate commit.",0,0,0,0.97195303440094,0.9793391823768616,0.9859811067581176,0.0,accept,unanimous_agreement
1143915912,11695,removed,0,0,0,0.9654131531715392,0.9801433682441713,0.9591778516769408,0.0,accept,unanimous_agreement
1143943552,11695,"okay, added `dictiterator` field to `dbiterator`, and introduced ability to iterate entries using new `dbiteratornext` function.",0,0,0,0.9888612627983092,0.984890639781952,0.9891760945320128,0.0,accept,unanimous_agreement
1144001211,11695,some duplicated code. idea: [code block],0,0,0,0.9884804487228394,0.9837546944618224,0.9875465035438538,0.0,accept,unanimous_agreement
1144045489,11695,"made it use cluster_slots, we can always add a new constant later if we want to.",0,0,0,0.9888712763786316,0.9930062294006348,0.9940429329872132,0.0,accept,unanimous_agreement
1144082037,11695,"i like it, looks nicer this way. thanks.",1,1,1,0.9753738045692444,0.9939422011375428,0.9935373663902284,1.0,accept,unanimous_agreement
1156514208,11695,[code block] this check is already in cumulativekeycountadd,0,0,0,0.9890825748443604,0.9896672964096068,0.9948710203170776,0.0,accept,unanimous_agreement
1156520031,11695,"[code block] too verbose? i know we talked about this, but the name doesn't actually indicate what it is.",0,0,0,0.9565919041633606,0.8773728013038635,0.7002238035202026,0.0,accept,unanimous_agreement
1156521560,11695,these changes aren't needed anymore.,0,0,0,0.9665637016296388,0.9754608273506165,0.9891814589500428,0.0,accept,unanimous_agreement
1156521614,11695,ditto about this.,0,-1,-1,0.8497233390808105,0.8629909753799438,0.6253005862236023,-1.0,accept,majority_agreement
1157873723,11695,true,0,0,0,0.970885157585144,0.905175805091858,0.7606672048568726,0.0,accept,unanimous_agreement
1159276201,11695,"let's call it `slot_size_index`, and if anyone is interested in what kind of index, then they can go and read the comment.",0,0,0,0.9881711006164552,0.9864952564239502,0.993690013885498,0.0,accept,unanimous_agreement
1159278282,11695,"why? line above doesn't have spaces. i suggest we keep it as is, we should probably commit to a common code style and reformat entire codebase some day.",0,0,0,0.9828413724899292,0.9742116332054138,0.9776265621185304,0.0,accept,unanimous_agreement
1159281464,11695,"true, it's not necessary, i was hoping to avoid extra function call when cluster mode is disabled, but the cost must be negligible.",0,0,0,0.9756031036376952,0.957452356815338,0.990217387676239,0.0,accept,unanimous_agreement
1159324210,11695,"addressed this by introducing a separate function `calculatekeyslot`, which unlike `getkeyslot` would never use cached value. we should use this function everywhere where we may need to operate on random keys that don't belong to the same slot as client's command (e.g. eviction, defrag, etc)",0,0,0,0.9887353777885436,0.9944002032279968,0.9944885969161988,0.0,accept,unanimous_agreement
1159325706,11695,please look at the most recent version where fairness issues were addressed. this comment explains approach that i took [a link],0,0,0,0.9764377474784852,0.967941164970398,0.9938808679580688,0.0,accept,unanimous_agreement
1167284488,11695,are you planning to also make the `expire` dictionary to be per slot? it is pretty much a mirror image of the main dictionary. if you want per slot then you should also do the same for `expire` dictionary,0,0,0,0.9803674221038818,0.9901752471923828,0.9930805563926696,0.0,accept,unanimous_agreement
1167302754,11695,"to get all the keys in a slot, we don't need one expire dict per slot.",0,0,0,0.9844529032707214,0.9915319085121156,0.9919958114624025,0.0,accept,unanimous_agreement
1176044220,11695,there is no benefit in splitting expiry dictionary per slot as it doesn't have any memory overhead in cluster mode.,0,0,0,0.9719482064247132,0.9761408567428588,0.9878382682800292,0.0,accept,unanimous_agreement
1181115647,11695,ok makes sense.,0,0,0,0.9771789312362672,0.9806748032569884,0.9621150493621826,0.0,accept,unanimous_agreement
1226137086,11695,we can just perform a right shift without an extra bitwise and operation?,0,0,0,0.9876279830932616,0.9888701438903807,0.9927223324775696,0.0,accept,unanimous_agreement
1226163452,11695,"i thinks we should also split the expire dictionary, one slot should be a atomic unit including the expire data. and it's useful to implement something like `flushslot [slot] async`",0,0,0,0.9715609550476074,0.9865931868553162,0.987446427345276,0.0,accept,unanimous_agreement
1226197315,11695,"using a list holding the dict pointer is very dangerous i think, it's easy to forget clear the pointer in queue when releasing the dict. the way in `tryresizehashtables` can be used to rehash safely.",-1,0,-1,0.9030061960220336,0.7754897475242615,0.588991105556488,-1.0,accept,majority_agreement
1242873837,11695,"i believe we originally wanted to avoid this since it would make the `volatile *` eviction policies much more difficult. i think that was before we came up with the idea with the fenwick trees, so this might be a lot simpler to implement now.",0,0,0,0.8988504409790039,0.9814524054527284,0.9842774868011476,0.0,accept,unanimous_agreement
1268950693,11695,"i agree, it's potentially error prone, this code was developed before efficient db iteration was introduced, so i haven't tried it yet. let me check performance numbers and update it if it works well.",0,0,0,0.9548631310462952,0.9259945750236512,0.9118595123291016,0.0,accept,unanimous_agreement
1292756226,11695,there's a tab in that line.,0,0,0,0.9848175644874572,0.9858280420303344,0.9900836944580078,0.0,accept,unanimous_agreement
1292757596,11695,"is this a badly resolved merge conflict? i.e. iirc recently we changed this code to use **try**expand, and added an error reply.",0,0,0,0.9258409738540648,0.960253119468689,0.9732969403266908,0.0,accept,unanimous_agreement
1292758269,11695,"maybe we can create a new `dbfind` to be used instead of `dictfind`? this way, instead of adding the extra call to getkeyslot in each of these lines (referring to the key name in argv twice), we'll just replace the name of the function we're calling. this pattern is used a lot. in contrast to dictadd and dictdelete and other places that call getkeyslot.",0,0,0,0.97788405418396,0.9941942095756532,0.9886441230773926,0.0,accept,unanimous_agreement
1292765850,11695,i'm not sure if we have test coverage for defrag in cluster-enabled mode. let's add one.,0,0,0,0.8853116035461426,0.8948317170143127,0.962160050868988,0.0,accept,unanimous_agreement
1292789825,11695,"can you confirm (and maybe mention it in the comment), that is guaranteed not to return a dict that's empty (unless the entire db is empty). if that's not the case, i think we have bugs in evict.c",0,0,0,0.9864118099212646,0.9907564520835876,0.9934367537498474,0.0,accept,unanimous_agreement
1292790375,11695,"before this change, we would get 5 samples from each db. now for cluster enabled, we'll get 5 samples the first db, and can get less from other dbs. that's ok since in cluster enabled there's only one db.. we do plan to support multi-db un-sharded clusters some day, but i suppose that when we do, these will also have just one dict, and this condition will be changed. maybe it's a good idea to introduce `server.sharding_enabled` in parallel to `cluster_enabled` at this point in time? wdyt?",0,0,0,0.9103489518165588,0.9308269619941713,0.9277614951133728,0.0,accept,unanimous_agreement
1292794495,11695,"we've expanded (copy paste) dictmemusage here. which means that if it'll some day change, this code can remain outdated. maybe we can improve? maybe a form of dictmemusage that takes counters as input?",0,0,0,0.9865548610687256,0.9825173020362854,0.986215591430664,0.0,accept,unanimous_agreement
1292796228,11695,"i see we have a few usages of `long long int`, any reason not to drop the `int` part? (more common to omit it)",0,0,0,0.9858542084693908,0.9911887645721436,0.9896146655082704,0.0,accept,unanimous_agreement
1292796905,11695,we have to increment rdb_version to 12,0,0,0,0.9868637323379515,0.9877585768699646,0.9942516088485718,0.0,accept,unanimous_agreement
1292797474,11695,in order to ignore gracefully you must skip the data! i.e. call rdbloadlen twice. move this condition to below the reading lines...,0,0,0,0.8538066744804382,0.867982029914856,0.9622608423233032,0.0,accept,unanimous_agreement
1292797856,11695,"this is a bug (we must read / skip the data). in fact, there's no need for this line at all since we're not doing anything with this info.",0,0,0,0.5642857551574707,0.9499571323394777,0.981952965259552,0.0,accept,unanimous_agreement
1292798033,11695,"the indentation was off before, but it seems off after too. or maybe i'm missing something, and there are hidden tabs here? in any case, there's no need to modify this line or file in this pr, please revert.",0,0,0,0.9723977446556092,0.9742040634155272,0.9909586906433104,0.0,accept,unanimous_agreement
1292798495,11695,why did you have to remove this assertion (and the other one below)?,0,0,0,0.976870059967041,0.9885107278823853,0.9886152744293212,0.0,accept,unanimous_agreement
1292800999,11695,how could this happen? maybe an assertion is appropriate?,0,0,0,0.9732947945594788,0.9710073471069336,0.9879387617111206,0.0,accept,unanimous_agreement
1292807716,11695,"i don't think cme and cmd are therms we use in the code base. maybe it's fine to use them in a conversation / discussion to be prompt, assuming the context is set, but let's avoid using them in official code / docs.",0,0,0,0.9689863920211792,0.9898281097412108,0.9240784645080566,0.0,accept,unanimous_agreement
1292811014,11695,"let's optimize mass insertion (mset), and increment once instead of per-key? we can certainly optimize rdb loading, in the cases were we know the source rdb is already sorted by slot (new format)! maybe we can also do that with multi-exec, and scripts which is guaranteed to be in the same slot by somehow summing the new keys and updating the count when execcommand / evalcommand returns? this way we'll still be able to tell people to use scripts and pipeline (with transaction :disappointed:) instead of suggesting to add fancy multi-key commands (e.g. think of a multi incr). i know that's a bit problematic since the multi-exec can contain commands that require that data (e.g. randomkey), so we'll need some late invalidation mechanism (to apply the pending changes before needing them) if we go that direction, we can maybe handle dbgenericdelete in the same way.",0,0,-1,0.5540542602539062,0.9734511375427246,0.9701207876205444,0.0,accept,majority_agreement
1292812019,11695,shouldn't this line be placed inside the above block (i.e. only when switching db)? i'm probably missing something. please have a look at it.,0,0,0,0.9064759016036988,0.9626030325889589,0.954857587814331,0.0,accept,unanimous_agreement
1292813029,11695,"lets add a comment that it's 1 based. or even say that the range is `[1 .. dbsize+1]` also, let's mention the complexity formula.",0,0,0,0.9876182079315186,0.9900628924369812,0.9934906959533693,0.0,accept,unanimous_agreement
1292826277,11695,why not just memset to 0?,0,0,0,0.9677950143814088,0.974128007888794,0.9874552488327026,0.0,accept,unanimous_agreement
1292828415,11695,"why `strtouq`? isn't `strtoull` more appropriate? and actually, maybe we should use our own `string2ull` which is suppose to be faster.",0,0,0,0.9867807030677797,0.9928680658340454,0.9831390976905824,0.0,accept,unanimous_agreement
1292831083,11695,can't we use the updates binary index tree for this for a slightly faster calculation?,0,0,0,0.9841735363006592,0.9931790828704834,0.9926068782806396,0.0,accept,unanimous_agreement
1292833958,11695,"styling: i think i'd rather add a line break here, and maybe even curly brackets.",0,0,0,0.9784222841262816,0.9507715702056884,0.9882982969284058,0.0,accept,unanimous_agreement
1294236533,11695,"i think there's a problem here with scripts that declared script_allow_cross_slot. this also brings me to a realization, that i'm not sure we have any way to detect bugs in this mechanism. i.e. we don't have tests that can detect keys being placed in the wrong dict. and we don't have any assertions when the binary index tree is decremented below 0.",0,0,0,0.6676327586174011,0.9244019985198976,0.9561650156974792,0.0,accept,unanimous_agreement
1301445632,11695,"it seems like we could utilize the binary lifting strategy instead of binary search, which has the potential to optimize the complexity to log(n). [a link].",0,0,0,0.9838528633117676,0.989643096923828,0.989440143108368,0.0,accept,unanimous_agreement
1312218315,11695,"it struck me that this code applies runs not only to scan but also on hscan, sscan, etc. as long as it's implemented as a dict. we should check `o == null` to make sure it applies only to scan. [code block]",0,0,0,0.9589803814888,0.98623788356781,0.9722280502319336,0.0,accept,unanimous_agreement
1312220073,11695,"we should probably only encode the slot in the cursor if we're scanning the keyspace, i.e. scan, not hscan, sscan, etc. [code block]",0,0,0,0.987752079963684,0.9945471286773682,0.9942627549171448,0.0,accept,unanimous_agreement
1314145234,11695,let's list this in the top comment (together with any other user visible changes),0,0,0,0.9884656667709352,0.9909748435020448,0.9953533411026,0.0,accept,unanimous_agreement
1316761037,11695,"i'm not sure this graceful error handling is needed. we do that when loading individual keys, in order to fail gracefully on a corrupt or malicious restore command. but i'm not sure that's needed on rdb loading / full-sync. was there any discussion about that that i missed? p.s. if we do that, we should also do it for the expires dict and the per-slot dicts.",0,0,0,0.8565952181816101,0.9645397663116456,0.9776484370231628,0.0,accept,unanimous_agreement
1316767478,11695,"is this related to [a link] p.s. i think the log message is insufficient, we don't know which dict we failed to allocate and what was it's size. i suggest to either improve the log message, or pass a boolean argument to expanddb to cause it to use zcalloc instead of ztrycalloc in which case it'll panic with full stack trace and the requested size.",0,0,0,0.9382954239845276,0.9847311973571776,0.9901140928268432,0.0,accept,unanimous_agreement
1317514507,11695,"i did try to increment rdb_version. however, one of the test `unit/expire` fails due to encoded value comparison. [code block] our validation is to do a `string match `on the following `{restore foo17 * {*} absttl}` rdb_version - 11 [code block] rdb_version - 12 [code block] i don't understand tcl well. are the curly bracket is a literal match or to compare list of string within it ? note: rdb version bump on unstable also leads to failure of this test.",0,0,0,0.9500784277915956,0.9589447379112244,0.984022617340088,0.0,accept,unanimous_agreement
1317516764,11695,"yeah, i was trying to address that particular comment.",0,0,0,0.8490009307861328,0.7039316892623901,0.9750463962554932,0.0,accept,unanimous_agreement
1318148081,11695,"i don't know tcl that well either. what seems to happen is that a list in tcl is usually represented as a chain of words in `{}`, and so is a sub-list. in this case, either the dump payload no longer contains spaces so it doesn't need to be wrapped in `{}`, or because it contains s `}` char that gets escaped, it decided to escape more symbols and dropped the `{}` wrapping. in any case, the solution (i tested it), is to change `{*}` with just `*`. i.e. `{restore foo6 * * absttl}`",0,0,0,0.9499767422676086,0.9839143753051758,0.9535107612609864,0.0,accept,unanimous_agreement
1319028481,11695,"i can confirm this seems right! `read_from_aof` uses `lappend` to build its result. when `lappend` appends a string that contains spaces, it wraps it in `{}` but now it doesn't seem to contain spaces anymore. [code block] and yes because it contains a `}` which maybe can't be written inside `{}`, because if it's escaped, the backslash is added to the string too... look: [code block]",0,0,0,0.8305128216743469,0.9377623796463012,0.6453158855438232,0.0,accept,unanimous_agreement
1319081805,11695,thanks both of you / . i think both `{restore foo6 * * absttl}` and `{restore foo6 * absttl}` have the same meaning. i will stick to what oran proposed for better readability in the test.,1,1,1,0.9353085160255432,0.9776421785354614,0.9872892498970032,1.0,accept,unanimous_agreement
1320140467,11695,"let's give them a common prefix, and maybe add a comment in the int / unsigned variables / arguments below that they use this type. alternatively, we can better use an enum type.",0,0,0,0.987472414970398,0.9918240904808044,0.9923633337020874,0.0,accept,unanimous_agreement
1320151536,11695,"it's not ""by type"", it's ""from iterator"". rename?",0,0,0,0.9857816100120544,0.9900524020195008,0.9924529194831848,0.0,accept,unanimous_agreement
1320154078,11695,"what's ""mid""? it's out of context here, let's rename, and add a comment describing the function",0,0,0,0.983244776725769,0.9426150918006896,0.9904022216796876,0.0,accept,unanimous_agreement
1320167467,11695,"in theory, we already have a slot here (we get here from a dict iterator, so we know which dict (slot) we're working on). see if you can improve.",0,0,0,0.9788029193878174,0.983301043510437,0.991443693637848,0.0,accept,unanimous_agreement
1320169131,11695,"fixme? p.s. i suppose we don't have any test with cluster mode and expire that does defrag. i think we must add one for code coverage, otherwise it could explode in production running untested code due to some silly typo.",0,0,0,0.8242651224136353,0.9669154286384584,0.6918535232543945,0.0,accept,unanimous_agreement
1320171941,11695,the dictfind -> dbfind wrapper i suggested in a comment of a previous review would fit here too,0,0,0,0.9866900444030762,0.9919689297676086,0.9943125247955322,0.0,accept,unanimous_agreement
1320187490,11695,"it's a little hard for me to follow the code here (probably due to using small monitor with gh, and being too lazy to clone the code). i have a feeling something is odd here, why is this code not needed in cluster mode? can we somehow avoid duplicating this logic and big comment?",-1,-1,-1,0.9614999294281006,0.9584646224975586,0.8372025489807129,-1.0,accept,unanimous_agreement
1320188809,11695,"maybe we can create a dbscan() interface, instead of messing with the cursor here? imagine we'll need such scan in another place (or a few others) in the future, i don't like to keep cloning that logic. iirc we do that in module.c too already.",0,0,0,0.8813133239746094,0.8960345983505249,0.9713966846466064,0.0,accept,unanimous_agreement
1320191138,11695,isn't that `continue` wrong? we skip the `mh->num_dbs++`,0,0,0,0.9635412096977234,0.991555392742157,0.9921953678131104,0.0,accept,unanimous_agreement
1320192570,11695,i think i already commented on that in a previous review. this code assumes things on the dict internals. we need to move that part of logic to dict.c,0,0,0,0.983998954296112,0.9859521389007568,0.9819085597991944,0.0,accept,unanimous_agreement
1320195409,11695,"i think it's wrong not to save the rdb_opcode_resizedb opcode when cluster mode is enabled. the rdb should still contain this opcode, even if it's unlikely for the reader to use it.",0,0,-1,0.7195847630500793,0.9326592683792114,0.5790491700172424,0.0,accept,majority_agreement
1320197214,11695,"again, same bug as before (which was just resolved the other day and now reintroduced. you can't skip the reading part. in order to ignore gracefully, you need to read the data and then not use it.",0,0,0,0.8952882885932922,0.8896123766899109,0.8019166588783264,0.0,accept,unanimous_agreement
1320704529,11695,"i don't think it makes sense in this pr, since it's not a complete implementation. it probably makes sense to have one holistic pr that will add the sharding enabled.",0,0,0,0.8047422766685486,0.9728158116340636,0.945723295211792,0.0,accept,unanimous_agreement
1320717009,11695,"if we can, i think we should be across the board abstracting away the notion that the main dict and the key/value dict are two separate dictionaries. why wouldn't we just have a single, ""expanddict(db, keys, expires"".",0,0,0,0.9833199381828308,0.9892413020133972,0.986601173877716,0.0,accept,unanimous_agreement
1320718335,11695,"i also don't really like this. it's tightly coupling the assumption that expires and keys must be two separate dictionaries. i would rather have apis that are more semantically useful (getexpirecount, getkeycount) then have the same apis. the dict_type_max seems to only be used 2 real places for iteration, even though there are a lot of other places we could probably iterate over it as well if we want to keep it. if we really want to keep this, is should also be an enum.",-1,-1,-1,0.9829225540161132,0.9103829264640808,0.9413647055625916,-1.0,accept,unanimous_agreement
1320720703,11695,"[code block] db_type implies this is the type of db. this is more like a subordinate dictionary. don't really like the name though, and am open to alternatives.",-1,-1,0,0.9506990313529968,0.5612197518348694,0.7328736186027527,-1.0,accept,majority_agreement
1320720791,11695,this name no longer makes sense since it's on a dictionary and not the database.,0,0,0,0.7820187211036682,0.9709855318069458,0.9600660800933838,0.0,accept,unanimous_agreement
1320721542,11695,is this for handling the non cluster mode case? i don't know what other case any of the dictionaries wouldn't be populated. maybe we should do something like just check that right away to be clearer.,0,0,0,0.979446291923523,0.915587604045868,0.9860154390335084,0.0,accept,unanimous_agreement
1327579747,11695,"we're still leaving a bunch of unnecessary code touches, we should clean these up.",0,0,0,0.85400390625,0.6604475975036621,0.7528352737426758,0.0,accept,unanimous_agreement
1327590732,11695,"i suppose this comment is no longer quite accurate, as this code is now more complex.",0,0,0,0.7179118990898132,0.8557185530662537,0.970088005065918,0.0,accept,unanimous_agreement
1327592446,11695,"this seems high, do we need to be so aggressively looking for hash tables to resize?",0,0,0,0.838070273399353,0.6182222962379456,0.9821723103523254,0.0,accept,unanimous_agreement
1327594164,11695,"i don't understand why these are breaks and not continues. if the database has no expires, we will check one dict per cron, which doesn't seem like the intended behavior.",0,-1,-1,0.8410122990608215,0.5257734656333923,0.5837623476982117,-1.0,accept,majority_agreement
1327596070,11695,"these are not db iterator specific functions, but they are under the heading.",0,0,0,0.9882652759552002,0.9905961751937866,0.9937703013420104,0.0,accept,unanimous_agreement
1327597017,11695,"if we can, let's make this opaque and have apis for accessors. i also think this is the one usage of dicttype that i think makes sense. i would prefer it be flags on the iterator type though, and not dicttype.",0,0,0,0.9747276902198792,0.9670936465263368,0.9823721051216124,0.0,accept,unanimous_agreement
1331933629,11695,i have added the prefix as `dict_main` and `dict_expires` and defined an enum for for this. i tried separate apis and think its resulting in a lot of repetitive code. i am looking over to optimize in more places by using `dict_type_max`.,0,0,0,0.873222827911377,0.987062394618988,0.8746015429496765,0.0,accept,unanimous_agreement
1331939477,11695,"yes, to make it more clear, changed it to `dictsizebyslot`",0,0,0,0.986974835395813,0.994030773639679,0.9936641454696656,0.0,accept,unanimous_agreement
1333632643,11695,this is changed to `getfairrandomslot` and it guarantees that it returns a slot whose dict is not empty unless the db is empty. adding the comment.,0,0,0,0.9893429279327391,0.9932286739349364,0.9958928823471068,0.0,accept,unanimous_agreement
1336288520,11695,"here, we are calculating the slots in the dictionary. binary index tree cannot be utilized here.",0,0,0,0.9869601726531982,0.993098795413971,0.9926538467407228,0.0,accept,unanimous_agreement
1337729812,11695,it's still valid at an individual ht level though(dictionary per slot).,0,0,0,0.9890170097351074,0.9933525323867798,0.993466317653656,0.0,accept,unanimous_agreement
1337731015,11695,i think we can piggyback on the cron_dbs_per_call value and no need to introduce a new constant. wdyt ?,0,0,0,0.9812522530555724,0.9820797443389891,0.9857138395309448,0.0,accept,unanimous_agreement
1337760630,11695,i think there is two things. 1. we are now overloading the term slot to mean two different things. we should probably update it to be bucket. 2. i think it's still worth mentioning this is now incremental. a single ht might be full but it will take some time to reclaim it.,0,0,0,0.9453944563865662,0.9778751134872437,0.9720317721366882,0.0,accept,unanimous_agreement
1338176842,11695,"ohh, i was mixing `slots` with `keys`",0,0,0,0.977417528629303,0.9100348949432372,0.9606406092643738,0.0,accept,unanimous_agreement
1338191872,11695,maybe we should rename dictslots to dictbuckets to avoid the confusion? dictslots is only used in a handful of places within the repo. or create an alias. it's a macro anyway.,0,0,0,0.9866216778755188,0.989840567111969,0.984331488609314,0.0,accept,unanimous_agreement
1338441289,11695,"i don't think that's what caused my confusion, but i support the above suggestion (avoiding using the term ""slots"" there)",0,0,0,0.8328958749771118,0.9596792459487916,0.9545433521270752,0.0,accept,unanimous_agreement
1340693875,11695,"just +1, we talked about this offline and it's buried somewhere in one of my comments.",0,0,0,0.9589648246765136,0.9591954350471495,0.9794296026229858,0.0,accept,unanimous_agreement
1342092275,11695,i don't see this used in dict.h or dict.c? maybe it doesn't belong here?,0,0,0,0.9577342867851256,0.9799259305000304,0.96855229139328,0.0,accept,unanimous_agreement
1342092399,11695,maybe we can remember this from outside? we know which dict we're scanning..,0,0,0,0.9801586270332336,0.9891051650047302,0.986928403377533,0.0,accept,unanimous_agreement
1342096590,11695,"i think the prefix should be db, not dict. how about this? [code block]",0,0,0,0.986177146434784,0.9916348457336426,0.9895654916763306,0.0,accept,unanimous_agreement
1342101817,11695,"i still think the slots*sizeof(dictentry*) part belongs in dict.c and maybe the sizeof(dict) too. maybe instead of calling a plain `dictentrymemusage()` we should call `size_t dictmemoryusage(int dicts, long long slots, long long keys)` or alike?",0,0,0,0.9873946905136108,0.9933329224586488,0.9857497215270996,0.0,accept,unanimous_agreement
1342104795,11695,"i'll state again that i think this method should get an argument weather to use dictexpand or dicttryexpand. in case it was called from rdb.c, i think it should panic in zmalloc and not fail gracefully.",0,0,0,0.9828192591667176,0.9792170524597168,0.9855005145072936,0.0,accept,unanimous_agreement
1342106028,11695,"shouldn't we move to the next slot when the `valid()` return err? otherwise, the loop in expire.c will just keep looping, instead of maybe breaking out? am i missing something? p.s. i suppose we should make sure this is covered by tests.",0,0,0,0.9852049350738524,0.9790436029434204,0.9802300930023192,0.0,accept,unanimous_agreement
1342106466,11695,"that's a bit awkward, this tip was created for a different reason, and the assumption that only in this flow we have to calculate the slot rather than use the cached one seems odd and dangerous. at the very least, there should be a big comment here, but i'd rather find another solution. let's discuss.",-1,-1,-1,0.9423251748085022,0.9766671657562256,0.9833996891975404,-1.0,accept,unanimous_agreement
1342965673,11695,the other solution which i thought about was we could provide the slot information which is already available in the eviction code flow but would require us to introduce another method or alter the parameters in this api and affect all other callers.,0,0,0,0.9846530556678772,0.9920973777770996,0.990794837474823,0.0,accept,unanimous_agreement
1342965999,11695,damn i missed this case. let me handle it.,-1,-1,-1,0.9879770874977112,0.9877015948295592,0.994838297367096,-1.0,accept,unanimous_agreement
1342966342,11695,sure.,0,0,0,0.9536533951759338,0.9664214849472046,0.9824982285499572,0.0,accept,unanimous_agreement
1343033256,11695,i think `dict.h` api(s) should be at a dictionary unit level and shouldn't be providing results for multiple of it. the above logic seems well abstracted under `db.c` which is now using multiple dictionaries to store the data.,0,0,0,0.9869996905326844,0.9935981035232544,0.9854249358177184,0.0,accept,unanimous_agreement
1343225850,11695,it's slightly difficult to pause the scanning for a slot while it is in progress and undergoes a large data cleanup to have 99% buckets empty. i've added a test case to verify the skip logic is handled and the slot iteration continues.,0,0,0,0.974692702293396,0.9132513403892516,0.9774897694587708,0.0,accept,unanimous_agreement
1343226831,11695,made it inline.,0,0,0,0.9787485599517822,0.9856269359588624,0.9937998652458192,0.0,accept,unanimous_agreement
1343233941,11695,any thoughts. she liked `dbkeytype` as it signifies if the key would be actual data or expire data. could we discuss here and finalize ? i don't have a strong preference here tbh.,1,0,0,0.5376524925231934,0.7942095398902893,0.7369648218154907,0.0,accept,majority_agreement
1343267483,11695,"i agree with the highest level comment, it should be db and not dict, since it's on the db and not the dict. [code block] the other point is i don't want to be exposing that there are two underlying dictionaries for the two types of accesses into the main db. you are either accessing the main keys or volatile keys.",0,0,0,0.979042112827301,0.9824297428131104,0.9802788496017456,0.0,accept,unanimous_agreement
1343282560,11695,setexpire is called unconditionally in various places on the expiry. this increment should depend on whether or not the object existed had an expire.,0,0,0,0.98568993806839,0.9882425665855408,0.993392050266266,0.0,accept,unanimous_agreement
1343307173,11695,"even if we don't implement this, let's follow up. i'm not sure i followed the link, but i do intuitively believe that finding a slot by index should ~o(log(n))",0,0,0,0.9470277428627014,0.9294531345367432,0.98541522026062,0.0,accept,unanimous_agreement
1343322839,11695,"maybe inside of calculatekeyslot() we should be evaluating whether or not we're in the main command execution part (i.e., inside the call, i think the flag is `client_executing_command`). the slot is only valid during the command execution, not during other side effects.",0,0,0,0.9887268543243408,0.9944844841957092,0.9883853197097778,0.0,accept,unanimous_agreement
1343326099,11695,how does this disable resizing?,0,0,0,0.963118612766266,0.9670526385307312,0.9946611523628236,0.0,accept,unanimous_agreement
1343328854,11695,"this shouldn't be included here, since there is no dependencies in rdb.h for cluster stuff. probably needs to be in some other file, probably rdb.c",0,0,0,0.987095057964325,0.9924151301383972,0.9857967495918274,0.0,accept,unanimous_agreement
1343390833,11695,never ending bgsave forbids dict expansion/contraction.,0,0,0,0.8741815686225891,0.9301945567131042,0.9610671997070312,0.0,accept,unanimous_agreement
1343441561,11695,removed.,0,0,0,0.9311882257461548,0.9782117605209352,0.9612457156181335,0.0,accept,unanimous_agreement
1343446553,11695,"good catch, done.",1,1,1,0.954816997051239,0.9627410173416138,0.9759638905525208,1.0,accept,unanimous_agreement
1343447340,11695,done. need to retrieve the dict slightly lower down in the code.,0,0,0,0.9820644855499268,0.9889224767684937,0.9931957721710204,0.0,accept,unanimous_agreement
1343552314,11695,"i thought of that too, but i was also afraid that some side effect mechanism will attempt to access other keys from within call as well, like eviction does. i suppose we don't have these in redis (e.g. no eviction in exec or eval, and i can't think of anything else like that). we do have both scripts and modules accessing random keys inside commands, and these should be handled separately (please ack). so bottom line, i support your suggestion, please also add some comments around that.",0,0,0,0.8746656775474548,0.8734068274497986,0.6673524379730225,0.0,accept,unanimous_agreement
1343629986,11695,please add some volatile keys to the defrag test.,0,0,0,0.9859678745269777,0.9943718910217284,0.9947901964187622,0.0,accept,unanimous_agreement
1343641047,11695,this one is still not resolved.,0,0,0,0.809699296951294,0.9346731305122375,0.7068095207214355,0.0,accept,unanimous_agreement
1343644700,11695,"ok, but the `sizeof(dictentry*)` and maybe `sizeof(dict)` shouldn't be here. i.e. the knowledge that the lookup table has a pointer per bucket, better go to dict.c imo.",0,0,0,0.9866369366645812,0.994292378425598,0.9906705617904664,0.0,accept,unanimous_agreement
1343654295,11695,"why ""skipped""? if it's a try_expand and it failed, we handled it above. if it was a !try_expand and it failed, then it panicked and killed the process. so here we know we succeeded.",0,0,0,0.9557644724845886,0.990885853767395,0.988803207874298,0.0,accept,unanimous_agreement
1343656272,11695,"ohh, now it is.",0,0,0,0.863892138004303,0.9645105600357056,0.8663117289543152,0.0,accept,unanimous_agreement
1344382453,11695,updated to print only on `dict_err` `dictexpand` can return `dict_err` if no expansion happens due to certain conditions. it is not equivalent to the panic/oom kill.,0,0,0,0.9825308918952942,0.9872075915336608,0.9933003187179564,0.0,accept,unanimous_agreement
1344479284,11695,[code block] from [a link] let's only use this optimization when we are executing a command.,0,0,0,0.9869128465652466,0.9908962845802308,0.9938307404518129,0.0,accept,unanimous_agreement
1344532289,11695,"i don't see any response on this, so will add my two-cents. this seems like optimizing before understanding the bottleneck. i'm not too worried about the performance, since we expect most of the binary tree to remain in memory so subsequent updates should be fast. i'm also weirdly uncomfortable with having the index tree be slightly out of date when doing multi-execs. implementing logic to invalidate it is adding a lot more complexity that we try to generally avoid.",-1,-1,-1,0.9735935926437378,0.9791700839996338,0.9856591820716858,-1.0,accept,unanimous_agreement
1344641560,11695,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1344754786,11695,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1344857519,11695,"i would like to stick with this. let me know if you have a strong objection, we can revisit.",0,0,0,0.9522106051445008,0.7173284292221069,0.9625393152236938,0.0,accept,unanimous_agreement
1345229316,11695,"this could maybe cause issues for the fragmentation thresholds of this test. any reason not to greatly reduce the number of keys? i.e. as soon as we have some volatile keys (e.g. 1), that code path is covered (even if we don't re-locate them). alternatively, if we wanna check that when we relocate a key name, the other dict is updated, i think we should set some ttls to a few keys in the `asdf1` group (the one that suffers from eviction) i.e. [code block] or maybe a loop to set it to the first 100 and last 100 keys in each range? i don't want more since i'm afraid it'll de-stabilize the fragmentation thresholds of the test. wdyt?",0,0,0,0.97597074508667,0.9899501800537108,0.9857929348945618,0.0,accept,unanimous_agreement
1345232985,11695,"by ""remain in memory"" you mean the cpu cache, right? that's still an o(logn) operation, which we can completely avoid if we unify them. maybe we can conduct a simple benchmark with mset of 10 keys, and compare the performance?",0,0,0,0.9859251379966736,0.9885685443878174,0.9900854825973512,0.0,accept,unanimous_agreement
1345235416,11695,"this one is now resolved with the change you did in `tests/unit/cluster/scripting.tcl`, right? please add a comment in these checks you added there describing their purpose.",0,0,0,0.98865407705307,0.9913613200187684,0.9957324862480164,0.0,accept,unanimous_agreement
1345238957,11695,no strong objection.,0,0,0,0.9618794322013856,0.9239287972450256,0.9716310501098632,0.0,accept,unanimous_agreement
1346231633,11695,"i played around with some numbers ranging [10000,100000] and `10000` looked pretty safe in terms of frag ratio and time took for defrag to complete. your suggestion seems to cover more cases though, will try to incorporate it.",0,0,0,0.9252750873565674,0.9597951769828796,0.9286697506904602,0.0,accept,unanimous_agreement
1346304565,11695,added very small set of volatile keys to the existing keys `asdf1*` and `asdf2*`. it should ideally undergo some eviction code flow as well as scan through expire dictionary during defrag.,0,0,0,0.9872057437896729,0.994721531867981,0.9948838353157043,0.0,accept,unanimous_agreement
1346834224,11695,"i mean, if we do a ""defrag later"" step after each dict, rather than after each db, we'll maintain a shorter list of defrag later keys, and we won't need to do the calculatekeyslot overhead.",0,0,0,0.985592007637024,0.9909995198249816,0.9892054796218872,0.0,accept,unanimous_agreement
1347988746,11695,made the code change to handle defraglaterstep to be processed after each scan of slot.,0,0,0,0.985757291316986,0.9939299821853638,0.9953184723854064,0.0,accept,unanimous_agreement
1348251328,11695,~~there is some issue with the current implementation causing a crash. investigating.~~ fixed.,0,0,0,0.9419914484024048,0.5658712387084961,0.9641475081443788,0.0,accept,unanimous_agreement
1348322380,11695,please have a look at the implementation and let me know what you think about it.,0,0,0,0.97139972448349,0.9654349088668824,0.9280864000320436,0.0,accept,unanimous_agreement
1349679408,11695,"defraglaterstep returns true if more work is needed. so why do we need this? taking a closer look, i think the code before this change already handled the defraglater after each dict. am i missing something?",0,0,0,0.970881462097168,0.9670923352241516,0.9879635572433472,0.0,accept,unanimous_agreement
1352854349,11695,"in the earlier logic, the next slot discovery used to happen as soon as the main/expires dict scan was completed. and the defrag_later list would be non-empty at that point. like we discussed above, we wanted to reuse the slot information in the defraglaterstep and avoid the recomputation. this change avoids the next slot discovery until the defrag_later list becomes empty.",0,0,0,0.9853590726852416,0.9931504130363464,0.989655613899231,0.0,accept,unanimous_agreement
1353420103,11695,added comment to the test. as well as added a assertion on the bit decrement operation to not go below zero.,0,0,0,0.9882237911224364,0.9922996163368224,0.9949705004692078,0.0,accept,unanimous_agreement
1354804628,11695,"i don't see that in the code. one of us is missing something, so let's add more details. i see two `do` loops, and the first thing that happens in both is a `defraglaterstep` and a `break` if it returns true. the only thing we need to worry about is that we don't switch slot when that list isn't empty, and for that purpose, we just need to make sure that the code that changes `ctx.slot` isn't reachable when the list isn't empty. or in other words, the `continue` you added seems enough and there's no need for that variable and if-else you also added. what am i missing?",0,0,0,0.8708750605583191,0.9753463864326476,0.9583353996276855,0.0,accept,unanimous_agreement
1355326488,11695,"if we don't have the `if (!defrag_later_item_in_progress) {` condition it would scan the same slot again after completion of the `defraglaterstep` as `cursor` and `expires_cursor` would be set to `0`, which we want to avoid.",0,0,0,0.9822403788566588,0.9938164353370668,0.9885972142219543,0.0,accept,unanimous_agreement
1356381760,11695,"ohh, you're right. thanks.",1,1,1,0.9571208357810974,0.9812436699867249,0.9883452653884888,1.0,accept,unanimous_agreement
1359695939,11695,we're getting a valgrind error because `mh->db[mh->num_dbs].overhead_ht_expires` isn't being set when there are no expires. is there a reason we aren't unconditionally setting this? [code block],0,0,0,0.9451325535774232,0.9836561679840088,0.9894724488258362,0.0,accept,unanimous_agreement
750401799,9788,i don't think we must document the history here (unless there are backwards compatibility concerns that should be in the foot notes) [code block],0,0,0,0.9854234457015992,0.9893803596496582,0.98531973361969,0.0,accept,unanimous_agreement
750404230,9788,"being a base file name, i wanna see just name here, and i wanna add the suffix (file type) at runtime. i don't mind trimming the `.aof` suffix we get from the user (in case he didn't update his config file), and i also don't mind keeping it and adding another suffix after it. but for new users / deployments, i want to have something that's cleaner, so i suggest: [code block]",0,0,0,0.931571125984192,0.9701454639434814,0.9738042950630188,0.0,accept,unanimous_agreement
750412827,9788,"let's stick to one terminology, either ""meta"" or ""manifest"" [code block]",0,0,0,0.9870288372039796,0.9896932244300842,0.9915144443511964,0.0,accept,unanimous_agreement
750421819,9788,"[code block] btw, it looks like your editor is inserting some non-ascii characters, e.g. `、` instead of `,` and ` `",0,0,0,0.9834347367286682,0.9929718375205994,0.993155002593994,0.0,accept,unanimous_agreement
750425302,9788,"these new config interfaces need to be documented in redis.conf, and also listed in the top comment of the pr under some ""interface changes section"" note that we use the pr top comment as a squash-merge commit comment as also for the purpose of release notes.",0,0,0,0.9888695478439332,0.9940778017044068,0.995574712753296,0.0,accept,unanimous_agreement
750426388,9788,"`int_min` doesn't seem right. this one is just for testing, but worth mentioning in the top comment anyway. thing is that some reviewers (mainly the core team), may not bother to read the entire source code, and will approve this pr based on the detailed top comment.",0,0,0,0.9549646377563475,0.9855142831802368,0.9140884280204772,0.0,accept,unanimous_agreement
750431612,9788,"i haven't yet got to read the code behind it, but i wonder why this needs to be in cron, and not just when aofrw succeeds or an aof is being loaded after a crash?",0,0,0,0.7799314260482788,0.944047749042511,0.9148339033126832,0.0,accept,unanimous_agreement
750433406,9788,"i wonder if we want to keep this field and just transmit 0 (backwards compatibility concerns)? let's discuss... p.s. if we don't (or even if we do), let's list this in the top comment's ""interface changes section"".",0,0,0,0.9666566848754884,0.9836175441741944,0.9706591367721558,0.0,accept,unanimous_agreement
750441418,9788,"in the past, we attempted to avoid using prid64 and instead just used `long long` (or `long long` casting). p.s. why is this in server.h? i presume that aof.c is the only one that needs to be aware of these details (including some of the defines above).",0,0,0,0.985076367855072,0.987307608127594,0.9935919642448424,0.0,accept,unanimous_agreement
750782283,9788,"if the user configures the name as `appendonly.xxxxx` or `appendonly.xxx.yyy` (not the default `appendonly.aof`), should we also trim it to appendonly?",0,0,0,0.990131378173828,0.9954642653465272,0.9933823347091676,0.0,accept,unanimous_agreement
750803078,9788,"i think you provide the name `appendonly.12.rdb, appendonly.25.aof, appendonly.26.aof` does look more intuitive, i decided to use your rules.",0,0,0,0.9568690657615662,0.9764328598976136,0.9762881994247437,0.0,accept,unanimous_agreement
750804192,9788,"yes, i actually thought about it. the `delhistoryaoffilescron` function will use bio to delete all history files and update the manifest file on the disk simultaneously. in theory, it is not a very heavy operation, so let's move it to backgroundrewritedonehandler?",0,0,0,0.979396104812622,0.985887348651886,0.9812896847724916,0.0,accept,unanimous_agreement
750805412,9788,"indeed, maybe some users' monitoring systems rely on this info field, so i keep it and force it to 0.",0,0,0,0.9802893996238708,0.961625039577484,0.989069640636444,0.0,accept,unanimous_agreement
750832655,9788,"there may be this possibility: the user exited the process before cleaning up the history (redis was killed), and the history files will be kept until the next rewrite success.",0,0,0,0.9884706735610962,0.9887517094612122,0.9904464483261108,0.0,accept,unanimous_agreement
750901819,9788,"i don't think so. as i said, i'm also willing to keep this suffix, but since it's a common config i figured we can make a minimal effort to clean it. i.e. if the string has at least 5 chars, and ends with that 4 chars suffix, trim the last 4 chars. but now it occurs to me that maybe if some piece of external software will try to take the value of that config and search for the files based on this base name, this trimming can cause some confusion. on the other hand, it is likely that this ""server management software"" is coupled with the deployment scripts and the server configuration, so i don't think it's a real issue. let's seek additional feedback. ?",0,0,0,0.9233906865119934,0.9482349753379822,0.94717276096344,0.0,accept,unanimous_agreement
750902557,9788,this is why i suggested to call that on startup too.,0,0,0,0.9852651953697203,0.991574227809906,0.9930296540260316,0.0,accept,unanimous_agreement
750902834,9788,wdyt?,0,-1,0,0.9751594066619872,0.614355742931366,0.9878125786781312,0.0,accept,majority_agreement
750915534,9788,"modified, `delhistoryaoffiles` will be called in three places: 1. when the redis server starts 2. when aofrw successfully finish 3. when `config set aof-enable-auto-gc yes`",0,0,0,0.9870570302009584,0.9936973452568054,0.9919781684875488,0.0,accept,unanimous_agreement
750979190,9788,maybe it will be better to negate this? and call it `aof-disable-auto-gc` (have it 0 by default)?,0,0,0,0.985397458076477,0.9946331977844238,0.9881795644760132,0.0,accept,unanimous_agreement
751043835,9788,"[code block] is this just for the manifest? don't we have temp files elsewhere? what about the double-write files? p.s. i think we can just use a hard coded `.tmp` suffix for all of these, not necessarily define it per use.",0,0,0,0.9887738227844238,0.9933043122291564,0.9931172132492064,0.0,accept,unanimous_agreement
751047406,9788,"i think this the ""file"" prefix and camel-case may be redundant [code block]",0,0,0,0.9874200224876404,0.9903339743614196,0.9870087504386902,0.0,accept,unanimous_agreement
751198657,9788,"[code block] p.s. i think we can give up this thin wrapper, and just copy the dup code here (we don't use it elsewhere)",0,0,0,0.9795278310775756,0.9755293130874634,0.9918156266212464,0.0,accept,unanimous_agreement
751206580,9788,"this one returns an sds (should be freed with sdsfree), let's change the return type. same goes for the one below, and maybe others.",0,0,0,0.9880129098892212,0.993249535560608,0.9938363432884216,0.0,accept,unanimous_agreement
751208470,9788,"i'd rather add spaces between arguments in function calls. i know redis is inconsistent in that (each file and function has its own style), but i think that's where we should aim for in new code. [code block]",0,0,0,0.9785252213478088,0.9830552339553832,0.9795501828193665,0.0,accept,unanimous_agreement
751258142,9788,"i think it looks a bit odd that this macro returns `buf` but doesn't take it as an argument (like sdscat does). it looks like a memory leak overriding `buf`. let's either pass `buf` as an argument in addition to `info` (which i prefer), or have the macro do the part of writing to `buf` too (and have no return).",0,-1,-1,0.579720139503479,0.5782353281974792,0.7291201949119568,-1.0,accept,majority_agreement
751268189,9788,"i know config.c does the same, but what's the advantage of first reading the lines one by one using `fgets` and concatenating them to a big string, only to split it in a second loop?",0,0,0,0.9852539896965028,0.985771417617798,0.99026358127594,0.0,accept,unanimous_agreement
751270387,9788,i guess it would be a good idea to use `pathisbasename` to validate that there's no abuse here.,0,0,0,0.9372146129608154,0.9684338569641112,0.983754575252533,0.0,accept,unanimous_agreement
751303363,9788,"we're running from tail to head, don't we want to push to head? (not that it really matters)",-1,0,-1,0.8805555701255798,0.9809437394142152,0.5667217373847961,-1.0,accept,majority_agreement
751311400,9788,"styling. i suggest to indent by 4 rather than align to some position (certainly no the offset of the second argument, but also not the first). this way, if the log function we call (in this case serverlog) is renamed, we don't need to re-align the arguments. i also don't see why in this case we wanna designate a separate line per argument (certainly not if we didn't for ll_warning) feel free to apply to others calls (the reason i commented on this one is because it attracted my eye due to an excessive space on the last line) [code block]",0,0,0,0.9654534459114076,0.9647030234336852,0.9859193563461304,0.0,accept,unanimous_agreement
751312637,9788,we get here on `open` failures too [code block],0,0,0,0.9889618754386902,0.9928754568099976,0.9924450516700744,0.0,accept,unanimous_agreement
751316500,9788,"do we really need to designate a special function for that? i think it should always come together with a call to `getaofmanifestasstring` anyway, so i think we should collapse this one into persistaofmanifest",0,0,0,0.9682360291481018,0.9908470511436462,0.989497184753418,0.0,accept,unanimous_agreement
751320314,9788,"let's attempt to have the first word in ""api"" functions (specifically the non-static ones that are declared in server.h and used in many files), represent the module they belong to. i.e. these should all start with `aof`, i.e. `aofdelhistoryfiles`. there is some attempt to do that in redis, and although inconsistent, i think we should try to follow it in new code.",0,0,0,0.9851727485656738,0.9929454922676086,0.9882093667984008,0.0,accept,unanimous_agreement
751324399,9788,"i think this log message shouldn't be ll_debug. i guess `ll_notice` is good, and even ll_warning may be ok (there are not a lot of these).",0,0,0,0.9441430568695068,0.9620969295501708,0.8166738152503967,0.0,accept,unanimous_agreement
751325416,9788,"so if redis crashes after we wrote that file, we'll be left with garbage on the disk. this garbage isn't affecting us, so i suppose we're ok with that, but why don't we use the `bg_unlink` mechanism? i.e. logically delete now, and pay the deletion price in the thread... it still wouldn't guarantee there's no garbage since we don't sync the directory structure, but the difference is that we'll leave garbage only on power / system failures (not if the process crashes or is killed)",0,0,0,0.9342963695526124,0.9731667637825012,0.9341405034065248,0.0,accept,unanimous_agreement
751331192,9788,"besides the documentation / phrasing, i'd like to start a discussion as to why we need that feature at all? what are the use cases for that?",0,0,0,0.9794272184371948,0.9828254580497742,0.9888519644737244,0.0,accept,unanimous_agreement
751408662,9788,"it could be that this is the first time a user tries to enable aof at runtime, in which case i think a disk error should not be fatal. but i see that `opennewincraofforappend` does `exit(1)` (unlike `openlastorcreateincraofforappend`). lets see if we can figure out a solution, maybe it should do the `opennewincraofforappend` before the fork?",0,0,0,0.98562890291214,0.9899336695671082,0.989974558353424,0.0,accept,unanimous_agreement
751418070,9788,"we're soon gonna completely remove the code that generates resp code from inside a fork, i.e. aofrw will always create an rdb file. this means that the feature of calling bgrewriteaof when aof is not enabled, should no longer be supported (it's the same as calling bgsave). we can clean up this code in a later pr, but since i see this scenario is causing issues in this one, maybe we can remove that now. i.e. don't remove yet all the aof text generation, but do change this command to return an error if `server.aof_state != aof_on` and then you can delete the `createnew` argument.. or we can do that later. p.s. if we do that now, let's mention it in a behavior changes section in the top comment.",0,0,0,0.970201849937439,0.9894230961799622,0.9728465676307678,0.0,accept,unanimous_agreement
751420552,9788,let's be sure to have a test case for this flow.,0,0,0,0.9797000288963318,0.9875180125236512,0.9910247325897216,0.0,accept,unanimous_agreement
751430918,9788,"so is `aof_current_size` the size of all incremental (non history) parts? or also including the base? let's make the comment clearer. also maybe rename `aof_newfile_size` to `aof_last_incr_size`? (""new"" may be ambiguous)",0,0,0,0.9876817464828492,0.9947677850723268,0.9943488240242004,0.0,accept,unanimous_agreement
751435086,9788,styling. `if` with multiple lines should move the `{` to the next line (less confusing indentation). [code block],0,0,0,0.98815256357193,0.9920437932014464,0.9880877137184144,0.0,accept,unanimous_agreement
751436032,9788,"so i understand this pr doesn't have the double write code.... indeed it probably makes the code cleaner, but we need to discuss it to make sure we all agree if this is ok.",0,0,0,0.809893786907196,0.8831486105918884,0.9797398447990416,0.0,accept,unanimous_agreement
751601176,9788,"when loading an rdb, i think we may want to set `rdbfilebeingloaded` (which `startloadingfile` sets) in some way, this controls behavior when corruption is detected. and it would also be a good idea to pass the file size. on the other hand, i don't think we wanna do a separate startloading / stoploading per file, and instead use just one pair like before. so we need to find a way to determine the file size ahead of time, and update the file name when needed. let's look into it and see what we can come up with.",0,0,0,0.9462319016456604,0.97060364484787,0.965322494506836,0.0,accept,unanimous_agreement
751777540,9788,"at present, i only use `aof-enable-auto-gc` in the test to assert that expected history aof will be generated in aofrw. however, i am wondering whether there is such a scenario: the user has a backup system that will continuously upload all incremental aofs, because our aofs have timestamp annotations, so we can even recovery the data to each previous point in time. therefore, after each aofrw, we cannot delete the history aof immediately, unless the user has actually uploaded these aofs . this is just a guess of mine. i don't mind that it is only used for testing purposes like `aof-child-rewrite-delay` and not exposed in `redis.conf`.",0,0,0,0.8106783032417297,0.8253213167190552,0.903340220451355,0.0,accept,unanimous_agreement
751784435,9788,"yes, `aof_newfile_size` only means the last ""that is, newly created "" incr aof, its main purpose is to provide the correct position when ftruncate this aof file. i think `aof_last_incr_size` is indeed clearer, modified.",0,0,0,0.9845118522644044,0.990436851978302,0.991679847240448,0.0,accept,unanimous_agreement
751806860,9788,"yes, double writing will make the code look more complicated (i implemented it in #9539 ). in addition, although redis may create infinite number of files on the disk if aofrw is repeatedly failing. but this is almost impossible or very rare in reality, because aofrw will bring fork overhead every time, and users will not let aofrw fail like this.",0,0,0,0.6511961817741394,0.9692408442497252,0.97503000497818,0.0,accept,unanimous_agreement
751965265,9788,"about this test i wanna modify and improve it, please review the tests part later, thank you.",1,1,1,0.8831976056098938,0.915549099445343,0.8152568340301514,1.0,accept,unanimous_agreement
752003270,9788,"ok, i have a feeling that such an external mechanism will require more assistance from redis. at the very least it be able to trigger gc manually, or clean the manifest in some way (before/after deleting the files). i guess we should leave this feature out of the scope for now until we design it properly. so in that case, let's mark this flag as a testing one (comment), and remove the documentation from redis.conf. i also think it's still a good idea to negate it. p.s. we do plan to soon add some config.c flag on all test testing configs see [a link] i.e. it'll probably be the ones that are not documented in redis.conf.",1,1,0,0.507526695728302,0.7224532961845398,0.8765640258789062,1.0,accept,majority_agreement
752006248,9788,can you estimate how much more overhead this feature adds? i guess the double writing code on it's own is not more than 5 lines. but the file tracking / renaming may be a bit more... i do think repeated failures will be common... user can find out he has insufficient memory after a week of repeated failures and maybe thousands of files on the disk.,0,0,0,0.8896636962890625,0.9190919995307922,0.963546872138977,0.0,accept,unanimous_agreement
752077704,9788,also used in `aofmanifestdup` to dup base_aof_info,0,0,0,0.9880368709564208,0.9949641227722168,0.9953873753547668,0.0,accept,unanimous_agreement
752179441,9788,here i want to ensure the order they were before.,0,0,0,0.9828296303749084,0.9847858548164368,0.9897521734237672,0.0,accept,unanimous_agreement
752184958,9788,"yes, i'm arguing that you're reversing the order. maybe i'm missing something... since you're iterating the old list from tail to head, if you're inserting to the tail of the new list, it'll reverse the order.",0,0,0,0.5233514904975891,0.689232349395752,0.9732410311698914,0.0,accept,unanimous_agreement
752188129,9788,changed to ll_notice.,0,0,0,0.9851232171058656,0.9935126900672911,0.9938207268714904,0.0,accept,unanimous_agreement
752220571,9788,changed to `bg_unlink` and deleted the code added in bio,0,0,0,0.9880086183547974,0.9956811666488647,0.9939898252487184,0.0,accept,unanimous_agreement
753647386,9788,it means to verify whether this file ends with .rdb?,0,0,0,0.9877492785453796,0.994437575340271,0.9930238723754884,0.0,accept,unanimous_agreement
753649606,9788,"okay, i have made aof open before redis-fork so that we can find disk errors in advance.",0,0,0,0.988398015499115,0.9878963232040404,0.9922783374786376,0.0,accept,unanimous_agreement
753675790,9788,"i don’t think there will be a lot of work. the key is that we are sure that it is necessary to do this. i think this will cause two problems: 1. code understanding may bring some burdens 2. when double writing files (obviously we can't get around the atomicity problem), when one successfully and another file fails written, should we directly exit? of course, double writing can indeed solve the possibility of hundreds of incr aofs. therefore, we can make a decision as soon as possible, i can proceed to implement it.",0,0,0,0.8957408666610718,0.9394415616989136,0.8282121419906616,0.0,accept,unanimous_agreement
753676307,9788,here i pass size as a parameter to startloadingfile. i think the original parameter `fp` is too restrictive for caller (must be a file opened in advance).,0,0,0,0.975532054901123,0.9852467775344848,0.9919421672821044,0.0,accept,unanimous_agreement
753676533,9788,do you mean that all incr aof loads only use a pair of `startload/stopload`? then use an function like `updateloadsize` to update the file size in the middle?,0,0,0,0.9882785081863404,0.9929882884025574,0.994198441505432,0.0,accept,unanimous_agreement
753845148,9788,"no, it verifies that it's a file name without folder names or absolute files (locks redis inside it's `dir` config)",0,0,0,0.9898157119750975,0.994175910949707,0.9951565861701964,0.0,accept,unanimous_agreement
753848583,9788,"yes, just one pair of startload / stopload, ideally we should know the total size of all when we start loading, and fix the relevant places not to reset the read counters when we switch files. thing is that the arguments for this startloading function are used for two things: 1. the file name is used in order to know what to report on failures, and be able to distinguish between diskless and dis-based replication (see `rdbreporterror`) 2. the size argument is used for progress reporting, see `info persistence`, i.e. `loading_total_bytes`, `loading_loaded_bytes`, `loading_loaded_perc`. we need to somehow make them work correctly.",0,0,0,0.9745146036148072,0.9922480583190918,0.9924612641334534,0.0,accept,unanimous_agreement
753850079,9788,"i see that now `startappendonly` creates a new file, but it doesn't write to `server.aof_fd` until after `rewriteappendonlyfilebackground` (same as it is in unstable), however, rewriteappendonlyfilebackground does this: [code block] so i think opennewincraofforappend still has a chance to `exit`. and in any case, it'll open the file again, writing to `server.aof_fd`, and we probably have an fd leak.",0,0,0,0.9706600308418274,0.9894969463348388,0.9916194677352904,0.0,accept,unanimous_agreement
753876014,9788,"ok, modified.",0,0,0,0.9845120906829834,0.9685930013656616,0.9932831525802612,0.0,accept,unanimous_agreement
754214398,9788,"i added a `startloadingincraoffiles` function to set the size of the entire incr aofs, and then in the `loadsingleappendonlyfile` function, `loadingincraofprogress` will be used to update the progress of the loading. unlike `loadingrdbprogress` (originally `loadingprogress`), `loadingincraofprogress` receives a relative size (not a absolute file offset). please review the code here if there is any problem, thank you.",1,0,1,0.6985642910003662,0.7516815066337585,0.5609747171401978,1.0,accept,majority_agreement
754227580,9788,"do you have any ideas here? i wonder if we still have a solution, that is, once we find that our incr aof number reaches a threshold (for example 32, this means aofrw have consecutive failed 32 times), we stop the automatic retry aofrw and print a log and set a global status. i think the current unlimited aofrw is not very reasonable(if aofrw keeps failing so many times, it means there must be some serious problem, such as insufficient memory, some modules have bugs when implementing aof rewrite, etc., i think it is meaningless to automatically retry aofrw in this case.), aofrw also will bring fork overhead every time. what do you think? i think we can forcibly set `server.aof_rewrite_base_size` or clear `server.aof_rewrite_scheduled` to delay or close automatic aofrw.",-1,0,0,0.668533444404602,0.6363850831985474,0.932058036327362,0.0,accept,majority_agreement
754893676,9788,"i discussed it with the core team today. we concluded that we rather not invest in double write for now, and we can always add that later if we get feedback about problems with infinite number of files. the suggestion of some aofrw throttling also came up. i'm not certain how to do it (don't like to change a config), we can try thinking of it, but that's also something that can be added in the future.",0,0,0,0.8402490019798279,0.8588305115699768,0.9245294332504272,0.0,accept,unanimous_agreement
754903329,9788,"well, i don't think this requires a configuration. we can simulate the tcp retransmission algorithm (binary exponential back off). when aofrw fails, we have at least twice the time (or size) to retry aofrw again (don't try again immediately like now). if it fails again, it will double. we only need to determine a maximum internally. this is just my simple idea, maybe we have a better way.",0,0,0,0.9120526909828186,0.9687984585762024,0.964930295944214,0.0,accept,unanimous_agreement
754907586,9788,"ohh, sorry, i was confusing `server.aof_rewrite_base_size` with `server.aof_rewrite_perc` (didn't want the backoff be visible in `config get`).",-1,-1,-1,0.9886980056762696,0.97799950838089,0.9721853137016296,-1.0,accept,unanimous_agreement
754928722,9788,"maybe move that to be next to loadingprogress / startloadingfile, and rename to just `loadingincrprogress`. i.e. a generic progress report that reports the delta rather than absolute.",0,0,0,0.9882823824882508,0.9930821657180786,0.988307774066925,0.0,accept,unanimous_agreement
754929451,9788,"is `base_size` better named `last_progress_report_size`? i think ""base"" is not a good word here (since it keeps changing).",0,0,0,0.6267344951629639,0.9641122817993164,0.9769465327262878,0.0,accept,unanimous_agreement
754930412,9788,maybe this better be after the loop rather than inside the condition that breaks?,0,0,0,0.9766135215759276,0.9896056652069092,0.9832747578620912,0.0,accept,unanimous_agreement
754931203,9788,"nit pick. i prefer just one line, it's not long enough to justify ugly line break imho",-1,-1,-1,0.9564674496650696,0.9557671546936036,0.9946492314338684,-1.0,accept,unanimous_agreement
754933223,9788,"i meant just one startloading for the whole thing (not one for the base and one for all incr files) regarding the new functions that's ok, just that maybe the function naming should be neutral and just state the fact of what they do (relative or absolute instead of rdb or aof)",0,0,0,0.9811313152313232,0.979417622089386,0.9867056012153624,0.0,accept,unanimous_agreement
754937734,9788,maybe that's another metadata to keep in the manifest?,0,0,0,0.984566867351532,0.9938615560531616,0.9888999462127686,0.0,accept,unanimous_agreement
755077262,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
755077920,9788,modified,0,0,0,0.9729309678077698,0.8963590860366821,0.8045071363449097,0.0,accept,unanimous_agreement
755083385,9788,"i understand what you mean. if we add `size` in manifest, do we need to check whether the size is the same as the actual size of the file when we load it? there are still some questions about the manifest, that is, now we only have “name/type/seq” meta in manifest, do we need other meta, such as the timestamp of file creation, or other information (maybe we will use it in the future), because once the manifest format is publish, it will not be modified later.",0,0,0,0.9769420623779296,0.9901680946350098,0.9778684377670288,0.0,accept,unanimous_agreement
755095375,9788,"yes, i'm not certain about my suggestion either. i don't think we need do validate the size (as long as it's just used for progress report) but anyway, it was just an idea, we can drop it.",0,0,0,0.9633277654647828,0.8680063486099243,0.943209707736969,0.0,accept,unanimous_agreement
755096863,9788,maybe it would be cleaner if `progress_size` will be a local variable declared when setting it? and / or call it `progress_delta`?,0,0,0,0.9873255491256714,0.9950764775276184,0.988561749458313,0.0,accept,unanimous_agreement
755160701,9788,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
755164011,9788,modified,0,0,0,0.9729309678077698,0.8963590860366821,0.8045071363449097,0.0,accept,unanimous_agreement
755165000,9788,modified,0,0,0,0.9729309678077698,0.8963590860366821,0.8045071363449097,0.0,accept,unanimous_agreement
755176188,9788,"sorry i didn't understand what you mean. when we calls `rewriteappendonlyfilebackground` in `startappendonly` function, `server.aof_fd` must be -1, so `rewriteappendonlyfilebackground` will not be opened new aof file. i don’t understand under what circumstances the fd leak you mentioned happened。",-1,-1,-1,0.9877839684486388,0.9828944206237792,0.9927284717559814,-1.0,accept,unanimous_agreement
755177820,9788,i have restored the declaration of the `rewriteappendonlyfilebackground` function.,0,0,0,0.9872738122940063,0.9931126236915588,0.995193898677826,0.0,accept,unanimous_agreement
755184172,9788,modified,0,0,0,0.9729309678077698,0.8963590860366821,0.8045071363449097,0.0,accept,unanimous_agreement
755184546,9788,modified,0,0,0,0.9729309678077698,0.8963590860366821,0.8045071363449097,0.0,accept,unanimous_agreement
755205320,9788,"yes you are right, i am wrong. fixed :)",1,1,1,0.9148300290107728,0.994882345199585,0.9942143559455872,1.0,accept,unanimous_agreement
755222621,9788,test added.,0,0,0,0.9847517609596252,0.9898595213890076,0.9946351647377014,0.0,accept,unanimous_agreement
755226738,9788,"please review this part again,thanks.",1,1,0,0.68059903383255,0.7024631500244141,0.8481303453445435,1.0,accept,majority_agreement
755721167,9788,"i have optimized a version, please review it.",0,0,0,0.978091299533844,0.9679409265518188,0.9925743341445924,0.0,accept,unanimous_agreement
755992070,9788,"i implemented this function according to the previous description, because i think we should need it now, because in actual applications aofrw is often happens (such as the child oom), and redis automatically retry aofrw is so fast ( default 10hz), so it is easy to create a bunch of small incr aof files. i am just solving it by increasing the delay linearly (of course there may be other non-linear better algorithms), i think it can solve our problem, if aofrw has failed 10 times (maybe we need to reduce this value ), then the subsequent aofrw will become slower and slower.",0,0,0,0.8765733242034912,0.9270904064178468,0.9422730803489684,0.0,accept,unanimous_agreement
755993022,9788,"plz review this part again, thanks.",1,1,1,0.900388777256012,0.6730137467384338,0.7376373410224915,1.0,accept,unanimous_agreement
756127541,9788,"ohh, i now see i got the condition in rewriteappendonlyfilebackground wrong (the one in step 4 below) 1. startappendonly does `newfd = open()` 2. startappendonly calls rewriteappendonlyfilebackground 3. rewriteappendonlyfilebackground does `if (server.aof_fd != -1) opennewincraofforappend();` 4. opennewincraofforappend does `server.aof_fd = open()` 5. startappendonly does `server.aof_fd = newfd;` (after rewriteappendonlyfilebackground returns with success) i'd still argue that this is a bit confusing, and that maybe it would have been better to open the new file just in one place. i understand that the `open()` in `startappendonly` is the one i asked for (for graceful failure). and that we'll need one for reoccurring rewrite (which can be in rewriteappendonlyfilebackground). maybe we can solve it in a cleaner way if we move the opening of the new file in rewriteappendonlyfilebackground to before `fork()` is called (it doesn't really matters if it is done in the parent before or after fork), and then maybe it's nicer to have just one call to `open`, or even two in some if-else chain, and it'll be less confusing as to which function is responsible of opening the new file and which one is responsible of setting `server.aof_fd` (they'll all be in just one place).",0,0,0,0.954206109046936,0.9807448387145996,0.9180664420127868,0.0,accept,unanimous_agreement
756132458,9788,"do we have no other complications in this pr due to the fact bgrewriteaof can be called when aof is not enabled? if we do, let's return an error here in that case, and simplify the code. if we don't then this case will be deleted anyway in a few weeks by another pr.",0,0,0,0.9842830896377563,0.9939551949501038,0.992014229297638,0.0,accept,unanimous_agreement
756150206,9788,"i think this should not be a config, but rather a debug sub-command (completely unreachable for normal users). see `set-active-expire` and alike. p.s. i haven't looked at the tests yet, but maybe there's a different way to induce a failure without the need of such a config. maybe by using `rdb-key-save-delay`, and then killing the child from the test (with `kill`)",0,0,0,0.966346800327301,0.9896442890167236,0.9864792227745056,0.0,accept,unanimous_agreement
756159044,9788,"the simple mechanism seems ok, or we can maybe improve (i don't mind too much). maybe just make it clear in the top comment what's the return value of this function (true to prevent rewrite) maybe a slightly better one would be to start with a 1 minute delay and then double the delay time on each failure up to a limit of one day? wdyt?",0,0,0,0.9414225816726683,0.93586665391922,0.8033088445663452,0.0,accept,unanimous_agreement
756163048,9788,"16 seem too high to me too, maybe 8 or even 4 would work? just remember it can't be lower since we don't count failures, we're counting files, so the base is 3",0,0,0,0.947995662689209,0.896637499332428,0.9324766993522644,0.0,accept,unanimous_agreement
756166997,9788,lgtm,0,0,0,0.9795994758605956,0.7242414951324463,0.9618706703186036,0.0,accept,unanimous_agreement
756246041,9788,"calling bgrewriteaof when aof is disable is no problem. the only difference is that we will not open a new incr aof (similar to not write aof rewrite buf). but we will still update and generate the correct base file (it can be aof or rdb, depending on whether we will enable `aof-use-rdb-preamble`). these have corresponding tcl tests. i think our ultimate goal is to create base file as rdb file (such as `aof-use-rdb-preamble` is enabled by default). but i don't quite understand why `bgrewriteaofcommand` must return err (when aof is off) or be deleted.",0,0,0,0.9545931816101074,0.9860401153564452,0.978797435760498,0.0,accept,unanimous_agreement
756489946,9788,"i refactored the `opennewincraofforappend` function to achieve consistency guarantee without exit when an error occurs, and i move it before redis-fork. plz review this part again, thanks.",1,1,1,0.954182744026184,0.5195868015289307,0.9666116833686828,1.0,accept,unanimous_agreement
756523137,9788,"`aof_rewrite_limite_threshold` has been changed to 3, which means that aofrw may have failed 2 or 3 times continuously. `aof_rewrite_limite_nax_delay` has been modified to 1440 minutes (1 day). although i think it may be a bit long and 1440 is not an exponent of 2, but it is fine.",0,0,0,0.9610412120819092,0.990716516971588,0.8724610209465027,0.0,accept,unanimous_agreement
756540862,9788,"that is what i did before this commit, but i encountered a problem when writing the aofrw limit test, because i wanted to simulate a scenario where the auto rewrite failed. but after we changed `aof_rewrite_limite_threshold` to 3, it is easy to achieve the goal using kill. so i rolled back the configuration now.",0,0,0,0.9633683562278748,0.9829457998275756,0.9873812198638916,0.0,accept,unanimous_agreement
756606530,9788,"i understand what you mean, we let base directly become rdb, delete `rewriteappendonlyfilerio` and related code. but i'm not sure if this will cause any problems, such as use for analysis or parsing relying on the aof format, and now it must face both the rdb format (base) and the aof format (incr). do we still keep `aof-use-rdb-preamble` to let users make choices?",0,0,0,0.9725197553634644,0.9844241738319396,0.9769166111946106,0.0,accept,unanimous_agreement
756632679,9788,"do we have any conclusions about this? can we directly use the original name (after all, it is configured by the user or default), and then we use `base` or `incr` to indicate the type of this file, such as `appendonly.aof.1.base`, `appendonly.aof.1.incr`, `appendonly.aof.2.incr`。 the current solution does not seem to be very good: `appendonly.aof.2.rdb`, `appendonly.aof.3.aof`, it is difficult to understand that a name contains both `rdb` and `aof`. wdyt ?",0,0,-1,0.8995530009269714,0.9870399832725524,0.5561960339546204,0.0,accept,majority_agreement
756753619,9788,"examples of issues: will it create a meta file? what happens if we then restart redis with aof enabled? will it load that aof file? deleting the `aof-use-rdb-preamble` config and the code behind `rewriteappendonlyfilerio` is a topic for the next pr. i do think we wanna delete them, that's a lot of code that is hard to maintain, and i know it gives module authors a hard time. but anyway, for the purpose of this pr, i just say that if the option of calling bgrewriteaofcommand when aof is disabled is causing any complications, i think we can delete it right now, since sooner or later we don't want to support that option (it'll be identical to bgsavecommand)",0,0,0,0.7099406719207764,0.7050963044166565,0.8922009468078613,0.0,accept,unanimous_agreement
756759019,9788,"maybe you're right (that a day is too long). if it fails consistently, then i don't care to delay it for one day, the only problem i see with it is that if the admin fixes the problem (adds more disk / ram space), it'll want to trigger a retry manually asap rather than wait for the next interval, and waiting one day may be too long. so either we add some mechanism to override that (like `bgrewriteaof force`), or reduce back to one hour, which may be an acceptable time to wait. wdyt? either way, let's be sure to document this in the top comment for the purpose of release notes and other reviewers (which will only look at the description, not the code)",0,0,0,0.9263371229171752,0.864629328250885,0.9510745406150818,0.0,accept,unanimous_agreement
756762336,9788,fyi: just note i wrote `rdb-key-save-delay` (not `aof-child-rewrite-delay`).,0,0,0,0.9875394105911256,0.9922046661376952,0.994658887386322,0.0,accept,unanimous_agreement
756822672,9788,"yes, manifest file will be created, because we will generate a base aof/rdb, as long as there is a change in the aof file, we have to track it. if redis restarts and aof is enabled, of course we have to load it. this logic is the same as the original redis。 aof enable and disable do not affect the creation of the manifest, it only affects whether we write aof files and whether a new incr aof will be generated during aofrw. if we are sure to delete the `aof-use-rdb-preamble` configuration and the `rewriteappendonlyfilerio` related code, i think i can do it in this pr because they have more or less impact on the current pr. i am happy to do this.",0,0,0,0.9828617572784424,0.991655707359314,0.9822304844856262,0.0,accept,unanimous_agreement
756827028,9788,"for now, let's keep the simple approach you have (just use it as base, and possibly generate odd file names). we can focus on other aspects of this pr and leave that one for last. then i guess we need to map a few cases and what would be the outcome of each to decide. i.e. users who upgrade from an old system who use the default config, vs users who upgrade from an old system who have explicitly overwritten it, and how will redis behave on upgrade (should load the old data in either one of the cases)",0,0,0,0.9718515872955322,0.9863862991333008,0.9792719483375548,0.0,accept,unanimous_agreement
756831765,9788,"ok good. so it does seem like these (rewrite that generates an aof format, and the possibility to call bgrewriteaof when aof is disabled) aren't complicating this pr too much, and in that case it is better to do that change in a different pr. it'll make the discussion on these easier (to discuss them separately), and will not block the merging of this pr.",1,0,1,0.7362713813781738,0.5118893384933472,0.6263254284858704,1.0,accept,majority_agreement
756834907,9788,"i think 1 hour and 1 day are fine, because we can still use the 'bgrewriteaof' command to execute aofrw immediately during the limit period. so we reduce back to one hour, just like: 1, 2, 4, 8, 16, 32, 60",0,0,0,0.8821142911911011,0.9884621500968932,0.979133665561676,0.0,accept,unanimous_agreement
756839810,9788,i have removed the `aof-child-rewrite-delay` configuration and used the `rdb-key-save-delay` instead.,0,0,0,0.988257110118866,0.993941068649292,0.9949365854263306,0.0,accept,unanimous_agreement
756846275,9788,"okay, iawy.",0,0,0,0.9689756035804749,0.6786331534385681,0.9196744561195374,0.0,accept,unanimous_agreement
756879986,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
756884444,9788,do you have any suggestions here?,0,0,0,0.9850026965141296,0.9875664710998536,0.9918107986450196,0.0,accept,unanimous_agreement
756884617,9788,"i see you changed the suffix (saw your last commit), i meant to just use what ever is in the config as base file name and apply the suffixes on it (i.e. that there's no need for now to strip the "".aof"" suffix that the user may have provided). i.e that i'm ok with ""appendonly.aof.0.rdb"" maybe i don't mind the base/incr suffix, but i think it is redundant (it's also indicated by the meta file). what the suffix came to denote in my ""design"" is the format inside the file (i.e. considering we'll deprecate the possibility for aofrw to generate aof command content, the base file is an rdb format).",0,0,0,0.9660597443580629,0.9846979379653932,0.9739341735839844,0.0,accept,unanimous_agreement
757163072,9788,"well, i understand what you mean. one reason for changing `.rdb` to `.base` is because in the current pr, the base file may be in aof or rdb format (depending on the `server.aof_use_rdb_preamble` is yes or no), if base is in aof format but we still end with `.rdb` may be confusing (the user will try this features of this pr when merged, but the next pr hasn't merged yet ). note that what i said is only in this pr. if we remove `server.aof_use_rdb_preamble` and `rewriteappendonlyfilerio` in the next pr, we can say that our base is rdb and incr is aof. so `appendonly.aof.1.rdb` and `appendonly.aof.2.aof` will be certain (reflecting their internal format). this may be my concern. after all our next pr (remove `server.aof_use_rdb_preamble` and `rewriteappendonlyfilerio`) should be merged soon (the workload is not much, but we have to think clearly about the impact it brings). so if we don’t mind this short-term confusing, i am willing to roll back the suffix to the previous version. wdyt?",0,0,0,0.9653999209403992,0.978659451007843,0.9677113890647888,0.0,accept,unanimous_agreement
757320913,9788,"theoretically, if we want this pr to be really clean on it's own (and not count on the next change), maybe we can either add a `.aof` or `.rdb` suffix for the rewrite depending on `server.aof_use_rdb_preamble` (to indicate the format). and if additionally we also want some notation if it's a base or incr, we can keep these too. then maybe in the next pr we can remove this complication. on the other hand, i don't mind letting it be one way or the other in the short term, and i'm quite sure we're gonna trim the aof generation code very soon, i'm just worried that we won't forget it and keep only the ""base"" notation and no indication on the format. so maybe it's better to just add both (not a big overhead in coding)",0,0,0,0.9020662307739258,0.9843156933784484,0.9534629583358764,0.0,accept,unanimous_agreement
757332106,9788,"currently `base` and `incr` use separate seq, they can be incremented separately. if `base` also uses the aof suffix(`server.aof_use_rdb_preamble` is no), there may be a file name conflict between `base` and `incr`. if `base` and `incr` share a seq, then seq is not continuously increasing. which do you think is better?",0,0,0,0.9825297594070436,0.9925045967102052,0.9918642044067384,0.0,accept,unanimous_agreement
757337039,9788,"i guess we can invest a few extra lines of code (which we may clean in the future), and add both ""base"" / ""incr"" notation in the file name, as well as "".aof"" or "".rdb"" to denote the format. shouldn't be too complicated, and we may consider changing that in a few weeks.",0,0,0,0.9695060849189758,0.9835819005966188,0.9738113880157472,0.0,accept,unanimous_agreement
757364347,9788,"wdyt about this? [code block] in addition, do we necessary to reflect its internal encoding format on the file name (or whether the user really cares about this). we divided the aof into one base file and multiple incr files (that is multi part). we add the `.rdb` suffix just to tell the user that the base file is an rdb, but i think it can be explained in the document and release notes(that is, multi part = one base rdb + many incr aofs). this can simplify our naming rules: ` basename_seq.type` for example: [code block] or [code block]",0,0,0,0.9796259999275208,0.9845083951950072,0.9734535217285156,0.0,accept,unanimous_agreement
757881784,9788,"for some reason i prefer the suffix to denote the format, maybe i'm looking too much into it, but what complications does it add? is it more than some 4 lines of code?",0,0,0,0.6261847019195557,0.7517628073692322,0.9082541465759276,0.0,accept,unanimous_agreement
757893037,9788,i have modified the pr according to the rules mentioned above. [code block],0,0,0,0.987939476966858,0.989518702030182,0.9955796599388124,0.0,accept,unanimous_agreement
757902946,9788,[code block] safer use of macro arguments. btw do we really need a macro here?,0,0,0,0.9833855032920836,0.9919763207435608,0.9848478436470032,0.0,accept,unanimous_agreement
757903567,9788,consider handling of lines longer than buf - maybe even treat it as an error?,0,0,0,0.9387154579162598,0.9795024394989014,0.9900778532028198,0.0,accept,unanimous_agreement
757903725,9788,consider forward compatibility and just ignore extra args?,0,0,0,0.9829491376876832,0.9871559143066406,0.9924015998840332,0.0,accept,unanimous_agreement
758099526,9788,"plz review this part again and see if there are any more problems? thanks. i will remove `base` and `incr` suffix in the next pr (remove `server.aof_use_rdb_preamble` and `rewriteappendonlyfilerio` related code), so as to use the following rules: [code block]",1,0,1,0.6872545480728149,0.7348426580429077,0.9219478368759156,1.0,accept,majority_agreement
758178138,9788,"[code block] the error message was incorrect, it may exist but fail to open for other reasons.",0,0,0,0.891551673412323,0.981855034828186,0.9846822023391724,0.0,accept,unanimous_agreement
758214708,9788,lgtm,0,0,0,0.9795994758605956,0.7242414951324463,0.9618706703186036,0.0,accept,unanimous_agreement
758328557,9788,"consider some decoupling, such as * populate an arbitrary `aofmanifest` rather than directly access `struct server` * returns an error and let the caller decide on how to handle it",0,0,0,0.9859077334403992,0.9904436469078064,0.991421639919281,0.0,accept,unanimous_agreement
758330348,9788,"why is this necessary? if we want to distinguish a non-existing file from other errors, we can just consult `errno` no?",0,0,0,0.982757329940796,0.9888734817504884,0.9855284094810486,0.0,accept,unanimous_agreement
758332334,9788,"what is the purpose of the additional `redis_stat`? if all we need is to distinguish an error from a non-existing file, we could just look at `errno` no?",0,0,0,0.9872649908065796,0.9932923316955566,0.9900532364845276,0.0,accept,unanimous_agreement
758334632,9788,is there any specific reasoning behind both using a key/value line structure *and* insisting on the order of keys per line?,0,0,0,0.9793094396591188,0.9904497265815736,0.9914870262145996,0.0,accept,unanimous_agreement
758338142,9788,"probably safe to simply assert here, afair it should only fail if `zmalloc()` fails - which should end up in an earlier panic anyway.",0,0,0,0.9832108020782472,0.9920082092285156,0.981523334980011,0.0,accept,unanimous_agreement
758343160,9788,we probably want to keep it dirty if write failed.,-1,0,0,0.5018333196640015,0.97691410779953,0.9037084579467772,0.0,accept,majority_agreement
758348200,9788,"perhaps we should consider a smaller max delay. even if we use 5 minutes, that's max 288 files per day which is still not a huge number of files (assuming someone is monitoring the system at reasonable interval).",0,0,0,0.9823399782180786,0.9705365896224976,0.9784474968910216,0.0,accept,unanimous_agreement
758386138,9788,"consider logging ""file [x/n]"" to help troubleshooting and give better visibility into the loading process?",0,0,0,0.984741747379303,0.9933708906173706,0.993033766746521,0.0,accept,unanimous_agreement
758440240,9788,"lol.. i was arguing for a day. i think there are cases where something can fail for weeks and no one will notice. as discussed in another thread, if the admin solves the problem he can run bgrewriteaof instead of waiting for the next interval, so why make it that short?",1,1,1,0.807026207447052,0.8982914686203003,0.9302281737327576,1.0,accept,unanimous_agreement
758825536,9788,"i think it is necessary. although there is only one `sdscatprintf` function in the macro, the definition of the format is repeated. imagine that we need to change the format of the manifest in the future (for example, add new fields in the back), then we only need to change the macro.",0,0,0,0.9865911602973938,0.9904806017875672,0.9803357124328612,0.0,accept,unanimous_agreement
758828351,9788,"have removed 'argc != 6' and add 'argc < 6', this will allow we to add new fields in the future.",0,0,0,0.9871772527694702,0.9943119287490844,0.9944379329681396,0.0,accept,unanimous_agreement
758856226,9788,added,0,0,0,0.973513960838318,0.9267084002494812,0.8435775637626648,0.0,accept,unanimous_agreement
758857987,9788,"the situation you mentioned has been handled in the if branch, and definitely doesn't exist error in the else branch (this code is currently redis used, i did not modify it)",0,0,0,0.988437831401825,0.9919135570526124,0.9925393462181092,0.0,accept,unanimous_agreement
758863343,9788,"1. i think there is no need to pass the aofmanifest parameter here. as you can see, in all the functions i implemented, some passed the aofmanifest parameter and some did not. the principle is that if it is a public api, such as being used in server.c, then it is the top-level api, and then it can directly access `server.aof_manifest`. other functions with aofmanifest parameters , they are mainly used internally (aof.c), and may handle two cases of `server.aof_manifest` and `temp_manifest`, so they need a variable parameter. there are similar top-level apis (declared in server.h): [code block] as you can see, if i pass all server.xxxx parameters in the main function of server.c, it will seem meaningless and the style is not uniform. [code block] 2. i don't think a return value is needed here. the reason is that manifest is a very important file (even more important than `redis.conf`), so once an error occurs, it is safest to exit directly and print the error message. the following is the function declaration for loading redis.conf: [code block]",0,0,0,0.9692349433898926,0.9894557595252992,0.976557195186615,0.0,accept,unanimous_agreement
758866266,9788,modified,0,0,0,0.9729309678077698,0.8963590860366821,0.8045071363449097,0.0,accept,unanimous_agreement
758866789,9788,modified,0,0,0,0.9729309678077698,0.8963590860366821,0.8045071363449097,0.0,accept,unanimous_agreement
758866972,9788,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
758867162,9788,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
758868972,9788,"yes, i discussed with . it was originally one day. i changed it to 1 hour later. in any case, once the user finds and solves the related problem, he can use bgrewriteaof to execute aofrw immediately without waiting for the limit. so i think there is no need to change here. wdyt?",0,0,0,0.9753677248954772,0.6865132451057434,0.9795370101928712,0.0,accept,unanimous_agreement
758870727,9788,"i may not understand your question too well, but i think the manifest is a meta file of aof, which requires a strict format restriction. and the manifest is different from `redis.conf`. `redis.conf` allows users to modify and customize by themselves, but in theory the manifest file can only be generated and modified by redis, so the manifest does not need flexibility, it needs a definite format. i don't know if my answer can solve your question, and i look forward to your feedback.",1,0,1,0.5613712072372437,0.952183187007904,0.9591817259788512,1.0,accept,majority_agreement
758876763,9788,"first of all, i wrote this code with reference to the existing redis code (similar writing in many places). in addition, i have researched it myself. i think it is not a safe practice to use errno directly. i give you a ref link: [a link]",0,0,0,0.9286625385284424,0.9660947918891908,0.963906466960907,0.0,accept,unanimous_agreement
758884107,9788,"do we really need this? currently, we can get the progress of loading through `server.loading_loaded_bytes` and `server.loading_loaded_perc` (print in redis info). in addition, if there is an error in the intermediate loading, we will also print out the file name with the error. i think the information we printed is enough now, wdyt?",0,0,0,0.9751530885696412,0.9840546250343324,0.987445831298828,0.0,accept,unanimous_agreement
759319537,9788,"i think yossi meant that if the manifest lines look like: [code block] it implies that they're pairs of key and value, and can be ordered differently, in which case the parser can iterate on the pairs in an if-else chain inside a while loop and don't care about the order. if it is mandatory that the order is fixed, then we may not need the ""key names"", and just do [code block] i.e. regardless of the fact users aren't expected to edit it. the fact we chose this flexible format, means we better also have a flexible parser.",0,0,0,0.8885126709938049,0.9797704219818116,0.9839534759521484,0.0,accept,unanimous_agreement
759332980,9788,"yes, the manifest format is fixed, i think we do not allow the following situations: [code block] the reason why it is displayed in the form of key-value (not just value) is because the user may often look at this file (after all, it is plain text and readable), and the key can clearly tell user the meaning of value. imagine that when we add other information to the manifest in the future, having a strict key identification can make it easier for us to do format verification. and, in the manifest file, i think we should not lose readability by skimping on a few bytes.",0,0,0,0.9474580883979796,0.9707008004188538,0.9842958450317384,0.0,accept,unanimous_agreement
759342340,9788,"the code we're looking at, prints a message when the file is present and was loaded successfully, and obviously when there's some parsing error, it prints a log message to (inside the function). besides that i see the function also has a specific print when the file is missing, and when it's empty. so i think that log-wise we're covered. i do see that we fail the loading when the file is present and empty, and maybe that's not good? the old code used to succeed when a file was either missing or empty. for the new code, we don't expect it to be missing (if we added it to the manifest, it should be there), but it could be empty (if there's no traffic after rewrite started). maybe the base file must never be empty, since that's either an rdb, or an aof with at least a select statement? but what if the server just started (a new deployment with no pre-existing data or persistence files), and then it is restarted after it created the aof file and didn't yet process any write command? i suppose the same could also be with upgrades (no manifest file). and i guess this concern will be resolved once we implement #9794 and always generate an rdb as base (even when starting empty).",0,0,0,0.9436236023902892,0.9688555598258972,0.9317260384559632,0.0,accept,unanimous_agreement
759397549,9788,"i agree, but changing the parsing code to use a while with if-else chain will not complicate the parser much, and will make it flexible.",0,0,0,0.9678152203559875,0.930789589881897,0.9788474440574646,0.0,accept,unanimous_agreement
759789250,9788,"i think you may have misunderstood it. the current implementation is: only when aof does not exist will load error, when it is empty, we will directly load the next one, the following is my handling of the return value: [code block]",0,0,0,0.9587565660476683,0.9743257761001588,0.9738420248031616,0.0,accept,unanimous_agreement
759824288,9788,"i have modified it to use for loop, plz review this part again, thanks.",1,1,1,0.961065709590912,0.9139175415039062,0.937998116016388,1.0,accept,unanimous_agreement
759932120,9788,"yes, you're right, i misinterpreted that code. so we skip empty files, and fail on non existing ones, and either of the 4 states (missing, empty, error, success) there is a log print. i think we're good, but maybe i'm missing yossi's intention in the original comment.",0,0,0,0.9291386008262634,0.8242812156677246,0.6401007771492004,0.0,accept,unanimous_agreement
759933974,9788,lgtm. maybe add a comment next to the last `else` and the `<6` to note that it was done for forward compatibility.,0,0,0,0.9885023832321168,0.9936475157737732,0.9920541048049928,0.0,accept,unanimous_agreement
770526837,9788,"depending on how often this will be used, maybe we should pre-allocate the `sdsnew` to be reasonably big, so we don't re-allocate it twice in sdscat. i.e. maybe do `sdsnewlen(sds_noinit)`. same can be done in dirremove",0,0,0,0.986840844154358,0.9942914247512816,0.9883042573928832,0.0,accept,unanimous_agreement
770893232,9788,"i think the temp dir must be based on the server.aof_filename pattern, and not a constant one. otherwise, if there are two servers in the same dir, their temp upgrade dir clash.",0,0,0,0.97404807806015,0.9754915833473206,0.9859126210212708,0.0,accept,unanimous_agreement
770895001,9788,does that cause a restart of the upgrade? looks like we're exiting with an error? maybe i'm missing something (looking at the diff of this commit in gh rather than the full source tree),0,0,0,0.910119891166687,0.9782639145851136,0.9786393642425536,0.0,accept,unanimous_agreement
772143017,9788,"ohh, looking at this again, i realize the error is not related to the comment above it (the upgrade restarts only if we successfully remove the dir, but if we can't then we fail and exit. i suppose this is not expected to ever happen.",0,0,0,0.575631856918335,0.8674448132514954,0.9488596320152284,0.0,accept,unanimous_agreement
772173860,9788,"here will crash in sentinel mode, it does not call `aofloadmanifestfromdisk`.",0,0,0,0.9824478030204772,0.9829937219619752,0.9810039401054382,0.0,accept,unanimous_agreement
772742569,9788,"fixed, thx.",0,0,0,0.9842363595962524,0.845086395740509,0.9717017412185668,0.0,accept,unanimous_agreement
773676185,9788,why not `.`?,0,0,0,0.9741812944412231,0.9869051575660706,0.987101674079895,0.0,accept,unanimous_agreement
773682145,9788,indentation and line break [code block],0,0,0,0.982203245162964,0.9909642934799194,0.9944327473640442,0.0,accept,unanimous_agreement
773684494,9788,"maybe it's a better idea actually rename it to the normal format and add a `base` suffix etc, and not just move it to the folder? we probably can't afford to put a suffix on it (we don't know the content), though, we maybe that's not a good idea, unless we conclude to remove the suffix from our file name template anyway. note that if we do that, we need to relax the upgrade failure recovery conditions in `strcmp(am->base_aof_info->file_name, server.aof_filename)`, but i'm not sure that's a problem.",0,0,0,0.9576653242111206,0.9627676606178284,0.9650729298591614,0.0,accept,unanimous_agreement
773741198,9788,because i want to make them more unified: [code block],0,0,0,0.9684848189353944,0.9863277673721312,0.9913716316223145,0.0,accept,unanimous_agreement
773761166,9788,"ok, in my eyes it's a table: [code block] maybe if we change the `_` to `.`, or change the first `.` to `_` it'll make more sense? i.e. either: `appendonly.aof.1.base.aof` or `appendonly.aof_1_base.aof`",0,0,0,0.9783953428268432,0.989267110824585,0.9827540516853333,0.0,accept,unanimous_agreement
773795695,9788,"no, we cannot add a suffix when rename here, because this is the only way to identify the interrupted upgrade. `am->base_aof_info->file_name` is same with `server.aof_filename` only appears when upgrading. otherwise, if a file with a suffix appears in the manifest but does not exist in the aof dir, we consider this to be a serious error and the process exits directly.",0,0,0,0.9778285026550292,0.9812750220298768,0.9899159073829652,0.0,accept,unanimous_agreement
773799466,9788,"i don't like to have too many `.` , it can easily lead to misunderstandings because it contains the `.aof` `.1` `.base` `.aof` suffix",0,-1,0,0.5108887553215027,0.9502947330474854,0.674817681312561,0.0,accept,majority_agreement
773799785,9788,fixed.,0,0,0,0.9810503125190736,0.979083240032196,0.9905837774276732,0.0,accept,unanimous_agreement
773803755,9788,"i think it is not a strong requirement to include the encoding format in file name. we can add the format field in the manifest, if anyone is interested in this. aof dir: [code block] the content of manifest: [code block]",0,0,0,0.9782987833023072,0.9875182509422302,0.9768872261047364,0.0,accept,unanimous_agreement
773837992,9788,"it's not the ""only way"" we identify it. it's at the very least a combination of a file in the manifest that's missing on the disk, and the presence of the old (legacy location) file on the disk. but i do agree that this make our interrupted upgrade detection better, so i'll drop it. p.s. if we wanted we could have also added an indication in the manifest that this is the upgrade file.",0,0,0,0.9807790517807008,0.9884412288665771,0.9631840586662292,0.0,accept,unanimous_agreement
773838756,9788,i think the indentation change is in some way missing (because of the parenthesis),0,0,0,0.9790990352630616,0.9673610925674438,0.9781298637390136,0.0,accept,unanimous_agreement
773852970,9788,"i don't see the problem with multiple `.` in the file name.. it's not uncommon, and it's a well established pattern to only look past the last `.` for the file format, so in that respect, in my eyes the manifest is the format and should use `.` also, there are already two `.` in your other file patterns, so i'm not sure what's bothering you about it. if the other `_` bother us, we can change it to `.` as well. as for the format suffix, i don't think it should be part of the manifest, i think it should be in the file name, and what's bothering us is that we have two mentions of the ""format"" in the file name (`.aof` can appear twice)",0,0,0,0.8081505298614502,0.7229026556015015,0.8259479403495789,0.0,accept,unanimous_agreement
773858136,9788,"i think it is necessary for us to vote for this rule. let me summarize that we now have blow options ( maybe you have other plans to add): **note**: we have concluded that the original `appendfilename` (default `appendonly.aof`) will be used as the `basename` of the new file name, and we **cannot do any trim** operations on `appendfilename`, so we are discussing how to combine the suffix part of the new name. 1. use `. ` to combine `basename` and `suffix` [code block] 2. use `_` to combine `basename` and `suffix` [code block] 3. use `_` to combine `basename` and `suffix` and remove format `suffix` [code block] 4. use `_` to combine `basename` and `suffix` and remove format `suffix`, and add format field to manifest file. [code block] and the content of manifest (add format field ): [code block] 5. use `. ` to combine `basename` and `suffix`, remove format `suffix`, and remove one more `.` to simplify naming [code block] and the content of manifest (add format field ): [code block] please vote which one of the above are more satisfactory to you, or if you have a better suggestion, thank you.",0,0,0,0.9182082414627076,0.9355000257492064,0.9845751523971558,0.0,accept,unanimous_agreement
773873218,9788,"i had a discussion about this (the annoying presence of "".aof"" in file names derived from `appendfilename`) with -steinberg to try to see if we can come up with something. one idea that came up is this: 1. when creating the manifest on upgrade, use `server.aof_filename`, but without any "".aof"" suffix if present 2. when creating the base file entry for the upgrade in the manifest, do the same (remove the "".aof"" suffix) 3. after when moving the existing aof file into the folder, do the same. 4. after the upgrade is done (rename is completed), and on normal startup if there was no upgrade, we actually trim the "".aof"" suffix from `server.aof_filename` (modify the variable) so now, if someone does `config get appendfilename` or `config rewrite`, the value of the config no longer has the `.aof` suffix. so if i had a concern that that someone will write a bash script doing [code block] this would still work. notes: * i don't particularly like this idea (yet) * i must note that we have other configs for which the config get value is mutated. e.g. `config set maxmemory 1g` will translate to a different value in config get. * it would still look ugly for anyone looking at the redis.conf file that's shipped with redis (mentioning `appendonly.aof`, in case there are no config rewrites), but what we can do is delete that line from the default config, and only rely on the default value hard-coded in redis. * we can update the comment in redis.conf to just mention `# appendfilename appendonly` (without the suffix) * this means that the only way a user of a new deployment to observe that the hard coded default value is with `.aof` is by looking at the code, since at startup we change it right after handling the upgrade procedure, that default is not observable in any way. * unlike the `maxmemory` config, this one is immutable, so you can't observe that you do config set, and get a different value in config get.",-1,0,-1,0.9360377192497252,0.943817138671875,0.5999916195869446,-1.0,accept,majority_agreement
773895207,9788,"i don’t think it’s a good idea to modify the user’s configuration without authorization. `appendfilename` and `maxmemory` are different. if we trim `appendfilename`, we won’t be able to distinguish between these two configurations: `appendfilename appendonly `and `appendfilename appendonly.aof`.",0,0,0,0.9737178087234496,0.9587864875793456,0.9288247227668762,0.0,accept,unanimous_agreement
773897506,9788,"i agree.. i don't see any other good way to get rid of "".aof"" we have in the middle of the file names we create. i vote for 1",0,0,0,0.870176374912262,0.7798237204551697,0.8952956795692444,0.0,accept,unanimous_agreement
774487221,9788,"commenting here, for a discussion about another block in the config that i can't comment on (no changes). [code block] first, the term ""preamble"" is no longer applicable, since they're now in different files. but obviously we can't rename the config. what we can do, is update the documentation, which should state that this config determines if the rewrite will generate an rdb format, or an aof (resp) format.",0,0,0,0.9809995889663696,0.9894267320632936,0.9868261218070984,0.0,accept,unanimous_agreement
774494703,9788,"i'm also in favor of 1. i don't see the `.aof` as such a big problem as it only affects users who transition from an older version and don't bother updating the configuration file. it's important not to do something terribly wrong in this case, but having less-than-ideal file naming seems reasonable to me.",0,0,0,0.5972936153411865,0.8480471968650818,0.8462478518486023,0.0,accept,unanimous_agreement
774542121,9788,"i voted for 5, just from my personal aesthetic point of view.",0,0,0,0.9443492293357848,0.9347565174102784,0.9039583802223206,0.0,accept,unanimous_agreement
774545399,9788,"first of all, i still don't like the method that using `appendfilename` as prefix, it makes the new files' name ugly and hard to understand. i prefer using file lock (i.e. a unified `lock` file in folder), if user start some redis instances in the same folder, just log and exit. but if you insist on handling some strange schrodinger's scenarios and want suffix, i vote for 2. because use `.` to combine may lead to a problem, if someone like me don't like the prefix, he or she may set the prefix `appendfilename` to empty, file start with `.` is invisible.",-1,-1,-1,0.9687462449073792,0.936888873577118,0.954170286655426,-1.0,accept,unanimous_agreement
774560029,9788,"i don't see why anyone would set the prefix to empty. you'd better set it to just ""appendonly"", or ""my_redis"", or ""redis-1"". anyway, i don't mind to use `_` in between the different parts of the template, but i think the last part should be the file format (obviously using `.`). so maybe this could be a plan: [code block] note that the manifest is now a csv instead of being space separated. and maybe that brings another concern: whatever we choose ad a separator, we must make sure the user doesn't include in his file names `appendfliename` since it'll mess up our parsing (i.e. if he uses space or comma)",0,0,0,0.9291854500770568,0.9846081137657166,0.9737908244132996,0.0,accept,unanimous_agreement
774824722,9788,"coming in late, i would also prefer option 1, but don't feel strongly between option 1 and 2.",0,0,0,0.855309247970581,0.971571683883667,0.8570976257324219,0.0,accept,unanimous_agreement
774949981,9788,"i don't think the documentation should refer to ""base"" and ""incr"" as terms or format, but rather use plain english (""base"" and ""incremental"") [code block]",0,0,0,0.9835825562477112,0.9912376999855042,0.9852547645568848,0.0,accept,unanimous_agreement
774951964,9788,there was too much detail here imho. users and admins don't need to understand what resp is (that's for client library developers). and don't care about the file format header bytes. [code block],-1,-1,-1,0.7989497184753418,0.5643377304077148,0.6716802716255188,-1.0,accept,unanimous_agreement
775012377,9788,fix,0,0,0,0.9845474362373352,0.9446781873703004,0.8724648356437683,0.0,accept,unanimous_agreement
775012414,9788,fix,0,0,0,0.9845474362373352,0.9446781873703004,0.8724648356437683,0.0,accept,unanimous_agreement
775051173,9788,you missed one 8-) [code block],0,0,0,0.940061330795288,0.9182098507881165,0.9886794686317444,0.0,accept,unanimous_agreement
775208493,9788,i concluded that it's ok to just strip down this info field.,0,0,0,0.9739843606948853,0.9716320633888244,0.9854224920272828,0.0,accept,unanimous_agreement
775208776,9788,"ohh, i now see that since i wrote down this comment we've re-introduced that field and it's always set to 0 (and the top comment already indicates that). did we decide that in some other comment? wdyt? keep a dead info field always set to 0, or trim it? (i'm leaning towards trimming it)",0,0,0,0.7504191994667053,0.9544182419776917,0.9588853120803832,0.0,accept,unanimous_agreement
775213392,9788,"doesn't this mean the max limit will be 32? i suppose we should remove the condition for `limit_deley_minutes < aof_rewrite_limite_nax_minutes` and always do the ` <<= `. p.s. since we're aiming to multiply by 2, and not do some bit manipulation, i think the code will be clearer if we use ` *= 2`. (performance is all the same anyway)",0,0,0,0.9774167537689208,0.9860879778862,0.9915533661842346,0.0,accept,unanimous_agreement
775214574,9788,this division always gave me the shivers. maybe it's time to change that constant to 1024?,0,0,-1,0.732029378414154,0.9818966388702391,0.8464163541793823,0.0,accept,majority_agreement
775215030,9788,"i think we must reflect that truncation in the return value, and let the caller handle it. if this was not the last aof file in the list, we can't afford to continue to handle the next one. we can choose between: 1. skip any remaining aof files. 2. fail with an error since we only expect truncation in the last file i think i prefer 2. maybe we should reflect this decision in the pr top comment, for other reviewers to see.",0,0,0,0.9669965505599976,0.9841290712356568,0.9437276124954224,0.0,accept,unanimous_agreement
775218990,9788,why is this reorder needed? the database is empty during this rewrite anyway.,0,0,0,0.9739588499069214,0.9819930791854858,0.9828876256942748,0.0,accept,unanimous_agreement
775219093,9788,isn't that the default? why do we provide file name and dir name here? just to be explicit since the test refers to them? maybe instead we should make the test use config get?,0,0,0,0.9867790937423706,0.9934183359146118,0.9915483593940736,0.0,accept,unanimous_agreement
775219356,9788,maybe we should put this in utils.tclor in aofmanifest.tcl? (using config get) i imagine there would be other tests that want to access the last aof file.,0,0,0,0.985444724559784,0.9946842789649964,0.98947936296463,0.0,accept,unanimous_agreement
775219491,9788,"why was that sleep needed? if there's some timing issue, i'd rather add some `wait_for` and finish sooner rather than add another 1 second delay here. also, if it is really needed, let's add a comment why.",0,0,0,0.9738720059394836,0.985983431339264,0.9934219717979432,0.0,accept,unanimous_agreement
775224918,9788,another case where i'm not clear as to why we need to override default configs with the same value,0,0,0,0.9340581297874452,0.8379904627799988,0.949029266834259,0.0,accept,unanimous_agreement
775224952,9788,why are all of these needed here? afaict they're unused. am i missing anything?,0,0,0,0.9117099046707152,0.5985476970672607,0.9450966715812684,0.0,accept,unanimous_agreement
775225503,9788,same question about default configs (here and in the test below),0,0,0,0.9866424798965454,0.9911824464797974,0.9935652613639832,0.0,accept,unanimous_agreement
775225604,9788,"that's the same pattern we used in expire.tcl which i suggested to extract to a utility function, right? same for the test just below, and another one further down.",0,0,0,0.9883544445037842,0.9914986491203308,0.9932550191879272,0.0,accept,unanimous_agreement
775225928,9788,"maybe we should have `create_aof` implicitly create the folder when needed? maybe we could pass it an optional argument to of a string to put in the manifest? or maybe just an optional boolean, in case the manifest content is the same in all the tests that do this?",0,0,0,0.988502025604248,0.9957120418548584,0.9910736680030824,0.0,accept,unanimous_agreement
775225958,9788,same question about default configs.. why do we need to override them?,0,0,0,0.9664586782455444,0.9680325388908386,0.987448751926422,0.0,accept,unanimous_agreement
775227953,9788,"why did you choose to print to stderr here and not to the log file. note that if redis was started daemonized, then these prints go nowhere. at the time this code is executed (in loaddatafromdisk), the old code in redis used to print failures to the log file.",0,0,0,0.981274664402008,0.9813578724861144,0.9864121675491332,0.0,accept,unanimous_agreement
775230416,9788,"try to avoid using the term ""rewrite"" before explaining it. [code block]",0,0,0,0.8735265135765076,0.991203546524048,0.9908093214035034,0.0,accept,unanimous_agreement
775232044,9788,i see many of the tests below are missing some assertion to check that we successfully hit the scenario we aimed for. i.e. match some log message of the expected failure.,0,0,0,0.986817181110382,0.988619327545166,0.9865154027938844,0.0,accept,unanimous_agreement
775232825,9788,"maybe it'll be better if each of these tests is in a test scope. like so: [code block] i.e. the server is started inside the test and not vice versa. p.s. this way if the test has some skip tag, the server setup and creation is skipped too",0,0,0,0.9809951186180116,0.991913080215454,0.9832077026367188,0.0,accept,unanimous_agreement
775233218,9788,do we also have a test that attempts to load an old preamble-rdb file? i.e. put one in the assets folder and attempt to upgrade from that.,0,0,0,0.9872149229049684,0.993850588798523,0.9945513606071472,0.0,accept,unanimous_agreement
775233394,9788,can't we use `set client [redis_client]`?,0,0,0,0.9886106848716736,0.995071828365326,0.9951901435852052,0.0,accept,unanimous_agreement
775233637,9788,"that's a long sleep. maybe this was copied from somewhere, so i'd like to use this opportunity to promote this into a utility function. it can use shorter sleeps (10ms), and do the verbose puts only in one of 100 iterations",0,0,0,0.9310303926467896,0.9713836908340454,0.9518631100654602,0.0,accept,unanimous_agreement
775234037,9788,"let's add some comment that we synthetically create a layout of an interrupted upgrade (interrupted before the rename). and even describe that it's a folder containing manifest pointing to a missing file, where e file is still outside the folder.",0,0,0,0.9877625703811646,0.9868940114974976,0.993816375732422,0.0,accept,unanimous_agreement
775234483,9788,let's add an assertion for some log message here too (all tests that expects the server to fail starting),0,0,0,0.9887136816978456,0.9921404719352722,0.9939841628074646,0.0,accept,unanimous_agreement
775234957,9788,i think it would be better if the two servers are nested (running at the same time). [code block],0,0,0,0.9835811853408812,0.9896793365478516,0.986500322818756,0.0,accept,unanimous_agreement
775236162,9788,"that's a lot of time, let's increase the check interval (`wait_for_condition 1000 10` should be ok, right?)",0,0,0,0.8061507344245911,0.977788746356964,0.8447682857513428,0.0,accept,unanimous_agreement
775236426,9788,maybe use this opportunity to check that the temp files are deleted? (by counting the number of files in the folder),0,0,0,0.9846311211586,0.9926403164863586,0.9885489344596864,0.0,accept,unanimous_agreement
775237627,9788,"1. let's make sure that all of the above steps got to complete while the `rdb_bgsave_in_progress` is still 1. 2. setting the key-save-delay will not cause the fork to detect it, and we'll still have to wait for it to complete. i guess we have to kill it to proceed.",0,0,0,0.859666645526886,0.9833137392997742,0.9875109195709229,0.0,accept,unanimous_agreement
775237762,9788,"let's change the constant sleep with a wait_for_condition. we can look at the `aof_rewrite_scheduled` info field (i.e. assert that it's 1 before, and then wait for it to go to 0 before doing `waitforbgrewriteaof`",0,0,0,0.9871923923492432,0.9913610816001892,0.9915115237236024,0.0,accept,unanimous_agreement
775238110,9788,i'd like to increase the interval (10ms). the rewrite check in servercron happens every tick.,0,0,0,0.980292022228241,0.9863842129707336,0.9944658875465392,0.0,accept,unanimous_agreement
775238701,9788,"the lowest throttle is 1 minute, right? and in the absence of a throttle, redis would have started a new rewrite every 10 ms, right? so maybe we can have a shorter sleep?",0,0,0,0.9734740853309632,0.9824631214141846,0.97748064994812,0.0,accept,unanimous_agreement
775238900,9788,maybe we can also assert to check that there's no `aof_rewrite_in_progress`?,0,0,0,0.9884843230247498,0.9950696229934692,0.9923520684242249,0.0,accept,unanimous_agreement
775238976,9788,maybe assert here that aof_rewrite_in_progress is 0 too? i.e. just to make it clear that the next bgrewriteaof is gonna be the one that succeeds.,0,0,0,0.9866623282432556,0.9920916557312012,0.9889062643051147,0.0,accept,unanimous_agreement
775239610,9788,"-steinberg i'm not sure which version did you review? iiuc we eliminated the references to uppercase base and incr in the docs. maybe your phrasing comments are still applicable, but maybe you should dismiss them and make new suggestions base on the latest?",0,0,0,0.9605111479759216,0.9841641783714294,0.910359501838684,0.0,accept,unanimous_agreement
775244034,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775244132,9788,changed to 100ms,0,0,0,0.9823265671730042,0.9885231852531432,0.9803860783576964,0.0,accept,unanimous_agreement
775244336,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775245004,9788,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
775297024,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775297422,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775297490,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775297652,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775298021,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775302156,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775403304,9788,"i think we can trim it. `info` is already free to omit fields depending on settings, so i guess clients should be used to not finding specific fields in some cases.",0,0,0,0.9869326949119568,0.9817522764205932,0.986906111240387,0.0,accept,unanimous_agreement
775452024,9788,"yes, under normal circumstances, only the last aof will have abnormal multi/exec, i prefer 2 too.",0,0,0,0.971253216266632,0.969585657119751,0.9851544499397278,0.0,accept,unanimous_agreement
775455266,9788,"ok.. in this case it's a field that's unlikely to be used by clients (apps), just monitoring software. please trim it (again), and update the top comment.",0,0,0,0.9837816953659058,0.9899559020996094,0.99327552318573,0.0,accept,unanimous_agreement
775472174,9788,"yes, rollback it.",0,0,0,0.9857110381126404,0.950673520565033,0.9887828230857848,0.0,accept,unanimous_agreement
775472980,9788,here i refer to the previous style. maybe when someone will change the default value in the future?,0,0,0,0.9859753251075744,0.9915196299552916,0.9927418231964112,0.0,accept,unanimous_agreement
775474545,9788,"removed ,maybe added when i debug.",0,0,0,0.9853090643882751,0.9817280769348145,0.9910674691200256,0.0,accept,unanimous_agreement
775475504,9788,removed.,0,0,0,0.9311882257461548,0.9782117605209352,0.9612457156181335,0.0,accept,unanimous_agreement
775704537,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775707375,9788,added,0,0,0,0.973513960838318,0.9267084002494812,0.8435775637626648,0.0,accept,unanimous_agreement
775707658,9788,"no, will report err: [code block]",0,0,0,0.9846204519271852,0.9804654121398926,0.9601260423660278,0.0,accept,unanimous_agreement
775722964,9788,changed to waitforbgrewriteaof,0,0,0,0.9872419834136964,0.979013204574585,0.9788429737091064,0.0,accept,unanimous_agreement
775723305,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775723545,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775723703,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775726471,9788,added,0,0,0,0.973513960838318,0.9267084002494812,0.8435775637626648,0.0,accept,unanimous_agreement
775727759,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775731527,9788,added,0,0,0,0.973513960838318,0.9267084002494812,0.8435775637626648,0.0,accept,unanimous_agreement
775731686,9788,added,0,0,0,0.973513960838318,0.9267084002494812,0.8435775637626648,0.0,accept,unanimous_agreement
775735126,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775737327,9788,added,0,0,0,0.973513960838318,0.9267084002494812,0.8435775637626648,0.0,accept,unanimous_agreement
775738505,9788,just imitate the previous style` {appendonly {yes} appendfilename {appendonly.aof}`,0,0,0,0.984995424747467,0.9925166964530944,0.994981586933136,0.0,accept,unanimous_agreement
775738661,9788,just imitate the previous style {appendonly {yes} appendfilename {appendonly.aof},0,0,0,0.98594331741333,0.9891310930252076,0.9957018494606018,0.0,accept,unanimous_agreement
775738687,9788,just imitate the previous style {appendonly {yes} appendfilename {appendonly.aof},0,0,0,0.98594331741333,0.9891310930252076,0.9957018494606018,0.0,accept,unanimous_agreement
775744059,9788,added,0,0,0,0.973513960838318,0.9267084002494812,0.8435775637626648,0.0,accept,unanimous_agreement
775745544,9788,"when we initialize (for example, when redis is started), we will open incr aof instead of creating a new base, so i think the original comments is fine.",0,0,0,0.9600545167922974,0.9840341806411744,0.9712954759597778,0.0,accept,unanimous_agreement
775745694,9788,"i think they mean the same thing, right?",0,0,0,0.9622918367385864,0.9690297842025756,0.9778193831443788,0.0,accept,unanimous_agreement
775749312,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775751807,9788,the aof initialization don't create base aof.,0,0,0,0.9682086110115052,0.9862244129180908,0.9894166588783264,0.0,accept,unanimous_agreement
775754571,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775757692,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775790602,9788,"i think we better drop both, it's long to read and maybe slightly confusing. also since the defaults are never gonna change, even if we refer to these in the code, i'm not sure we should bother to define them.",0,-1,-1,0.9375550746917723,0.5286991596221924,0.5771957039833069,-1.0,accept,majority_agreement
775792769,9788,need to remove all the default value override in the existing test?,0,0,0,0.973831057548523,0.9938123226165771,0.9937295913696288,0.0,accept,unanimous_agreement
775796248,9788,removed.,0,0,0,0.9311882257461548,0.9782117605209352,0.9612457156181335,0.0,accept,unanimous_agreement
775796301,9788,removed,0,0,0,0.9654131531715392,0.9801433682441713,0.9591778516769408,0.0,accept,unanimous_agreement
775796356,9788,removed,0,0,0,0.9654131531715392,0.9801433682441713,0.9591778516769408,0.0,accept,unanimous_agreement
775796439,9788,removed,0,0,0,0.9654131531715392,0.9801433682441713,0.9591778516769408,0.0,accept,unanimous_agreement
775797507,9788,"we're gonna change this soon (will always create a base file even in that case), see #9794 but maybe we can find a way to say that without mentioning neither ""initial"", nor ""rewrite"" which is also not in line with the above mentioned plan. i see this section is below all the text that defines the folder and base / incremental. so maybe we can just refer to the ""base""?",0,0,0,0.9780017137527466,0.992178440093994,0.9862950444221495,0.0,accept,unanimous_agreement
775798234,9788,i think base is better.. rewrite is just one way to create a base file (see plans in #9794 ),0,0,0,0.8758290410041809,0.9771615862846376,0.9710636138916016,0.0,accept,unanimous_agreement
775799341,9788,"can you explain in more detail ""always generate base rdb (even when starting empty)""",0,0,0,0.98835551738739,0.9920404553413392,0.9945321083068848,0.0,accept,unanimous_agreement
775799963,9788,"it will soon (see #9794). but also, considering the state of this pr, isn't it better to tag the first aof file we create as ""base""? i.e. when loading an aof manifest, the first file we load must always be a ""base"" file. i.e. it would be wrong to start from an ""incremental"" file since it implies we're starting from the middle with no view of the history, so in that sense i think that on empty startup, we should change the code and tag the first file as ""base""",0,0,0,0.9740663766860962,0.9911822080612184,0.9864618182182312,0.0,accept,unanimous_agreement
775832657,9788,"when rdb-preamble is enabled (or maybe even if it isn't), and redis starts up empty configured to persist to aof, i want it to do an rdbsaverio and generate an empty base file. this may be required for some modules that want to persist their configuration into rdb aux fields, so that when we recover from persistence, they know with which config that persistence was created.",0,0,0,0.988756000995636,0.9918137788772584,0.9933765530586244,0.0,accept,unanimous_agreement
775845823,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775845869,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775853586,9788,maybe we'll change that text in the next pr.,0,0,0,0.980815291404724,0.9873966574668884,0.9793535470962524,0.0,accept,unanimous_agreement
775864818,9788,"this looks odd to me, as it could override other valid statuses so it looks dangerous (like failure or different types of success). in practice, as far as i can tell, we init it to ok at the top, and after that the only way to get here with a non-ok status is the truncated status. so i think this line should be removed.",-1,-1,-1,0.8763964176177979,0.9581062197685242,0.7249666452407837,-1.0,accept,unanimous_agreement
775874649,9788,"i think it's odd to hide (override) the truncated status, let's propagate it to the caller when it's valid. and override it with failed when it's not in the last file. we'll need to update the two callers of that function to handle that value correctly. debug.c isn't expecting it, so it can consider it as failure (maybe revert your change there?) and server.c can consider it as success (which it already does afaict).",0,0,-1,0.7658495903015137,0.8106498718261719,0.4991741776466369,0.0,accept,majority_agreement
775886149,9788,maybe now you can let go of the numbering (can get out of sync in with future edits) and even most titles (i.e. when the test name has the exact same info),0,0,0,0.9858605861663818,0.9902931451797484,0.9881983399391174,0.0,accept,unanimous_agreement
775889432,9788,why is this at the end of the previous test and not the beginning of the next one?,0,0,0,0.9291461110115052,0.9898169040679932,0.9873573780059814,0.0,accept,unanimous_agreement
775896369,9788,"in case it's very fast, we won't get to see it turn to `1`. i think it's ok to: 1. see the scheduled flag turn off. 2. waitforbgrewriteaof if for some reason that's not enough, we can wait for `[s total_forks]` to get incremented.",0,0,0,0.9834988713264464,0.9781777858734132,0.982029139995575,0.0,accept,unanimous_agreement
775896501,9788,please mention what are we waiting for to happen.,0,0,0,0.9769805669784546,0.9804068207740784,0.990037202835083,0.0,accept,unanimous_agreement
775896800,9788,"the wait_for_condition will fail, there's no need for the assertion",0,0,0,0.981170892715454,0.9509503841400146,0.992122232913971,0.0,accept,unanimous_agreement
775897321,9788,"i didn't bother to download and look at the binary file, so i don't know what's in it. i assume some of these keys are part of the rdb header, and some are part of the aof tail? is that true? maybe add a comment here.",0,0,0,0.981389343738556,0.8694635033607483,0.9864944219589232,0.0,accept,unanimous_agreement
775898403,9788,right.,0,0,0,0.9566289782524108,0.9793882369995116,0.9789980053901672,0.0,accept,unanimous_agreement
775899188,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775902002,9788,oh my mistake,-1,-1,-1,0.9860633015632628,0.948908030986786,0.9896242022514344,-1.0,accept,unanimous_agreement
775904698,9788,i think this can be removed.,0,0,0,0.9856644868850708,0.9621762037277222,0.9881540536880492,0.0,accept,unanimous_agreement
775905163,9788,"all k1 k2 and k3 in rdb header, do we need rdb header and aof tail?",0,0,0,0.9896221160888672,0.9946240186691284,0.9954996705055236,0.0,accept,unanimous_agreement
775905794,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775907084,9788,"ok, do [s total_forks]",0,0,0,0.987520694732666,0.9890736937522888,0.992806911468506,0.0,accept,unanimous_agreement
775907253,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775907588,9788,"yes, i wanna make sure we can still handle such files (since we no longer generate them)",0,0,0,0.9838808178901672,0.9815391898155212,0.9910638332366944,0.0,accept,unanimous_agreement
775907949,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
775909556,9788,"need to add truncated here, or maybe just change it to an `else` for the above?",0,0,0,0.9772651791572572,0.9948195815086364,0.99213445186615,0.0,accept,unanimous_agreement
775909751,9788,same here?,0,0,0,0.9831424355506896,0.9754432439804076,0.9924941062927246,0.0,accept,unanimous_agreement
775914671,9788,changed to `if (ret == aof_open_err || ret == aof_failed) `,0,0,0,0.983439803123474,0.9935996532440186,0.9933057427406312,0.0,accept,unanimous_agreement
775914804,9788,changed to `if (ret == aof_open_err || ret == aof_failed)`,0,0,0,0.983439803123474,0.9934186935424804,0.9935994148254396,0.0,accept,unanimous_agreement
775916165,9788,is any of the other states valid in this case? like not_exist and open_err?,0,0,0,0.9838290810585022,0.9937577247619628,0.9932992458343506,0.0,accept,unanimous_agreement
775917548,9788,#define aof_ok 0 -> ok #define aof_not_exist 1 -> aof_failed -> goto cleanup #define aof_empty 2 -> ok #define aof_open_err 3 -> goto cleanup #define aof_failed 4 -> goto cleanup #define aof_truncated 5 -> aof_failed (if not last file) -> goto cleanup,0,0,0,0.9773592352867126,0.9915751814842224,0.9828577041625975,0.0,accept,unanimous_agreement
775917797,9788,i think i covered all the status,0,0,0,0.9781768321990968,0.8271957039833069,0.9803438186645508,0.0,accept,unanimous_agreement
775937228,9788,"ok, i think you're right. wanted to double check.",0,0,0,0.9404916167259216,0.929939031600952,0.8810808062553406,0.0,accept,unanimous_agreement
776832493,9788,[code block] updated the log message to be more clear to users.,0,0,0,0.9873369336128236,0.989943504333496,0.9954687356948853,0.0,accept,unanimous_agreement
776835168,9788,[code block] updating the log message because the error may not necessarily be due to a non-existing file.,0,0,0,0.9856524467468262,0.9915423393249512,0.9921432733535768,0.0,accept,unanimous_agreement
776838066,9788,"suggest to move this check out of this function, as it seems like a generic create-if-not-exists utility function.",0,0,0,0.9802696108818054,0.9934453964233398,0.9932952523231506,0.0,accept,unanimous_agreement
776892639,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
776893358,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
776893374,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
776893418,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
776893763,9788,"no, the file must not exist here, because we ruled out this possibility in the if branch.",0,0,0,0.97736257314682,0.9906050562858582,0.9895367622375488,0.0,accept,unanimous_agreement
776893912,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
776894141,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
776894274,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
776894325,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
776894415,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
776894558,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
776894648,9788,and note we will return aof_not_exist error code.,0,0,0,0.9873100519180298,0.987116038799286,0.9947392344474792,0.0,accept,unanimous_agreement
777004480,9788,"what we know here is that both `fopen` and `fstat` failed. i guess you could change [code block] then when you get here, you know for sure it doesn't exist.",0,0,0,0.981953740119934,0.9792718291282654,0.9900800585746764,0.0,accept,unanimous_agreement
777019408,9788,"yes, but does it mean that when it returns -1 the file must not exist? it could be a range of other errors.",0,0,0,0.9794952869415284,0.974251925945282,0.9890901446342468,0.0,accept,unanimous_agreement
777024434,9788,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
815555837,9788,"should be `appendonly.aof*` instead of `appendonly.aof.*` now, `appendonly.aof` will not be ignored.",0,0,0,0.985493004322052,0.9938550591468812,0.9943576455116272,0.0,accept,unanimous_agreement
815592564,9788,"maybe you're right, but the current implementation doesn't create a file named `appendonly.aof` unless you manually copy an old-style aof for upgrade testing. so i think we just need to ignore the file we're going to create. wdyt?",0,0,0,0.9817051887512208,0.9759021401405334,0.9767411947250366,0.0,accept,unanimous_agreement
815608833,9788,"i think it's a good idea to ignore both. i.e. both the ones we create, and the ones we created in the past, that are still left in the folder.",0,0,0,0.6317984461784363,0.9552854299545288,0.9404571652412416,0.0,accept,unanimous_agreement
815617083,9788,"only developers pay attention to `.gitignore`, and when i updated the `unstable brance` code, `appendonly.aof` caught my attention, so i started this discussion.",0,0,0,0.9617940187454224,0.9847084283828736,0.9901320934295654,0.0,accept,unanimous_agreement
815625209,9788,"sounds reasonable, i'll make a pr to add it, thanks.",1,1,1,0.9002507925033569,0.8962209224700928,0.8725603818893433,1.0,accept,unanimous_agreement
984633230,11012,"we don't typically add licensing information in headers. also, you aren't redis labs.",0,0,0,0.9815971851348876,0.989489734172821,0.9913191199302672,0.0,accept,unanimous_agreement
984634960,11012,should this just be a `listnode listnode` so we don't have a double layer of indirection?,0,0,0,0.985148310661316,0.992638349533081,0.9922237396240234,0.0,accept,unanimous_agreement
984637261,11012,"wonder if it's time to make this an enum? if it's too intrusive it's okay to skip it, but i'm going it'll be a small change.",0,0,0,0.789641261100769,0.6680964827537537,0.9252904057502748,0.0,accept,unanimous_agreement
984638049,11012,[code block] more reason to make it an enum.,0,0,0,0.9837407469749452,0.9877753257751464,0.9921332597732544,0.0,accept,unanimous_agreement
984646790,11012,"as far as i can tell blocked_list and blocked_zset aren't handled separately, and they could be generalized to `blocked_no_key`. there is the ongoing beval conversation, [a link] which we could trivially add support for with this.",0,0,0,0.984847128391266,0.9933807849884032,0.9926924705505372,0.0,accept,unanimous_agreement
984684026,11012,"i don't think we want to recursively call this api. for lmove, you could have a chain of calls that goes deeper into the stack. instead, we can probably just loop until all of the unblocked keys have been satisfied. which i think is handled properly in handleclientsblockedonkey, we just need to make sure we don't enter that function recursively.",0,0,0,0.9801064729690552,0.9694190621376038,0.9847815036773682,0.0,accept,unanimous_agreement
985236406,11012,"[code block] i was wondering who's ""you""?",0,0,0,0.9479160904884338,0.9723615646362304,0.9898167848587036,0.0,accept,unanimous_agreement
985236975,11012,isn't that a second lookup? why can't we use `de`?,0,0,0,0.9620985984802246,0.9860862493515016,0.9917614459991456,0.0,accept,unanimous_agreement
985238113,11012,"let's decide if we add a space between function arguments or not. redis has some areas with it ans some without. i personally prefer with, but in any case let's not have both types in this function.",0,0,0,0.9843053221702576,0.9757499098777772,0.9896562099456788,0.0,accept,unanimous_agreement
985238760,11012,"i don't think i understand this one. there are cases of commands blocked on multiple keys, but they all get released as soon as one key is signaled. why do we have a check on blocked type here? p.s. please avoid line comments.",0,0,0,0.9269720911979676,0.5993194580078125,0.5654946565628052,0.0,accept,unanimous_agreement
985240545,11012,"cool. so all of these got dropped: * target, bblockpos, xread_* and are now retrieved from argv again. any disadvantage in that?",1,0,1,0.9531722664833068,0.5798712372779846,0.9054340124130248,1.0,accept,majority_agreement
985240761,11012,"why do we need a separate header for this? i see all the forward declarations of functions remained in server.h i'd argue that this move just creates a bigger diff that's harder to review, destructs the blame long with no reason.",0,0,0,0.9049851894378662,0.607627272605896,0.889733612537384,0.0,accept,unanimous_agreement
985241581,11012,"let's rename this to ""init"" instead of ""reset"" it is only used on creation, and it looks as if it leaks the old dict.",0,0,0,0.9866347908973694,0.9795849323272704,0.9947736859321594,0.0,accept,unanimous_agreement
985242146,11012,not sure i'm in favor of relocating this function (specifically without changing it). note is is modified in #11310,0,0,0,0.9714473485946656,0.9796486496925354,0.781571090221405,0.0,accept,unanimous_agreement
985243184,11012,"this comment is misplaced now, belongs in a loop. maybe no longer needed by the new design. but maybe we should bother to write a test case for this scenario?",0,0,0,0.8618607521057129,0.961536705493927,0.98308265209198,0.0,accept,unanimous_agreement
985245129,11012,i think it could be a good idea to also do notouch and noexpire. the key will be touched when we run the command on it. and i think i'd rather not do lazy expiry from this code path.,0,0,0,0.9354769587516784,0.967151939868927,0.9430241584777832,0.0,accept,unanimous_agreement
985245623,11012,"we won't need that if we use noexpire. i think it's safer. if we do drop that, i suppose we can drop the lines that backup and restore core_propagates. fyi.",0,0,0,0.7587846517562866,0.8473225831985474,0.8853282928466797,0.0,accept,unanimous_agreement
985248246,11012,"i think i'd rather do that just before deciding to block (calling blockforkeys), and not in the loop that processes arguments (we don't yet know what the command is gonna do). both in terms of efficiency (generating that string is time consuming), and also due to possible sideeffects. p.s. i think we have to use `rewriteclientcommandargument`",0,0,0,0.9741476774215698,0.9854881167411804,0.9790881276130676,0.0,accept,unanimous_agreement
985250141,11012,"did we change an error code in any of these? i.e. did the error code in all 6 cases modified in this file remain as it was (either `nogroup` or `wrongtype`)? i think that if we did change the error code, we must find a way to fix it. but even if it's just the text, maybe it could be a little bit confusing. i.e. before, it was clear that the error was from the unblocking process... on the other hand, the command could have just as well arrive from the original command (depending on the order of execution). wdyt?",0,0,0,0.9423255920410156,0.956602931022644,0.9568699598312378,0.0,accept,unanimous_agreement
985254292,11012,this is somewhat problematic. let me explain why. currently we do not process command unless it was realy unblocked by the currently executed command. when we try to unblock clients on the ready key we first match the blocked clients blocking type to the type of the key `` if ((o != null && (receiver->bstate.btype == getblockedtypebytype(o->type))) `` so in case a client is blocked on mylist key for example it should not be reprocessed in case some other client will do ``zadd mylist 1 1`` i guess we can think of improvement here which will also require us to maintain the blocking timeout differently.,0,-1,0,0.8399016261100769,0.8648947477340698,0.6083868145942688,0.0,accept,majority_agreement
985254368,11012,not funny :(,-1,-1,-1,0.9904609322547911,0.9939716458320618,0.9961537718772888,-1.0,accept,unanimous_agreement
985254982,11012,i am not sure i understand. removing the call here is basically a breaking change. we currently depend on the logic which execute a blocked command as soon as the key is ready...,-1,-1,-1,0.6480297446250916,0.7854023575782776,0.7385823726654053,-1.0,accept,unanimous_agreement
985255487,11012,this is more of a preparation for future use cases (we might want to block on several keys until they are all available) it is not 100% needed at this point but i found it harmless to support. sure will fix that,0,0,0,0.8819234371185303,0.9216054677963256,0.923052191734314,0.0,accept,unanimous_agreement
985255855,11012,currently non - the only thing is the argv change in order to support xread,0,0,0,0.9888752698898317,0.9817533493041992,0.9911194443702698,0.0,accept,unanimous_agreement
985256071,11012,we thought this way the code will be more modular. in a perfect universe you might think that redis sub parts are better moduled rather than declared in a giant header file.,0,0,0,0.9401119947433472,0.9714850187301636,0.9869346618652344,0.0,accept,unanimous_agreement
985260358,11012,not changed yet :) - we probably have a pr race here. i think we will have to make sure to merge these 2 correctly.,1,1,1,0.9705803990364076,0.9944514632225036,0.9938659071922302,1.0,accept,unanimous_agreement
985264889,11012,"note to self: fix this ""ugly"" xreadgroup part to consider rename of the command",-1,0,-1,0.5875851511955261,0.9114591479301452,0.7085128426551819,-1.0,accept,majority_agreement
985283302,11012,i think the error code was changed in case of streamgroup blocking operation which was unblocked due to stream deletion (we used to return -unblocked) i can try and fix that (maybe by looking at the unblocked flag in the stream process command) in order to prevent this from being breaking change.,0,0,0,0.9869825839996338,0.9923658967018129,0.9895105361938475,0.0,accept,unanimous_agreement
985410156,11012,although what you suggest make sense it will probably break some tests which are dependent on the replication backlog,0,0,0,0.9754628539085388,0.9001933336257935,0.9845538139343262,0.0,accept,unanimous_agreement
985417349,11012,i think it is confusing. let's add that when it'll be needed (and tested),-1,-1,-1,0.961012840270996,0.7414612174034119,0.7357589602470398,-1.0,accept,unanimous_agreement
985418339,11012,"in some subsystems i agree. in this one i feel it isn't needed, and just makes the diff harder to review.",0,0,0,0.9219926595687866,0.923023760318756,0.9064355492591858,0.0,accept,unanimous_agreement
985429517,11012,"right.. need to decide if to merge the smaller one and then update the bigger one, or let the smaller one wait (longer). anyway, i think this function suites db.c as well, so i'd rather not move it.",0,0,0,0.9735644459724426,0.967136025428772,0.9787424802780152,0.0,accept,unanimous_agreement
985431841,11012,"ohh, that propagation is not just because of the expire, but also because of what the unblocked command does? but aren't we going through `call` again? (which handles it already) please run a quick test to be sure, and consider updating the comment.",0,0,0,0.9801202416419984,0.9909347891807556,0.9863947629928588,0.0,accept,unanimous_agreement
985441802,11012,"yes, i better fix the comment as well if indeed this should stay you can check (for example) the test ``multi + lpush + expire + debug sleep on blocked client, key already expired`` it verify the del was received on the replication stream when we turn off the active expire",0,0,0,0.9839844107627868,0.9839648008346558,0.9944498538970948,0.0,accept,unanimous_agreement
985445984,11012,"i think that your suggestion is correct, i only think that some tests will require fix or i missed some cases where this is still needed... what do you think?",0,0,0,0.9634631872177124,0.9099363088607788,0.5184147953987122,0.0,accept,unanimous_agreement
986421185,11012,"/ / - basically i can align the errors of a deleted/change type stream (either by multi/exec, flushall, swapdb or stream delete) currently the implementation is to issue `` unblocked the stream key no longer exists `` in the following cases: 1. the stream key has been deleted (ie. calling del) 2. the stream and group existed but the key type was changed by overriding it (ie. with set command) 3. the key not longer exists after we swapdb with a db which does not contains this key 4. after swapdb when the new db has this key but with different type. now i would only like to ask at this point what do you find a better option: 1. we align to the current behavior (always error with -unblocked) while this makes sense that a different error is used (otherwise why this command blocked and not exit with error in first place) this will prevent the user from understanding exactly what happened to the stream key... was it overridden with different type or was it deleted...) - i can keep the error type and use different error massages in this case, but i wonder if applications will match error massages. one thing to note is that it is basically non-deterministic error reporting since (for example) a blocking command might have been racing with a key deletion/override 2. we can keep my current implementation that will not issue -unblocked but will use the same error type as today which will be more useful for a user to distinguish the 2 cases, but is less ""ideal"" in terms of the rational to ""why did this blocked on the first case"" wanted to catch your thoughts on that.",0,0,0,0.9845647811889648,0.9905960559844972,0.9839090704917908,0.0,accept,unanimous_agreement
986809251,11012,"i think we can use dictaddraw and later conditionally update the dictentry, instead of doing double lookup (find and add)",0,0,0,0.9871949553489684,0.9871772527694702,0.9880419969558716,0.0,accept,unanimous_agreement
987597632,11012,"i can't find any reference to noexpire, but yes, the `propagatependingcommands` is here to handle lazy-expiry only (all other replication handling happens in `aftercommand`)",0,0,0,0.9857807755470276,0.9931380152702332,0.9929561614990234,0.0,accept,unanimous_agreement
987664102,11012,"sorry for the xreadgroup special case, it was a bad idea anyway, it seems like we're going in the direction of trying to unblock clients even if the key doesn't exist anymore (see [a link] perhaps we want to keep this info inside the `bstate`? i.e. that we want to try to unlock if the key doesn't exist anymore (will be true for modules and xreadgroup) maybe we can even extend this idea and allow module to explicitly state if they want to be unblocked when the key doesn't exist? we can add a special ctx flag that the caller has to set before calling `rm_blockclientonkeys` all that i mentioned above is an optimization, trying to aoid redundant calls to `unblockclientonkey`/`moduleunblockclientonkey`",-1,-1,-1,0.9859164357185364,0.989205241203308,0.991828441619873,-1.0,accept,unanimous_agreement
987669485,11012,then we can replace [code block] with [code block],0,0,0,0.9871324300765992,0.9921668767929076,0.9952829480171204,0.0,accept,unanimous_agreement
987674258,11012,can you please reinstate these moved functions to the same location they were (perhaps at the price of a forward declaration)? it's hard to review,0,0,0,0.969135284423828,0.9567008018493652,0.98872572183609,0.0,accept,unanimous_agreement
987684586,11012,"i prefer (2) this idea of this pr is to re-process blocked clients, which means it can fail in exactly the same way as the non-blocking variant. when a user executes a blocking command it has to expect and handle errors that may arise in case the command didn't block in the first place, so i don't see this as a breaking change",0,0,0,0.8718039393424988,0.9751015901565552,0.964055359363556,0.0,accept,unanimous_agreement
987687340,11012,thoughts?,0,0,0,0.9232996106147766,0.9257810711860656,0.9498485326766968,0.0,accept,unanimous_agreement
987913122,11012,"so do you see any problem with adding noexpire and fox the tests? p.s. the noexpire flag is new, didn't exist when these tests were written",0,0,0,0.988917589187622,0.9887675642967224,0.9935491681098938,0.0,accept,unanimous_agreement
987930569,11012,"i agree. seems better that the command that initiated the blocking will tell us what's the trigger for unblocking, rather than have the blocking framework full of special code to be familiar with the different commands..",0,0,0,0.873409628868103,0.60540771484375,0.93794584274292,0.0,accept,unanimous_agreement
987950390,11012,"sure, we can do that (just out of curiosity, is it just to save these 2 code lines the call `propagatependingcommands`?)",0,0,0,0.9780554175376892,0.991610586643219,0.990802764892578,0.0,accept,unanimous_agreement
987951754,11012,"not that it's not a good reason, the less `propagatependingcommands` in the code, the better",0,0,0,0.6432380080223083,0.8111506104469299,0.9624741673469543,0.0,accept,unanimous_agreement
988058813,11012,"yes, trying to eliminate side effects of things that are done outside command execution (like testing for non local cluster keys in processcommand)",0,0,0,0.982039749622345,0.988042950630188,0.9890426993370056,0.0,accept,unanimous_agreement
988106691,11012,"i also favor the 2nd option as it is more informative, and am similarly of the opinion that error type changes do not fall into the breaking catergory.",0,0,0,0.9520918726921082,0.8828532695770264,0.92190420627594,0.0,accept,unanimous_agreement
988616154,11012,"although part of me wants to resist interface changes due to refactoring, i tend to agree that we should take the second option, for the same reason described about (race). i hope we're not missing anything, and some odd reason why a user should distinguish between these two cases (being blocked and released, or not blocked in the first place). please make sure this is clearly described in the top comment.",0,0,0,0.9113535284996032,0.9690728783607484,0.8673345446586609,0.0,accept,unanimous_agreement
993585364,11012,i reverted back the blocked.h file since i noticed there is a consensus around that,0,0,0,0.9742639064788818,0.9921669960021972,0.98922860622406,0.0,accept,unanimous_agreement
993585817,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
993588401,11012,"i made the change. i also changed the following tests in list.tcl: ""swapdb wants to wake blocked client, but the key already expired"" && ""multi + lpush + expire + debug sleep on blocked client, key already expired"" to be more aligned to the new logic. there might still be other tests that might fail (i believe a daily run will be needed before we merge this)",0,0,0,0.9802210330963136,0.992067575454712,0.9874396324157716,0.0,accept,unanimous_agreement
993589997,11012,"- made the change (even though i hate adding more parameters to the api blockforkeys :) ) i think in the future we might want to keep this per key and it might be the ""return of the bki"" but for now this is simple.",1,1,1,0.905789315700531,0.9758020043373108,0.9859771728515624,1.0,accept,unanimous_agreement
993590207,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
993590752,11012,i made some effort to make the diff cleaner. tell me what you think,0,0,0,0.957677125930786,0.8173052668571472,0.9142650961875916,0.0,accept,unanimous_agreement
993599676,11012,seems like my work in [a link] (signal deleted keys only if needed) and the work here (process the client on a deleted key only if needed) complete each other :) q: why didn't you check `o == null`?,1,1,1,0.9504095911979676,0.9890154004096984,0.9840173125267028,1.0,accept,unanimous_agreement
993607766,11012,i extended the previous comment about that in the top comment.,0,0,0,0.9849051833152772,0.9911017417907716,0.9830331206321716,0.0,accept,unanimous_agreement
993626875,11012,"yes will be ""fun"" to merge these well, since this call will be triggered by both cases (type change and removed key) i need to attend both",0,0,1,0.5651305913925171,0.7759374976158142,0.9138356447219848,0.0,accept,majority_agreement
993736326,11012,ok good point (is there a test that hits that? iirc i wrote one),1,1,1,0.9202494025230408,0.7201335430145264,0.9447188377380372,1.0,accept,unanimous_agreement
994356451,11012,too much indentation?,-1,0,0,0.6833146214485168,0.5128850340843201,0.8044474720954895,0.0,accept,majority_agreement
994361865,11012,"to make things more explicit, let's add some commands after swapdb and watch their propagation here. i.e. we can do `set somekey someval` and then `get k` so we can see lazy expiry happens after swapdb. let's do the same in the test below. and let's mention this change (notouch+noexpire) in the top comment (to make it clear why the tests had to be changed). mention that one of the reasons is to reduce the changes to the key space that are done outside of normal command execution (same as getnodebyquery)",0,0,0,0.9772725105285645,0.9913827776908876,0.991174340248108,0.0,accept,unanimous_agreement
994365397,11012,"ohh, i see your next commit relies on`set-active-expire`. i'd rather my approach (one block of assert_replication_stream) also, the one with active expire seems like it has a race condition.",0,0,0,0.9658750295639038,0.9504714012145996,0.9788091778755188,0.0,accept,unanimous_agreement
994699641,11012,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
994700284,11012,check my last commit (new one) is that what you meant?,0,0,0,0.976471185684204,0.9863220453262328,0.994175910949707,0.0,accept,unanimous_agreement
994842985,11012,"i suggested to set another key before the exists, so that we can distinguish that expiration from a case in which it was expired by swapdb.",0,0,0,0.9887474775314332,0.9929260015487672,0.9924089908599854,0.0,accept,unanimous_agreement
995125642,11012,i'm not sure this actually changes the behavior. instead of recursing to do the unblocking we would loop over them in a while loop. it's like a tail recursion optimization. i think we generally want to avoid recursion inside redis commands.,0,0,0,0.8892771005630493,0.8328042030334473,0.9161587357521056,0.0,accept,unanimous_agreement
995126516,11012,"i will say i never really liked this optimization to begin with, since it's very broad and assumes there is only one type of operations being done on the dataset. i'm ok forgoing it, but maybe we can make a note to find more optimizations. i don't think this part of the codebase has been optimized much for performance.",0,0,0,0.5191400647163391,0.5209630131721497,0.6975357532501221,0.0,accept,unanimous_agreement
995291611,11012,"the way i see it is that the current behavior require us to make sure no other client will be able to successfully run a blocking command before an already blocked client has processed it, so this recursion (which is not new) was left as it is. i also thought of this while writing the refactor, and imo the solution is that a client will also check on each key of a blocking command, if that key has pending blocked clients (in which case it should also be blocked). i agree that this recursion is not preferred, but i would like to leave some optimizations to the next phase, as this is becoming hard to approve since the code change is large.",0,0,0,0.9294537305831908,0.9694976210594176,0.9607177376747132,0.0,accept,unanimous_agreement
995295882,11012,"i agree that a better infrastructure would not need to be aware of a specific blocking-on-keys type, but rather a general ""blocked-on-keys"", i also agree we would like to have more blocking types in the future. however this will require much deeper changes since the blocking timeout should also be refactored, in case we will allow reprocessing a command in order to evaluate if it is still blocked. not a huge change but it will probably complicate some cases.",0,0,0,0.8830196261405945,0.9782146215438844,0.9483346343040466,0.0,accept,unanimous_agreement
1004417603,11012,please check [a link],0,0,0,0.9811499118804932,0.98492693901062,0.99485445022583,0.0,accept,unanimous_agreement
1005271161,11012,don't we also need to make sure the flag is set to 0 otherwise? or is the one in unblock and at startup enough?,0,0,0,0.9863941073417664,0.9943002462387084,0.9936568140983582,0.0,accept,unanimous_agreement
1005276302,11012,"i notice this `return` skips restoring the `server.current_client`, so that was a bug in an old version of this pr. but i see in 7.0, we had a `continue` with a similar problem. can one of you look into it?",0,0,0,0.9851234555244446,0.973983108997345,0.9922949075698853,0.0,accept,unanimous_agreement
1005384630,11012,"i'm not sure i like the introduction of `dictincrunsignedintegerval`. i think the fact dict provides a get and set convince macros is enough, and you can do get, incr, and set yourself. this becomes even clearer when this code increments by -1, and even more so when you end up doing another get afterwards (which wasn't necessary if the dict only provided only get and set. if you do keep it, then maybe the macro can return the new value, and you can drop that extra get, but i think i rather drop the incr.",-1,0,0,0.5789254903793335,0.9225674867630004,0.7429941892623901,0.0,accept,majority_agreement
1005387574,11012,"i think that this should go outside the loop (or just drop the stack variables, operate directly on the arguments, which will be made non-optional.",0,0,0,0.9856178164482116,0.977380096912384,0.982406735420227,0.0,accept,unanimous_agreement
1005389291,11012,"note that you used the signed version here, and the unsigned version in the other places.",0,0,0,0.9873195886611938,0.9885317087173462,0.9934675097465516,0.0,accept,unanimous_agreement
1005409066,11012,i think we better also do `$rd read` and match the response.,0,0,0,0.9873316884040833,0.9806504845619202,0.9863835573196412,0.0,accept,unanimous_agreement
1005412904,11012,"fyi, you can do `$rd deferred 0` and `$rd deferred 1` to change a connection between deferring more and normal mode. maybe the majority of this test will become simpler (calling it `r2` and using deferring mode just for the short period we do the brpop)",0,0,0,0.9820867776870728,0.9882055521011353,0.9911901950836182,0.0,accept,unanimous_agreement
1005455923,11012,basically it is enough as it is now. but i can also take it out of the loop to keep it safer,0,0,0,0.971379816532135,0.9859923720359802,0.985584557056427,0.0,accept,unanimous_agreement
1005459720,11012,thank you - indeed i already fixed it but did not commit yet.,1,1,1,0.9444276094436646,0.9255492091178894,0.9498026967048644,1.0,accept,unanimous_agreement
1005467611,11012,"imo the incr version keeps the code cleaner. if you have a strong opinion i should drop it i will (btw regarding the incr by -1, i can also add decr flavor, i just thought this would be too much)",0,0,0,0.8049637079238892,0.9660457372665404,0.9505727887153624,0.0,accept,unanimous_agreement
1005474030,11012,probably sleepless night result :(,-1,-1,-1,0.987215518951416,0.9903179407119752,0.9956828355789183,-1.0,accept,unanimous_agreement
1005493749,11012,i agree with oran,0,0,0,0.9527598023414612,0.9315974116325378,0.9788416028022766,0.0,accept,unanimous_agreement
1005736272,11012,let me try that,0,0,0,0.9781129956245422,0.96600079536438,0.9563815593719482,0.0,accept,unanimous_agreement
1005899803,11012,"i am not sure there is a bug now and in the old version. i think that in the old case when the code (before the change made in #11310) there was an assumption that no change to the current client, while now, after the change presented in we will still reset the server.current_client to be the same as was before the call to moduletryserveclientblockedonkey. so imo there is not bug here - but maybe i am missing something.",0,0,0,0.8688801527023315,0.9270498752593994,0.9381639361381532,0.0,accept,unanimous_agreement
1006615933,11012,i'm not following you... doesn't that continue in 7.0 mean that in some cases we'll not restore `server.current_client` to its previous value?,0,0,0,0.8196611404418945,0.8923661708831787,0.941506803035736,0.0,accept,unanimous_agreement
1006618310,11012,"i think it's odd that we have an ""in-pace"" increment but then we do a get operation on the result. personally i think that dict.h doesn't need to offer that mechanism, and the caller needs to handle it. but if you insist to keep it, at least make it return a value so that you don't need the extra getter. and also make sure you don't mix the signed and unsigned versions.",0,0,0,0.8444163203239441,0.7783287763595581,0.6841251850128174,0.0,accept,unanimous_agreement
1006673571,11012,i agree and i did that on the last commit. i think the code is cleaner this way,0,0,0,0.863466739654541,0.8575988411903381,0.8862170577049255,0.0,accept,unanimous_agreement
1006677916,11012,i did not really change any logic in this function. my original pr change was to add the: `` if (c->flags & client_pending_command) c->flags &= ~client_pending_command; `` the change of always calling aftercommand and reset server.current_client was part of [a link] and i think that new behavior is kept in this pr.,0,0,0,0.9752443432807922,0.984325647354126,0.9895673394203186,0.0,accept,unanimous_agreement
1006693431,11012,indentation,0,0,0,0.982236921787262,0.822169840335846,0.9911677837371826,0.0,accept,unanimous_agreement
1006708045,11012,"i'm not talking about this pr, i'm talking about the code in 7.0. that `continue` means we don't restore `server.current_client` [a link]",0,0,0,0.9230483770370485,0.9862878322601318,0.98588889837265,0.0,accept,unanimous_agreement
1007047595,11012,i think that we had it for a while so probably modules usually do not fail to process blocked clients (or they fail before replacing the current client) do you see that differently?,0,0,0,0.9734989404678344,0.9762770533561708,0.9888575077056884,0.0,accept,unanimous_agreement
1027266029,11012,fixed in [a link],0,0,0,0.98800128698349,0.9866787791252136,0.9950093030929564,0.0,accept,unanimous_agreement
1027841056,11012,let's mention the interface changes in the top comment.,0,0,0,0.9871565103530884,0.990412414073944,0.993889331817627,0.0,accept,unanimous_agreement
1027856280,11012,"let's mention this behavior change in the top comment, and the use of lookup_noexpire",0,0,0,0.9874395728111268,0.9917570948600768,0.994631290435791,0.0,accept,unanimous_agreement
1027897882,11012,"maybe we don't have to move this big block? it's was never accessed anywhere outside blocked.c even before, but there's a server struct variable holding this struct and it still has a comment referring to it.",0,0,0,0.9854414463043212,0.988150119781494,0.9792335629463196,0.0,accept,unanimous_agreement
1027932704,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1027933208,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1027935865,11012,i am afraid i do not understand. the bkinfo is gone (for now) do you mean the comment itself?,-1,-1,-1,0.9791872501373292,0.9461116194725036,0.9842296242713928,-1.0,accept,unanimous_agreement
1028010421,11012,"sorry, either i commented on the wrong block, or somehow gh quoted the wrong thing. i meant for the `readylist` struct and its comment.",-1,-1,-1,0.9861371517181396,0.9836609959602356,0.987902820110321,-1.0,accept,unanimous_agreement
1028019433,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1029469385,11012,"[code block] for consistency with other usages of ""total""",0,0,0,0.988810896873474,0.9937978386878968,0.9944508075714112,0.0,accept,unanimous_agreement
1030057552,11012,maybe also replace `on_nokey` with another term? maybe `on_del`? or `_removed`?,0,0,0,0.9861371517181396,0.994665026664734,0.993482768535614,0.0,accept,unanimous_agreement
1030117231,11012,should avoid `server.stat_numcommands++` too? [a link],0,0,0,0.9856663346290588,0.9944972395896912,0.9956690073013306,0.0,accept,unanimous_agreement
1030126333,11012,"now we only count the command reprocessed slowlog and latency, but lost the command ""processed"" time, the last `c->duration`, do we need add the last duration to the current duration?",0,0,0,0.9884309768676758,0.9914078116416932,0.9930744171142578,0.0,accept,unanimous_agreement
1030144253,11012,change to `unblock_on_key_changed` or `unblock_on_nokey_or_wrongtype`? since `xreadgroup` unblocked not only on key removed but also on key type changed.,0,0,0,0.9871826171875,0.9939858317375184,0.993232011795044,0.0,accept,unanimous_agreement
1030155212,11012,use `dictfind` directly here? then we can avoid add other flags in the future.,0,0,0,0.9862585067749025,0.99290269613266,0.9938732385635376,0.0,accept,unanimous_agreement
1030246212,11012,thats a valid point. i guess we can accumulate the time we processed the command until we reached the decision to block.,0,0,0,0.9807946085929872,0.9572214484214784,0.984605073928833,0.0,accept,unanimous_agreement
1030249920,11012,"i also don't like the `nokey`, but there's already a thread about it, let's discuss it there: [a link]",-1,-1,-1,0.9509466886520386,0.810387909412384,0.8773348927497864,-1.0,accept,unanimous_agreement
1030251723,11012,"soloestoy [a link] i'd argue that when a key is overwritten with another key / type, we can view it as ""removal"" (and re-insertion).",0,0,0,0.9809637069702148,0.9897487759590148,0.9906184077262878,0.0,accept,unanimous_agreement
1030256106,11012,i think lookupkeyreadwithflags also cover some checks (i.e expiry checking) but maybe it would have been a good idea to present a new type of enu(lookup_transparent) which we will always maintain to do nothing with the key like #define lookup_transparent (lookup_nonotify | lookup_nostats | lookup_notouch | lookup_noexpire),0,0,0,0.9812498688697816,0.9936532974243164,0.9887378215789796,0.0,accept,unanimous_agreement
1030257037,11012,"i don't think we should use dictfind. we do want to know if the key is logically there (e.g. we do want an expiration test, just not to delete the key if it is expired). it's essentially a lookup key with 0 side effects. maybe want to add a lookup_no_sideeffects (macro that includes all other flags) and use it here, this way other flags added in the future are less likely to be overlooked.",0,0,0,0.9796476364135742,0.9878957271575928,0.9866517782211304,0.0,accept,unanimous_agreement
1030260996,11012,i guess so :),1,1,0,0.9783194661140442,0.9884151220321656,0.9728638529777528,1.0,accept,majority_agreement
1030265536,11012,unblock on nokey can also happen in cases the key type was changed. so i just followed the same semantics presented in #11310 - i can take the advice from : total_blocking_keys_on_nokey_or_wrongtype (great simple name :)),0,0,1,0.8443371057510376,0.506927490234375,0.9872095584869384,0.0,accept,majority_agreement
1030267943,11012,i can agree on that one(unblock_on_nokey_or_wrongtype) but it would require aligning all the places which were presented as part of #11310 . since this is not a complete mistake (depends how you look at nokey) i suggest we avoid changing this as this is not customer facing.,0,0,0,0.9719558954238892,0.9875088334083556,0.9921521544456482,0.0,accept,unanimous_agreement
1030350947,11012,"then i guess we can stick with `nokey`, it's enough that it's documented what it means, and it's easy to grep for it (i.e. we define a short term, and document what it means). imo, just change `tot` to `total`",0,0,0,0.9742501974105836,0.9535748958587646,0.9790504574775696,0.0,accept,unanimous_agreement
1030354379,11012,"or add a new flag to make the unblocked client call `call()` directly, `processcommand()` contains too many checks",0,0,0,0.979280650615692,0.9844777584075928,0.9951977133750916,0.0,accept,unanimous_agreement
1030368695,11012,"not sure i understand the context. is this meant to be related to this discussion: [a link] isn't that discussion resolved? i don't know what was in the code when the comment was placed, but it looks to me as if there's no risk of recursion now.",0,0,0,0.8231267929077148,0.9146302342414856,0.7971062064170837,0.0,accept,unanimous_agreement
1030387130,11012,"i think that in case of pause we do want to call processcommandandresetclient. i guess we could handle the 2 cases differently, but it will return some of the things we would like to eliminate (such as updatestatsonunblock)",0,0,0,0.9842705130577089,0.9881315231323242,0.9878201484680176,0.0,accept,unanimous_agreement
1030392383,11012,"actually, the current implementation only incorrectly handles the latency histogram and slowlog. imo before this change the pre-attempt duration was calculated twice for blocking commands since both incremented the `c->lastcmd->microseconds` (am i right?) but i guess i should better align this in this pr.",0,0,0,0.9848552346229552,0.9103094339370728,0.9865092635154724,0.0,accept,unanimous_agreement
1030575850,11012,"until now i did not understand , but i think that indeed there is an issue here: lets say i have 3 clients (a,b,c) each blocked on lists (l1,l2,l3) respectively and in that order. now i have client h calling `multi; lpush l1 1; lpush l2 2 ; exec` so client h will also call handleclientsblockedonkeys which will take the current list of ready_keys aside and iterate over it. the first key it will go over is l1 for which the only blocked client in the list will be client 'a' which will be unblocked and will call processcommandandresetclient. but lets say client 'a' is doing a `blpoprpush l1 l3 0` which will signal l3 as ready? so it would have called handleclientsblockedonkeys (recursive call), which will signal l3 as ready and then it would process client c before processing client b, which was blocked first. i am not sure how big of a problem this is (it cannot happen in case l2 == l3) but this gives me motivation to follow suggestion",0,0,0,0.955075979232788,0.9596286416053772,0.9677494168281556,0.0,accept,unanimous_agreement
1030609549,11012,"ohh, now i see what i was missing, handleclientsblockedonkeys is not called only from beforesleep, but also from processcommand. i'm not sure it matters that it'll process client c before client b, but i do fear the recursion. maybe we can test some flag so that processcommand doesn't do that, and then the loop in handleclientsblockedonkeys will take care of the rest?",-1,-1,-1,0.9688109755516052,0.8862989544868469,0.9372097253799438,-1.0,accept,unanimous_agreement
1030711077,11012,actually i do think there is an issue with that: for example what if client 'c' was unblocked first and running `blmpop l2 l3` - so it would get precedence over client 'b' on popping from list l2... which is a bug imo.,-1,-1,0,0.5278378129005432,0.5110567212104797,0.9791497588157654,-1.0,accept,majority_agreement
1031358300,11012,"i don't think that's a bug.. or maybe i'm missing something. are you saying that because you know the order in which the commands arrived to redis? from the client's perspective they might have arrived in the order [a,c,b] and letting c pop something that was pushed by a as well as something that was pushed by whoever released a from blocking.",0,0,0,0.9279749989509584,0.8144957423210144,0.9394882321357728,0.0,accept,unanimous_agreement
1031362024,11012,"i agree that in case the 2 clients weere blocked together the user might not notic. but our documentation clearly states: [code block] and it can be that client 'c' was blocked way longer after client 'b' removing the recursion will help avoid that. but i am also looking to understand if i can somehow avoid the porcesscommand overhead and potential acl/oom calls (it does makes no sense that a client which already successfully issued some blocking command and now waiting long time would later fail on it once we modify the acl rules), although i agree application would probably have to write defensive code either way.",0,0,0,0.9245713353157043,0.9762784242630004,0.9722381830215454,0.0,accept,unanimous_agreement
1031383714,11012,"ok, you're right. it does violate that statement (and fairness). we can add a test for it... so in theory, we have the server.ready_keys list that should keep the order, but because handleclientsblockedonkeys messes with this list (replaces it), and because of the recursion, we can run into that situation, right? i do think we wanna eliminate the recursion anyway. so maybe setting a flag so that processcommand doesn't call handleclientsblockedonkeys in that flow?",0,0,0,0.906562328338623,0.9639113545417786,0.9510599970817566,0.0,accept,unanimous_agreement
1031456642,11012,yes - i will eliminate the recursion,0,0,0,0.9823527932167052,0.9669755697250366,0.9938562512397766,0.0,accept,unanimous_agreement
1034515381,11012,i have introduced a flag to prevent the recursion. i could use the new client_reprocessing_command flag. but i did not want to hard link the logic of reprocessing with the fact that we are doing handleclientsblockedonkeys,0,0,0,0.9571035504341124,0.985775113105774,0.9927563071250916,0.0,accept,unanimous_agreement
1034540568,11012,- i have made some fixes to statistics. i personally do not like to log the blocking command duration to the command stats before it was unblocked (with the duration) but i did not want to change the existing behavior. take a look and tell me what you think.,-1,-1,0,0.7250003814697266,0.9061078429222108,0.5985570549964905,-1.0,accept,majority_agreement
1034540885,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1034567105,11012,"there's a chance the client was freed, and `c` is an invalid pointer. see evictclients. the way to test it is to detect that `server.current_client` was nullfied.",0,0,0,0.9877573251724244,0.9919061660766602,0.9909880757331848,0.0,accept,unanimous_agreement
1034568013,11012,"if we don't need this elsewhere, maybe use a static variable instead of server globals member? you won't have to touch 2 other files for that.",0,0,0,0.9876623153686525,0.9918774366378784,0.9900227189064026,0.0,accept,unanimous_agreement
1034574461,11012,"maybe a nicer way to do that is to make sure to zero `duration` in after calling `lookupcommand` (in `processcommand` and elsewhere) and also, make sure to skip that whole block (the `lookupcommand` and zeroing of `duration`) on blocked clients (true also for blocked_postpone, it's just wasteful). if we do that, we can always use `+=` in `call()`.",0,0,0,0.9694764018058776,0.9946478009223938,0.9768466353416444,0.0,accept,unanimous_agreement
1034581051,11012,"why did you move the latency monitor sample into the slowlog `if(!blocked)`? i think latency monitor can always sample.. although it's unlikely that a blocked command took a long time in it's initial processing, but if it did there's no reason to hide it.",0,0,0,0.9774639010429382,0.9814250469207764,0.9871467351913452,0.0,accept,unanimous_agreement
1034585409,11012,"why did you change that? shouldn't it be the other way around? i.e. the old code avoids logging the command when it got blocked, and the new code avoids logging the command when it got released from the block. the logical time where it got executed (and performed its action) is when it got released.",0,0,0,0.975536286830902,0.9895506501197816,0.9910234212875366,0.0,accept,unanimous_agreement
1034587614,11012,what's the difference? (between client_unblocked and client_reprocessing_command) aren't they both set at the same time (from the perspective of `call()`)?,0,0,0,0.9787075519561768,0.9941253662109376,0.9918082356452942,0.0,accept,unanimous_agreement
1034593160,11012,maybe we can move this outside and unify updatestatsonunblock into here? could also maybe make the while `c->duration` thing a bit nicer (all in one place),0,0,0,0.9466851353645324,0.9935721158981324,0.9866413474082948,0.0,accept,unanimous_agreement
1034603775,11012,let's make the test quicker [code block],0,0,0,0.98477041721344,0.9866772890090942,0.9943934679031372,0.0,accept,unanimous_agreement
1034730410,11012,"client_unblocked will also be set for posponed client which will not reprocess the command. personally i so not understand why we even want to report commands which did not complete (eg timedout) we could maybe add a function to accumulate them to the statistics when a client is timedout (like the ""updatestatsonunblock"" we can have an updatestatsontimeout. but i wanted to keep the current behavior similar to what it is today.",-1,0,0,0.5612818002700806,0.9593175053596495,0.9686198234558104,0.0,accept,majority_agreement
1034732082,11012,that is one option - personally i think that a better is to completely eliminate updatestatsonunblock. imo a blocked client shuld not update stats and mostly act as if the command was never issued (aside for the monitor which is probably needed),0,0,0,0.965590476989746,0.9774761199951172,0.9664596915245056,0.0,accept,unanimous_agreement
1034784451,11012,"afaik the old code (before this pr) would log to monitors as soon as the command was executed - even if it was blocked. this makes sense as we would like to report the first time we are handling the command. unlike the slowlog which imo had a ""theoretical"" bug in which it might have reported the command twice",0,0,0,0.9851319193840028,0.9774052500724792,0.9801045656204224,0.0,accept,unanimous_agreement
1034787149,11012,haha. i originally did that and thought it would be better to keep aligned with the existing way we handle such cases. can you say then why do we usually keep things in server? (i thought it was some kind of way to potentially have multiple servers...),1,1,1,0.9276829957962036,0.9622851014137268,0.9633803963661194,1.0,accept,unanimous_agreement
1034793667,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1034800090,11012,"why should the latency monitor, monitor an incomplete command? i have no problem reverting it, but it just does not makes sense to me.",-1,0,-1,0.4982543289661407,0.706065833568573,0.6911917924880981,-1.0,accept,majority_agreement
1034805440,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1034987183,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1034987260,11012,i have no clue... there are also a ton of places that use plain global variables in the top of c files (e.g. acl.c). but in this case it can also be a static var in a function. i guess the question is if we think it'll be useful for others or not.,0,0,0,0.9558570384979248,0.5244742631912231,0.8374398946762085,0.0,accept,unanimous_agreement
1034988923,11012,"latency monitor doesn't monitor commands, it monitors the main thread latency doing various tasks. e.g. it measures how long it takes to `fork()`, or how long the eviction loop takes.",0,0,0,0.9800840616226196,0.9796532392501832,0.9850785732269288,0.0,accept,unanimous_agreement
1034992651,11012,"i think it was wrong, we should log it when it was logically executed. wdyt?",0,0,0,0.9344961047172546,0.901594579219818,0.7314704656600952,0.0,accept,unanimous_agreement
1035005270,11012,"postponed clients **do** re-process the command, it'll get to `processpendingcommandandinputbuffer` and call `processcommand` again for the postponed command. maybe for perspective, think of module blocked clients.. they can do some work on the original execution, then do some incremental work from time to time, and then another bulk of code when being unblocked. the same could be argued to apply for stream blocked commands and others. i do think we wanna increment the fact the command was called (as soon as it got to `call()`), and measure all the fragments of time it took.",0,0,0,0.9643964767456056,0.9807615876197816,0.9730046987533568,0.0,accept,unanimous_agreement
1035006842,11012,nothing would make me happier than to avoid register it when blocked :),1,1,0,0.6914786100387573,0.9006155729293823,0.6223734617233276,1.0,accept,majority_agreement
1035020029,11012,"correct me if i am wrong. postpone client would start processing the command but will quit one it gets into the check of: blockpostponeclient - which is before it got into the call(). so it would not have been recorded anywhere. if i used the client_unblocked here instead of client_reprocessing_command the postpone client would not account once it will reprocess the command, which is why i added this flag (otherwise i would not need it ) imo i would prefer what i suggested earlier which is to not account anything (including maybe even the monitor) for blocked commands and only account them once the command is executed.",0,0,0,0.8904510140419006,0.9138237833976746,0.9012411236763,0.0,accept,unanimous_agreement
1035034300,11012,"so according to what you say a blocked command should be recorded twice? so for a ""fast-command"" which took longer we should get 2 events?",0,0,0,0.983565628528595,0.9912469983100892,0.9924615025520324,0.0,accept,unanimous_agreement
1035036397,11012,"i guess there is some kind of rational in this, since the monitor will let us understand when the issue happened. it is just strange that we can potentially see more occurrences on the latency monitor then the actual number of commands we processed. but i can say the same regarding the slowlog...",0,0,-1,0.5481755137443542,0.8916096687316895,0.8906009793281555,0.0,accept,majority_agreement
1035146853,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1035148561,11012,"done - please check if that was your intention. btw - i can do the same for acl check, but you mentioned that you prefer it this way.",0,0,0,0.8339598774909973,0.9325987100601196,0.9711615443229676,0.0,accept,unanimous_agreement
1035148781,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1035812103,11012,"ohh, ok. postponed commands are ""reprocessed"" from the perspective of `processcommand()`, but not from the perspective of `call()`. so you're right, we must not skip them. i think that when i gave that comment, i looked at a diff from a previous commit (of this pr) and i wondered why you changed the flag, but now i see that entire check is new (added in this pr). i think i do prefer to keep counting commands that got to `call` even if eventually timed out, but i suppose i'm open to compromise on that if it conflicts with many things and makes things much simpler.",0,0,0,0.8310033082962036,0.8620365858078003,0.9542351961135864,0.0,accept,unanimous_agreement
1035815118,11012,"even if we keep the current behavior, won't it be cleaner to embed `updatestatsonunblock` in `call()`? ohh, actually it may be an issue with modules and client unblock..",0,0,0,0.9410316348075868,0.9253164529800416,0.9880498051643372,0.0,accept,unanimous_agreement
1035820149,11012,maybe we're missing resetting it in places that call `call()` not via `processcommand()`. i.e. there are a few other places that do `lookupcommand()`. or maybe the better way is to reset it in `createclient` and `freeclientargv()` (where we reset `c->cmd`),0,0,0,0.9838279485702516,0.994572103023529,0.9856488704681396,0.0,accept,unanimous_agreement
1035822033,11012,let's apply that on postponed commands too.,0,0,0,0.9885166883468628,0.9920050501823424,0.9932987093925476,0.0,accept,unanimous_agreement
1035848839,11012,again - this will not work since postpone commands did not reach that part yet.,0,0,0,0.8725447058677673,0.969438910484314,0.9582459926605223,0.0,accept,unanimous_agreement
1035875495,11012,yeh - i will move it to resetclient,0,0,0,0.9696686267852784,0.9465697407722472,0.9896644949913024,0.0,accept,unanimous_agreement
1035912527,11012,this is an early stage of `processcommand`. postponed commands did reach it before being postponed,0,0,0,0.9876060485839844,0.9921215772628784,0.99369615316391,0.0,accept,unanimous_agreement
1036159419,11012,"as you pointed out, there are two blocks doing postpone. the one i was referring to, is done after looking up the command and knowing it's flags. the postpone just above this block is one that doesn't depend on the command flags, and is done asap (without making any effort to respond or reject the command, not even an arity check). maybe we can move that postpone to after the lookup, or maybe we should add some flag to be able to distinguish between them.",0,0,0,0.9791932106018066,0.9913043975830078,0.9882276654243468,0.0,accept,unanimous_agreement
1040080595,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1040083505,11012,"we had some offline discussions about that. as much as i tried, merging the logic of blocked commands and postpone clients is harder than i thought. i think the main difference is that postpone clients are not really calling the command, but rather being postpone ""on the way"" to call the command as apposed to other blocked commands which decide to be blocked somewhere during the command execution. i do not think this is the last word on the subject and i plan to do farther refactor (modules etc...) maybe i can document our thoughts on the top commit and we leave it to the next steps in order to push this long going pr?",0,0,0,0.6519737839698792,0.7766262292861938,0.90874981880188,0.0,accept,unanimous_agreement
1040083921,11012,i think the last refactor answered that,0,0,0,0.9854322075843812,0.9546346664428712,0.9865331649780272,0.0,accept,unanimous_agreement
1040084778,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1040627227,11012,"good idea to put it here, however, i think there's a problem with scripts. luaredisgenericcommand only calls freeclientargv. maybe we should change luaredisgenericcommand to call resetclient, which also does a few excess steps, or maybe this reset of c->duration belongs in freeclientargv? the function name doesn't seem like a match, but it's actions (also resetting c->cmd) could be an ok fit. i'm leaning towards freeclientargv. either way, let's try to add a test that can detect this problem.",0,0,1,0.7058517932891846,0.8608241081237793,0.7889500260353088,0.0,accept,majority_agreement
1041741899,11012,i agree about logging the command when it was logically executed.,0,0,0,0.979070782661438,0.9626720547676086,0.9886576533317566,0.0,accept,unanimous_agreement
1041995391,11012,"i notice there's a race condition in these tests (common for many tests in this file). they issue a command to be blocked, but don't call wait_for_blocked_client, so we can't really know if the xreadgroup got to redis before or after the set. in the past, that race would have resulted in the test failing due to the difference in the error code, but now the race will still let the test pass. i'd like to add wait_for_blocked_client to all the tests in this file in which it's missing. not sure if as part of this pr, or another one in unstable (so that we know this pr doesn't silently breaks or fixes some existing issue)?",0,0,0,0.9684730768203736,0.8404668569564819,0.9610992670059204,0.0,accept,unanimous_agreement
1042116300,11012,yes you are right. i think it is reasonable making this fix. i will make the effort,0,1,1,0.8144381642341614,0.592581570148468,0.6092899441719055,1.0,accept,majority_agreement
1043043262,11012,"i understand your point regarding lua scripts. however i do not think placing it in freeclientargv is the correct solution. the reason is that imo it is logically wrong to assume this is were we finish/start processing new command. for example i think blocking zpop, when reprocessed might call rewriteclientcommandvector which will free the argv. so in this case in my implementation we will loose the duration of the first processing try. imo since lua is already doing a ""proprietary"" handling of preparing the client for the next command , probably since it cannot really call resetclient as it will also reset some other things which might be needed during the lua execution (asking flag, pointer to cur_script etc..) , it should explicitly zero the duration.",0,0,0,0.9394556283950806,0.9581449627876282,0.9397695064544678,0.0,accept,unanimous_agreement
1043311598,11012,"good point, but then, maybe we should split the role of resetclient into two, or pass some boolean argument? i.d rather put the logic in one place and have script_lua.c call it than clone individual lines (increases the chance something else will be overlooked one day)",0,0,0,0.6551876068115234,0.9331316351890564,0.735637366771698,0.0,accept,unanimous_agreement
1045205607,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1045205647,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1045207696,11012,", . after your comment about the monitor command, i **did** apply the following logic: when a client is blocked during processing of some command it will **not** update any statistic and will not report to the monitor. that will help keep all blocking flows with about the same logic. this also implies that when we have many clients blocked on blocking command we will have no way to get that from the command stats (user can still get the information from the client list for example). i want to have this first approved by you and then i will update the top comment.",0,0,0,0.969090223312378,0.9539179801940918,0.94161194562912,0.0,accept,unanimous_agreement
1045207719,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1045207940,11012,i think we can close this sub thread,0,0,0,0.9781055450439452,0.9136893153190612,0.9812659621238708,0.0,accept,unanimous_agreement
1045238893,11012,would probably be nicer to unify these two calls into one and use a ternary operator or whatever on the duration arg,0,0,0,0.9628753662109376,0.9930330514907836,0.9860536456108092,0.0,accept,unanimous_agreement
1045241062,11012,"we're no longer honoring the original caller's call flags (`cmd_call_stats` and `cmd_call_slowlog`). maybe we no longer need them? as far as i can tell, the only place were they are used (actually absent) is aof loading, and there are some hacks to ""respect"" that from scripts and multi (by looking at `server.loading` and `client_id_aof`) i think that we should either kill these two flags and add explicit conditions for aof, or cache them as the original call intent in the client struct. btw, aof has an assertion that commands it run never get blocked, so there's no bug here, just confusing code. let's e careful here and make the right choice, it'll soon get more complicated with #11568 and maybe one day with #9925 i'm leaning towards killing these flags, wdyt? fyi.",0,0,0,0.9623939990997314,0.9903475046157836,0.9885671138763428,0.0,accept,unanimous_agreement
1045241449,11012,"it seemed a bit confusing to me at first, consider adding a comment.. i.e. we incrementally accumulate any re-try of the call into c->duration, and we accumulate that into the command stats only when the command finishes. is that right?",0,-1,0,0.5925170183181763,0.9502501487731934,0.7655290365219116,0.0,accept,majority_agreement
1045245877,11012,"moving that block means that when a module asked not to process any clients, we'll still return bad command and arity errors. iirc the reason you moved it was because the check for `client_reprocessing_command` meant that `c->cmd` was null. maybe instead of moving it, we can change the condition to check `c->cmd` rather than `client_reprocessing_command`? then maybe we can eliminate that flag? would no longer be in use. in any case, i don't like the way it's currently set (setting a client struct flag as if we pass an additional argument to processcommand). instead, if we keep that flag, i think it should be an indication that we did call `cmd->proc` and we now gonna call it again (distinguish between a command that's really re-executed, and one that got postponed by processcommand and was never actually called). i'm not sure what we'll do with that distinction, but it seems like something useful.",-1,-1,-1,0.9516621828079224,0.5425503253936768,0.9581292271614076,-1.0,accept,unanimous_agreement
1045265563,11012,that is right. i will add a comment to clarify,0,0,0,0.9578048586845398,0.9599067568778992,0.9923135638237,0.0,accept,unanimous_agreement
1045266074,11012,"i think it was broken event before my change. for example the failed_calls was incremented without checking the cmd_call_stats. i agree regarding removing these flags, as i could not find any use for them aside what you mentioned.",0,0,0,0.9746431112289428,0.9821051359176636,0.9850318431854248,0.0,accept,unanimous_agreement
1045266146,11012,will do,0,0,0,0.9603245854377748,0.957181751728058,0.9619618058204652,0.0,accept,unanimous_agreement
1045268039,11012,"i also had the same thought, but i thought it is too implicit assumption that can cause some issues in future implementations or bugs. i also feel we should aim to have as little difference between client calling processcommand and actually calling cmd->proc. the postpone introduced in [a link] is basically a different type of blocking which indeed prevents ""command processing"" as apposed to the cases handled inside processcommand. i think it is o.k to have modules postpone commands after verifying arity, it is probably what the user would prefer anyway (why should we postpone something that will never be able to run?) i can consider using the client_pending_command which imo is a nice candidate to decide on ""reprocessing""",0,0,0,0.8081225752830505,0.9757023453712464,0.9585387706756592,0.0,accept,unanimous_agreement
1045433522,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1045433644,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1045921061,11012,in the end i tried to use the cmd->proc as it seemed like the easiest way to solve the issue. i am not 100% comfortable with it as i have no good way to verify we indeed reprocessing (other then to use the reprocessing flag :) ) i did run the tests with a combination of the check for cmd->proc and asserting in case we are trying to process a command when this flag is not present and did not get any assert. please take a look and share your thoughts,-1,1,1,0.4205881953239441,0.9663466811180116,0.9816436171531676,1.0,accept,majority_agreement
1045923699,11012,"i think it is not crucial to decide now if we want to eliminate the fields or not, we are basically risking some unknown module flow to have wrong statistics. if you both feel that we can drop these flags i will, but i do not see it as a showstopper",0,0,0,0.6537823677062988,0.5850045084953308,0.8080496191978455,0.0,accept,unanimous_agreement
1046286754,11012,"the changes lgtm. i still think it would be nice to be able to know in `call()` that it's not the first time we get there on behalf of the current command. it can be a flag, or maybe even a counter that we can show in client list. not sure what it would be useful yet, so we can put it aside for now. maybe has an idea?",0,0,0,0.8228753209114075,0.9353427290916444,0.8567758798599243,0.0,accept,unanimous_agreement
1046321874,11012,"you're arguing that nothing changed in this pr with that regards, so we can lave it as is. we did add monitor to that flow, but these call flags were only about stats and slowlog (monitors are not connected yet when loading aof file). the only way this problematic flow will happen, is probably when a module decides to propagate it's blocking command to the aof file, and then on startup we'll load the aof and these will appear in the command stats. i wanna argue that this pr is about sorting out the mess of the blocking framework, so this thing falls under that umbrella. so still, i think we either want to keep these flags in the client struct for the re-execution, or drop these flags entirely and instead handle aof, eval, and multi concerns explicitly. maybe if we implement a test first (involving a module, together with multi, eval, and aof), it'll be easier to get a feel of what we wanna do. feel free to join this party.",-1,-1,0,0.5843783020973206,0.8255347609519958,0.778745174407959,-1.0,accept,majority_agreement
1046356666,11012,i think that indeed this is a refactor meant to place some order to the blocking mess. but it is still not complete. modules blocking should also have some refactor imo which might be a good point to address these concerns. for now i suggest i will explicitly check for the aof cases (i think it is (client_multi + client_id_aof) or (server.loading + client_script) right?,0,0,0,0.9536731243133544,0.9775671362876892,0.9240436553955078,0.0,accept,unanimous_agreement
1046646325,11012,i don't think command stats should have the information about blocking. we should likely have a separate field indicating the number of blocked clients along with client list which indicates clients are blocked.,0,0,0,0.9815675616264344,0.9668715000152588,0.9558453559875488,0.0,accept,unanimous_agreement
1046695271,11012,i think my last commits does exactly that. we already have info fields for the number of blocked clients and the number of blocked keys. we also have an indication for blocked clients on the client list.,0,0,0,0.9869472980499268,0.980847179889679,0.987496018409729,0.0,accept,unanimous_agreement
1047254466,11012,i did something :) take a look if that is what you meant,1,1,1,0.9201341271400452,0.9942436814308168,0.99512380361557,1.0,accept,unanimous_agreement
1047351217,11012,"i looked at the change, it bothered me that the documentation of the function says what it does (lists the fields it zeros), but not what it's purpose. i'm wondering again why we can't change luaredisgenericcommand to simply call resetclient?",-1,0,-1,0.891745388507843,0.7942555546760559,0.9231417179107666,-1.0,accept,majority_agreement
1047388967,11012,it bothered me 2 as i told you i have hard time trying to understand what we encapsulate. i think there might be issues reseting client during lua script. for example do we want to clear the asking flag (this is possible to run lua after asking right?) also the current slot is zeroed and the request type which are some examples of things we might not to reset imo. maybe i am wrong but lua solves it by clearing some fields itself. i can maybe suggest that we can create a separate function to resetclient during lua?,-1,-1,-1,0.6826443076133728,0.532826840877533,0.9284445643424988,-1.0,accept,unanimous_agreement
1047435809,11012,"in lua scripts, the client which we reset is the lua (internal) client, not the real client that called the script.",0,0,0,0.986867904663086,0.9916115403175354,0.9908071160316468,0.0,accept,unanimous_agreement
1048134930,11012,oh. so you say it will be o.k to reset the semi client. i added the resetclient instead. lets see if it fails any tests,0,0,0,0.9790826439857484,0.971324622631073,0.958800733089447,0.0,accept,unanimous_agreement
1057765703,11012,i committed a potential change which deprecates the stats and slowlog command flags. take a look and tell me what you think.,0,0,0,0.982882797718048,0.8362060785293579,0.985800564289093,0.0,accept,unanimous_agreement
1058178955,11012,please be sure to mention that module bug in the top comment,0,0,0,0.9814077019691468,0.9880285263061525,0.9940892457962036,0.0,accept,unanimous_agreement
1058182909,11012,"i think we need a two step thing. 1. find the real client, i.e. if this is a script use the server.script_caller, if this is a module, get the real caller too. 2. then check if the real caller is an aof client. this practice is done in a few places already, although it looks like not for modules. it should be impossible to call a script during loading (unless it comes from the aof), but for modules i think it is possible. i.e. mark the module command to be allowed during loading, and then use rm_call. if it gets complicated (affecting more places), maybe we'll leave that for another pr.",0,0,0,0.9626410603523254,0.9784688353538512,0.9547381401062012,0.0,accept,unanimous_agreement
1058406690,11012,i also thought about that. i think however this is a bit complicated to navigate and locate the original client throughout all the module and function/script flows. maybe it would be simpler to maintain a pointer to the original client in each client struct? thinking about it - would just checking the server.current_client be enough?,0,0,0,0.9384760856628418,0.970109760761261,0.9666800498962402,0.0,accept,unanimous_agreement
1058415446,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1058492061,11012,"ok, so taking modules out of the equation (they're not currently handled by the code), let's also remove them from the comment above this block (or turn it into a todo). regarding the current check (using `server.loading`), i think a better one is `if (c->id == client_id_aof || (c->flags & client_script && server.script_caller->id == client_id_aof))` or get the `caller` like we do for `client_tracking` below this code. for some reason i thought that `server.current_client` is set by modules, but now i see it isn't. so how about doing: [code block] we don't propagate scripts to aof, and we don't allow them during loading, so the only way `c` would be a script is if it is called form a module command, and then current_client should reflect either the network caller or the aof client.",0,0,0,0.9772216081619264,0.9910452961921692,0.9884461164474488,0.0,accept,unanimous_agreement
1058516914,11012,"as we discussed offline. i see that the server.current_client is preserved during aof loading, so i changed the check to reflect that.",0,0,0,0.9868597388267516,0.987945318222046,0.9948776960372924,0.0,accept,unanimous_agreement
1058538323,11012,lgtm,0,0,0,0.9795994758605956,0.7242414951324463,0.9618706703186036,0.0,accept,unanimous_agreement
1058826984,11012,"i want to have this first approved by you and then i will update the top comment. approved, please mention it in the top comment and resolve this discussion.",0,0,0,0.9728280901908876,0.9260920882225036,0.9904752373695374,0.0,accept,unanimous_agreement
1058840671,11012,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
1058857817,11012,"let's comment that this method is only used on timeout, error and modules, and not on most unblocked cases. and in that light, i wonder if we wanna add them to the monitor (i.e. the timeout cases)?",0,0,0,0.9639583826065063,0.989041030406952,0.9904451370239258,0.0,accept,unanimous_agreement
1058860488,11012,do we really need to take extra care not to use background_duration on blocked keys? it'll be 0 anyway. am i missing something?,0,0,0,0.7977597117424011,0.8941196203231812,0.9289096593856812,0.0,accept,unanimous_agreement
1058863697,11012,don't we want to skip monitor too when !update_command_stats (aof loading),0,0,0,0.978888213634491,0.9859303832054138,0.9940140843391418,0.0,accept,unanimous_agreement
1058865733,11012,i'd like to make sure we have some tests around this area.,0,0,0,0.9519777297973632,0.9719007015228271,0.9752419590950012,0.0,accept,unanimous_agreement
1058901413,11012,working on it,0,0,0,0.9656718373298644,0.949994683265686,0.8633134365081787,0.0,accept,unanimous_agreement
1058902044,11012,i guess we can add it to the check. even though afaik the monitors are not connected during aof loading so this probably was never a problem,0,0,0,0.9830868244171144,0.9560551047325134,0.9877051115036012,0.0,accept,unanimous_agreement
1058910222,11012,"ohh, right. so i'm not sure which will be more confusing.. to make it explicit so i wouldn't have made that comment, or if we make it explicit someone would make a pr to suggest to remove it.",-1,-1,0,0.7240794897079468,0.8833653926849365,0.5071985125541687,-1.0,accept,majority_agreement
1058998673,11012,since this is currently not only a case of timeout (modules run this command as well) i do not think we can avoid reporting it to monitors.,0,0,0,0.9017958641052246,0.9790306687355042,0.989767849445343,0.0,accept,unanimous_agreement
1059002588,11012,"to tell the truth, idk. i only tried to keep this aligned with existing logic. do you know if we always take the background duration? (i think it is only updated by specific call to rm_blockedclientmeasuretimeend)",0,0,0,0.9733812212944032,0.9685065150260924,0.9893904328346252,0.0,accept,unanimous_agreement
1059054947,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1059055184,11012,"added the aof check to the ""if"" statement",0,0,0,0.9881978631019592,0.9923891425132751,0.995044469833374,0.0,accept,unanimous_agreement
1059130825,11012,i meant that we can add an argument or something so we can make a distinction between timeout / error and modules.,0,0,0,0.97907292842865,0.990215301513672,0.9900593757629396,0.0,accept,unanimous_agreement
1059132289,11012,"guy is currently away. what i meant was that since it's only updated in rm_blockedclientmeasuretimeend, it should be otherwise set to 0, and then we can avoid the condition here and always sum it. i.e. even if we call rm_blockclientonkeys we set it to 0..",0,0,0,0.918607532978058,0.5312077403068542,0.971229374408722,0.0,accept,unanimous_agreement
1059139839,11012,we can also call the module command from the script,0,0,0,0.9863228797912598,0.9924782514572144,0.9950594902038574,0.0,accept,unanimous_agreement
1059140250,11012,i now realize that we can use `rm_call_flags` with `!` flag instead of adding this one.,0,0,0,0.9819936156272888,0.9868359565734864,0.989389717578888,0.0,accept,unanimous_agreement
1059255275,11012,so you are o.k with totaly not reporting timedout commands?,0,0,0,0.9754629731178284,0.9836709499359132,0.9902329444885254,0.0,accept,unanimous_agreement
1059255417,11012,o.k - i basically agree. will do,0,0,1,0.7928770780563354,0.7319973707199097,0.5120131969451904,0.0,accept,majority_agreement
1059255628,11012,"that will not work imo. the '!' flag will only replicate the ""called"" command and not the module command itself.",0,0,0,0.5926201939582825,0.9370456337928772,0.9819981455802916,0.0,accept,unanimous_agreement
1059274473,11012,"if we log monitor when a command was actually executed, and the command never did, i think it makes sense not to log it. it's the same as a command that got rejected by oom or other error. maybe we need another pair of eyes on this. ?",0,0,0,0.9582096338272096,0.9579954743385316,0.9443029165267944,0.0,accept,unanimous_agreement
1059274795,11012,"ohh, right. :facepalm:",0,0,-1,0.7976031303405762,0.5032524466514587,0.942294180393219,0.0,accept,majority_agreement
1059281764,11012,"just to place my personal opinion: i feel that the monitor should log every command once it is being handled. even in case a command was timedout, it does not mean it was not handled. i can find some reason to monitor both commands which are blocked and also monitor again the fact that they are reprocessed (maybe add some indication in the monitor output) but i feel it can be confusing not monitor blocked commands which were timedout.",0,0,0,0.8206616640090942,0.9281233549118042,0.9283129572868348,0.0,accept,unanimous_agreement
1059303188,11012,"some day, monitor will also be able to track commands that failed (e.g. on oom) and so on. we have great plans for monitor in the far future, see [a link] in the meanwhile, with the current monitor, i don't think it should log things that didn't take place. i.e. if you'll see a blpop in the monitor, you'll think an element was popped, when in fact the command failed. i.e. it failed in a similar manner as an oom, etc. it's true that it it would have failed on wrongtype we would have logged it anyway, but in my eyes, that's just because the current infra is limited. edit: if someone re-plays the commands in monitor, the wrongtype one will consistently fail again with no harm, but for timeouts it can be a more complicated problem.",0,0,0,0.6983559131622314,0.7813600301742554,0.5979593396186829,0.0,accept,unanimous_agreement
1059370169,11012,"i strongly agree with ran - in principle, monitor should log every command as it is handled. errors and timeouts aren't the same things imo, although both may be triggered by circumstances/topology and the dataset. because timeouts are asynchronous by definition, the only consistent way to treat the potential ones (i.e. all blocking commands) that i see is to log them as they are first processed (which appears to be the current behavior). because monitor is less-than-ideal for replay purposes, if that's needed, i feel a new trace command, or perhaps some variation on aof, is better.",0,0,0,0.934349000453949,0.976584255695343,0.8975039720535278,0.0,accept,unanimous_agreement
1059478816,11012,"it may be the wine speaking, but i don't understand any of this. isn't monotor used to track which commands were actually executed, like a live aof stream that also includes read commands? it does not include commands that were rejected (oom). how is it useful for the user to log timed out commands ?",0,0,0,0.9680845141410828,0.5259445309638977,0.7260084748268127,0.0,accept,unanimous_agreement
1059592503,11012,"you raise a good point. i guess that it should be clear if the monitor command should report commands which were ""intercepted"" or actually ""processed"". currently our documentation indeed states the later, however the current implementation indicates the first. my point was that ""timedout"" commands are a different case than ""rejected"" commands. currently we do not report commands which failed authorization (and oom), but a timedout command is actually being processed and the fact that it was timedout does not mean it was not handled (it does mean it did not fully cause the requested effect). for example let's say a command to read from a stream with non existing group was received, we will report it on the monitor even though it ended with error. i think of timeout as an error to complete processing the command, unlike the case of a command which was rejected.",0,0,1,0.5487598776817322,0.9456361532211304,0.9360641241073608,0.0,accept,majority_agreement
1059712642,11012,"the example you gave about stream with non existing group is similar to the one i gave earlier about wrongtype. i think these cause less damage to the monitor user than reporting a command that failed on timeout. i think some use cases for monitor will try to feed the command stream back to redis, in the case of wrongtype, the command will consistently fail again immediately, but in the case of timeout, i could either hang, or worse, succeed for some reason. i'll try to grab to comment here as well.",0,0,0,0.8944900035858154,0.919357419013977,0.9696113467216492,0.0,accept,unanimous_agreement
1059729011,11012,"i discussed it with yossi, and he convinced me to flip this around. the arguments were: 1. we were trying to conclude if monitor is about the database (which command modified the data), or about clients (which client executed a command). for the first, there are already ways to ""monitor"" the database, which are keyspace notification, aof, and attaching a replica, but for the later, there's nothing so many monitor should serve this purpose (monitor client commands and not database changes). 2. we have some future plans for monitor ([a link] so some day it'll be able to also log rejected command, and maybe also both the being blocked time and the being released time, as well as the release reason (timeout or not), so maybe for now, the right thing to do is to keep it was it was and avoid any logical change (other than clear bug fixes), so we don't end up incrementally changing it and breaking some use case multiple times. so the bottom line of that discussion is that in contrast to my previous opinion (to make a change to avoid logging on timeouts), i'd like to revert an earlier change we made, and keep logging blocked clients in the initial `call()`, when being blocked.",0,0,0,0.8560816645622253,0.973948061466217,0.8281571865081787,0.0,accept,unanimous_agreement
1059758541,11012,"i implemented according to the decision to keep monitors current behavior. i placed a flag which indicates a client is currently executing a command which is cleared once the cmd->proc is completed and the client is no longer blocked. the main issue with this is that it will not work well in case of nested calls (lua, multi etc...) but since currently we do not allow blocking in nested calls (i am still not 100% sure regarding modules) this should be fine.",0,0,0,0.9729291796684264,0.9809908866882324,0.9257953763008118,0.0,accept,unanimous_agreement
1059769779,11012,"maybe it's better to match the `lpush`, and then add another trivial command (e.g. `incr`) and match that. so we know we didn't log the pop between the push and incr.",0,0,0,0.9852494597434998,0.9953927993774414,0.98398095369339,0.0,accept,unanimous_agreement
1059790473,11012,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
689111570,9357,"* maybe use `memtol` instead of `atoi`? * i think we should error if it is set to a value larger than 4gb (only allow reducing it) * i don't like the fact we write to a plain global, let's either add it to the server struct, or add an accessor function in quicklist.c (and the global will be static) * also, this subcommand isn't included in the help [code block]",-1,0,0,0.8590186834335327,0.959828555583954,0.9542973637580872,0.0,accept,majority_agreement
689111966,9357,"not sure what the comment was for, probably a leftover? [code block]",0,0,0,0.9235522150993348,0.9465140700340272,0.899681031703949,0.0,accept,unanimous_agreement
689112653,9357,"on 64 bit system, this change increases the size of the struct by 8 bytes (padding), from 32 bytes, to 40. i don't see any other option though, and i suppose that normally it doesn't make much difference. the only case it will make a big difference is if you have a lot of lists that are very short (just one node with a small ziplist). if we want, maybe we can use one of the `extra` bits to make a distinction between two types of node structs, one for small list nodes and one for larger ones.",0,0,0,0.9688155651092528,0.9809821844100952,0.9852097630500792,0.0,accept,unanimous_agreement
689112739,9357,the comment needs a update (no longer 4+n),0,0,0,0.98492693901062,0.9902220964431764,0.994059681892395,0.0,accept,unanimous_agreement
689113239,9357,"we need to increment the rdb version (rdb.h) and declare a new encoding type for list (rdb.h), and then the loading code need to handle both correctly (let's add a test that loads an old rdb file with quicklist)",0,0,0,0.987415850162506,0.9940998554229736,0.9939990043640136,0.0,accept,unanimous_agreement
689123060,9357,"we need to re-arrange these tests in some way. the ones that use the `debug packed_threshold` trick don't need the `config set proto-max-bulk-len` etc, and don't need to use all the `r write` and `write_big_bulk`, so they can be made a lot shorter and cleaner. we do also want other group of tests that don't use that debug trick, and do use the proto-max-bulk-len and all the `r write` mess, and these need to have the `large-memory` tag. in theory i could say that we can run the same batch of tests twice, with the same code, once with small strings and the debug trick, and a second time on large strings. this way we avoid code duplication. but on the other hand, the code that uses small strings can be made much much shorter and more readable so i think i rather have that duplication.",0,0,0,0.942842662334442,0.9921675324440002,0.9844980835914612,0.0,accept,unanimous_agreement
689131912,9357,"why all these separator lines? i see that ziplistrepr is attempting to generate some json like string (although that seems broken), maybe should do something that fits that. it may also be nice to add a flag to that function (controllable from the debug command) that controls if this function prints the actual content of the node, or just their metadata (i.e. it won't call ziplistrepr, and it wont print the actual string for sds, but rather just the length). p.s. it seems this function is missing proper handling of compressed nodes.",0,0,0,0.930497407913208,0.9811635613441468,0.967822790145874,0.0,accept,unanimous_agreement
689132310,9357,i suppose this should be `>=` rather than `>`,0,0,0,0.986793041229248,0.9883183240890504,0.9875367283821106,0.0,accept,unanimous_agreement
689132500,9357,"you're matching `container` (enum) with threshold? i suppose you meant that if either of the nodes (a or b) are none, you return null (not using the threshold)",0,0,0,0.9872135519981384,0.9928475618362428,0.9934238195419312,0.0,accept,unanimous_agreement
689132975,9357,"the comment seems wrong (we don't insert a ziplist), i guess a copy paste thing, is there any reason why rdb.c won't just use quicklistpushtail for these?",0,0,0,0.8987833857536316,0.8481550812721252,0.9563623666763306,0.0,accept,unanimous_agreement
689133444,9357,"redis doesn't use `bool` and `true` and `false`. please convert to `int`, `1` and `0`. i think the method can refer to a ""plain node"" or a ""non-containerized node"" not sure i can find a better term. maybe adding the word ""plain"" next to the declaration of `quicklist_node_container_none` will help? [code block]",0,0,0,0.9847056269645692,0.9937049746513368,0.9897828698158264,0.0,accept,unanimous_agreement
689133640,9357,i think all of these should be using `>=` rather than a `>`,0,0,0,0.9873643517494202,0.9854156374931335,0.9738280177116394,0.0,accept,unanimous_agreement
689133895,9357,"i saw you added a union alias, let's use it or drop it. [code block]",0,0,0,0.9884235262870787,0.9889736771583556,0.9952882528305054,0.0,accept,unanimous_agreement
689134172,9357,"ohh, maybe we wanna keep this function in order to avoid the extra malloc and memcpy. well, it needs renaming, and an improved comment (see my comment on __quicklistinsertentrynode). it would also be nice to document both here, and in the ziplist one that's used by rdb.c, that it takes ownership of the buffer passed to it.",0,0,0,0.945261001586914,0.9807637929916382,0.9713220000267028,0.0,accept,unanimous_agreement
689139047,9357,"that handles a case in which the old node was plain (non containerized), but what about the case where you're replacing an entry in a ziplist with one that's too big for it? you need to split the ziplist into up to 3 nodes. also there's' the case where you're placing a small entry instead of a big one, you can probably create a ziplist, and even merge it with the ones on either or both sides.",0,0,0,0.9868003129959106,0.9827210307121276,0.9936342239379884,0.0,accept,unanimous_agreement
689262682,9357,"i think it would be slightly nicer to put that `if` first in the function, or nested inside the `!node` one.",0,0,0,0.969604194164276,0.9805462956428528,0.9804453253746032,0.0,accept,unanimous_agreement
689269237,9357,"this code was recently change, and you need to rebase (merge form unstable). let's try to re-think the last two `if`s in that if-else chain. * the one before the last, says that if the current node is full, and we need to append to it's very end, instead maybe we can append to the beginning of the next node instead. * the last `if` in this chain, says that there's no other resort than splitting the current node in the middle. i don't think we wanna add any code to these two blocks, instead just add more condition to the `if`s and add new blocks before or after them. so in that case, considering that the two new actions you added in these blocks are both when `sz > threshold`, it would be enough to just add a first `if` to handle this case, so that the last two `if`s will not be reachable. i.e. 1. `else if (sz >= threshold)` (inside that, check if we have to do splitting or not) 2. `else if` .. all the conditions about next node being full `|| node->container == none` 3. `else` . split a ziplist. does this sounds right? -steinberg please have a look",0,0,0,0.9750154614448548,0.962738573551178,0.9796146750450134,0.0,accept,unanimous_agreement
689270868,9357,"don't we have a method that does this that can be used instead of repeating these lines (and the increments below)? if not, maybe create one. i.e. this can either be one that does all of this (including the malloc and memcpy. or we can do the malloc and memcpy here, and just at least call a common to handle the creation and modification of the node members and counters.",0,0,0,0.9846755862236024,0.9937323927879332,0.9918272495269777,0.0,accept,unanimous_agreement
689272632,9357,"you're not allowed to use `strlen` in redis (nearly ever!!) strings are not assumed to have null terminator at the end.. they may have many null chars in the middle. we call them ""binary safe strings"" they always come with `len`. besides that, you didn't match the `entry` node length, so you could have reached beyond it's bounds. the if should be something like `return (len==len2 && memcmp(p, p2))`",0,0,0,0.9786712527275084,0.8316305875778198,0.703004002571106,0.0,accept,unanimous_agreement
689273978,9357,"i have a feeling that we're overlooking compressed nodes. i want quicklist to still be able to compress ""plain"" nodes, not just ziplists. let's figure out a way to test this heavily.",0,-1,0,0.8147966265678406,0.9025029540061952,0.8067758679389954,0.0,accept,majority_agreement
689275712,9357,"it's a bad idea to cast pointers like that. let's assume that size_t is 64 bit and int is 32 (that's actually the common case). so you have a 64 bit variable and you pass a function a pointer to a 32bit variable. it'll only write to 32bits, and the other half of that variable will remain unchanged. what's worse, in a bigendian system, it'l write to the wrong half of the variable, and even if the other half is zero, your result will be completely messed up. instead, you need to declare a temporary stack variable at the right size, pass a pointer to it, and then copy the value when the function returns.",-1,-1,-1,0.9808195233345032,0.9640320539474488,0.9746681451797484,-1.0,accept,unanimous_agreement
689278346,9357,same comment about pointer casting... please go over the code and verify you don't do these anywhere else,0,0,0,0.9283278584480286,0.9495524168014526,0.9914946556091307,0.0,accept,unanimous_agreement
689279136,9357,styling.. [code block],0,0,0,0.986747145652771,0.988311231136322,0.9872143268585204,0.0,accept,unanimous_agreement
689287794,9357,"i just wanna confirm.. we wanna remove one entry from the tail and put it at the head. the case you handled above is where the tail is ""plain"", so you just need to move a full node. but there's another case, where the tail is a ziplist, and you wanna move an entry to the head, but the head is ""plain"" (not a ziplist). is that case ok because quicklistpushhead handles that?",0,0,0,0.9825026988983154,0.9858905076980592,0.9731068015098572,0.0,accept,unanimous_agreement
689292329,9357,let's use `%zu` instead of casting to `int`,0,0,0,0.9877469539642334,0.9944356679916382,0.9939530491828918,0.0,accept,unanimous_agreement
689292524,9357,let's use `%zu` instead of casting to `int`,0,0,0,0.9877469539642334,0.9944356679916382,0.9939530491828918,0.0,accept,unanimous_agreement
689293544,9357,use `%zu` instead of casting to `int`,0,0,0,0.9868359565734864,0.9942020773887634,0.9941179752349854,0.0,accept,unanimous_agreement
690248424,9357,not sure i understand the union is union {unsigned char *zl; unsigned char *entry;}; the size is common for both entry and zl. do you think i should add also a union for the size ?,0,0,0,0.9840548634529114,0.9886647462844848,0.9235411882400512,0.0,accept,unanimous_agreement
690256580,9357,yes it is handled by quicklistpushhead,0,0,0,0.9871533513069152,0.9925962090492249,0.9919739365577698,0.0,accept,unanimous_agreement
690269264,9357,can you give an example ? or point to something similar ?,0,0,0,0.9864146113395692,0.9928374886512756,0.9927145838737488,0.0,accept,unanimous_agreement
690273098,9357,1) do you mean that len1 = entry->sz in case of plain node ? 2) there is a comment here - /* passthrough to ziplistcompare() */ should i remove it completely or change it ?,0,0,0,0.9828588366508484,0.995451271533966,0.9934887886047364,0.0,accept,unanimous_agreement
690279922,9357,do you mean replacing quicklist_node_container_none with quicklist_node_container_none_plain or adding a new enum quicklist_node_plain ?,0,0,0,0.9886121153831482,0.9947378039360046,0.9946897029876708,0.0,accept,unanimous_agreement
690286331,9357,can you please elaborate on your suggestion ? not sure i understand.,0,0,0,0.7320787906646729,0.9642056226730348,0.8313319087028503,0.0,accept,unanimous_agreement
690290291,9357,[code block] i guess that's what should mean. then subtract 1 from extra.,0,0,0,0.9858457446098328,0.983340322971344,0.992259919643402,0.0,accept,unanimous_agreement
690328531,9357,why not add at the start of `_quicklistinsert`. [code block],0,0,0,0.9879729747772216,0.9947566986083984,0.994038462638855,0.0,accept,unanimous_agreement
690340756,9357,"would it be better to move tail node to head, without having to copy and free memory?",0,0,0,0.9853364825248718,0.9926992058753968,0.9846739768981934,0.0,accept,unanimous_agreement
690356440,9357,"because the caller executing quicklistnext will use the data in entry directly, if you do not decompress, the data in entry will be compressed. and we need to compress the current entry before moving to the next one.",0,0,0,0.987496256828308,0.9925772547721864,0.9932311773300172,0.0,accept,unanimous_agreement
690466323,9357,sorry. seems that i thought you're writing int `zl` in this line. ignore..,-1,-1,-1,0.9893323183059692,0.992595374584198,0.9928627610206604,-1.0,accept,unanimous_agreement
690467494,9357,let's make sure there's a unit-test that covers it.,0,0,0,0.9838539958000184,0.9883764386177064,0.9898603558540344,0.0,accept,unanimous_agreement
690472804,9357,"the comment is no longer relevant, in the past it meant that there's no reason to describe what this function does, since it's just a wrapper. but that's no longer true, so a proper comment is probably needed. regarding the memcmp, yes, there's no point in doing memcmp if the buffers are not the same size (i.e. we know the buffers are not equal). and obviously ignoring the size of one of them and doing memcmp with the size of the other, could cause a segmentation fault.",0,0,0,0.7015182375907898,0.9855212569236756,0.9897391200065612,0.0,accept,unanimous_agreement
690475858,9357,"i think we can't use `quicklist_node_plain` since this is an enum that describes the `->container` field. so the prefix of this enum is needed to be common. i think that `none` and `plain` are in some way synonymous, and if we use the term `plain` and we can more easily refer to is and search for it (unlike ""none""). so i think `quicklist_node_container_plain` is the right term. wdyt?",0,0,0,0.9805455207824708,0.9631108641624452,0.9796754121780396,0.0,accept,unanimous_agreement
690481822,9357,we currently have: [code block] so instead it could be: [code block] -steinberg do you think we should do it? i tend to think we should skip it.,0,0,0,0.9508490562438964,0.9887397885322572,0.988307535648346,0.0,accept,unanimous_agreement
690485120,9357,"i.e. then when we allocate ""plain"" nodes, we allocate them with extra 4 bytes, and look at `(node->sz | (size_t)node->sz_high[0])` rather than plain `node->sz` (obviously we can wrap that in a macro)",0,0,0,0.9860510230064392,0.9953603148460388,0.993537962436676,0.0,accept,unanimous_agreement
690515378,9357,"there are cases where the string is small and can fit into the beginning of the next node instead of the tail of the current one, and alike. your suggestion will prevent that, right?",0,0,0,0.986828863620758,0.9603908658027648,0.9929721355438232,0.0,accept,unanimous_agreement
691023541,9357,"""prints the actual content of the node, or just their metadata (i.e. it won't call ziplistrepr, and it wont print the actual string for sds, but rather just the length)."" what do you mean by just the length ? for a ""plain"" node i will print the value and for ziplist node i will only print number of entries ?",0,0,0,0.9870570302009584,0.99070143699646,0.9870405793190002,0.0,accept,unanimous_agreement
691048120,9357,would this threshold be more appropriate to change to a configuration?,0,0,0,0.9853516221046448,0.9915050864219666,0.985681653022766,0.0,accept,unanimous_agreement
691054144,9357,"""it would also be nice to document both here, and in the ziplist one that's used by rdb.c, that it takes ownership of the buffer passed to it."" not sure i fully understand this part...",-1,0,0,0.8749517798423767,0.9636874198913574,0.7274027466773987,0.0,accept,majority_agreement
691063192,9357,"i mean that if that flag is off, you only print all the metadata you have on the node, without calling ziplistrepr or printing the value of the plain string. this can be the number of records, the size (of the string or ziplist), the container type, and compression. if the flag is on, you print all the above, but also print the data (ziplistrepr or print the actual string/buffer)",0,0,0,0.9869094491004944,0.9895455241203308,0.9886206984519958,0.0,accept,unanimous_agreement
691064479,9357,"i don't think we want another configuration for this. we already have a configurable threshold of how much to put into each ziplist. i think of this threshold as a debug hack to test all the mechanics of quicklist, without consuming huge amounts of memory.",0,0,0,0.8469868898391724,0.9433134198188782,0.937900960445404,0.0,accept,unanimous_agreement
691067238,9357,"the caller passes a pointer and the function takes ownership of that memory (i.e. the caller doesn't need to release it, and should actually never access it again). something like: `zl - the data to add (pointer becomes the responsibility of quicklist)`",0,0,0,0.985184907913208,0.9932454228401184,0.9934476017951964,0.0,accept,unanimous_agreement
692022623,9357,"in the recent past i suggested to change `quicklist_node_container_none` to `quicklist_node_container_plain`, so that whenever we want to refer to a non-ziplist (or soon to be non-listpack) node we can just say something like this in comments: ""for **plain** nodes, we do...."" i.e. we can't say ""for **none** nodes..."", maybe we can say ""for **non-ziplist** nodes"", but that's awkward. now i wanna suggest something else: maybe we'll call them packed and unpacked? i.e. we won't use the term ziplist or listpack, but use a general term of ""packed"" [code block] in theory we can also change the above constant from 1 and 2, to 0 and 1, and then use these fields as booleans. i.e. if we rename `int container` to `int packed` [code block] but i'm not sure we wanna go that way. what do you think?",-1,0,-1,0.7537572383880615,0.5563166737556458,0.9681772589683532,-1.0,accept,majority_agreement
692081321,9357,"i think it works, and i can't think of a situation where we need to support multiple containers.",0,0,1,0.9741709232330322,0.9330827593803406,0.7258058190345764,0.0,accept,majority_agreement
692115890,9357,"lol.. i wanna remind you #8880 [a link] on a second though i think i'd rather avoid drastic changes that we may some day wanna revert. so i stand behind my suggestion above keeping the field names, and just renaming the enums to packed and unpacked. this way when listpacks arrive to town, we won't need to rename the ziplist (packed can refer to either ziplist or listpack). and also considering that the `zl` field now has a union alias named `entry` that can also play along, i.e. instead of renaming the `zl` field to `lp`, we can just delete it and use `entry`. p.s. i'm not sure which one of these prs will be merged first. possibly the listpack one will be easier since it just replaces one packing format with another one, and they already have similar capabilities. whereas this pr still needs to figure out the lzf compression complications (which don't pose any concern for the other pr). so whichever pr is merged first, they should both use the same variable and enum names (i.e. `entry` and `container_packed`) agreed?",1,1,1,0.9709190726280212,0.9756289720535278,0.9446322917938232,1.0,accept,unanimous_agreement
692676143,9357,"agree. it doesn't matter which pr will be merged first, i will not be modified from #8880, it will be completely new, #8880 is no longer applicable.",0,0,0,0.9674968719482422,0.9864326119422911,0.968562126159668,0.0,accept,unanimous_agreement
693497893,9357,"i think you forgot to initialize it here. (i think `1<<30` is good, with a comment saying it's 1gb) i think it should probably be at the very top of the file (that's where globals are usually placed. i would suggest to put the function that modifies it right next to it, so that some comment explaining what it does (threshold for plain nodes), where's the real limit (4gb), can serve both the variable and the function.",0,0,0,0.846504807472229,0.980138659477234,0.9444867968559264,0.0,accept,unanimous_agreement
693498145,9357,"i think the limit of not allowing it to be set to values larger than 4gb (clamping) should be here in this file, so that the code in debug.c doesn't need to know anything about it (i.e. the variable is static, and the default threshold or limits, are all bound to quicklist.c) p.s. i saw a bunch of junk code in debug.c, i guess temporary.",0,0,0,0.9430650472640992,0.9735672473907472,0.972228467464447,0.0,accept,unanimous_agreement
693517704,9357,aren't you ignoring the `after` variable here?,0,0,0,0.968009114265442,0.9933462142944336,0.990437924861908,0.0,accept,unanimous_agreement
693520415,9357,"i don't think this method should be declared in the header file, i think it can be a static one in the c file, or maybe even a macro or not needed at all. the other one is needed here only because of the debug command (hack)",0,0,0,0.9461549520492554,0.9911985993385316,0.9884309768676758,0.0,accept,unanimous_agreement
694084254,9357,set-active-expire set-skip-checksum-validation quicklist_packed_threshold should we use `-` here?,0,0,0,0.9888773560523988,0.9948659539222716,0.9956567287445068,0.0,accept,unanimous_agreement
696224354,9357,"when the new encoding replaces the old one, the old one will no longer be used, it will only appear during the rdb loading process and will be converted to the new encoding.",0,0,0,0.9860835671424866,0.9929420948028564,0.9935070276260376,0.0,accept,unanimous_agreement
696229824,9357,why make this judgment? aren't we trying to get it to support more than 4g?,0,0,0,0.7368990778923035,0.9110971093177797,0.9757915735244752,0.0,accept,unanimous_agreement
696235145,9357,using `_unpack` feels a bit odd.,-1,-1,-1,0.8548181056976318,0.8945959210395813,0.7682046890258789,-1.0,accept,unanimous_agreement
696297665,9357,"in fact, there's no need for `obj_encoding_quicklist_unpack` to be defined at all! we only need to tell the difference in the rdb loading (`rdb_type_list_quicklist_unpacked`) p.s. `rdb_type_list_quicklist_unpacked` is not a good name (it is always used, regardless of whether or not there are unpacked nodes. it could just be `rdb_type_list_quicklist_2` like `rdb_type_zset_2`",0,0,0,0.8902083039283752,0.9718291759490968,0.9687174558639526,0.0,accept,unanimous_agreement
696300310,9357,looks like a typo. meant to use `<` instead of `>`. [code block],0,0,0,0.9855642914772034,0.9781644344329834,0.9677461981773376,0.0,accept,unanimous_agreement
696303850,9357,there's absolutely no need for this define.. in ram we have only one quicklist encoding type.,0,0,0,0.9738255143165588,0.9805036783218384,0.9884483218193054,0.0,accept,unanimous_agreement
696331139,9357,"took a second look, i was wrong, there's no typo and `>` is ok. the threshold must be below 4gb (the technical limit), so we error if it's greater. updated my suggested patch above.",0,0,0,0.9733030796051024,0.9752848148345948,0.9522148370742798,0.0,accept,unanimous_agreement
696340043,9357,"ohh, i did get confused.",-1,-1,-1,0.9496886134147644,0.8942447900772095,0.5174455046653748,-1.0,accept,unanimous_agreement
696394396,9357,please take the comment i suggested too,0,0,0,0.979567289352417,0.9824740290641784,0.9947752952575684,0.0,accept,unanimous_agreement
702518529,9357,[code block] uniform format with `rdb_type_zset_2`.,0,0,0,0.9881742000579834,0.9944466352462769,0.9950363039970398,0.0,accept,unanimous_agreement
702520495,9357,[code block] it looks like it could just be replaced with `__quicklistinsertplainnode`.,0,0,0,0.9880026578903198,0.9939913153648376,0.9933953881263732,0.0,accept,unanimous_agreement
702521712,9357,would it be better to use `realloc`?,0,0,0,0.9874354600906372,0.994707465171814,0.988301694393158,0.0,accept,unanimous_agreement
702524376,9357,large strings can be created like this: [code block],0,0,0,0.9870458841323853,0.9933568835258484,0.9940962791442872,0.0,accept,unanimous_agreement
702524913,9357,"[code block] `old_ver.rdb` can't express it is quicklsit, we can change filename to `list-quicklist-2.rdb`.",0,0,0,0.9884678721427916,0.99577659368515,0.9953474402427672,0.0,accept,unanimous_agreement
702607966,9357,"i think you misunderstood what the `quicklistrotate` method does. top comment: `/* rotate quicklist by moving the tail element to the head.*/` it only moves the last element to the top, not the head to the tail. look at the code you have also moved the head to the tail.",0,0,0,0.9772581458091736,0.9075964093208312,0.896019697189331,0.0,accept,unanimous_agreement
702608968,9357,i think we should add a big element related test to redis_test.,0,0,0,0.9873387813568116,0.9808197617530824,0.982291579246521,0.0,accept,unanimous_agreement
702621682,9357,i assume you want to validate the old `rdb_type_list_quicklist` to the new `rdb_type_list_quicklist2`? you can refer to the `convert-zipmap-hash-on-load` test.,0,0,0,0.9897047877311708,0.994936227798462,0.9934629201889038,0.0,accept,unanimous_agreement
702808223,9357,"if `quicklist->head` is `quicklist_node_container_none`, we also need to insert the plain node directly. the same applies to `quicklistpushtail`.",0,0,0,0.9891585111618042,0.9947211742401124,0.994456112384796,0.0,accept,unanimous_agreement
702833871,9357,"not sure if i'm understanding this correctly, is this the way it should be? [code block]",0,0,-1,0.9417760372161864,0.9368062615394592,0.7098780870437622,0.0,accept,majority_agreement
702857928,9357,not sure the scenario you are referring to... if (new node == plain) && (head == plain || head ==small) we get to first if (new node == small) && (head == plain) second if fails and we get to the else (new node == small) && (head == small) we will probably get to if (or else if ziplist is full),0,0,0,0.962983250617981,0.9841958284378052,0.9690228700637816,0.0,accept,unanimous_agreement
702858662,9357,i committed by mistake... i will commit it now with the test...,-1,0,-1,0.9322648644447328,0.9612354040145874,0.9801619052886964,-1.0,accept,majority_agreement
702858980,9357,is my test not checking it correctly ?,0,0,0,0.646338701248169,0.9496122598648072,0.95025372505188,0.0,accept,unanimous_agreement
702882878,9357,"i was trying to find a specific scenario for testing but couldn't find one. , will you be able to give a specific example so i can take it and fix the code accordingly ?",0,0,0,0.9437031149864196,0.984573781490326,0.931390941143036,0.0,accept,unanimous_agreement
702883385,9357,so what is the bottom line here ? do we want to do it ?,0,0,0,0.9745697379112244,0.9918389916419984,0.9764174222946168,0.0,accept,unanimous_agreement
702884444,9357,so bottom line is that i only change in naming is : unsigned int container : 2; /* none==1 or ziplist==2 */ ==== > unsigned int container : 2; /* unpacked==1 or packed==2 */ ?,0,0,0,0.9852281808853148,0.975671648979187,0.9875956773757936,0.0,accept,unanimous_agreement
702890146,9357,"yeah, i misunderstood.",-1,-1,0,0.9600903391838074,0.9320159554481506,0.9081199169158936,-1.0,accept,majority_agreement
702893688,9357,"my mistake, the rdb name should be list-quicklist.rdb (the old rdb type). i was actually wondering how to validate the old list-quicklist to list-quicklist-2 validation, since the encoding of the quicklist has not changed, do you have another way? all i can think of right now is to go through the quicklistrepr to get the relevant information.",0,-1,-1,0.796663224697113,0.5053242444992065,0.8518262505531311,-1.0,accept,majority_agreement
702895404,9357,"as i understand it, it should be `unsigned int packed : 2; / unpacked==1 or packed==2 */ ? `. because using `node->container` is weird, it doesn't mean it's packed .",-1,0,-1,0.9214745163917542,0.950454831123352,0.9084612131118774,-1.0,accept,majority_agreement
706825282,9357,"i may be missing some context, but if we don't need the data, free+malloc is better than realloc (saves the need for memcpy)",0,0,0,0.9760638475418092,0.9883198738098145,0.9909247159957886,0.0,accept,unanimous_agreement
706827074,9357,do you agree with that ?,0,0,0,0.972334623336792,0.985343337059021,0.9908643364906312,0.0,accept,unanimous_agreement
706830180,9357,"i was thinking we're gonna use the term `plain` (not `unpacked`)? i don't have any objection to the term `container` (listpack, and ziplist are containers, and plain means there's no container), since `none` was completely unused till now, there's no reason not to rename it. however, since we're going to rename `ziplist` soon to `listpack`, then i don't mind renaming it already to `packed`. the only reason not to rename things that are not completely off, is to keep changes to the blame log low, and avoid conflicts, but since we'll have to rename `ziplist`, and since `none` ins unused, then i suppose we're going to change all the lines that refer to `container`, right? if that's right, and we're going to change all lines anyway, then i don't mind to change `container` too, but if we rename it to `packed` then we should indeed use `unpacked` rather than `plain`. so both options are viable to me: 1. `unsigned int container : 2; / plain==1 or packed==2 */` 2. `unsigned int packed : 2; / unpacked==1 or packed==2 */` my previous aim was to take this: 3. `unsigned int container : 2; / plain==1 or ziplist==2 */` i.e. in this case we don't modify the variable name or the constant that's currently used. and then when makes the pr that changes ziplist to listpack, he can change ziplist into either listpack or packed. i think i actually prefer 3, since it'll reduce the loc change in this pr. it doesn't touch the ziplists, so why rename the define or variable? bottom line, i vote for taking option 3 in this pr, and then change it option 2 in a future pr.",0,0,0,0.9131900668144226,0.9700573682785034,0.9458190202713012,0.0,accept,unanimous_agreement
707053787,9357,"i think it's as simple as enabling compression `list-compress-depth=1`, adding a plain nodes and and triggering this code. maybe you can even modify `tests/asserts/default.conf` and run the test suite.",0,0,0,0.9801766872406006,0.988399624824524,0.9870525002479552,0.0,accept,unanimous_agreement
707055442,9357,"i don't want to do that (yet), but let's leave this comment unresolved to get more feedback.",-1,0,0,0.6611165404319763,0.7179062962532043,0.8118079304695129,0.0,accept,majority_agreement
707072543,9357,the new optional argument needs to be documented in the help message.,0,0,0,0.9852285385131836,0.985173225402832,0.9949707984924316,0.0,accept,unanimous_agreement
707074095,9357,"being a debug command, we don't need to be too strict about the syntax and errors. i'd just go with something similar to `server.active_expire_enabled = atoi(c->argv[2]->ptr);` also, the name `enabled` is wrong. should be `deep` or `light` or such.",0,0,0,0.952046036720276,0.9808841943740844,0.9403762221336364,0.0,accept,unanimous_agreement
707076275,9357,"a simple `addreplyerror` is better. both less code, and also better since it sends an error rather than a plain bulk string.",0,0,0,0.9480047821998596,0.9871063232421876,0.9872272610664368,0.0,accept,unanimous_agreement
707077743,9357,"should we add a macro `node_is_plain`, instead of the existing `node->container == quicklist_node_container_none`.",0,0,0,0.9888920187950134,0.9952321648597716,0.994742751121521,0.0,accept,unanimous_agreement
707079411,9357,i think it's better to add a `light` or `deep` argument to `quicklistrepr` and a few if-else rather than add two functions is some code duplication.,0,0,0,0.98219496011734,0.9846609234809875,0.977863311767578,0.0,accept,unanimous_agreement
707081355,9357,"let's also print the compression flag, and the size in the light mode. and let's convert the `container` to string, i.e. [code block]",0,0,0,0.986950695514679,0.9931286573410034,0.9954167604446412,0.0,accept,unanimous_agreement
707083849,9357,let's change back to free+malloc,0,0,0,0.9704246520996094,0.9902771711349488,0.9940902590751648,0.0,accept,unanimous_agreement
707101815,9357,"sorry i didn't see this comment (it was hidden). i tried adding the following unit test, which triggers this code. [code block]",-1,-1,-1,0.9862049221992492,0.9810357093811036,0.9904476404190063,-1.0,accept,unanimous_agreement
707123803,9357,"i'm not sure what printf does on negative size of `%.*s`. maybe we should add some truncation in case of an overflow? please check. maybe the truncation should not be just on overflow, but in any case `entry.sz > (1<<20))` or so?",0,0,0,0.966812551021576,0.8601344227790833,0.9416472315788268,0.0,accept,unanimous_agreement
707132815,9357,let's add a check that the value is one of the two we support and if not abort the loading gracefully. e.g. see calls to `rdbreportcorruptrdb` below and return null after releasing what we need to release.,0,0,0,0.9885168075561525,0.9907476902008056,0.9947799444198608,0.0,accept,unanimous_agreement
707137222,9357,"unrelated to this pr: i see that we save compressed nodes as compressed strings, i.e. the same format as we would save non-compressed nodes when `server.rdb_compression` is enabled. this means we decompress them on load time, right? which is why we don't bother to save the compression flag. (on reload it'll get lost). i see room for improvement to save this flag and then avoid decompression on load time. since we're changing the rdb format now and save the `container` field, maybe we should use this opportunity to save the `encoding` field too?",0,0,0,0.9140247106552124,0.9848688840866088,0.9765692949295044,0.0,accept,unanimous_agreement
707151210,9357,don't you also need to set `list-max-ziplist-size` so that each entry is in it's own node? maybe add some comments explaining what you aim to test in each of these tests and how.,0,0,0,0.9863184690475464,0.9931871891021729,0.994525671005249,0.0,accept,unanimous_agreement
707155677,9357,"this should be some 5gb, right? see more details in [a link]",0,0,0,0.9834054708480836,0.9875009059906006,0.9940927624702454,0.0,accept,unanimous_agreement
707156882,9357,the complete bit-field here is: [code block] we already have `sz` which is 32 bits. we don't need the `count` field and we don't need the `extra` field. this is another 26 bits. together with `sz` it's 58 bits (or 67 million times more than 4gb). why not just use this?,0,0,0,0.9841879606246948,0.992534875869751,0.9910553693771362,0.0,accept,unanimous_agreement
707160466,9357,"why don't we need the `count` field? do you suggest to rely on the ziplist header? not sure i'd like that.. and also, it may be lzf compressed.",0,0,0,0.9792481660842896,0.96001935005188,0.9418514966964722,0.0,accept,unanimous_agreement
708904577,9357,", i am closing this thread because i split the tests to small / big / compression. and we have more threads regarding other issues with the tests.",0,0,0,0.946800172328949,0.7688297629356384,0.9162160158157348,0.0,accept,unanimous_agreement
708961648,9357,yes... its temporary so i can run the test on a regular machine and not an extra big one.,0,0,0,0.9644084572792052,0.9574439525604248,0.978223979473114,0.0,accept,unanimous_agreement
710953256,9357,"i thought `count` is the number of items in the ziplist but in case of none container we don't have a zip list but rather just an sds, which is single entry (count always == 1). i guess i'm mixed up.",0,0,0,0.9577823281288148,0.6998887062072754,0.9374343752861024,0.0,accept,unanimous_agreement
710968909,9357,"ohh, ok. re-purpose these bits just in case of a plain (non-packed) node. well, it'll be a little bit complex.. so the question again is if it wort it. i.e. with all that complexity we might as well just add a few more bytes to the node when it's a plain node and allocate a different struct (the extra bytes are not a high price to pay for a node holding a string that's huge anyway). but the main question is if the extra 8 bytes do any significant damage on ziplist nodes. i.e. the extreme case is lots of lists with one small members, but that's not a realistic case, right?",0,0,0,0.9394591450691224,0.8625770807266235,0.7616572976112366,0.0,accept,unanimous_agreement
710988936,9357,"i think it's not a big deal to add the extra 8 bytes, but i'm leaning towards the idea of having some union that'll include the ""container specific"" data (like `extra_len_bits` for none and `count` for ziplist). this will make the code clearer i think. anyway that's all i have to day, either option is good.",1,0,1,0.6326600313186646,0.6312522292137146,0.930570662021637,1.0,accept,majority_agreement
711718204,9357,"ok, just remember that doing so doesn't really test what you intend to test. i.e. it does test that the test code is correct, but it doesn't prove that there aren't any bugs in the c code (like using `int` instead of `long` or `size_t`).",0,0,0,0.9834756851196288,0.9892655611038208,0.990024209022522,0.0,accept,unanimous_agreement
719427150,9357,"maybe the term ""light"" needs more words to be explained? let's change the code below so that 0 is light (shallow) and 1 is deep (full), or we can consider it an lod integer [code block]",0,0,0,0.98087340593338,0.992659032344818,0.9868993759155272,0.0,accept,unanimous_agreement
720689745,9357,is this line redundant?,0,0,0,0.9177129864692688,0.9531722664833068,0.9601702690124512,0.0,accept,unanimous_agreement
720791949,9357,"i think this block should be moved into the one below, so that the same comment (and debug print) covers them both.",0,0,0,0.9876229763031006,0.9882715344429016,0.9821383953094482,0.0,accept,unanimous_agreement
720793335,9357,"why do we check `if (full)` here? we wanna split it even if non-full since we can't fit the new item into it. also, it's clear by locking at the flow, that there's no ultimate `else`, so if we reach there, we didn't insert the new data. however, considering the checks in `_quicklistnodeallowinsert`, full will always be set. so imho this condition is just confusing, should be plain `else` p.s. i see there's still one handling of `islargeelement` in the code below. it's dead now, let's delete it.",0,-1,0,0.7889973521232605,0.7451269626617432,0.7353305220603943,0.0,accept,majority_agreement
720794385,9357,"technically ""max"" would be 2 (3 would be ""next"" or so). but also, since you're using this to validate the rdb input, and it's not 0 based, you also need ""first"". i'd suggest to either add a `quicklistisvalidcontainer(int)` function / macro, or just change these to be 0 based, and then have max set to 1.",0,0,0,0.9872531294822692,0.9938833713531494,0.99206805229187,0.0,accept,unanimous_agreement
720794789,9357,"in some cases `rdbreportcorruptrdb` calls `exit()` so the code after it is unreachable, but in some cases it doesn't (e.g. on retore command). so you'll need to `return null` here too, and also make sure there's no memory leak (i.e. do `decrrefcount(o);` see below). also, i now notice that the other `return null` you added above is also leaking memory.",0,0,0,0.9857487082481384,0.9918798804283142,0.992823600769043,0.0,accept,unanimous_agreement
720795700,9357,"styling: either we use one line, or if we break the `if` into two lines, we need to indent the conditions and braces differently [code block]",0,0,0,0.9869478940963744,0.99292254447937,0.9940409064292908,0.0,accept,unanimous_agreement
720796024,9357,"yeah, returning two replies on one command would make a huge mess.",-1,-1,-1,0.9615573287010192,0.9527543783187866,0.8262643814086914,-1.0,accept,unanimous_agreement
723908577,9357,so what is decided here ?,0,0,0,0.9762862920761108,0.9904111623764038,0.991593599319458,0.0,accept,unanimous_agreement
723909040,9357,now this test is passing. any other issues you see with compression ?,0,0,0,0.988538920879364,0.9903869032859802,0.9876124262809752,0.0,accept,unanimous_agreement
723909474,9357,", you want to change this in this pr ?",0,0,0,0.9784013628959656,0.9925203323364258,0.9906979203224182,0.0,accept,unanimous_agreement
723910253,9357,i've added a temporary comment and will be changed when ready to submit.,0,0,0,0.9840518236160278,0.9854958653450012,0.9946354031562804,0.0,accept,unanimous_agreement
724031089,9357,"why delay that? is it too big for your computer? or for the pr ci? we already have the `large-memory` guarding a test that allocated 512mb, and it's enabled by default and only skipped on some platforms. these tests will allocate 5gb, right? and will be protected by the same flag. if that's too much, maybe we need to make the tests disable that flag by default.. i.e. whatever we wanna do later, we should do now and see that it works, or conclude that we some improvement.. please check how much memory and how much time do these tests take when you change them, and see if they succeed running in the gh actions ci.",0,0,0,0.9167011976242064,0.9491190314292908,0.8054074645042419,0.0,accept,unanimous_agreement
724053850,9357,discussed with and he agrees that: if we accept the current code of changing `sz` to `size_t` then in practice a single item list will grow from 136 to 144 bytes (verified with `memory usage`). so the worst case scenario is we increase memory usage by less than 10%. i think that for this specific scenario (which is a very inefficient usage of lists) the overhead is tolerable.,0,0,0,0.9185782074928284,0.9849721789360046,0.9697959423065186,0.0,accept,unanimous_agreement
724074875,9357,"i thought about it together with yoav, and concluded that there's no need to do anything now. saving the compression flag is not needed, since the loader knows how many nodes there are in the quicklist it loads and knows the current configuration of the node compression (which is possibly different than the one used to save the file), so it can decide on it's own which nodes to keep compressed. p.s. even if we'll decide we wanna keep the compression instead of decompress and re-compress, we'll at least need to de-compress in order to do ziplist sanitization.",0,0,0,0.9542306065559388,0.970311403274536,0.9551891684532166,0.0,accept,unanimous_agreement
724637515,9357,"[code block] btw, if there is only one line in the if, we don't need `{}`.",0,0,0,0.9889158010482788,0.9927613735198976,0.994051158428192,0.0,accept,unanimous_agreement
724937532,9357,"should this method be moved to the end, as it's defined at the end of quicklist.h.",0,0,0,0.9884815216064452,0.9949711561203004,0.9948863387107848,0.0,accept,unanimous_agreement
724959680,9357,missing compression?,0,0,0,0.9296178221702576,0.981790006160736,0.9881784319877625,0.0,accept,unanimous_agreement
724960103,9357,compression is also missing here.,0,0,0,0.9779006838798524,0.9812495112419128,0.9831330180168152,0.0,accept,unanimous_agreement
725440219,9357,forget to call `quicklist->count--`.,0,0,0,0.9534981846809388,0.98834490776062,0.5976343154907227,0.0,accept,unanimous_agreement
726029769,9357,should this comment line be deleted?,0,0,0,0.9800935387611388,0.9929848313331604,0.9885502457618712,0.0,accept,unanimous_agreement
726034074,9357,it looks like a wrong conflict was resolved.,-1,0,0,0.8728130459785461,0.899882435798645,0.6331552267074585,0.0,accept,majority_agreement
726084328,9357,forget to change here. `#define rdbisobjecttype(t) ((t >= 0 && t <= 7) || (t >= 9 && t <= 18))`,0,0,0,0.9788386225700378,0.9928683638572692,0.9919662475585938,0.0,accept,unanimous_agreement
726357565,9357,node count is 1 inside __quicklistdelnode quicklist->count=-node count,0,0,0,0.9849953055381776,0.9634788036346436,0.9937496185302734,0.0,accept,unanimous_agreement
726841414,9357,what's wrong with that comment? (other than the reference to `zl` which we renamed?,-1,0,0,0.6060075759887695,0.9685585498809814,0.9004450440406799,0.0,accept,majority_agreement
726847520,9357,"you should now remove these asserts in this file, and a bunch of checks in t_list.c added them in redis 6.2 and they got cherry picked to unstable, but in your branch that's handled please go over the change in c5e6a6204c4cf57f85e7c83a9b4e99f1a7204fd2 and undo the ones that are no longer needed.",0,0,0,0.9880911111831664,0.9924518465995787,0.9942997694015504,0.0,accept,unanimous_agreement
726859339,9357,"now the conflict is properly resolved (diff-wise), but i think there's a bug. there's a reason these few lines got extracted from `quicklistreplaceatindex` to `quicklistreplaceentry`. since now `quicklistreplaceentry` is an api of it's own (used in t_list.c), all your plain node handling code needs to move to the inner method.",0,0,0,0.9751832485198976,0.9894921779632568,0.9781242609024048,0.0,accept,unanimous_agreement
726861742,9357,"this comment has been changed to ` * when quicklistnode->entry is compressed, node->entry points to a quicklistlzf */` and old has not been deleted.",0,0,0,0.987403154373169,0.9952391386032104,0.99558287858963,0.0,accept,unanimous_agreement
726866348,9357,in #9589 the maximum element limit in the list can also be removed (`list_max_item_size`).,0,0,0,0.9890867471694946,0.9947822690010072,0.994647204875946,0.0,accept,unanimous_agreement
726869120,9357,"ohh, the same line appeared twice. i was only looking at the small diff that's part of that comment, didn't see context.",0,-1,0,0.6966819167137146,0.5537670254707336,0.942619264125824,0.0,accept,majority_agreement
727646473,9357,we can use `quicklistdelindex` instead of `quicklistdelrange` to avoid excess traversal.,0,0,0,0.9884031414985656,0.992801547050476,0.994709610939026,0.0,accept,unanimous_agreement
728607846,9357,this is just to avoid call `quicklsitcompress` twice? if that's the case i think we can move `zipstlistreplace` to above ifs(add else).,0,0,0,0.9883082509040833,0.994817078113556,0.9923065304756165,0.0,accept,unanimous_agreement
728712945,9357,i think `full` and `avail_next` are guaranteed to be 1 and 0 since `_quicklistnodeallowinsert` has this check: [code block] am i missing anything?,0,0,0,0.9892372488975524,0.9919849634170532,0.9919008016586304,0.0,accept,unanimous_agreement
728713541,9357,let's also delete the `list_max_item_size` define (no longer needed),0,0,0,0.9888131022453308,0.9919450879096984,0.9947686195373536,0.0,accept,unanimous_agreement
728714507,9357,"we'll need to move this code into the ""test"" block and tag it with `needs:debug` (and the recovery code). otherwise it'll fail when executed on external servers which block debug.",0,0,0,0.9795637726783752,0.9948866963386536,0.9930411577224731,0.0,accept,unanimous_agreement
728716067,9357,"maybe add a few comments as to what exactly you aim to test, either here at the top, or next to each block.",0,0,0,0.9832528829574584,0.9849776029586792,0.98973947763443,0.0,accept,unanimous_agreement
728750808,9357,"indeed. we should delete `full`, `!avail_next` and `!avail_prev`.",0,0,0,0.9853485226631165,0.993724763393402,0.9901623725891112,0.0,accept,unanimous_agreement
730360200,9357,i'm curious. why do you flush at the end of each test? maybe it's better to flush in the beginning of the next one (if needed),0,0,0,0.7169438004493713,0.9207532405853271,0.9291832447052002,0.0,accept,unanimous_agreement
730360608,9357,"i didn't understand what ""combinations"" means, now the comment above explains it, but maybe a better name could be: `test lset with packed / plain, old / new combinations`? i'm also willing to leave it as is, but either way, better keep the comment above and if needed update other tests / comments that refer to this one..",0,0,0,0.944610595703125,0.9641250371932985,0.9011166095733644,0.0,accept,unanimous_agreement
730361071,9357,"we have here 3 nearly identical tests that are repeated twice. maybe we can run them inside a foreach loop? and maybe have it just skip the debug command, or one of the loop iterations if unsupported (checking the tags)? maybe if it's just these 3 tests, it's not a big deal, but if there are others with similar considerations it may be worth it i.e. to avoid duplicate code and risk one copy being updated and the other one forgotten. maybe a similar thing can be done for this: [code block]",0,0,0,0.966639757156372,0.9742063283920288,0.9660837054252625,0.0,accept,unanimous_agreement
730668983,9357,"before this merge i was using different names for the lists. in order o use same name and since some of the tests are not clearing the list, i have just flush the db. is that a problem ?",0,0,0,0.9775248765945436,0.9087082743644714,0.9375592470169068,0.0,accept,unanimous_agreement
730694939,9357,"no, but i think it's nicer that each test starts with a flush (takes care of it self) rather than end with one (still relies on other tests to exit cleanly)",0,0,0,0.9356120824813844,0.9546269774436952,0.9752238988876344,0.0,accept,unanimous_agreement
732709877,9357,"tags are by default executed (unless `--tags - ` is added, or `--tags ` is added. i.e. one means run everything except a certain tag, the other means run only a certain tag. but now we need that tag to be skipped by default. so i think we need some explicit mechanism rather than rely on the tags. i think the mechanism we should follow is the `cluster:skip` tag. see this code in server.tcl: [code block] i.e. i think the tag here in list.tcl is ok (it tags a test as needing large memory), no need to change this line. but we need to do these too: 1. add an optional argument to test_helper.tcl (like `--cluster-mode`) 2. add skipping code in server.tcl (`tags_acceptable`) like the one i pasted above) 3. add a note about it in `tests/readme.md` (like the one who mentions `--cluster-mode`)",0,0,0,0.9745087027549744,0.9891995191574096,0.9853402972221376,0.0,accept,unanimous_agreement
732714919,9357,"in the readme, we can say that any test that requires over 100mb will be by default skipped. i suppose this `--large-memory` flag should be described in the top comment (instead of the todo it has now) also, let's describe: 1. the new debug sub-commands 2. rdb format change 3. any other major change that may be interesting for reviewers who don't wanna bother reading the code.",0,0,0,0.9693619012832642,0.9881389737129213,0.989267110824585,0.0,accept,unanimous_agreement
732965413,9357,"if you rename the tag you need to modify bitops.tcl too. but actually, i think the is name was better. it indicates the test requires large memory. otherwise, if you refer cli option, it should be `no-largemem:skip`. i think the should have been negated (hence my other comments). so bottom line, i suggest applying my comments, and then rename all the references to tag back to the old name.",0,0,0,0.973641872406006,0.9781572222709656,0.975660502910614,0.0,accept,unanimous_agreement
733579779,9357,"i prefer the older ones, which are over 80, but not too long.",0,0,0,0.85699063539505,0.925805389881134,0.9460941553115844,0.0,accept,unanimous_agreement
733584331,9357,this change can be reverted.,0,0,0,0.9789056777954102,0.9847358465194702,0.994340181350708,0.0,accept,unanimous_agreement
733584503,9357,this change can be reverted also.,0,0,0,0.983933448791504,0.9880664348602296,0.994766354560852,0.0,accept,unanimous_agreement
733585780,9357,this line should not be needed.,0,0,0,0.9585899114608764,0.9701570868492126,0.9867534041404724,0.0,accept,unanimous_agreement
733589002,9357,"im not sure why github shows ""} else if (!strcasecmp(c->argv[1]->ptr,""set-skip-checksum-validation"") &&"" as line that changed... it is same line. i rather not change lines that is not relevant for the pr",0,0,0,0.7685973048210144,0.6913279294967651,0.9034194946289062,0.0,accept,unanimous_agreement
733590148,9357,`if` needs to be followed by a space.,0,0,0,0.9826291799545288,0.9919608235359192,0.991771638393402,0.0,accept,unanimous_agreement
733592609,9357,"i've looked at the code, and it has been modified by [a link] btw, if the condition in if is multi-line, `{` will be on the next line.",0,0,0,0.987967312335968,0.9845879077911376,0.9938300251960754,0.0,accept,unanimous_agreement
733593791,9357,i'll change the location of { ... thanks,0,1,1,0.5388376116752625,0.6546878218650818,0.8620370030403137,1.0,accept,majority_agreement
733595162,9357,this is a compile warning with `redis_test`. [code block] [code block],0,0,0,0.98927104473114,0.9934525489807128,0.9953104853630066,0.0,accept,unanimous_agreement
733605879,9357,forget to add `quicklist-v2` to [a link],0,0,0,0.9644686579704284,0.9922022819519044,0.9498823881149292,0.0,accept,unanimous_agreement
733610528,9357,should i change also quicklist to quicklist-v1 ?,0,0,0,0.987976610660553,0.9946556091308594,0.9947481751441956,0.0,accept,unanimous_agreement
733619106,9357,"it doesn't seem to be necessary, because `rdb_type_string` was added with both `zset-v1` and `zset-v2` ([a link] i don't think we should change the old one.",0,0,0,0.9846394062042236,0.9922884106636048,0.9924654960632324,0.0,accept,unanimous_agreement
733632406,9357,you left this out.,0,0,0,0.9721603989601136,0.9840844869613647,0.9782581925392152,0.0,accept,unanimous_agreement
733639286,9357,"this will be fail under 32bit, the max value of `proto-max-bulk-len` and `client-query-buffer-limit` is 2147483647(2gb) under 32bit.",0,0,0,0.9869046807289124,0.9913229942321776,0.9913957715034484,0.0,accept,unanimous_agreement
735084329,9357,"for the record, i don't care about the 80 line limit.. people have large monitors these days and i think it's silly to stick to very short lines. i also don't think we need to have any strict line length limit, we should try to keep lines from being too long, but if in some cases we the code looks better with longer lines, that ok with me. for multi-line `if` we do want to move the `{` to the next line, and in the case of this specific block `set-skip-checksum-validation`, i see no reason to change it (the form in unstable is ok)",-1,-1,0,0.962515115737915,0.7060070633888245,0.5737264156341553,-1.0,accept,majority_agreement
735085628,9357,"good point, so these tests should be completely skipped in 32bit builds (even if user passes `--large-memory`). i.e. since we've set the threshold of what we call ""large memory"" at 100mb, people may wanna use it in 32bit builds, but we must skip these tests in some way. one way would be to try and detect how redis was built (using `[s arch_bits] == 64`) the other way could be to try and set these configs inside a catch, and then do a `config get` to see if they succeeded. i think the second way could be nicer since it can also implicitly work against external servers that block or clamp this config. either way, this would let us easily avoid repeating these two configs per test.",0,0,1,0.5918945670127869,0.9677502512931824,0.6641262769699097,0.0,accept,majority_agreement
735226154,9357,[code block] not aligned `\`.,0,0,0,0.9642270803451538,0.992825984954834,0.9902313351631165,0.0,accept,unanimous_agreement
735425723,9357,"this line is not needed, because `quicklistcompress` is already called in `__quicklistdelnode`.",0,0,0,0.9891427159309388,0.9938256740570068,0.9950396418571472,0.0,accept,unanimous_agreement
735432624,9357,"as above, it should be moved to the `else`.",0,0,0,0.9867542386054992,0.9936679005622864,0.9943045973777772,0.0,accept,unanimous_agreement
736209511,9357,"wrong is here, `size*` to `unsigned int*` will be truncated.",0,0,0,0.8091962337493896,0.960291028022766,0.8988640308380127,0.0,accept,unanimous_agreement
736247490,9357,"should change it to `unsigned int sz`, it looks like the temp variable `size` is not needed.",0,0,0,0.9886524081230164,0.9947059750556946,0.9936692118644714,0.0,accept,unanimous_agreement
736312589,9357,it looks like what you want is this: [code block],0,0,0,0.9820547699928284,0.976353406906128,0.9931613206863404,0.0,accept,unanimous_agreement
736393582,9357,not sure i understand what you did here...,-1,-1,-1,0.9653193950653076,0.6327045559883118,0.5917556285858154,-1.0,accept,unanimous_agreement
736416011,9357,"because `data[5]` is a char, it must be false when compared with `i`. and `assert(1)` will be no effect.",0,0,0,0.979608714580536,0.9934276938438416,0.99098140001297,0.0,accept,unanimous_agreement
737075309,9357,"the second and fourth arguments to `lzf_compress` are `unsigned int`, which will truncate if `node->sz` is larger than 4gb. `lzf_decompress` is the same.",0,0,0,0.9880086183547974,0.99512380361557,0.9944698810577391,0.0,accept,unanimous_agreement
737084739,9357,"it seems to be a tricky problem, if we can't let lzf support 64-bit we won't be able to compress data larger than 4gb. ping",0,-1,0,0.8323168754577637,0.8693402409553528,0.7822741270065308,0.0,accept,majority_agreement
737715664,9357,"interesting, good catch! i haven't looked at the code yet, but i suppose there's nothing that technically prevents lzf from supporting larger values, and we can modify the code to fix it. in any case, this would also cause issues for rdb.c when it attempts to store simple strings that are huge, and that's much worse since it's the default config (unlike quicklist compression). maybe we should ignore that for now and leave that for a followup pr?",1,1,1,0.9844648241996764,0.9554126262664796,0.9933319687843324,1.0,accept,unanimous_agreement
737996005,9357,by lcov it seems that we are missing the test of the code. maybe we can use `debug reload` to coverage it.,0,0,0,0.9643551111221312,0.9792018532752992,0.992042601108551,0.0,accept,unanimous_agreement
738169204,9357,"`entry_node` only used here, and the definition can be moved here. [code block]",0,0,0,0.9885460734367372,0.9937785267829896,0.9959808588027954,0.0,accept,unanimous_agreement
738206356,9357,[code block] it seems that the result is the same for both ways of writing. [a link],0,0,0,0.9850014448165894,0.9834829568862916,0.9935543537139891,0.0,accept,unanimous_agreement
738351383,9357,"this should be moved to before of `if (!ziplistvalidateintegrity(data, encoded_len, deep_integrity_validation, null, null))`, when the container is `quicklist_node_container_plain`, it is not necessary to incr.",0,0,0,0.9881558418273926,0.995069980621338,0.995571494102478,0.0,accept,unanimous_agreement
738906040,9357,"when encountering corrupt data, `encoded_len` maybe 0, in which case we use `quicklistappendplainnode` to insert a data of length 0. i feel that it should be skipped, otherwise, it will be followed by `zmalloc(0)` to create a `quicklistnode->entry`. the existing code doesn't crash or write illegally to memory, but i think it is dangerous. corrupt data restore command: [code block]",-1,0,-1,0.7764856815338135,0.9490199089050292,0.7044005393981934,-1.0,accept,majority_agreement
739079269,9357,it seems that we can revert to the old code and only modify `quicklist->tail->zl` to reduce the changes.,0,0,0,0.9874520897865297,0.992423176765442,0.9909058809280396,0.0,accept,unanimous_agreement
739110501,9357,"this implementation feels wrong, when getting the value of the current iterator, we should not set current to the next node. for example, the following code: [code block]",0,0,-1,0.6854133009910583,0.5892691612243652,0.8523021936416626,0.0,accept,majority_agreement
739793902,9357,good catch. please fix and add a test to the corrupt-dump.tcl unit.,1,1,1,0.9351255297660828,0.9685625433921814,0.9899487495422364,1.0,accept,unanimous_agreement
739795521,9357,"i see the very bottom of this function does move `iter->current` to the next node if the ziplist is drained. but indeed it does do that after re-compressing the one we just finished with... so aren't we just missing a call to quicklistcompress before setting current? either way, let's make sure this is tested.",0,0,0,0.9786929488182068,0.9844054579734802,0.9906609654426576,0.0,accept,unanimous_agreement
739930374,9357,"when the current ziplist is drained, it needs to move to the next quicklistnode, which immediately performs another quicklistnext. so after each execution of quicklistnext, the current is pointing to the current quicklistnode that needs to be fetched, not the next one. i think we should unify the implementation of plain and packed. [code block]",0,0,0,0.9848964214324952,0.9919388890266418,0.9897397756576538,0.0,accept,unanimous_agreement
740163070,9357,redundant blank line.,0,0,0,0.8875429630279541,0.6260964274406433,0.8117470145225525,0.0,accept,unanimous_agreement
740199276,9357,forget to free `data` when `encoded_len` is 0.,0,0,0,0.8783408999443054,0.989602506160736,0.9851087927818298,0.0,accept,unanimous_agreement
740248797,9357,debug reload has an implicit save in it. [code block],0,0,0,0.9887810945510864,0.9922979474067688,0.9940842986106871,0.0,accept,unanimous_agreement
740249743,9357,please also add the test to the corrupt-dump.tcl for this case,0,0,0,0.9846247434616088,0.9942697286605836,0.9955690503120422,0.0,accept,unanimous_agreement
740252292,9357,"i think testing just one call to `next` in this test is a miss. let's do a full iteration to cover the entire list (and even verify the last `next` returns 0. maybe it would also be a good idea to mix plain and non plain nodes? i.e. set the threshold to 3, and add: [code block]",0,0,0,0.9578202366828918,0.9903766512870787,0.9704009890556335,0.0,accept,unanimous_agreement
740253604,9357,i guess it's nice to add `unlikely` in these `if`s,0,0,0,0.9755154848098756,0.8719379305839539,0.9825246930122375,0.0,accept,unanimous_agreement
740979022,9357,"what kind of test in corrupt-dump.tcl do you want ? i see that in the existing test ""corrupt payload: fuzzer findings - valgrind negative malloc"" i get to the new if : if (data == null || (encoded_len == 0)) { if (encoded_len == 0) zfree(data); decrrefcount(o); return null; }",0,0,0,0.985977292060852,0.9853772521018982,0.9943532943725586,0.0,accept,unanimous_agreement
741001367,9357,[code block] [a link] the memory leak you describe is caused by this.,0,0,0,0.968576431274414,0.99112731218338,0.9925453066825868,0.0,accept,unanimous_agreement
741003914,9357,"means to add `restore list 0 ""\x12\x01\x01\x00\n\x00\x8f\xc6\xc0w\x1c\n\xb3<"" replace` to the corrupt-dump.tcl test. this test will not fail until you add `(encoded_len == 0)`, after that it will return `*bad data format*` error.",-1,0,0,0.7983340620994568,0.993809163570404,0.9918596148490906,0.0,accept,majority_agreement
741010222,9357,which test in corrupt-dump.tcl should i add it to ?,0,0,0,0.971132755279541,0.9935623407363892,0.9929110407829284,0.0,accept,unanimous_agreement
741015579,9357,add a test like this: [code block],0,0,0,0.9873729348182678,0.992065966129303,0.995554268360138,0.0,accept,unanimous_agreement
741049327,9357,"nit pick: in theory a more correct check would be `if (data) zfree(data);` the check on `encoded_len` is just because we know there are two entry conditions to the above if. but also, since it's valid to zfree a null pointer, we can just `zfree(data);` without any condition.",0,0,0,0.9848511815071106,0.9917797446250916,0.9387068152427672,0.0,accept,unanimous_agreement
741826687,9357,opened an issue: [a link],0,0,0,0.9872869253158568,0.9911216497421264,0.9920554757118224,0.0,accept,unanimous_agreement
805323684,10285,"let's give a full example of the declaration here (not `...`). and also document the full list of callback types (i.e. the header file is not used when generating the reference documentation, so all defines and typedefs should be mentioned in the c file comments.",0,0,0,0.9884315729141236,0.9928141236305236,0.9939746260643004,0.0,accept,unanimous_agreement
805324050,10285,"make sure to document the expectations from the `err` argument. should it always be a static string? (i don't think it's a good choice), if not, then who's releasing it?",0,0,0,0.9806132316589355,0.9723896384239196,0.9879520535469056,0.0,accept,unanimous_agreement
805324335,10285,i think this flag should be renamed to default,0,0,0,0.9872761368751526,0.9741373062133788,0.9856394529342652,0.0,accept,unanimous_agreement
805324806,10285,"this api is a little bit more complicated than others, maybe it should come with an example, and certainly a few more doc words.",0,0,0,0.9103955626487732,0.8817871809005737,0.9539456367492676,0.0,accept,unanimous_agreement
805331108,10285,"if i understand the concept correctly (didn't dig too deep in the code), all that redis does with the enum_values is to check that users didn't provide any invalid input, but that's something the module can easily do on it's own (it has to compare the string to the enum values again anyway, right?), so effectively this gives the same features as rm_registerstringconfig, just more complicated to use. alternatively, with a similar registration interface, we could have provided an integer value to the set / get callback, but then it means the enum always starting form 0 and are consecutive (in redis they allow more flexibility, like defining several aliases to the same integer value, or using power of two / bits). i think we want to have the set / get callbacks get integers, and change the registration function to take an array of integers in addition to the strings.",0,0,0,0.9747115969657898,0.9826052188873292,0.983784556388855,0.0,accept,unanimous_agreement
805331337,10285,"args are optional in module load, i don't think we should make them mandatory here.",0,0,0,0.9702910780906676,0.9515819549560548,0.9861847758293152,0.0,accept,unanimous_agreement
805332847,10285,"i do think we should support double configs (it's an important primitive type, just like integer and string). i think the concerns around precision are no different than redis's doubles in values (e.g. hincrbyfloat etc). maybe it's a good opportunity to also extend the redis internal configs to support that (we'll have use for it one day)",0,0,0,0.9454497694969176,0.9630451798439026,0.9366747736930848,0.0,accept,unanimous_agreement
805334355,10285,i didn't see this documented (or tested). i'm not sure i like it. i assume that on success you expect the module to rm_retain the string? and the caller to decrement it's refcount? why shouldn't that work correctly for failures too?,-1,-1,-1,0.8731922507286072,0.5711660981178284,0.5199599862098694,-1.0,accept,unanimous_agreement
805335026,10285,"i'm not sure redismodule_applyconfigs api is needed. we certainly don't want to call the callback from withing it's registration call, but we can call all the setters when the module's onload exits, or even after all modules are loaded (when we process all configs that where not recognized at startup and got queued for after modules are loaded). the advantage for redismodule_applyconfigs is that after all configs are set, the module gets a chance to validate their sanity and exit if there's a mismatch may also be required for config set at runtime. i.e. in the spirit of #9748 to separate between the value setter callback, and the apply callback, and get just one apply callback for several configs. so maybe instead of redismodule_applyconfigs, the module should give an additional (optional) apply callback? i.e. we'll call it after applying the configs for either startup and runtime (config set) cases. p.s. i didn't look at the code or tests yet, but for the purpose of variadic config set, we need to be sure we handle rollbacks correctly.",0,0,0,0.9442333579063416,0.9737634658813475,0.982284128665924,0.0,accept,unanimous_agreement
805335289,10285,"any reason not to let the module also set the default value, just for the purpose of rewrite not to put them in the config file? that's the only way to later change defaults, and distinguish between explicit and implicit settings.",0,0,0,0.9842870235443116,0.9924744963645936,0.9846997857093812,0.0,accept,unanimous_agreement
805337709,10285,"i'm not certain about imposing that any config with a `.` must be a module's config. i'm ok with forcing all module configs to have the prefix of ` .`. if i understand the code correctly, when we load a config, if it's not recognized (and starts with `.`) we can queue it to be processed after modules are loaded, and then fail if not matching module is found. but i don't think it means that all configs with `.` must be a module ones.",0,0,0,0.9710601568222046,0.9406323432922364,0.9542540907859802,0.0,accept,unanimous_agreement
805390599,10285,"not sure about this, with one arguable exception (`latency-tracking-info-percentiles`) there was never a case for a floating point config.",0,0,0,0.9357498288154602,0.9774013757705688,0.7550264000892639,0.0,accept,unanimous_agreement
805394026,10285,"i am in favor of a single mechanism that enables delivering multiple configuration parameters in a single shot, which can be used at load time or when a multi-parameter set is performed. maybe it'd be easier to have a single `redismoduleconfigsetfunc` that takes a single struct or array of structs expressing the desired config change to support that, instead of a single call per parameter. this could also make it easier for a module to perform a `redismoduleloadconfigs` at load time, and receive the same array of structs that would be processed by the set callback, making it possible to abort the load if the configuration is invalid.",0,0,0,0.9319732189178468,0.9912323355674744,0.973537802696228,0.0,accept,unanimous_agreement
805394114,10285,"if we don't do that, how do we guarantee there are no name conflicts?",0,0,0,0.9686506986618042,0.9896872639656068,0.9702802300453186,0.0,accept,unanimous_agreement
805395923,10285,"i think such a mechanism will be more complicated to use on the module's side. i.e. on simple / single configs, the module can just implement a set of callbacks, and doesn't need to worry about anything else. the apply function and config grouping is something more advanced and rare.",0,0,0,0.9502621293067932,0.9753353595733644,0.9785393476486206,0.0,accept,unanimous_agreement
805451667,10285,"this was something i realized while passing through the code late on friday. i don't agree with the implementation, but found it better to just document it then try to fix it. in either case we should add a test for it.",0,0,0,0.9654134511947632,0.95523202419281,0.9269104599952698,0.0,accept,unanimous_agreement
805454192,10285,"one other use case is being able to do initialization based on configs. internally we have example where we have a datastructure that isn't feasible to change at runtime, so we want initialize it at startup. it has a default size, but this default can be overridden by a config. we need this overridden value available during onload(), since ideally we initialize there. we would need some type of deferred loading otherwise. the intention of the apply was just to make it coherent when the configs were now available.",0,0,0,0.9763956069946288,0.9932852983474731,0.9903337359428406,0.0,accept,unanimous_agreement
805454892,10285,"the code doesn't require the '.', it was just a mechanism to help prevent conflicts. it does prevent us from adding configs with .s in the future, but i'm not sure why we would ever do that.",0,0,0,0.7315208911895752,0.9743693470954896,0.9854742288589478,0.0,accept,unanimous_agreement
805556265,10285,"looking at the code i don't see why it prevents us to add such configs in the future. we go look for module configs only after we're done trying to match the built in ones. i think this can remain as is. i.e. module configs have to have `.`, but it doesn't mean that they're the only ones. i don't see any problem with conflicts this way.",0,0,0,0.947169542312622,0.9687143564224244,0.9418078660964966,0.0,accept,unanimous_agreement
805625529,10285,"i'm not bought on that specific option, but i do think the following is a must: * have a single mechanism that covers both simple and more advanced use cases. * make all configs available at `onload` time, before it returns, so it's possible to abort loading and handle initialization. * support atomic multi-parameter set.",0,0,0,0.9751380085945128,0.9805732369422911,0.9557005167007446,0.0,accept,unanimous_agreement
806239466,10285,"that message is in regards to the requirement that a loadex command contains an args keyword in it. loadex args is currently valid while loadex is not. in reflection, not sure why this has value. going to remove the restriction",0,0,0,0.9725279808044434,0.9319816827774048,0.9790192246437072,0.0,accept,unanimous_agreement
808899608,10285,if this is currently only used for modules why not just make this a `redismodule` pointer. this will make things much clearer and if we ever need private data for other commands then we can change it later. this will also eliminate the requirement for the `module_config` flag (non null meaning it's a module config).,0,0,0,0.987868309020996,0.9938523769378662,0.9908990859985352,0.0,accept,unanimous_agreement
808918269,10285,"there are a few configs in which we decided to take percentage, arguably, in some it was a result of not having a floating point config support. p.s. while we are on the subject, the numeric configs have support for `%` notation, similar to the `mb`/`gb` notation, see `percent_config`, maybe we should expose this to modules too (although it's internal structure is hackey, i.e. negative values).",0,0,0,0.9764670729637146,0.9924604296684264,0.9904137253761292,0.0,accept,unanimous_agreement
809044019,10285,i'm not sure i like this limitation. it can just as well be a convention and not part of the code. i think we can guarantee there are no conflicts during the config registration phase when loading the module the same way we guarantee there are no command conflicts when loading the module leaving the `modulename.cmdname` a mere convention for command names.,0,0,0,0.6326940059661865,0.8995746970176697,0.5399793982505798,0.0,accept,unanimous_agreement
809047745,10285,i'd like us to reconsider making the `configs` table a hash. i was also considering this when i implemented the multi config get/set realizing there's an o(n^2) complexity matching the config args to the table.,0,0,0,0.9643834233283995,0.9898332357406616,0.992335855960846,0.0,accept,unanimous_agreement
809060688,10285,why? i think what we currently do in case of an unrecognized config in the config file is simply ignore it. it'll remain in the rewritten file as is. shouldn't this be the case here too?,0,0,0,0.9655802845954896,0.8880428075790405,0.9805322289466858,0.0,accept,unanimous_agreement
809085316,10285,i'm not too sure we really need the `set_ctx`. for the regular configs we tried to avoid distinguishing the context in the setter functions to make them simpler. this seems like the only place someone actually reads the `set_ctx` and it appears just for the sake of performing some assertion in case of a software bug. i think we can remove this and just return the error with 0. the caller can detect the error return value and assert (or propagate it).,0,0,0,0.9706333875656128,0.9567295908927916,0.9496725797653198,0.0,accept,unanimous_agreement
809090758,10285,not critical but should probably be `long_str_size`.,0,0,0,0.988239288330078,0.9901672601699828,0.9876214861869812,0.0,accept,unanimous_agreement
809647621,10285,"sorry, my suggestion is missing `sdsempty()`. should be `sds config_name = sdscatfmt(sdsempty(), ""%s.%s"", module_name, name);`",-1,-1,-1,0.9568727612495422,0.9790908098220824,0.9819874167442322,-1.0,accept,unanimous_agreement
810238660,10285,"yeah, caught this when running with asan. no problem",0,0,1,0.8599510788917542,0.9014132022857666,0.7127850651741028,0.0,accept,majority_agreement
810593469,10285,do you think that's acceptable to get a static error string (modules can't format runtime content into it). how would that work with modules written with languages other than c (java / rust)?,0,0,0,0.9839175939559937,0.9883506298065186,0.9918362498283386,0.0,accept,unanimous_agreement
810593879,10285,"so the actual enum (int) values always starting form 0 and are consecutive (in redis they allow more flexibility, like defining several aliases to the same integer value, or using power of two / bits). i think we want to allow modules similar flexibility and change the registration function to take an array of integers in addition to the strings.",0,0,0,0.9864278435707092,0.9898118376731871,0.9931087493896484,0.0,accept,unanimous_agreement
810595255,10285,"i think we need to decrrefcount both on either success or failure. the module should ""retain"" the string if it chooses to keep it (or clone it)",0,0,0,0.9846785068511964,0.9823237657546996,0.9870331287384032,0.0,accept,unanimous_agreement
810596520,10285,"i'm not certain we wanna expose `config_hidden` to modules, but maybe we do wanna expose `percent_config` and `octal_config` ?",0,0,0,0.9809870719909668,0.986041247844696,0.9629802703857422,0.0,accept,unanimous_agreement
810599423,10285,"personally, i don't see any advantage in doing `if (ismodulestandardconfig(config))` vs `if (config->flags & module_config)`",0,0,0,0.9512715935707092,0.987841784954071,0.974331796169281,0.0,accept,unanimous_agreement
810599647,10285,"to me, it's confusing to see this comment next to the `standardconfigget` function when it speaks about other functions. personally, i'd either split it to fragments, separate it from the function (maybe with `/*-------*/` header, or just drop it (doesn't seem that useful)",-1,-1,-1,0.9397515654563904,0.8053399920463562,0.8591858744621277,-1.0,accept,unanimous_agreement
810600648,10285,do we assume here that all configs with `.` are modules? why do we need the `strchr` search? won't it work just the same by just calling `isconfignameregistered`?,0,0,0,0.9858136773109436,0.9945133924484252,0.9930740594863892,0.0,accept,unanimous_agreement
810601391,10285,"since this search is a little bit wasteful (full iteration on all configs and string compare), and considering we already have a similar search done by the caller (haven't seen it yet, but otherwise we could not afford an assertion), maybe we should drop this one. or alternatively, change this function to return an error on an existing config, and drop the other check.",0,0,0,0.8926970362663269,0.9793486595153807,0.9810824394226074,0.0,accept,unanimous_agreement
810601652,10285,"this call to realloc per config could be very wasteful. let's add a mechanism to remember the size of allocation and number of unused entries, and do a realloc only once in 32 or so.",-1,0,0,0.8092899322509766,0.9323804974555968,0.9091931581497192,0.0,accept,majority_agreement
810601869,10285,"if we do the above, we need to avoid shrinking here.. but seeing this memmove (which could be called repeatadly), i'm starting to lean towards using a dict.. on the other hand, it would not be bad if there's only one or two modules registering just a few configs. and even if a module registers a hundred configs, module unload is a very rare event. so maybe we shouldn't worry about it after all. wdyt?",0,0,0,0.7498368620872498,0.487924575805664,0.7109533548355103,0.0,accept,unanimous_agreement
810602314,10285,"on the other hand, seeing the loop in removeconfig, and realizing that even that one is called inside a loop, gives me the shivers.",0,0,-1,0.62039715051651,0.9845097661018372,0.9076993465423584,0.0,accept,majority_agreement
810603513,10285,not sure why createmodulestandardconfig is needed. it's impolite to pass structs on the stack. ;-),-1,1,1,0.5521019697189331,0.9864268898963928,0.964376986026764,1.0,accept,majority_agreement
810608432,10285,"i'm usually in favor of doing `argv+i` instead of `&argv[i]` or alike, but in this case, why not just `argv[i]`? p.s. i think the code below will be nicer if the increments for for `i` will be the last act, and all the other logic will refer to the unmodified position.",0,0,0,0.9806389212608336,0.9721039533615112,0.9081737995147704,0.0,accept,unanimous_agreement
810614514,10285,"i think we can afford to use `server.module_configs_queue` for the loadex command too, rather than add this context member. we don't really need it in any other context, and it'll actually simplify rm_loadconfigs, and a few other places. when we're done with server startup we have a check that verifies that list is empty, and we don't have nested calls to loadex. we'll have to add one or two comments that explain that it's used in two different cases, but i think it'll clean more than two lines.",0,0,0,0.948487102985382,0.969907522201538,0.8623541593551636,0.0,accept,unanimous_agreement
810614939,10285,"i don't like the concatenation here, (just in order to split it later in `loadmoduleconfigs`), but since it's done to be uniform with the case of loading lines from the config file, i suppose we don't have a better way.",-1,-1,-1,0.9479016065597534,0.9150055646896362,0.666375994682312,-1.0,accept,unanimous_agreement
810615614,10285,"btw, we also don't support multi_arg_config, i suppose the only impact on that is that the module will have to split the string on it's own, right? -steinberg ^^",1,1,1,0.8685750365257263,0.9663265347480774,0.992689311504364,1.0,accept,unanimous_agreement
810616131,10285,aren't we missing `dlclose`?,0,0,0,0.9838287830352784,0.9924808740615844,0.991557240486145,0.0,accept,unanimous_agreement
810617131,10285,"in the context of config set command, we do one search to find the relevant config in config.c, but that only brings us to the right module, and now we do another search. maybe instead of storing the module pointer in the config.c struct we'll save a moduleconfig pointer, and add a module pointer to moduleconfig? this way we don't need the second search.",0,0,0,0.9848437905311584,0.9920696020126344,0.9864618182182312,0.0,accept,unanimous_agreement
810617453,10285,"this will be easier to follow if we check them incrementally. i.e. first check that we didn't get any unsupported flag, and then check that the memory flag is not applied without numeric",0,0,0,0.9840408563613892,0.9883721470832824,0.9911584258079528,0.0,accept,unanimous_agreement
810618920,10285,note to self. check that this can't skip the init time default setting.,0,0,0,0.9865526556968688,0.9880528450012208,0.9937310814857484,0.0,accept,unanimous_agreement
810619184,10285,"note to self. this is duplicating quite a lot of logic from config.c maybe we can somehow embed it differently into the config.c structs so that our callback is called just instead of setting the referenced variable, and we can avoid duplicating that logic.",0,0,0,0.9658383131027222,0.9922080636024476,0.9872485995292664,0.0,accept,unanimous_agreement
810621124,10285,"something seem fishy here to me, and i can't put my finger on it. why do you need to call the function pointer with `*`? it should be just `config->get_fn.get_string(...)` i see this builds successfully, and i don't see that this is a **reference** to a function pointer **variable**, but rather just a function pointer.",0,-1,0,0.5760642886161804,0.826490044593811,0.631826639175415,0.0,accept,majority_agreement
810624374,10285,"i don't like much of the core around the error message handling in this function. i see it is modeled after `loadbuf` in config.c, which i don't like much either. but let's at least avoid allocating an object on the heap in case there's no error. i suppose we'll have to run the loop twice, but the code will probably be cleaner, and performance wise two loops in this case is probably better than two excessive malloc calls.",-1,0,-1,0.9531848430633544,0.4915561378002167,0.6406429409980774,-1.0,accept,majority_agreement
810624470,10285,"i don't like much of the core around the error message handling in this function. i see it is modeled after `loadbuf` in config.c, which i don't like much either. but let's at least avoid allocating an object on the heap in case there's no error. i suppose we'll have to run the loop twice, but the code will probably be cleaner, and performance wise two loops in this case is probably better than two excessive malloc calls.",-1,0,-1,0.9531848430633544,0.4915561378002167,0.6406429409980774,-1.0,accept,majority_agreement
810624491,10285,"i don't like much of the core around the error message handling in this function. i see it is modeled after `loadbuf` in config.c, which i don't like much either. but let's at least avoid allocating an object on the heap in case there's no error. i suppose we'll have to run the loop twice, but the code will probably be cleaner, and performance wise two loops in this case is probably better than two excessive malloc calls.",-1,0,-1,0.9531848430633544,0.4915561378002167,0.6406429409980774,-1.0,accept,majority_agreement
810624497,10285,"i don't like much of the core around the error message handling in this function. i see it is modeled after `loadbuf` in config.c, which i don't like much either. but let's at least avoid allocating an object on the heap in case there's no error. i suppose we'll have to run the loop twice, but the code will probably be cleaner, and performance wise two loops in this case is probably better than two excessive malloc calls.",-1,0,-1,0.9531848430633544,0.4915561378002167,0.6406429409980774,-1.0,accept,majority_agreement
810625455,10285,"how is this at all possible to get that error (config not found?) i suppose that if we take my suggestion of keeping a reference to `moduleconfig` as `privdata`, it'll be clearer that this is unreachable. let me know if i'm missing anything.",0,0,0,0.9750328063964844,0.910652756690979,0.9890690445899964,0.0,accept,unanimous_agreement
810626340,10285,"for instance looking at `set_numeric_type` and `get_numeric_type`. if we just add another numeric type `numeric_type_callback` then all the code handling numerics in config.c could serve modules too. (of course i'm referring to all types, not just numeric) it might make module.c and config.c more coupled with each other. but we'll reduce code duplication, and update / fixes will implicitly be applicable to both. maybe make a poc in a side branch to decide.",0,0,0,0.9749470353126526,0.992026150226593,0.9883652925491332,0.0,accept,unanimous_agreement
810626975,10285,"even if we go with letting the module provide explicit values for each enum, we always run the risk that it's getter callback returns a value for which there's no registered string. maybe `ll2string` would be better than ""unknown"" e.g. in case of some bug or corruption, it'll provide some additional info.",0,0,0,0.9849622249603271,0.9905458688735962,0.9713279008865356,0.0,accept,unanimous_agreement
810629810,10285,"actually, even when parsing the config file, we already have it split. i.e. we could maybe use the `argv` we already have split, instead of `lines` here: `listaddnodetail(server.module_configs_queue, sdsnew(lines[i]))`",0,0,0,0.9877243041992188,0.9943475127220154,0.994365930557251,0.0,accept,unanimous_agreement
810632444,10285,"i may be missing something, but as far as i can tell the apply_fn is only called from the context of rm_loadconfigs, and it should be also called from config set command (each unique callback called only once after all setters have been called). actually, it should **only** be called in the context of config set (same as with the config.c infrastructure, which doesn't call these on startup). on startup the module is getting all the setter callbacks before it's initialization stage, so it doesn't need the apply callbacks.",0,0,0,0.979211449623108,0.993016004562378,0.9817694425582886,0.0,accept,unanimous_agreement
810634199,10285,"ohh, i found what i was missing: `rm_registerstringconfig` passes the apply function pointer directly to `addmoduleconfig` this means that config.c calls the module callback (without any dispatcher or module context). on one hand this is the only way to have the code in `configsetcommand` de-duplicate the apply function callbacks (not call the same one twice). i.e. if it would go though some generic module.c dispatcher that de-duplication would break. but on the other hand, binding the module callback signature to the config.c one is probably wrong, we'll end up paying for that someday. i think we should add context pointer argument to that callback, which will force us to find a way to decouple these callback signatures and and find another solution for the de-duplication. maybe the generic config.c infrastructure should have an optional ""privdata"" pointer for each apply function, and it'll de-duplicate only if both the apply function pointer and the privdata are identical. then module.c will heap allocate some structure with the module pointer, and provide that together with some dispatcher function as callback. then that dispatcher can create a `redismodulectx` when calling the module apply callback?",0,0,0,0.9471212029457092,0.9835823774337769,0.8788513541221619,0.0,accept,unanimous_agreement
810637483,10285,"our strings have refcount, i don't think this is needed. we can pass the strings to the module, and then release them if not retained or copied.",0,0,0,0.9881316423416138,0.9596278667449952,0.9936054944992064,0.0,accept,unanimous_agreement
810637609,10285,maybe extend this example with something that checks the input and returns an error string.,0,0,0,0.98325115442276,0.9889336824417114,0.9836146235466005,0.0,accept,unanimous_agreement
810641215,10285,"i can't find code that does that. we must make sure the default value used for the config rewrite is the same one used as default for startup. and the only way to do that, is to use that default on startup (when the config didn't provide an explicit one)",0,0,0,0.941430687904358,0.9837070107460022,0.9833630323410034,0.0,accept,unanimous_agreement
811352385,10285,"i didn't necessarily want to traverse the entire configs array on every single config present in the .conf file. in this particular case, where its only module configs that can be removed, i considered it a runtime improvement. if we want this logic generalized, however, it makes sense to switch it to just isconfignameregistered.",0,0,0,0.9834862947463988,0.9905250668525696,0.9875396490097046,0.0,accept,unanimous_agreement
811353812,10285,"i considered this as well, and tend to agree. it's awkward to have it as part of ctx as well.",-1,-1,-1,0.9125447869300842,0.9500961303710938,0.9761328101158142,-1.0,accept,unanimous_agreement
811357043,10285,"the situation that this accounts for is 1. a module load with configs. 2. a rewrite. 3. a module unload, and then 4. another config rewrite. this causes the server to not start-up from the .conf file because the module configurations are still in the .conf file.",0,0,0,0.97163724899292,0.9882078766822816,0.993661403656006,0.0,accept,unanimous_agreement
811359399,10285,"i completely agree, but i found this to be somewhat out of scope. i think it makes more sense to make that part of a separate pull request",0,0,0,0.8518822193145752,0.9597655534744264,0.9117494225502014,0.0,accept,unanimous_agreement
811369518,10285,"i thought config_hidden was useful for the same reason we expose it, just to provide some functionality for testing but it should show up if you do `config get .*`.",0,0,0,0.9581953287124634,0.9901893734931946,0.9799514412879944,0.0,accept,unanimous_agreement
811372104,10285,"my personal opinion is that we should move all the configs to a dictionary, it optimizes a lot of the cases. i didn't necessarily want to do all that work here, so i was inclined to either do that as a follow up. maybe someone can do that in parallel.",0,0,0,0.7821125984191895,0.9061145186424256,0.9711914658546448,0.0,accept,unanimous_agreement
811375589,10285,"that's good to know, there are several other places in the code that use 128 as a magic number for the max serialized size of a long.",0,0,1,0.6943740248680115,0.7316585183143616,0.8872629404067993,0.0,accept,majority_agreement
811378537,10285,"if we have apply. i agree i think we could probably remove the set_ctx, which servers a similar role.",0,0,0,0.9776943922042848,0.9783350825309752,0.991280734539032,0.0,accept,unanimous_agreement
811632308,10285,"i prototyped it a bit here, [a link] i didn't notice that much perf changes. get, as implemented, will require a bit more work though.",0,0,0,0.9592706561088562,0.9026572704315186,0.9809401631355286,0.0,accept,unanimous_agreement
811642504,10285,[code block] only `module loadex ` is required now.,0,0,0,0.9890806674957277,0.9949722290039062,0.99516761302948,0.0,accept,unanimous_agreement
811718564,10285,"the server will fail startup after stage **2** in the above description (in case it doesn't start with the module). just the fact that we write module confs into the config file has the potential to cause a startup issue. but we still want to do so. so my suggestion is either 1. allow this, and in case of a startup issue the user will need to fix their config file. 2. **any** unrecognized config will be excluded during the rewrite (no matter if it's a module or not). or even better commented out during the rewrite. 3. extend module unload command to optionally rewrite the config during unload if we've performed a rewrite since the load. in this rewrite we explicitly skip this module's configs. (i'm for 2 with the ""comment"" extension)",0,0,0,0.968824863433838,0.9869303703308104,0.976000726222992,0.0,accept,unanimous_agreement
812323838,10285,"i'm not sure i love how this is being handled now, but we do no longer just remove configs from an old file instead we comment out the offending lines.",1,1,-1,0.7355060577392578,0.5462188124656677,0.8078046441078186,1.0,accept,majority_agreement
817306290,10285,use `define` for 32 and add some comments?,0,0,0,0.9883580803871156,0.9953836798667908,0.9953290224075316,0.0,accept,unanimous_agreement
817307218,10285,at the moment this is a place holder until i merge in [a link],0,0,0,0.9874929189682008,0.9902632236480712,0.9944485425949096,0.0,accept,unanimous_agreement
825251519,10285,this function name doesn't make that much sense being exposed publically. maybe we should write a wrapper for getconfigfromname + performinterfaceset,0,0,0,0.6621039509773254,0.9756681323051452,0.9579915404319764,0.0,accept,unanimous_agreement
825251628,10285,"you can check for the interface type == enum here, and then you don't need to keep track of the is_enum.",0,0,0,0.9887427091598512,0.9877548813819884,0.994751513004303,0.0,accept,unanimous_agreement
825251760,10285,"this needs to fail if the module config is doing extra validation on the set value, since it can reject it.",0,0,0,0.9730359315872192,0.8869755864143372,0.9896472096443176,0.0,accept,unanimous_agreement
825252774,10285,"i'm not sure we need these anymore, since we are going to use the type from config.c",0,0,0,0.97427499294281,0.9351813793182372,0.884954571723938,0.0,accept,unanimous_agreement
825253015,10285,"it doesn't look like we need this any more, since the module_config always stores a pointer to the module. the list can just store a list of the module_configs.",0,0,0,0.982079029083252,0.9900716543197632,0.9891768097877502,0.0,accept,unanimous_agreement
825253239,10285,probably more readable in this context. [code block],0,0,0,0.9867514371871948,0.9869186282157898,0.9721081256866456,0.0,accept,unanimous_agreement
825253356,10285,unused,0,0,0,0.9405757188796996,0.9426007866859436,0.96555495262146,0.0,accept,unanimous_agreement
825253365,10285,i'm not sure many of these are used outside of config.c,0,0,0,0.9505727887153624,0.6932156682014465,0.9369074106216432,0.0,accept,unanimous_agreement
825253958,10285,"we should parse these parameters ""before"" starting to do any loading. failing here for syntax errors just makes life more complex.",-1,0,0,0.6197118759155273,0.901509404182434,0.8993136286735535,0.0,accept,majority_agreement
825254186,10285,this code is unused now.,0,0,0,0.9607175588607788,0.9656882286071776,0.9909706115722656,0.0,accept,unanimous_agreement
825254436,10285,"this is likely not binary data safe, since sdssplitargs will split on spaces. if the value has a space it will break, we probably need to store this as something other than an sds pair. (like a tuple)",0,0,0,0.969302535057068,0.9726809859275818,0.9851322770118712,0.0,accept,unanimous_agreement
825255060,10285,"this being a macro is a bit weird and unexpected, i would also expect this to actually return a type. [code block]",-1,-1,-1,0.9782924056053162,0.946776807308197,0.988419771194458,-1.0,accept,unanimous_agreement
825255231,10285,"it should work okay with rust, you can specify a static lifetime string.",0,0,0,0.9876846075057985,0.9461253881454468,0.9930155277252196,0.0,accept,unanimous_agreement
825255439,10285,if you take my earlier suggestion to update `createmoduleconfig` [code block],0,0,0,0.9892325401306152,0.9917694330215454,0.9950878024101256,0.0,accept,unanimous_agreement
825255474,10285,"maybe use new_config instead of newenumconfig? it's also the only place you use camelcase for variable names in this pr, not sure if that was intentional.",0,0,0,0.9721882343292236,0.990880846977234,0.9646276831626892,0.0,accept,unanimous_agreement
825255888,10285,"listempty() should do the same thing here, and is a little bit clearer.",0,0,0,0.984504461288452,0.9870741367340088,0.9892390966415404,0.0,accept,unanimous_agreement
825256072,10285,moduleconfig is in server.h [code block],0,0,0,0.988486647605896,0.993740439414978,0.9944686889648438,0.0,accept,unanimous_agreement
825256520,10285,don't we also need to free the default sds string value?,0,0,0,0.9884493947029114,0.9936085939407348,0.9938178658485411,0.0,accept,unanimous_agreement
825257155,10285,"also, we should duplicate the default value and decrrefcount on the redismodule string, we only need to keep around the sds value.",0,0,0,0.988394856452942,0.9930422306060792,0.9945148229599,0.0,accept,unanimous_agreement
827729762,10285,"if only now we apply module configs, then there's no need to provide the `module_configs_apply` to the above call to `restorebackupconfig`",0,0,0,0.988389253616333,0.9938417673110962,0.9940261840820312,0.0,accept,unanimous_agreement
827731328,10285,this is a response to the discussion about not writing unknown configs? in that case: 1. please add a clear comment above this code block describing that it does / why. 2. please make sure this change is described in the pr top comment.,0,0,0,0.985166609287262,0.9940536618232728,0.9946653842926024,0.0,accept,unanimous_agreement
827900309,10285,trying to make this long line slightly shorter (removing excessive casting). [code block],0,0,0,0.9698293805122375,0.9827594757080078,0.9921506643295288,0.0,accept,unanimous_agreement
827903717,10285,do you remember why this was a define and not a function? i'm guessing it's a leftover from repeated refactoring we did. it doesn't look like it does any type checks these days (the value passed in is always a `long long`),0,0,0,0.9767298102378844,0.9842798709869384,0.9896905422210692,0.0,accept,unanimous_agreement
827907273,10285,"actually, since it also does `return`, i'd rather have that in a separate line. i.e. i don't mind putting the action of an `if` in the same line, but if that action changes the execution flow (break, continue, return, goto), i'd rather have it in a separate line. the exception is repeated error handling, where adding a check and a goto or return after each line, will bloat up the number of lines considerably, and make the actual code less readable [code block]",0,0,0,0.9649379253387452,0.9777307510375975,0.9840052127838136,0.0,accept,unanimous_agreement
827914385,10285,"we end up keeping a pointer to that dummy value (which is on the stack). let's make sure to nullify it on the next line. the other alternative is to nullify it in embedcommonconfig (when module_config is set), but that's before it is actually set, so we'll have to re-order things so that it'll be effective.",0,0,0,0.9838290810585022,0.9881089329719543,0.99143785238266,0.0,accept,unanimous_agreement
827943629,10285,"what's the point of this check? preparing for additional flags in the future? at the moment it looks silly. imho we should either drop it, or declare some mask next to redismodule_config_memory and check the mask here. (and change `numeric_flag` to `numeric_flags`) i'd vote to drop it, we can always extend it in the future.",-1,-1,-1,0.7925271987915039,0.9357991814613342,0.984956920146942,-1.0,accept,unanimous_agreement
827947806,10285,why do we need to get the prev value and release it? it this leftover from something? or does the module relies on us releasing it? (which i think is wrong!),-1,0,0,0.8664348125457764,0.9028042554855348,0.9816079139709472,0.0,accept,majority_agreement
827950570,10285,"or maybe escape them with sdscarrepr when we create that list? either way, let's add a test.",0,0,0,0.9849440455436708,0.9935043454170228,0.9932854175567628,0.0,accept,unanimous_agreement
827971412,10285,we're leaking the ctx in this return.,0,0,0,0.9791995882987976,0.8575047254562378,0.9937198162078856,0.0,accept,unanimous_agreement
827976697,10285,"why bother storing the return value back to `module->module_configs`? this list api will never re-allocate the list (the return value is only a dead-code error handling, with potential for some chaining). p.s. if we remove this, maybe there's no need for the `addmoduleconfigtolist` function, and we can just embed this code into the caller.",0,0,0,0.9842752814292908,0.9938780665397644,0.9867559671401978,0.0,accept,unanimous_agreement
827983846,10285,"i'd rather avoid string concatenation macros (`##`), makes it hard to grep the code. i think it'll be ok to expand this macro and add these two lines in each place. also, the name suggests that it deals with the default value, but it doesn't",0,0,0,0.9649983644485474,0.979382872581482,0.97849303483963,0.0,accept,unanimous_agreement
827997069,10285,"shouldn't that say `retrieves the value from the module` or something like that? the apply function's roles is not to `verify`, the set callback can do verification too (unlike the native redis configs which are just backed by a variable pointer, and an extra `is_valid` callback), for modules the set callback is the one that does the validation. p.s. i'm not sure if we should use uppercase `set` / `get` / `apply` in these docs (these can be used to refer to commands or sub-commands, but that's not what we do here). i think we better use `setfn` instead, and possibly quote it with ` for markdown docs. regarding the apply callback, instead of stating that it's for validation, we should state that: 1. it is only called by config set command (not on startup). 2. it can be used to apply a config after it (and several others) were changed atomically. 3. when config set changes a bunch of configs together, it is called only once (de-duplicated if the same callback pointer and privdata was used for several configs), we should probably mention that `setfn` is called on startup with either the default value or the one provided by the user, but the `applyfn` is not called on startup.",0,0,0,0.9698877930641174,0.9889238476753236,0.9861138463020324,0.0,accept,unanimous_agreement
828017272,10285,outdated,0,0,0,0.7892751693725586,0.9308403730392456,0.932908833026886,0.0,accept,unanimous_agreement
828018569,10285,i think we need to explicitly refer to `enable-protected-configs`,0,0,0,0.9885591864585876,0.9878072142601012,0.988598108291626,0.0,accept,unanimous_agreement
828019647,10285,"not sure i understand that line, or that i agree it's the right approach. i think the module needs to manage it's memory, and redis needs to increment refcount only if it keeps the pointer given by the module.",0,0,0,0.9518588185310364,0.9797813892364502,0.783379077911377,0.0,accept,unanimous_agreement
828023088,10285,"i don't understand the ""memory management"" of this sample code. i think we should only retain when we use the new value, in which case, we should free the previous one.",0,0,0,0.8853393197059631,0.709703266620636,0.8576722741127014,0.0,accept,unanimous_agreement
828027131,10285,"why do we need to `decrrefcount(default_val)`? so that users can forget about it and don't worry about releasing it? i don't think that's good, if we would have decided to keep a reference we should have incremented it, but since we copied it, i think we should't mess with the refcount.",0,0,-1,0.967004895210266,0.9664174914360046,0.6292920708656311,0.0,accept,majority_agreement
828029598,10285,"looking at the other sample code we have (e.g. `rm_call`). we use `*` in the beginning of each line in the examples too. i'm not sure what the markdown formatter does, i'd rather stick to the same practice. p.s. do that for other examples too",0,0,0,0.9747514724731444,0.9825301766395568,0.973816454410553,0.0,accept,unanimous_agreement
828030991,10285,missing a newline.,0,0,0,0.5537136793136597,0.9417330026626588,0.947834014892578,0.0,accept,unanimous_agreement
828032997,10285,let's mentioned it should be called in `rm_onload`,0,0,0,0.9876890182495116,0.9923863410949708,0.9956566095352172,0.0,accept,unanimous_agreement
828034779,10285,"nit pick, we're inconsistent about adding spaces, but let's at least be consistent within the line 8-) [code block]",0,0,0,0.9439651966094972,0.6314234137535095,0.8741335868835449,0.0,accept,unanimous_agreement
828039944,10285,"this will abort the process if a user provided a config in the config file, and we didn't find any module that claimed it, right? i think we should also abort if the module registered configs and didn't call the load api. i.e. catch that programmer error even if the user didn't pass any config at loading time. wdyt?",0,0,0,0.9846503138542176,0.9508333206176758,0.9892654418945312,0.0,accept,unanimous_agreement
828044664,10285,"this will fail if the user provided configs to loadex and they where either not recognized by the module, or it forgot to call the load api, right? maybe we should also cover the case that the module registered configs and forgot to call the load api? i.e. even if the user didn't pass configs, or used just module load and not module loadex? wdyt?",0,0,0,0.9793597459793092,0.9773194193840028,0.9883878827095032,0.0,accept,unanimous_agreement
828047795,10285,"i think this is the place where we're also suppose to apply the default values to the module. i.e. call the `setfn` callback with either the value provided by the user, or the default value. if we don't call the setter with the default value on load time, we can get a case where there's a mismatch between the default value for execution, and the default value for rewrite. to do that, i suppose we need to change the loop to iterate over the registered configs, rather than the ones provided by the user (module_configs_queue).",0,0,0,0.9841302037239076,0.9922337532043456,0.9865647554397584,0.0,accept,unanimous_agreement
828251186,10285,"my recollection was that it was needed at some point since we had a places where val was either unsigned or signed, it looks like that isn't required any more.",0,0,0,0.9454282522201538,0.9912853837013244,0.9883721470832824,0.0,accept,unanimous_agreement
828513541,10285,"probably add some documentation for this, since it's hard to follow without context.",0,0,0,0.976892113685608,0.9803423285484314,0.969167709350586,0.0,accept,unanimous_agreement
828554752,10285,"this is currently how it works, ill add a test to clarify that.",0,0,0,0.9721117615699768,0.9334478974342346,0.9903766512870787,0.0,accept,unanimous_agreement
828634656,10285,"server panic here instead, this isn't valid.",-1,0,0,0.707635223865509,0.5481279492378235,0.6621146202087402,0.0,accept,majority_agreement
828638071,10285,"maybe we should have an error label at the end of the function, so that we don't have duplicate places where we fail loading.",0,0,0,0.978659212589264,0.9853832721710204,0.975658118724823,0.0,accept,unanimous_agreement
828641501,10285,"pin: we should document that get() does not consume the string, so if the client is doing any type of transformation it knows its still valid afterwards.",0,0,0,0.988920032978058,0.9884491562843324,0.992617666721344,0.0,accept,unanimous_agreement
828645837,10285,"[code block] i know it's not widely done it redis, but we should try to respect apis.",0,0,0,0.9821616411209106,0.9904706478118896,0.9803078770637512,0.0,accept,unanimous_agreement
828656277,10285,i'm going to recant what i said earlier and still think we should do sdscatrepr here for the variable name. otherwise we might fail to parse it later. it's a simpler invariant to maintain that this is always properly formed.,0,0,0,0.978851079940796,0.9750357270240784,0.988830864429474,0.0,accept,unanimous_agreement
828662431,10285,i still believe this logic can be in the modulecommand() function. it's then possible to have the parseloadexarguments actually reply with a useful human message. generally the best practice is to do validation of input parameters before any actual work. (i think on failure this leaks the open handle too),0,0,0,0.8942517638206482,0.977185070514679,0.9864553213119508,0.0,accept,unanimous_agreement
828674839,10285,[code block] |= i guess also works? seems not right though.,0,0,0,0.8836052417755127,0.9307016730308532,0.97351336479187,0.0,accept,unanimous_agreement
828679380,10285,"we call this an integer, but everything else is called numeric. let's make it consistent.",0,0,0,0.9835712909698486,0.9805737137794496,0.9904412031173706,0.0,accept,unanimous_agreement
828683538,10285,we need an errno for invalid name i suppose?,0,0,0,0.9842256307601928,0.9584349393844604,0.9913859367370604,0.0,accept,unanimous_agreement
828690956,10285,"made a related comment, but i think we should make sure this is can't happen so we can serverpanic here instead.",0,0,0,0.9861278533935548,0.9665800333023072,0.989050269126892,0.0,accept,unanimous_agreement
828693507,10285,might to severassert() that config is not null.,0,0,0,0.9852756261825562,0.9831423759460448,0.9833645224571228,0.0,accept,unanimous_agreement
828696535,10285,"let's test string as well, since we know there are some memory issues handling constraints.",0,0,0,0.9866058230400084,0.990052044391632,0.9904900789260864,0.0,accept,unanimous_agreement
828697337,10285,"maybe also add a test for configs that don't exist, and/or owned by different modules.",0,0,0,0.9862853288650512,0.9920816421508788,0.9893117547035216,0.0,accept,unanimous_agreement
828698322,10285,"going to be slightly paranoid and say let's remove ""log4j"" so nobody asks why we have log4j in our repo.",-1,-1,0,0.7488356232643127,0.5327829122543335,0.7026230692863464,-1.0,accept,majority_agreement
828801206,10285,"what do you mean? it already aborts the process when the module didn't call the load api, even if the user didn't actually provide any configs? can you show me what i'm missing?",0,0,0,0.9809957146644592,0.9122129082679749,0.9925230145454408,0.0,accept,unanimous_agreement
829301590,10285,"oh, sorry bout that, i misread the question, we should abort if configs are registered and no loadconfigs is called. i'll add this functionality.",-1,-1,-1,0.9897693395614624,0.9911755323410034,0.987046241760254,-1.0,accept,unanimous_agreement
832896015,10285,"there is ci fail in the fully ci of this pr: [a link] [code block] at this time, only using `argv[0]` cannot determine whether the configuration already exists. [code block]",0,0,0,0.975823938846588,0.9950409531593324,0.99358469247818,0.0,accept,unanimous_agreement
833101511,10285,debug prints? don't forget to remove...,0,0,0,0.9812605381011964,0.9172932505607604,0.990688681602478,0.0,accept,unanimous_agreement
833194243,10285,"if the same config is provided twice, this break would mean we used the first one rather than the last one. maybe considering the unpleasant nested loop, we rather store module_configs_queue in a dict? this will eliminate both the nested loop and the issue with duplicate configs. p.s. let's add a test for that.",0,0,0,0.9823471307754515,0.9800207614898682,0.9897961020469666,0.0,accept,unanimous_agreement
833197224,10285,why bother resetting this variable? (initialized when the next iteration starts...,0,0,0,0.5127020478248596,0.9838363528251648,0.9785727262496948,0.0,accept,unanimous_agreement
833199571,10285,"maybe we want to print a log message with something about the contents of the list? e.g. at least one entry. p.s. considering we do that only for loadex, maybe it's a hint to indicate that this shouldn't be here.. i.e. for the case of server startup, we do that after done loading all modules, and for the case of loadex we do that in the loadex command? this will also mean that this function doesn't need to take the `is_loadex` argument (which is a win imho)",0,0,0,0.9830034971237184,0.9108911752700806,0.9190687537193298,0.0,accept,unanimous_agreement
833216113,10285,"i see you renamed it, but it still uses string concatenation `##` but also, i see it's no longer used, so i guess you just forgot to delete it?",0,0,0,0.98164165019989,0.9926008582115172,0.9913144707679749,0.0,accept,unanimous_agreement
833217460,10285,leaking `config_name` (applies to other similar apis as well),0,0,0,0.9773796200752258,0.9943122863769532,0.9917424917221068,0.0,accept,unanimous_agreement
833221919,10285,"since rm_registerstringconfig holds the documentation for the rest of them, i think it's better to put it first (in case someone reads the docs top-to-bottom.",0,0,0,0.9837024211883544,0.9868767261505128,0.9888206720352172,0.0,accept,unanimous_agreement
833236799,10285,"[code block] all of that won't actually be needed since i think loadmoduleconfigs doesn't need to take that argument, and instead the validation that there are no configs unhandled should be in the loadex command itself. actually it also means that we can remove `is_loadex` from the module context (triple win). now if only we can find a way to also find a way to get rid of the excess `load_configs_called` member (present in all contexts, even ones not used for the module loading), that would be great.",0,0,0,0.9802820682525636,0.7650325298309326,0.6452885270118713,0.0,accept,unanimous_agreement
833260764,10285,can't we use the `module_configs` list for that instead of this boolean?,0,0,0,0.9871447682380676,0.9948981404304504,0.9942455887794496,0.0,accept,unanimous_agreement
833316060,10285,better to return a redismodulestring so there won't be an ownership issue,0,0,0,0.9737051129341124,0.9822101593017578,0.989064395427704,0.0,accept,unanimous_agreement
833537356,10285,"should absolutely have a log message, this is included only for loadex due to the situation where multiple modules with configs are loaded from a .conf file. the reason its currently located here is for a rather esoteric edge case where a string config is initialized, and theres a bad argument to loadex. if we do the length check after onload is completed, the module author never gets the chance to free the string.",0,0,0,0.6858128309249878,0.8735655546188354,0.9866870641708374,0.0,accept,unanimous_agreement
833569512,10285,"you mean that we can return an error to rm_loadconfigs in that case? i'm not sure that's right.. arguably the module did everything right, and it's just that the user passed an invalid argument to loadex, so loadex could return an error, and possibly unload the module. or if we can't / don't wan to unload the module, maybe it's ok to return an error that indicates the module was loaded but the configuration failed... also, i suppose logging a message to the log file with the name of the invalid config is not enough.. maybe we better have that as part of the reply?",0,0,0,0.9233352541923524,0.8397306203842163,0.875527560710907,0.0,accept,unanimous_agreement
834040171,10285,should be `addmoduleconfigapply`?,0,0,0,0.9865903854370116,0.9947269558906556,0.9952270984649658,0.0,accept,unanimous_agreement
834515398,10285,i believe we no longer need to sdscatrepr here due to the conversion from list->dict. not entirely sure i'm not missing anything here.,0,0,0,0.6311081647872925,0.9262568354606628,0.9797601103782654,0.0,accept,unanimous_agreement
834634335,10285,maybe we can check `server.sentinel_mode` instead of that string compare? i.e. disable that feature in sentinel mode completely?,0,0,0,0.9884164929389954,0.9956566095352172,0.990014672279358,0.0,accept,unanimous_agreement
834636362,10285,"i suppose you're right (no longer need sdscatrepr), since we also no longer join and split strings (glad to see that gone, it bothered me a lot). but please be sure to include a test with a config set to a value that contains spaces, and even null chars.",0,0,1,0.9466949105262756,0.8912965059280396,0.6441381573677063,0.0,accept,majority_agreement
834638357,10285,please add a top comment describing what the function does and what it's used for.,0,0,0,0.9849772453308104,0.9845646619796752,0.9927076697349548,0.0,accept,unanimous_agreement
834639464,10285,"correct me if i'm wrong, this loop will never run more than one iteration, right? i.e. we can tell by the first config if it was initialized or not. so we traded a single boolean in a module context (many instances of these), to a boolean per config (many instances of these too). not sure which one i like less...",-1,-1,-1,0.8863219022750854,0.9398571848869324,0.6982866525650024,-1.0,accept,unanimous_agreement
834639975,10285,"btw, the one thing that is almost consistent in redis, is that we avoid line comments (`//`). (the other is that the opening curly brace is in the same line of the `if`, unless it's a multi-line condition)",0,0,0,0.9847546815872192,0.9923926591873168,0.9914763569831848,0.0,accept,unanimous_agreement
834648861,10285,"maybe the `performmoduleconfiginitfromname` function should have the word ""default"" or even ""defaultvalue"" in it?",0,0,0,0.9885503649711608,0.9952359795570374,0.989948272705078,0.0,accept,unanimous_agreement
834680483,10285,wdyt about a single boolean in the module struct itself?,0,0,0,0.9873998165130616,0.989920973777771,0.99260675907135,0.0,accept,unanimous_agreement
834682447,10285,"i'm shocked i didn't think of that option 8-). i guess i was hung on thinking it should be put in a struct that's transient and not long-lived, but that's not a real concern. if we need just one boolean per loaded modules, that's obviously it's place.",1,-1,-1,0.660016655921936,0.9687549471855164,0.4451744258403778,-1.0,accept,majority_agreement
834918199,10285,"here 1 is failure, but in `moduleconfigapplyconfig`, 0 is failure, i think we should avoid this confusion. [code block]",0,0,0,0.9731691479682922,0.9897454977035522,0.9892724752426147,0.0,accept,unanimous_agreement
835853623,10285,p.s. why did we move this function? can we bring it back above `moduleunload` to make for a smaller diff and less blame log damage?,0,0,0,0.987052857875824,0.9941032528877258,0.9603965878486632,0.0,accept,unanimous_agreement
835856864,10285,"reviving this topic in a new thread, since the previous one is lost far above. maybe we want a `redismodulestring *err` so that modules can format the string and not have to rely on a static one.",0,0,0,0.9849812984466552,0.9905363917350768,0.9911943674087524,0.0,accept,unanimous_agreement
835857448,10285,"we must nullify this otherwise we'll attempt to free an uninitialized pointer, or can't distinguished between old one that should be freed and null. [code block]",0,0,0,0.9849883317947388,0.9883710741996764,0.991853415966034,0.0,accept,unanimous_agreement
835857625,10285,"i don't understand this comment, but it smells like it's covering a bug. the code looks valid, i.e. if we get a value that we wanna reject, we return an error, and keep (avoid freeing) the old pointer. so maybe the comment about the leak is outdated? p.s. let's return some error string in `*err` to test that infra.",0,0,0,0.8612887859344482,0.960323691368103,0.949686884880066,0.0,accept,unanimous_agreement
835857926,10285,"in theory, it would been much easier if the default value for strings would have been a plain `char*`, so modules would have been able to use a static string and avoid all the mess around heap allocations. however, doing that would mean that default values can't contain null chars. maybe that's acceptable?",0,0,0,0.978140354156494,0.98404723405838,0.975886046886444,0.0,accept,unanimous_agreement
835858577,10285,"maybe make that redismodule_loadconfigs call conditional (depending on an `argv` argument), this way we can add code to test the case that it's not called.",0,0,0,0.9879435300827026,0.9943850040435792,0.9902532696723938,0.0,accept,unanimous_agreement
835858746,10285,"if we free `strval` before unload, don't we also need to nullify the pointer? otherwise we'll free it twice.",0,0,0,0.988257110118866,0.992262363433838,0.9915894865989684,0.0,accept,unanimous_agreement
835859293,10285,"so this part tests loading modules and configs, from the config file, right? mabe add a comment, since whoever misses it may think this is completely uncovered.",0,0,0,0.9864619374275208,0.9699637293815612,0.9941654205322266,0.0,accept,unanimous_agreement
835859728,10285,"actually, this way we have no way to test what happens when loading a module with configuration error from config file. let's add a test that loads a module from config file. hints: 1. `testrdb.tcl` does it, you can copy some code from there. 2. the test infra doesn't support passing the same config to `start_server` twice, so don't try to test two modules from a config file. please also add tests for rejected configs, and missing loadconfig calls for this path.",0,0,0,0.982182800769806,0.9908816814422609,0.9928643703460692,0.0,accept,unanimous_agreement
835910935,10285,this seems good. originally i suggested commenting out these lines instead of completely removing them. wdyt?,1,1,1,0.9444479942321776,0.8361587524414062,0.8977065682411194,1.0,accept,unanimous_agreement
836709259,10285,"i don't necessarily feel particularly strongly either way. it is also a larger question for the future i think, as there may be future use cases where configs only exist for a certain period of runtime. to me it feels somewhat more intuitive that they would be removed because they're part of the module, and modules that are unloaded get their load directives removed on a rewrite (if present), but again i don't feel all that strongly.",-1,0,0,0.7784342765808105,0.6190085411071777,0.903275728225708,0.0,accept,majority_agreement
836901930,10285,"the contract can be that on our side is that we don't mutate or retain a pointer to it, just copy the value out. the caller is then free to pass back a reference it retains so that it can be freed or modified later. the reason configs use char *err instead of sds is because the vast majority of cases don't need special allocation or handling. i think the proposed approach would just introduce a lot more creating of strings.",0,0,0,0.973977029323578,0.9895413517951964,0.987932026386261,0.0,accept,unanimous_agreement
836902092,10285,i think the current implementation makes more sense of passing in a string. i would somewhat prefer that we call decrrefcount though within redismodule_registerstringconfig so that you don't have to worry about freeing it otherwise.,0,0,0,0.9643051624298096,0.9636365175247192,0.9456806182861328,0.0,accept,unanimous_agreement
836913082,10285,[code block] i still don't think we should be converting empty strings to null. it seems more straight forward to give the module the empty string and it can decide what to do with it.,0,0,0,0.9745080471038818,0.9784149527549744,0.9773455858230592,0.0,accept,unanimous_agreement
837074849,10285,"ok, you suggest that it'll remain a `char*`, and then the module can either use a static string, or some global pointer to a heap allocated one, which it releases next time / later. would that work for the non-c modules too?",0,0,0,0.9878222346305848,0.993621289730072,0.9932442307472228,0.0,accept,unanimous_agreement
837075743,10285,"i guess even changing this in the future won't be a breaking change, and we do want to avoid a situation where the re-written config keeps growing because we're inserting comment lines. so i'm fine with leaving this as is.",0,0,0,0.9252192974090576,0.9770734906196594,0.9249126315116882,0.0,accept,unanimous_agreement
837075759,10285,"i understand that for the majority of the cases that would be easier to use, but the interface seems odd to me. wdyt?",0,-1,-1,0.6510951519012451,0.6956544518470764,0.814669668674469,-1.0,accept,majority_agreement
837078778,10285,"i gave it some thought and here are a few points i have: [1] this is probably not a common issue (doing config rewrite, then module unload and config rewrite again). [2] removing a line with a config could mean that it leaves behind some comment documenting that line. i think this is bad. e.g. [code block] so i think we should comment these lines, but it can be maybe done in a followup pr, not a mandatory task for this one.",-1,0,-1,0.951141119003296,0.885199785232544,0.8778862953186035,-1.0,accept,majority_agreement
837168329,10285,let's match against the actual error message (`cannot set string to 'rejectisfreed'`),0,0,0,0.9858524799346924,0.9945712685585022,0.9929479360580444,0.0,accept,unanimous_agreement
837191882,10285,i think that for configuration it makes sense to pass `const char*` and its acceptable that it can not contains null chars.,0,0,0,0.9822560548782348,0.9803476333618164,0.9800485372543336,0.0,accept,unanimous_agreement
837218031,10285,"i actually like the original idea of passing a newly allocated redismodulestring that redis frees. it's simple, flexible and i don't see why it should be incompatible with non-c modules.",1,1,1,0.7988194823265076,0.7143074870109558,0.9062455892562866,1.0,accept,unanimous_agreement
837235109,10285,"agree with , i don't see why a `const char *` wouldn't be enough. but if we do have a good reason to use a redismodulestring, i agree with we should transfer ownership so the caller doesn't need to free it.",0,0,0,0.9738396406173706,0.983050525188446,0.9534509181976318,0.0,accept,unanimous_agreement
837242748,10285,"i think both options are a bit odd, but i suppose it's unlikely that a module will want a default value for a config to contain null chars, and i suppose ones that do, can find an ugly way around it. so maybe a plain `char*` would be most convenient.",0,-1,-1,0.5290917754173279,0.5906688570976257,0.7139078974723816,-1.0,accept,majority_agreement
837246746,10285,"allocating redismodulestring is surely compatible with everything. the question was if using a plain `char*` (without passing ownership) is acceptable. at least for c modules, it's much more convenient since usually the errors are static string. and as madolson suggested, modules can even use a global buffer, and format a message into it (as long as redis grantees to copy it right away)",0,0,0,0.97428560256958,0.8958309888839722,0.9894082546234132,0.0,accept,unanimous_agreement
839304991,10285,"i reproduced the fail test on alpine, when i comment out this line test is ok. but i didn't find out the real reason why, no stack on alpine is too painful.",-1,-1,-1,0.5092934370040894,0.9232086539268494,0.7962627410888672,-1.0,accept,unanimous_agreement
839306594,10285,"this line should be wrong, it should be `redismodule_freestring`, but it's not the cause of the test failure.",0,0,0,0.8950385451316833,0.9805034399032592,0.9563597440719604,0.0,accept,unanimous_agreement
839398149,10285,"it's interesting that valgrind doesn't report that leak (leaking the actual string). i suppose the tcl test code doesn't set the string twice (replacing a previous one). it's also odd that the alpine code crash on some corruption, but valgrind doesn't report anything.",0,0,0,0.955760657787323,0.88494473695755,0.8848189115524292,0.0,accept,unanimous_agreement
839409440,10285,actually i see we do have a test that does it. so i don't know why valgrind doesn't report the leak. [code block],0,0,0,0.9734579920768738,0.9738787412643432,0.9887711405754088,0.0,accept,unanimous_agreement
839421725,10285,"yoav helped me figure this out. it must be an embedded string, so being short the robj pointer holds the sds in the same allocattion.",0,0,0,0.9812135100364684,0.9660949110984802,0.9606265425682068,0.0,accept,unanimous_agreement
839423885,10285,the only thing i can think of is that on alpine the dynamic library loader doesn't properly inits the global (maybe when the module is unloaded and reloaded). can you try to init that global to null from the `onload` function and see if it helps?,0,0,0,0.973334789276123,0.9929446578025818,0.992926299571991,0.0,accept,unanimous_agreement
839441323,10285,you guessed it right. strval needs to be reset to null after free. change code to following will be ok: [code block],0,0,0,0.9845207333564758,0.9835073947906494,0.9895365238189696,0.0,accept,unanimous_agreement
839468641,10285,please make a pr to fix both issues.,0,0,0,0.975550889968872,0.9864365458488464,0.9917173981666564,0.0,accept,unanimous_agreement
840734025,10285,"i did test and confirm this was the case, i specifically asked for the case to make sure we weren't mismanaging the allocation, forgetting about embedded strings.",0,0,0,0.9832487106323242,0.9822694659233092,0.992916226387024,0.0,accept,unanimous_agreement
1181196681,12109,"if this is an anonymous map (not a file), why use mmap and not just malloc? is it in order to gradually grow that buffer? what about gradually shrinking it (dismissing the parts we processed an no longer need)? i think it's better to use a linked list of constant size buffers like we do in `replbacklog`",0,0,0,0.9826825857162476,0.992449164390564,0.9887953996658324,0.0,accept,unanimous_agreement
1181198598,12109,"i wouldn't want to add a config for that thing. redis should just do the right thing by default (considering it doesn't have any drawbacks), and if a capabilities negotiation is needed. we could work around that disk-based issue (by adding some delay like repl-diskless-delay to disk-based). another possible issue could have been cloning the cob when a new replica joins an existing fork, maybe that can now be mitigated by the shared replication buffers and backlog up to a point (the backlog size). anyway i don't think disk-based is a critical issue to solve since diskless is the default nowadays and it doesn't have any significant disadvantages.",0,0,0,0.9516270756721495,0.9784082174301147,0.973889410495758,0.0,accept,unanimous_agreement
1181209314,12109,"this config isn't documented, but i wonder if we need / want it anyway, and if not, what should be the default value. considering any default other than unlimited would be wrong, setting it too low can cause nearly every user to be forced to adjust it, setting it too high, is similar to setting it to unlimited, it'll not do enough to protect the system, and if users don't experience issues, they might not tune it. today, replication buffers are excluded from eviction and oom (because eviction can cause a feedback loop when issuing dels), that's not the case with this buffer, however, replicas can't do eviction or oom. on the other hand, `client-output-buffer-limit` (for replicas) is by default set to 256mb, after which the client is disconnected. maybe we can inherit the value from that config, which could already be tuned, instead of forcing people to set this one on upgrades?",0,0,0,0.886926531791687,0.9323341250419616,0.9320546984672546,0.0,accept,unanimous_agreement
1181217300,12109,"there are several advantages to using mmap for allocating memory: 1. anonymous mappings can reduce fragmentation 2. unampping actually gives the memory back to the os. 3. a single pointer is easier to use (compared to a linked list, we get a contiguous virtual memory), easier means less maintenance overhead. 4. map_hugetlb can be used. when mmap is used with exponential growth factor, less reallocations are required than when linear growth is used for linked lists. for example, for linked list with 1024*16 as block size it will take around 6000 allocations to reach size of 1mb, comparing to ~30 using exponential grows factor. right now we free the buffer when we are done streaming it. we can consider shrinking it gradually, however the replica local streaming part is blocking so i am not sure freeing space is necessary.",0,0,0,0.9519546031951904,0.989471435546875,0.9601168632507324,0.0,accept,unanimous_agreement
1181219973,12109,"once the feature will be stable, the feature flag can stay on. i prefer removing the feature flag at a later stage. a delay before starting disk based sync will work. there is a downside of longer syncs, but it is a good workaround. regarding issue upon cloning the cob when a new replica joins an existing fork. do you mean while using disk based sync? and at which step this new replica joins?",0,0,1,0.8047701120376587,0.984128475189209,0.770552396774292,0.0,accept,majority_agreement
1181220886,12109,"i'm not sure these advantages are really right or justified. 1. that argument about reducing fragmentation can be said about anything else in redis. i.e. if each buffering subsystem will manage it's own memory directly to os, and return it in the right order, rather than the allocator, it'll avoid fragmentation. on the other hand, the allocator let's you share things, so by not using the allocator, you're also not plugging fragmentation holes created by other subsystems. i don't think that's a reason to use mmap. besides, working with buffer chunks bigger than a page, isn't susceptible to fragmentation. 2. arguing that unmapping immediately gives the memory to the os immediately, can be seen as a disadvantage, there's a reason why allocators don't immediately do it, it improves performance. if you think you can do better than jemalloc maybe starts a competing allcator :stuck_out_tongue: 3. that's certainly true if you don't bother to dismiss its head :smile: 4. i'd argue that this is a premature optimization. without showing any benchmarks or explicit reasoning, i'd go with the typical / simple approach. 5. not sure i understand the exponential growth thing. i suppose you can do the same with a greedy growth mechanism (allocating bigger blocks), and i suppose it can be counted as an advantage or a disadvantage. 6. the replica applies that buffer (calls processinputbuffer) in a blocking manner, but this loop consumes memory (processing commands that could be growing to the database), so releasing memory during that loop is desired. 7. the one advantage of a contiguous buffer that i can see, is that it would have been interesting to reduce the need of copying that data form that buffer to the query buffer, but i'm not sure it would be worth the complexity.",0,0,0,0.8031491637229919,0.8724368810653687,0.5879952907562256,0.0,accept,unanimous_agreement
1181225187,12109,"i agree with the above concerns, i don't like using `client-output-buffer-limit` because in most cases until the sync is done, this replica is worthless. we may use `client-output-buffer-limit` in cases when the replica is currently serving clients.",-1,0,0,0.7536142468452454,0.8087529540061951,0.9324119091033936,0.0,accept,majority_agreement
1181227094,12109,"see copyreplicaoutputbuffer. i.e. in a disk-based master, a replica that joins an existing fork inherits the cob from another one waiting for the same fork. this should be impossible now, but we can keep the fork's repl offset in some server var, and check if it happens to still exist in the backlog. anyway, diskless is the future, so i'm not certain we'd wanna invest here.",0,0,0,0.967758059501648,0.986136555671692,0.9820547103881836,0.0,accept,unanimous_agreement
1181246181,12109,i agree that not sharing memory and filling holes has its drawbacks. also not releasing memory during the loop can be harmful. identifying which method is the most effective will be challenging. i will move to linked list :thumbs_up:,-1,1,1,0.7429757118225098,0.579179048538208,0.9074352383613586,1.0,accept,majority_agreement
1181596277,12109,"[code block] if we return inside an if block, there is no need to use else if. we can simply use if statement.",0,0,0,0.988582730293274,0.992197573184967,0.9947882890701294,0.0,accept,unanimous_agreement
1182379470,12109,thanks :thumbs_up:,1,1,1,0.925590991973877,0.9691943526268004,0.9951086640357972,1.0,accept,unanimous_agreement
1201502395,12109,"[code block] i'm not really sure we need this new api, i think this pattern is much more common and easier to follow",0,0,0,0.8009888529777527,0.91622132062912,0.9810943603515624,0.0,accept,unanimous_agreement
1201505777,12109,shouldn't this be like a sync write? it seems possible this might be a partial write.,0,0,0,0.9750900268554688,0.9756431579589844,0.9831164479255676,0.0,accept,unanimous_agreement
1201508492,12109,"do we need this step? my understanding is that the replica will start sending ""replconf ack"" once it is only, why do we need a new mechanism to indicate we are online?",0,0,0,0.977217733860016,0.9891694784164428,0.991004467010498,0.0,accept,unanimous_agreement
1201508604,12109,do we know why this is causing a merge conflict?,0,0,0,0.9566247463226318,0.9832009077072144,0.9844979643821716,0.0,accept,unanimous_agreement
1201510528,12109,"these are no longer accurate, need to bumpt hem up.",0,-1,-1,0.5297322273254395,0.8115074038505554,0.9920850396156312,-1.0,accept,majority_agreement
1201512890,12109,"i don't think we should artificially change the state to transfer to avoid the server assert in the function. also, this functions documentation is ""don't call this function directly"", so it seems like we should honor that.",0,0,0,0.9813003540039062,0.9762566089630128,0.9765824675559998,0.0,accept,unanimous_agreement
1201809909,12109,"thanks, fixed",1,1,1,0.80034339427948,0.8649866580963135,0.7960073947906494,1.0,accept,unanimous_agreement
1201838656,12109,"i agree regarding the artificial change, i will fix that. in regards to calling replicationabortsynctransfer directly, the documentation also states ""...use cancelreplicationhandshake() instead."". by calling replicationabortsynctransfer from within cancelreplicationhandshake, i feel like i honor the request :grinning_face_with_smiling_eyes: i will refactor it now that i understand there is no real difference between aborting normal sync and aborting rdb channel sync",1,0,1,0.7972476482391357,0.8940998911857605,0.963143825531006,1.0,accept,majority_agreement
1201843118,12109,"yes, we can use replconf ack instead of replconf connect. i missed that.",-1,0,0,0.899793267250061,0.9769679307937622,0.9858322143554688,0.0,accept,majority_agreement
1201867888,12109,"this should be corrected, thanks",1,1,1,0.928995966911316,0.7269994616508484,0.8989659547805786,1.0,accept,unanimous_agreement
1201902139,12109,i somehow replaced all the tabs with spaces. fixing now,0,0,0,0.9786732792854308,0.8154576420783997,0.9886946082115172,0.0,accept,unanimous_agreement
1243397394,12109,"return without flag the client ""client_slave"", then the normal client may be killed if users set timeout.",0,0,0,0.9554653167724608,0.9786040782928468,0.9916656613349916,0.0,accept,unanimous_agreement
1243420699,12109,"should use ""client_type_slave"" here",0,0,0,0.9870785474777222,0.9944297671318054,0.9953546524047852,0.0,accept,unanimous_agreement
1249355753,12109,"this is the main connection of the replica, not a normal client. replication data will be transmitted via this channel, we don't want to treat this replica as a normal client",0,0,0,0.9735325574874878,0.9834802746772766,0.989803671836853,0.0,accept,unanimous_agreement
1249359774,12109,"this buffer is on the replica side, so it's a bit misleading. during the full sync, the replica received online replication data through the main channel and buffered it. this is all replica flow, so the client type slave is out of context.",0,0,0,0.8861587047576904,0.6073915362358093,0.9538357853889464,0.0,accept,unanimous_agreement
1261243474,12109,we should probably use the same mechanism we have in the other reply lists. i.e. a `buf[];` which takes responsibility of the real malloc_usable_size (internal fragmentation),0,0,0,0.988227903842926,0.994806945323944,0.9931864738464355,0.0,accept,unanimous_agreement
1261246322,12109,"the list keeps track of the len, so what's `len` for? is it the total size of used memory or data? comment is needed.",0,0,0,0.9882861971855164,0.9934843182563782,0.9947679042816162,0.0,accept,unanimous_agreement
1261248795,12109,"this one doesn't need to be atomic, right?",0,0,0,0.977348804473877,0.9542074203491212,0.9883268475532532,0.0,accept,unanimous_agreement
1261251618,12109,"too long. but also the term we use for now is ""master"", let's avoid causing further confusion and mix terms. [code block]",0,0,0,0.983171284198761,0.9491620659828186,0.7856513857841492,0.0,accept,unanimous_agreement
1261253557,12109,"if we have this here, why we need the repldatabuf struct declared above? comment is needed to indicate what `len` tracks.",0,0,0,0.9869153499603271,0.9945406317710876,0.9935604333877563,0.0,accept,unanimous_agreement
1261284864,12109,"i think we should have just one place that matches `slave_req` and changes `replstate`. i.e. finds the replicas that are waiting and match our fork matches their requirements, then activates them (changes `replstate`) all other places should just check the `replstate`, and avoid looking at `slave_req`. we do that in rdbsavetoslavessockets, and we can do that in rdbsavebackground too if needed. p.s. there's an indentation issue.",0,0,0,0.9862983822822572,0.986646056175232,0.9875038266181946,0.0,accept,unanimous_agreement
1261308724,12109,"should this be done with connsyncwrite? or like rdbsaveriowitheofmark using riowrite? does it need to belong in replication.c or rdb.c? if it's part of the replica 2nd channel negotiation, it should be in replication.c if we consider it the rdb payload header, then it should be in rdb.c and use riowrite.",0,0,0,0.9882782101631165,0.9953110814094543,0.994159698486328,0.0,accept,unanimous_agreement
1261314104,12109,"btw, don't we need to revive rioinitwithfdset, or a similar one writing to multiple conns (mix of rioinitwithfdset and rioinitwithconn)? i.e. from what i can tell this pr still uses the pipe, am i missing anything?",0,0,0,0.980991780757904,0.9882652759552002,0.9906536936759948,0.0,accept,unanimous_agreement
1261316747,12109,"p.s., we do still need to keep the pipe mechanism in case the replica doesn't support 2nd channel.",0,0,0,0.9854472875595092,0.9914422631263732,0.9926976561546326,0.0,accept,unanimous_agreement
1261327047,12109,why are these in server.c and not replication.c?,0,0,0,0.9823854565620422,0.9923708438873292,0.9915345311164856,0.0,accept,unanimous_agreement
1261331847,12109,p.s. i think #11125 is a prerequisite for this pr.,0,0,0,0.8417638540267944,0.9833745956420898,0.9926390647888184,0.0,accept,unanimous_agreement
1261349119,12109,"how is that ""partial sync"" state? [code block] maybe `slave_state_background_rdb_load` should be `slave_state_bg_transfer`? or maybe i'm misreading something...",0,0,0,0.5312044620513916,0.9714853763580322,0.9841858744621276,0.0,accept,unanimous_agreement
1261350586,12109,"should that have a `mem_` prefix? or do we want to put it in the ""replication"" section?",0,0,0,0.987500250339508,0.9955103397369384,0.993578553199768,0.0,accept,unanimous_agreement
1261378484,12109,"maybe we should sort out some terms. i.d rather avoid using ""2nd channel"" since it's not clear which one is the first and which one is the second. i think ""rdb channel"" is ok, but ""psync channel"" doesn't sound right to me (psync stands for partial sync). it could be ""commands channel"", but maybe it should be ""main channel"" since in some cases this socket carries everything. so how about ""rdb channel"" and ""main channel""?",0,0,0,0.9545873403549194,0.9898602366447448,0.9672226309776306,0.0,accept,unanimous_agreement
1261380098,12109,why did you wrap that in a function?,0,0,0,0.9567800164222716,0.9861456751823424,0.993129551410675,0.0,accept,unanimous_agreement
1261381806,12109,"btw, what exactly is it good for?",0,0,0,0.9766225814819336,0.9707226753234864,0.9888536930084229,0.0,accept,unanimous_agreement
1262349121,12109,let's increase the buffer size (`buf[net_host_port_str_len]` is too small),0,0,0,0.983686864376068,0.9922330379486084,0.9923008680343628,0.0,accept,unanimous_agreement
1262383881,12109,"looking at the above comment, this code is very odd, we need to improve the comment. i.e. in this case it's not a successful partial sync, it's a fake partial sync with the offset belonging to the ongoing rdb channel.",-1,-1,0,0.6125512719154358,0.5568675398826599,0.5749343037605286,-1.0,accept,majority_agreement
1262402657,12109,"the point was that if you return here, without setting client_slave and adding the client to the `server.slaves` list, then it's a normal client (until it sends another psync, after establishing the rdb channel). i think this is ok. we have a similar case when replica wannabe's are sending replconf to set various flags, until they send a psync that's not rejected, they are normal clients.",0,0,0,0.9790615439414978,0.9889257550239564,0.6573890447616577,0.0,accept,unanimous_agreement
1262418954,12109,"this comment can be confused with `replconf rdb-only`. let's avoid the ""rdb only"" part, and say it's a full-sync that uses second channel for the rdb snapshot.",0,0,0,0.9824650883674622,0.9929445385932922,0.9923916459083556,0.0,accept,unanimous_agreement
1262427751,12109,"""end-offset"" is a bit vague. maybe `needs-repl-offset`? also, the code below doesn't only imply the payload must include the ""end-offset"", it also implies that the connection is an rdbchan and should be handled by the fork child process, so maybe this option should be called `full-sync-rdb-2nd-chan` (we can come up with a shorter name, i'm just trying to convey the point that this command means more than just requesting an ""end-offset"".",0,0,0,0.9604737758636476,0.9885925054550172,0.9863337874412536,0.0,accept,unanimous_agreement
1262436292,12109,"how about ""no-fullsync"" instead? psync is the command (capable of both partial and full), i think `no-fullsync` would be clearer.",0,0,0,0.9871535897254944,0.9949736595153807,0.992360293865204,0.0,accept,unanimous_agreement
1262436371,12109,"maybe i'm confused, but i don't think we should tie the rdb-channel, diskless or psync2 capability with `psync-only` or `no-fullsync`. the desire to try partial sync and abort if not possible (without triggering a fork), is a common request (same as one that just asks for the live command stream, without the snapshot). the ability to handle psync2 responses, or handle rdb-channel should be a completely separate flag. let's split this one into `no-fullsync` and `full-sync-cmd-chan` (to match my above suggestion for `full-sync-rdb-2nd-chan`)",0,0,0,0.9697153568267822,0.9528971314430236,0.7947695255279541,0.0,accept,unanimous_agreement
1264612674,12109,let's try to be more consistent in terminology. let's use `repl_2nd_chan` instead of `repl_sec_conn` and `client_2nd_chan_` instead of `client_rdb_channel_` or maybe you have a better proposal?,0,0,0,0.9830941557884216,0.9934954643249512,0.9924700260162354,0.0,accept,unanimous_agreement
1264613234,12109,"i'm confused. `>=_send_psync && <= receive_psync_reply` is very short state, just one command's round trip. how does it apply to ""intransferstate""? or maybe i'm missing something?",-1,-1,-1,0.8504554629325867,0.7410327196121216,0.8644737601280212,-1.0,accept,unanimous_agreement
1264613810,12109,"let's rename this function. i'm paranoid about changing the role of a function and keeping it's prototype (return value doesn't count). if some fork or an old branch / pr is using it elsewhere, it'll compile and take a long time before the bug is found. how about `replicacreatemasterclient`?",-1,-1,-1,0.9615323543548584,0.7016407251358032,0.7640534043312073,-1.0,accept,unanimous_agreement
1264614167,12109,[code block] was there a reason for the `== 1` part? it's generally better to do `!=0` rather than `==1`,0,0,0,0.9839773774147034,0.9941049218177797,0.993873119354248,0.0,accept,unanimous_agreement
1264614848,12109,maybe this is more consistent and also clear? [code block],0,0,0,0.986098051071167,0.9931105375289916,0.9891050457954408,0.0,accept,unanimous_agreement
1264615417,12109,maybe this term is better? [code block],0,0,0,0.9843322038650512,0.9904245734214784,0.9854007363319396,0.0,accept,unanimous_agreement
1264615604,12109,"is this term better? that's a sister variable for `master`, right? maybe move it above `cached_master`? [code block]",0,0,0,0.987557888031006,0.9944319128990172,0.994999885559082,0.0,accept,unanimous_agreement
1264618010,12109,"not sure this function is needed, but i suppose it can help improve readability a bit. in which case, let's drop the `sync` part (it's not about the operation mode, it's about what this `conn` is used for) wdyt? [code block]",0,0,0,0.9812299013137816,0.988920032978058,0.9669085741043092,0.0,accept,unanimous_agreement
1264620621,12109,"let's avoid ""fsync"" as an alias for full-sync (i.e. it refers to fsync for files). [code block]",0,0,0,0.9870431423187256,0.9954347014427184,0.995144248008728,0.0,accept,unanimous_agreement
1264621491,12109,[code block] don't forget to update the variable names if renamed.,0,0,0,0.9865315556526184,0.9893378019332886,0.9953510761260986,0.0,accept,unanimous_agreement
1264634499,12109,p.s. i feel the function name doesn't accurately describe what it does or when it's called or what purpose it fills (the comment does). maybe repconnectiondone? or something that indicates it's the final state of one of the connections... do you have a better idea?,0,0,0,0.9379122257232666,0.958191692829132,0.9673714637756348,0.0,accept,unanimous_agreement
1264637559,12109,"actually, now that i see other bits of code (how updatereplicationstateactive is called from readsyncbulkpayload), i wonder if this should really be a client, or just a connection? the `master` client is only created (retroactively) when an outbound connection (used to send commands and get responses) becomes an inbound one (used to receive commands). so should this second channel connection have a client struct assigned to it? can you explain it to me?",0,0,0,0.9684288501739502,0.9913120865821838,0.9857871532440186,0.0,accept,unanimous_agreement
1264648090,12109,where do we do these in case this `if` is skipped? looks like this will be missing after a full-sync in case the race condition ends up skipping them here. we should probably put this in a function to be called from .... ? i'm actually not sure. please help me understand that flow.,0,0,0,0.9092684388160706,0.9008120894432068,0.9145227670669556,0.0,accept,unanimous_agreement
1264650099,12109,"maybe moving this into the above if-else (the one that checks `isrdbconnectionsync`) would be nicer.. p.s. maybe we don't have to keep the condition on `usemark`? (we don't have it in `updatereplicationstateactive`) i mean: it's not necessary in disk-based, but doesn't do any harm either.",0,0,0,0.9742563366889954,0.976781129837036,0.9774353504180908,0.0,accept,unanimous_agreement
1264651366,12109,function name is too generic. [code block],0,0,0,0.832541286945343,0.8291650414466858,0.7203612327575684,0.0,accept,unanimous_agreement
1264652426,12109,another place that requires consistent terminology. `rdbconnection` -> `2ndchannel`?,0,0,0,0.9885100722312928,0.994090974330902,0.992929756641388,0.0,accept,unanimous_agreement
1264652976,12109,"i'm not very happy with this approach of switching between them on random errors (or maybe i'm missing something?) i think that instead of this global variable being set to 1 on any master host update and 0 on any (many?) failures, we need some smarter negotiation mechanism. e.g. connect, send a replconf command, and depending on the response decide how to proceed.",-1,-1,-1,0.8885554671287537,0.781004011631012,0.963251769542694,-1.0,accept,unanimous_agreement
1264656858,12109,"it feels a little bit odd to use printf to generate scanf format. if it's just to avoid hard-coding `40` (config_run_id_size) into the string, we can use a constant string and a static_assert to make sure the the constant is right. but on the other hand, this constant is part of the protocol, it is never going to change.",-1,-1,-1,0.6954769492149353,0.6009588837623596,0.8405908346176147,-1.0,accept,unanimous_agreement
1264700691,12109,"here's another reason to drop the config now, rather than keep it temporarily and drop it later. if we don't intend to keep it, we don't want to refer to it in comments, and also iirc there are some pieces of code that can be simplified (drop a wrapper function). it'll be harder to locate and clean these things later. i'd argue that if we need to keep it only for testing the previous behavior, we can do one of two things: 1. check out an older branch (that's actually safer too, if we wanna be sure none of our changes caused any side effect). 2. comment out some line in replconfcommand to cause the connecting side to think the server doesn't support the new protocol and fall back to the previous one.",0,0,0,0.9202880859375,0.9718230962753296,0.968716025352478,0.0,accept,unanimous_agreement
1264708203,12109,"i think we'll need to split these into separate commands (with pipeline), so we can use the response to know what the other server supports.",0,0,0,0.9867983460426332,0.9869104027748108,0.98620343208313,0.0,accept,unanimous_agreement
1264709921,12109,"actually, as i think i stated earlier, assuming i understand the current implementation, i think the code / state machine needs to change. i think maybe we can merge these two state machines together in a different way. if i understand the current code, we do a psync (attempting a partial sync), then if it results in full-sync we abort it, and start over with a 2 channel sync even if the server doesn't support 2 channel sync. is that right? instead i think we should start by some capability discovery, then depending on the capabilities, try a partial sync and fall back into a 2 channel full-sync, or (if the remote is not capable) proceed with the old full sync (without aborting the psync) as we used to do.",0,0,0,0.9614765644073486,0.9726399183273317,0.9582411646842957,0.0,accept,unanimous_agreement
1264710577,12109,"i'm confused, if the state is receive_psync_reply, how come we're sending and not receiving anything?.",-1,-1,-1,0.7247733473777771,0.8465858101844788,0.9754251837730408,-1.0,accept,unanimous_agreement
1264711230,12109,"that's actually not parsing the endoff reply (there's no such command). it parses the second-channel sync response (`$endoff: `). let's make it clear.. maybe extracting the code of processendoffsetresponse into this block will make it clearer. i.e. that function can't be re-used anywhere else anyway, and it'll make this state machine code more self contained, using other functions only in order to perform actions (i.e. reinitreplicamainconnection and preparerdbconnectionforrdbload, but not for the purpose of the replication protocol state machine, it's printf and scanf)",0,0,0,0.9753026962280272,0.9883117079734802,0.9886928796768188,0.0,accept,unanimous_agreement
1264712888,12109,"once again, current terminology is ""master"". ""primary"" is just causing confusion at this point imho",0,0,0,0.9336989521980286,0.9689676761627196,0.5156069397926331,0.0,accept,unanimous_agreement
1264716738,12109,"should this be a debug level or notice level print? i don't see that we dropped the connection, and i also don't see that we paused the read handler. does that mean we'll keep hitting this callback again and again until the buffer accumulates on the master's side and it drops the connection? we should certainly improve here, and also make sure there's a test for it (if there isn't already one)",0,0,0,0.9752107858657836,0.9839242100715636,0.9858090281486512,0.0,accept,unanimous_agreement
1264717041,12109,"i don't know how yet, but i think we should find a way to avoid that copying from the buffered list to the query buffer.",0,0,0,0.963889181613922,0.8864805102348328,0.9846222996711732,0.0,accept,unanimous_agreement
1264717240,12109,"since the buffer is local, i think processing events every x bytes may be too frequent. maybe we need to add some time based threshold based on hz.",0,0,0,0.956115424633026,0.9395025968551636,0.9852369427680968,0.0,accept,unanimous_agreement
1264724321,12109,just noting that we need to make sure that we have tests that reliably hit the two branches of this race condition.,0,0,0,0.971606194972992,0.9855377078056335,0.9872434735298156,0.0,accept,unanimous_agreement
1264725844,12109,i see we're using it to store the replication offset to be used in slavetrypartialresynchronization. i guess we can add a dedicated variable for that.,0,0,0,0.9882087707519532,0.9843831658363342,0.9922683835029602,0.0,accept,unanimous_agreement
1264726807,12109,the empty multi-bulk thing is odd. why not use some error code `-fullsyncneeded`?,-1,-1,-1,0.6221712231636047,0.7227329015731812,0.6465381979942322,-1.0,accept,unanimous_agreement
1264727011,12109,"not sure why we must change this line, if we do, maybe just unify it with the previous one? or leave it as it was....",-1,0,-1,0.5858005881309509,0.9704601168632508,0.5024160742759705,-1.0,accept,majority_agreement
1264921448,12109,"not sure if i already commented on that or not. i realize that there's nothing holding the end-offset in ram in the time gap between the creation of the fork and the psync request that follows. i.e. if the backlog is very small, and there's high traffic rate, it could already be rotated and lost. i think that instead we should somehow link the two connections (one of them will associate itself with the other one, maybe by id), and we'll start accumulating slave buffers without waiting for that psync. let's discuss that or any other alternatives to cover that issue.",0,0,0,0.9367852210998536,0.9422568082809448,0.9586398601531982,0.0,accept,unanimous_agreement
1266882333,12109,"i agree, ""rdb channel"" and ""main channel"" are better names. i thought i removed all references to 2nd channel, will do another scan",0,0,0,0.9523950815200806,0.931233048439026,0.9719518423080444,0.0,accept,unanimous_agreement
1266885162,12109,"we do need to revive rioinitwithfdset, this pr does not yet include direct communication between child process to replica. i want to split that to another pr as this one is already heavy.",0,0,0,0.9733024835586548,0.9370999932289124,0.9851981997489928,0.0,accept,unanimous_agreement
1266901484,12109,"we agreed on calling it rdb-channel, i will rename the states accordingly",0,0,0,0.9738802313804626,0.988640546798706,0.9944894313812256,0.0,accept,unanimous_agreement
1266905766,12109,i think it is a mistake. it should be an handshake state,-1,0,-1,0.9050942659378052,0.5016468167304993,0.95363050699234,-1.0,accept,majority_agreement
1267652209,12109,"i think i'd rather see the full picture (and benchmarks) before committing to this. this pr is indeed big, but i don't think adding that makes a huge difference.",0,0,0,0.7702934145927429,0.8336443305015564,0.9532684683799744,0.0,accept,unanimous_agreement
1440535369,12109,"total size of used memory, i'll add comment",0,0,0,0.9865973591804504,0.970206618309021,0.9919646978378296,0.0,accept,unanimous_agreement
1440620901,12109,we use it to track replica streaming progress. we can actually get raid of it and instead decrement `pending_repl_data.len` in real time.,0,0,0,0.9874045848846436,0.9937644004821776,0.9943835735321044,0.0,accept,unanimous_agreement
1441452384,12109,"i think it makes more sense (to decrement). it's odd to have a list of buffers and a var representing it's size, and have it outdated. p.s. if we do need them both, then one should probably say ""peak"" and / or the other ""remaining"". and it should probably not be a `stat_` variable and don't need atomic access.",0,0,0,0.9742217063903807,0.907872438430786,0.9468573331832886,0.0,accept,unanimous_agreement
1441584462,12109,"ack, it would be helpful to know the replica's buffer peak since `pending_repl_data.len` is changing rapidly. i'll fix it.",0,0,0,0.9112336039543152,0.9714180827140808,0.9821733236312866,0.0,accept,unanimous_agreement
1441591937,12109,this is a mistake. removing.,-1,-1,-1,0.9463262557983398,0.9506558179855348,0.97704017162323,-1.0,accept,unanimous_agreement
1441770531,12109,"on second thought, i don't think we should support rdb-channel sync when the master uses disk. i may be wrong, but disk-based sync at the master side main advantage is that the background process is not dependent on the replica's responsiveness. this is useful for cases where replicas are slow and we want to avoid bgsave process cow (in exchange to larger cob). when used in such cases, rdb-channel sync will: 1. use child process to write snapshot to disk. 2. **use child process again** to write snapshot from disk to replicas sockets. rdb-channel will therefore degrade the performance of master disk base syncs. it is only used for that sync type, so i would like to remove this method entirely.",0,0,0,0.9614405035972596,0.986458957195282,0.9626144170761108,0.0,accept,unanimous_agreement
1441847125,12109,"there could be two other reasons to use disk-based master: 1. if you want to know the size of the rdb payload before you start reading it (accurate progress) 2. if you have an old slave (or something else that acts as a slave), and don't support the new eof format (don't declare the replconf capa for it). anyway, i agree, we don't have to support disk-based master and rdb-channel. i don't currently remember the context of my comment and too lazy to care. it might still be applicable, or might not.",-1,0,0,0.5994438529014587,0.9379141926765442,0.9528912901878356,0.0,accept,majority_agreement
1444590736,12109,"my preference is to keep rdb clean from rdb-channel stuff, so i'll move it to replication.c.",0,0,0,0.9839670062065125,0.9887850284576416,0.9907050728797911,0.0,accept,unanimous_agreement
1444934092,12109,yes replication section would be a better choice,0,0,0,0.9470072388648988,0.9739234447479248,0.986729621887207,0.0,accept,unanimous_agreement
1445014293,12109,"im not sure, i'll unwrap it",-1,-1,0,0.5757197737693787,0.786217987537384,0.7242523431777954,-1.0,accept,majority_agreement
1452128555,12109,"in my opinion, there are two options for addressing this issue. we can either link the two connections or use a weaker approach, which will only link them to a specific offset. using the first approach, master will generate a random magic string when bgsave begins and give it to the replica along with the `endoffset` response. it will keep a pointer to that end offset until the replica's main connection requests psync (using that magic string). the second approach involves master holding a struct containing offset and count. as soon as bgsave starts, master will insert the end offset into the struct and increment the count. this offset counter will be decremented when some replica requests psync with that offset. the second approach might fail if some random replica asks for the exact offset, so i think the first approach is a bit more complex but generally better. edit: the first approach can also work with the ip-address and listening-port reported be the replica.",0,0,0,0.9654099345207214,0.9866355061531068,0.9768291115760804,0.0,accept,unanimous_agreement
1452350693,12109,"changing ""end-offset"" to ""rdb-conn""",0,0,0,0.9874481558799744,0.9928956627845764,0.995276689529419,0.0,accept,unanimous_agreement
1453254495,12109,changing to `repl_rdb_transfer_s`,0,0,0,0.9878177046775818,0.9936776757240297,0.994817316532135,0.0,accept,unanimous_agreement
1453271020,12109,"`master_2nd_chan` or `master_rdb_chan` may sound like this variable is used by the rdb channel, when it actually the main connection. i suggest `repl_provisional_master` / `repl_tmp_master` / `repl_in_progress_master`",0,0,0,0.98697167634964,0.9943804144859314,0.9929898977279664,0.0,accept,unanimous_agreement
1453434654,12109,"i agree it isn't about operational mode, renaming to `isrdbconnection`",0,0,0,0.971695363521576,0.9770435690879822,0.9871817827224731,0.0,accept,unanimous_agreement
1453477406,12109,"function does need to be renamed, i think `completetaskrdbchannelsync` may be a good fit.",0,0,0,0.9041667580604552,0.9930332899093628,0.981297254562378,0.0,accept,unanimous_agreement
1457200069,12109,"i see, so until steady state is achieved, i will use a dedicated structure for the psync_master.",0,0,0,0.9881126284599304,0.9854627847671508,0.9897520542144777,0.0,accept,unanimous_agreement
1457287391,12109,"i'm not sure i have the right context in my head right now, but if i get it correctly, with the second approach these are more issues with misbehaving clients. i feel i rather link them by communicating the client id, but maybe ip and port pair can work too. please try to solve it (starting to collect slave buffers right away instead of relying on the backlog), and when the time comes i'll review the solution you chose and comment if necessary.",-1,0,0,0.6273215413093567,0.7401704788208008,0.9055340886116028,0.0,accept,majority_agreement
1457296859,12109,"btw, maybe we can create the two `client` structs together, one of them without a `conn` and reserve it for later (somewhat similar to what we do with cached_master). not sure which one is cleaner.",0,0,0,0.7981346845626831,0.9879559874534608,0.977189838886261,0.0,accept,unanimous_agreement
1457811475,12109,"ack, so i will continue with the first approach - peering replica's connection according to address & port tuples. in the context of establishing two clients simultaneously, my understanding is that there might be a scenario where the master node ends up with three clients associated with a single replica. this arises because, during the initiation of the rdb connection by a replica, the master can only confirm that it is the same instance once the replica transmits its address. consequently, upon accepting the new connection, the master may generate an additional, unused client before being able to identify and manage the connection correctly.",0,0,0,0.979563057422638,0.986813187599182,0.975877285003662,0.0,accept,unanimous_agreement
1461680481,12109,"i agree, we can send ack whenever it isn't rdb-connection sync. i will move it to the upper if.",0,0,0,0.97966331243515,0.9555374383926392,0.9855528473854064,0.0,accept,unanimous_agreement
1461681167,12109,"i did some refactoring, i think that after that the flow now will be clearer. after refactor, in the race condition case (rdb is loaded before psync established), main connection will call -> `slavetrypartialresynchronization` -> `completetaskrdbchannelsync` -> `replicationresurrectprovisionalmaster` there it will initialize `server.master` with the relevant fields. * note that some of the method has been renamed",0,0,0,0.97953462600708,0.9822956919670104,0.9653852581977844,0.0,accept,unanimous_agreement
1461783699,12109,"in general, i agree with the concept of local variables, but in the context of the syncwithmaster read handler, i am not sure if it is a viable option. at the handshake phase, the replica will send ""replconf no-fullsync"", receive +ok or -err, and update local variable, `master_supports_rdb_channel`, accordingly. when the replica needs to choose a sync method (after repl_state_receive_psync_reply) `master_supports_rdb_channel` will already be out of scope. aside from the locality of the variable, i agree with the comment. i'll make sure we don't choose sync approach at random.",0,0,0,0.9568132162094116,0.9933115243911744,0.9553001523017884,0.0,accept,unanimous_agreement
1461877658,12109,"though we probably won't change config_run_id_size, asserting that it is 40 seems more confusing than snprintf. my preference is to keep this line general, and to add documentation.",0,0,0,0.937410056591034,0.9575324058532716,0.8702376484870911,0.0,accept,unanimous_agreement
1461921860,12109,"if the two options above are considered better rollback options, i will remove the configuration.",0,0,0,0.9867246747016908,0.9898742437362672,0.993561029434204,0.0,accept,unanimous_agreement
1461963701,12109,"correct, however we have already verified remote capability in some way. when we try to psync the first time, we call `replconf no-fullsync`, so at this point we already know that master supports rdb-channel. this command can't fail because of old master version. perhaps we should remove the verification from repl_rdb_conn_receive_replconf_reply (15 lines below). i believe that, although this scenario is impossible, it keeps the implementation complete.",0,0,0,0.9015679359436036,0.987741470336914,0.9826921224594116,0.0,accept,unanimous_agreement
1462219414,12109,it is confusing. this is overuse of the last normal replication state before we move to rdb-channel sync. i think we can add another state in between repl_state_receive_psync_reply to repl_sec_conn_receive_replconf_reply in order to make it clearer.,-1,-1,-1,0.9502145648002625,0.9700596332550048,0.7925894856452942,-1.0,accept,unanimous_agreement
1464709379,12109,"i agree. upon reaching the limit, we will set the read handler to null. *also this log should be at the notice level.",0,0,0,0.970224678516388,0.957183599472046,0.9812849760055542,0.0,accept,unanimous_agreement
1464717029,12109,"setting buffer limits poses another problem. due to the fact that the replica is unaware of the total size of the snapshot, it may read too much repl-data and never be able to load the snapshot. in order to determine the buffer limits, it would be useful to share the expected snapshot size with the replica.",0,0,0,0.872677206993103,0.984790861606598,0.9606238007545472,0.0,accept,unanimous_agreement
1464931917,12109,"ack, i'll add time based threshold",0,0,0,0.9857221841812134,0.9238268136978148,0.9860063791275024,0.0,accept,unanimous_agreement
1466443497,12109,"we don't know the expected snapshot size. i think a notice level print, and a suspension of the read handler should be enough. then the buffer will accumulate on the master's side, and eventually lead to disconnection due to slave buffer limit? p.s. we'll have to have a test that covers these paths.",0,0,0,0.9826838374137878,0.9538620114326476,0.9880152344703674,0.0,accept,unanimous_agreement
1469196508,12109,"as a snapshot size assessment, we can look at the master's `used_memory_dataset`",0,0,0,0.9870113134384156,0.9931305050849916,0.994127869606018,0.0,accept,unanimous_agreement
1469244894,12109,this is very inaccurate. it can easily be 2 time higher or lower (or even 10 times in pathological cases). i'm not sure i understand what exactly you wanna do with that info. maybe that'll still be valid in some way.,-1,-1,-1,0.8969091176986694,0.95018470287323,0.9343307018280028,-1.0,accept,unanimous_agreement
1469267737,12109,"ideally, i would like to prevent a case in which the replica side buffer accumulates too much data, and the replica is unable to load the rdb. when that happens, i would like the master's cob to take a part or to fail the sync operation. i don't want the sync to continue if it has no chance of succeeding.",0,-1,0,0.8984115719795227,0.598547101020813,0.9812809824943542,0.0,accept,majority_agreement
1469464143,12109,"if the sync won't continue, all we can do is drop the connection and retry (hoping the conditions change, e.g. more memory will be available later). you can't afford false negatives (unnecessary dropping of the connection if it could succeed), and if there are also false positives (not detecting correctly that it's hopeless), then i wonder if we should bother to implement anything based on the estimated rdb file size. let's keep it simple, read as much as we can, let the rest be accumulated in the master, until it disconnects us.",0,0,0,0.9104024767875672,0.723125696182251,0.8989678621292114,0.0,accept,unanimous_agreement
1477302771,12109,"you can also use a stringify macro and let the compiler concatenate adjacent strings.. but again, this constant is part of the protocol, it will never change, it can't change. it's like remaining flexible in case tcp will some day no longer be ip protocol number 6.",0,0,0,0.971380054950714,0.9848108291625975,0.9913057684898376,0.0,accept,unanimous_agreement
1477309967,12109,let's move it up to be part of the group flags.,0,0,0,0.984788179397583,0.992707908153534,0.9928387999534608,0.0,accept,unanimous_agreement
1477311001,12109,hidden configs (meant to be used by the testing framework) shouldn't be documented.,0,0,0,0.9589514136314392,0.9787447452545166,0.9772502779960632,0.0,accept,unanimous_agreement
1477311510,12109,"not that it really matters, but i think `seconds` is an odd unit for sleep. would be ok if we take that argument as a floating-point and convert it, but maybe it'll better to take milliseconds",0,0,-1,0.5671583414077759,0.9155518412590028,0.6013633012771606,0.0,accept,majority_agreement
1477318976,12109,"this looks a bit odd. the function isn't just a wrapper for rdbsave, it performs child process setup (like proc title and closing of pipes). i'd really rather these be kept in the same function that in the same function that created the fork and the pipe. let's try to search for another solution. why did you extract these to here?",-1,-1,-1,0.93921560049057,0.9394028186798096,0.7805989384651184,-1.0,accept,unanimous_agreement
1477319262,12109,"since you crated a function for setupbidirectionalcommunication, maybe we should have destroybidirectionalcommunication(pant / child). either two functions, or one that takes an argument. you can still wrap the rio related part in a function, but the proc-title and cpu-affinity should be moved back to the one that called fork, and the pipe thing to some method about the bidirectional communication.",0,0,0,0.9873384237289428,0.9882412552833556,0.9926142692565918,0.0,accept,unanimous_agreement
1477324596,12109,"we have far too many confusing functions in replication.c already, and with this split of rdbsavetoslavessockets, we also have some in rdb.c, we must sort it out. we need to make sure it's clear, which one runs in the master, and which one runs in replicas. we need to make it clear which ones run in the fork child, and which ones run in the parent process. this can be done with some common prefix, and / or with a clear comment above the function (when it is called and what it does)",0,0,0,0.9181454181671144,0.9856995940208436,0.9219508767127992,0.0,accept,unanimous_agreement
1477330636,12109,"""pipeline"" -> ""pipe? [code block]",0,0,0,0.9881664514541626,0.99301940202713,0.9941336512565612,0.0,accept,unanimous_agreement
1477331226,12109,"the function name is a bit too generic. since the code isn't a generic ""bidirectional communication"", i.e. it writes to server.rdb_pipe_*, let's name it better",0,0,0,0.8514218330383301,0.840043842792511,0.66970294713974,0.0,accept,unanimous_agreement
1477332598,12109,"an alternative approach to all the comments above, is to revert all these changes, and just unify these two methods (withpipe and direct) into one, and pass some argument to choose between the two behaviors. it may be more readable to read all that logic once, and know which parts are conditional, rather than read it twice and wonder what are the different parts. also, it reduces the risk of a bug fix applied to one and not to the other.",0,0,0,0.97505921125412,0.9883655309677124,0.9844567179679872,0.0,accept,unanimous_agreement
1477333521,12109,"now that i'm done reading the modifications to rdb.c, i support my last comment. it could be one method, which either takes the decision from outside as a boolean, or creates a boolean on the stack with the decided mode of operation, and then all the code in one log function without duplication. if there are certain aspects that are complicated (like creating bidirectional communication) that can be extracted to a well isolated and properly named functions. that can be done, but then the ""interface"" of this set of functions should be clear (create / destroy, parent / child, etc). and still, i'd argue that the whole flow of fork-till-exit in these two flows should be in one function.",0,0,0,0.9730634689331056,0.9362261891365052,0.9367429614067078,0.0,accept,unanimous_agreement
1477340306,12109,let's be sure to document all the interface changes in the top comment.,0,0,0,0.9848865866661072,0.9877898693084716,0.9941588640213012,0.0,accept,unanimous_agreement
1477340410,12109,same goes for the new info fields (replicas_repl_buffer_*),0,0,0,0.9877499938011168,0.993057370185852,0.9949744939804076,0.0,accept,unanimous_agreement
1477340682,12109,why use a separate printf? let's unify these 3 calls to sdscatprintf,0,0,0,0.9876635670661926,0.9867390394210817,0.9911735653877258,0.0,accept,unanimous_agreement
1477344173,12109,static string? why do we need a separate buffer and a sprintf?,0,0,0,0.9817837476730348,0.977429747581482,0.9886136054992676,0.0,accept,unanimous_agreement
1477346175,12109,"i think i commented on this in the past. i think `no-fullsync` is a good feature to have, and should be completely separate from rdb-channel or main-channel. if the main-channel needs to enable no-fullsync, it can do that in addition to marking itself as main-channel. or if (since) no-full-sync is mandatory for main-channel, then we can implicitly enable it. i.e. i think we can have 3 replconf arguments: * no-fullsync - in some cases, replicas, or tools that look like replicas, may wanna try to re-connect but if a partial-sync isn't possible, they don't want a full one automatically as fallback * rdb-chan (or rdb-chan-rdb-conn) - identify the connection as such * main-chan (rdb-chan-cmd-conn) - identify the connection as such the last one can implicitly or explicitly set no-fullsync as well, but the implementation behind these flags should be separate imho. p.s. had you only created the two `chan` arguments (`main-chan` and `rdb-cnan`), and give each the functionality and behavior it needs, i wouldn't have commented asking for `no-fullsync`. this discussion is a result of you naming them `end-offset` and `psync-only` which are misleading imho.",0,0,0,0.8822561502456665,0.9736316800117492,0.8777074217796326,0.0,accept,unanimous_agreement
1477373349,12109,"from the interface name, i don't understand what's the difference between this and isreplicardbchannel. is it that this one is on the replica side and the other one on the master side? maybe rename to `isreplicardbconn`? i wish we had a way of making it clear (the ""used by replica"") wasn't immediately clear to me, since it's all about t replica (connection), i didn't immediately understand it means that it runs on the replica side.. i wish we could have split that code to differnt files, or give functions different prefix, but i don't have any idea of a good prefix. lets start by adding s clear line in the comment. like [code block] or [code block]",-1,0,0,0.7174735069274902,0.698150098323822,0.778195858001709,0.0,accept,majority_agreement
1477383162,12109,"in the context of the above. this one was clear (better than the 3 functions before it) but let's standardize it to a separate line and use it everywhere, or at least in new code.",0,0,0,0.9855924248695374,0.9903640151023864,0.992521345615387,0.0,accept,unanimous_agreement
1477413230,12109,"what does that line do? :confused: take a pointer to a stack variable, and write it to a local variable that we no longer use? p.s. maybe document the arguments in the function doc comment.",0,0,-1,0.8758254647254944,0.9186811447143556,0.815985918045044,0.0,accept,majority_agreement
1477413773,12109,maybe refer the reader to feedreplicationbuffer to learn the details there,0,0,0,0.9879626631736756,0.9926466941833496,0.99311500787735,0.0,accept,unanimous_agreement
1477416525,12109,"commenting on this discussion after briefly reviewing the last push. i'm not sure i understand the flow after your recent changes, and i'd rather read about in some doc comment instead of understanding it from the doc. iirc the previous revision used to disconnect and re-connect in order to try different approaches (old and new), and i remember commenting about it that instead we should have some capability exchange at early stage (sending some command and seeing if it responds with an error), so that we can get it connected in one go (also in old master new replica or vice versa). if this was implemented, can you please describe this fallback mechanism in some big comment in the code (and maybe also in the top comment of the pr). come to think of it, even the non-fallback mechanism should be documented somewhere in the code (like it is documented in the top comment of the pr), so please make sure both (new mechanism, and it's fallback) are described, and then it'll be easier to review the code (or the procedure).",0,0,0,0.9585238695144652,0.9694948196411132,0.9076594114303588,0.0,accept,unanimous_agreement
1477417552,12109,"re-opening this discussion (maybe for a different purpose, or maybe that was your aim all a long.. first i'll state again that the user should never worry about (or be able to) control which mechanism we use for replication. and if you need some config in order to benchmark things you better just use the old version, or put some ifdef in the code. however, we do want to write tests that check fallback, surely for a new replica to connect to an old master (required), but maybe also for an old replica to connect to a new master (because we have some 3rd party components acting as fake replicas). it's best that we write tcl tests to cover that, and for that we need be able to cause either party to react as if it doesn't understand the new protocol. it's best to do that in a single point (not spread these checks all over), so we should do that at protocol negotiation for that we can create a config to control it, but then, it should be a hidden config, and it should not be documented in the conf file (just add a single short line in config.c to define it's purpose)",0,0,0,0.9522327780723572,0.962473690509796,0.9053813219070436,0.0,accept,unanimous_agreement
1477731120,12109,"ack, i'll replace it with the actual value next revision",0,0,0,0.9848939776420592,0.9538686275482178,0.9839966893196106,0.0,accept,unanimous_agreement
1477828023,12109,"ok, good point. i thought we will only need old master to new replica. i will make the config hidden and add some tests. essentially, if we aim to verify the configuration solely in one location (during the handshake), then in all other instances, we must check `master_supports_rdb_channel` instead to determine which functionality should be applied.",1,0,1,0.8190577626228333,0.5054600238800049,0.7136614918708801,1.0,accept,majority_agreement
1478614926,12109,the fallback mechanism is implemented in this revision. it happens when the replica receives `replconf psync-only` response (will change it to replconf main-channel). i will make it clearer by verifying the default value of the master response (`+ok`) in this way you can't miss it :).,0,0,1,0.8650068640708923,0.8578641414642334,0.9592214226722716,0.0,accept,majority_agreement
1479851949,12109,both comments are irrelevant as we are merging rdbsavetoslavessocketswithpipeline with rdbsavetoslavessocketsdirect to one method (correct me if i'm wrong).,0,0,0,0.901655614376068,0.9581481218338012,0.9863536953926086,0.0,accept,unanimous_agreement
1479865845,12109,do you mean one general comment which explains the flow and states of rdb-channel session (like replication buffer blocks)? or specifically this new state?,0,0,0,0.987547755241394,0.9921939373016356,0.9928023219108582,0.0,accept,unanimous_agreement
1479894998,12109,we don't need it. will remove the buffer,0,0,0,0.9838830828666688,0.9364674091339112,0.9932651519775392,0.0,accept,unanimous_agreement
1479986708,12109,"initially, i thought the issue was enabling psync2 in case the replica asked for an end offset. although i agree that we almost have `no-fullsync` or `psync-only` for free, i think that implementing such behavior will require more than simply adding replconf options. with proper design and testing, i will be happy to add this feature later on. in the meantime, i'll rename `no-fullsync` to `main-channel`.",0,0,0,0.4913654029369354,0.5090035200119019,0.7813430428504944,0.0,accept,unanimous_agreement
1480012694,12109,i agree that master and replica used methods are mixed in the file which makes it unclear to the reader in many ways. i have a task in my backlog for that.,0,0,0,0.9729906916618348,0.9854737520217896,0.980707049369812,0.0,accept,unanimous_agreement
1480052025,12109,"oh i missed that, my bad",-1,-1,-1,0.9872767329216005,0.991269588470459,0.9944517016410828,-1.0,accept,unanimous_agreement
1481018118,12109,"yes, if you apply my other suggestion, then this becomes irrelevant",0,0,0,0.9570247530937196,0.9776336550712584,0.9887683391571044,0.0,accept,unanimous_agreement
1481025047,12109,"still, please invest some time in editing the top comment to describe both the design and mechanics of the new mechanism, as well as the fallback. it'll be easier to make sense of the code after reading the description.",0,0,0,0.9814155101776124,0.9903606176376344,0.9839099645614624,0.0,accept,unanimous_agreement
1481029199,12109,"i mean a bullet list of all the interface changes (configs, commands, command arguments and command replies). in this case: * the `state` sub-field in the `slave%d` info field (`info replication`), has a new `bg_transfer` state. (in addition to `wait_bgsave`, `send_bulk`, `online`)",0,0,0,0.9882251024246216,0.991135835647583,0.9931451082229614,0.0,accept,unanimous_agreement
1483115938,12109,we're not using `bool` and `true`/`false` in redis.,0,0,0,0.973757803440094,0.9887527227401732,0.9885041117668152,0.0,accept,unanimous_agreement
1483123345,12109,now we should rename that var too,0,0,0,0.9775661826133728,0.9912344217300416,0.9940361976623536,0.0,accept,unanimous_agreement
1483129691,12109,"if there's one thing that redis source code is consistent about is that for some reason it avoids using line comments. in nearly anything else, it's inconsistent.",0,0,0,0.917709469795227,0.8245506286621094,0.6873663663864136,0.0,accept,unanimous_agreement
1499199049,12109,"the chart in the top comment now handles it, right? so we can dismiss this thread? however, the image you posted there is a bit hard to read (due to scaling), and when i click on it to get the larger version, i get error 404. on the other hand, we don't want the code base (and future generations) to rely looking at that image in the pr, we need to convert that diagram to ascii art and also include it in the code (unless you already did).",0,0,0,0.9479127526283264,0.9243876338005066,0.9668916463851928,0.0,accept,unanimous_agreement
1499363043,12109,maybe we better omit this field (or give it a 3rd state) when the full-sync is over and this is just an normal slave?,0,0,0,0.9813109636306764,0.9942206144332886,0.9872596263885498,0.0,accept,unanimous_agreement
1499375087,12109,shouldn't this be part of freeclient instead of being here?,0,0,0,0.9627429246902466,0.9928145408630372,0.9917747974395752,0.0,accept,unanimous_agreement
1499449544,12109,"the word ""pending"" is a bit odd to me, maybe we can find a nicer solution. are the rdb-connection slaves being kept in some collection other than `server.clients`? maybe we can find a solution where this dict points to the rdb connection clients, and they're the ones holding that repl-buffer reference temporarily? i wanna use this opportunity though to discuss the `peering`, `peer` and `unpeer` terms that i see you're using with this collection. personally i find that confusing, specifically when the name of the list is `pending`, and not `peered`? maybe `peer` and `unpeer` should be just `add` and `remove`, and maybe `pending` should be something else? (or we need to say what are they're pending for). so maybe it'll be easier to follow if we keep a dict of rdb clients (it'll be easy to understand what we keep there and when we add / remove one)? p.s. could it be that the main connection is created after the rdb connection is already done and disconnected? i suppose we can't afford that anyway, since then what's our trigger to clean garbage from this pending_slaves dict if the main connection is never established? other notes: * by `repldatablock` you mean `replbufblock`, right? * if we keep it in the current form, i think we should state more clearly that in what state / duration they're listed here (i.e. that they're removed when the main connection is created)",-1,-1,-1,0.9276560544967652,0.907248556613922,0.5990134477615356,-1.0,accept,unanimous_agreement
1499520717,12109,"i fixed the diagram. regarding top comment for high level overview, i wanted to put this explanation somewhere in the code (not sure yet where does it belong). i think it is easier to understand the new interface as part of the sync flow, tell me if you think bullet list will be clearer. [code block] its a good idea to add the diagram as well but it isn't enough to cover all interface changes.",0,0,1,0.7789197564125061,0.7349249124526978,0.9125495553016664,0.0,accept,majority_agreement
1501765201,12109,"yes (i did some minor edit to the above). i think it could be placed in the pr top comment (which is maybe also missing some other details from the issue, and a quick summary of measurements for the benefits it mentions). and we should put that somewhere in replication.c (maybe as part of the comment above slavetrypartialresynchronization?). it could be nice if we can also fit an ascii art diagram (of the one you placed at the top comment), but maybe we can live without it, if we just mention the skipped steps (i.e. in the enum in server.h, we can maybe comment on the places that jump from a state and skips the ones that are immediately after it, where they skip to and in what case).",0,0,0,0.9491968750953674,0.964608073234558,0.9798793792724608,0.0,accept,unanimous_agreement
1501783130,12109,"logically, we need to skip slaves that already have a node. maybe this state doesn't occur, but i think we better handle it.",0,0,0,0.9668956995010376,0.959954559803009,0.9860381484031676,0.0,accept,unanimous_agreement
1501792013,12109,"i don't think i'm happy with the fact we're pairing them based on the ip+port. what happens if two replicas connect to the same master simultaneously but not at the exact same time? i.e. they'll have the same ip and port, but different offset, and they deserve different repl buff nodes. maybe the psync request should carry the client id of the other connection? (then we can easily find the buffer pointer by looking up the client) or maybe we should have the dict key be ip+port+repf_offset? note that we need to handle both the case of same ip+port with different offset, and the case of ip+port with the same offset. so if we don't tie them to client id, we need some refcount to avoid removing one from this dict too early. p.s. we need to make sure we have tests covering all these cases.",0,0,-1,0.6995179057121277,0.8815828561782837,0.8985908627510071,0.0,accept,majority_agreement
1501857995,12109,"right, currently we keep it as replica main connection for the rest of the time. i agree it might be confusing. will fix that",0,0,0,0.9480770230293274,0.7806961536407471,0.957685887813568,0.0,accept,unanimous_agreement
1501860888,12109,"yes, i will fix that",0,0,0,0.9761508703231812,0.9844048619270324,0.9876794219017028,0.0,accept,unanimous_agreement
1501865938,12109,"- currently the dictionary values are the replica's rdb-client. regarding if the rdb load is done before replica established psync connection, we can keep the rdb client up until the psync conn establishes successfully or until some timeout is reached. however it is a rare case so it sounds a bit like an over kill to me. i think we should allow sync to fail in such cases, as the rdb is probably very small anyway. - lets use add and remove instead of peer and unpeer, and instead of pending_replicas we can use `slave_waiting_psync`. yep, will fix that right i will clarify that",0,0,0,0.661565363407135,0.9102760553359984,0.95682293176651,0.0,accept,unanimous_agreement
1501867825,12109,"right, it can't happen as we forbid two parallel forks, but it makes more sense to check that.",0,0,0,0.9676879048347472,0.9755040407180786,0.9821597933769226,0.0,accept,unanimous_agreement
1501872539,12109,"i agree that ip:port isn't a good dictionary key. imo adding offset wont help as well because if two replicas are syncing with the same offset, then we will have issues if one of the rdb connections got closed while the other hasn't asked for psync yet (if this client is used as the value of the dictionary then refcount wont help). overall breaking client id is harder, but i still have to figure how will the replica main conn send the rdb-client id. i think we will have to add an extra call to replconf, and a new replication state.",0,0,0,0.8638464212417603,0.943913459777832,0.943520963191986,0.0,accept,unanimous_agreement
1502371169,12109,"ohh, right (`dictadd(server.pending_slaves, slave_name, slave);`), so it means this statement is wrong: `dict[slave ip] = repldatablock` what's rare? the case when the rdb part will complete before the second connection is established? i don't think it's rare. and what do you mean by allowing it to fail? if it'll be failing psync and resorting to a full one it could be an ok solution, but just failing full sync is wrong imho. in any case, i rather solve all race conditions. either we change the design in a way that there's no race (we wait with the final part of the fork), or we make sure that both cases are handled correctly (and add a test).",0,0,-1,0.5980125069618225,0.7890943288803101,0.5612542629241943,0.0,accept,majority_agreement
1502566800,12109,"right i will fix that comment. and i agree, in this case we should let full sync finish successfully, decrement refcount, and then if psync offset is outdated, the replica should resync. i have already wrote some tests that cover those scenarios (take a look at `test rdb-channel psync established after rdb load`). now that we have the full picture i will cover the above cases as well.",0,0,0,0.9375388026237488,0.9110642075538636,0.9815955758094788,0.0,accept,unanimous_agreement
1502767317,12109,"i have added a short summary with the main benefits, as well as a replica machine state diagram. located above syncwithmaster.",0,0,0,0.9830740094184875,0.8927549719810486,0.9830799102783204,0.0,accept,unanimous_agreement
1502815517,12109,"before resolving this comment, does [a link] enough? or should i go into more details like you mentioned?",0,0,0,0.9795395135879515,0.9868803024291992,0.9939640164375304,0.0,accept,unanimous_agreement
1521201799,12109,please improve indentation and word wrapping.,0,0,0,0.9804109930992126,0.9838629961013794,0.9884845614433287,0.0,accept,unanimous_agreement
1521210772,12109,"first, how come an **int** hash function uses `nocase`? that's probably a bug. secondly, why do we need siphash in order to hash an integer? why not just return the integer as the hash index? (and then apply a mask on it) in which case this can be handled in server.c, no need to modify dict.c to support it.",0,0,0,0.9874570965766908,0.9943333864212036,0.9741398096084596,0.0,accept,unanimous_agreement
1521216729,12109,maybe change that dict into a rax and follow the footsteps of lookupclientbyid?,0,0,0,0.9840898513793944,0.9947236776351928,0.9920957684516908,0.0,accept,unanimous_agreement
1521266285,12109,"i'm not certain we actually need it. the range of `long long` is high enough so that we can assume we'll never wrap around and get to negative numbers. i'd rather drop these, but if we keep them they should probably use `unsigned long long` and not `uint64_t`",0,0,0,0.9619340300559998,0.919029176235199,0.8968753814697266,0.0,accept,unanimous_agreement
1521270517,12109,"afaik the key to the dict can be the integer itself, no need for heap allocation for it.",0,0,0,0.9889378547668456,0.9905903339385986,0.9921908974647522,0.0,accept,unanimous_agreement
1521275652,12109,"i think the term ""identify"" it too broad. how about `replconf set-rdb-conn-id `? also, please update the diagrams (ascii and image) with this step. p.s. maybe we use `replconf main-conn ` (instead sending two commands, one of them carrying a boolean)? i.e. we'll need to postpone the `main-conn` till we know the id? not sure if this could work, haven't looked into the details.",0,0,0,0.968118131160736,0.9891919493675232,0.9194189310073853,0.0,accept,unanimous_agreement
1521391869,12109,"yep, `nocase` is a bug. if we don't need siphash, then why masking?",0,0,0,0.9629182815551758,0.7434911131858826,0.9703434109687804,0.0,accept,unanimous_agreement
1521402143,12109,"mostly, this dictionary will hold very few clients. my preference is to keep it as simple as possible. aside from efficiency, what are the advantages of using radix tree here?",0,0,0,0.9603449106216432,0.9562605023384094,0.9595033526420592,0.0,accept,unanimous_agreement
1521419675,12109,"right, long long is enough. i will remove that",0,0,0,0.9724101424217224,0.9459094405174256,0.993720531463623,0.0,accept,unanimous_agreement
1521437022,12109,"true, i just think it a bit odd to fool the dictionary that cid is a pointer while it is actually the key itself. it might cause confusion, as well as threaten memory access.",-1,-1,0,0.856065034866333,0.9465607404708862,0.7643248438835144,-1.0,accept,majority_agreement
1521449407,12109,i mean that the hash function can just return the integer as is.. and the dict will apply the mask to know which bucket it falls in... no need for siphash,0,0,0,0.9812368750572203,0.966586172580719,0.988819181919098,0.0,accept,unanimous_agreement
1521450564,12109,"idk.. just that we're repeating an existing pattern, so it looks simpler.",0,0,0,0.9744271039962769,0.9683941602706908,0.961061716079712,0.0,accept,unanimous_agreement
1521454896,12109,"i agree, i'll rename the subcommand and will update the diagrams today. `replconf main-conn` should be called before the first psync request (before the replica even knows it has to get the entire snapshot). otherwise after psync fails, the master will start to send the rdb using the main connection immediately.",0,0,0,0.9857808947563172,0.9788190126419068,0.9905734658241272,0.0,accept,unanimous_agreement
1521466284,12109,"actually, looking at an older version of redis, we had this: [code block]",0,0,0,0.9864569306373596,0.9923251867294312,0.9902963042259216,0.0,accept,unanimous_agreement
1521471750,12109,"i don't see the problem. the dicttype can have keycompare, keydup, and keydestructor set to null. and the keys are always plain integers (casted to void*). the hashfunction can either just return the integer, or use the more sophisticated dictinthashfunction mentioned above (not sure about it's benefits)",0,0,0,0.9731586575508118,0.9658101797103882,0.9197198152542114,0.0,accept,unanimous_agreement
1521604325,12109,"ack, sounds good. so dict key will be plain integers and if we don't have a reason to use mask then the hash will be the identity function.",1,1,0,0.8867712020874023,0.9030564427375792,0.8397818803787231,1.0,accept,majority_agreement
1521760890,12109,discussed in this thread [a link] we will use identity function for hashing integers,0,0,0,0.9875032305717468,0.9915149211883544,0.9949911236763,0.0,accept,unanimous_agreement
1521772261,12109,"i was not aware of this use case, very nice. in general, i believe that rax is a good option, but i'm not sure if it's worth changing the existing implementation because it's pretty simple as it is.",1,1,1,0.5704455971717834,0.9695515036582948,0.9904205799102784,1.0,accept,unanimous_agreement
1522704556,12109,"it's not simple if you have to create infrastructure (hash function and other generics) in order to support it, or it does something no one else does. and if there is another place that already doing something similar and you can add another similar instance without duplicating their infra. the bottom line here is that if we don't have any specific reason to prefer one over the other, we should take the one that adds fewer lines of code, or is easier to understand (repeating a pattern used elsewhere helps here).",0,0,0,0.9741092324256896,0.9750253558158876,0.9831106662750244,0.0,accept,unanimous_agreement
1523010387,12109,"let's mention the units, and i think 5 seconds is too short. maybe 60s makes more sense?",0,0,0,0.876203715801239,0.9541465044021606,0.973391056060791,0.0,accept,unanimous_agreement
1523011789,12109,"why ""first""? it's the time it was freed, and repeated free attempts should just be ignored (already scheduled for freeing) i'd suggest `rdb_client_free_time`, or maybe `rdb_client_disconnect_time`",0,0,0,0.9854921698570251,0.993559718132019,0.991481065750122,0.0,accept,unanimous_agreement
1523378778,12109,"i think this patter would be nicer [code block] this way that whole block is just about rdb channel to be honest, i'm not sure we should re-use the protected flag, maybe we should rely on a new flag, or maybe the rdb_channel one is sufficient. it's true that this flag does almost exactly what we need, but on the other hand, other users of this flag set it together with removing read and write handlers, and we're not, so it could cause some confusion or issues some day. i don't mind keeping what you did, just saying i feel a little bit uncomfortable",0,0,0,0.6125123500823975,0.5086329579353333,0.5313343405723572,0.0,accept,unanimous_agreement
1523380785,12109,here it looks clear that `first_free_time` should be renamed to include the words rdb_client,0,0,0,0.98708176612854,0.9937824606895448,0.9922882914543152,0.0,accept,unanimous_agreement
1523382054,12109,why do we need to clear the flag here?,0,0,0,0.9587438702583312,0.9868742823600768,0.985355019569397,0.0,accept,unanimous_agreement
1523490966,12109,wrong order? [code block],0,0,0,0.5460181832313538,0.9909921884536744,0.9216423630714417,0.0,accept,unanimous_agreement
1523507308,12109,what about 32bit?,0,0,0,0.9868153929710388,0.9853602051734924,0.9920151233673096,0.0,accept,unanimous_agreement
1523545789,12109,[a link] this is also one reason why rax would be a better choice.,0,0,0,0.9740254282951356,0.9870255589485168,0.9922053217887878,0.0,accept,unanimous_agreement
1523562368,12109,"we can increase it to 60, but then i would like it to be configurable so i won't have to wait a full minute just to test it.",0,0,0,0.9322763681411744,0.9305087327957152,0.9899163842201232,0.0,accept,unanimous_agreement
1523567503,12109,"currently the client stays in `clients_to_close` list, and the server tries to close it every time. but i will have to fix it anyway so `rdb_client_disconnect_time` is better fit",0,0,0,0.982093334197998,0.9812829494476318,0.9824061393737792,0.0,accept,unanimous_agreement
1523612467,12109,"while i was writing it, i thought cob overruns would be handled here during the grace period. i now believe that we won't be able to reach this point under such circumstances. for now, i will remove it, and then determine the cob overrun case once i have covered it with tcl tests.",0,0,0,0.9417682886123656,0.9832459688186646,0.9821001887321472,0.0,accept,unanimous_agreement
1523614051,12109,the rdb flag is sufficient however we use it for logs and other stuff so turning off the flag will cause confusion. i agree that using `client_protected` may cause wired bugs in the future. i will use dedicated flag.,0,0,0,0.9806674718856812,0.9902902245521544,0.9783074855804444,0.0,accept,unanimous_agreement
1523621777,12109,"thanks, i will rename all occurrences",1,1,0,0.7572953104972839,0.8125913739204407,0.5710065364837646,1.0,accept,majority_agreement
1523634024,12109,"firstly, we must decrease connection refs. if conn->refs does not equal zero when we get into callhandler, then the connection will not be freed. [code block]",0,0,0,0.9861552119255066,0.9933502078056335,0.9940832257270812,0.0,accept,unanimous_agreement
1523646599,12109,it will raise a bug on 32bit machine! as suggested we should use rax instead of the dictionary as it is already implemented in this context. thanks!,1,1,1,0.9779003262519836,0.977638304233551,0.9876837134361268,1.0,accept,unanimous_agreement
1523668535,12109,ack. will use rax instead ok dictionary,0,0,0,0.9881560802459716,0.8724281787872314,0.948891282081604,0.0,accept,unanimous_agreement
1524103505,12109,you're right.,0,0,0,0.9367263913154602,0.7213375568389893,0.7370946407318115,0.0,accept,unanimous_agreement
1524261320,12109,"we also don't wanna wait 5 seconds to test it, so setting it longer is good.. we can add a debug command to tune it for testing",1,0,0,0.7822513580322266,0.90789133310318,0.8264521360397339,0.0,accept,majority_agreement
1525036213,12109,"`raxfind()` had changed, perhaps you could merge unstable.",0,0,0,0.9877493977546692,0.983772337436676,0.993880033493042,0.0,accept,unanimous_agreement
1527448821,12109,"i personally think these two lines are simple enough to just be cloned rather than create a method for that. same goes for removeclientfromraxgeneric, and lookupclientbyidgeneric",0,0,0,0.957287073135376,0.9809979796409608,0.9329702854156494,0.0,accept,unanimous_agreement
1527451789,12109,"i.e. these two mechanisms, each needs primitive functions for adding, removing, and lookup (so that the caller is simple), but i don't think they have to share code.",0,0,0,0.9785282015800476,0.9816434979438782,0.9856433868408204,0.0,accept,unanimous_agreement
1528873331,12109,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1529007631,12109,"not sure how this is related. i meant the top comment of the pr (which will later become the commit comment when squash-merging). i.e. that comment should describe the motivation, benefits, design, interface changes, any regressions or additional unrelated changes, etc. so that someone can read that comment and know all the important bits without reading the code",0,0,0,0.9372531771659852,0.9832528829574584,0.9525827765464784,0.0,accept,unanimous_agreement
683689833,9323,can we leave this in cluster.h and import it where we need it?,0,0,0,0.988194465637207,0.9948601722717284,0.9947277903556824,0.0,accept,unanimous_agreement
684999246,9323,"i think it may be a cleaner approach to turn on both `server.loading` and `server.async_loading` in our scenario. this way, all the existing code that checks the `loading` flag will not need a change, and we'll only need to add a few exceptions like `server.loading && !server.async_loading`.",0,0,0,0.9759615063667296,0.9908321499824524,0.970127284526825,0.0,accept,unanimous_agreement
685044438,9323,"unlike before, now we're not copying the other db members (e.g. blocking_keys, watched_keys). we should at least set them all to null (calloc or memset).",0,0,0,0.9846512079238892,0.9912511706352234,0.9873128533363342,0.0,accept,unanimous_agreement
685124417,9323,"we may have a few issues with modules (the more complicated ones, which have out of keyspace global data). first, till now the modules were aware of a concept of backup and restore, and who knows what they actually do with it, and now instead they may need to be aware of a concept of temp db. secondly, they may rely on the fact that during that loading time no commands are received. thirdly, some may even themselves call rm_call commands on the data during loading. please share your thoughts. p.s. i think it may be ok to avoid using this mode when modules are involved, or maybe decide to make a breaking change in the module api around that area, i think not many modules started using it, and not many people use this swapdb feature.",0,0,0,0.9102135300636292,0.8630324602127075,0.9089235067367554,0.0,accept,unanimous_agreement
685410493,9323,"i think this method belongs in db.c, maybe we want a thin wrapper for it here, or maybe we wanna give up all the thin wrappers (their main purpose was their doc comments i think) [code block]",0,0,0,0.9809040427207948,0.9886420369148254,0.9887577891349792,0.0,accept,unanimous_agreement
685422022,9323,"you mean the call to emptydb? i think that's exactly what you intended. i.e. you're at this point rdb.c won't touch the main active db, will only load data into the temp one, and only when you swap them eventually you're logically flushing the old one. for watched keys, etc, we'll handle everything then, and for modules, there's no good way to tell what can happen, we'll discuss that in the different comment. or am i missing your point in that todo?",0,0,0,0.9299624562263488,0.9789857864379884,0.966086447238922,0.0,accept,unanimous_agreement
685426895,9323,"i mentioned in one of my first comments that internally, `server.loading` should be also set when async_loading is active, i'm not sure yet if we wanna apply that on the info loading flag too. i.e. if we do, then existing code that looks at that flag will notice redis is loading (even though commands don't fail with `-loading`).",0,0,0,0.9867308139801024,0.9884069561958312,0.9890822172164916,0.0,accept,unanimous_agreement
685436033,9323,i'm not sure this rename is beneficial.,-1,-1,-1,0.9014756679534912,0.917174994945526,0.851813793182373,-1.0,accept,unanimous_agreement
685446527,9323,"this function is not as generic as it seems (by it's name), the implementation and behavior are quite specific for placing the newly loaded temp db at the main active one, and the old active one in the temp. logically, that's where we change the main one.... so i think we need a better name for it, and we certainly need a beefier doc comment.",0,0,0,0.920627236366272,0.7829840779304504,0.9334954023361206,0.0,accept,unanimous_agreement
685463726,9323,"the todo was more questioning what is mentioned in the original comment: /* old comment: we call to emptydb even in case of repl_diskless_load_swapdb * (where disklessloadmakebackup left server.db empty) because we * want to execute all the auxiliary logic of emptydb (namely, * fire module events) */ mainly about modules, so touching this again after discussion on how to handle them.",0,0,0,0.9451661705970764,0.9919015765190125,0.9883931279182434,0.0,accept,unanimous_agreement
685472943,9323,"that's what i was afraid. could be that some tool (for example a load balancer) is checking for the ""loading"" from info instead of sending another kind of command. but at the same time, it's not a breaking change to show info loading: 1 without responding commands with `-loading`. won't change behavior for those that simply upgrade redis, it's just that it will require tweaking to take advantage of this implementation if they rely on info. so wouldn’t this option be on the table? i'd be glad to change it to not have the info async_loading as well, but we have plenty of info loading_* properties during loading that can be useful, even to monitor the state of the server during this period of degraded performance or in case something goes wrong. this information without any loading or async_loading to tell that these status properties are present there sounds inconsistent. personally i’d like to see either one or both in info during async_loading, but my familiarity on its usage out there is limited and in practice, for our individual use cases it’s not relevant because we use ping for probes. just thinking more on the general public of course.",-1,-1,-1,0.779668390750885,0.8479971289634705,0.8212471604347229,-1.0,accept,unanimous_agreement
685474219,9323,reverting this part,0,0,0,0.9560450315475464,0.9663099050521852,0.9930019974708556,0.0,accept,unanimous_agreement
685478530,9323,"thanks, will do",1,1,1,0.6849675178527832,0.9089723825454712,0.9016011357307434,1.0,accept,unanimous_agreement
685484844,9323,"thanks for the review and feedback sounds good with applying the behavior only when replica was previously in sync with a master. could the check rely on master_link_status == up? and what about the cases where we're running standalone and replica started from an unavailable master but managed to load it's own rdb from disk (so it's a master temporarily), then master comes up shortly and starts full sync?",1,1,1,0.7834258079528809,0.97034752368927,0.9791471362113952,1.0,accept,unanimous_agreement
685941509,9323,"i gave it a lot of thought, here's what i think. here's a list of scenarios: 1. a replica gets disconnected a gets a full-sync when it reconnects 2. a replica was connected to one master and got redirected to a new master (of the same replication chain) and got a full sync for some reason. 3. redis was restarted from rdb file (after a graceful shutdown), and has replicaof config, attempted a partial sync with the replid it got from the rdb file, but gets a full sync. 4. the replica was a master till now and got some data from that era, then gets a replicaof command and does a full-sync 5. the replica started empty and is attempting it's it's first sync ever. 6. the replica was replicating from a certain master, and is now full-syncing from another master that's completely unrelated to the previous one (i.e. imagine a sharded db with two shards, and two replicas, m1, m2, r1, r2, and now r2 that has the data of m2 is made a replica of r1, so it gonna get the data from m1. we don't want it to serve the data it has from the past). i think the first 3 scenarios want so allow clients to read the data, but on the last 3 we don't! i think that the rule here is that if the current dataset in the db represent a valid point in time of of the master're were full-syncing from, then we wanna allow reads, but if it doesn't represent a certain point in time of that master (possibly represents data of another master, or replication chain), then we don't want to serve reads. i think the only way to tell that is if in `slavetrypartialresynchronization` we get a full-sync with the same replid that we asked for (different offset since the offset we asked for doesn't exist in the backlog anymore). the disadvantage is that there's one case that it'll miss: if the master at the head of the replication chain changed, and we switched the replid, then we reconnect and instead of getting successful partial-sync, we happen to get a full one. in this case we have no way to tell that in fact the old replid is actually an valid point in time of the new one. this explanation is a bit long and messy, i hope i managed to convey the idea.",0,0,0,0.9081289768218994,0.9801586866378784,0.7774924039840698,0.0,accept,unanimous_agreement
686703222,9323,"trying understand better (sorry the lack of c skills) `blocking_keys, watched_keys, ready_keys` are all dictionaries the same way as dict and expires, but only `dict` and `expires` are swapped in the end. does it make sense to init `dict` and `expires` with null and then `blocking_keys, watched_keys, ready_keys` with `dictcreate`?",-1,-1,-1,0.9749835133552552,0.9701364636421204,0.8621076345443726,-1.0,accept,unanimous_agreement
686714639,9323,"you can either just replace the `tempdb->dbarray = zmalloc()` with `calloc` (zeros the memory it allocates). or, inside your loop over `server.dbnum`, you can `memset(&tempdb->dbarray[i], 0, sizeof(redisdb));`. in theory, we should have created an array that only holds the `dict` and `expires` members, but since we pass that `redisdb*` to functions that work with that type, we can't. so i'm just trying to make sure we have null pointers there, and not random (uninitialized) ones.",0,0,0,0.9839043617248536,0.9918044805526732,0.9913017153739928,0.0,accept,unanimous_agreement
686786804,9323,"i am not aware of a module that performance rm_call during load. but modules definitely assume there will be no traffic during load. with this pr we will have to change this assumption. i believe, in order not to break existing modules, we will need to disable this new feature if a module does not state that it supports it (just like with short-read error during rdb load). wdyt?",0,0,0,0.9376575350761414,0.8745792508125305,0.9715691804885864,0.0,accept,unanimous_agreement
686799116,9323,this is now swapmaindbwithtempdb,0,0,0,0.988671898841858,0.9902731776237488,0.9941895008087158,0.0,accept,unanimous_agreement
686799366,9323,"added your method comment, renamed to swapmaindbwithtempdb, moved to db.c (merging with dbswapalldatabases), removed thin wrapper from replication.c.",0,0,0,0.9889554381370544,0.995790958404541,0.9954487681388856,0.0,accept,unanimous_agreement
686826035,9323,"thinking about the case that is hard to deal with: i assume this is case 6. when could that happen (that a replica will follow a master of another shard)? is that only if some replicaof command was raised? could we track if any replicaof was executed since last successful replication? then if there was any, we simply don't serve reads during replication. sounds like a simple bit value that we set 1 when replicaof is executed and reset to 0 when successful replication finishes.",0,0,0,0.9804949760437012,0.894310474395752,0.94437837600708,0.0,accept,unanimous_agreement
687475169,9323,"the case i was describing last, which is not part of 1..6 is this: * imagine a replication chain a <- b <- c (i.e. a is the master at the head of the chain) * now normally, if b is promoted to be the new master, and a becomes a replica of b or c, what will happen is that b generates a new replid, and disconnects c. c then re-connects and succeeds a partial sync and acquires the new replid * but if instead c takes too long to reconnect and the psync fails and results in a full-sync, then it'll see that the replid it got is different than the one it asked for, and in our case (if we choose to take my suggestion in this comment), will avoid doing a swapdb based replication (or at least avoid serving traffic during the loading). lets call this case 7. it is different than 6 since in 6 we were talking of two different masters, not holding different points in time of the same data. i think this compromise is ok, and i don't think case 7 is very likely, so i still think we can continue with the suggestion i gave in my comment. feel free to suggest a better idea. the context is, how to decide in which cases to use swapdb based diskless repl and still serve clients during loading, and in which cases to avoid that (read my suggestion [a link]",0,0,0,0.965717911720276,0.987927258014679,0.9899449944496156,0.0,accept,unanimous_agreement
687498993,9323,"applying this logic, when you have a setup with cluster disabled containing 1 master and some replicas and the master restarts, then we still won't serve reads during full sync because master will come up with a new replication id, but if it's not cluster and we know that no replicaof was issued, isn't always the case it's safe to continue serving reads?",0,0,0,0.9831748604774476,0.979660987854004,0.989965558052063,0.0,accept,unanimous_agreement
687633866,9323,"you're right, but that's actually another bug. when the master restarts the replica shouldn't do full-sync: #8015 i think that counting replicaof commands, or keeping track of whether or not the replicaof command was with the same ip+port pair or different ones, is the wrong thing to do. also note that it would also mean that when you switch to replicate from one source replica to another (in a replica chain), this will fail (we'll think we got connected to a new master), whereas my replid design will succeed. in fact we have that replid mechanism for exactly that reason (to know which master/timeline we're part of). we can even solve the case that i said is problematic (case 7), if we improve the protocol. i.e. some future psync can use multiple replid+offset pairs when asking for sync, or and the psync reply can carry multiple pairs back, and even carry part of the backlog. but we should lave that out of the scope now, since it requires protocol changes.",-1,0,0,0.6452251076698303,0.7839879393577576,0.9683334827423096,0.0,accept,majority_agreement
687673837,9323,"thanks for clarifying that suggestion about checking for an issued replicaof would be only when replid is different in the handshake (and only for cluster disabled if that helps). but i see the point to make a proper fix in the protocol. also, the pr mentioned relies on master loaded from rdb (i guess masters using rdb as primary persistence are not common anymore because that has high data loss potential and aof is just available to be used, or i’m wrong?) in summary, i’ll be glad to move on, but the original issue i thought to be solving wouldn’t be solved, even though there are still other improvements. drifting a bit, the scenario i’m trying to cover is to make redis more reliable when used as a primary database and not only as cache. i’m using a standalone setup to achieve virtually no data loss (having fsync=always in master for example). but it’s impossible to restart master in this scenario without putting down all replicas afaik (unless there’s some manual job to disconnect them and reconnect one by one). but in kubernetes everything could happen.",1,1,1,0.8956357836723328,0.9584861993789672,0.978131115436554,1.0,accept,unanimous_agreement
687998750,9323,"you're referring to graceful restart, right? (not a crash recovery) see the comment i posted in [a link] i think maybe that can solve both of your problems, and also get you faster startup time. i don't like the idea of matching replicaof commands and looking at their args. i do like to solve this problem for graceful restarts, even when aof is configured. p. s. there is some [a link] about annotating aof, but i still think it's not much good for graceful restarts, only crash recovery.",-1,1,0,0.9074895977973938,0.6718006134033203,0.7693231701850891,,review,no_majority_disagreement
691922936,9323,"i had a lengthy discussion about this with . we think the current plan is good. i.e. * if there's a psync, there's no problem. * if there's a full sync with the same replid, and the user uses repl-diskless-load=swapdb, we'll keep serving reads. * if there's both a full sync and a replid change (either because of replication topology change or a master restart), we won't serve reads during sync. * however, since we're gonna implement #8015, we don't expect full syncs after a graceful master restart. we can proceed to implement this mechanism then.",0,0,1,0.5700257420539856,0.9338126182556152,0.95393568277359,0.0,accept,majority_agreement
691928309,9323,"this change is gonna break modules that use the `redismoduleevent_replbackup` mechanism anyway, so i suggest the following: 1. we deprecate `redismoduleevent_replbackup`. i.e. starting redis 7.0, we never fire that event. we do that since in the new ""swapdb"" mechanism there's no concept of backup and restore, instead there's a concept of temporary db. 2. we create a new api named `redismoduleevent_replasync`, holding 3 sub-events; started, completeed, aborted. 3. we add another module flag for `redismodule_setmoduleoptions` with which the module can declare it supports this mechanism, i.e. redismodule_options_handle_repl_async. 4. in replication.c, if there are modules loaded which registered a data type, and didn't declare they're supporting this, we fall back to the alternative (either the `on-empty-db` diskless replication, or disk-based replication).",0,0,0,0.9703415036201476,0.9937222599983216,0.963129997253418,0.0,accept,unanimous_agreement
694827528,9323,i believe the last commit settles this strategy then. added an extra test as well.,0,0,0,0.9759883284568788,0.976962685585022,0.9869688153266908,0.0,accept,unanimous_agreement
695163690,9323,"some styling issues.. i can also fix later, when we're near complete... [code block]",0,0,0,0.9533444046974182,0.9859139919281006,0.7577245831489563,0.0,accept,unanimous_agreement
695956417,9323,"changes for module events done in last commit. ajusting the current tests soon, but i would like to hear how much of the deprecated events we need to keep first.",0,0,0,0.9820985794067384,0.942011296749115,0.9918116331100464,0.0,accept,unanimous_agreement
698016644,9323,"it occurred to me for a moment that maybe the ""data type"" part should be dropped, since modules with aux data can also be affected. then i realized that we are lucky that these aux fields are only possible when data type being registered. so i just wanna check with you that you don't see any problem with other modules, i.e. ones that use rm_call or rm_openkey",0,0,0,0.9101320505142212,0.7126650810241699,0.907833456993103,0.0,accept,unanimous_agreement
698017782,9323,"if we deprecate `redismoduleevent_replasync`, we surely still wanna keep it in the header file, so old modules can still handle it (although their code that handles it is now dead code) when used on new redis. but what about the documentation? do we wanna drop the old api from the documentation, or keep it here with a deprecation notice?",0,0,0,0.9862841367721558,0.9884763956069946,0.9848238229751588,0.0,accept,unanimous_agreement
698019132,9323,i think that maybe we better fire the event before discarding the db. maybe modules will find that more useful. i.e. they're gonna get a bunch of `free` callbacks and they'll wanna know if these callback are for actual data or temp data. do you think we need to have a post discard event too?,0,0,0,0.9791755676269532,0.9842196106910706,0.9815576076507568,0.0,accept,unanimous_agreement
698019351,9323,maybe we better call this event before the call for `swapmaindbwithtempdb`. wdyt?,0,0,0,0.988024652004242,0.9891133308410645,0.9918930530548096,0.0,accept,unanimous_agreement
705205344,9323,"yes, i believe pre and post could be useful.",0,0,0,0.8939072489738464,0.932979166507721,0.9633098244667052,0.0,accept,unanimous_agreement
705207943,9323,"i believe yes when the main db (which is now the temp db) will be deleted, a module will get the free function called, right? i believe a module would like to know that those free happen on the main db after it was swapped.",0,0,0,0.9089969992637634,0.9886054396629332,0.989370584487915,0.0,accept,unanimous_agreement
705208341,9323,and maybe also a done notifcation? or do we get any other notification that will indicate done?,0,0,0,0.985600769519806,0.9909272193908693,0.994358479976654,0.0,accept,unanimous_agreement
705235206,9323,"yes, i think we better have both",0,0,0,0.9383787512779236,0.8752650022506714,0.9823007583618164,0.0,accept,unanimous_agreement
706833966,9323,should it then be: 1. redismodule_subevent_repl_async_aborting 2. redismodule_subevent_repl_async_aborted ?,0,0,0,0.9853283762931824,0.9942675232887268,0.9928911924362184,0.0,accept,unanimous_agreement
706833986,9323,should it then be: 1. redismodule_subevent_repl_async_swapping_db 2. redismodule_subevent_repl_async_completed ?,0,0,0,0.989026129245758,0.9935059547424316,0.9946512579917908,0.0,accept,unanimous_agreement
706960428,9323,"i think your change for #9398 is right, since, before `swap db`, all data is not changed. maybe you could remove the same comments and add some new comments for explaining current `swapdb` mode special behaviors. btw, for redis multi line annotation, the format is [code block]",0,0,0,0.9738450646400452,0.9921848177909852,0.9187018871307372,0.0,accept,unanimous_agreement
707285843,9323,"i'm ok with what you suggested, but maybe a better alternative could be something like: 1. redismodule_subevent_repl_async_discard_start 2. redismodule_subevent_repl_async_discard_done (or abort_start / abort_done). the advantage is that it's a common prefix for a start and end of the same operation (rather than two similar words with ing and ed suffix)",0,0,0,0.9652557373046876,0.9770747423171996,0.7967065572738647,0.0,accept,unanimous_agreement
707291761,9323,"ohh, i just realized the discard is (always) async. so the module can't use these start / done notifications to know know if a free callback is part of the discarded database or the other one... i suppose that can be a real issue for some modules, and they'll have no choice but avoid declaring this capability. for the other ones, i suppose firing the event before we start discarding is slightly better. what do you think?",0,0,0,0.9491804242134094,0.8791348338127136,0.8457858562469482,0.0,accept,unanimous_agreement
707293000,9323,"same as the other discussion: [a link] there's probably no value in both start and end events, and if we have just one, better have it before the action imho.",0,0,0,0.980130672454834,0.988959789276123,0.967000126838684,0.0,accept,unanimous_agreement
707308254,9323,"i actually believe that we should not check if a module created a datatype here, a module might need to be aware of this feature even if it does not have a datatype. for example, a module that collects stats about the keyspace. such module will probably register on keyspace events, it will collect stats and it will want to be aware of possible swap db to know how to handle loaded events correctly. i agree that without loaded events, only modules with datatypes need to be aware of this feature, but the loaded event breaks this assumption.",0,0,0,0.8984465003013611,0.979633092880249,0.9708104133605956,0.0,accept,unanimous_agreement
707310256,9323,ok. thanks. so let's remove the `listlength(module->types)` part,1,1,1,0.9711869955062866,0.8040841817855835,0.9092847108840942,1.0,accept,unanimous_agreement
707310559,9323,"agree, do not see other choose ...",0,0,0,0.8736411333084106,0.8861237168312073,0.9415364861488342,0.0,accept,unanimous_agreement
707329882,9323,"re-posting an old comment that got lost: i think it may be a cleaner approach to turn on both `server.loading` and `server.async_loading` in our scenario. this way, all the existing code that checks the `loading` flag will not need a change, and we'll only need to add a few exceptions like `server.loading && !server.async_loading`.",0,0,0,0.9601926803588868,0.9878808259963988,0.9838137626647948,0.0,accept,unanimous_agreement
707579653,9323,", maybe a small confusion, but what we have added is redismodule_subevent_repl_async_load_aborted, for the case we started loading on tempdb then discarded due to failure. there's also the discard that happens after successful load. in this case we fire a redismodule_subevent_repl_async_load_completed should the abort really become discard (from your comment here) and be fired only on the failure scenario?",0,0,0,0.983035445213318,0.9873661994934082,0.9154343008995056,0.0,accept,unanimous_agreement
707580073,9323,"did you copy that from somewhere? it look logical, but maybe missing from the old code, even in a non-swapdb-based diskless loading..",0,0,0,0.9857032895088196,0.9931806325912476,0.9932475090026855,0.0,accept,unanimous_agreement
707581188,9323,why is that done here? (there's another copy of the same logic below) maybe a merge conflict resolution issue..,0,0,0,0.8947305679321289,0.9856707453727722,0.989589512348175,0.0,accept,unanimous_agreement
707589752,9323,"some of your multi-line block comments have indentation issues . in this case it's not even a new comment, so i suppose maybe your editor is doing this? please go over them. [code block]",0,0,0,0.9841320514678956,0.9619776606559752,0.9476546049118042,0.0,accept,unanimous_agreement
707593878,9323,"i now realize (or maybe i managed to forget it), that there's a case in which we'll do a swapdb diskless loading, but without async loading, i.e. we don't allow reads during loading. in that scenario, maybe we still wanna support the old module api (the one about backups)? and still do swapdb? current code will just fall back to disk-based loading. i must say i don't like my suggestion above (too complicated), but wanted to raise it anyway.",0,-1,0,0.5192312598228455,0.5126228928565979,0.4991005063056946,0.0,accept,majority_agreement
707597482,9323,i agree with your earlier suggestion to extract this code (that's now exists in two different places) to a function. i think a proper name can be: [code block],0,0,0,0.979774296283722,0.973691701889038,0.977080225944519,0.0,accept,unanimous_agreement
707599734,9323,"as suggested earlier, i think the `loading` flag should always be set, even when `async_loading` is also set. this will let you revert many lines where you did `loading || async_loading` or `!loading && !async_loading`.",0,0,0,0.9875461459159852,0.992438018321991,0.9903918504714966,0.0,accept,unanimous_agreement
707600625,9323,"as you suggested, unlike the code inside redis, which will always set the two flags, i agree that the `loading` flag in info should be off while doing an async loading. so you'll need this change: [code block]",0,0,0,0.9843445420265198,0.9921408891677856,0.9913634061813354,0.0,accept,unanimous_agreement
707602428,9323,you'll also need to modify `processcommand`: [code block],0,0,0,0.9885593056678772,0.9910220503807068,0.9957958459854126,0.0,accept,unanimous_agreement
707606945,9323,this wait is now ineffective. we need another way to check. maybe look at `master_sync_in_progress` or set `replicaof no one` and look at `role`?,0,0,0,0.9480063915252686,0.758614718914032,0.9884155988693236,0.0,accept,unanimous_agreement
707611364,9323,"where there any changes in the new tests since my last review (before you rebased)? i rather review the diff and not re-read the whole thing, but i can't find the old commit in gh.",0,0,0,0.973365068435669,0.9652400612831116,0.990519642829895,0.0,accept,unanimous_agreement
707613641,9323,"please disregard our recent comments about the before and after. i.e. all the aborting / aborted and discard_start / discard_done. they where all about a way for the module to be able to distinguish between `free` callbacks of the main db, and the temp db, but since the freeing is always done in the background, the before and after notifications are no good. the only think that's left to change imho is that we prefer that the aborted and completed events be fired before the freeing starts rather than after it.",-1,0,0,0.5047923922538757,0.9811407327651978,0.9121688008308412,0.0,accept,majority_agreement
707628286,9323,no changes in the tests. the big rewrite is just a rebase + integrating with the 2 conflicting prs,0,0,0,0.982475757598877,0.9789645075798036,0.9878798127174376,0.0,accept,unanimous_agreement
707630418,9323,done then ;) thanks,1,1,1,0.9781824350357056,0.994573414325714,0.9948580265045166,1.0,accept,unanimous_agreement
707632310,9323,so i guess method name becomes `modulehandlereplasync`? (see change),0,0,0,0.9881276488304138,0.9935216307640076,0.9943139553070068,0.0,accept,unanimous_agreement
707633508,9323,"done, extra change here is that this routine is now only executed for swapdb in case it's not asyncloading.",0,0,0,0.9882330298423768,0.993388295173645,0.9928613305091858,0.0,accept,unanimous_agreement
707637731,9323,"seems to be really some merge issue, but also interesting, why it's not the first statement? seems cheaper than the getexpire thing to return 0 (to be done in some other pr if that's the case, i'm reverting).",0,0,0,0.9345232844352722,0.9737278819084167,0.973856806755066,0.0,accept,unanimous_agreement
707641047,9323,maybe module**s**handlereplasync?,0,0,0,0.9856659770011902,0.9942147135734558,0.9948915243148804,0.0,accept,unanimous_agreement
707641443,9323,"actually, `module` is the prefix for all methods. so maybe `moduleallmoduleshandlereplasync`?",0,0,0,0.9879767298698424,0.994964361190796,0.9936424493789672,0.0,accept,unanimous_agreement
707643554,9323,"styling: now that the `if` is a one liner, the curly brackets go in that same line.",0,0,0,0.9882583022117616,0.991821587085724,0.9910770654678344,0.0,accept,unanimous_agreement
707646689,9323,"i don't think that's right (to put that `if`). you mean that if `asyncloading` is true, it means we're still connected to the same master, and thus there's no need to discard the replication backlog and disconnect replicas? i don't think that's right.. if we are forced to do a full sync (even if that's the same master), we have no way to know what changed, and we can't afford future partial syncs. anything i'm missing?",0,0,0,0.7349523305892944,0.5305805802345276,0.8464229106903076,0.0,accept,unanimous_agreement
707651132,9323,"oh i see! reverted, thank you",1,1,1,0.987812340259552,0.99131178855896,0.9921127557754515,1.0,accept,unanimous_agreement
707665181,9323,i have raised this question to here: [a link],0,0,0,0.9728400111198424,0.9680909514427184,0.9951474070549012,0.0,accept,unanimous_agreement
707669496,9323,"_""current code will just fall back to disk-based loading.""_ maybe it's the late time of the day =d, but i can't see this. it should still do the diskless load, but returning loading status, right?",0,0,1,0.923128068447113,0.9563605189323424,0.9179782271385192,0.0,accept,majority_agreement
707679631,9323,what happens? because this test still runs under and test swapdb on sync loading mode,0,0,0,0.9852296710014344,0.970036506652832,0.9927103519439696,0.0,accept,unanimous_agreement
707698235,9323,"it's right, but it's better if the implentation of slot-to-key can be hidden in cluster.c. slottokeycopytobackup and slottokeyrestorebackup did this. i have an idea about this. i'll comment more tomorrow.",0,0,0,0.9703200459480286,0.9034664034843444,0.9579763412475586,0.0,accept,unanimous_agreement
708041030,9323,i was asking about the `dirty++`,-1,0,0,0.6429587602615356,0.9792363047599792,0.9874637126922609,0.0,accept,majority_agreement
708043072,9323,[code block] turning off `enabled` in `usedisklessload` means it'll be disk-based.,0,0,0,0.9887729287147522,0.995319664478302,0.9942759871482848,0.0,accept,unanimous_agreement
708055981,9323,"ohh, right, no async loading because replid changed. i saw you removed this code, and concluded it's an async loading: [code block] so a recap, we now have: 1. either disk-based or disk-less that's not `swapdb`, in which case the loading flag is set, and info keyspace will be emptied. 2. diskless swapdb when replid changed or modules with issues are present, in which case loading flag is set, and keyspace is not emptied. 3. diskless swapdb when replid didn't change and no modules with issues, in which case loading flat is off, and keyspace is not emptied. i.e. before this change we had case 1 (which was also the case when swapdb was used), and no such distinction between the loading flag and the keyspace. bottom line, the change you made in the test was only needed for the keyspace, not the loading flag. so the test is fine.",0,0,0,0.9710432887077332,0.9445679783821106,0.9611589312553406,0.0,accept,unanimous_agreement
708100762,9323,"to keep the encapsulation of slot-to-key in cluster.c, we can make clusterslotstokeysdata an opaque type. it means that it can only be accessed as a pointer. functions in cluster.c need to be called to do anything with it. here in server.h, just declare it as a struct without declaring the fields. [code block] the rest can be in cluster.c and cluster.h. (actually encapsulation is not that great in redis. we have too much stuff in the header files. things like cluster_slots could actually be defined in cluster.c instead since it's only used there, but let's not solve that problem in this pr.) [code block] i think `server.cluster.slots_to_keys` can also be a pointer to an allocated structure. it makes it possible to just swap the pointers without using memcpy. does this make sense?",0,0,0,0.9114214181900024,0.9348214268684388,0.9647822380065918,0.0,accept,unanimous_agreement
708206435,9323,"oh, yes. i saw this in many places where db is touched and felt uncomfortable in not having it here as well.",-1,-1,-1,0.9593719244003296,0.924666702747345,0.7831186652183533,-1.0,accept,unanimous_agreement
708215386,9323,"ok, so it's about the modules. that sounds a bit hard to solve. falling to disk-based load creates a requirement on disk space that was not there before, i see. is your suggestion to do a non-async swapdb, and fire the old events for backwards compatibility, or actually bring the whole mechanism of backups back?",0,-1,0,0.8282721042633057,0.905052661895752,0.969534993171692,0.0,accept,majority_agreement
708303396,9323,"i was thinking for a moment that this should actually be incremented by the number of keys in the db, and that this should certainly be done in any diskless replication rather than just on swapdb mode. i.e. in disk-based replication, the rdb we got from the master serves for persistence too, so server.dirty can be set to 0, but in diskless, it should be incremented for each key we load. (somewhat related to [a link] however, i see that on disk-based we don't reset it to 0, so i'm not certain if we should touch it in diskless at all. please let me know if there's anything i'm missing.",0,0,0,0.9013928771018982,0.8329943418502808,0.9726881980895996,0.0,accept,unanimous_agreement
708332098,9323,"i don't want to bring back the old backup/restore code (too complicated to maintain both). i was thinking that maybe in this mode (no traffic during loading), we can support the old module api without bringing back the old backups mechanism, and maybe the modules will be ok with it. i.e. if the modules don't do rm_openkey or any other odd things during loading, they won't be able the tell the difference between the old backup/restore/discard approach, and the new temp/apply/discard approach? you can probably tell me i'm wrong.",0,0,0,0.9007476568222046,0.8600301146507263,0.8980916738510132,0.0,accept,unanimous_agreement
708333325,9323,"regarding the fact it falls back to disk-based, which it didn't before, i don't think that's a major issue. i don't think swapdb is very commonly used anyway, and so are modules, so their combination is not a high concern.",0,0,0,0.9311662912368774,0.9622472524642944,0.9367210865020752,0.0,accept,unanimous_agreement
709087671,9323,"i think we need to keep the documentation and mention it is deprecated, as well as use `__attribute__((deprecated))` to produce a compile time warning.",0,0,0,0.989035665988922,0.9858580231666564,0.9854902029037476,0.0,accept,unanimous_agreement
709091202,9323,"the save policy refers to ""write operations"", not sure if loading an entire rdb should be considered as n operations depending on number of keys or just a single operation. i lean towards leaving it as is.",0,0,0,0.9097136855125428,0.9834449887275696,0.9678833484649658,0.0,accept,unanimous_agreement
709248488,9323,"ok. , please revive the doc comment and add the deprecation notice and attribute",0,0,0,0.9865702986717224,0.9194504618644714,0.9942150712013244,0.0,accept,unanimous_agreement
709250331,9323,"ok, by ""as is"" i assume you mean to increment the counter only once. i.e. before this pr it wasn't incremented at all. and if we do that, we should increment it also in any of the other diskless loading modes (not just swapdb / async). please make it happen, and also mention this ""bugfix"" in the top comment of the pr (will be used for release notes and commit comment when squash-merging)",0,0,0,0.9833807945251464,0.9871485829353333,0.9773852229118348,0.0,accept,unanimous_agreement
709567812,9323,"made the change, but need to confirm the places where it should be `(server.loading && !server.async_loading)` from my search, this is what needs to be analyzed: module.c [code block] multi.c [code block] rdb.c [code block] scripting.c [code block]",0,0,0,0.9858933687210084,0.9930005073547364,0.9954311847686768,0.0,accept,unanimous_agreement
709594664,9323,done and pr description updated,0,0,0,0.9754098057746888,0.975895881652832,0.9874547719955444,0.0,accept,unanimous_agreement
709599816,9323,thanks a lot for the tips do you mind adding a commit with your suggestion? (or maybe a separated pr focused on organizing these types after this is merged as this is probably happening soon?),1,1,1,0.9263168573379515,0.9511353969573976,0.9676520824432372,1.0,accept,unanimous_agreement
709608986,9323,i can maybe make the opaque type preparations before this pr is merged. i prefer that code isn't moved back and forth too much in unstable.,0,0,0,0.9260034561157228,0.9636688232421876,0.9899014234542848,0.0,accept,unanimous_agreement
709892891,9323,"* module.c - i think we can keep the current code that depends only on `loading` so the module will know we're in loading state. * multi.c - this is complicated, that code decides if `call` should put things in slowlog / stats and propagate to the aof / replicas. so this may depend if the exec was received from the aof file or another client, in either case, we don't want to propagate (and it'll also not allow any write commands), but for the slowlog and stats we wanna make that distinction. * rdb.c - this may be similar to the above, i.e. a restore command can fail differently when called from aof vs a client. but actually, we don't expect a restore command during loading on a read-only replica, so i think the code can stay as is (use `server.loading) * scripting.c: * write commands - i don't currently understand how we could have got an eval command on a replica during loading before this pr. maybe that means a replica that's restarting from aof? in that case, we wanna make a distinction again depending on the source of the command. commands that arrived from aof should never fail, and ones that arrive from clients should. * oom - similar to the above. before this pr, eval commands from clients would be blocked during loading, and the check here was in order to never fail evals from aof. we need to make a distinction depending on the client that triggered it. * cluster - same as the above. bottom line, the main complication here is to detect the client while loading. we could check `c->id == client_id_aof` instead of `server.loading` or in the case of scripting.c check `server.lua_caller`. i would love if you can validate these.",0,0,0,0.9762843251228333,0.9854810833930968,0.9776178002357484,0.0,accept,unanimous_agreement
709916298,9323,"i checked the codes about `server.dirty`, sadly its usages and definitions are ambiguous(i can't figure it out it means how many keys changed or event happened), and expiration and eviction doesn't increment it neither, i will open a new issue to discuss it.",-1,0,0,0.9754828214645386,0.8481907248497009,0.5175371766090393,0.0,accept,majority_agreement
710193408,9323,"here i made clusterslottokeymapping opaque. i also made tempdb opaque (implementation fully in db.c). it's based on your branch with one commit added. [a link] `./runtest-cluster` fails, but it fails also with your branch for me. did you run it?",0,0,0,0.9868227243423462,0.9893213510513306,0.9933300614356996,0.0,accept,unanimous_agreement
710244303,9323,in all the cases above (apart from module.c) we should check the client instead of server.loading in module.c i suggest adding redismodule_ctx_flags_async_loading,0,0,0,0.9850612282752992,0.9952876567840576,0.9934792518615724,0.0,accept,unanimous_agreement
710276214,9323,"ok about module.c we can add that. and indeed most other cases actually meant to check if the client is the aof client rather than look at the loading flag. however for rdb.c it's a bit more complicated, since the loading could be either restore command (coming from the master client, an aof or a normal client), but could also be an rdb file (not a command). so fat the loading flag check meant to distinguish between a restore command and an rdb file loading... so now we'll need two checks, first see if this is a command or an rdb file, and then check which client issued it. however, since we don't expect restore commands during async loading, we can decide to keep the current code too.. on a second thought, i'd vote for the complicated one (being more explicit)",0,0,0,0.9390987157821656,0.9349772930145264,0.97904634475708,0.0,accept,unanimous_agreement
710449596,9323,"oh, i always thought these were succeeded on pr build. i just debugged and found a few things: it crashes on this block of inittempdb(): [code block] removing it and, as it should be, adjusting the test to watch for async_loading instead of loading will make it pass. and of course, the test needs to be renamed to fit the changes made. considering it's an area you have previous experience, any suggestion? this block is inspired on your: [code block] but i added to ensure a clean tempdb->slots_to_keys on the when we initialize it prior to loading data on it.",0,0,0,0.8500942587852478,0.9253736138343812,0.9153951406478882,0.0,accept,unanimous_agreement
710494856,9323,"the slot-to-key data is supposed to match what's in server.db[0]. if the db is cleared the slot-to-key data should also be cleared. there is nothing complicated about it. if you fixed it, then i guess you can add my commit (cherry-pick) and fix it the same way?",0,0,0,0.9844126105308532,0.98728209733963,0.9863572120666504,0.0,accept,unanimous_agreement
710497773,9323,"a bit of confusion here, i haven't fixed ;) i mentioned it works when the line is removed, but not necessarily that's the correct to do. i don't understand why the current code to init this tempdb->slots_to_keys simply fails. it's something on other side of the application that blows up when i run this memset.",1,1,1,0.9303303956985474,0.9697727560997008,0.943271815776825,1.0,accept,unanimous_agreement
710504944,9323,i don't know either. i'm not familiar with async load. :),1,1,1,0.9030770659446716,0.9884219765663148,0.9945108890533448,1.0,accept,unanimous_agreement
710505976,9323,it's late here. i will look tomorrow.,0,0,0,0.7967463135719299,0.9228805899620056,0.886555552482605,0.0,accept,unanimous_agreement
710540326,9323,"see last commit ""fix slots to keys handling on swapdb"" correct me if i'm wrong but i don't think we actually needed to store it in the tempdb. previously it was flushed during backup, now i flush right before swapdb. it the replication fails, it's still intact. the cluster test also won't crash with this change anymore (crash unrelated to async_loading fix).",0,0,0,0.9830520153045654,0.9774987697601318,0.9904360175132751,0.0,accept,unanimous_agreement
710788812,9323,"wait a second. when we do async load, do we load the dump into tempdb and then swap? is this how it works? doesn't it mean that we need one slot-to-key mapping for the tempdb and another one for the main db? we can only clear the slot-to-key mapping when we clear the database. if we swap with a non-empty database, we need a matching slot-to-key mapping. if we clear the slot-to-key mapping when the database is not empty, it is easy to create a test case which crashes: delete all keys. there is an assert in slottokeydelentry which will fail.",-1,0,0,0.8782370686531067,0.8919368386268616,0.9508850574493408,0.0,accept,majority_agreement
710827011,9323,"having a bad feeling about the complexity of this whole change now =) so while doing the replication, the calls to slottokeyaddentry should apply to a tempdb slots_to_keys, not to server.cluster->slots_to_keys as it has been in this pr so far? if that's the case, we need to send a pointer to the methods that change server.cluster->slots_to_keys to work on either the temp or server.cluster according to the situation. makes sense ?",1,-1,-1,0.9440791606903076,0.9366655349731444,0.9831162095069884,-1.0,accept,majority_agreement
710998129,9323,"yes. sorry, i didn't closely follow the discussion about slots_to_keys. as long as we keep serving from server.db we need the server.cluster->slots_to_keys to remain the old one. during async loading, we also need dbadd to update the new temporary slots_to_keys. then if we discard the temp db, we discard the temp slots_to_keys, and if we swap the db to be the primary db, we need to copy the tmp slots_to_keys over the primary one.",-1,-1,-1,0.9454728960990906,0.9748898148536682,0.974190354347229,-1.0,accept,unanimous_agreement
711002743,9323,"the last committed changes don't look correct yet. p.s. i don't mind the fact that cluster_slots is moved to server.h, and maybe slots_to_keys being moved to be part of the database. it should only be allocated when cluster is enabled, but i think trying to isolate that part in cluster.c/h and make redis unaware of how many hash slots there are is not worth it. if has another idea i don't mind trying (didn't follow that part of the discussion). p.p.s the cluster tests are indeed not executed on the pr ci (they're too slow), and also the only existing test for that may need some improvement to properly catch errors around this change, please look into that.",0,0,0,0.8078389763832092,0.9340471029281616,0.920214056968689,0.0,accept,unanimous_agreement
711229394,9323,"now hopefully that's what we need, please check again. and thanks for the patience.",1,1,1,0.9505583643913268,0.8887602686882019,0.9791410565376282,1.0,accept,unanimous_agreement
711250886,9323,"i think that the change in your last commit is technically correct, but i must say i don't like it too much. i think it would be better to move this structure to the redisdb struct (to be allocated only when cluster is enabled). this way dbadd would handle it correctly, and the tempdb we allocate during replication would be enough (no need for an extra member in the cluster struct). i think it's ok for server.h to be aware of the slots count, it doesn't have to be abstracted in cluster.h. wdyt? btw, maybe we better block async loading of someone enabled a writable replica? i don't usually care for writable replica, enabling it is an invitation but bugs and inconsistencies. but looking at the current code (""forchanging""), it'll obviously do the wrong thing..",0,0,0,0.7723823189735413,0.6221259236335754,0.4839422106742859,0.0,accept,unanimous_agreement
711267696,9323,"i started with that solution, but then felt forced to have it in a public place in order to not flood methods with tempdb argument. but also agree it would be more self-contained. about writable replicas, they are more for caching calculated results, like those commands with store flag and things like that, right? i'm indifferent, your call ;) btw, now that we just need minor changes, please feel free to make commits. unfortunately i'll be short on time during next week, then i'm more available from the 26th. as i see, we have: - this possible refactoring for the placing temporary slots_to_keys in different location [a link] - adjust some async_loading conditionals as mentioned here [a link] - maybe better support deprecated module api [a link] which maybe is just about doing this: [a link]",1,1,1,0.8897739052772522,0.9937872886657716,0.9503616094589232,1.0,accept,unanimous_agreement
711315541,9323,"the commit i made above makes slot-to-key mapping an opaque type. the isolation is good imo. it's better in cluster.c because the slot hashing and everything else for cluster is there and does not need to be visible outside it. it's easy to extend those functions to pass a slottokeymapping* to slottokeyaddentry() and the other functions, as you said . let's do that! :) that's all we need afact.",1,1,1,0.9846639037132264,0.995735764503479,0.994440257549286,1.0,accept,unanimous_agreement
711726175,9323,"as i said, i don't mind to expose this part of the cluster code in server.h (it's not as complicated as the cluster bus gossip or anything like that), it it's just a trivial listing of keys per slot, i also don't have an objection to the opaque mechanism you created, which seems nice. but the problem is still that unlike the handling of `dbarray` argument to `rdbloadrio` and `db` argument to `dbaddrdbload`, which is able to make sure we add data into the temp db, while commands are serving from another (the one in the `server` struct), this mechanism isn't handling that yet. right? i think that in theory, an opaque `slots_to_keys` pointer should be stored inside the redisdb struct, and if we do that, it solved the above problem (since the `db` pointer is passed around). till now the cluster code got away from that problem because unlike non-clustered redis, redis-cluster only supports one database. but now, we actually have two. p.s. we do have some future plan we have, to drop support for sentinel, by allowing non-sharded clusters with multiple databases and voting replicas. in that case cluster will support multiple databases, but will actually not need the slot-to-key mapping.",0,0,1,0.8946396112442017,0.5732682943344116,0.7297428846359253,0.0,accept,majority_agreement
711991355,9323,"i like the idea of putting the slot-to-key mapping (pointer) inside the redisdb struct. then, a temp db can just be a redisdb and we don't need a specific tempdb struct. the slot-to-key mapping can still be opaque and delegated from db to cluster if we like, independently of that.",1,1,0,0.8447555303573608,0.5128125548362732,0.6577152013778687,1.0,accept,majority_agreement
716195028,9323,"change made, but i couldn't identify based on current code how to precisely apply the deprecated attribute in some cases. for example, before or after the elements?",0,0,0,0.9870133996009828,0.9648454785346984,0.9833230376243592,0.0,accept,unanimous_agreement
716195617,9323,i'm not sure myself. i suggest you try to revive the test code that uses them and see that you get the warning. i guess at least one warning is ok too (if we can't get them all to work).,0,0,0,0.7182210683822632,0.8361312747001648,0.8917498588562012,0.0,accept,unanimous_agreement
716974729,9323,"in current state, it will generate this warning on ./runtest-moduleapi ![a link] using the attribute on redismodule_subevent_repl_backup_* variables wouldn't work. please let me know if that's the desired outcome of the deprecation overall",0,0,0,0.9805371165275574,0.9786489605903624,0.9929284453392028,0.0,accept,unanimous_agreement
718208183,9323,i think one warning is enough. and i think we should convert the test in `tests/modules/testrdb.c` to use the new api. no sense in keeping the dead code anyway (apart from getting the annoying deprecation warning).,0,0,-1,0.6810833811759949,0.8199328184127808,0.548356294631958,0.0,accept,majority_agreement
720669329,9323,just one thing before i commit. is the goal of testrdb.c:replbackupcallback to check if the order of events is correct? we could use some comments to understand this file a bit better.,0,0,0,0.98216712474823,0.9885518550872804,0.991364359855652,0.0,accept,unanimous_agreement
720852157,9323,"i don't quite get the c->id == client_id_aof check as solution. i'm missing something. let's take multi.c [code block] for all situations: - no sync or async loading: we're fine with this code, always call full. - async loading, command is not from rdb or aof: ok, will call full - async loading, command from aof: ok, will call none - async loading, command from rdb (replication, for example): ? - sync loading: what if it's loading from rdb, client_id_aof won't cover it and we will end up calling full, right?",0,0,0,0.8513916730880737,0.962835729122162,0.8613914251327515,0.0,accept,unanimous_agreement
720866974,9323,"i think that what you're missing is that rdb file doesn't contain commands, just raw data. so the only ways for `call` to be called during loading is that it's either from the aof fake client or real client connection.",0,0,0,0.9815130233764648,0.9886000156402588,0.9815728664398192,0.0,accept,unanimous_agreement
720868215,9323,"i think it was attempting to use the callback for the purpose for which they were added, and see that they work correctly. i.e. it's a module with global data, that's stored into the aux fields of the rdb, and it was using the callbacks to create a backup and restore / discard it. similarly i guess the new test should use the new apis, and check that during rdb loading the old data is still accessible, and that if loading fails the temp data (that's already been loaded) is freed correctly, and that it the loading succeeds, the new data is accessible and the old one is released.",0,0,0,0.9799444675445556,0.9823728799819946,0.9840800166130066,0.0,accept,unanimous_agreement
720876004,9323,"changes done, but the complicated way for rdb.c would get quite complicated as we don't have the client there. do you believe it worth passing around for the explicitness?",0,0,0,0.9506866335868835,0.8517245054244995,0.9889940619468688,0.0,accept,unanimous_agreement
720888834,9323,"in rdb.c we can use `server.current_client` if it's null then we're processing an rdb file (or a preamble aof). if it's non-null we can check the id to see if it's the aof client. if it non null and not the aof client, then it's a restore command. like other places, no need to look at the `loading` flag at all. let's wrap that in some macro at the top and document that.",0,0,0,0.9839085936546326,0.9932966828346252,0.9881768822669984,0.0,accept,unanimous_agreement
725479740,9323,"i've been learning the last few days about the module api by looking documentation and code but couldn't understand the reasoning behind the replbackupcallback in testrdb.c. also, i couldn't find what actually uses it or tests it (runtest-moduleapi tests pass if we just remove the callback in current unstable branch). probably we need good documentation about the aux_save and aux_load and how it plays with replication and swapdb (independent of previous implementation or upcoming with this pr). currently: [code block] we could use some description on what redismodule_aux_before_rdb and redismodule_aux_after_rdb are. is it before/after saving/loading it? is it where the aux variables are stored phisically in the rdb stream (before it or after it)? i've learned that the last is the case by reading the code, but ""when"" could be renamed to ""where"" to be explicit it's not a moment in time but a position in the stream. as i understand now, what we'll need to do for the new test - to demonstrate what a real module would need to do - is: - change aux_load to start loading the global vars from stream into equivalent temp vars (if server.async_loading or if some flag set by started tells the async load is in progress (not sure what is better)). - on replasync completed event, set the aux to the temp aux and clear the temp aux. - on replasync aborted event, clear temp aux. makes sense or i missed some part? thanks",0,0,0,0.955707311630249,0.9785401821136476,0.964708149433136,0.0,accept,unanimous_agreement
725602971,9323,"the `when` means it is called before and after the callbacks to save / load the keys. for example, the module has an opportunity to store the total count of keys before the actual keys (so on loading an array can be pre-allocated) or store any other info that he'll need when loading individual keys, or compute some some checksum on their values during serialization and then store that at the end of the rdb. maybe the documentation is not clear enough and needs improvements. you're right that the current code passes even if the callback is completely skipped. i assume it still had some value detecting issues from when it **is** called (like bugs and leaks) your plan seems right, maybe in order to verify this is really working, we need to add some assertions in the tcl code. like make sure to modify these ""runtime"" values during / before async loading, and see that we get the correct value during loading, and also the correct value in case the loading was aborted or succeeded.",0,0,0,0.949792504310608,0.9778398871421814,0.9905378818511964,0.0,accept,unanimous_agreement
725636565,9323,"i think it looks odd that we have that method. the code is identical to the other one, and the `tempdb` argument is not necessarily temp (could be the real db)... i suggest to have just one method doing memset, which takes a db. if we wanna avoid modifying the few calls to slottokeyflush, then we need to make it a wrapper method (that take no arguments and calls the other one)",-1,-1,-1,0.7226527333259583,0.6722474098205566,0.6744537949562073,-1.0,accept,unanimous_agreement
725637355,9323,"i think the indentation changes you added are unwanted, it causes the diff to look as if you changed all these lines, when in fact you just added one (harder to review and also trace back history of things in git log). considering that anyway, one line has a unique indentation to it, i think we can revert the others. maybe the middle ground is to move the `expires_cursor` line to be one before the last, and then the first bulk of lines will have the old (short) indentation, and the last two will have the same long one? or, i'm also ok with leaving all the existing lines as is. i.e. the short ones have extra indentation, and the two long ones have their own way...",0,0,0,0.9018765091896056,0.944762647151947,0.9474446773529052,0.0,accept,unanimous_agreement
725642377,9323,amended last commit reverting this indentation and consolidating the 2 slottokeytempdbflush method,0,0,0,0.9861395359039308,0.992472767829895,0.9947158694267272,0.0,accept,unanimous_agreement
725661403,9323,"if we make `clusterslotstokeysdata` opaque (like i didn't in a code example posted earlier in another comment), we don't need to move these structs and cluster_slots to server.h. we only need a typedef and an incomplete struct.",0,0,0,0.9865618348121644,0.9908163547515868,0.9926803112030028,0.0,accept,unanimous_agreement
725662202,9323,the slot-to-key array needs to be free'd somewhere before the tempdb is free'd. flush just memsets it to zero. maybe we can replace slottokeyflush with two functions: slottokeyinit (allocates it) and slottokeydestroy (frees it)?,0,0,0,0.988080620765686,0.9942408800125122,0.9916627407073976,0.0,accept,unanimous_agreement
725663704,9323,"this code doesn't swap them. it just copies one to the other. don't we want to swap them like we do for dict, expires, avg_ttl and expires_cursor below? also, we don't need memcpy here. we can just swap the pointers, like this: if we want to swap them, don't we want to do something like this? [code block] ... or simpler, we can do this for all db numbers in the for loop below. it will be null for all dbs except 0, but it does matter imo.",0,0,0,0.9738520979881288,0.980655550956726,0.9800628423690796,0.0,accept,unanimous_agreement
730433722,9323,"i see you added `external:skip`, but maybe we should also add the `repl` tag like other tests (they kinda cover the same thing, but who knows what will someone try to skip...)",0,0,0,0.9861878156661988,0.980725347995758,0.9862370491027832,0.0,accept,unanimous_agreement
730434100,9323,this will need to be adjusted once #9323 is merged (not sure which one will be merged first) fyi,0,0,0,0.9781096577644348,0.98919278383255,0.9835749864578248,0.0,accept,unanimous_agreement
730434352,9323,this can take a long time (5-10 seconds). maybe we rather rely on another test (one with no delay) rather than let this one complete loading.,0,0,0,0.972534716129303,0.978659689426422,0.9741952419281006,0.0,accept,unanimous_agreement
730434656,9323,these two (or maybe soon to be 3) tests have a lot on common. maybe we can run them in a `foreach` loop that executes the same code 3 times is a few `if`s to do the variations between them? will also make it easier to realize what's different and make future adjustments.,0,0,0,0.9604037404060364,0.9822362661361694,0.9838502407073976,0.0,accept,unanimous_agreement
730447575,9323,thank you for the suggestions . commited changes for swapping pointers instead of memcpy and splitting slottokeyflush into 2 functions,1,1,1,0.9333735704421996,0.9394730925559998,0.9691357016563416,1.0,accept,unanimous_agreement
730448249,9323,"these 2 new tests are under `tags {repl} {`, isn't already tagged with that?",0,0,0,0.9883280396461488,0.9939748644828796,0.9948585033416748,0.0,accept,unanimous_agreement
730451438,9323,"ohh, right. sorry",-1,-1,-1,0.989810347557068,0.9926282167434692,0.9958209991455078,-1.0,accept,unanimous_agreement
730451581,9323,"isn't that change adding a leak? it used to do only memset, and now it also does malloc.",0,0,0,0.9788851141929626,0.9780344367027284,0.9921839833259584,0.0,accept,unanimous_agreement
730460855,9323,"before, slots_to_keys was a variable declared in clusterstate struct, now it became just a pointer in redisdb struct. if it wasn't a pointer, we would have automatically wasted memory the size of cluster_slots for each db in the array. we just need it to be allocated for db[0]. we actually refer to it without providing the array index all the time. about leak, aren't the calls to `slottokeydestroy` enough?",0,0,0,0.9664387106895448,0.9733738899230956,0.9884493947029114,0.0,accept,unanimous_agreement
730461673,9323,which call to slottokeydestroy? where is it called in the context of emptydb? note that `emptydb` is called every time user runs flushdb. and also on normal disk-based full sync.,0,0,0,0.9903221726417542,0.9950826168060304,0.994587540626526,0.0,accept,unanimous_agreement
730473927,9323,"hah, right. implemented slots to keys as opaque type in last commit. this fix included.",0,0,0,0.9767717719078064,0.7474079132080078,0.968560755252838,0.0,accept,unanimous_agreement
735156282,9323,thanks for all the suggestions. closing as this was implemented.,1,1,1,0.7856844067573547,0.9526078701019288,0.9457614421844482,1.0,accept,unanimous_agreement
736493978,9323,same thing as [a link],0,0,0,0.9871070981025696,0.9904307723045348,0.994337260723114,0.0,accept,unanimous_agreement
736540978,9323,"ohh, sorry, i meant to mention #9166 (not 9323), but yes. i see you copied the modified code to trigger exhaustion of the backlog. resolving this comment..",-1,-1,-1,0.9886576533317566,0.984943389892578,0.9082716703414916,-1.0,accept,unanimous_agreement
736896849,9323,"do you wanna try to handle this comment (and the one below)? do you understand my suggestion? a for loop running the same code 3 times with small variations, one uses delay so we can test the state during loading. one that succeeds (which doesn't have the delay so it's fast), and one that gets aborted and we can check recovery.",0,0,0,0.9816442728042604,0.983914852142334,0.9902715086936952,0.0,accept,unanimous_agreement
738031943,9323,"making the test faster (2.5 seconds instead of 8), risks timing issues (especially in valgrind runs). we can't afford to use the same test for both reading from the replica while it's loading and also checking what happens when it succeeds. we must split it to two tests (or two iterations of the same test), one with a delay and one without.",0,0,0,0.8122852444648743,0.951890230178833,0.927993655204773,0.0,accept,unanimous_agreement
738033393,9323,why did you remove this? i think the replica can reconnect before we realize it stopped loading and then we'll end up waiting for it to finish,0,0,0,0.962549328804016,0.886929988861084,0.9882481694221495,0.0,accept,unanimous_agreement
738035299,9323,"again, for a successful test, i don't think we can accord to attempt to make it slow but not too slow. the test will be unstable and fail from time to time. i think we wanna run the same code twice, once with a delay and once without, and in each run test a different aspect.",0,-1,0,0.9041733145713806,0.6521548628807068,0.7798367738723755,0.0,accept,majority_agreement
738036585,9323,"in this case we don't need to do any funny things, so there's no real need to look at log lines. we can just `wait_for_condition` on `master_link_status` to be `up`",0,0,0,0.9612264633178712,0.9780476689338684,0.9811879992485046,0.0,accept,unanimous_agreement
738037379,9323,"in this case we don't need to do any funny things, so there's no real need to look at log lines. we can just `wait_for_condition` on `master_link_status` to be `up`",0,0,0,0.9612264633178712,0.9780476689338684,0.9811879992485046,0.0,accept,unanimous_agreement
738039085,9323,"i think there's a good chance that this line will miss the train. we didn't set any `repl-diskless-sync-delay`, and there's a chance the replica will re-connect and start bgsave before this config is applied. maybe we can just move it to before we disconnect the replica, or we need `repl-diskless-sync-delay` to delay the full sync a bit.",0,0,0,0.8987998962402344,0.9888352751731871,0.979033887386322,0.0,accept,unanimous_agreement
738040628,9323,"this line doesn't affect a fork that's already in progress (the fork child doesn't see this config change). in the test that checks for completion, we should just avoid setting this config in the first place. again, i think we need 3 tests. 1. checks the status during sync (needs a delay) 2. checks that status after failure (maybe it can be in the same run as the one above. 3. check for successful run (without any delays)",0,0,0,0.9728925228118896,0.9914702773094176,0.9900622367858888,0.0,accept,unanimous_agreement
738807301,9323,"replying here for all your test comments: - i was definitely underestimating the possible timing issues ;) - made another version following your idea to always achieve fast executions and makes total sense - followed the other suggestions in general - asserts now printed as individual test descriptions i know it will be tempting to say we can make variations for loading and async_loading on same test instead of splitting like i did, but i felt it would get quite bloated and hard to read. still, in this version we cover more things than before with just 2 main tests in replication.tcl. test time always under 1s each here.",1,1,1,0.512373149394989,0.9826968908309937,0.9948992133140564,1.0,accept,unanimous_agreement
739791128,9323,"sorry to bother you again, but maybe we don't need this ""delayed"" test? i.e. these assertions can be added into the ""aborted"" one before we abort it. so this means we only have two tests ""aborted"" and ""succeeds"". also, let's rename ""fast"" since the speed is just an internal concern of the test (not to take forever), but what it tests is what happens when it succeeds and fails replication..",-1,-1,-1,0.9892151951789856,0.9800957441329956,0.9807792901992798,-1.0,accept,unanimous_agreement
739791660,9323,"same here.. i.e. on one hand, we wanna test 3 things: 1. state during loading 2. after it is aborted 3. and when it succeeds so it is nice to see 3 tests with 3 titles. but on the other hand, we can combine the the first two and save some time.",0,0,0,0.8976595401763916,0.9665660262107848,0.9527307152748108,0.0,accept,unanimous_agreement
739792540,9323,"same here... we can run that same check (the value of `testrdb.get.before`), both before we abort and after. one more interesting complication, maybe we can find a way to make sure we abort only after the module got the callback and loaded a new value into it's temp variable? i.e. without that check, there's a race, and maybe in some cases we abort even before... maybe we'll add a command like `testrdb.async_loading.get.before` and do a `wait_for_condition` on it? i know it means that module is no longer a naive module that uses the new api to get things done, but it does improve the test... wdyt?",0,0,0,0.947577178478241,0.9832605719566344,0.9765215516090392,0.0,accept,unanimous_agreement
740486983,9323,good point about the race. suggestions applied. thanks,1,1,1,0.9843653440475464,0.9924781322479248,0.9945501685142516,1.0,accept,unanimous_agreement
740848018,9323,"i meant to return the value of `before_str_temp`, so we don't just wait for the notification that async loading started, but also make sure the redismodule_aux_before_rdb was called.",0,0,0,0.9889346957206726,0.994347870349884,0.993200957775116,0.0,accept,unanimous_agreement
740849329,9323,let's also update the comment so state that we wanna abort only after the temp db was populated by redismodule_aux_before_rdb,0,0,0,0.9888867735862732,0.992533802986145,0.9947275519371032,0.0,accept,unanimous_agreement
740849978,9323,"let's also put some comment above the function to mention it's a testing hack to control the timing of the test, and not something a valid module would do.",0,0,0,0.9778456091880798,0.987642765045166,0.9893826246261596,0.0,accept,unanimous_agreement
741396588,9323,"sure thing, done",0,0,0,0.9263406991958618,0.937123954296112,0.961781919002533,0.0,accept,unanimous_agreement
741478239,9323,"i'm not sure why we needed that, since we did have this: [code block] we had it only in the aborted path, but that's also the only one that set it to anything other than 0 in the first place. can you share some time measurements of before and after? in any case, these lines (which i just quoted) are now no longer needed. one more thing, i didn't bother to verify that the new numbers (delay and number of keys) you use are safe to avoid failures due to race conditions and slowness. please make sure they're causing the replication to be long enough so that we're sure we'll be able to interrupt it in the middle (i.e some 5 or 10 seconds should be ok)",0,0,0,0.9391704797744752,0.9484164714813232,0.951839029788971,0.0,accept,unanimous_agreement
741482601,9323,"the new numbers make replication longer. master has twice the keys (from 500 to 1000). the only impact i can see from the number of keys in replica is rdb flushing time to disk (only on valgrind test or when i use absurd amount of keys in my machine). about not needing: `$master config set save """"` aren't the 1000 keys in master going to be flushed to disk when we terminate master server after aborted path? edit: tbh, even in real life i see the server being blocked and slow to terminate when rdb is enabled (delays are after ""saving the final rdb snapshot before exiting."") so rdb-key-save-delay 0 doesn't save us from this, especially on valgrind test where delays are more noticeable",-1,0,0,0.9161009192466736,0.8429960608482361,0.6841127276420593,0.0,accept,majority_agreement
741490368,9323,"can you run that valgrind again so we can see if the ""waiting for process nnn to exit"" disappeared from all these tests after the `set save """"` was added? changing the replica keys to 20_000_000 changed total running time of runtest-moduleapi from 10s to 30s here, and started showing `waiting for process n to exit` about 5 times. but with these same 20 million keys and `set save """"` it's back to the 10 to 11s and there's no `waiting for process` same applies to master, achieved `waiting for process` by increasing to 100000 keys of 10000, but i get fast shutdown in this config when `set save """"`",0,0,0,0.985315203666687,0.9917612075805664,0.9937636256217957,0.0,accept,unanimous_agreement
741497215,9323,"i meant that we no longer need this, didn't suggest to remove `config set save """"` [code block] i've re-triggered the tests (same links). ideally we should tune it so that the ""successful"" test takes about a second or two, and the ""aborted"" test sets delays that would take at least 5 (or better yet 20) seconds, but since we abort it rather early, it also takes a second or two.",0,0,0,0.9809648394584656,0.9927070736885072,0.993708610534668,0.0,accept,unanimous_agreement
741502877,9323,"successful replication here takes about 1.1s. aborted (if not interrupted) about 11s, and interrupted as it is 1.2s",0,0,0,0.985949456691742,0.987637996673584,0.9891625642776488,0.0,accept,unanimous_agreement
741509349,9323,great! that's what we wanted. thank you!,1,1,1,0.991934299468994,0.9959331154823304,0.997552216053009,1.0,accept,unanimous_agreement
742627255,9323,"looks like for some reason you where looking at an outdated version, or maybe when you posted your approval, gh also posted an old comment you composed in the past. either way, in the last version the definition of cluster_slots didn't move (it's still in cluster.h)",0,0,0,0.9855448603630066,0.9858633875846864,0.9856288433074952,0.0,accept,unanimous_agreement
744605630,9323,"noticed that the failure here can happen after we already announced async_load_completed, swapped the databases and discarded the backup. can you please look into it and issue a fix?",0,0,0,0.9865767955780028,0.9857962727546692,0.992992639541626,0.0,accept,unanimous_agreement
753635512,9323,"somehow i think it should not be added `!server.async_loading` here? (a bit confused?) btw, i think `async_loading` should also require a document, maybe missing, i added it in [a link]",0,0,0,0.9675553441047668,0.9902105331420898,0.8806977272033691,0.0,accept,unanimous_agreement
753655567,9323,"it is indeed a bit confusing that in redis both flags are set in this mode, but in info, it's either one or the other. but we concluded that for each one (users or developers) it makes sense to look at it this way.",-1,0,-1,0.6602498888969421,0.8176525235176086,0.5620314478874207,-1.0,accept,majority_agreement
708582744,9166,"afaik the reason the replica buffers and aof buffers are not counted for eviction was because it can cause feedback-loop when we push dels into them. in that sense, since the backlog is now dynamically growing, it should be deducted as well. this means the code will be a lot simpler, right? just use `server.repl_buffer_size`?",0,0,0,0.9854555726051332,0.9907875657081604,0.9876559972763062,0.0,accept,unanimous_agreement
708585533,9166,let's sum them and do one atomicincr,0,0,0,0.9840637445449828,0.9794774055480956,0.9911508560180664,0.0,accept,unanimous_agreement
710030167,9166,"not sure i understand this one, maybe the name / doc should be improved. [code block]",0,0,0,0.97311133146286,0.9863451719284058,0.7406391501426697,0.0,accept,unanimous_agreement
710032897,9166,"the commit comment and pr can refer to the history. the code itself should usually document the current state (unless there are backwards compatibility issues, or any other reason to refer to the history) [code block]",0,0,0,0.9884164929389954,0.993417263031006,0.9952119588851928,0.0,accept,unanimous_agreement
710036980,9166,"i think these variables need a `repl_` prefix (they're only used on replica clients). despite the comments, it's hard for me to understand each of these. let's add some block comment above them to describe this group, and maybe improve the comment next to each of them.",0,0,0,0.958771824836731,0.9678836464881896,0.9759916067123412,0.0,accept,unanimous_agreement
710038008,9166,"why reference just one node? let's make sure this is explained, and refer to that explanation from here",0,0,0,0.983100175857544,0.9899340271949768,0.9879750609397888,0.0,accept,unanimous_agreement
710038554,9166,"since this is **counting** blocks, i guess it should be `long`. btw, do we really need it? can't we easily count them (`id` delta) on the spot when we need it?",0,0,0,0.9821788668632508,0.9907774925231934,0.9896384477615356,0.0,accept,unanimous_agreement
710064668,9166,"maybe split this into several `mem+=` lines each with a comment. i understand the last two compute the rax, the second one the linked list (shared with replicas, right?). and the first one computes the actual bytes. and since the histlen counts the used portion, we need to explicitly add the unused portion..",0,0,0,0.9863722920417786,0.9911500215530396,0.9858686923980712,0.0,accept,unanimous_agreement
710070840,9166,"maybe here's where we wanna use a similar trick to what you did in freememorygetnotcountedmemory? isn't that similar (without adding a loop)? note that there used to be a loop on slaves in `freememorygetnotcountedmemory` (executed per command), so adding one in info is not that bad, but still may be better.. the result of the other approach (what's now in freememorygetnotcountedmemory) is smaller, right? i.e. if the buffers have 100mb (because one replica is slow), and 50% of that is also part of the backlog. the current approach in this function will return 100mb, and the other approach will return 50mb. on the other hand, in case there's no slow replica, and the backlog uses 50mb, and the unsent portion of the replica buffers is just 1mb, then the current approach will show 1mb, and the other approach will show 0, right? so if we define that info field (`mem_clients_slaves`) as memory overhead that's beyond what's in the backlog. the approach that's now in freememorygetnotcountedmemory is good. i think it's better than counting overlapping memory. i.e. `mem_replication_backlog` and `mem_clients_slaves` better not overlap and we should decide that one of them takes precedence, and the other takes the rest. if you agree, then let's also document that somewhere (initially in the code, and later also in redis.io)",0,0,0,0.9536972045898438,0.9287219047546388,0.9687225222587584,0.0,accept,unanimous_agreement
710093692,9166,"i think this top comment should be made shorter (just mention it's similar for client output buffers, and that it is used for shared buffers between replica clients). the actual explanation of each field should be next to the field.",0,0,0,0.9876129031181335,0.9882857799530028,0.9828547239303588,0.0,accept,unanimous_agreement
710095772,9166,"maybe this is the opportunity to replace the terminology of ""slave buffers"" in the code to ""replica buffers"" or ""replica client buffers"". in any case, since you renamed the function, we should probably avoid introducing one with the word ""slave""",0,0,0,0.9850652813911438,0.9943033456802368,0.9896300435066224,0.0,accept,unanimous_agreement
710174346,9166,"please be sure to explain the refcount scheme (maybe with a diagram), so that it's clear how the refcount works. i.e the fact that each replica increments only the refcount of only the first node it points to.",0,0,0,0.9848784804344176,0.9897865056991576,0.9898530840873718,0.0,accept,unanimous_agreement
710356134,9166,"did you extract that to a separate function in order to re-use it somewhere? or because the origin was too long? i agree it's more readable and safer, but let's distinctly define the function's role. in other words: let's add a top comment (also explaining the return value/s)..",0,0,0,0.9692732095718384,0.9119775295257568,0.9803184866905212,0.0,accept,unanimous_agreement
710361814,9166,"although this is technically correct, one will always be empty, maybe it's clearer to add an `if` and handle replicas and normal clients separately?",0,0,0,0.9871299862861632,0.9927895665168762,0.986034333705902,0.0,accept,unanimous_agreement
710375366,9166,"this releases the entire replication buffer, right? not just the backlog. we do that since the only case were we free the backlog is when there are no replicas too, right? let's add a comment explaining both these points. let's also add an empty line between the different steps (backlog and buffers).",0,0,0,0.9862697720527648,0.9924058318138124,0.9937474727630616,0.0,accept,unanimous_agreement
711016653,9166,"i wonder why git decided these are changed lines? probably because the re-order.. maybe if we move it together with preparereplicastowrite to be lower that'll be resolved and the order of functions will still make sense. small win to blame log and possible conflicts.,",0,0,0,0.8337404131889343,0.5934098362922668,0.7659056186676025,0.0,accept,unanimous_agreement
711018153,9166,"let's revert that small styling fix, will make the diff nicer.",0,0,0,0.9760146737098694,0.9593023657798768,0.9899535775184632,0.0,accept,unanimous_agreement
711040952,9166,"maybe this name is better? it may be worth to move this define to redis.h next to the backlog struct declaration, just for the sake of documentation. [code block]",0,0,0,0.983655035495758,0.9942631125450134,0.9851447343826294,0.0,accept,unanimous_agreement
711175410,9166,"shouldn't that be [code block] i.e. we already incremented server.master_repl_offset with the full len, and we may have already written part of it to the previous node (or not) and updated len. so now the repl offset of the beginning of that node is `server.master_repl_offset - len`",0,0,0,0.987765908241272,0.9942966103553772,0.9938726425170898,0.0,accept,unanimous_agreement
711177192,9166,"i'm not yet clear what we do with these block ids. maybe i'll find out soon, but i suppose that should be documented in the header",0,0,0,0.965877652168274,0.8256273865699768,0.8875176906585693,0.0,accept,unanimous_agreement
711178254,9166,"maybe rename `repl_buffer_size` to `repl_buffer_mem`, i.e. it doesn't hold the size of the data in the buffers, but rather the memory they consume. either way, it should be documented there too.",0,0,0,0.9875217080116272,0.9955146908760072,0.9929030537605286,0.0,accept,unanimous_agreement
711179678,9166,let's add some short comment that documents what these vars are used for.,0,0,0,0.9876509308815002,0.9870152473449708,0.9932308197021484,0.0,accept,unanimous_agreement
711181616,9166,-steinberg i suppose it's a good idea that you'll review this pr in the context of client eviction.,0,0,0,0.8466629981994629,0.8407402634620667,0.9579173922538756,0.0,accept,unanimous_agreement
711182564,9166,"maybe the term ""indexed"" is more appropriate than ""recorded""?",0,0,0,0.9850760102272034,0.9920734763145448,0.9712031483650208,0.0,accept,unanimous_agreement
711183546,9166,let's try to avoid the s word when adding new code. [code block],0,0,0,0.9849531650543212,0.9910467267036438,0.9938530921936036,0.0,accept,unanimous_agreement
711187542,9166,"wanted to remove the word ""slave"" but actually, i don't think the rest of the text is needed here. instead of talking about slaves and backlog, we can say this function manages the replication stream (a term that was already used here). [code block] actually, this line can be completely removed, i think the rest of the comment stands for itself.",0,0,0,0.9829240441322328,0.9846494793891908,0.9882845878601074,0.0,accept,unanimous_agreement
711199583,9166,"maybe we should rename both functions to refer to ""replication stream"" rather than ""slaves""",0,0,0,0.9865238070487976,0.9942144751548768,0.983062982559204,0.0,accept,unanimous_agreement
711205008,9166,"let's remove the argument (and rename the function to ""replicationfeedstreamfrommasterstream"" or such)",0,0,0,0.9892788529396056,0.9946749210357666,0.9945048689842224,0.0,accept,unanimous_agreement
711208386,9166,shouldn't that be `raxprev`?,0,0,0,0.9798718094825744,0.9937927722930908,0.9941282272338868,0.0,accept,unanimous_agreement
711213444,9166,"ok, now i see why we have ids. so it's just in order to estimate the memory usage?",0,0,0,0.9855185747146606,0.9918375611305236,0.9845064282417296,0.0,accept,unanimous_agreement
711254515,9166,"`c` is the master client (not a replica), what am i missing?",0,0,0,0.9865370988845824,0.9888643026351928,0.994575262069702,0.0,accept,unanimous_agreement
711259061,9166,-steinberg maybe we need to consider that before client (or key) eviction?,0,0,0,0.9580657482147216,0.9944031238555908,0.9810038208961488,0.0,accept,unanimous_agreement
711261401,9166,"first, i think we should call them ""buffers"" (not ""buffer""). first because it's a linked list of allocations (same as we call the other ones ""client output buffers""), but secondly, because they serve multiple purposes (multiple replicas, and also the backlog) secondly, maybe we should use the word ""total""? i.e. in the past the `mem_clients_slaves` and `mem_replication_backlog` were each representing a portion of the memory, and you had to sum them to get the total. now they represent overlapping memory, and this metric is the actual used total. [code block] what do you think?",0,0,0,0.980560839176178,0.9929654598236084,0.986323893070221,0.0,accept,unanimous_agreement
711262640,9166,"i think we should name that var `repl_buffers_mem` (not about the number of bytes in the buffers, but about the memory they consume, right)?",0,0,0,0.9887457489967346,0.9939684867858888,0.9901210069656372,0.0,accept,unanimous_agreement
711263411,9166,"let's add a comment in `dismissclientmemory` as to why we don't need to dismiss that ""second"" output buffer there.",0,0,0,0.9849193096160888,0.9938110709190368,0.992734432220459,0.0,accept,unanimous_agreement
711523600,9166,why did you comment that? it means we don't know that the commands completed before proceeding to the rest of the test,0,0,0,0.92002272605896,0.9754737615585328,0.9929597973823548,0.0,accept,unanimous_agreement
711524105,9166,i think refcount and id can be made `int`,0,0,0,0.987785816192627,0.9894277453422546,0.989844560623169,0.0,accept,unanimous_agreement
711526217,9166,"what do you mean by ""bother""? also that line changes the backlog not output buffer.",0,0,0,0.9437312483787536,0.9876161217689514,0.9889005422592164,0.0,accept,unanimous_agreement
711526254,9166,"lets try to avoid using the term ""slave"" (please go over this file)",0,0,0,0.9493755102157592,0.991650402545929,0.9916366934776306,0.0,accept,unanimous_agreement
711526875,9166,"there's a lot of prep code before the test starts, let's add a short comment about about this test group",0,0,0,0.978171408176422,0.9596071243286132,0.9901121258735656,0.0,accept,unanimous_agreement
711528470,9166,"we're expecting about 1mb drop, let's validate that (one byte of diff can happen by chance)",0,0,0,0.9869591593742372,0.9866459369659424,0.9908718466758728,0.0,accept,unanimous_agreement
711528796,9166,"again, let's add a short comment about this group of tests.",0,0,0,0.9838818311691284,0.9775099158287048,0.9906651973724364,0.0,accept,unanimous_agreement
711529493,9166,[code block] maybe we want to reduce the `delay` to something more realistic.,0,0,0,0.9823746085166932,0.9914448857307434,0.98620343208313,0.0,accept,unanimous_agreement
711540885,9166,"please add a section in the top comment to mention the effect of this pr on interfaces. i.e. the main effect is an optimization that users won't really notice (it'll just work). but some info fields changed their purpose, were in the past accumulative and now overlapping. also mention the new info field.",0,0,0,0.984586238861084,0.9893130660057068,0.9908708930015564,0.0,accept,unanimous_agreement
713499259,9166,`s/slave/replica`?,0,0,0,0.9870449900627136,0.9942637085914612,0.9949589371681212,0.0,accept,unanimous_agreement
713505812,9166,"if we are introducing a `repl_backlog` struct, why not also put all of `repl_backlog_size/repl_backlog_histlen/repl_backlog_off` into it? logically they belong together. and of course, if we do that, then the type of this struct needs to be something more generic than `replbacklogrefreplbuf`. [code block]",0,0,0,0.9865766763687134,0.9949089884757996,0.9927529096603394,0.0,accept,unanimous_agreement
713785512,9166,"sorry, my bad (hard to control indentation in suggestions) [code block]",-1,-1,-1,0.9881622195243835,0.9929541945457458,0.9937870502471924,-1.0,accept,unanimous_agreement
713804578,9166,"i am making code fine, and apply your suggestions, l will update",0,0,0,0.8243829011917114,0.8465980291366577,0.5004132390022278,0.0,accept,unanimous_agreement
713805848,9166,"here, i think raxnext and raxpre is the same, but it seems raxpre is better",0,0,0,0.9748544692993164,0.9844741821289062,0.9811820387840272,0.0,accept,unanimous_agreement
713812011,9166,"ok, initially, i want to do this, but to make getclientoutputbuffermemoryusage uniform, i add this variable. now i change getclientoutputbuffermemoryusage for different client type, i also remove this, also remove the following `used_size_of_repl_buf`.",0,0,0,0.9884578585624696,0.992110550403595,0.9932025671005248,0.0,accept,unanimous_agreement
713813288,9166,just because the origin `writetoclient` function is too long. let me add a top comment,0,0,0,0.980622410774231,0.9577574729919434,0.9711730480194092,0.0,accept,unanimous_agreement
713818443,9166,"yes, the entire replication buffer is released. let me add comments for it",0,0,0,0.9849141240119934,0.9527624249458312,0.9921576976776124,0.0,accept,unanimous_agreement
713821255,9166,"yes, but `tail->used` just is the `len` which is update since of last written part.",0,0,0,0.9887336492538452,0.9941904544830322,0.9940709471702576,0.0,accept,unanimous_agreement
713846644,9166,"yes, but i think we actually want to count all memory into maxmemory limit. although the backlog is now dynamically growing, i think we still want to count the size of replication backlog into `maxmemory` limit. so here i only don't count the memory beyond the replication backlog into maxmemory limit.",0,0,0,0.98089337348938,0.974867582321167,0.9926300048828124,0.0,accept,unanimous_agreement
713869916,9166,"yes, it is unnecessary. i remove it",-1,0,0,0.5955392122268677,0.8930102586746216,0.991471827030182,0.0,accept,majority_agreement
713873063,9166,"""second"" output buffer? do you mean replica's output buffer?",0,0,0,0.9878224730491638,0.992817521095276,0.9907631278038024,0.0,accept,unanimous_agreement
714002880,9166,"maybe that would be ok, but only if we don't run into an endless feedback loop on mass eviction, which causes over-eviction and data loss. so i'd like to imagine 3 cases. let's say we have a server with maxmemory=1gb, and the backlog limit set to 100mb. 1. if the backlog is full and the replicas are not lagging, eviction deletes keys and the backlog normally remains 100mb, so other than a small spike because a new repl-buffer node is created it shouldn't cause an infinite feedback loop. 2. if there's a lagging replica that causes the repl buffers to grow to 500mb, each eviction would cause the buffer to grow, and had we counted that we could get into a feedback loop. but since we ignore the part above the first 100mb, we're ok. 3. if there are no replicas connected for a long time, so also no backlog, and the db is full constantly doing evictions. then a replica connects and the backlog and repl buffers start to grow, the eviction causes it to grow even faster, and it's now consuming 10mb. each (small) key being deleted inflates the memory further and the eviction loop keeps running until the backlog reaches 100mb, and which point the feedback loop stops and eviction eventually completes. let's analyse case 3. - since we now have incremental eviction, we don't have the risk of staying in an infinite loop, we'll re-sample the memory state when we re-enter the performevictions function. - since (unlike the old slave buffers), the backlog will keep consuming that memory even after the eviction loop stops and the replicas consume their buffers, we won't go into a resonance effect. the benefit of keeping the current proposal that doesn't ignore the backlog part (first 100mb in our case), is that on upgrades from previous versions, users won't suddenly be able to push another 100mb before reaching eviction. so bottom line, i'm changing my mind and i'm ok with this. still, i'd like to turn the attention of others to this discussion. let's mention it in the top comment and hope they'll read it when the time comes.",0,0,0,0.9462041854858398,0.9857526421546936,0.9322384595870972,0.0,accept,unanimous_agreement
714024626,9166,indentation,0,0,0,0.982236921787262,0.822169840335846,0.9911677837371826,0.0,accept,unanimous_agreement
714043623,9166,"i had a discussion about this with -steinberg and although we don't agree, i'd list the options here. background: previously we had these in info memory: `mem_clients_slaves` and `mem_replication_backlog`, people had to sum them if they wanted, or alternatively looking at each (specifically the slaves one), would immediately indicate where the majority of the memory is used. now we have several options: 1. keep each of these two represent how much memory used for that purpose, so summing them would mean part of the memory was accounted twice, and that's what the new `mem_total_replication_buffers` field is for. 2. delete these old fields since they're coupled with an old internal design. users can easily conclude that if the new `mem_total_replication_buffers` is bigger than the `repl_backlog_size` config, then that's an indication that replicas are causing trouble. 3. we can aim for 2, but meanwhile keep doing 1 for some backwards compatibility. 4. do what i'm gonna describe below: my suggestion: [code block] - so in case the replicas are not lagging, they'll show 0, and even if they do consume something, then we can argue that the new mechanism is utilizing the backlog so it doesn't cause any excess memory usage. - in case the replicas are lagging, the backlog will show the maximum, and the replicas will show the excess. - this is backwards compatible with what we had till now (people can sum these fields) - a quick look at these two metrics, and it's easy to realize where the memory is wasted and who's to blame",0,0,0,0.9622622728347778,0.967040717601776,0.9537636637687684,0.0,accept,unanimous_agreement
714076735,9166,"i want to propose abstracting `ref_repl_buf_block` and `ref_block_pos` into a single reference-like type, so we don't have to redundantly define them in all consumers of the global replication buffer list. (type name is up for debate) [code block] then we can have: [code block]",0,0,0,0.9842067956924438,0.9925899505615234,0.9919255375862122,0.0,accept,unanimous_agreement
714084897,9166,"is there a reason why this can't be squeezed into `replicationcron`? that seems to be a more fitting place? if there is a reason that this has to be done here in `beforesleep`, please document so future developers don't introduce regression.",0,0,0,0.9854314923286438,0.9936210513114928,0.9915629625320436,0.0,accept,unanimous_agreement
714115453,9166,"we could always calculate this on-demand when we need it, no? why maintain it as a variable? maintaining it means we need to update it whenever the global replication buffer list is touched, which happens in multiple places.",0,0,0,0.9865358471870422,0.9882126450538636,0.9809198975563048,0.0,accept,unanimous_agreement
714120412,9166,"suggest to encapsulate these into a `resetreplbufferblocks` function, since they are also used in `initserver(void)`",0,0,0,0.9882627129554749,0.9953016042709352,0.9936445951461792,0.0,accept,unanimous_agreement
714133362,9166,"`since the backlog is released only when there are no replicas and the backlog keeps the last reference of all blocks.` this is a major assumption we are making here. i would suggest we assert that this is actually true to gain confidence in our implementation of this assumption, at least for the first version of this feature. it will hurt performance a little bit, but given this is a rare operation, i think the pro outweighs the con. once we are confident that this assumption is always true, we can remove such assertions to get some performance back. something along the lines of: [code block]",0,0,0,0.895232617855072,0.9354392886161804,0.9500188827514648,0.0,accept,unanimous_agreement
714155733,9166,subjective nitpick. might be more readable this way. [code block],0,0,0,0.9873756170272828,0.9774101376533508,0.8713481426239014,0.0,accept,unanimous_agreement
714158812,9166,nitpick. whitespaces. [code block],0,0,0,0.9890725016593932,0.9874024391174316,0.9754698872566224,0.0,accept,unanimous_agreement
714164080,9166,"you are both right. at this point `len` and `tail->used` are exactly the same. since `tail->repl_offset` is the first offset of this particular node, i find the existing code (e.g. `tail->repl_offset = server.master_repl_offset - tail->used + 1;`) more intuitive to me, because `tail->repl_offset = server.master_repl_offset - len + 1;` look like we are subtracting the full input `len`.",0,0,0,0.9634634256362916,0.9766056537628174,0.9482513666152954,0.0,accept,unanimous_agreement
714165351,9166,should we move `preparereplicastowrite();` to here so it's closer to other replica related logic?,0,0,0,0.9867346286773682,0.9958292841911316,0.9944595098495485,0.0,accept,unanimous_agreement
714169478,9166,"isn't one of the major benefits of this pr that replicas don't consume memory to maintain their own output buffers? if replicas don't have ""client output buffer"" anymore, why do we still close replicas based on ""client output buffer""? i might be missing something, could you please explain(and document the reasoning as code comments)?",0,0,0,0.9611595273017884,0.9813886880874634,0.9835492372512816,0.0,accept,unanimous_agreement
714172626,9166,"this function doesn't decrement any refcount of any node, so it doesn't create any new opportunities to trim. i find it counter-intuitive that we call `trim` here. if we are calling it just to do some leftover work from previous trimming effort, i would suggest we leave that responsibility to the cron job.",0,0,0,0.9397926330566406,0.9873708486557008,0.7375532984733582,0.0,accept,unanimous_agreement
714179721,9166,"seems to me that our assumption is the following, so we should assert for it: [code block]",0,0,0,0.9778398275375366,0.9904741644859314,0.9881582856178284,0.0,accept,unanimous_agreement
714181828,9166,i might be missing something obvious but why we are dumping from the last block to the first? wouldn't that give us a reversed and wrong replication stream content?,-1,0,0,0.5457587838172913,0.8913210034370422,0.9361774921417236,0.0,accept,majority_agreement
714182538,9166,we don't need `if (server.repl_backlog)`.,0,0,0,0.987933874130249,0.9923660159111024,0.993682861328125,0.0,accept,unanimous_agreement
714188577,9166,"the monitor clients can be modeled as another consumer of the global replication buffer list, right?",0,0,0,0.988271415233612,0.994787096977234,0.9917187690734864,0.0,accept,unanimous_agreement
714193102,9166,explicitly assert that our assumption is always true. [code block],0,0,0,0.9871680736541748,0.9906172156333924,0.9931321740150452,0.0,accept,unanimous_agreement
714194777,9166,should we put this function in `replication.c` instead?,0,0,0,0.9890140891075134,0.9953136444091796,0.9947127103805542,0.0,accept,unanimous_agreement
714195267,9166,"suggest add comment saying replicas don't have their own dedicated ""client output buffer"" anymore.",0,0,0,0.9634990096092224,0.989668905735016,0.9950131773948668,0.0,accept,unanimous_agreement
714199824,9166,subjective nitpick. [code block],0,0,0,0.98648202419281,0.9888555407524108,0.5294197797775269,0.0,accept,unanimous_agreement
714205881,9166,"should we check `if (c->ref_repl_buf_node == null) return c_ok;` first? or do we assume it's guaranteed that when `_writetoclient` is invoked on a replica, the replica always has a valid `ref_repl_buf_node` already. if that is the assumption, we should assert.",0,0,0,0.9885300993919371,0.9945549964904784,0.9945695996284484,0.0,accept,unanimous_agreement
714270436,9166,"should we split this function into two now? since they are now counting two entirely different things: `getclientoutputbuffermemoryusage` for regular clients, and `getreplicareferencedreplbuffermemoryusage` for replica clients.",0,0,0,0.988308310508728,0.994132936000824,0.9910265803337096,0.0,accept,unanimous_agreement
714320085,9166,1. [code block] i think this is tribal knowledge that is not documented anywhere in the code. this is the first time i'm learning this. could we please document it? 2. i agree with the current logic.,0,0,0,0.9212438464164734,0.958676815032959,0.9626877903938292,0.0,accept,unanimous_agreement
714535922,9166,"i feel that replicationcron could be too slow / late, and maybe introduce excessive eviction or client disconnection in that time, and that can be also said on servercron. doing smaller steps in beforesleep sounds better to me. but maybe we should do some benchmark or analyze the worse case, instead of judge by feelings?",-1,0,0,0.5196352005004883,0.8873233795166016,0.9476749300956726,0.0,accept,majority_agreement
714536452,9166,"calculating it means to run on the long list, this cause cause latency in info and others.",0,0,0,0.9585832357406616,0.8978282809257507,0.9791308045387268,0.0,accept,unanimous_agreement
714539694,9166,"we can do that once and run test tests, but i don't think we can keep it. alternatively we can assert that there are no replicas. and we can also add some global counter of all refcounts (i.e. every time we increment a certain buffer's refcount, we also increment the global refcount), and then assert here that the global refcount is 0.",0,0,0,0.98468679189682,0.9876884818077089,0.9899689555168152,0.0,accept,unanimous_agreement
714545656,9166,"ohh, i guess i was missing the fact we just did `tail->used = len;` a few lines up, and for some reason i thought that `tail` is the previous node (the one into which we've written the first part). anyway, i don't recall what i was thinking, but my suggestion and the current code are the same. sorry.",-1,-1,-1,0.9884441494941713,0.9850363731384276,0.99208801984787,-1.0,accept,unanimous_agreement
714551831,9166,"they share memory, but that memory can still lead to issues and if a slow replica falls behind for too long, we wanna disconnect it and release the memory. in that sense if there are two that fall behind, and both crossed the threshold, we'll still disconnect both and reclaim the memory. also note (and maybe we can document that): setting a replica output buffer limit that's lower than the backlog size is pointless since: 1. disconnecting the replica will not release any memory, but also: 2. even in the previous versions, such a setting would mean that if a replica managed to use that backlog for psync, it'll immediately get disconnected. so that was an always an invalid configuration, and we should document that. -steinberg fyi (what we discussed yesterday). so after we put that invalid configuration aside, we can look at this pr as a simple optimization. i.e. semantically, when a replica uses less memory than the backlog limit config, we can argue that it uses the backlog and no memory of it's own. and when replicas consume more memory than the backlog, they share memory, and also the backlog benefits from that as an extra size. if we go with the above semantics, then my proposal for info fields makes sense, see [a link]",0,0,0,0.9538372159004213,0.9726616740226746,0.970484495162964,0.0,accept,unanimous_agreement
714552608,9166,"looking at the code it seems that `repl_buffer_blocks` and `repl_backlog->ref_repl_buf_node` are redundant. we have two pointer essentially pointing to the same list head. in some places we check one in some the other in some both(!) and the code also always needs to take care to update one when changing the other. i understand the attempt to separate two concepts here: ""the replication buffer"" and the ""backlog buffer"" but in reality they are exactly one and the same, and this reality actually shows at that they are also the same in practice. i suggest removing `repl_buffer_blocks` and instead just keeping the backlog structure.",0,0,0,0.9136388301849364,0.9533838629722596,0.947019636631012,0.0,accept,unanimous_agreement
714553605,9166,"it amended to the backlog, so now it may be too big, and we can trim the first node. i.e. iiuc that's the place where we'll usually trim one node (if there are no slow replicas). i suppose the comment should be improved.",0,0,0,0.9830453395843506,0.9897106289863586,0.9917762279510498,0.0,accept,unanimous_agreement
714556271,9166,"the code is a bit awkward, it does `sds tmp = sdscatsds(head, dump);`, i.e. inserts into the head. we're only printing the last 250 bytes (and only when bugs are found), so performance of stepping backwards and then forward again is not an issue. i suppose clean short code is what we should aim for, if we wanna improve it.",0,-1,-1,0.5912969708442688,0.5858932137489319,0.7104679346084595,-1.0,accept,majority_agreement
714557576,9166,"we have some plans for monitors with filters (per user or key), and also monitors that can have additional data being logged (like the responses or errors and such). i think we better leave them out of this.",0,0,0,0.97797030210495,0.9869484901428224,0.9825871586799622,0.0,accept,unanimous_agreement
714559534,9166,"i think it's nice that this detail of where the memory is stored and how is abstracted. i.e. the caller (in this case client list) doesn't care, it just wants to know how much data the client has pending to be written, or how much memory it consumes.",0,0,1,0.6256198883056641,0.9150156378746032,0.7892003059387207,0.0,accept,majority_agreement
714561135,9166,"yes, let's document that, and also big chunk of my previous comment, i.e. describe why not counting the backlog size would not cause a feedback loop concern.",0,0,0,0.980668604373932,0.9869686961174012,0.9897305965423584,0.0,accept,unanimous_agreement
714611157,9166,i'm for option 2 above. it's the most straight forward: simply how much memory is being used by the repl buffers (for backlog or replication). avoid confusing the user with multiple stats which derive from a single mechanism.,0,0,0,0.9772422909736632,0.9141952395439148,0.983375608921051,0.0,accept,unanimous_agreement
714618854,9166,as i mentioned in `getmemoryoverheaddata` i think there's no real point in a separate stat for `getslavesoutputbuffermemoryusage` because what we really care about is the total backlog size. so from my perspective we can delete this function. ```,0,0,0,0.9643377065658568,0.987271249294281,0.9888359904289246,0.0,accept,unanimous_agreement
714657369,9166,we may need a tie breaker (or a 5th option). please weigh in (or call me for quick summary).,0,0,0,0.9715895652770996,0.9845337867736816,0.990192413330078,0.0,accept,unanimous_agreement
714692281,9166,we already assert there is no replica.,0,0,0,0.9673286080360411,0.9899889230728148,0.9875109195709229,0.0,accept,unanimous_agreement
714729507,9166,we already call clienthaspendingreplies before calling _writetoclient,0,0,0,0.9897760152816772,0.9936004877090454,0.994520366191864,0.0,accept,unanimous_agreement
714734119,9166,"in replicationcron, it is too slow. initially i put it in replicationcron, it costed dozens of seconds for trimming replication backlog in my tcl tests. we free 1m buffer blocks per call, in beforesleep, we free 10m",0,-1,-1,0.7231687307357788,0.5240480303764343,0.6741516590118408,-1.0,accept,majority_agreement
714736690,9166,"actually, i tried to did that, but i gave up. first, replication backlog don't need `ref_block_pos`, and this way make the variable very long. such as, we access `ref_repl_buf_node`, maybe `server.repl_backlog->repl_buf_ref->ref_repl_buf_block` wdyt?",0,0,0,0.9753227829933168,0.9905748963356018,0.9878785014152528,0.0,accept,unanimous_agreement
714738739,9166,this way breaks too many unnecessary places. wdyt?,-1,-1,-1,0.6740059852600098,0.899739146232605,0.9576836824417114,-1.0,accept,unanimous_agreement
714739793,9166,"i think we should keep it, we only have two places to modify `repl_buffer_mem`, but it makes getting replication buffer memory easy.",0,0,0,0.9652167558670044,0.962981641292572,0.8572894334793091,0.0,accept,unanimous_agreement
714741091,9166,"no, see the comments of `preparereplicastowrite`",0,0,0,0.9871050119400024,0.9930031895637512,0.9918277263641356,0.0,accept,unanimous_agreement
714742952,9166,"we must call it here, as oranagra said.",0,0,0,0.9818668365478516,0.9906084537506104,0.9905663132667542,0.0,accept,unanimous_agreement
714748280,9166,"if we don't read, could we make sure that all data is completely sent?",0,0,0,0.9827162027359008,0.9911311268806458,0.985605537891388,0.0,accept,unanimous_agreement
714756942,9166,"yes. now i make replication backlog always as the last reference of `the replication buffer`. but i am not sure we could accept, maybe we want to keep replication backlog the same size with our setting.",0,0,0,0.9462278485298156,0.979621410369873,0.988025724887848,0.0,accept,unanimous_agreement
714788707,9166,"i see 11 usages of one, and 18 usages of the other (which is not that many), but more importantly, it looks like nearly any place that uses or sets them is also dealing with `server.repl_backlog_idx` (which we did change, so we'll be changing a block that we had to change anyway). i think the only places that only care about these two and not the others are `mastertrypartialresynchronization` and `genredisinfostring`, i.e. they care about the range, but not about the data. so i'm willing to consider this suggestion as if it only affects two functions, so if we feel it makes the code cleaner, let's go for it. i.e. the two things to avoid in such renames are blame log damage causing untraceable history (we modify many of these blocks anyway), and merge conflicts (with the two exceptions above, any fix touching these areas will have hard time being backported or merged to some odd fork anyway)",0,0,0,0.9608330726623536,0.9218904972076416,0.9484184980392456,0.0,accept,unanimous_agreement
714794767,9166,"since we don't have generic code that can act on that struct (common to both backlog and replica), i don't think this is a good idea. even if we could extract a 2 line function that's common, i think doing that (both the extraction of the function, and the extraction of the struct members), would cause more confusion. i combine this with yoav's [a link] to completely eliminate either the backlog reference or the head link to the buffer chain (a suggestion that i personally don't really like), makes me feel that this suggestion to unify the structs is probably not a good idea.",-1,0,0,0.7414191961288452,0.5736991167068481,0.7817993760108948,0.0,accept,majority_agreement
714800465,9166,please add a comment that explains it.,0,0,0,0.9775631427764891,0.9835841059684752,0.9937856197357178,0.0,accept,unanimous_agreement
714802826,9166,"we can run `$rd flush` to make sure it was sent, but not that it was received. we could look at `info commandstats` to know it was received, but please explain why did you remove it?",0,0,0,0.988338828086853,0.9944578409194946,0.9920995235443116,0.0,accept,unanimous_agreement
714825524,9166,"why did you add that? is it because you wanna revert the creation of the backlog if rdb load fails or rdb file is missing? i'm afraid that `access` and `open` will give different results. or actually, we do have a plan to one day allow a module to provide an alternative to file system access. i'll feel better if we can solve this differently, like destroy the backlog if no loading happened, or create it using some hook",-1,0,-1,0.8171769976615906,0.8179450631141663,0.8291171193122864,-1.0,accept,majority_agreement
714839416,9166,"because it makes maxmemory tests failed, current solution for replication backlog(blocks list) makes its exceed our setting. and i think this change makes sense. if there is no rdb, we don't need to create backlog. if rdb load fails, redis will exits. we allow redis run only if there is no rdb, of course, we can free replication backlog if errno is enoent later.",0,0,0,0.9748604893684388,0.9869014620780944,0.9286229610443116,0.0,accept,unanimous_agreement
714844005,9166,"so i'd rather free it laster than use a different method to check if it exists ahead of time. however, i didn't understand which test failed and why.. can you elaborate?",0,0,0,0.7404875755310059,0.8901866674423218,0.9880875945091248,0.0,accept,unanimous_agreement
714858756,9166,[code block] so replication backlog may be about 32k even if we set 16k by default.,0,0,0,0.9877457022666932,0.9943960905075072,0.9926984906196594,0.0,accept,unanimous_agreement
714865061,9166,and which test did it break? which assertion?,0,0,0,0.9686267375946044,0.9360403418540956,0.9914656281471252,0.0,accept,unanimous_agreement
714865331,9166,"here, i don't judge `listlength(server.slaves)` only `if ((long long)server.repl_buffer_mem > server.repl_backlog_size) ` i.e. i still regard the part of exceeding backlog size as the consumption of replica because we don't trim replication backlog in time, to avoid eviction. do you think it make sense?",0,0,0,0.974611759185791,0.9927266836166382,0.9914597272872924,0.0,accept,unanimous_agreement
714870520,9166,"yes, it makes sense to me.. specifically because the only reason there would be a very long list of excess nodes is when a replica dropped. so had we counted the memory that's actually being used by replicas, as long as they're connected we'd ignore that memory, and as soon as they drop we run into a massive eviction loop. let's document that too (i.e. that because the deletion is in the background, and has a delayed effect after a replica disconnects, we have to ignore it even if there are no replicas)",0,0,0,0.891426146030426,0.9373237490653992,0.9761738181114196,0.0,accept,unanimous_agreement
714959851,9166,"it depends on how do we envision this global replication buffer list will be consumed in the long term. are replica clients gonna be the only consumers of it? or do we see this global list as a generic ""change data capture stream"" that will potentially have more use cases/consumers? if we do, then the redundancy will only grow. e.g. more ""consumer"" structs will need to define their own `ref_repl_buf_node` and `ref_block_pos` and potentially more metadata that ""describes"" a pointer/reference into the global list. just a thought. re: `replication backlog don't need ref_block_pos` yes, replication backlog's `ref_block_pos` is virtually always `0`, but it can still have it. doesn't hurt, and may allow us to control replication backlog size in finer granularity(not important though).",0,0,0,0.9813894629478456,0.9644017219543456,0.9641932845115662,0.0,accept,unanimous_agreement
714961009,9166,i see. thanks for explaining. i don't feel strongly either way as long as we document the reason why we put it here (e.g. for speed).,1,1,1,0.7939740419387817,0.8234638571739197,0.9541285037994384,1.0,accept,unanimous_agreement
714976921,9166,this comment is marked as resolved without an response or code change.,0,0,0,0.98233163356781,0.991624653339386,0.9943844079971312,0.0,accept,unanimous_agreement
714977230,9166,this comment is marked as resolved without an response or code change.,0,0,0,0.98233163356781,0.991624653339386,0.9943844079971312,0.0,accept,unanimous_agreement
714977465,9166,this comment is marked as resolved without an response or code change.,0,0,0,0.98233163356781,0.991624653339386,0.9943844079971312,0.0,accept,unanimous_agreement
714985445,9166,"`preparereplicastowrite` decides whether to install write handler for a replica based on if there is data on the replication buffer to send to it. sorry probably a stupid question: wouldn't it make more sense if we first add some data to the replication buffer then call `preparereplicastowrite`, to give ourselves a better chance to send the newly added data to replicas right away? why we must call `preparereplicastowrite` before we add new data to the replication buffer?",-1,-1,-1,0.9862661957740784,0.9878506064414978,0.991100251674652,-1.0,accept,unanimous_agreement
714987558,9166,"makes sense. thanks for the explanation. re: `setting a replica output buffer limit that's lower than the backlog size is pointless`. should we enforce this in the code(e.g. in `config.c`, verify this invariant is held whenever these two configs are changed)?",1,1,1,0.9021103978157043,0.7428521513938904,0.9855520129203796,1.0,accept,unanimous_agreement
714990081,9166,this comment is resolved without a response or code change.,0,0,0,0.9812167882919312,0.9885901808738708,0.9925256967544556,0.0,accept,unanimous_agreement
714994958,9166,this comment is resolved without a response or code change.,0,0,0,0.9812167882919312,0.9885901808738708,0.9925256967544556,0.0,accept,unanimous_agreement
714995365,9166,this comment is resolved without a response or code change.,0,0,0,0.9812167882919312,0.9885901808738708,0.9925256967544556,0.0,accept,unanimous_agreement
714996809,9166,this comment is resolved without a response or code change.,0,0,0,0.9812167882919312,0.9885901808738708,0.9925256967544556,0.0,accept,unanimous_agreement
715336486,9166,"i make a mistakes, ignore my analysis above we will get oom error in this line [a link] i add `puts ""db9 [s db9] [s evicted_keys] [s mem_replication_backlog]""` before this line, i got this result [code block] in this test, we want to write about 96k data, but now replication backlog grows incrementally, i guess we only write 48k, and replication backlog also about 48k, and then we want to write the same number keys, before we set maxmemory to `used_memory+100k`, so eviction would happen, replication backlog will be bigger, replication backlog is 1m by default, i don't count it inot `notcountedmemory`, so server evicts all keys.",-1,0,-1,0.5043925046920776,0.954641342163086,0.4985465407371521,-1.0,accept,majority_agreement
715357098,9166,"i just want to make sure that all data is received by server. and i don't it is a good idea to keep this comment line, doesn't it have meaning?",-1,0,0,0.5286574363708496,0.7722519636154175,0.9680516719818116,0.0,accept,majority_agreement
715377774,9166,"i think we needn't always add comments around all this assert. you could see this pr has more than one hundred conversation, it is not easy to track more useful problem. please forgive i couldn't follow your code style, i prefer to follow redis original style, every one has his code style, even i also don't like some original styles, maybe before style is not good, but i like to follow. i don't want to put energy in this things unless core team ask me to change, for style problems, i would like to respect the decision of core team just because they always are responsible for this project.",-1,-1,-1,0.834388792514801,0.6802837252616882,0.4803072810173034,-1.0,accept,unanimous_agreement
715378767,9166,"i have no idea, we need to fix it?",0,-1,-1,0.6598125100135803,0.825075626373291,0.596982479095459,-1.0,accept,majority_agreement
715380376,9166,see the comments of preparereplicastowrite and prepareclienttowrite,0,0,0,0.986688792705536,0.9944158792495728,0.9941734671592712,0.0,accept,unanimous_agreement
715402249,9166,"yes, we always has this problem. the season why i think we should keep `replication_backlog_size` and `client_output_buffer_limit for replicas` instead of only use `replication buffer` is that users could set them arbitrary, the network between master and replicas is generally fine, so replicas output buffer is not always big. it seems an easy and effective way.",0,0,0,0.4928342700004577,0.7306116223335266,0.9647219181060792,0.0,accept,unanimous_agreement
715408357,9166,"it seems that `repl_backlog_size` shouldn't be in it, since it is a configuration. i don't reject idea, actually, according to oo, we should do that. i didn't it before since redis likes put them separately...",0,0,0,0.9297958612442015,0.942295253276825,0.9503817558288574,0.0,accept,unanimous_agreement
715415229,9166,"ok. one could argue that this test is over sensitive. if the test was using a replicated pair of servers, we would have had to change the test. but since the test isn't using replication, and isn't loading an rdb (like many others), let's try to make the memory usage more predictable for them. i.e. in the past (before soloestoy's recent change), there was on replication backlog in these tests. then the backlog was added, but its memory consumption was constant, so this test didn't notice. now its memory consumption gradually grows, and that breaks the test. let's make sure to avoid creating the backlog in that case, or create it and then destroy it if not needed. but i don't like the current solution. the better one imho is that if we didn't set `server.master_repl_offset` from `rsi.repl_offset` (or didn't load an rdb file at all), then we should destroy the backlog.",0,0,0,0.8953145146369934,0.8690770268440247,0.9180663228034972,0.0,accept,unanimous_agreement
715418806,9166,"ohh, i'm reading it backwards. you didn't comment this line, you uncommented it. why was it commented? looks like it was commented in the original commit that added that test: bf680b6f8c i have no clue why. probably a mistake.",-1,-1,-1,0.7614068388938904,0.7245631217956543,0.7579270005226135,-1.0,accept,unanimous_agreement
715421114,9166,"i always prefer smaller diffs and less damage to the blame log. try the re-order i suggested above, and compare to the merge-base, see if that re-order makes a smaller diff (don't change unchanged lines). if it works, keep it, if not, let's forget about it.",0,0,0,0.9410470128059388,0.9770970940589904,0.9813682436943054,0.0,accept,unanimous_agreement
715426725,9166,"p.s. we can't enforce one config to be greater than the other at config.c, because we don't know at which order they'll be changed. what we can / should do, as yoav suggested in another comment is that when we consider the replica-buffer limit, we `max()` it with the backlog size, so that setting it to a lower value will be meaningless. plus a big comment in the code explaining why it's invalid (psync will succeed and then drop the replica), and maybe a mention of that fact in redis.conf.",0,0,0,0.9664602279663086,0.986376941204071,0.9862050414085388,0.0,accept,unanimous_agreement
715445088,9166,"i updated commits, but it seems i forget to handle invalid `rsi.repl_offset`",0,0,0,0.9866140484809875,0.9065791964530944,0.9891079664230348,0.0,accept,unanimous_agreement
716161886,9166,"what do you mean? p.s. an alternative approach to what you took, is that instead of integrating the release of the backlog in the if-else chains of the loading, you can just add an `if (server.master_repl_offset == 0)` at the very end.",0,0,0,0.9888045191764832,0.9896911382675172,0.9943515062332152,0.0,accept,unanimous_agreement
716562112,9166,"note that client-eviction is only on ""normal"" clients (not replicas) so there probably isn't any issue here.",0,0,0,0.9776436686515808,0.9911222457885742,0.989843249320984,0.0,accept,unanimous_agreement
716566620,9166,"looking at the code i see this is called **before** client eviction takes place, so i think we're good.",1,0,0,0.8168235421180725,0.7807905077934265,0.8525717854499817,0.0,accept,majority_agreement
718542981,9166,"my take on this is it really depends if the user is trying to figure out how memory is utilized, or figure out how replication is doing. pointed out that it's expected that `info memory` would focus on memory usage because more detailed replica information can be accessed by `info replication` or `client list`. if we follow this reasoning then [4] makes sense. the main arguments i see against option [4] are: * it's usually best to expose raw metrics and not computed ones * changing the meaning of an existing metric is bad practice. perhaps a 5th option is [4] but using a different field name to indicate we're exposing the extra memory that does not overlap the backlog.",-1,0,0,0.6445251107215881,0.9856280088424684,0.960525929927826,0.0,accept,majority_agreement
718553697,9166,"so in 5, your not suggesting to rename them (would break backwards compatibility), you're suggesting to add an additional field that states that these are computed ones. we do already add a new field (the total size of all replication buffers), from the presence of this field one can conclude that the other two are computed.",0,0,0,0.9874367713928224,0.9924678206443788,0.99350243806839,0.0,accept,unanimous_agreement
724811933,9166,"so considering that there is a new field for the new total memory of all replication buffers, can i conclude that your 5 is the same as my 4?",0,0,0,0.9854457378387452,0.9864799380302428,0.9942679405212402,0.0,accept,unanimous_agreement
725586960,9166,"no, i was suggesting that if we do use a computed value we should rename the field to avoid a situation where the same metric describes different things in different versions.",0,0,0,0.97539085149765,0.9819773435592652,0.9860950708389282,0.0,accept,unanimous_agreement
725591971,9166,"but that defeats the purpose of computing them (in a way that will in some way retain backwards compatibility). i.e. the whole purpose was that if we compute them this way, existing code will (probably) be able to use them the same. but if we rename them, there's no point in doing that. since the old values are impossible to get, i think this is the only way to achieve backwards compatibility. if we're gonna rename them, we might as well leave them raw and break any existing monitoring software that depended on the old ones.",0,0,0,0.6961211562156677,0.9053319096565248,0.8262526988983154,0.0,accept,unanimous_agreement
726105265,9166,"this makes sense - so i support option [4]. normally i'd say we'd better off not to compute fields or change what they mean, but given that `info memory` is probably used to analyze how memory is used rather than observe replication behavior i think that makes sense.",0,0,0,0.97357439994812,0.9602537751197816,0.9678232669830322,0.0,accept,unanimous_agreement
727795364,9166,"i think you may want to compare `server.repl_buffer_mem` and `server.repl_backlog_size` instead of `server.repl_backlog_histlen`, since now `server.repl_backlog_histlen` is always near `server.repl_buffer_mem`",0,0,0,0.9814152717590332,0.9933041930198668,0.989006280899048,0.0,accept,unanimous_agreement
727959849,9166,"maybe we still want to use the old way of computing the total memory (rax, nodes and all), and then apply the if-else logic on the result?",0,0,0,0.9861258864402772,0.9929643869400024,0.9823933839797974,0.0,accept,unanimous_agreement
727985136,9166,"now the replication backlog memory size always is more than `repl_buffer_mem` by this way. you want to consider the nodes, rax node size of the backlog part which is not more than setting?",0,0,0,0.9879569411277772,0.9938016533851624,0.9941523671150208,0.0,accept,unanimous_agreement
728029363,9166,"i want all the memory to be accounted one way or the other. maybe add the portions of these that are not currently accounted, after the `if-else` into one of the two? i.e. add the rax and block list to the backlog memory?",0,0,0,0.9871554374694824,0.9943256974220276,0.9923486709594728,0.0,accept,unanimous_agreement
728585586,9166,"in current code, we consider block list into `mem_clients_slaves`, so we add the rax into backlog memory.",0,0,0,0.987970530986786,0.9941819310188292,0.9945719838142396,0.0,accept,unanimous_agreement
728692657,9166,yes,0,0,0,0.9564858078956604,0.9659429788589478,0.9686408638954164,0.0,accept,unanimous_agreement
728693967,9166,imho this one still needs to be done.,0,0,0,0.9160998463630676,0.9847446084022522,0.9589282870292664,0.0,accept,unanimous_agreement
728695371,9166,can you implement the `max()` design suggested above?,0,0,0,0.989603877067566,0.9944217801094056,0.9957213401794434,0.0,accept,unanimous_agreement
728695905,9166,and maybe also add some documentation about the reason (both code and maybe redis.conf if you find a place for it),0,0,0,0.9874474406242372,0.9894427061080932,0.9942336678504944,0.0,accept,unanimous_agreement
728776833,9166,"oh, but i think `repl_` prefix also is not clear, from you comments, how about `replica_` prefix, a little long. are current comments clear? i already changed some comments",0,0,0,0.979556441307068,0.8532761931419373,0.9860775470733644,0.0,accept,unanimous_agreement
728781248,9166,"looking at the last version i guess that's clear enough (also less variables so maybe no need for a block comment above the group). maybe just add `repl_` to `ref_block_pos`? anyway, do what feels right to you.. not a critical thing..",0,0,0,0.7722203731536865,0.9466148018836976,0.9736906886100768,0.0,accept,unanimous_agreement
728801201,9166,"oh, i ever thought you want us to implement it in other pr. let me do it.",0,0,0,0.9399497509002686,0.9013575315475464,0.9829402565956116,0.0,accept,unanimous_agreement
728819948,9166,"other pr is ok with me too.. but i'm afraid to forget, and this one seems to be a good opportunity to handle it. just be sure to also document it and it's reasoning (code, redis.conf, and top comment)",1,-1,1,0.7739036679267883,0.7557551860809326,0.6286554932594299,1.0,accept,majority_agreement
729942386,9166,i want to keep `ref_` prefix which is the same with `ref_repl_buf_node` prefix,0,0,0,0.9881970286369324,0.99195659160614,0.9946953654289246,0.0,accept,unanimous_agreement
730383405,9166,"i think this is too detailed, imho it should be enough to say: [code block]",0,0,-1,0.856567919254303,0.946535348892212,0.8225553035736084,0.0,accept,majority_agreement
730384078,9166,i thought we'll do this: (i think it's also cleaner) [code block] then just use hard_limit_bytes instead of `server.client_obuf_limits[class].hard_limit_bytes` wdyt?,0,0,0,0.9100380539894104,0.9931313395500184,0.9711558222770692,0.0,accept,unanimous_agreement
730384772,9166,i think it's just enough to mention why we skip part of the check [code block],0,0,0,0.9834672808647156,0.9857301712036132,0.9814864993095398,0.0,accept,unanimous_agreement
730385059,9166,why did you remove the reference to the eviction code? i think it may be useful,0,0,0,0.983403980731964,0.9890796542167664,0.9917826652526855,0.0,accept,unanimous_agreement
730428252,9166,"yes, it is clearer",0,0,0,0.982086181640625,0.9806721806526184,0.986221432685852,0.0,accept,unanimous_agreement
730431658,9166,"when i reviewed code, i thought it is not much related with `freememorygetnotcountedmemory `, i forgot why i added it, you think they are related?",0,0,0,0.9454157948493958,0.9862576127052308,0.9875360131263732,0.0,accept,unanimous_agreement
730432561,9166,"i think i was trying to say that this is related to the feedback loop concern when del commands are added to the backlog during eviction. i was probably trying refer to the big comments we added there. maybe it should be even be: `see comments in freememorygetnotcountedmemory for details` i.e. not to refer to the function, but rather to the comments there explaining what would happen when the backlog grows.",0,0,0,0.9271798729896544,0.991214632987976,0.9873102903366088,0.0,accept,unanimous_agreement
888266903,10517,blocked_wait_rerun seems like blocked_postpone with a timeout. so perhaps we should investigate if it makes sense to merge those too. i would prefer to have fewer assumptions to maintain.,0,0,0,0.9362643957138062,0.9890716075897216,0.9893611073493958,0.0,accept,unanimous_agreement
1101071638,10517,i think this change steps on the toes of #11012 and must be rebased and re-evaluated after. see the now existing `client_reprocessing_command`. fyi,0,0,0,0.9403515458106996,0.9915521144866944,0.9845196008682252,0.0,accept,unanimous_agreement
1101074238,10517,"i'm not sure it was necessary to extract these to a function, in #11012 we decided not to move it out and not to indent them all (just re-run some validations that may not be necessary). but also, maybe some of these are wrong to skip, like the check about busy_module_yield_flags. p.s. if we keep this change, ""validate"" may not be right, maybe ""prepare"" is better see e.g. modulecallcommandfilters, and also, maybe the top comment still belongs to processcommand. but anyway, i think after rebase we need to see if this change is still needed.",0,0,0,0.9604873061180116,0.9854620695114136,0.9718072414398192,0.0,accept,unanimous_agreement
1101076176,10517,"maybe i don't understand the purpose of this function though. i thought it's about command lookup, arity checks and other basic things that don't need to be re-evaluated when executing it the second time, but i now see that acl checks are here too.",0,0,0,0.9657419919967652,0.9559661746025084,0.8627316355705261,0.0,accept,unanimous_agreement
1101080041,10517,"i see you've reset it in `rejectcommand`, and here, but shouldn't it be cleared after every command we've executed (successfully)? actually, rejections (e.g. oom). and moved, just mean that we actually processed the command (replied to it). so it's actually the job of `commandprocessed` or `resetclient`. but then again, maybe this whole change isn't needed now (since this can be handled the same way as #11012)",0,0,0,0.9845810532569884,0.9925232529640198,0.9916192293167114,0.0,accept,unanimous_agreement
1101081741,10517,let's avoid the mass of unnecessary white space changes.,0,0,0,0.9700090289115906,0.908439040184021,0.9593487977981568,0.0,accept,unanimous_agreement
1102076169,10517,is this much difference between this and client_pending_command?,0,0,0,0.9664031267166138,0.9832425117492676,0.9917925596237184,0.0,accept,unanimous_agreement
1102079162,10517,is this actually stabilized with your changes?,0,0,0,0.9864084720611572,0.9901812672615052,0.993818461894989,0.0,accept,unanimous_agreement
1102083242,10517,"i missed the discussion about having a separate function that validates the high level construction of the command. i think it make sense to split out a validation function, that doesn't include module command filters.",-1,0,0,0.635111391544342,0.9199241399765016,0.979446530342102,0.0,accept,majority_agreement
1102084873,10517,"i would bump this to notice, we did this at aws and never contributed it. it's not strictly a warning, but it definitely should get logged by default. i think we should all remove the all caps `warning`.",0,0,0,0.9777858853340148,0.9649551510810852,0.9854405522346495,0.0,accept,unanimous_agreement
1102085454,10517,n->slaveof should imply nodeisslave(n) [code block],0,0,0,0.988322913646698,0.9931383728981018,0.9943042397499084,0.0,accept,unanimous_agreement
1102089207,10517,"not sure i fully get why we would replicate the slots here as opposed to in the rdb so the replica comes up knowing the slots. i also presume there are implications here related to the replication buffer now having information that diverges between nodes. some specific concerns about this: 1. the replica is already technically online and serving data at this point, so it won't have correct state. 2. i'm not sure we've fully thought through all the ways the clusterbus can propagate data at different rate than the replication stream, and how that might play with failovers.",0,0,0,0.6329967379570007,0.8560025691986084,0.7053603529930115,0.0,accept,unanimous_agreement
1102090931,10517,odd spacing here. also is this a bug fix?,-1,-1,-1,0.8450418710708618,0.8257728815078735,0.732245922088623,-1.0,accept,unanimous_agreement
1102095511,10517,"they do this today, but there is no enforcement or test asserting this behavior. do we need to take a dependency on this assumption and/or can we add some validation here?",0,0,0,0.9829051494598388,0.987989068031311,0.9915286302566528,0.0,accept,unanimous_agreement
1102100923,10517,"why is this a warning? this seems like a fairly minor event, this node is just acknowledging another failover.",0,0,0,0.5983086824417114,0.7072697281837463,0.8597546219825745,0.0,accept,unanimous_agreement
1102104596,10517,"isn't this logic already in clusterupdateslotsconfigwith ? edit: looks like victor wrote that after you did, oops.",-1,0,-1,0.9393479228019714,0.6743606925010681,0.8368674516677856,-1.0,accept,majority_agreement
1102121723,10517,"i'm not entirely clear why this can't just be a `wait` command issued by the client for now. i feel like there is some interesting ideas here about having having deep support in redis for commands that wait for replicas to process them before acknowledging and applying them locally, but i'm not sure we need that here.",0,0,0,0.8797304630279541,0.8905742168426514,0.7265908718109131,0.0,accept,unanimous_agreement
1102527985,10517,"with the changes in this pr, it looks like 1 only happens if myself is a replica, so maybe mention that too? a master left without slots doesn't jump to another chard.",0,0,0,0.979712963104248,0.9909205436706544,0.9886307716369628,0.0,accept,unanimous_agreement
1102529201,10517,we'll need to update the documentation with this new behaviour. at least redis.conf mentions this [code block],0,0,0,0.9864685535430908,0.991388499736786,0.9954524636268616,0.0,accept,unanimous_agreement
1102535801,10517,"i never understood why a master who lost its last slot does this, but i didn't dare changing it. in the use case of scaling down the number of shards, you migrate the slots away from a shard and then take down the nodes. then, when you think the node is empty, it starts replicating another master just when you want to take it down. very weird. it's good we're dropping that behaviour. (in this scenario, you'd not want the replicas to migrate either, but to stay in the empty shard... a workaround is to disable replica migration on the nodes in the shard before emptying the shard.)",-1,-1,-1,0.979799211025238,0.9923933744430542,0.9865652918815612,-1.0,accept,unanimous_agreement
1102562324,10517,"hehe, i don't know who wrote it first. i wrote something in april and something more in september. here it seems that this check is just moved around within the file. ping's detailed scenario explanation is new though.",0,0,1,0.908728301525116,0.7506603598594666,0.9269063472747804,0.0,accept,majority_agreement
1102566131,10517,trailing space within the warning. [code block],0,0,0,0.98807293176651,0.9916425943374634,0.956275999546051,0.0,accept,unanimous_agreement
1102977434,10517,"yeah, i like the explanation, we should definitely keep that around.",1,1,1,0.8481111526489258,0.4916537404060364,0.9527102708816528,1.0,accept,unanimous_agreement
1102979123,10517,"i guess this also isn't strictly necessary, but it seems like we copy this around all over the place.",0,0,0,0.9766320586204528,0.960382640361786,0.968010187149048,0.0,accept,unanimous_agreement
1105062792,10517,"are we sure people haven't built tooling around this state management anyways? my understanding is that the redis-cli doesn't handle these failure modes todays, so it's unclear why we're trying to preserve them on the server side.",0,0,0,0.924443244934082,0.9257708787918092,0.9792647361755372,0.0,accept,unanimous_agreement
1105064766,10517,should we clear the data out if we aren't going to import it? otherwise we just have random stale data.,0,0,0,0.9057286381721495,0.9403204321861268,0.9732332825660706,0.0,accept,unanimous_agreement
1105069170,10517,"an alternative is we could have some threshold after which if a node is importing data, and no other node in the cluster owns that data, we just take ownership of the slot. this removes the need for complex state handling with the replica.",0,0,0,0.9868023991584778,0.9902290105819702,0.9913512468338012,0.0,accept,unanimous_agreement
1105074883,10517,"made related comment elsewhere. i'm not convinced we need this blocking code, but if we do we should try to align the various blocking approaches more.",0,0,0,0.9626029133796692,0.970189094543457,0.9849648475646972,0.0,accept,unanimous_agreement
1105075287,10517,going to poke again to put stuff in the tests/unit/cluster so they run as part of the ci.,0,0,0,0.98370760679245,0.9900466799736024,0.9855608344078064,0.0,accept,unanimous_agreement
1105076132,10517,seems like some extra code.,0,0,0,0.9591109752655028,0.8959154486656189,0.9720396399497986,0.0,accept,unanimous_agreement
1105076439,10517,more extra code.,0,0,0,0.9772757887840272,0.9573922753334044,0.9873724579811096,0.0,accept,unanimous_agreement
1105077352,10517,usage of namespaces isn't very clear since you just reference them as if they were just normal variables.,0,0,0,0.9029017090797424,0.8961436748504639,0.9470807909965516,0.0,accept,unanimous_agreement
1105078602,10517,"maybe use ""get_cluster_nodes"" so that it's formatted into a dict instead of an array.",0,0,0,0.985368311405182,0.9945123195648192,0.9888525009155272,0.0,accept,unanimous_agreement
1105084141,10517,this also makes me think more that the replicas should have their own perceived state about on going slot migrations that is driven through the replication stream and not here.,0,0,0,0.9728085398674012,0.9820319414138794,0.980703353881836,0.0,accept,unanimous_agreement
1105085336,10517,stylistically we normally do this for readability: [code block] if the conditional is long and multi-line.,0,0,0,0.9872430562973022,0.988564670085907,0.990208387374878,0.0,accept,unanimous_agreement
1105087676,10517,this is also misindented.,0,0,0,0.7408287525177002,0.625217854976654,0.9062498211860656,0.0,accept,unanimous_agreement
1105336835,10517,yep that is the idea behind single-sourcing. suggestion incorporated.,0,0,0,0.9850471019744872,0.9504272937774658,0.9902461767196656,0.0,accept,unanimous_agreement
1105336913,10517,"it is not a clear cut to me whether this should be `warning` or `notice`. i can see both sides of the argument. since you mentioned one side, i will add the counter argument here which is ""any consensus-less based epoch bump risks data loss"" and it is in this sense that i think `warning` sends the right signal to the admins. that said, i am also fine with `notice` so i lowered the log level to `notice`. curious to hear the community's thoughts.",0,0,0,0.7623679041862488,0.8998203873634338,0.7431470155715942,0.0,accept,unanimous_agreement
1105349593,10517,"i think we have enough information here to make the right call and keep the cluster as consistent as possible. tooling implies human operators, which brings in human errors and delays so imo last resort.",0,0,0,0.9706573486328124,0.964887797832489,0.958074688911438,0.0,accept,unanimous_agreement
1105361211,10517,"is your suggestion to wait for the replication to restart and then fix the migrating target? if so, there will be an availability issue for the keys caught in the middle as they will be redirected to the wrong node until the migrating state is fixed, which is one of the problems this pr is trying to address.",0,0,0,0.9422438740730286,0.9678276181221008,0.99065899848938,0.0,accept,unanimous_agreement
1105362569,10517,sorry i keep forgetting about the multi-line style.,-1,-1,-1,0.9855072498321532,0.9912917017936708,0.9910083413124084,-1.0,accept,unanimous_agreement
1105369381,10517,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1105379430,10517,updated. actually i think i missed the is_replica check on `myself` - added the check now.,0,0,0,0.9753521680831908,0.9897106289863586,0.9891088008880616,0.0,accept,unanimous_agreement
1105388433,10517,"are you referring to case 2? i don't think it is a new behavior. it is a more reliable/predictable implementation of an existing behavior imo. more specifically, we had 2.1 before but it was based on slot count (lost_count == found_count). 2.2 manifested in a chained primary/replica relationship that we'd resolve later on.",0,0,0,0.979437530040741,0.987093150615692,0.9883037805557252,0.0,accept,unanimous_agreement
1105396751,10517,"yeah, an even worse situation could happen imo if somehow a failover, either manual (due to bugs/human errors) or automatic, races ahead of your attempt to take it down and now we have an application whose redis connections/requests get dropped. it is a rare case but when we are talking about the redis user base, small probability events can happen.",0,0,0,0.715737521648407,0.7389193177223206,0.5435774326324463,0.0,accept,unanimous_agreement
1105430286,10517,"when i added these new trace statements, i was thinking that all topology change events are important and worth extra attention because they are not expected on a steady cluster (modulo rolling upgrades and slot migrations, of course). now mulling over this some more, i think what i really wanted is a way to easily filter out all topology change events; whether or not these events are `warning` or `notice` is actually less important to me. would it work if i use a prefix for all these messages, say `topology:`?",0,0,0,0.89797043800354,0.9447836875915528,0.9571555852890016,0.0,accept,unanimous_agreement
1105432516,10517,the folding logic is written by victor. i moved it around with some explanation.,0,0,0,0.9855615496635436,0.9725705981254578,0.9944177865982056,0.0,accept,unanimous_agreement
1105432974,10517,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1105433200,10517,sorry bad merge,-1,-1,-1,0.9878737330436708,0.9936255216598512,0.9951313734054564,-1.0,accept,unanimous_agreement
1105451562,10517,i ran the entire cluster test suite including the new tests in a loop over 20 times without issues for last nov's [a link].,0,0,0,0.9846705198287964,0.9820997714996338,0.9928650856018066,0.0,accept,unanimous_agreement
1105508260,10517,"this log notice looks like a reference to the changes in this pr. perhaps we should log something that's more useful for the admin? and i think we should say who ""the sender"" is using `sender->name` (%.40s) like in other log entries. perhaps something like *""my last slot was migrated to %.40s. i am now an empty master.""* ? the term ""empty master"" can be useful since it's used under [a link]",0,0,0,0.976903200149536,0.9914480447769164,0.9852046966552734,0.0,accept,unanimous_agreement
1106158564,10517,i think this was our updated guidance we haven't merged yet: [a link],0,0,0,0.9518146514892578,0.958200216293335,0.9911125302314758,0.0,accept,unanimous_agreement
1106165349,10517,"i tried to deep dive into this behavior, and the best thing i can really come up with was that salvatore originally envisioned the cluster as just a collection of nodes that are either, ""participating"" in the cluster or ""staged"" to enter the cluster. moving between these states is always an operator action. so it makes sense that a master would continue to participate by becoming a replica of something. either that or we never thought about it that much :) i'm also fine with the new behavior.",1,1,1,0.9756903648376464,0.994124710559845,0.9933092594146729,1.0,accept,unanimous_agreement
1106189305,10517,"tooling doesn't mean human operators. when resharding is happening, i am assuming people are using tooling to assist with the reshard since it's hard to orchestrate on your own. i want to understand how that behaves with all of these states. more so because we should fix bugs there. since we aren't self-recovering from these errors, just trying to move everything into a more consistent state, i care more about a human coming in and recovering. if they had a procedure which now no longer works, i would like us to understand that. hopefully this just makes all the recovery easier.",0,0,0,0.5587894320487976,0.6662400960922241,0.8486979007720947,0.0,accept,unanimous_agreement
1106686498,10517,"right this is the goal with this pr. with this pr, the server can always park in an intermediate-yet-consistent state as if the re-sharding has paused gracefully despite primary failures. i believe the recovery is made much easier with this pr. even better, admins are no longer under the pressure to fix a broken cluster immediately because the cluster will continue to function properly, though at a reduced capacity (due to extra hops).",0,0,0,0.8236035704612732,0.97314453125,0.6854797601699829,0.0,accept,unanimous_agreement
1106711801,10517,"the two flags are indeed close but there are some properties i couldn't get from `client_pending_command`. for instance, i need to determine whether the `cluster setslot node ` command is being executed for the first time (prior to replication) or for the second time (after replication is complete). that said, i also don't like the significant overlap between the two. i have reworked the code to converge on `client_pending_command`.",-1,0,0,0.8963221311569214,0.6733953356742859,0.8298788666725159,0.0,accept,majority_agreement
1106758138,10517,"yep - i can see that the `client_rerun_command` flag unnecessarily couples several unrelated tasks, which was not intended. i have removed this flag and converged on `client_pending_command`, as suggested by madelyn as well.",0,0,0,0.9830613732337952,0.9792596101760864,0.989896297454834,0.0,accept,unanimous_agreement
1106858544,10517,"i renamed the new block state to `block_wait_for_repl`. conceptually speaking, i think the new block state is more like a combo of `block_wait` and `block_postpone`. more specifically, a command is blocked behind this replication so we will need to control what to reply (actually none) when the replication is completed.",0,0,0,0.9845746159553528,0.9890668392181396,0.988212525844574,0.0,accept,unanimous_agreement
1106860961,10517,"madelyn, i think you are referring to the new *client* flag as opposed to the blocking code. i have removed this client flag but i think we will need a new blocking code that allows us to express the new contract of *resume the pending command after the command is replicated*.",0,0,0,0.9794960618019104,0.98163902759552,0.9913422465324402,0.0,accept,unanimous_agreement
1106868410,10517,"the functionality in question is similar to that of the wait command, but there is a crucial difference. the wait command is intended for use by real clients, so when it completes, the replication status must be returned to the client that issued the original wait command. in contrast, in this case, the server must consume the replication status and continue executing the pending command. initially, i considered building the new wait* functionality on top of the existing wait command handling logic, but i ultimately concluded that it would be cleaner to introduce a new wait* contract instead.",0,0,0,0.97625070810318,0.9924174547195436,0.9865896701812744,0.0,accept,unanimous_agreement
1107706371,10517,okay i think i know where my confusion is coming from. the config name didn't tell the whole story that it also allows an empty primary to become replicas of the primary that takes away its last slot. the new behavior is imo more intuitive and better aligned with the config name. i will update the text next.,0,0,0,0.9579107165336608,0.9336667060852052,0.8393271565437317,0.0,accept,unanimous_agreement
1107792547,10517,adding topology is fine. we probably should add some standard about labeling of log messages anyways.,0,0,0,0.9617724418640136,0.988757312297821,0.9877062439918518,0.0,accept,unanimous_agreement
1107799631,10517,"i want to make sure we've exhausted the solution space before starting to go down this path, i really don't want a pseudo synchronous mechanism hanging out in the engine given the complexity. my understanding is that we are doing this so that we handle cases where neither a or a' own the slot anymore but b died, but my understanding is we can reconcile those states without this replication mechanism by just having b take ownership after some threshold. that seems more inline with the general reconciliatory nature of redis cluster. i also think it will be better handled in the cluster v2 world, since the td will issue the updated state. i believe this was discussed here: [a link]",0,0,0,0.8497783541679382,0.9236400723457336,0.9599663019180298,0.0,accept,unanimous_agreement
1107802991,10517,are there any such states where automation might take incorrect actions that were previously acceptable. such as if a migration failed part way through it might have just finalized the states? or are we assuming that all automation probably wasn't handling these modes.,0,0,0,0.9526329040527344,0.9827102422714232,0.9812151789665222,0.0,accept,unanimous_agreement
1108122176,10517,"there is an `assert_no_match` function to use for checks like this. btw, this code only checks that it's not a replica of the $owner node. not ""any other nodes"" as said in the comment. we could check role on the new node instead.",0,0,0,0.9872879981994628,0.9938045740127563,0.994597315788269,0.0,accept,unanimous_agreement
1108189647,10517,"can't we either use blocked_wait for this purpose, or even abandon the implicit blocking and instruct the client (redis-cli) to issue a wait command?",0,0,0,0.98275488615036,0.9956876635551452,0.992065966129303,0.0,accept,unanimous_agreement
1108201118,10517,"now that we're rebased, why do we need this change?",0,0,0,0.9616177678108216,0.9842817187309264,0.9853068590164183,0.0,accept,unanimous_agreement
1108204397,10517,removing this will also revert all the complications you added around client_pending_command in replication.c and blocked.c (will actually leave these two files unmodified),0,0,0,0.981513261795044,0.9904820919036864,0.9941434264183044,0.0,accept,unanimous_agreement
1109358372,10517,`redis-cli` worked in my previous tests but i can double check. is there any other automation tool that you would recommend validating as well?,0,0,0,0.9846745729446412,0.9922752976417542,0.9916058778762816,0.0,accept,unanimous_agreement
1109368702,10517,"what do you think if we add a `component` parameter to `serverlog` with predefined `component` integer values that map to strings such as `cluster`, `server`, `misc` (for catch-all), etc? i can create a bug to take care of this ""componentized"" logging improvement if this sounds interesting. this way, admin can easily zoom in a particular area of the server. for now, i will drop the logging level to `notice` and not add any one-off prefixes or suffixes.",0,0,0,0.984688401222229,0.984005093574524,0.9839147329330444,0.0,accept,unanimous_agreement
1109375925,10517,"this is the tricky part to get right reliably. 1. this is talking about a non-consensus based decision. what if the cluster was partitioned around the same time and the original owner was out of touch temporarily? 2. how does the importing node know definitely within a deterministic time window that no one else owns the slot? 3. until the ownership is fixed, the slot in question is unavailable. while this pr may add some complexity, i believe it's justified since it solves the problem at its core and provides the necessary determinism.",0,0,0,0.6910874843597412,0.9722886681556702,0.9068466424942015,0.0,accept,unanimous_agreement
1109380387,10517,i assume your comments refer to the 1s timeout - i was looking at this from the failure side. i think it is ok for the request to timeout and fail as long as we don't leave the cluster in a consistent state. i don't consider that the timeout must never happen. i can rephrase the timeout callout and clarify if that is what you are concerned about.,0,0,0,0.9275810718536376,0.9702184796333312,0.9784196615219116,0.0,accept,unanimous_agreement
1109387839,10517,"wanted to clarify that the synchronous behavior materializes on the client who issued the request in the first place. it is not so much different than the case where the client issues `wait`. i think this is the same question raised in this [a link]. i have provided my response there. please take a look. if the community is willing to wait for cluster v2, i agree it is a fair proposal to consider won't-fixing this spof issue in cluster v1.",0,0,0,0.9467610716819764,0.8100177645683289,0.8587790727615356,0.0,accept,unanimous_agreement
1110165801,10517,"iiuc, we don't save the migration states in the rdb file, correct? we can look at this state from the other angle - what could happen if there exist a window when the two nodes (primary and replica) don't agree on the migration states? first of all, we are currently in a perpetual inconsistent state; second, the inconsistent window will be small with this pr; third, if the primary crashes before the migration state has been replicated, it is either the same situation as before this pr or if there is already other replica in the shard, we have a chance to replicate the migration state again. overall, it is not a more incorrect than what we have now and i would say it improves a lot. fwiw, we are not dealing with a cluster wide consensus on this path. this is merely replicating states among nodes in the same shard, which is not much different than data replication, conceptually speaking. i am not sure if i understand your concern about the potential interference with clusterbus/failover? can you elaborate a bit more?",0,0,0,0.9634912610054016,0.9785531759262084,0.9870796799659728,0.0,accept,unanimous_agreement
1110169236,10517,i think this is the same question raised in this [a link]. i have provided a response [a link]. please take a look.,0,0,0,0.9777379035949708,0.9618490934371948,0.9779324531555176,0.0,accept,unanimous_agreement
1110171440,10517,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1110182316,10517,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1110493352,10517,"yes this change is no longer needed after rebasing. that said, i'd vote for keeping the validatecommand function (separation of concerns) but i am fine reverting this change if there is a consensus.",0,0,0,0.929479479789734,0.9871954917907716,0.9690342545509338,0.0,accept,unanimous_agreement
1110493922,10517,will do after closing the high level discussions,0,0,0,0.9821830987930298,0.9898834824562072,0.9866580367088318,0.0,accept,unanimous_agreement
1110517842,10517,downgraded to `notice` (and in other similar places),0,0,0,0.9611720442771912,0.9944102168083192,0.9708823561668396,0.0,accept,unanimous_agreement
1110518937,10517,"comments updated to clarify that ""1000ms"" is not a dependency for correctness.",0,0,0,0.9848196506500244,0.989847719669342,0.9920536279678344,0.0,accept,unanimous_agreement
1110539782,10517,agreed. this does sound like a logical thing to do. updated.,0,0,1,0.9346209168434144,0.792158305644989,0.8839255571365356,0.0,accept,majority_agreement
1110540721,10517,good point - `role` check added.,1,1,1,0.8912947773933411,0.5656083822250366,0.956227481365204,1.0,accept,unanimous_agreement
1110603295,10517,resolving since the other [a link] has more context. let's continue the discussion there.,0,0,0,0.9791947603225708,0.9877963662147522,0.9882735013961792,0.0,accept,unanimous_agreement
1111265562,10517,"so you need that because you want a command to be executed half way (propagating something, or initiating replication), then get blocked on a replication offset, and then when the repl_offset matches, the second half of the command is getting executed? it seems a bit against the concept of ""command"" in redis (being atomic), maybe we should somehow split that into two commands and issue a wait in between (sending them in pipeline)? i didn't dig into the changes in cluster.c, so correct me if i'm wrong. if we somehow give that up, we can revert nearly / all changes to blocked.c, replication.c, server.h, and server.c.",0,0,0,0.9433422684669496,0.6645235419273376,0.9348793625831604,0.0,accept,unanimous_agreement
1112673525,10517,"not really. what i need is essentially ""synchronous replication"" such that the command is first executed on the replicas and only upon successful replication gets executed on the primary. the command is still executed as an atomic unit so atomicity is upheld. the new thing is the ""synchronous replication"", which has not been done before. the command in question here is `cluster set `. the idea is to maintain backward compatibility with the existing slot migration protocol which always sends the command to the primaries. an alternative would be to have the admin finalize the slot ownership on the replicas explicitly. this is unconventional imo and places more burden on the admin side. i am not sure how to break the command apart into two parts. it is the execution order (primary after replicas) that this pr is trying to address. no worries. there are two spofs this pr is trying to solve. one happens during the slot migration and the other happens during the slot ownership finalization. the first one is mitigated by replicating the migration states to replicas either at the slot migration staring time and whenever a new replica comes up online. the second one is the one that requires the ownership to be finalized on the target replicas (if any) first, then on the target primary, and finally on the source shard, where the execution order between source primary and source replicas isn't material. this is the only order that would prevent a spof caused by a target primary crashing shortly after broadcasting its ownership to the cluster but target replicas getting stuck in the `importing` state. this [a link] has the details for the second spof.",0,0,0,0.9674502015113832,0.9853984117507936,0.9678686857223512,0.0,accept,unanimous_agreement
1112704441,10517,"i rather revert it. first to avoid unnecessary merge conflicts between branches and forks. secondly, i think some of the code in this function in your current for is misplaced, like module command filters, or other things that may need to be re-processed. lastly, if / when we do have to do some similar change due to some future project, the fine details of what needs to be in this function vs the outer one and it's name and role may be slightly different, so we'll have to modify things anyway, so why do it twice...",0,0,0,0.8299599885940552,0.9163264036178588,0.8966289162635803,0.0,accept,unanimous_agreement
1113313101,10517,"i think per component logging is a good idea. probably out of scope for this pr, just so we don't forget it i created the issue: [a link]",1,1,1,0.731860339641571,0.6445775032043457,0.8296068906784058,1.0,accept,unanimous_agreement
1113482156,10517,"this is only a problem for availability, since it should still know about the ownership in the other slots. if as far as the node knows, it doesn't own the slots so it won't take anything over. we don't know anything definitely, we have no strong forms of consistency without cluster v2. this is true. i know i've stated this before, but i don't believe this is really the core problem. the core of the problem is we have no consistent store of cluster state, everyone has their own local opinion of the state. there are also plenty of other availability drawbacks here: 1. if a replica is not currently responsive this will fail, whereas it could have completed successfully before. this is a different type of availability. my understanding is that the redis-cli finalizes the slot on all nodes together. 2. we can still lose the state. we aren't durably storing state, so we can end up with no one serving the slot. we can also end up with the state finalized on one of multiple replicas. that replica could win the election, and then subsequently fail, and the replica without the finalized state taking over. i'm happy as long as we converge. i would like you to take a look at this section.",0,0,0,0.5473061800003052,0.5629763603210449,0.8678117990493774,0.0,accept,unanimous_agreement
1113489642,10517,"this is being discussed in other issues, so going to resolve this.",0,0,0,0.9775168895721436,0.968841016292572,0.9915944933891296,0.0,accept,unanimous_agreement
1113528087,10517,"fully agreed that strong consistency for (cluster) metadata is much more desired. i have an implicit assumption that we will need to continue working with cluster v1 in the foreseeable future even after cluster v2 materializes hence my definition of ""core"" problems came with that constraint. these are real pain points for the cluster v1 customers.",0,0,0,0.8545322418212891,0.6627839207649231,0.8806339502334595,0.0,accept,unanimous_agreement
1113528420,10517,sgtm,0,0,0,0.9783707857131958,0.9109601974487304,0.9894869327545166,0.0,accept,unanimous_agreement
1113529707,10517,lowered to `notice`,0,0,0,0.9833924174308776,0.991117775440216,0.9954829216003418,0.0,accept,unanimous_agreement
1118634867,10517,incomplete revert. [code block],0,0,0,0.8332234025001526,0.9879881143569946,0.6804691553115845,0.0,accept,unanimous_agreement
1167929414,10517,i don't understand this change. we're gonna unblock the client without sending a reply?,-1,-1,-1,0.8630014657974243,0.8308449983596802,0.7099379301071167,-1.0,accept,unanimous_agreement
1170423721,10517,"good catch . this change is no longer needed and should be removed, now that the wait is done outside of the engine and this check will always return true so a reply is guaranteed. previously, client_pending_commnd can happen on this path if the engine itself decides to hold off the slot finalization on the primary until it is replicated.",1,0,1,0.9620426893234252,0.5335544943809509,0.9721654653549194,1.0,accept,majority_agreement
1170428076,10517,change reverted,0,0,0,0.9809938669204712,0.9574069380760192,0.9649603962898254,0.0,accept,unanimous_agreement
1175065644,10517,"this scenario comment needs to be updated to match the implementation, i.e. using setslot ... replicaonly.",0,0,0,0.9872531294822692,0.9950828552246094,0.9955176711082458,0.0,accept,unanimous_agreement
1175067361,10517,"i think we need a comment like ""this command was added to mitigate the following scenario"" here. possibly also describe what this command does, before explaining the problem scenario.",0,0,0,0.9857103228569032,0.9881332516670228,0.985161304473877,0.0,accept,unanimous_agreement
1175127632,10517,this comment could mention what this new setslot variant is.,0,0,0,0.9875077605247498,0.9914615154266356,0.9927104711532592,0.0,accept,unanimous_agreement
1175132723,10517,"this function `clustermanagersetslot` used to sent only one cluster setslot command. are you sure we should ""inject"" the new command here and send two commands? why not add the new command at the caller site? there are some calls to clustermanagersetslot with status=""node"" where we might not want to inject the new command, such as the calls from `clustermanagerfixslotscoverage()` and `clustermanagerfixopenslot()`. btw, `status` is always ""node"" here, so no need for %s.",0,0,0,0.9814963936805724,0.9943048357963562,0.99498850107193,0.0,accept,unanimous_agreement
1175144765,10517,"is this right? i though setslot replicaonly causes repliction only and has no effect on the node itself. or what do you mean by ""only on success will we handle the command""? another question: in the command setslot ... node (without replicaonly), is the command replicated or not? if not (and if an old redis-cli is used which doesn't send the new replicaonly command) do we rely on the cluster bus propagating the information to replicas instead?",0,0,0,0.9790522456169128,0.9930042624473572,0.9902175068855286,0.0,accept,unanimous_agreement
1175160807,10517,"isn't this still (semi-)synchronous replication? i thought the idea was to make setslot replicaonly replicate without blocking and just return the number of replicas. next, the client sends a wait. in this way, we don't need to introduce another wait-like command that blocks for replication. i think that's what the core team suggested. are there any issues with this approach?",0,0,0,0.9784055948257446,0.9850430488586426,0.986099362373352,0.0,accept,unanimous_agreement
1176013848,10517,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1176013904,10517,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1176015827,10517,you are right. this change is too broad. we only need to perform the replication when finalizing slots in the target shard. fixed.,0,0,0,0.9278391599655152,0.7232643365859985,0.985803246498108,0.0,accept,unanimous_agreement
1176016370,10517,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1176017361,10517,"thanks ! yeah i think i missed that ""full async"" part - i have updated the logic now to go full async. the wait is now initiated by the client now.",1,1,1,0.9859840273857116,0.9781004190444946,0.9898597598075868,1.0,accept,unanimous_agreement
1176017837,10517,this section is now re-written. can you please review again?,0,0,0,0.965319037437439,0.9903112649917604,0.9946422576904296,0.0,accept,unanimous_agreement
1176172058,10517,nit [code block],0,0,0,0.9879410862922668,0.9891023635864258,0.9871647357940674,0.0,accept,unanimous_agreement
1176174489,10517,explaining what a and b are before the sequence instead of afterwards makes it easier to follow the sequence imo. [code block],0,0,0,0.9832412004470824,0.9933655858039856,0.9769529104232788,0.0,accept,unanimous_agreement
1176619778,10517,"why exactly 1? we don't know the number of replicas, do we? what if there are no replicas at all? what if the primary crashes when one replica has replicated and the other replicas haven't, is it likely that this replica will be promoted because it has a better replica rank than the others? that's what i can think of. what's your reasoning?",0,0,0,0.9117622971534728,0.8936441540718079,0.9851548075675964,0.0,accept,unanimous_agreement
1176628617,10517,looks good now.,1,1,1,0.8918087482452393,0.9299731254577636,0.6216913461685181,1.0,accept,unanimous_agreement
1176831031,10517,"we do know the number of replicas though i was thinking that having one replica acknowledging is sufficient since we would need to lose both the primary and the replica in question to hit the original spof issue. on a second thought though, i am now convinced that we should wait for all replicas since the intent is ""best effort only"" anyways. will send in an update next. i have modified the engine to return a new error string ""target node has no replica"". yes, intuitively the replica who ack'd the replication would rank higher compared to the ones who didn't. that said, will wait for all replicas next.",0,0,0,0.907378613948822,0.9566324949264526,0.9561344385147096,0.0,accept,unanimous_agreement
1177094156,10517,"why not do proper indentation? the only reason it's not always done in the tests (afaik) is to avoid touching the git history of a lot of old code, but this is a new file.",0,0,0,0.9623120427131652,0.9828522801399232,0.9857058525085448,0.0,accept,unanimous_agreement
1177104677,10517,"i thought that is the best formatting :). jokes aside, happy to make any formatting change if someone can point me to the right template.",1,1,1,0.9905104041099548,0.990948498249054,0.9964272379875184,1.0,accept,unanimous_agreement
1177111465,10517,"well, i thought indent the body of { ... } is the normal, as is done in all the other { ... }. not that it matters much though, if you prefer to avoid it.",0,0,0,0.9492599368095398,0.982108473777771,0.9835625290870668,0.0,accept,unanimous_agreement
1177206246,10517,reformatted the test code so start_server is not longer multi-lines and fix some indentation issues. i think it looks like the majority of the test code but please let me know if there are still things missed.,0,0,0,0.983998715877533,0.9846466779708862,0.9129599332809448,0.0,accept,unanimous_agreement
1177460956,10517,"ok, fine. the only point i was thinking about is indenting the body of `start_cluster`. i know it's not indented in other test suites, which is odd but it's fine.",0,0,0,0.9575538039207458,0.93533855676651,0.7626381516456604,0.0,accept,unanimous_agreement
1178690752,10517,i see. i've fixed the indentation now. also added a new test.,0,0,0,0.9750144481658936,0.9737544059753418,0.9799275398254396,0.0,accept,unanimous_agreement
1240512940,10517,"yes, we don't today. i'm wondering if we should. would it simplify everything for correctness if slot ownership is transferred through the replication stream (almost exclusively). the current solution will also introduce some odd behavior since we different replicas will disagree on the offset, since some of them will have this new offset data. i think it makes more sense to have it as a new rdb aux field which can be ignored.",0,0,0,0.969398021697998,0.9495946168899536,0.9805434346199036,0.0,accept,unanimous_agreement
1240525126,10517,"this comment block is weirdly not indented that much, and just feels cramped.",-1,-1,-1,0.9670517444610596,0.9660716652870178,0.9721860885620116,-1.0,accept,unanimous_agreement
1240525525,10517,what is this for?,0,0,0,0.9697429537773132,0.9780064821243286,0.9856045246124268,0.0,accept,unanimous_agreement
1240525923,10517,"[code block] kind of surprised there isn't a better api for this, but would like to go through one of the defined rewrite mechanisms.",0,-1,0,0.6709266304969788,0.5186205506324768,0.5845969915390015,0.0,accept,majority_agreement
1240528841,10517,i think this an artifact from the earlier revision?,0,0,0,0.982491970062256,0.991828203201294,0.9812535643577576,0.0,accept,unanimous_agreement
1240537434,10517,"i'm pretty sure this isn't doing what you expect, but i think it works ok. replicationfeedslaves adds the request to the shared buffer, which all replicas get. so we are broadcasting this to all nodes. these are all idempotent so i think it's ok.",0,0,1,0.9500745534896852,0.8823093175888062,0.5369226336479187,0.0,accept,majority_agreement
1240545806,10517,"[code block] human nodenames were added in the interim, which is supposed to give better log visibility by reporting a logical identifier instead of just the guid for the node. if you can, please add it wherever it would be useful to have more information.",0,0,0,0.9867353439331056,0.989779770374298,0.991622269153595,0.0,accept,unanimous_agreement
1243074257,10517,agreed that this is not needed. removing,0,0,0,0.9789912700653076,0.959875226020813,0.988297998905182,0.0,accept,unanimous_agreement
1243077846,10517,good catch. removed,1,1,1,0.9702473282814026,0.9855815768241882,0.994541585445404,1.0,accept,unanimous_agreement
1244864637,10517,"this will break the client pause write status, since it doesn't check `server.paused_actions`",0,0,0,0.9791662096977234,0.975480020046234,0.9946367144584656,0.0,accept,unanimous_agreement
1405612888,10517,this is the replica online path so i don't see how clients could be paused for write?,0,0,0,0.9808177947998048,0.9908801317214966,0.9933766722679138,0.0,accept,unanimous_agreement
1533472447,13157,"you shall **not** remove the bsd license header, since there are third-party contributions to those files (without signing a cla), which were licensed under bsd-3-clause. the same also applies to other files in `src/*`.",0,0,0,0.9883219599723816,0.9949012994766236,0.9935177564620972,0.0,accept,unanimous_agreement
698383459,9320,"nit: this is a repeating pattern, a `clustergetconntype()` helper function might be nicer.",0,0,0,0.9696930646896362,0.988754391670227,0.9793567657470704,0.0,accept,unanimous_agreement
698385138,9320,we should probably identify the case where tls support was not loaded and report it clearly.,0,0,0,0.9863241314888,0.9905906319618224,0.9914973378181458,0.0,accept,unanimous_agreement
698386817,9320,i think we should avoid a linked list here and just hold an array for the sake of efficiency.,0,0,0,0.973275065422058,0.9649367332458496,0.9784205555915833,0.0,accept,unanimous_agreement
698388893,9320,"this is not currently used and i'm not sure how useful and practical it's going to be to ever support it (we'd need refcounts on connection types, and see that we can really evict all listening connections etc.). i suggest to drop it, at least initially and avoid dead code.",0,0,0,0.7928926944732666,0.7854485511779785,0.8805624842643738,0.0,accept,unanimous_agreement
698390191,9320,"i'd consider even turning these into assertions, i'm not sure we should accept an attempt to operate on a non-existing connection type as user / configuration error but rather a plain bug.",0,0,0,0.8454350829124451,0.65787273645401,0.9486597180366516,0.0,accept,unanimous_agreement
698391354,9320,"this should probably be an arbitrary string, as a field in the `connectiontype` struct.",0,0,0,0.9870304465293884,0.9945883750915528,0.991954743862152,0.0,accept,unanimous_agreement
895154316,9320,"which file is lower in the abstraction hierarchy now? anet.c or connection.c? anet.c is just some convenience wrappers on system calls, so connection.c / socket.c is using them when needed. but now we have code in anet.c that depends on a constant defined in connection.h. maybe to solve it we need another set of defines with an anet prefix. other alternatives is to either take a boolean, or split into many separate methods.",0,0,0,0.9840155839920044,0.9871312975883484,0.9823771715164183,0.0,accept,unanimous_agreement
895158418,9320,todo?,0,0,0,0.940309464931488,0.934238076210022,0.9920437932014464,0.0,accept,unanimous_agreement
895158700,9320,let's document that interface (and return value) somewhere. maybe here is the right place? or inside the struct..,0,0,0,0.9856824278831482,0.9912673830986024,0.9915632009506226,0.0,accept,unanimous_agreement
895160203,9320,let's document `force`,0,0,0,0.98653644323349,0.9903563857078552,0.9952617883682252,0.0,accept,unanimous_agreement
895168977,9320,"considering the types are constant and not dynamic, maybe we should add a lookup table with their names rather than indexes. i.e. the code can be dynamically loaded and more types can be added without changes in redis, but the list of types is hard coded.",0,0,0,0.9874171018600464,0.9919793605804444,0.9897762537002563,0.0,accept,unanimous_agreement
895169589,9320,"i don't think this should depend on `server.tls_replication`. instead, we probably need to clean up all types (a loop) here before `execve` note, this was added in #8589",0,0,0,0.9854958653450012,0.9918066263198853,0.9900564551353456,0.0,accept,unanimous_agreement
895170486,9320,"in the past we did `tlsinit()` just a bit after `initserverconfig()` (long before `initserver()`) this change could have some implications, and maybe we'll have to split registration from init. e.g. now we do the init after deemonization (which actually sounds better), and in the past we did it before)",0,0,0,0.982790231704712,0.9932608008384703,0.989896297454834,0.0,accept,unanimous_agreement
895170962,9320,"maybe `force_refresh`, or `reconfigure` is better? i.e. when false, we configure only if not already configured.",0,0,0,0.9869208335876464,0.9947156310081482,0.9888238310813904,0.0,accept,unanimous_agreement
895171000,9320,nitpick: extra space,0,0,0,0.985584795475006,0.9711913466453552,0.9627152681350708,0.0,accept,unanimous_agreement
895176689,9320,"i noticed a few places that you moved big chunks of code to the top (adding static), so they can be referred to from the table. maybe it'll be better to add a forward declaration rather than move a chunk of code (better for code review and blame log). it seems that (unlike most pr), we'll probably merge this one with a merge commit or a rebase merge (not a squash-merge). so if you do such additional changes we have two options: 1. add an additional commit with a title like `sqush into `, so we can review that commit and do the squashing before mergin the pr. 2. just amend the relevant commit and force-push (this will make it easy to see that the diff of that commit got smaller), bit om that case i'll ask for separate force-push per topic, so it'll be easy to click on the word `force` in github and see what was changed)",0,0,0,0.9486433863639832,0.987114667892456,0.9796034693717957,0.0,accept,unanimous_agreement
895177312,9320,"let's add some doc comment for these (specifically the `priv` arg). also, missing blank line above the previous function.",0,0,0,0.9884012937545776,0.9905214309692384,0.9950526356697084,0.0,accept,unanimous_agreement
895178445,9320,"don't we need to also abstract all the listen and accept code? i.e. this way we can replace the openssl based tls dynamically with another implementation, but what happens when we add another medium? i guess to judge this change we need to experiment with a branch that adds rdma on top of this, and see if indeed the only change needed in redis is initializing another entry in the connection type array. did you try this? (the commit comments suggest that maybe you did) p.s. maybe to be really flexible we'll also have to break apart ae.c",0,0,0,0.96071058511734,0.982122838497162,0.983942985534668,0.0,accept,unanimous_agreement
895736581,9320,"because rdma also needs to get local/remote info, but it's not an `anet_peer_name`, so i renamed this into `addr_peer_name`. and yes, using `addr_peer_name`(defined in connection.h) in anet.c is not good enough. as you suggested, what about `bool remote`?",-1,0,0,0.5564969778060913,0.9912130236625672,0.994213879108429,0.0,accept,majority_agreement
895736686,9320,"originally, it was `char ip[inet6_addrstrlen];` and `net_ip_str_len` is defined as 46. it's fine for both ipv4 and ipv6. i leave this as todo for rdma infiniband protocol. and `inet6_addrstrlen` is an anet style definition. what about `#define conn_addr_str_len 46`, and change this when rdma infiniband gets supported?",0,0,0,0.9852015376091005,0.9940617680549622,0.9931126236915588,0.0,accept,unanimous_agreement
895736775,9320,ok. i'll fix this in the next version.,0,0,0,0.9802315831184388,0.9819601774215698,0.9914190769195556,0.0,accept,unanimous_agreement
895736836,9320,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
895749195,9320,"i realized that this chunk of change is a hard work to review, so i decided to split this into 3 steps: - in this version, the tls still works statically, and registering types into an array. - registering connection types into a lookup table with their names(string) and making tls dynamically loadable. - implementing rdma connection type. i'm ok to change plan, using a lookup table in this series is good to me too. please let me know your decision. :d",1,1,1,0.990592896938324,0.986811339855194,0.9948936700820924,1.0,accept,unanimous_agreement
895758935,9320,ok.,0,0,0,0.9735831022262572,0.9740158319473268,0.980760931968689,0.0,accept,unanimous_agreement
895765794,9320,"sure, i'll change this into `reconfigure` in the next version.",0,0,0,0.986520290374756,0.9889686107635498,0.9889752864837646,0.0,accept,unanimous_agreement
895769478,9320,ok.,0,0,0,0.9735831022262572,0.9740158319473268,0.980760931968689,0.0,accept,unanimous_agreement
895774249,9320,ok.,0,0,0,0.9735831022262572,0.9740158319473268,0.980760931968689,0.0,accept,unanimous_agreement
895866235,9320,bool (int) sounds like a good compromise.,0,0,0,0.7980738282203674,0.9520766139030457,0.9517610669136048,0.0,accept,unanimous_agreement
895869423,9320,"ok, how about: ``` #define conn_addr_str_len 128 /* similar to inet6_addrstrlen, hoping to handle other protocols. */",0,0,0,0.9708649516105652,0.9922256469726562,0.9920498728752136,0.0,accept,unanimous_agreement
895886110,9320,"i took this note early in the review, before looking at the plan and commits in the other branch. i agree with your approach of doing it gradually, and i don't mind to keep printing an integer for now. i suppose we can even panic in this specific case. p.s. when we'll go dynamic, we can still use an array (with max of 8 entries), each type will be able to report it's name with a method returning it. i think we may be able to avoid any direct / hard-coded indexing into that array, except for maybe tls for which we can just reserve index 1. other extensions can be added in a way that redis doesn't need to explicitly refer to them (they'll register their own configs, etc), and the only one that will be hard-wired into redis it tls (in order to be backwards compatible with the old configs).",0,0,0,0.8921810388565063,0.6967413425445557,0.5743233561515808,0.0,accept,unanimous_agreement
906761118,9320,"i think we can afford to move these from networking.c to the other files (did i argue the other way around in the past?). i generally try to avoid moving files and disrupting the blame log, but this project is a refactory project, it can come with some cleanup and blame log destruction. i wouldn't want to move acceptcommonhandler, since that one has some logic to reply to clients, and update stats, so it seems more like networking **logic** than platform handling.",0,0,0,0.8701925277709961,0.9781671762466432,0.9643723368644714,0.0,accept,unanimous_agreement
906761922,9320,"i think you may have missed my point, or maybe i didn't explain it well enough. i meant that instead of having hard coded indexes like `#define conn_type_tls 2`, we'll allocate them dynamically, by doing string searching only at startup, and cache the index in a variable. so the indexes are not hard coded, but it's still o(1) to look up an item. i'd like to see just one or two interfaces here that work with strings, so it's easy to make sure they're only used at startup. the majority of the changes in this commit (`use connection name of string`), should probably be reverted.",0,0,0,0.9090007543563844,0.9378756880760192,0.9288024306297302,0.0,accept,unanimous_agreement
906763478,9320,nit: missing space before parenthesis,0,0,0,0.954945743083954,0.825971782207489,0.9548960328102112,0.0,accept,unanimous_agreement
906765173,9320,"let's add some comment what this does. i.e. it works for both tcp and tls, and handles both port and bind address, right? maybe even find a better name for the function to reflect that..",0,0,0,0.9828634858131408,0.9837710857391356,0.987159013748169,0.0,accept,unanimous_agreement
906765503,9320,"i see that in the past, we had a call to `closesocketlisteners` when `listentoport` failed (in `changebindaddr`). please look into that and confirm it's not needed, or add it.",0,0,0,0.9869584441184998,0.994274914264679,0.9934214949607848,0.0,accept,unanimous_agreement
906766001,9320,"i'm afraid that moving these prints to be done earlier (in `initserver`, before loading the persistence data), could have some side effects (if someone's monitoring the log file to know when to connect). i'd rather move that back here.",-1,-1,-1,0.9249846339225768,0.8820748925209045,0.7186770439147949,-1.0,accept,unanimous_agreement
906768616,9320,"maybe it's better to have two separate defines instead of `use_openssl`. i.e. `prepare_for_tls_support` vs `include_tls_support`? if not, then maybe just use 1 and 2 instead of 89 and 69, since comments are needed anyway next to each use. please review the makefile changes.",0,0,0,0.984487235546112,0.9951367974281312,0.993602693080902,0.0,accept,unanimous_agreement
906769292,9320,let's add a check to make sure it is marked as executable (same as is done in `moduleload`,0,0,0,0.988734006881714,0.9909504652023317,0.9951133131980896,0.0,accept,unanimous_agreement
906769536,9320,i think the logging verbosity is too low. let's at least use ll_notice (like we do when loading a module).,0,0,0,0.9373220801353456,0.964553713798523,0.9376057982444764,0.0,accept,unanimous_agreement
906770535,9320,"i'm not sure i like this approach. the one i had in mind is just a `:` separated list of paths, and then let them register configs at runtime, with some mechanism of delayed config applying same as we did in [a link] the other approach could be like we do in the `loadmodule` config directive, which takes an argv array. i.e. each module in one config line, and these can be repeated. if we do that, then config rewrite mechanism becomes complicated, but the bright side is that it's following the footsteps of an existing mechanism (unlike the one currently implemented). wdyt?",0,0,-1,0.5425404906272888,0.6395626068115234,0.5256490111351013,0.0,accept,majority_agreement
906773444,9320,"i hope this move is safe... iiuc nowadays the code in the config file parsing doesn't touch the runtime state, just the config globals (and the apply functions are just being used by config set command, not the config file parsing). so this change seems ok..",1,1,1,0.8695054650306702,0.6351907849311829,0.964263916015625,1.0,accept,unanimous_agreement
906782338,9320,"it's a nice proof of concept, but why would we want to load the unix socket as an extension, or exclude it completely? unlike the tls thing, it doesn't require any heavy dependencies or overheads.. i think i'd like to drop that commit.",1,1,1,0.5987240076065063,0.7605180740356445,0.6065183281898499,1.0,accept,unanimous_agreement
906901085,9320,"from the point of my view, the unix socket is necessary only when we start redis with unixsocket config, we have a chance to implement `load extension on use`, so i did this change. and you are right, unix socket has no dependence, always building into redis is also ok to me. i'll remove this change in the next version.",0,0,0,0.9515058398246764,0.8816739916801453,0.9647241234779358,0.0,accept,unanimous_agreement
906901603,9320,"ok, i'll move `accepttcphandler`/`accepttlshandler`/`acceptunixhandler` to socket.c/tls.c/unix.c.",0,0,0,0.9878743290901184,0.9906993508338928,0.9947599768638612,0.0,accept,unanimous_agreement
906901653,9320,ok.,0,0,0,0.9735831022262572,0.9740158319473268,0.980760931968689,0.0,accept,unanimous_agreement
906901703,9320,ok.,0,0,0,0.9735831022262572,0.9740158319473268,0.980760931968689,0.0,accept,unanimous_agreement
906905234,9320,"in the past, redis changed address for the tcp/tls together in `changebindaddr`, if one failed, close them all: [code block] but now, `changelistener` changes the bind listener for a single one, so we don't have to call `closesocketlisteners`. on the other hand, i did not close tcp listener if tls listener bind fails. [code block] should we close tcp listener if tls bind fails?",0,0,0,0.986985981464386,0.993005871772766,0.9930096864700316,0.0,accept,unanimous_agreement
906905383,9320,ok.,0,0,0,0.9735831022262572,0.9740158319473268,0.980760931968689,0.0,accept,unanimous_agreement
906907010,9320,ok.,0,0,0,0.9735831022262572,0.9740158319473268,0.980760931968689,0.0,accept,unanimous_agreement
906907049,9320,ok.,0,0,0,0.9735831022262572,0.9740158319473268,0.980760931968689,0.0,accept,unanimous_agreement
906911227,9320,"i have an idea to reuse `struct standardconfig`, but i need export this struct and the related functions. for example, the tls extension registers config: [code block] in the future, the rdma extension registers config: [code block] `config set xxx:bind yyyy` changes the listener address, and `config get xxx:bind` returns the listen address. the legacy `bind port tls-port` is still supported. i have a concern that rdma can not listen address during startup, it has to wait command `config set rdma:bind yyyy`. so i also implement this to allow an extension to listen from command line/config file. and searching connection type by string is necessary here.",-1,0,0,0.7307664155960083,0.957241415977478,0.9052543044090272,0.0,accept,majority_agreement
906913653,9320,"let me explain why i use `use_openssl` with different value instead of new flags: the server side and client side share the same compiling flags, `use_openssl` affects both server and client. i realized this and still used `use_openssl` with different value. using 1 and 2 instead of 89 and 69 is fine to me.",0,0,0,0.9033684730529784,0.982705056667328,0.9859187602996826,0.0,accept,unanimous_agreement
906931541,9320,"searching connection type by string (or index) is unlikely code path, it's used only: - create listener at startup, change listener by command - connblockingconnect/connconnect in cluster and replication - tls/unix reuse some method from tcp it affects performance very little. but searching by string can be used a little widely, for example, `config set rdma:bind yyyy`, even `config set tcp:bind yyyy` gets supported in the future.",0,0,0,0.974898099899292,0.9925618767738342,0.991442859172821,0.0,accept,unanimous_agreement
907009835,9320,"i don't think a generic ""*:bind"" and ""*:port"" that's searching for the right extension with a common config property (e.g. port, and bind) is the way to go. i imagine that some extensions will have a few extension specific properties (like tls has for certificates and other features), and i think we better off just expose a way for extensions to register their own configs, same as we do for modules. then, the question remains if we should allow extensions to also take startup arguments that are non-configs from the same line that specifies the dynamic library path. if we do that, then i think we better have one line per extension, and allow the user to specify multiple lines (like we do for `loadmodule`). and then, i also think we should just pass an argv array to the extension (not a key-value pair list), it's arguably more flexible, and also similar to the existing mechanism we have for modules (i don't want too many different approaches coexisting in redis). again, the other alternative is to just take a plain `:` list of paths, forget about load time arguments, and only rely on the config infrastructure that we'll introduce in the next pr.",0,0,0,0.9716411232948304,0.9796363115310668,0.970610499382019,0.0,accept,unanimous_agreement
907014110,9320,"i don't think i follow you. tls is added in two steps: one is to decide if tls support is at all included in the build (when disabled we don't even need the headers installed on the system), and the other one decides if redis-server has it build in, or as a loadable extension. it can be one define with 3 states (0,1,2 / undefined,1,2), or it can be two defines that are either both undefined, both defined, or just one defined. i think the second approach is less confusing since it doesn't rely on the value of the define, and we have clear names. the client side (redis-cli and redis-benchmark) will only be using the first define (which dictates that tls support is at all enabled for the build). maybe elaborate on what you meant by client, in case i'm missing something.",0,0,0,0.9581905007362366,0.9442108273506165,0.906249701976776,0.0,accept,unanimous_agreement
907021243,9320,"responding to the list above. * doing string search on startup or on config change is probably ok. * i'm not sure it's very nice to do that on connconnect (possibly each time a connection drops and has to be re-established) * the generic bind and port configs approach you suggestion is not desired imho as i stated in the other comment (unix has path and no port, lts has many other configs, i think we better rely on a separate list of configs for each extension and not try to come up with a generic one). * for tls and unix to re-use socket functions using string search is probably wrong as can be seen here: [code block] all in all, seeing so many interfaces that take string, scares me, even if we make sure they're all used in reasonable places now, i think it'll be too easy to misuse in the future. i'd rather limit the string search to just one function (maybe with the name ""find"" in it), and have the rest of them take indexes and keep some global variable with a cached index. or better yet, a global variable with a pointer to the object, so in the few places that redis explicitly needs a certain connection class, it uses that variable, and even indexing isn't needed.",0,0,0,0.8635950088500977,0.976296067237854,0.9377531409263612,0.0,accept,unanimous_agreement
907037310,9320,"ok, i see (indeed no need to call closesocketlisteners on the same connlisten that failed (listentoport already does that when it fails). but yes, i do think we need applybind to clean after it in case it failed on a late stage (close the socket listener when the tls listener failed). iirc, this mechanism was was set in place for the later rollback that's attempted. i.e. if you change the port or bind at runtime and the listen fails, it attempts to roll back the actions, and re-bind to the old address / port. p.s. i now notice that when createsocketaccepthandler (in changelistener), in the past we used to fail gracefully, and now we panic. any reason for that?",0,0,0,0.9747548699378968,0.9860377907752992,0.975957989692688,0.0,accept,unanimous_agreement
907127592,9320,"when createsocketaccepthandler (in changelistener), we should fail gracefully instead of panic. i'll correct this.",0,0,0,0.9618013501167296,0.9874256253242492,0.988067626953125,0.0,accept,unanimous_agreement
907157016,9320,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
907180452,9320,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
909575616,9320,"i'm not sure we need this. as long as we don't allow extensions to be added or removed at runtime, i think it's enough that we added it the list where `rename-command` and others were mentioned, and it'll mean that the original line isn't deleted from the config file.",0,0,0,0.9748727083206176,0.9705837965011596,0.9706608057022096,0.0,accept,unanimous_agreement
909681303,9320,"i still feel that there are still way too many interfaces that take a string as a connection type, and i think that all of these should take a `connectiontype*` or index as input. i feel that there should be only two interfaces that take that string, one is the registration (conncreate) and the other is a lookup (connectionbytype) that should be **only** used at startup to cache direct pointers to some types (or by using a singleton method like you did with connectiontypetcp)",0,0,0,0.5029462575912476,0.9224403500556946,0.802559494972229,0.0,accept,unanimous_agreement
910517524,9320,ok. i'll remove this in the next version.,0,0,0,0.9841755032539368,0.9847294688224792,0.993845522403717,0.0,accept,unanimous_agreement
910520288,9320,"ok! by the way, `void conntypecleanup(const char *typename);` is unused now, it's supposed to clean up a single listener, but we clean up all the listeners by `void conntypecleanupall()`. so i'll remove this function in the next version. also introduce connectiontypetls() to get tls connection type fastly.",0,0,0,0.8049076199531555,0.9009252786636353,0.8751737475395203,0.0,accept,unanimous_agreement
912444307,9320,"i still see interfaces that i think i'd like to change / delete. * conncreateaccepted (should take a connection type) * conntypeofcluster (should return a connection type) * conncreate (should take a connection type) * conntypeofreplication (should return a connection type) * conntesttype - delete, if someone needs to use it, it may be an indication that they're doing the wrong thing? * connaccepthandler - same?",0,0,0,0.9453863501548768,0.976353108882904,0.9768192172050476,0.0,accept,unanimous_agreement
912445302,9320,"i'm trying to understand how generic these are and if they indeed need to be part of the interface. i.e. if they can ever serve any other connection type, or just for extensions re-implementing the tls one. same about conntypeconfigure, and obviously conngetpeercert. one other alternative is to explicitly call a tls specific function. i.e. the code that uses all of these is tls specific code, doing something like `conntypegetclientctx(connectiontypetls());` or `conntypeconfigure(connectiontypetls(), &server.tls_ctx_config, 1)`. i'd like your feedback here.",0,0,0,0.9392102360725404,0.9878009557724,0.978813409805298,0.0,accept,unanimous_agreement
912589556,9320,"what about add a new api like `connctrl()` style, and wrapper tls specified function into this?",0,0,0,0.9885895252227784,0.9931871891021729,0.9943998456001282,0.0,accept,unanimous_agreement
912884790,9320,"i don't think exposing the openssl context should be part of the interface, because we have no guarantee that any tls implementation is going to have openssl. if we believe it is required for certain operations, we should probably define a more abstract interface for those. a generic `conngetpeercert` is reasonable. we could insist on differentiating generic from tls connection interfaces and only supporting it in the latter, but i'm not sure if it's worth the trouble - it can remain part of the basic interface and just be left out if not applicable.",0,0,0,0.8895997405052185,0.972630262374878,0.9363253116607666,0.0,accept,unanimous_agreement
913422718,9320,we probably need to document the arguments for each of these somewhere. maybe here is a good place (where we define the interfaces)?,0,0,0,0.9700093865394592,0.9849291443824768,0.9921971559524536,0.0,accept,unanimous_agreement
917351911,9320,"i realized that we probably need to list extensions in the info output, one important reason is that we want them to be present in the crash log. if it were a normal config, we could have used debug_config. so maybe we should have explicitly add it to the crash log, like we do for debug_config, but since we don't have a config get support for that, it's probably better to list them in info, like we do for modules. for modules, we also list them in hello command, and we have a special info section, but for extensions, it's probably enough to just add a single line comma separated field in the ""server"" section of info.",0,0,0,0.9469975829124452,0.9817412495613098,0.9437333345413208,0.0,accept,unanimous_agreement
922986597,9320,"i was thinking of something like this (to show the list of loaded extensions): [code block] i can see how what you did can be useful too, so i'm not sure which one we prefer, or maybe both? but if we do keep it, i think the info field name should be prefixed (i don't think we want the info name to be the plain extension name), e.g: [code block] wdyt?",0,0,0,0.9624692797660828,0.9603192806243896,0.9760137796401978,0.0,accept,unanimous_agreement
923000521,9320,"hi, i also noticed `tcp_port:6379` in the `info server` command. and the code `server.port ? server.port : server.tls_port` means `tcp` has higher priority than `tls`. if we can ignore the backwards capability in this output, this field can be removed too. originally, i was thinking of `extensions:tls,rdma` too, and i found the limitation of `tcp_port:6379`, so i did this version.",0,0,0,0.9681106209754944,0.9915469288825988,0.9846445322036744,0.0,accept,unanimous_agreement
924277081,9320,"hi, is it ok to remove `tcp_port:6379` if adding [code block]",0,0,0,0.9887918829917908,0.9855823516845704,0.9948086738586426,0.0,accept,unanimous_agreement
924422125,9320,"no, i think we need to maintain backwards compatibility. p.s. i did discus this topic with yossi today. he suggested that the info keyword will be index based, could be easier for clients to enumerate on them (like we list slaves and databases). i.e. [code block] i'm also not sure we need the `type=` part, since i do think we need another place that lists extensions, so i suggest to drop it. i.e. in the future we'll have extensions for compression algorithms, or persistence volume access, not just listeners, so extensions should be listed separately, not as part of the listeners list. yossi suggested that the extensions be listed in a section of their own like modules, one extension per line, rather than a single info comma separated field i suggested. but it looks like we didn't come to an agreement yet about whether extensions are a type of module or not, yossi argues that they should be just another type of modules), and in that case we don't need to list them them at all, they'll be listed in the modules section. so i'll ask that you'll wait a few more days until we decide that, but meanwhile you can fix the `listener` info lines as i described above.",0,0,0,0.8541721105575562,0.984036386013031,0.9800307154655457,0.0,accept,unanimous_agreement
933250585,9320,"maybe instead we can let the module detect it's being loaded later than bootup, and it can just abort it's loading (rather than what we have now were we let it complete initialization and then try to destroy it)? i imagine we can easily find a simple way to detect it (without even adding a new api). i can't think of one right now, so the next best thing is to add an rm_getcontextflags that looks if server.loadmodule_queue isn't empty. maybe the same can be said about unload, it can simply return some error from the unload callback? it seems that this is already supported.",0,0,0,0.9742193222045898,0.984016180038452,0.9780178666114808,0.0,accept,unanimous_agreement
933286602,9320,i don't like the fact clusterinit is called form within initlisteners. can we move it to be called immediately after?,-1,-1,-1,0.9788822531700134,0.923454999923706,0.94854474067688,-1.0,accept,unanimous_agreement
934071437,9320,"hi, `module:name=helloworld,ver=1,api=1,filters=0,usedby=[],using=[],options=[bootup-only|deny-unload]` is quite explicit and clear, we can easily know the attribute of the specific module. returning error in `redismodule_onunload` also works fine to refuse to unload a module, but we lose this information. i'm a little confused about testing server.loadmodule_queue, can we distinguish bootup stage from running stage without any module?",0,0,0,0.7199308276176453,0.9244030117988586,0.9130049347877502,0.0,accept,unanimous_agreement
934146430,9320,"that would be wrong. these flags or capabilities should come from the module code, not be provided by the user who loads it. i don't understand what we lose? i meant, for example. to add a flag in rm_getcontextflags, something like redismodule_ctx_flags_deny_loading_on_startup, which rm_getcontextflags will set when server.loadmodule_queue is non empty. then the module (tls in this case), will be able to test this flag in it's `redismodule_onload`, and return an error if it's not set.",0,0,0,0.8598754405975342,0.9106782674789428,0.7576659917831421,0.0,accept,unanimous_agreement
936408783,9320,"the module api [a link] is generated from the comments in this file, so the new field should be documented in the comment above. also, i don't think i like the name. i this is should be negated and mention what it stands for, and not what it's used for. i'd call it before_server_startup, or server_startup_pending or alike. while we're here, and now that sentinel can load modules, i think we need a flag for that too. so that modules that don't wanna be loaded into sentinel can refuse to be loaded. i.e. add redismodule_ctx_flags_sentinel similar to redismodule_ctx_flags_cluster. p.s. these are interface changes that need to be mentioned in the pr top comment for the purpose of review / approval and release notes.",-1,0,0,0.700280487537384,0.9000216722488403,0.8851560354232788,0.0,accept,majority_agreement
936470950,9320,"i think the flag name is negated from what it does (and the comment). i would keep the name and update the comment to say ""didn't finish starting"" or ""performing startup"". and change the code to check a non-empty `loadmodule_queue` (change `== 0` to `> 0`)",0,0,0,0.9882150888442992,0.9902931451797484,0.9905126690864564,0.0,accept,unanimous_agreement
942743502,9320,this feels awkward. why not have a separate tls type here instead of a generic poorly typed control method. these still have to be called from redis. something like: [code block],-1,-1,-1,0.9632190465927124,0.9856905341148376,0.9917452931404114,-1.0,accept,unanimous_agreement
942745977,9320,"i don't think @ is used anywhere in redis for describing arugments. [code block] there is a couple of other places this is set as well, i didn't call them all out though.",0,0,0,0.9789026975631714,0.9802697896957396,0.9871864318847656,0.0,accept,unanimous_agreement
942764017,9320,"why was this moved from anet? seems like the right place, this doesn't seem strictly related to connections.",0,0,0,0.9500336647033693,0.9752618074417114,0.985528528690338,0.0,accept,unanimous_agreement
943029035,9320,"hi, formating ip and port into a string, this is quite common. this can be also used by rdma in the next step. rdma supports rocev2, the address is similar to the ipv4 style.",0,0,0,0.9806533455848694,0.9909920692443848,0.9890214800834656,0.0,accept,unanimous_agreement
943039547,9320,"from this design, we need define something in connection.h: [code block] my concern is: * **struct connectiontype** is a common/base class of every connection type, it should contain the common methods only. * if we need introduce any other connection specific method, we need modify **struct connectiontype**. (ex, struct foocontrol *fooctrl).",0,0,0,0.9796660542488098,0.9943649768829346,0.9900994896888732,0.0,accept,unanimous_agreement
945287609,9320,it was discussed here [a link] and iirc we concluded a generic `control` is better than polluting the interface with tls specific concerns.,0,0,0,0.9824230670928956,0.9836339354515076,0.993629276752472,0.0,accept,unanimous_agreement
945714782,9320,"any reason not to simply return an error here, and panic only if we fail trying to register the built-in types?",0,0,0,0.586682140827179,0.9748045206069946,0.9547513723373412,0.0,accept,unanimous_agreement
945733823,9320,"i think this can be somewhat misleading: it seems as if sentinel actually supports tls modules, but that's not the case - it only supports the openssl based tls module, because it uses `hiredis` for its client side work. i propose these changes: * drop `ctrl_tls_get_ctx` and `ctrl_tls_get_client_ctx`, because they won't be useful with generic modules anyway. * make sentinel support tls only if compiled, not as a module, and then directly access these contexts. i realize tls+sentinel came up before, i should have thought about this bit before...",0,0,0,0.9203192591667176,0.9692827463150024,0.9757847785949708,0.0,accept,unanimous_agreement
945738339,9320,is this change from returning an error to panic really required?,0,0,0,0.8908650279045105,0.9640162587165833,0.947395920753479,0.0,accept,unanimous_agreement
945742786,9320,"i think this is a bit confusing, why not use `--tls` to enable tls tests and `--tls-mod` (or `--tls-module` so it's more obvious) to both enable tls and load the module?",-1,-1,-1,0.6403735280036926,0.6084422469139099,0.6954236030578613,-1.0,accept,unanimous_agreement
945747224,9320,i suggest to use `tls_module` and `build_tls=module` to make it more obvious what `mod` means.,0,0,0,0.9874700903892516,0.993395984172821,0.9932014346122742,0.0,accept,unanimous_agreement
945812367,9320,"so sentinel will support other connection modules, but not tls? it's a bit odd.",-1,-1,-1,0.7859326601028442,0.8983122706413269,0.8861426115036011,-1.0,accept,unanimous_agreement
945841802,9320,"it will support inbound modules on incoming connections only, anyway. so yes, very partial support.",0,0,0,0.9585983753204346,0.8890452980995178,0.971444606781006,0.0,accept,unanimous_agreement
945869078,9320,"ok, just to make things more generic, can't we use that hack of accessing these contexts directly even if tls is loaded as a module? do we need to note somewhere that (other than tls) the connection modules for sentinel only work on incoming connections? or can we skip it? (considering that there are not official connections anyway, and we only need to document tls)",0,0,0,0.9703861474990844,0.98922461271286,0.9882254600524902,0.0,accept,unanimous_agreement
946245346,9320,"connection type is allowed to be loaded during redis startup only, at this stage, reporting unexpected connection types seems obvious. for example, `./src/redis-server --loadmodule src/redis-tls.so --loadmodule src/redis-foo.so` tries to load 2 modules, unfortunately they have the same connection name `tls`, if we don't panic here, we don't know which one is in use.",0,0,0,0.9424825310707092,0.9299622178077698,0.9814141392707824,0.0,accept,unanimous_agreement
946255739,9320,"i followed the original logic: [code block] sorry, i'm not familiar enough with the detailed historical reason, i'd leave this to you to decide ...",-1,-1,-1,0.9873661994934082,0.980983316898346,0.982302188873291,-1.0,accept,unanimous_agreement
946339856,9320,"i think yossi meant that the panic (or rather `exit`), is handled outside. i.e. we'll return an error here, it'll cause the module to fail loading, and then moduleloadfromqueue will fail. it would mean the user doesn't know the reason was a conflicting name, unless we add a log print either here, or in the module when that call returns with an error.",0,0,0,0.9707409143447876,0.9864952564239502,0.986706793308258,0.0,accept,unanimous_agreement
946390559,9320,"so `changebindaddr` (called by `applybind` from config.c) would have panicked. but `changelistenport` (called by `updateport` in config.c) would have just returned an error. generally, on bind failures, i'm guessing the right thing to do is error, and let the config system do a rollback. unlike what we do on startup, in which we should fail and exit (i prefer `exit` rather than `panic`) however, in this case, calling createsocketaccepthandler is not expected to fail (all it does is call aecreatefileevent). p.s. we do have tests for both configs (testing a failed listen at runtime and making sure the server reverts), and these both still pass. i'm not sure what's the best way forward. i'm not certain if such an error would be recoverable, so maybe a panic is right.",0,0,0,0.8930061459541321,0.9742887020111084,0.9576483368873596,0.0,accept,unanimous_agreement
946405567,9320,"currently, we hide all the symbols as static in tls.c, and uplayer calls tls specific apis by connection layer only, should we break this rule? and i think we can rename `enum conncontroltype` to `enum conncontroltls`, and define `enum conncontrolfoo` in the future. what do you think about this?",0,0,0,0.9837278127670288,0.9914945363998412,0.9873842000961304,0.0,accept,unanimous_agreement
946437032,9320,"i guess we can break this rule for sentinel, when linking statically.",0,0,0,0.9866785407066344,0.9669232964515686,0.9855507612228394,0.0,accept,unanimous_agreement
946443541,9320,"so sentinel will support connection modules, but not tls? (so it'll be untested). can't we break that rule for non-static linked tls module as well?",0,0,0,0.9889931082725524,0.9927459359169006,0.9922472238540648,0.0,accept,unanimous_agreement
946487676,9320,"the tls specific apis is not general enough, but the global variable symbol is also not general. currently we can call wrapper apis to get variables instead of linking the variable symbol across source files. should we revert this part?",0,0,0,0.9862918853759766,0.9790171980857848,0.9889400601387024,0.0,accept,unanimous_agreement
948350333,9320,"maybe we can make a hack that works in reverse and it'll still mean tls can be a module, even for sentinel. it looks odd to me that sentinel supports connection modules, but not tls. what if we declare these globals in redis, by default set to null, and have the tls module write into them? if it does work (and i think it should), many of the changes of this commit can be dropped (and the remaining ones squashed into the right place)",-1,0,0,0.6213138699531555,0.7920747399330139,0.9155728816986084,0.0,accept,majority_agreement
948620348,9320,"i don't really agree with the concern of ""polluting the interface"". the connection implementation is still tightly coupled to the core, since we explicitly call the tls functions with specific arguments. if the interface changes, i presume that calling sites would rather have a type mismatch to know something has changed instead of silently ignoring or mishandling it.",-1,0,0,0.5459392070770264,0.603291928768158,0.9182295203208924,0.0,accept,majority_agreement
948625935,9320,hi connection module is allowed only when the building version matches with redis server. this is quite similar to linux kernel&modules.,0,0,0,0.983859360218048,0.9853512048721312,0.9927214980125428,0.0,accept,unanimous_agreement
948627005,9320,this is quite similar to linux kernel&modules. right. so it seems like the added benefit of having verifying type is a good thing?,0,0,0,0.7581596374511719,0.8884891271591187,0.9707489609718324,0.0,accept,unanimous_agreement
948693867,9320,hi could you please give me any hint about this?,0,0,0,0.980624258518219,0.9776005148887634,0.9625260233879088,0.0,accept,unanimous_agreement
948981832,9320,"as it's an internal interface, i'm ok with both ways.",0,0,0,0.9698805212974548,0.8855901956558228,0.9647595286369324,0.0,accept,unanimous_agreement
948984957,9320,"the point is that sentinel uses hiredis, hiredis uses openssl. unless we completely change that so sentinel will use the connection infrastructure, sentinel+tls will still need to be compiled and linked against openssl.",0,0,0,0.9889397025108336,0.993462085723877,0.988789439201355,0.0,accept,unanimous_agreement
948992669,9320,"yes, so it must link against tls anyway, but listening to tls can come from a module. it means it supports the module, but it doesn't remove the dependency of openssl. i still think it's more streamline (we use the module approach everywhere). you think it's misleading? or impossible?",0,0,0,0.9366883635520936,0.920247197151184,0.9661815166473388,0.0,accept,unanimous_agreement
950720192,9320,"i'll also make a point since this is an internal interface, it's an easily reversible decision. the use case i'm imagining is that we wan to change the interface, but only update one of many calling sites. since the compiler isn't validating the interface, we don't see an error and it fails at runtime.",0,0,0,0.9760120511054992,0.9663295149803162,0.9882440567016602,0.0,accept,unanimous_agreement
950834142,9320,"ok, let's go back on this and re-add the specific (type safe) interfaces. iirc it's just 2 interfaces now since the other 2 were converted to a hack using global externs (outside of this interface)",0,0,0,0.9875717163085938,0.9801724553108216,0.9911876916885376,0.0,accept,unanimous_agreement
950840601,9320,"i synced with yossi about this, and here's the summary: * even if sentinel will take tls (for inbound connections) from a module, and keep using hiredis for outbound connections, it'll mean that the tls module has to be an openssl one. i.e. it'll not be able to support an s2n tls module since hiredis would be incompatible with it. * for distros to compile and ship redis with tls as a module (rather than static), won't be beneficial, as long as sentinel is still hard-linked with openssl. * we argue that sentinel can't support connection modules at all (not just tls), since (for now), these only control the inbound connections, but not the outbound (that's currently handled by hiredis). this leaves with two options: 1. when compiling redis with tls as a module, just avoid building sentinel at all (leave sentinel completely unsupported in that build). 2. when compiling redis with tls as a module, build sentinel with only basic tcp support and no tls capability. we choose option [2], which i think is what currently implemented in this pr, with two possible required changes: 1. i see you removed the execution of the sentinel test suite in this mode, but i think we should still execute it, just do that without tls. 2. maybe we should revert some of the changes we did in server.c with regards to allowing sentinel to load modules (that applies to any modules, not just connection modules).",0,0,0,0.8805344700813293,0.9506304264068604,0.8140146136283875,0.0,accept,unanimous_agreement
951289503,9320,i noticed this got reverted,0,-1,0,0.9503169059753418,0.6142182350158691,0.9413694143295288,0.0,accept,majority_agreement
951296028,9320,"i see you added a piece of code to prevent the tls module to be loaded into sentinel, but i was under the impression we agreed that we won't support any module (connection or other modules) in sentinel mode. i.e. revert redismodule_ctx_flags_sentinel and maybe some other changes we made in server.c initialization order. the reason is that currently, any connection module loaded into sentinel will only affect the incoming connections into sentinel, and not the outgoing ones (unlike what we have for cluster and replication), so i think it makes little sense to allow sentinel to load connection modules. do you disagree?",0,0,0,0.9611771106719972,0.9813251495361328,0.9765775799751282,0.0,accept,unanimous_agreement
951326252,9320,"iirc, you mentioned that other subsystems may be built as module too(maybe rio?)... if i misunderstand anything, please correct me, i'll fix this in the next version.",0,0,0,0.979295015335083,0.5377151370048523,0.9688441157341005,0.0,accept,unanimous_agreement
951336241,9320,"i did say that, didn't think of sentinel at the time, in fact afaik it doesn't use rio (doesn't save rdb files) maybe some day we'll want to allow sentinel to load modules (that can add commands etc), but for the moment, the main reason we did that was to allow adding connection modules, and we just realized that's not really gonna work (i.e. it only works on incoming connections, not on outgoing ones). so i think we should revert that change.",0,0,0,0.9611318707466124,0.9723251461982728,0.9808939695358276,0.0,accept,unanimous_agreement
952256594,9320,"i did this change in order to solve the startup race (because we not init the listeners after printing the pid message), but it got broken when you moved the init back to before the ""server initialized"" print. i'll sort it out (move the listeners init back to before the print), and push soon",0,0,0,0.982068121433258,0.9887958765029908,0.9900053143501282,0.0,accept,unanimous_agreement
768056785,9934,"build will fail, if you compile with `build_tls=yes`. need to modify ct_tls as well.",0,0,0,0.9515068531036376,0.9841343760490416,0.982979655265808,0.0,accept,unanimous_agreement
768057743,9934,"imo, the function become too big to follow.",0,-1,-1,0.9219304323196412,0.7855198979377747,0.4980780780315399,-1.0,accept,majority_agreement
768067079,9934,"imo, usually it is not a good practice to use the same variable to specify size of array and then use it as iterator. moreover, i think we can simplify the logic around the maximum of iterations and discard one condition (regarding `iov_max`).",0,0,0,0.9848219752311708,0.9901111721992492,0.9834522604942322,0.0,accept,unanimous_agreement
768071736,9934,"originally, after each reply to client, the caller function, `writetoclient()`, verified whether to send the next reply. now, multiple replies will be sent to client before the caller will have the chance to verify its breaking condition in its`while(clienthaspendingreplies(c))`. i think we should find a way to preserve original breaking condition, at least for this pr.",0,0,0,0.9725050926208496,0.9924672245979308,0.9873958230018616,0.0,accept,unanimous_agreement
768076250,9934,"i think you can discard this condition, for the first iteration, by having a variable that will be initialized before the loop with value of `sentlen = c->sentlen`. and by the end of first loop it will be set to zero. and simply have unconditionally: `iov_base = o->buf + sentlen;`",0,0,0,0.985181450843811,0.991114854812622,0.98652982711792,0.0,accept,unanimous_agreement
768303853,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
768308597,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
768320331,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
768322728,9934,"it seems that this line is redundant, `iovcnt` will be reset to 0 below.",0,0,0,0.9795652627944946,0.9885313510894777,0.9915480017662048,0.0,accept,unanimous_agreement
768324295,9934,this piece of code can be moved into `if (sent_bytes >= 0)` so that the `sent_bytes = 0;` in the above else can also be removed.,0,0,0,0.9885757565498352,0.9950898885726928,0.995287299156189,0.0,accept,unanimous_agreement
768326692,9934,"this line can be moved before `while ((next = listnext(&iter))) {`. while we don't restrict variable definitions to the top of the list, it's cleaner to keep them all together. btw, `listrewind` and `while ((next = listnext(&iter)))` are better placed together.",0,0,0,0.9865199327468872,0.9919785261154176,0.992871105670929,0.0,accept,unanimous_agreement
768327343,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
768327387,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
768327447,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
768327522,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
768329014,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
768339374,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
768343348,9934,"actually, i don't think this is necessary cuz there will be always a non-null node when sent_bytes is not zero.",0,0,0,0.9670619964599608,0.984978973865509,0.9865348935127258,0.0,accept,unanimous_agreement
768714601,9934,it seems these codes can be removed. the following `while (remaining)` contains this condition.,0,0,0,0.9881255626678468,0.9940160512924194,0.9913839101791382,0.0,accept,unanimous_agreement
768719516,9934,"yeah, however, if `sent_bytes` is miscalculated due to a bug, it may cause `listnext` to return null, adding `serverassert` is just to make the bug better exposed.",0,0,0,0.9820600748062134,0.9845148324966432,0.9884243011474608,0.0,accept,unanimous_agreement
768721734,9934,it's for `remaining == 0`.,0,0,0,0.9868205189704896,0.989232897758484,0.9945796728134156,0.0,accept,unanimous_agreement
768726403,9934,"this looks a bit odd, as it recopies all the memory to a new buf.",-1,-1,-1,0.8813117146492004,0.9639900922775269,0.6393115520477295,-1.0,accept,unanimous_agreement
768728921,9934,"yep..., this is more like an implementation of compatibility for tls cuz there is no such a system call of `ssl_writev()`.",0,0,0,0.975804090499878,0.971660017967224,0.9875609278678894,0.0,accept,unanimous_agreement
768778596,9934,please write unconditionally instead: [code block],0,0,0,0.9850422739982604,0.9901633858680724,0.992234468460083,0.0,accept,unanimous_agreement
768780734,9934,i think we should fine tune this condition. please see my opinion above,0,0,0,0.8931934833526611,0.925402283668518,0.9671552777290344,0.0,accept,unanimous_agreement
768853835,9934,"this is the code before i open this pr, why should we change it?",0,0,0,0.9524543285369872,0.9817424416542052,0.9895931482315063,0.0,accept,unanimous_agreement
768957821,9934,talking about `if (listlength(c->reply) > 1) {`. i think we should apply this enhancement only if first two buffers are no bigger than net_max_writes_per_event. please see my explanation below.,0,0,0,0.9829201102256776,0.9888193011283876,0.9944553971290588,0.0,accept,unanimous_agreement
769172318,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
769190740,9934,"if this is done, the performance of tls may be affected, we may need more benchmarking to verify it.",0,0,0,0.9843940138816832,0.9860154390335084,0.9855338335037231,0.0,accept,unanimous_agreement
769192699,9934,"the current implementation for tls increases memory copies but reduces system calls, so i think it's still an uncertain impact, we can have some benchmarks later to check it out.",0,0,0,0.9617089033126832,0.9596325755119324,0.9800671935081482,0.0,accept,unanimous_agreement
769196394,9934,"there is a constraint below, in the `while` loop, which makes sure that we don't gather more than `max_iov_size_per_event` == 8 `clientreplyblock`s whose maximum size is 16kb, thus the amount of bytes being sent is in the range of [0, 8*16=128kb], i think it's done? or you want to reduce `max_iov_size_per_event`, like to 4?",0,0,0,0.9873092770576476,0.9933440685272216,0.9928218722343444,0.0,accept,unanimous_agreement
769759240,9934,"i've tried to optimize this code, and it feels like it works. no need for `if else` anymore. [code block]",0,0,1,0.89555424451828,0.7547499537467957,0.8656724691390991,0.0,accept,majority_agreement
769781139,9934,good job! thank you~,1,1,1,0.9919176697731018,0.995931088924408,0.9973167777061462,1.0,accept,unanimous_agreement
769999328,9934,"in the client list `c->reply` i don't see any limitation over the size of objects . where do you this 16kb limitation? the big profit of this feature is for aggregating small objects. as for the large objects, we need to be careful and preserve previous behaviour. regarding max_iov_size_per_event, i think the opposite, this value is too small and should be bigger, around 256. there are few commands that send multiple small replies that can be aggressively aggregated. for example run command command and hunderds of tiny replies from the server that all can be aggregated into a single write/packet.",0,0,0,0.9382820129394532,0.9235894083976746,0.9345025420188904,0.0,accept,unanimous_agreement
770003044,9934,"we must distinct this feature to small packets, otherwise we risk with stack-overflow here and multiple redundant copies of big chunks such that each time a small portion will be actually sent. if you still not convinced, please set-and-get a key of size 1mb and enter follow the code to get better sense.",0,0,0,0.9848138689994812,0.9759026169776917,0.9821182489395142,0.0,accept,unanimous_agreement
770154878,9934,"[a link] i get the amount of 16kb from `proto_reply_chunk_bytes`, it's the minimum size of a node of reply list, there could be some nodes whose sizes are greater than 16kb, but i still can't find the ""small objects"" you were talking about, i thought you have to fill a node with 16kb before moving to the next one? please inform me if i'm missing something, thanks~",1,1,1,0.7921206951141357,0.7299931645393372,0.9786593317985536,1.0,accept,unanimous_agreement
770174089,9934,"i actually don't like the max_iov_size_per_event limit, because we already have the net_max_writes_per_event limit externally, and doing the same in `_writetoclient` looks too weird.",-1,-1,-1,0.9846151471138,0.9696397185325624,0.987964391708374,-1.0,accept,unanimous_agreement
770266972,9934,"if i get the code right, the reply `'len` can be only few bytes but it will be copied to allocated chunk of memory, no smaller than `proto_reply_chunk_bytes`. but this chunk size is irrelevant to our flow - the written length in the reply buffer is still only `len` (in code: `tail->used = len; `) i agree with you that having another length limitation at `_writetoclient` looks weird. but this way or another we need to limit this feature to aggregating only small replies and avoid try optimizing big ones. i hope you agree with me about this point.",-1,1,-1,0.8851197361946106,0.7866484522819519,0.4490678012371063,-1.0,accept,majority_agreement
770468156,9934,"indeed, and i'm also speculating whether overly large aggregated packets might affect other connections, leading to an overall performance drop. i ran a test, there is a very significant drop in performance. command: [code block] unstable: [code block] with this pr: [code block]",0,0,0,0.9402633905410768,0.961654007434845,0.8857375979423523,0.0,accept,unanimous_agreement
770505491,9934,i also ran a benchmark test but got an exactly opposite result (linux with 8 cores (single-threaded mode) and 32 gb mem): unstable: [code block] use-writev: [code block],0,0,0,0.9490921497344972,0.9931043982505798,0.9923287034034728,0.0,accept,unanimous_agreement
770512220,9934,"do you use macos? m1? i also test on macos, same as you. `writev` on `macos` will bring more performance gains than on linux. the above test results are in ubuntu vm.",0,0,0,0.9822884798049928,0.9867825508117676,0.9940126538276672,0.0,accept,unanimous_agreement
770516620,9934,"no, i ran the benchmark test on my linux server with 8 cores (single-threaded mode) and 32 gb mem.",0,0,0,0.9865016341209412,0.98845773935318,0.9920995235443116,0.0,accept,unanimous_agreement
770518202,9934,"ohh, looks like it's time for me to ditch vm, every time my test results are different from everyone else's. can you also conduct a test?",-1,0,-1,0.6225337982177734,0.6457163691520691,0.7958283424377441,-1.0,accept,majority_agreement
770629327,9934,this is the benchmark results from my another linux server(2 cores and 4gb mem): [code block] unstable: [code block] use-writev: [code block] it should be pointed out that the benchmark results don't seem to be so stabilized each time.,0,0,0,0.9854686856269836,0.9935890436172484,0.9921413660049438,0.0,accept,unanimous_agreement
770887106,9934,"hi, i am running inside container, so don't expect shiny numbers :) in the following scenario the unstable branch gives little better numbers: [code block] since i know that command command is not optimized and reply with many small writes/packets - i expected to see here dramatic improvement: [code block] in case of big packets, the numbers are more or less the same: [code block] please note that performance will be even worse against the pr in case of tls, as we are making there additional copy. we need to fine tune the scenario of small packets while all the rest should preserve original flow.",1,1,1,0.9790812730789183,0.9930663108825684,0.993022918701172,1.0,accept,unanimous_agreement
770924177,9934,"... following review our reply infrastructure, i have an idea that might simplify the solution - can be common to tls and non-tls - and avoid from using writev() (and mocking it for tls). it goes as follows: - (as we want to optimize only for small packets) each allocated clientreplyblock (crb) is usually of `size` much bigger than actually being `used`. - if there is more than 1 reply in the list and there is enough free space in the first object `(header.size-header.used)` to include `next.used`, then [code block] wdyt?",0,0,0,0.9471672177314758,0.9872019290924072,0.9622074365615844,0.0,accept,unanimous_agreement
771060614,9934,"`memcpy(next.buf, header.buf + totallen, next.used)` --> `memcpy(header.buf + totallen, next.buf, next.used)`",0,0,0,0.9840071797370912,0.994404435157776,0.9879269003868104,0.0,accept,unanimous_agreement
771061395,9934,"i fail to see how this new approach is going to work better than `writev()`, after all, it does more memory copies.",-1,0,-1,0.842887282371521,0.5357837677001953,0.6503921151161194,-1.0,accept,majority_agreement
771062836,9934,"any chance that we use `writev()` only when there is a scenario with small packets and as for other cases like big packets and tls, we just fall back to the approach it used to be?",0,0,0,0.9857446551322936,0.9923211932182312,0.9828333258628844,0.0,accept,unanimous_agreement
771085897,9934,"i don't fully understand this, if the length of replies is greater than 1, then the first clientreplyblock will definitely be filled up to clientreplyblock->size, it won't have any free space.",0,0,0,0.8099861741065979,0.8320360779762268,0.6446555256843567,0.0,accept,unanimous_agreement
771100125,9934,"cmd: `memtier_benchmark --hide-histogram --tls --cert=./tests/tls/redis.crt --key=./tests/tls/redis.key --cacert=./tests/tls/ca.crt -n 1000000 -t 1 -c 1` i ran a benchmark on linux and the result seemed to have a different opinion: unstate: [code block] use-writev: [code block] actually, i now tend to think that the fluctuation of bench results between unstable and use-writev is intermittent other than `command`.",0,0,0,0.7196550965309143,0.9741186499595642,0.9884005784988404,0.0,accept,unanimous_agreement
771129193,9934,"i use `memtier` to test `command`, and the results were the opposite of , which is weird. unstable [code block] use-writev [code block]",-1,-1,-1,0.9701520800590516,0.9923256635665894,0.9869410395622252,-1.0,accept,unanimous_agreement
771136846,9934,"i think you misread his data, actually, your result is consistent with his, `use-writev` is way faster than `unstable` with `command`, the main disagreement here is a concern that `writev()` may have a negative impact on the performance of other redis commands, but according to my experiences, running benchmark test between `unstable` and `use-writev` didn't always get the stable results: sometimes `use-writev` is better, sometimes `unstable` is better..., therefore i tend to think that's due to other factors and `writev()` is ok to go.",-1,0,0,0.6188303232192993,0.9356899261474608,0.7529126405715942,0.0,accept,majority_agreement
771325969,9934,"i ran a test with `command` and `get` and `set` together, and it seems that even with both big and small packets, the small packet gives a performance improvement, after all, `command` shows a 3x performance improvement. unstable [code block] pr [code block]",0,0,0,0.9694514274597168,0.9914535284042358,0.9846577048301696,0.0,accept,unanimous_agreement
771476246,9934,did you get this benchmark results from linux or macos?with or without tls?,0,0,0,0.9886838793754578,0.9933393597602844,0.9936793446540833,0.0,accept,unanimous_agreement
771483327,9934,i have only tested ubuntu without tls.,0,0,0,0.9776428937911988,0.9864679574966432,0.9902172088623048,0.0,accept,unanimous_agreement
771488733,9934,i think we need a more comprehensive test. * different packet sizes 1. small packet 2. large packet 3. small packet and large packet mix * enable or disable io-threads * with or without tls.,0,0,0,0.981744110584259,0.983270823955536,0.982737362384796,0.0,accept,unanimous_agreement
771493726,9934,"yes, there is still a lot to do back there, i will try to accomplish more benchmarks during the weekend, thank you guys for all the efforts here, i really appreciate it.",1,1,1,0.9877101182937622,0.9945541620254515,0.9856356382369996,1.0,accept,unanimous_agreement
771905323,9934,", following reviewing the code, we can further optimize the code by involve the most often used buffer in writev as well, which is client's static buffer. (i.e. , the client has a static buffer that being reused, before attempting to malloc new buffers) one note about performance, since time measurements might be rather inconclusive when it reaches big buffers or optimized commands, alternative approach can simply to count system-calls with `strace`. attaching pid and trace write() sys-call: `strace -e trace=write -p 1234`. or get statistics per syscall type ` strace -c -p 1234`.",0,0,0,0.9751958250999452,0.992384672164917,0.9813267588615416,0.0,accept,unanimous_agreement
771934134,9934,you mean add `client->buf` into iovec for `writev()`?,0,0,0,0.988336145877838,0.9952783584594728,0.9942122101783752,0.0,accept,unanimous_agreement
771935475,9934,yes. i still think that this feature is effective only for small buffers alone. in case of big buffers there are much more considerations that we need to take into account.,0,0,0,0.96309894323349,0.973077356815338,0.961275041103363,0.0,accept,unanimous_agreement
771963626,9934,"please check out the latest commit which includes static buffer in the buffer queue of `writev()`, and we may want to do some new benchmark tests.",0,0,0,0.9884573817253112,0.9937241673469543,0.9944431185722352,0.0,accept,unanimous_agreement
771971530,9934,"- i don't think we need `nbuf`. we can use `iov_max` (it is only 1024 entries and allocated on stack). - if you agree with previous claim, then we can replace the two conditions with single `if(c->bufpos > 0)` - since the static buffer is rather small ~16kb, kernel has no problem write it in one sys-call, and much more (i tested multiple 1mbs and all written in one sys-call). note that current implementation won't attach it to a big reply buffer that follows. - regarding tls, since it is not optimized, i think we better avoid writev() - based on last two arguments, maybe we can writev something like that: [code block] thank you",0,0,0,0.9624000787734984,0.9861836433410645,0.9762272834777832,0.0,accept,unanimous_agreement
771976340,9934,"we can use `iov_max` as the length of `iov`, but i don't think we can simply rely on `if (c->bufpos > 0)` to decide whether to use `writev()` cuz the reply list may still have multiple nodes even if the static buffer is empty.",0,0,0,0.98894602060318,0.9920897483825684,0.9914421439170836,0.0,accept,unanimous_agreement
771983255,9934,"i wrote it above implicitly... since the static buffer is rather small, in the common case it will be written entirely, together with the reply buffer that follows. that is, i tried to simplified the condition, assuming that this optimization has little effect over big buffers.",0,0,0,0.9735317826271056,0.9838851690292358,0.9893457293510436,0.0,accept,unanimous_agreement
772315945,9934,"i think this judgment is right. the only possible edge condition is bufpos==0, and reply length is 1, which is actually enough to use `write`, but it feels like it makes the code more complicated. btw, i actually don't like `== conn_type_socket`, but i feel like we can avoid it.",0,0,1,0.7737711668014526,0.8886581659317017,0.548109233379364,0.0,accept,majority_agreement
772371956,9934,so we should move the current implementation to a new function called `writemultibuftosocket()` and restore the old code of `_writetoclient()`?,0,0,0,0.9892706871032716,0.9950581789016724,0.99418044090271,0.0,accept,unanimous_agreement
772378026,9934,"perhaps we can verify that tls also delivers performance gains before deciding whether to revert to the old code. i'm inclined to add the `writemultibuftosocket` method, the code is getting too big now.",0,0,0,0.684576153755188,0.8478562235832214,0.9856296181678772,0.0,accept,unanimous_agreement
772399923,9934,"for a start, hope you agree with me that current implementation of `ct_tls::writev()` is not adequate for big buffers and we must avoid memcpy. one way to achieve common interface, is to modify `ct_tls::writev()` to decide whether to use `writev()` or multiple `write()`s based on some threshold. imo, if we have 16kb static buffer and 1mb reply buffer - for `ct_socket`, will be a single sys-call of `writev()` for both buffers (currently imp of `_writetoclient()` won't do it) . - for `ct_tls`, will have two write()s (rather than memcpy and single sys-call writev().) if we have two buffers of size 1mb, then - for `ct_socket`, i think we better see two distinct `write()` - preserve previous behavior , unless we goanna put an effort to test performance (i don't think it is an interesting case to challenge and put an effort.) - for `ct_tls`, will have two write()s",1,0,0,0.5413913726806641,0.9515161514282228,0.7374001741409302,0.0,accept,majority_agreement
772833521,9934,"i benchmarked again in the morning, and i agree with that writev's merging of large packets does not result in a significant performance gain(or it won't bring as significant a performance gain as merging smaller packets). my test steps. 1. create a string key of 1m 2. use `redis-benchmark -p 100 -n 10000 get key` to test so that each clientreplyblock ~1m, and c->reply length is 100",0,0,0,0.960867404937744,0.9658032655715942,0.9782614707946776,0.0,accept,unanimous_agreement
772902919,9934,"well, i guess i can set up a new function and move the new code into it, then restore the _writetoclient(), but i am concerned that there'll be duplicate code.",-1,0,-1,0.8436746597290039,0.964085578918457,0.8365378975868225,-1.0,accept,majority_agreement
797644998,9934,"do we have some upper bound of the size for this allocation? what if the user have 500mb key? i suggest to either drop this optimization completely for tls, and just make a look that calls conntlswrite, or have a fallback mechanism, in which we try to count the total length and abort the count if we find more than 32k or so. so if there are many small items, we copy them to the stack and use one conntlswrite call. but if there are big objects, we stop the count (avoid a long extra loop), and just callback to multiple conntlswrite calls.",0,0,0,0.980232000350952,0.9652318358421326,0.9892008304595948,0.0,accept,unanimous_agreement
797713467,9934,please add a line or two of comments in each `if` and `else` block to describe it's role and actions.,0,0,0,0.9871500730514526,0.9925745725631714,0.9938353300094604,0.0,accept,unanimous_agreement
797727122,9934,"i'm not sure we need this `else`. i understand that maybe in the case that all we have is the static buffer, we prefer to use `write` and not `writev` (it's maybe a very common case of people sending simple set/get commands without pipeline). but as soon as we have a reply list, i don't think i mind always using `writev`, even if the reply list is just one node.",0,0,0,0.9002187848091125,0.9692553877830504,0.9648913145065308,0.0,accept,unanimous_agreement
797741999,9934,"if we hit an empty node, i suppose we need to be sure to zero `offset` before skipping to the next. this is probbly not a realistic scenario, but still feels right.",0,0,0,0.8318028450012207,0.9539477229118348,0.9733038544654846,0.0,accept,unanimous_agreement
797744501,9934,"i don't know where you saw that buffer being refereed as ""successive"", iirc it is called ""static reply buffer"" [code block]",0,0,0,0.9838575720787048,0.965498685836792,0.9908389449119568,0.0,accept,unanimous_agreement
797749442,9934,"i think it'll be cleaner to re-compute the data we had in that buffer, rather than rely on `iov[0]`",0,0,0,0.9840635061264038,0.989087700843811,0.9754882454872132,0.0,accept,unanimous_agreement
797764918,9934,"when we've written more than the contents of just one buffer, we're now over incrementing `sentlen` (i.e. `remaining` represents data from several buffers). i rather fix that, and then the `if` below doesn't need to use `>=`, just `==`. or am i missing anything?",0,0,0,0.9825837016105652,0.9841243624687196,0.9898664951324464,0.0,accept,unanimous_agreement
797769435,9934,"if we didn't write the full buffer, don't we need to break out? isn't doing `remaining -=` on the entire size of `iov[0].iov_len` too much?",0,0,0,0.927241861820221,0.98311585187912,0.9889910221099854,0.0,accept,unanimous_agreement
798187545,9934,"there is a limitation in `_writetoclient`, it makes sure that the total amount of bytes to send won't be greater than `net_max_writes_per_event`== 64kb.",0,0,0,0.9870734214782716,0.9877959489822388,0.9947971701622008,0.0,accept,unanimous_agreement
798198990,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
798201539,9934,"yes, then `remaining` is less than 0, and it will skip the below `while (remaining > 0)`, which is the same effect as breaking out.",0,0,0,0.9793518781661988,0.990670919418335,0.9918729662895204,0.0,accept,unanimous_agreement
798202839,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
798204500,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
798232792,9934,removed.,0,0,0,0.9311882257461548,0.9782117605209352,0.9612457156181335,0.0,accept,unanimous_agreement
798233599,9934,i think you might want to take a look here.,0,0,0,0.9796327352523804,0.9660874605178832,0.9660910367965698,0.0,accept,unanimous_agreement
798274635,9934,"ok, but the limitation and the allocation are in two different functions. or worse, this is a generic infrastructure, it can't assume anything about how it'll be used. i.d like to implement the fallback mechanism i described, you can set the threshold to 64k so that it'll never actually run, but then it could mean we have a bunch of untested code. p.s. looking at _writetoclient, it doesn't actually grantee anything about the size, since what it does is stop adding more nodes when you passed the 64kb limit, but it does that only after we passed it. so if we have two linked list nodes, one of 1kb, and the other of 20mb, it'l queue both. or am i missing something?",0,0,0,0.9444311857223512,0.7991484999656677,0.9071958661079408,0.0,accept,unanimous_agreement
798291698,9934,aren't we now missing the update of `c->sentlen` in case we didn't send the full thing (an `else` for the above `if`?),0,0,0,0.9875426292419434,0.9953176975250244,0.991916000843048,0.0,accept,unanimous_agreement
798317745,9934,"i'm not certain what to look at here. please try to sum up the pending things. i see two things in that discussion. 1. discussion around the maximum size that can be written using writev. 2. benchmark results, which may no longer be relevant, since i understand the static buffer wasn't part of writev when these benchmarks were run. regarding the maximum size, is the discussion around fairness or performance? from fairness point of view, i think the old code wasn't really fair anyway, it attempted to avoid writing more buffers into the socket if it passed net_max_writes_per_event, but if a single buffer contained 500mb, it didn't avoid trying to write as much as the socket could take. regarding performance, i'm not sure what there is to lose here, i didn't look into the kernels' implementation of writev, but if i assume it is as efficient, and avoids copying data, then all we need to do is: 1. avoid copying data on our side, i don't see any copy on our side apart from the code in tls, which i think could be improved to only do that for a successive list of very short buffers. 2. if there are are series of large buffers, maybe we can avoid using writev, but i'm not sure it matters. 3. for the common case of only static buffer, after my review, we keep using the old code, that's a very common case. please let me know which parts of this long discussion are still pending and what would you like me to respond to.",0,0,0,0.8288750052452087,0.8458393216133118,0.7509575486183167,0.0,accept,unanimous_agreement
798322991,9934,"delete it in the latest commit by accident, added back.",0,0,0,0.9742388725280762,0.983940601348877,0.985398769378662,0.0,accept,unanimous_agreement
798328283,9934,"make sense, i will make a new approach based on your idea.",0,0,0,0.9468650817871094,0.9644144177436828,0.9728517532348632,0.0,accept,unanimous_agreement
798407513,9934,"please add some comments before each block of code. what it does, and in this case, also why..",0,0,0,0.9779712557792664,0.9894017577171326,0.9924450516700744,0.0,accept,unanimous_agreement
798514115,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
798656824,9934,perhaps can add an assert. [code block],0,0,0,0.9891637563705444,0.9932965636253356,0.9942169189453124,0.0,accept,unanimous_agreement
801313526,9934,"is it necessary? from my point of view, `offset` will always be equal to cum cuz they are both the accumulation of iov lengths.",0,0,0,0.9846653342247008,0.9926766157150269,0.982913076877594,0.0,accept,unanimous_agreement
801547037,9934,"we're currently using the `ssl_mode_enable_partial_write` and `ssl_mode_accept_moving_write_buffer` flags with openssl to preserve `write()` compatibility, so i'm not sure there's real value in doing any kind of aggregation that openssl would do itself.",0,0,0,0.969772219657898,0.981550931930542,0.9444498419761658,0.0,accept,unanimous_agreement
802302265,9934,"so you suggest to chuck everything after that `if`, and let `conntlswritev` just do repeated calls to `conntlswrite`? do you think there's a point to try to benchmark this?",0,0,0,0.9853690266609192,0.990403175354004,0.9888291954994202,0.0,accept,unanimous_agreement
802334990,9934,"yes, i don't think we should add this mechanism without benchmarking and proving that there's real benefit in doing that. in theory it could be even counter productive, and it's possible that we'd get better results by tuning openssl or using in it a different way (e.g. avoid those two mentioned flags when we have unmovable buffers and don't need `write()` compatibility).",0,0,0,0.9773275852203368,0.9761217832565308,0.9660404324531556,0.0,accept,unanimous_agreement
806625329,9934,looks like the current code is able to give 10% improvement for in tls (for command that heavily depends on deferred replies) [a link],0,0,0,0.9814729690551758,0.9792449474334716,0.9605906009674072,0.0,accept,unanimous_agreement
806672716,9934,sorry to nag about it again :) but to me the function become too big to follow. please move the code in this if to another static function.,-1,-1,1,0.8947731852531433,0.991051197052002,0.9692967534065248,-1.0,accept,majority_agreement
806676281,9934,please add a comment above the function,0,0,0,0.9857916831970216,0.9890732169151306,0.9955767393112184,0.0,accept,unanimous_agreement
806904682,9934,"`iovc_len` is more like the length of the iovec instead of the length of bytes, don't you think?",0,0,0,0.9838294386863708,0.9918360114097596,0.9830935001373292,0.0,accept,unanimous_agreement
806904984,9934,ditto,0,0,0,0.8428916931152344,0.9222367405891418,0.9754701256752014,0.0,accept,unanimous_agreement
806912715,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
806921315,9934,you are right. maybe `iov_len_sum`?,0,0,0,0.958541750907898,0.9838142395019532,0.989165723323822,0.0,accept,unanimous_agreement
806927063,9934,"what i have in mind is `iov_bytes_len`, is that good to you?",0,0,0,0.8110098242759705,0.9606300592422484,0.9922468662261964,0.0,accept,unanimous_agreement
806930045,9934,sound good. thanks.,1,1,1,0.9518107771873474,0.987584948539734,0.9881592988967896,1.0,accept,unanimous_agreement
806934159,9934,"please note that from hereafter the variable play a different role. to make it more readable, better to allocate new one (optimized by compiler).",0,0,0,0.9854552745819092,0.9890182018280028,0.9919895529747008,0.0,accept,unanimous_agreement
806940949,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
806941235,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
806980210,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
807592443,9934,"sorry if i wasn't clear enough. `iov_bytes_len` represent the total amount of data referenced in iov[]. in this block section we would like to use a distinct variable than `iov_bytes_len` which represents the the total amount of data that actually sent. please use another name, maybe `iov_bytes_sent` or alike.",-1,-1,-1,0.9869330525398254,0.977799355983734,0.9666776061058044,-1.0,accept,unanimous_agreement
807597724,9934,"please mark function as static (... i know that several functions in this file could have use `static`, and yet.)",0,0,0,0.9861857295036316,0.9880744814872742,0.9908995628356934,0.0,accept,unanimous_agreement
807618122,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
807618202,9934,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
665354516,9202,typo? [code block],0,0,0,0.988338589668274,0.9923266768455504,0.9931395649909972,0.0,accept,unanimous_agreement
665366349,9202,"i also think like viktor, i think the docs need to move to the c file.",0,0,0,0.9734528064727784,0.9670057892799376,0.985371232032776,0.0,accept,unanimous_agreement
665396600,9202,"maybe you wanna add `bignum` and `verbatim`, i.e. `(` and `=` and maybe `attributes` and `push` some day.",0,0,0,0.9879576563835144,0.9944624304771424,0.9881929755210876,0.0,accept,unanimous_agreement
665398657,9202,"at some point, get rid of line comments `//`",0,0,0,0.9779746532440186,0.9910815954208374,0.9913864135742188,0.0,accept,unanimous_agreement
665400256,9202,"i think that's called a ""null"" response, not an ""empty bulk""",0,0,0,0.9841320514678956,0.9843825697898864,0.9833176136016846,0.0,accept,unanimous_agreement
665417429,9202,"i think that one was called ""null array"" (empty is when len == 0)",0,0,0,0.9880073070526124,0.99018794298172,0.989271640777588,0.0,accept,unanimous_agreement
665442527,9202,maybe `3` should stand for resp3? like `!` it's easier to notice it's not related to the format of the arguments. i wish `a` and `r` would not be letters either..,0,0,0,0.9305161833763124,0.9755894541740416,0.9641425609588624,0.0,accept,unanimous_agreement
665455089,9202,"you're adding new module apis, let's list them in the top comment.",0,0,0,0.9867790937423706,0.9848628640174866,0.9947913885116576,0.0,accept,unanimous_agreement
665458871,9202,"if we add the other types (bignum, verbatim), we'll want to add them to the module api too..",0,0,0,0.9868680238723756,0.9921369552612304,0.9946107864379884,0.0,accept,unanimous_agreement
665464735,9202,"in resp2 mode, the old code would have kept representing sets and maps as arrays. 1. where is this handled in the new code? 2. do we have test coverage for this, if not, let's add.",0,0,0,0.9881873726844788,0.9936637878417968,0.9940178394317628,0.0,accept,unanimous_agreement
666060794,9202,"this is a good point, but i do not think this is even possible, if resp2 is set on the client then the reply will be written as resp2 from the first place. am i missing something?",0,0,1,0.839881420135498,0.6491285562515259,0.5345802903175354,0.0,accept,majority_agreement
666061805,9202,we still need to distinguish between this and resp3 null ('_'). how about null_bulk?,0,0,0,0.9874492883682252,0.9918587803840636,0.99381023645401,0.0,accept,unanimous_agreement
666062132,9202,"yep, will change it",0,0,0,0.9801599979400636,0.845012903213501,0.9735442399978638,0.0,accept,unanimous_agreement
666063691,9202,"good point, it was not supported by the current lua parser.",0,1,1,0.6807542443275452,0.8287606239318848,0.8983887434005737,1.0,accept,majority_agreement
666079847,9202,"maybe you're missing `redis.setresp()`? i.e the lua script is the one who controls the response it gets from the lua_client, not the real client that executed lua.",0,0,0,0.9849178194999696,0.994454562664032,0.9868723154067992,0.0,accept,unanimous_agreement
666080613,9202,"sure, `null_bulk` is ok. just didn't think that ""empty"" is good because it can be confused with an array of size 0",0,0,0,0.9744543433189392,0.952491283416748,0.966630518436432,0.0,accept,unanimous_agreement
666087178,9202,"i prefer ""array"" and ""string"" instead of ""bulk"" and ""multi bulk"", but maybe it's just my personal preference. consistency is more important anyway. the page [a link] calls them ""bulk string"" and ""array"" and the null variants are ""null bulk string"" and ""null array"". (multi bulk is even misleading, since it's an array of any element type, not only of bulk strings.)",0,0,0,0.9381914734840392,0.9711167216300964,0.9723365306854248,0.0,accept,unanimous_agreement
666124318,9202,"conclusion of discussion with `redis.setresp` is setting the protocol on the lua client (`server.lua_client->resp`). this means that if the user performs `redis.setresp(2)` (or uses it by default), when a command will be executed using `redis.call` it will be written to the lua client buffer as resp2. this means that checking the protocol number of the client when parsing is redundant.",0,0,0,0.9884958267211914,0.9954771399497986,0.9923740029335022,0.0,accept,unanimous_agreement
667453762,9202,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
667453783,9202,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
667453802,9202,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
667454266,9202,"i added `verbatim` and `bignum`, do you want me to add also `attributes` on this pr? regarding `push` not sure it's relevant for lua and modules but i agree the parser needs to handle it, should i add it to the parser on this pr?",0,0,0,0.986603856086731,0.9920639395713806,0.991521954536438,0.0,accept,unanimous_agreement
667454278,9202,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
667454416,9202,ended up with: 1. null_bulk_string 2. null_array let me know if you think its ok,0,0,0,0.9849112033843994,0.980985701084137,0.975978136062622,0.0,accept,unanimous_agreement
667454427,9202,see comment above,0,0,0,0.981052577495575,0.9702662825584412,0.9929077625274658,0.0,accept,unanimous_agreement
667454446,9202,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
667454486,9202,will do once i will update the top comment,0,0,0,0.9856581091880798,0.9749438762664796,0.992803990840912,0.0,accept,unanimous_agreement
667454504,9202,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
667468048,9202,"bignum and attributes are currently totally missing from redis, so adding them is maybe not a must. although maybe the first to use them will be modules (who may have more rapid development schedule or cutting edge), so it's good to have them. regarding push, that one is already in use in redis, it is currently quite complicated to find a way for modules to generate them (they need to write into other client's output buffer at the right time, not just reply to the current one). but the parsing part is quite simple, so yet, let's handle it in this pr (and list in the top comment).",0,0,0,0.5550407767295837,0.9126275777816772,0.7681818008422852,0.0,accept,unanimous_agreement
667959480,9202,"considering attributes are inherently a map, maybe it's sufficient to document that, and let the caller use the map api? same goes for the callreply interface.",0,0,0,0.9879646301269532,0.991879105567932,0.9916993379592896,0.0,accept,unanimous_agreement
667960385,9202,can we improve the test so that the script actually looks at the attributes?,0,0,0,0.9868608117103576,0.9884312152862548,0.993871569633484,0.0,accept,unanimous_agreement
667965748,9202,what if one day we will want to change implementation for attributes?,0,0,0,0.9778462052345276,0.9811710119247437,0.9799879789352416,0.0,accept,unanimous_agreement
667967102,9202,"as mentioned on top comments, attributes are not expose to the script and i leave it to another pr after we decide how to expose them. this is just check the parser handles them and scripting.c jusy ignores then...",0,0,0,0.9627426862716676,0.9550225734710692,0.9943515062332152,0.0,accept,unanimous_agreement
667969836,9202,"the spec documents that they're a map so that's not gonna change. i suppose we'll still be able to add some flag in the reply object to denote that it's an attribute map, and we'll still be able to write different logic to handle them inside the same api. this is just an idea, i suppose unifying them can even confuse people (until the notice the documentation that explains it). if you don't feel it's good, we can drop it.",0,0,0,0.9561008214950562,0.9147061109542848,0.872039258480072,0.0,accept,unanimous_agreement
667971030,9202,"ohh, right.. well, i suppose it's a good idea to also leave a comment in the code (maybe both in the test and in the implementation)",0,0,0,0.662784218788147,0.8435250520706177,0.966559112071991,0.0,accept,unanimous_agreement
667987000,9202,"we can call `addreplyproto` and save the extra mallc,free,memcpy [code block]",0,0,0,0.9862346053123474,0.9932745695114136,0.9954019784927368,0.0,accept,unanimous_agreement
667989839,9202,i'd rather not waste so many lines on that nonsense. [code block],0,-1,-1,0.6941149234771729,0.6900102496147156,0.984031856060028,-1.0,accept,majority_agreement
667991422,9202,this needs to be documented in the top comment of `rm_call` too,0,0,0,0.9888660311698914,0.994664430618286,0.9952925443649292,0.0,accept,unanimous_agreement
667991924,9202,let's change the code in debug protocol to use it. and let's extend redis-cli too,0,0,0,0.9852859377861024,0.9928857684135436,0.9949488639831544,0.0,accept,unanimous_agreement
667993496,9202,"i hate lines 8-) i see this file has too many spacing. some with double space, and some with excessive single space. imho space is needed so that you separate two groups each consisting of multiple lines. please go over this file and consider removing some... [code block]",-1,-1,-1,0.4894771873950958,0.9914900660514832,0.9919548630714417,-1.0,accept,unanimous_agreement
667997365,9202,"maybe we need a way to propagate some error in case strtod fails, or the string is too long?",0,0,0,0.9671558737754822,0.9812798500061036,0.9764463901519777,0.0,accept,unanimous_agreement
668000766,9202,"maybe we should have just one api, that returns the verbatim string as return value and the format in an output argument? same maybe applies for map and attributes key+value. i.e one api with two return values. wdyt?",0,0,0,0.9866241216659546,0.9889823794364928,0.986729621887207,0.0,accept,unanimous_agreement
668003443,9202,"maybe we wanna repeat some of these tests in resp2 mode, so that we have coverage of that translation? same goes for the module resp tests..",0,0,0,0.9856088757514954,0.9933599829673768,0.9885762333869934,0.0,accept,unanimous_agreement
668019438,9202,i think i added it,0,0,0,0.9803935289382936,0.8821854591369629,0.990546941757202,0.0,accept,unanimous_agreement
668021389,9202,"the idea in this parser is that it does not need to handle replies error as it parse replies generated by redis, this allowes it to be faster. you think we should handle errors anyway? (we will probably lose performance)",0,0,0,0.9407113194465636,0.9872263073921204,0.9554583430290222,0.0,accept,unanimous_agreement
668023462,9202,"i actually think that split them is better, but i will not insist, let me know if you want me to join them...",0,0,0,0.8546584844589233,0.7520024180412292,0.8086509108543396,0.0,accept,unanimous_agreement
668035556,9202,"i did not, added it to `modulecreateargvfromuserformat`, will add it to rm_call as well ...",0,0,0,0.9858435988426208,0.9921051263809204,0.99561607837677,0.0,accept,unanimous_agreement
668107595,9202,", it requires updating the hiredis, seems like our current version do not have it: [a link] while on hiredis master it exists: [a link] do you want to do it on this pr or on another pr?",0,0,0,0.9768474102020264,0.9884831309318542,0.9932684302330016,0.0,accept,unanimous_agreement
668110030,9202,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
668110109,9202,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
668110291,9202,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
668110418,9202,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
668111194,9202,will add another commit which will remove empty lines,0,0,0,0.987133264541626,0.9856829047203064,0.9945492148399352,0.0,accept,unanimous_agreement
668117421,9202,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
668127279,9202,only rm_ functions get their docs exported by the script...,0,0,0,0.983519732952118,0.9932788014411926,0.9947920441627502,0.0,accept,unanimous_agreement
668129629,9202,let's do it in another pr. need to look at the last pr that updated hiredis and see the methodology (git subtree) and also chose the right hiredis version,0,0,0,0.9772455096244812,0.9923230409622192,0.9945969581604004,0.0,accept,unanimous_agreement
668130512,9202,"i'm not sure. if the previous ones didn't handle it, and it's an api that's internal to redis (we are free to change it when we like), then we can skip that now",0,0,0,0.9554656147956848,0.8282472491264343,0.7938550710678101,0.0,accept,unanimous_agreement
668132985,9202,"the previous ones didn't handle it, and its also clearly stated on the lua parser today: [a link]",0,0,0,0.9848238229751588,0.9871292114257812,0.9942288398742676,0.0,accept,unanimous_agreement
668171197,9202,"came here to change `give` to `given`, but ended up changing the wording. you can choose otherwise. [code block]",0,0,0,0.987710416316986,0.992909848690033,0.9950172305107116,0.0,accept,unanimous_agreement
668177387,9202,"i see you added a loop for the lua tests, can we easily add something for the module tests? e.g. it'll test that attributes are skipped for resp2",0,0,0,0.9815046191215516,0.993650496006012,0.9914626479148864,0.0,accept,unanimous_agreement
668199551,9202,"rethinking about it, i am not sure what we are testing here. we say that if resp2 is used then the reply does not even contain resp3 (map, set, double, ...). so do we want to test resp2 parsing (arrays, strings, numbers, ...), i believe this is pretty cover already no?",-1,0,0,0.5054442882537842,0.7950956225395203,0.8991186618804932,0.0,accept,majority_agreement
668653774,9202,you now have two replies in these functions. that's bad...,-1,-1,-1,0.9888161420822144,0.9932792782783508,0.9957706332206726,-1.0,accept,unanimous_agreement
668656737,9202,but the first one verifies that it returns an error and sends nothing... if it succeed the test will fail,0,0,0,0.7592481374740601,0.6949988007545471,0.9913191199302672,0.0,accept,unanimous_agreement
668658801,9202,"are verbatim formats always null terminated strings? or we need to pass length with that char pointer? i see that in the spec they don't have a specified length (like bulks), and we find them by looking for : separator. i guess that means that they're expected to be text, and not binary data, and in that case they're not expected to have null in the middle. do you agree?",0,0,0,0.9833877086639404,0.979141652584076,0.982883632183075,0.0,accept,unanimous_agreement
668663133,9202,"the string itself does get a len output argument. regarding the format, the spec specifies that it's always 3 chars so i thought it's not needed to give a length. [a link]",0,0,0,0.987588346004486,0.9903627038002014,0.9946306943893432,0.0,accept,unanimous_agreement
668726838,9202,"somewhere, salvatore had a long post about resp3 being upper case and not a version thing (not resp v3) [code block]",0,0,0,0.9847285151481628,0.940078616142273,0.9895690083503724,0.0,accept,unanimous_agreement
668728278,9202,missing documentation in the c file,0,0,0,0.8189437389373779,0.9905099272727966,0.9867217540740968,0.0,accept,unanimous_agreement
669135035,9202,"should this return c_err otherwise? i would expect that to be corruption. i just saw yossi's comment, you can fix it later.",0,0,0,0.9785850048065186,0.9806631207466124,0.984536588191986,0.0,accept,unanimous_agreement
669564476,9202,"please try to follow redis code style, i.e. `callreply *callreply` etc.",0,0,0,0.9881960153579712,0.9946902990341188,0.9947041869163512,0.0,accept,unanimous_agreement
669565785,9202,any reason not to just reply `ok` here? many `debug` commands are dangerous as it is and returning such status replies is not such a common practice.,-1,0,0,0.7047658562660217,0.8715152740478516,0.8842348456382751,0.0,accept,majority_agreement
669568377,9202,"nit: this comment block needs indentation and at least another round of review for spelling/grammar/etc. also, please avoid tab characters.",0,0,0,0.9850450158119202,0.9867311716079712,0.6633046269416809,0.0,accept,unanimous_agreement
669570625,9202,need to handle `p==null`?,0,0,0,0.9790070056915284,0.993741810321808,0.9934794902801514,0.0,accept,unanimous_agreement
669571333,9202,need to handle invalid length?,0,0,0,0.936800479888916,0.9650759696960448,0.9826391935348512,0.0,accept,unanimous_agreement
669571812,9202,handle `p==null` here as well? this repeats itself.,0,0,0,0.9857881665229796,0.993107795715332,0.9931334853172302,0.0,accept,unanimous_agreement
669573392,9202,"this kind of assumptions back fire over time, i think we need a really good reason (backed by data) to create a fragile parser.",0,-1,-1,0.8018190860748291,0.7924075722694397,0.5705446004867554,-1.0,accept,majority_agreement
669573786,9202,same as above.,0,0,0,0.9746477603912354,0.9857698678970336,0.9922299981117249,0.0,accept,unanimous_agreement
669574732,9202,[code block] repeats a few times below.,0,0,0,0.9865646362304688,0.9910469651222228,0.9934315085411072,0.0,accept,unanimous_agreement
669941514,9202,"discussion summary: we will leave error handling for another pr (because the old parser did not check for protocol correctness as well, so we are not changing the behavior). on the other pr we should add error handling code and make sure we do not see any performance regression. i guess this covers the other comments about error checking above, please confirm.",0,0,0,0.976984202861786,0.9848893880844116,0.9748841524124146,0.0,accept,unanimous_agreement
670424062,9202,"nitpick: i'd rather have everything in the non-expanded form here, i.e. `callreplygetstring`. also, `callreplygetboolean` and `callreplygetarrayelement`.",0,0,0,0.987281858921051,0.9856197834014891,0.9860119223594666,0.0,accept,unanimous_agreement
670427763,9202,"[code block] also, ""blob"" -> ""buffer""?",0,0,0,0.9889703989028932,0.9939000606536864,0.993057370185852,0.0,accept,unanimous_agreement
670431182,9202,missing copyright,0,0,0,0.8624903559684753,0.9677174091339112,0.9611886739730836,0.0,accept,unanimous_agreement
670795476,9202,"i think you mean expanded, non-abbreviated?",0,0,0,0.984074592590332,0.9887064695358276,0.9869154691696168,0.0,accept,unanimous_agreement
670818224,9202,why not call this resp_parser? that is what it is right?,0,0,0,0.9705753326416016,0.9564872980117798,0.992459237575531,0.0,accept,unanimous_agreement
671882172,9202,will be changed on another pr because it requires renaming,0,0,0,0.98708176612854,0.9933350086212158,0.9940339922904968,0.0,accept,unanimous_agreement
671882497,9202,"good point, i agree it makes more sense on the api (although we never reach here..).",1,1,1,0.6686679124832153,0.9420821070671082,0.9575202465057372,1.0,accept,unanimous_agreement
672026261,9202,what's wrong with bool?,-1,0,0,0.861474335193634,0.9533380270004272,0.5564203858375549,0.0,accept,majority_agreement
672032820,9202,"can you tell me why you suggested these changes? personally i do prefer less boilerplate lines. but the code is already full of these, so i'm interested to know if there's a good reason to switch the others, or keep using both.. admittedly, i see now that a prefix of `/**` only exists in the apis added in the past. but closing the `*/` in a separate line (which i also dislike, specifically on short comments), exists everywhere.",-1,-1,0,0.5634637475013733,0.7441887259483337,0.9290102124214172,-1.0,accept,majority_agreement
672284662,9202,[code block] redundant blank line.,0,0,0,0.9472098350524902,0.9693255424499512,0.9780540466308594,0.0,accept,unanimous_agreement
672297960,9202,thanks,1,0,1,0.6094269156455994,0.5400217771530151,0.8643599152565002,1.0,accept,majority_agreement
672785656,9202,"this is confusing, because `rep->val.ll` is allowed to be `llong_min`, or whether it should be `assert`.",0,-1,0,0.5700606107711792,0.8098868727684021,0.7302072644233704,0.0,accept,majority_agreement
672821450,9202,"this is how it is today, i did not change that : [a link]",0,0,-1,0.9339147210121156,0.9484991431236268,0.653102695941925,0.0,accept,majority_agreement
672830270,9202,"if `rep->type` is `redismodule_reply_string`, `callreplygetlonglong(rep)` will return `llong_min`. so how does the caller determine that it returned a error? `if(callreplygetlonglong(rep) == llong_min)`?",0,0,0,0.9880115389823914,0.995022177696228,0.9932859539985656,0.0,accept,unanimous_agreement
673052871,9202,"i understand what you are saying, i just mentioned that it is already like this today (and it's not like this pr breaks it). also, the user can check the reply type to understand if it's long and not count on the result of `callreplygetlonglong`.",0,0,0,0.9722435474395752,0.9685423374176024,0.9856837391853333,0.0,accept,unanimous_agreement
674792176,9202,"i think this should be ""redis labs ltd."".",0,0,0,0.9852538704872132,0.9904659986495972,0.987488567829132,0.0,accept,unanimous_agreement
674796762,9202,"he copied that from defrag.c but looking at the [a link] at the very bottom of redislabs.com website i see `redis labs, inc.` at the top.",0,0,0,0.9867700338363647,0.9897943139076232,0.9924691319465636,0.0,accept,unanimous_agreement
675003318,9202,don't we need to document all these types in rm_callreplytype?,0,0,0,0.9883914589881896,0.9933972358703612,0.9936800003051758,0.0,accept,unanimous_agreement
675004513,9202,"reminder, please document this in the top comment of the function",0,0,0,0.9867573976516724,0.9884262084960938,0.9953534603118896,0.0,accept,unanimous_agreement
680506229,9202,"summarizing: 1. on lua this is a dead code because lua will never call this function when the reply is not an integer 2. modules can do whatever they want but if the module reaches this code then it must be a bug in the module, the module has a way to check the reply type before calling this function. i believe the correct way was to assert that the type is redismodule_reply_integer, it will hold for lua but it might crash modules that misuse the api it might be considered a breaking change. there is no good way to return an error to the module (with the current api), so probably the best thing to do is to keep the behavior as it is today.",-1,0,0,0.6291216015815735,0.7150461673736572,0.9738426804542542,0.0,accept,majority_agreement
680506663,9202,summarizing: we decided to added resp2 and resp3 tests. was added here: [a link],0,0,0,0.9788166880607604,0.9023414254188538,0.9938918352127076,0.0,accept,unanimous_agreement
680506895,9202,cover here: [a link] thanks,1,1,1,0.6292842626571655,0.8038711547851562,0.6251712441444397,1.0,accept,unanimous_agreement
680507005,9202,error handling summary: [a link],0,0,0,0.985705018043518,0.9873720407485962,0.993250012397766,0.0,accept,unanimous_agreement
680507051,9202,error handling summary: [a link],0,0,0,0.985705018043518,0.9873720407485962,0.993250012397766,0.0,accept,unanimous_agreement
680517673,9202,iirc you need a blank line before the bullet list for markdown to be rendered correctly.,0,0,0,0.9889360070228576,0.98626047372818,0.9916786551475524,0.0,accept,unanimous_agreement
680531617,9202,"yes, indeed.. it screwed me up recently, here's the fixup commit as evidence: [a link]",-1,0,-1,0.7745633721351624,0.7369077801704407,0.9016273021697998,-1.0,accept,majority_agreement
680700689,9202,"thanks, fixed.",1,1,1,0.6975147128105164,0.8492836356163025,0.8536084890365601,1.0,accept,unanimous_agreement
681325767,9202,"on another thread, [a link] i talked with some oss lawyers and they suggested just putting `copyright redis contributors.` for new files. the copyright years are not required for the most part. feel free to to include redis labs ltd. if you feel it's important.",0,0,0,0.8644376993179321,0.9627227783203124,0.9378147721290588,0.0,accept,unanimous_agreement
681326348,9202,no-script*,0,0,0,0.9070504903793336,0.989006280899048,0.990351378917694,0.0,accept,unanimous_agreement
681772712,9202,"we're also checking this issue, let's stick with what we've done so far until we have an agreement on anything new.",0,0,0,0.9742306470870972,0.9680824875831604,0.9780110120773317,0.0,accept,unanimous_agreement
773936370,9974,did you mean this? [code block],0,0,0,0.9871829748153688,0.993660032749176,0.9948092699050904,0.0,accept,unanimous_agreement
773939012,9974,fyi 8-),1,1,0,0.9178273677825928,0.9396224617958068,0.9901025295257568,1.0,accept,majority_agreement
774545686,9974,maybe we can keep the search and just remember to also return that indication at the end?,0,0,0,0.9865821599960328,0.992775559425354,0.9905120730400084,0.0,accept,unanimous_agreement
774547951,9974,"[code block] i suppose we don't need to look for the keyword in the command name. and as already coded, we don't look for it in the very last arg (since the keys are expected to follow)..",0,0,0,0.9846124053001404,0.986769676208496,0.9931627511978148,0.0,accept,unanimous_agreement
774549102,9974,"if `i` can be `> argc`, can it also be `< 1`? e.g. if `startfrom` is bigger (absolute) than `argc`",0,0,0,0.9870163798332214,0.9947341680526732,0.9916244149208068,0.0,accept,unanimous_agreement
774560924,9974,"the fact that we didn't find anything using one spec, doesn't mean we should return, we should continue to the next spec.",0,0,0,0.9641247987747192,0.9827203750610352,0.9851890802383424,0.0,accept,unanimous_agreement
774563952,9974,i'd rather `continue`,0,0,0,0.9695203304290771,0.9804129004478456,0.9681751132011414,0.0,accept,unanimous_agreement
774567726,9974,"maybe we want to have some clamping based on argc? i.e. i see `last` is computed like `last = first + (int)numkeys-1;` it could be out of range, or huge in a few other places.",0,0,0,0.9876809120178224,0.9902690649032592,0.9831863641738892,0.0,accept,unanimous_agreement
774568696,9974,actually maybe we better clamp last and first too according to `argc` (not just `count`). otherwise this loop can be long.,0,0,0,0.985693097114563,0.9852308034896852,0.9864796996116638,0.0,accept,unanimous_agreement
774570011,9974,"again, i think we should `continue` to the next spec.",0,0,0,0.984265923500061,0.981423795223236,0.9842954874038696,0.0,accept,unanimous_agreement
774570852,9974,"could `step` be negative? if so, we need to check `i < 1`",0,0,0,0.983412742614746,0.993160367012024,0.9900726079940796,0.0,accept,unanimous_agreement
774573995,9974,"in the normal `getkeysfromcommand`, the `getkeys_proc` takes priority over the metadata in the command table. why did we decide here to try the spec before the proc? or alternatively, if we check the keyspecs first, why bother add read and write flags to the procs?",0,0,0,0.9850202798843384,0.99519544839859,0.9928642511367798,0.0,accept,unanimous_agreement
774575123,9974,i didn't understand the question,-1,-1,-1,0.6773393750190735,0.5971418619155884,0.8221412301063538,-1.0,accept,unanimous_agreement
774575762,9974,"i'm not certain if all the users of this method use these keys for just read. maybe some that don't pass `storekeyofs`, use the others for write too? since this is a ""generic"" function, maybe the flags should be passed from outside?",0,0,0,0.9796263575553894,0.9569234251976012,0.9553783535957336,0.0,accept,unanimous_agreement
774608882,9974,"since sort can read from various ""random"" keys, we have to add explicit acl code in sortcommand, like we do in scriptverifyacl and execcommand",0,0,0,0.988520085811615,0.994931161403656,0.9912351369857788,0.0,accept,unanimous_agreement
774608913,9974,"i just noticed that the json file for sort_ro doesn't mention incomplete. in sort the write key does mention it, but we can actually also read from more keys",0,0,0,0.9775773882865906,0.985923171043396,0.974268078804016,0.0,accept,unanimous_agreement
774690949,9974,my monitor is wide and narrow 8-). i'd like to be able to fit two more lines in.,1,0,0,0.7850053310394287,0.7470257878303528,0.9509971737861632,0.0,accept,majority_agreement
774691537,9974,"come to think of it, we can reduce both width and height by using early return and continue, instead of nested `if`s. :smile:",1,0,1,0.9755699634552002,0.5175939798355103,0.9870768189430236,1.0,accept,majority_agreement
774696669,9974,"let's add a short top comment. and also maybe refer to what ""op"" means (""operation"", may not be immediately clear). maybe add that to the doc of the function below. it may be especially confusing since both these functions take `op` and `oplen` but they contain different things. i.e. iiuc one is a single op and it's string len, and the other is a list of space delimited ops (and the string len of that) i also see that we assume the input in this one is wrapped by parenthesis, which we strip? let's mention that too.",0,0,0,0.9635581374168396,0.984825074672699,0.9848495721817015,0.0,accept,unanimous_agreement
774708527,9974,"change to what? it's an invalid syntax, what other options we have?",0,0,0,0.941951870918274,0.7620354294776917,0.8125327229499817,0.0,accept,unanimous_agreement
774712499,9974,also maybe we should block repeated uses or `r` and `w` and error on them? p.s. maybe we should be case-insensitive?,0,0,0,0.9815682768821716,0.99335116147995,0.9920660853385924,0.0,accept,unanimous_agreement
774714859,9974,please update redis.conf docs,0,0,0,0.9869334697723388,0.990356981754303,0.9943904280662536,0.0,accept,unanimous_agreement
774720051,9974,"i'm a little confused why we have both this function and the one above it (aclcheckkey). seems like we wanna expose just one that has a loop and checks both the default, and a loop on all selectors. seems like exposing aclcheckkey (as non static) is dangerous (someone may call it, and it'll look like it's working but will be incomplete)",-1,-1,-1,0.9058910012245178,0.9175126552581788,0.9349122643470764,-1.0,accept,unanimous_agreement
774721731,9974,leftover from debugging?,0,0,0,0.982119083404541,0.9780623316764832,0.9797754287719728,0.0,accept,unanimous_agreement
774722339,9974,are pubsub using just the default selector? do we have anything that's validating the users don't attempt to provide pubsub rules in non-default selectors?,0,0,0,0.9862533211708068,0.9933886528015136,0.9936729669570924,0.0,accept,unanimous_agreement
774741914,9974,"adding a review comment so we don't forget this, and can resolve it when done.",0,0,0,0.9816215634346008,0.9876969456672668,0.9939286708831788,0.0,accept,unanimous_agreement
774742585,9974,please add a comment above the block to describe what it does (compose the `upcoming` list). .. easier to read and skip when big chunks of code have a title.,0,0,0,0.9816341996192932,0.976133108139038,0.9943516254425048,0.0,accept,unanimous_agreement
774742805,9974,don't forget to clean these prints up when done (few more below),0,0,0,0.96062433719635,0.9814173579216005,0.9835277199745178,0.0,accept,unanimous_agreement
774743142,9974,i'd rather avoid these two line breaks (since we're changing these lines anyway due to indentation),0,0,0,0.9649212956428528,0.9735550880432128,0.9221959710121156,0.0,accept,unanimous_agreement
774744029,9974,"shouldn't it be the other way around? i.e. exit with ok as soon as we found a match, and exit with error if the loop gets exhausted.",0,0,0,0.9644752144813538,0.9914361834526062,0.9855217933654784,0.0,accept,unanimous_agreement
774745332,9974,"""closest"" means ""most detailed""? maybe add some comment explaining what we aim for... p.s. don't we also need to keep the correct `idxptr` of the error we choose to propagate upwards? (i suppose the same command can't do both keys and channels, so i guess it's just a theoretical problem, but it stands out when looking at the coed)",0,0,0,0.9672607779502868,0.9780831933021544,0.985961616039276,0.0,accept,unanimous_agreement
774747131,9974,"please add a top comment. p.s. maybe a more appropriate name would be acladdreplyselectordescription? the ""get"" in the title made me think this method returns something to the caller.",0,0,0,0.9878342151641846,0.9872149229049684,0.9894334673881532,0.0,accept,unanimous_agreement
774748692,9974,"it's odd (and dangerous) that the map len is set here, but some of the fields are actually part of aclgetuseraddselectorreply. i would suggest to use differed reply and have aclgetuseraddselectorreply return the count, but i know it comes with a performance overhead (many small packets and `write` system calls). so maybe a comment can resolve that...",-1,0,-1,0.6023532748222351,0.504041314125061,0.8247169256210327,-1.0,accept,majority_agreement
774751933,9974,"i'm not sure i understand it, and if i do, i'm not sure it's necessary or desired to support that. maybe after i read the test code i'll understand better.",-1,0,-1,0.7723528742790222,0.7367676496505737,0.5364256501197815,-1.0,accept,majority_agreement
774752984,9974,please describe the interface change to getuser and any others in the top comment of the pr (easier review and release notes),0,0,0,0.9819213151931764,0.9804376363754272,0.9953733086586,0.0,accept,unanimous_agreement
774753734,9974,what's the purpose of these? maybe you wanna use `assert_error` (to verify you're getting the right error),0,0,0,0.9849483370780944,0.99136620759964,0.9905960559844972,0.0,accept,unanimous_agreement
774755109,9974,"would be better to convert the response to dict, and fetch the intended fields, rather than rely on hard coded indexes.",0,0,0,0.986044943332672,0.9921980500221252,0.9866353869438172,0.0,accept,unanimous_agreement
776108485,9974,"a more descriptive error, i was indecisive at the time.",-1,-1,0,0.9351831674575806,0.5608741641044617,0.8916285634040833,-1.0,accept,majority_agreement
776108558,9974,both makes sense to me.,0,0,0,0.9627980589866638,0.9762758016586304,0.9792447090148926,0.0,accept,unanimous_agreement
776108612,9974,yup,0,0,0,0.7866461277008057,0.6203734278678894,0.8985633254051208,0.0,accept,unanimous_agreement
776111892,9974,"i don't think this function needs to be high performance, i'm happy doing the deferring.",1,1,1,0.8934386372566223,0.9728382229804992,0.9576174020767212,1.0,accept,unanimous_agreement
776112682,9974,"in my defense, i just copied it verbatim from guy, so we can blame him :)",1,1,1,0.9263696670532228,0.9547560811042786,0.9630150198936462,1.0,accept,unanimous_agreement
780872813,9974,"i couldn't find any existing cases where step is negative, perhaps wants to weigh in.",0,0,0,0.7727141380310059,0.9721419215202332,0.9647749066352844,0.0,accept,unanimous_agreement
780873222,9974,"now that i understand this better, i believe we want to trust the specs over the procs here. i will omit adding the flags.",0,0,0,0.9484416842460632,0.9410833716392516,0.9598379135131836,0.0,accept,unanimous_agreement
780873450,9974,:confounded_face:,-1,0,-1,0.9629771113395692,0.978184163570404,0.9668278098106384,-1.0,accept,majority_agreement
780873599,9974,"now that i understand better, it's really just the incomplete flag we need to handle. so i will make sure sort and migrate implement flags.",0,0,0,0.972753643989563,0.9788556694984436,0.9644683599472046,0.0,accept,unanimous_agreement
780874128,9974,this seems like an independent bug that maybe we can pull out of this pr.,0,0,0,0.7181065082550049,0.9321895837783812,0.981923520565033,0.0,accept,unanimous_agreement
781139994,9974,i think i was wrong... it's `lastkey` and `limit` that can be negative with some special meaning.,-1,0,0,0.8587501645088196,0.9190703630447388,0.938696026802063,0.0,accept,majority_agreement
781142299,9974,"there are some cases where the specs are limited (can't find all keys). specifically migrate, when the the auth password is ""keys"". since this is for acl, maybe we can't afford to make any compromises here? maybe we wanna use the `incomplete` flag, to decide between these approaches? i.e. always prefer the key-specs, unless the `incomplete` flag is present, in which case we make the `getkeys_proc` mandatory. wdyt?",0,0,0,0.983346462249756,0.99053955078125,0.983507513999939,0.0,accept,unanimous_agreement
781143127,9974,ohh great... reading it after i posted a similar comment here: [a link],1,1,1,0.9696381092071532,0.946716845035553,0.9636272192001344,1.0,accept,unanimous_agreement
781144681,9974,"if this wasn't about a security topic, i would mind leaving it behind... but since it is, i think we must handle it. we can leave it out of this pr, and handle in a followup pr after this one is merged. in which case, please add a todo checkbox in the top comment, to open a separate pr / issue for it.",0,0,0,0.974219560623169,0.984865665435791,0.921474814414978,0.0,accept,unanimous_agreement
781162246,9974,"so we're gonna add `incomplete` flag on the read key-spec on both sort and sort_ro, as part of **this** pr, right?",0,0,0,0.9785218834877014,0.9945825934410096,0.9930959343910216,0.0,accept,unanimous_agreement
783221334,9974,"yes, prefer key-specs, unless one of them has ""incomplete""",0,0,0,0.9823593497276306,0.9927740097045898,0.9899780750274658,0.0,accept,unanimous_agreement
783556894,9974,sure.,0,0,0,0.9536533951759338,0.9664214849472046,0.9824982285499572,0.0,accept,unanimous_agreement
783557813,9974,"in either case, i defined the logic to be the first ""key/channel"" that was not matched by any selector. that should also handle the case if modules want to define a command that touches both.",0,0,0,0.9880436062812804,0.9938827753067015,0.9954677820205688,0.0,accept,unanimous_agreement
783557913,9974,i'll add a top comment for this.,0,0,0,0.982803463935852,0.9808669686317444,0.9940523505210876,0.0,accept,unanimous_agreement
783656255,9974,"based on other communication, i think if there is an incomplete flag we want to abort and go to the authority which is the function call.",0,0,0,0.9857953786849976,0.9787002205848694,0.9896063208580016,0.0,accept,unanimous_agreement
783656935,9974,"i think they were in the draft, they should loop over selectors now.",0,0,0,0.9849510192871094,0.9814000129699708,0.9831422567367554,0.0,accept,unanimous_agreement
783657493,9974,the logic was rewritten to hopefully be clearer now.,0,0,0,0.9781668186187744,0.9887712597846984,0.9886541366577148,0.0,accept,unanimous_agreement
783659788,9974,"i added some more docs here and took the suggestion to make them static. i also moved selectors internal to acl.c, since they shouldn't be exposed outside of the acl code. they're basically an implementation detail.",0,0,0,0.9845773577690125,0.9892694354057312,0.988841474056244,0.0,accept,unanimous_agreement
783666347,9974,"i'm thinking of this function in a more generic term. it's purpose is to find all the keys and return an indication of the flags, and it can someday be used elsewhere. so i'd prefer to conclude the search and find all the keys that could be found. if we want an early abort optimization, maybe that could be an input flag? if not, let's at least make sure the function's top comment mentions that the search is aborted early as soon as this flag is found.",0,0,0,0.9796867370605468,0.9808564186096193,0.9763092398643494,0.0,accept,unanimous_agreement
783972974,9974,"i think the term ""root"" may be misleading here, please elaborate a bit on what ""root"" means.",0,0,0,0.9511364698410034,0.9406519532203674,0.8581919074058533,0.0,accept,unanimous_agreement
784054703,9974,"i'd like to find a better name for this operator. at first, i didn't like the `no-` prefix, since it's actually an operation (like 'reset'), but then i realize `nopass`, which i guessed this is modeled after, but this is actually more similar to `resetoass` than `nopass`. besides but two differences: 1. it uses `-` while `nopass` / `resetpass` is one word. 2. it's too damn long. so how about `resetselectors`, `clearselectors`, or `resetsel`, where the documentation will say it only resets the secondary selectors? or alternatively, we can add both `resetsel`, and `reset2ndsel`",-1,-1,-1,0.896997332572937,0.9119186401367188,0.9729645848274232,-1.0,accept,unanimous_agreement
784056135,9974,"p.s. here (unlike in redis.conf), maybe the term ""root"" user permissions is ok. but still maybe it's better being more verbose and explain it (copy paste from redis.conf)",0,0,0,0.9775322675704956,0.9865610003471376,0.9877492785453796,0.0,accept,unanimous_agreement
784091097,9974,debugging print?,0,0,0,0.9831722974777222,0.9776350259780884,0.9941708445549012,0.0,accept,unanimous_agreement
784111043,9974,"i'm trying to understand this change, maybe need some help. in the past, there was a `continue` in the `argc` loop, now there's a `break`. then, the outer `lines` loop has a `continue` that wasn't there before. what's the gist of that change?",0,0,0,0.8200507760047913,0.9677866101264954,0.9115585088729858,0.0,accept,unanimous_agreement
784132726,9974,"i see you're using the non-verbose mode for the root selector, and the verbose mode for the non-root selectors. i understand that's for backwards compatibility, but isn't that problematic? i.e. if someone uses special read/write root selectors in the root it'll hide information form the user? maybe it's better to use the non-verbose mode automatically when the selector is r+w? (would be backwards compatible as long as people don't use the new features). or am i missing something and the root selector doesn't support explicit r/w modifiers?",0,0,0,0.9487699270248412,0.945793628692627,0.9655229449272156,0.0,accept,unanimous_agreement
784149610,9974,did you mean this? [code block],0,0,0,0.9871829748153688,0.993660032749176,0.9948092699050904,0.0,accept,unanimous_agreement
784150606,9974,did you mean this? [code block],0,0,0,0.9871829748153688,0.993660032749176,0.9948092699050904,0.0,accept,unanimous_agreement
784153053,9974,maybe add a top comment for `georadiusgetkeys` about the fact it doesn't maintain flags and why,0,0,0,0.9782904982566832,0.9928585290908812,0.9887786507606506,0.0,accept,unanimous_agreement
784153287,9974,maybe add a top comment for `xreadgetkeys` about the fact it doesn't maintain flags and why,0,0,0,0.976664423942566,0.9926767349243164,0.9892860054969788,0.0,accept,unanimous_agreement
784157576,9974,"i didn't see fixes to the bugs i found in getkeysusingkeyspecs, or changes in the logic of when getkeysfromcommand uses key-specs, vs when it uses the getkeys_proc. i guess that's still pending? p.s. when you edit that, take extra care when thinking about modules.",0,0,0,0.9799410700798036,0.9840224981307985,0.9785807132720948,0.0,accept,unanimous_agreement
785358973,9974,"i wasn't planning on updating getkeysfromcommand for this pr, did we want to do that?",0,0,0,0.8422436118125916,0.9615294337272644,0.9896252751350404,0.0,accept,unanimous_agreement
785359089,9974,sure.,0,0,0,0.9536533951759338,0.9664214849472046,0.9824982285499572,0.0,accept,unanimous_agreement
785359961,9974,"i don't hate clearselectors. i dislike the term reset, although used elsewhere, has confused our customers at least. i think it external documentation we can call these ""selectors"", main user has ""root permissions"".",-1,-1,-1,0.976507306098938,0.9909915924072266,0.8181289434432983,-1.0,accept,unanimous_agreement
785360224,9974,thoughts on naming?,0,0,0,0.9564220905303956,0.8556557893753052,0.970238208770752,0.0,accept,unanimous_agreement
785360920,9974,"two things: 1) i don't know why i added error variable, that looks like a bug. 2) the previous version printed out a string that is the filename + linenumber + errmsg for each error, which can be confusing since it's not helpful. let me pull this change out into a separate pr, since for some definition it is a backwards incompatible change.",0,0,0,0.900730848312378,0.731616735458374,0.8630977869033813,0.0,accept,unanimous_agreement
785361045,9974,"although this may be an esoteric case, it just becomes difficult to differentiate someone having all permissions on ""%r~*"" versus someone who has read permissions on ""*"". i don't know if that's a likely outcome, but it seemed worth guarding against. the alternative i was considering was just omitting all of the keys that weren't all permissions from the root permissions.",0,0,0,0.7828903198242188,0.9391791224479676,0.9811038970947266,0.0,accept,unanimous_agreement
785361068,9974,added some new wording.,0,0,0,0.98199200630188,0.9813719987869264,0.9927133917808532,0.0,accept,unanimous_agreement
785395055,9974,"i don't see the need to build pre-optimization for that case, since you should call the other function to fetch the keys.",0,0,0,0.9839451909065248,0.9763412475585938,0.982819139957428,0.0,accept,unanimous_agreement
785395195,9974,"yeah, probably.",0,0,0,0.9573038816452026,0.9184752702713012,0.9661924839019777,0.0,accept,unanimous_agreement
785396473,9974,"ok, next revision is clamping to argc for last, and just continuing if first > argc.",0,0,0,0.9872265458106996,0.9880623817443848,0.9938166737556458,0.0,accept,unanimous_agreement
785406056,9974,"i guess not.. if we're using `getkeysfromcommandwithspecs` directly in acl. maybe we need to come up with some plan though to test that both of these are returning the same set of keys. iirc, guy wrote some temp code in processcommand to try calling both and assert that they return the same (the run the full test suite and see it doesn't crash). maybe it's a good idea to repeat that test, but also it would be nice to think of some test that can be added to the test suite.",0,0,0,0.8257867693901062,0.9380068182945251,0.9442511200904846,0.0,accept,unanimous_agreement
785408524,9974,"sorry.. i didn't understand your response. 1. isn't `%r~*` and `read permissions on ""*""` the same? 2. can people use the `%r~*` notation on the root selector? 3. are you saying that in the root segment, you rather fold `%rw~` into just `~` (for backwards compatibility), and the non-root selectors you rather be explicit (i.e. user who provided `~` will get back `%rw~`)?",-1,-1,-1,0.990136742591858,0.96740984916687,0.9892917275428772,-1.0,accept,unanimous_agreement
785409966,9974,"by unneeded pre-optimization you mean to about the search early as soon as the incomplete flag is found (optimization)? or keep searching to return a list as full as possible? i.e. which one of these is unneeded? i consider this a reference implementation of how to extract keys from key-specs, i don't know how it'll be used in the future (inside redis), and would even rather think that people will copy that code from redis to use in other projects. thus, i'd rather let it keep the search, and not abort here.",0,0,0,0.9613160490989684,0.9598629474639891,0.9848335385322572,0.0,accept,unanimous_agreement
785411138,9974,"wow, i don't recall what i meant to say here. do you? i suppose i suggested that we need to also break when `i` is negative (when walking backwards)? so we don't segfault in `argv[i]->ptr` below.",0,0,0,0.85992032289505,0.741052508354187,0.8082706928253174,0.0,accept,unanimous_agreement
785411695,9974,"off by one? (last is an actual position, and argc is a count) [code block]",0,0,0,0.9882070422172546,0.992304265499115,0.9907888770103456,0.0,accept,unanimous_agreement
785479496,9974,"""resetselectors"" is confusing but consistent, ""clearselectors"" also works for me.",0,0,0,0.8501027226448059,0.8572121858596802,0.7794209122657776,0.0,accept,unanimous_agreement
785600007,9974,"if we want this function be a complete reference implementation for fetching keys, we may want to call the get_keys_proc() here instead of aborting.",0,0,0,0.9891435503959656,0.991664707660675,0.99143785238266,0.0,accept,unanimous_agreement
785601773,9974,"i'm not sure i originally followed what you said, but i agreed to something but didn't make a change. doing a negative check here makes sense though.",0,0,0,0.8313419818878174,0.6325945854187012,0.6910064220428467,0.0,accept,unanimous_agreement
785771522,9974,"you mean that client will replace that with a call to command getkeys? i don't think i like it this way. most clients are ok with getting one key (for cluster support), and don't care if it's incomplete. i prefer to return all what we can return, and an indication that it's incomplete.",-1,0,0,0.77842777967453,0.7249853610992432,0.6776624917984009,0.0,accept,majority_agreement
785774259,9974,"i see you used `<0`, i think we can safely abort on `<1` (no sense in searching in the command name)",0,0,0,0.985939621925354,0.9831722974777222,0.9919267892837524,0.0,accept,unanimous_agreement
786342898,9974,then let's provide clients with an implementation that get's one key for cluster mode support. i don't think this code should be a model for an unknown number of client implementations. this code could be much simpler if it's just searching for a single key.,0,0,0,0.9777814745903016,0.9780703186988832,0.9921900629997252,0.0,accept,unanimous_agreement
786446348,9974,"i rather not maintain two implementations. i think that with minimal changes to this one, it can serve all purposes. i.e. add some input flags like: 1. exit asap as soon as an incomplete is found. 2. exit asap as soon as one key is found. actually, for the first purpose, we don't even need to scan the arguments, we can just add a short 3 line function that runs on the key-specs and returns an & mask of all flags. and we can even ignore the second purpose, users can easily edit the code and add a return as soon as one key is found. so what i'd prefer is: 1. add a new function to extract all key-spec flags and avoid calling this one at all on commands that have incomplete. 2. remove the handling of the incomplete flag in this function, and leave the code able to extract all possible key names it can.",0,0,0,0.9467920660972596,0.9555543661117554,0.8420363068580627,0.0,accept,unanimous_agreement
786924073,9974,are we sure we don't wanna just use the current user?,0,0,0,0.9804878830909728,0.9491162300109864,0.9910208582878112,0.0,accept,unanimous_agreement
786973168,9974,my thought was that it's slightly safer to run this since you can test on a user that is disabled and has no passwords. it makes the command a little more verbose though.,0,0,0,0.9417576193809508,0.9480039477348328,0.95382958650589,0.0,accept,unanimous_agreement
786986375,9974,"ok.. maybe it's indeed better, considering the user which we wana test may not have access to the acl command. and it's likely that the admin who defines the acls is the one which wants to test it.",0,0,0,0.971207857131958,0.98709374666214,0.9733693599700928,0.0,accept,unanimous_agreement
786988613,9974,"fair enough, i'll update this. it's not something i care that much about.",-1,0,0,0.9279775619506836,0.477221667766571,0.8327778577804565,0.0,accept,majority_agreement
787227237,9974,"i didn't understand this change from your other pr, this isn't the part that is incomplete, it's the next section that is.",0,0,0,0.6636945605278015,0.9513885378837584,0.923135221004486,0.0,accept,unanimous_agreement
787227623,9974,i also didn't understand this change. channels are not the same as shard channels.,-1,0,0,0.8277149796485901,0.537398099899292,0.6230360269546509,0.0,accept,majority_agreement
787227761,9974,"also, we should make these all the same case",0,0,0,0.9804427027702332,0.9895604848861694,0.9929367899894714,0.0,accept,unanimous_agreement
787291887,9974,"i didn't quite implement your suggestion, but i did something similar. let me know what you think: this function has two optional search flags: get_keyspec_ignore_channels and get_keyspec_return_partial. channels is straightforward, but partial is used both to check for incomplete flags as well as allows for syntax checking. on syntax errors, the default behavior is now to return nothing, back like in the earlier revisions, but when get_keyspec_return_partial is passed in it will still return all of the valid keys found. also note that in an earlier revision there was clamping, and i decided that potentially return false keys was not a good behavior. (if a client was trying to route for cluster mode, it might route to the wrong instance). so now it just continues.",0,0,0,0.9632733464241028,0.9566335678100586,0.8079499006271362,0.0,accept,unanimous_agreement
787341308,9974,"codewise this feels over-engineered, but it will make it easy to add more types of permissions in the future if we go down that route.",0,0,0,0.826117217540741,0.9418983459472656,0.9285518527030944,0.0,accept,unanimous_agreement
787408357,9974,"i think sort has two issues (each one deserves an incomplete flag due to a different reason). it has an input keys key-spec, that's only able to find the key to sort, but is not able to find the keys behind the by and get patterns. and it has an output keys key-spec (which is missing in sort_ro), that has an incomplete flag on it's own right (maybe i'm wrong? ) either way, i think the first incomplete, belongs to the input keys key-spec. the other alternative is to add a 3rd spec for these by and get keys. wdyt?",0,1,0,0.9380568265914916,0.6420223116874695,0.9605776071548462,0.0,accept,majority_agreement
787411708,9974,"my thought was that in the context of key-spec, saying these are pubsub channels is enough, and it is enough to say that they're ""channels"". i.e. normal publish channels don't have key-spec, the only reason these have, is because they're sharded. the main reason i did that was because i wanted all key-spec flags to be short, and one word. i guess that's not a real important concern. let me know if you feel strongly that this is a mistake, in which case we'll revert it asap.",0,0,0,0.8143124580383301,0.8935722708702087,0.8941563367843628,0.0,accept,unanimous_agreement
787412207,9974,"yes, i see i used upper-case letters for `rw`, `ro`, and also for `insert`, `update`, but not for channel and incomplete. unlike command info, in which case they're all lower-case, except `rw`, `ro` which are initials for two words. i suppose we should consolidate that (command info and module api should be the same), which way do you prefer?",0,0,0,0.9847260117530824,0.983850359916687,0.9908874034881592,0.0,accept,unanimous_agreement
787447243,9974,"i see that some places have spaces between the parameters and some are not. whether we need to unify, i tend to have space.",0,0,0,0.9674537777900696,0.9729755520820618,0.9834119081497192,0.0,accept,unanimous_agreement
787518772,9974,"i'll review it soon. but first 2 questions: 1. so it means that redis uses the partial flag (to abort on the first sign of incomplete), and if cluster clients will copy that code, they'll use partial too in order to get just one key? doesn't it mean they may get 0 keys (in case for sort the first key-spec has the incomplete flag)? 2. don't you think that for redis, for the purpose of deciding if we wanna use the getkeys_proc or the key-specs, it's easier and faster to just add a 3 line function that iterates on all key-specs and returns a mask of all flags? (without caring about the args)",0,0,0,0.9555333256721495,0.981226682662964,0.9480205178260804,0.0,accept,unanimous_agreement
787541122,9974,"i'd like your feedback here too. see discussion in [a link] and [a link] i see in the acl getuser [a link] that it says the `note that command rules are returned as a string in the same format used with the acl setuser command`, while the `keys` field is a plain list of key patterns (without the `~` dsl prefix), so we can't use it now, and we need to choose between keeping this field (a list of all key that can be possibly accessed), or deleting / deprecating that field. and in addition to that, we need to decide between adding a new field which has the `key-permissions` as dsl, or as currently implemented, a nested list of different permissions, each containing a list of patterns. wdyt?",1,0,0,0.7057786583900452,0.9832375049591064,0.662888765335083,0.0,accept,majority_agreement
787559769,9974,i don't think it's just the ow / update spec that's incomplete. the ro / access is also incomplete (each for a different reason),0,0,0,0.9035298824310304,0.8856831192970276,0.9273827075958252,0.0,accept,unanimous_agreement
787576982,9974,"i think we can waive on this `unknown` key-spec, and just add the incomplete flag to the other spec. wdyt? for sort and sort_ro, is it better to add a 3rd `unknown` key-spec (in which case maybe it doesn't have to have the incomplete flag), or just add the incomplete flag to the first spec (about the input keys). p.s. do you remember why the output-key spec is incomplete? that stands for itself, right?",0,0,0,0.9792938828468324,0.987051010131836,0.9826646447181702,0.0,accept,unanimous_agreement
787580172,9974,"i think this contradicts the top comment that says: `but returns the keys found in other keyspecs`. i'd rather move this block to a different function that just returns the mask of all specs, so that we know to rely only on getkeys_proc for the ones that have any incomplete spec.",0,0,0,0.9638002514839172,0.989120364189148,0.9774043560028076,0.0,accept,unanimous_agreement
787600872,9974,"i also think the comment about the return is wrong. should say that it returns the number of keys found. with current code, if the partial flag is not provided, it doesn't return 0 on incomplete. i think the incomplete flag should have nothing to do with this function.",0,0,0,0.7191239595413208,0.9714059233665466,0.9403697848320008,0.0,accept,unanimous_agreement
787614753,9974,"since the modulegetcommandkeysviaapi api doesn't support flags, and modules can soon declare key-specs, i think we may wanna move this for last priority (only if there are no key-specs or something). i suppose we can leave this topic for a future pr (maybe also add a variant for `redismodule_keyatpos` that adds a flag). let's open another issue for this (before we mark this comment as resolved)",0,0,0,0.9830213785171508,0.9917290806770324,0.99093759059906,0.0,accept,unanimous_agreement
787635133,9974,"maybe i'm missing something. these are key-spec flags, right? why are the non-sharded pubsub listed here?",0,0,0,0.8916539549827576,0.9846656322479248,0.8186811208724976,0.0,accept,unanimous_agreement
787678053,9974,"opened an issue: [a link] , we can resolve this comment if you don't have any quick reply for it.",0,0,0,0.9862077236175536,0.9793055653572084,0.993417739868164,0.0,accept,unanimous_agreement
787689012,9974,"spoke to guy, indeed the reason the key-spec for store is both `unknown` and `incomplete` is that during the search for the store keyword, we we could find the by and get pattern (which could be the word ""store"") and then we'll return the wrong result . i.e. for that reason i'ts not just marked as incomplete like other specs, it avoids even attempting to find that key (hence the `unknown`. what guy recommended was to add a 3rd spec of `unknown` type, with `incomplete` for the get and by args, rather than add the incomplete flag to the first key-spec (for the key we're sorting)",0,0,0,0.9463881850242616,0.9061784148216248,0.9855981469154358,0.0,accept,unanimous_agreement
787689613,9974,"p.s. pity we can't add comments in the json files, maybe we need to add a description or comment field per keyspec",-1,0,0,0.9847334027290344,0.8095374703407288,0.6642351150512695,0.0,accept,majority_agreement
787700163,9974,"given that it's a new major release and this command is mostly user-facing, i say we can probably break compatibility and for every key return a tuple of (permissions, key pattern). clients should be able to deal with both cases easily (depending on the type of every key element returned).",0,0,0,0.986260712146759,0.9831878542900084,0.9907982349395752,0.0,accept,unanimous_agreement
787755508,9974,"sort: 1. inpput key: regular ""range"" spec 2. by/get: ""incomplete"" and ""unknown"" 3. store: ""incomplete"" and ""unknown"" sort_ro: same as sort, except the last one",0,0,0,0.9876745343208312,0.994136929512024,0.988899827003479,0.0,accept,unanimous_agreement
787797399,9974,"i now noticed this is case-insensitive compare. but still fixed it to be similar to command command, and only use capital letters for the initials",0,0,0,0.9705238938331604,0.983403503894806,0.9802380800247192,0.0,accept,unanimous_agreement
787799961,9974,"i see that `addreplyflagsforkeyargs` exposes `cmd_key_channel` and not `cmd_key_shard_channel`, and `commandkeyspecsflagsfromstring` is the other way around. i'm still not certain about their different roles",0,0,0,0.9379028677940368,0.8965505361557007,0.9876125454902648,0.0,accept,unanimous_agreement
787870628,9974,i second the breakage - we can deprecate and replace the existing in favor of the extended. i think that in most cases the pattern->permissions mapping is more straightforward - it seems easier for a human to understand and simpler to implement in a theoretical client.,0,0,0,0.9752506613731384,0.9783410429954528,0.9705585241317748,0.0,accept,unanimous_agreement
787929458,9974,"i have some concern about the currently implemented approach. the one we have now is that we generate 3 nested entries in the `key-permissions` map elements. one for `read`, one for `write`, one for `all`. but what if we add more combinations in the future (insert, delete, etc) instead of 3 options (mask of 2 bits), we may get 7 combinations. i'm leaning towards making the `key-permissions` field a dsl like `commands` wdyt?",0,0,-1,0.6170229911804199,0.9021065831184388,0.7585198879241943,0.0,accept,majority_agreement
788127412,9974,"i thought they were useful to add. shard channels aren't keys either, but we thought they were useful to be treated as keys.",0,0,1,0.981658101081848,0.9784854650497437,0.8255329132080078,0.0,accept,majority_agreement
788133777,9974,"but we didn't define key-specs for these commands, so they're not used.. also, the reason we thought it's useful to define shard channels as keys, was to assist cluster clients, and also parts in redis, to do their thing.. it's not needed for normal pubsub",0,0,0,0.9667322039604188,0.9892248511314392,0.9741386771202089,0.0,accept,unanimous_agreement
788136608,9974,"do mean a single string like commands (e.g. `~foo ~bar` as a single argument) or still split into an array of individual dsl arguments? i prefer the second, which would look like: [code block]",0,0,0,0.9756184220314026,0.9937191009521484,0.9936239719390868,0.0,accept,unanimous_agreement
788200363,9974,"i decided to revert this, so let's discuss later.",0,0,0,0.9670133590698242,0.9371741414070128,0.9856552481651306,0.0,accept,unanimous_agreement
788200769,9974,"let's try to imitate the `commands` field. i must say i don't understand why he chose to do the keys this way.. also, considering that getuser is the opposite of setuser, maybe it should have been one long dsl string, and not resp. but take my advice with a grain of salt, i didn't play much with the acl commands.",0,0,0,0.7557294368743896,0.9010756611824036,0.8381012082099915,0.0,accept,unanimous_agreement
788297269,9974,i prefer putting the boolean operator on the newline so it's clearer what operation is being done. i see it inconsistently done in redis.,0,0,0,0.9614461660385132,0.9811559915542604,0.9787437319755554,0.0,accept,unanimous_agreement
788297522,9974,"i like spaces, salvatore didn't really like spaces but i don't think he forced it, so we're in a place where it's pretty divergent.",-1,-1,0,0.7288874387741089,0.955882728099823,0.7464616298675537,-1.0,accept,majority_agreement
788297559,9974,ty!,1,1,1,0.5472345948219299,0.8959217667579651,0.8588604927062988,1.0,accept,unanimous_agreement
788302106,9974,"reverting this code, punting it until later.",0,-1,0,0.9465597867965698,0.7023529410362244,0.992548644542694,0.0,accept,majority_agreement
788332888,9974,sounds good enough. let's just make it all look the same.,1,1,0,0.8902026414871216,0.645858883857727,0.6550577282905579,1.0,accept,majority_agreement
788605825,9974,should we start mentioning `[s]publish` ?,0,0,0,0.987475574016571,0.9950677156448364,0.9938748478889464,0.0,accept,unanimous_agreement
788613643,9974,i guess it's much easier to read if we introduce a `acl_all_permission`. and also has a defined value for the constant.,0,0,0,0.9854771494865416,0.9620060324668884,0.9790063500404358,0.0,accept,unanimous_agreement
788620862,9974,why is this required? if we are already creating the selector above with the same flag ?,0,0,0,0.9819484353065492,0.9921417236328124,0.992356538772583,0.0,accept,unanimous_agreement
788625270,9974,don't we need to privately free each selector first via `aclfreeselector` ?,0,0,0,0.9890540838241576,0.994522213935852,0.9938179850578308,0.0,accept,unanimous_agreement
788629358,9974,nit: do we want to name the variable as `selector` to be consistent across the code?,0,0,0,0.989245593547821,0.9947255253791808,0.9899060130119324,0.0,accept,unanimous_agreement
788632104,9974,why do we need to the flag check if at the end there is only one bit operation ?,0,0,0,0.9763991236686708,0.9799841046333312,0.9886682629585266,0.0,accept,unanimous_agreement
788641922,9974,feels like a magic number. should we define something for default flag ?,0,0,0,0.8333399891853333,0.7919492721557617,0.6594339609146118,0.0,accept,unanimous_agreement
788703101,9974,do we split at 80 chars per line ?,0,0,0,0.9851905703544616,0.9897902607917786,0.9925952553749084,0.0,accept,unanimous_agreement
788958237,9974,"no, listrelease will call the freemethod automatically, which is aclfreeselector.",0,0,0,0.98885577917099,0.9935762286186218,0.9921044111251832,0.0,accept,unanimous_agreement
788958443,9974,"i don't split, and i've seen others not explicitly try to split it as well, when it doesn't really help readability to split.",0,0,0,0.7917768359184265,0.7207970023155212,0.9251796007156372,0.0,accept,unanimous_agreement
788959613,9974,"to prevent having something like '%~wwwwwwww' be accepted, it's just tighter input validation.",0,0,0,0.958407700061798,0.969666600227356,0.9829776287078856,0.0,accept,unanimous_agreement
788961140,9974,don't really want to touch that here.,-1,-1,-1,0.8910231590270996,0.8454987406730652,0.642581045627594,-1.0,accept,unanimous_agreement
788963078,9974,"i think it damages readability. - splitting at arbitrary position (offset, rather than a logical one). - adds more lines so we get less lines fit in our screen. - these days people have very wide monitors (and vertical screen space is needed, and there's an abundance of unused horizontal space)",-1,0,-1,0.8203046917915344,0.6290917992591858,0.8198060393333435,-1.0,accept,majority_agreement
788971932,9974,"this grabs `sunsubscribe` as well, which we don't want. i'm going to add an explicit check for that if that works. i'm also going to test this.",0,0,0,0.9860091805458068,0.9729747772216796,0.9946302175521852,0.0,accept,unanimous_agreement
788986722,9974,"actually, this is missing other support for modules + channels that was also removed. we can add it back, but the functionality isn't here right now.",0,0,0,0.9688099026679992,0.9670810699462892,0.9889853000640868,0.0,accept,unanimous_agreement
789009661,9974,"i'd still argue this function belongs in db.c next to the other one. also, even if modules can't yet use it (so my commit comment was false), i think conceptually it's nicer to count on key spec flags (or any other flags), rather than explicitly list function names. i.e. the transition we're making in other places like processcommand, to stop maintaining lists of functions, and instead define their behavior in flags.",0,0,0,0.9741293787956238,0.9854406714439392,0.9774885177612304,0.0,accept,unanimous_agreement
802922663,10273,"here we assume that if there's only one item, it must be the schema to validate each item, and we do not support an array of items with size==1. i.e. we can't tell the difference between [code block] and [code block] one might argue that the latter has no use in redis (it means that the first item in the array is a string, and we don't care about the rest. if additionalitems=false is also provided, it means the array must have exactly one element, and it's a string. both cases seem to be not useful for redis)",0,0,0,0.9071044325828552,0.9897181987762452,0.9894388318061828,0.0,accept,unanimous_agreement
844403626,10273,what's that?,0,0,0,0.856007993221283,0.9194039702415466,0.9801049828529358,0.0,accept,unanimous_agreement
844404496,10273,maybe we wanna include `since` field here?,0,0,0,0.9849826693534852,0.9936495423316956,0.9888443350791932,0.0,accept,unanimous_agreement
855086324,10273,"it describes an object (i.e. map/dict/hash) whose values are strings (in json, and luckily also in redis, the keys are always strings)",0,0,0,0.988744854927063,0.9911813735961914,0.9876143932342528,0.0,accept,unanimous_agreement
855087390,10273,i feel like the reply-schema should not deal with the history of the reply (that's why we have the history section of the command) maybe or would like to chime in,0,0,0,0.8451708555221558,0.9764822125434875,0.9771979451179504,0.0,accept,unanimous_agreement
1061616673,10273,"let's add some comments, either for each, or at least for the block. also, i think i'd like an `ifdef` for controlling this feature, i don't think it should exist in a production compilation.",0,0,0,0.9760141968727112,0.9846773147583008,0.9904195666313172,0.0,accept,unanimous_agreement
1061624993,10273,i'm not certain i understand what this value field is used for. but maybe this should be `long` or `long long`? p.s. i've seen some commands using a type of `integer` and others use `number`.,0,0,0,0.9765121936798096,0.9293675422668456,0.9313916563987732,0.0,accept,unanimous_agreement
1061634847,10273,"what are we using rediscommandresp2type and rediscommandresp3type for? i see the schema files have references to `const`, which i don't see in either of these.",0,0,0,0.985789716243744,0.9909231066703796,0.991961658000946,0.0,accept,unanimous_agreement
1061636163,10273,"i see the schemas never seem to provide any value, so aren't these `value.string` and `value.boolean` empty / uninitialized? aren't we suppose to reply with the type (translate `cur->type` to text) instead?",0,0,0,0.981946051120758,0.9893879890441896,0.9905766248703004,0.0,accept,unanimous_agreement
1061638425,10273,"i think this config should be marked as hidden_config, and the other one put under `ifdef` (or maybe both should)",0,0,0,0.9886952042579652,0.9930777549743652,0.98428875207901,0.0,accept,unanimous_agreement
1061643071,10273,"for comments that start a section, let's add some line with hyphens [code block] or actually, maybe we should move this to a new c file? to make it clear that it's not part of the production runtime code?",0,0,0,0.98625385761261,0.9950026869773864,0.9926667809486388,0.0,accept,unanimous_agreement
1061652096,10273,let's use long_str_size?,0,0,0,0.9884727597236632,0.9930557608604432,0.9945412278175354,0.0,accept,unanimous_agreement
1061657392,10273,"please go over your code and add some comments for functions and big chunks of code. i.e. in this one you can say these are commands without a response, or change the client state to one that's excluded from this mechanism.",0,0,0,0.98742014169693,0.9898640513420104,0.9930054545402528,0.0,accept,unanimous_agreement
1061658785,10273,let's document this file format and this separator somewhere. maybe at the top of the dedicated file we create for it.,0,0,0,0.9861052632331848,0.9925652742385864,0.9919604659080504,0.0,accept,unanimous_agreement
1061660742,10273,why do we bother to create an iovec if we don't use writev? instead just write them in the first loop instead of having two loops...,0,0,0,0.955069661140442,0.8845242857933044,0.9682379961013794,0.0,accept,unanimous_agreement
1061664222,10273,i don't think we can rely on `c->sentlen`. seems that we need our own variable to distinguish between what we already processed and what we didn't.,0,0,0,0.9652165174484252,0.9645161032676696,0.9528833031654358,0.0,accept,unanimous_agreement
1061665169,10273,maybe comments in this function are outdated due to being copied and modified. i think this entire function needs a rewrite.,0,0,0,0.9138078689575196,0.946540594100952,0.9164236187934875,0.0,accept,unanimous_agreement
1061666022,10273,"again outdated comments, and we probably don't need both of these functions, just one.",0,0,0,0.78778076171875,0.8099980354309082,0.8989412784576416,0.0,accept,unanimous_agreement
1061684110,10273,please add comments,0,0,0,0.9764469861984252,0.9857516884803772,0.9927023649215698,0.0,accept,unanimous_agreement
1061688775,10273,"maybe we should move the implementation of the hooks (we're gonna add more of them, right?) and implicit response translators (which we're gonna add) to another file? so it'll be easier to realize that this isn't part of the normal test suite infrastructure? this redis.tcl is already very hard to understand, so by taking a big chunk of code out of it, we can let the reader focus on the other half.",0,0,0,0.956876277923584,0.909111261367798,0.9798702001571656,0.0,accept,unanimous_agreement
1061690007,10273,"can we really return? don't we just wanna force the hello to use resp3 and let the command run? isn't the caller expecting a response? also, it could be that this hello is meant to do something else (like setting the client name)",0,0,0,0.9827613234519958,0.988155484199524,0.9897089600563048,0.0,accept,unanimous_agreement
1061690906,10273,why did you do that change? other flows in this if-else chain just let the function return normally (with output of the last statement),0,0,0,0.986423671245575,0.991415798664093,0.9894989728927612,0.0,accept,unanimous_agreement
1061696377,10273,"can you explain (to me) why we need both? if we access a global here, why do we need a per-connection variable and vice versa? p.s. maybe it'll be nice if such functions (specifically if we'll have many of them) do something like this: [code block]` maybe it'll be easier to focus on the normal part separately than the special thing.",0,0,0,0.9626202583312988,0.8497671484947205,0.9872226715087892,0.0,accept,unanimous_agreement
1061699672,10273,missing some comment about what it does and for which commands. i.e. flattern output of hrandfield,0,0,0,0.9748702049255372,0.9872031807899476,0.9836350679397584,0.0,accept,unanimous_agreement
1061700849,10273,maybe with the recent improvements you don't need these and can let the resp2 tests run as well? same for zset.tcl,0,0,0,0.9864891767501832,0.9925374388694764,0.9903945326805116,0.0,accept,unanimous_agreement
1061701020,10273,why did you delete this?,0,0,0,0.9254283308982848,0.9809119701385498,0.9725087881088256,0.0,accept,unanimous_agreement
1061702213,10273,"lets do what we said on the call, and add a mechanism for implicit translators in redis.tcl (or another file next to it), so that we don't have to wrap each new call to xread that's added.",0,0,0,0.9883610010147096,0.993723452091217,0.9927809834480286,0.0,accept,unanimous_agreement
1061702626,10273,why did you have to change quote type?,0,0,0,0.9718427062034608,0.981116771697998,0.9926214218139648,0.0,accept,unanimous_agreement
1061703359,10273,let's try to resolve that with the implicit translators mechanism.,0,0,0,0.9840638637542723,0.9907773733139038,0.99129456281662,0.0,accept,unanimous_agreement
1061706672,10273,let's add some big comment explaining* * what it does * for what purpose * how to use it,0,0,0,0.9327343702316284,0.9582916498184204,0.9883823990821838,0.0,accept,unanimous_agreement
1061710317,10273,"let's add somewhere a list of validations that we do, and also include the planned ones that are yet to be implemented. i.e. * warn about the commands that are missing schema * warn about about schemas that are uncovered by the tests output * warn about replies that don't match the schema.",0,0,0,0.9798015356063844,0.9897243976593018,0.9932552576065063,0.0,accept,unanimous_agreement
1066837878,10273,note: change both to debug command (also with ifdef),0,0,0,0.9883911609649658,0.9919790029525756,0.9948570728302002,0.0,accept,unanimous_agreement
1066844493,10273,"first, log the client static buffer, and then c->reply. look at redis 6.2",0,0,0,0.978544294834137,0.9932246804237366,0.9952243566513062,0.0,accept,unanimous_agreement
1066861248,10273,"before logging argv, save the size of the reply list (list length + size of last) and the static reply buffer - these leftovers from previous commands that were not written to socket. when logging the response, we need to start logging from offset we saved above",0,0,0,0.988010823726654,0.9933491349220276,0.9929077625274658,0.0,accept,unanimous_agreement
1066869935,10273,"comment: key and val are the key and val of a json. in this case the json we are parsing happens to be a json schema, which also has similar key words such as type, boolean, integer, etc.",0,0,0,0.986877739429474,0.9927250146865844,0.9924824833869934,0.0,accept,unanimous_agreement
1066872484,10273,"check, remove if not used",0,0,0,0.9847144484519958,0.9825608134269714,0.9944763779640198,0.0,accept,unanimous_agreement
1066874915,10273,1. change to long long 2. rename stuff to clarify that this structs just represent an arbitrary json file,0,0,0,0.9844653010368348,0.9902538657188416,0.9891325831413268,0.0,accept,unanimous_agreement
1066877066,10273,move all response translators to a different (new) file,0,0,0,0.9862667322158812,0.992421805858612,0.9934322834014891,0.0,accept,unanimous_agreement
1066880673,10273,"1. log current command in __dispatch__raw__ (connection var, like $::redis::response_interpreters) 2. $::redis::response_interpreters will no longer be a connection var, but rather a table mapping command name to its interpreter 3. here in this function we will find our interpreter by using the command name and said table",0,0,0,0.9812321066856384,0.9935883283615112,0.9928485155105592,0.0,accept,unanimous_agreement
1066881457,10273,will revert,0,0,0,0.9481475949287416,0.9250321984291076,0.9868274927139282,0.0,accept,unanimous_agreement
1066886330,10273,"turn `!$::force_resp3 || $::redis::testing_resp3($id) == 1` into a function ""should_fake_resp2"" and comment: when forcing resp3 some tests that rely on resp2 can fail, so we have to translate the resp3 response to resp2",0,0,0,0.9558587670326232,0.9928516745567322,0.993943989276886,0.0,accept,unanimous_agreement
1066893898,10273,"some tests use rawread to verify the line protocol, in these cases we do not intervene and just skip what's needed if force_resp3 (only the ones that test resp2)",0,0,0,0.9879202842712402,0.9920777678489684,0.9926069974899292,0.0,accept,unanimous_agreement
1066895380,10273,different pr,0,0,0,0.948363184928894,0.93779194355011,0.9737010598182678,0.0,accept,unanimous_agreement
1066895860,10273,and tag person from blamelog,0,0,0,0.9267263412475586,0.9895272254943848,0.9944055080413818,0.0,accept,unanimous_agreement
1066897150,10273,different pr,0,0,0,0.948363184928894,0.93779194355011,0.9737010598182678,0.0,accept,unanimous_agreement
1066900981,10273,set nullres set nullres_withscores if not test_expects_resp3: // rewrite these vars,0,0,0,0.9884794354438782,0.9810813069343568,0.993937373161316,0.0,accept,unanimous_agreement
1067094685,10273,"so far all hellos were just in order to change the resp, without expecting a response but i guess we should run anyway, and change argv[1] to be ""3"" if it's ""2"" (in the case of force_resp3) i assume there's a test somewhere that actually verifies the response of hello when changing protocol, perhaps we will skip it if force_resp3",0,0,0,0.9769483208656312,0.9744155406951904,0.988587498664856,0.0,accept,unanimous_agreement
1097262748,10273,"should this be `oneof` ?. otherwise, if reply is `poooong`, it will match the second schema.",0,0,0,0.9878491163253784,0.9925576448440552,0.9943524599075316,0.0,accept,unanimous_agreement
1097282565,10273,`poooong` is a legal reply for ping,0,0,0,0.9831820130348206,0.9922745823860168,0.9940451383590698,0.0,accept,unanimous_agreement
1097287875,10273,"oh, i didn't know that",-1,-1,0,0.6882601976394653,0.8507490754127502,0.792219877243042,-1.0,accept,majority_agreement
1104885191,10273,remove,0,0,0,0.9725990891456604,0.947705328464508,0.9896913170814514,0.0,accept,unanimous_agreement
1104885363,10273,remove,0,0,0,0.9725990891456604,0.947705328464508,0.9896913170814514,0.0,accept,unanimous_agreement
1104885524,10273,remove,0,0,0,0.9725990891456604,0.947705328464508,0.9896913170814514,0.0,accept,unanimous_agreement
1104885860,10273,remove `.tcl`,0,0,0,0.985400140285492,0.9919014573097228,0.9933713674545288,0.0,accept,unanimous_agreement
1104888323,10273,"1 and 3 are covered, added the 2nd point to the todo in the top comment",0,0,0,0.9860714077949524,0.9897432923316956,0.9920511841773988,0.0,accept,unanimous_agreement
1105467889,10273,pinging,0,0,0,0.9824581742286682,0.9299814105033876,0.9308006167411804,0.0,accept,unanimous_agreement
1105714643,10273,"we decided that for now, we'll avoid adding any interface changes. we'll use the tests to validate the schema, but keep it internal to be exposed in some future date. so this needs an `#ifdef`",0,0,0,0.9851696491241456,0.9932802319526672,0.9923015832901,0.0,accept,unanimous_agreement
1107060710,10273,"let's avoid ""sentinel"", to avoid confusing with the redis sentienel. [code block]",0,0,0,0.9873294830322266,0.9913787841796876,0.9931408762931824,0.0,accept,unanimous_agreement
1107146057,10273,we don't need the zeroing since we have the memset.,0,0,0,0.98319411277771,0.9851486682891846,0.991303324699402,0.0,accept,unanimous_agreement
1107147515,10273,"let's document this mechanism (offset saving, what it does and why). maybe it's a good idea to add some doc comment above other (simpler) function as well.",0,0,0,0.9754663705825806,0.9781288504600524,0.9919264316558838,0.0,accept,unanimous_agreement
1107153728,10273,"if we care about performance, we can use adlist bookmakrs to avoid looping though to find the first item. but maybe we don't wanna bother since this is testing infra.",0,0,0,0.9778071045875548,0.9647151231765748,0.962416172027588,0.0,accept,unanimous_agreement
1107163108,10273,i don't understand this. why is the `else` needed? is the comment about writetoclient outdated?,-1,0,0,0.7357168197631836,0.5784276127815247,0.5686489343643188,0.0,accept,majority_agreement
1107163889,10273,why do we need fflush? we're closing it anyway...,0,0,0,0.6273139119148254,0.9484747052192688,0.94174987077713,0.0,accept,unanimous_agreement
1107169022,10273,"maybe we need a comment here. i assume the comment where the function is implemented will describe the mechanism, but here is an odd call. i.e. i assume should be called in `processcommand` after parsing the command and emitting the command name to the file, so why do we need it before any reply? if it's needed here, let's explain it. same for the call in addreplydeferredlen",0,0,0,0.9817866683006288,0.9910653233528136,0.971131443977356,0.0,accept,unanimous_agreement
1107171780,10273,"i don't see you added such comment where you changed the order (in replication.c), so why add one here? if it's not important enough, let's not add anything here, and if it is, we need to add in the other places, specifically where we had to do changes.",0,0,0,0.9798842668533324,0.9848527312278748,0.989298939704895,0.0,accept,unanimous_agreement
1107190186,10273,"fyi, in most of our `switch` statement, the `case` isn't indented. not sure i care much though.",-1,-1,0,0.9672032594680786,0.7262696623802185,0.799471378326416,-1.0,accept,majority_agreement
1107191236,10273,"please `ifdef` that one, no need to waste memory on something that's not being used.",0,0,0,0.9836211204528807,0.966459333896637,0.9210367798805236,0.0,accept,unanimous_agreement
1107192149,10273,"let's add some comment before that struct, maybe with a reference to logreqres.c",0,0,0,0.9867532849311828,0.9930883049964904,0.9939367175102234,0.0,accept,unanimous_agreement
1107198789,10273,"so this part will actually be populated even when redis is compiled without the reqres debug feature, and without the code that uses it in command docs, right? i might not mind another stale pointer per command, but if it is populate it could be unnecessary overhead. we can let the python code that generates commands.c add ifdefs into the generated code. maybe the downside could be that our ci can't catch some mistakes when prs are made, but i'm not sure what it can catch with the current state, and if we want to catch things maybe we should address it separately, i.e. by a ci job that enables something, but without any implications for production builds.",0,0,0,0.9586105346679688,0.96864116191864,0.963350772857666,0.0,accept,unanimous_agreement
1107211217,10273,maybe we can move these to redis.tcl to avoid repeating them in each root file? could have been the right thing for tlsdir as well?,0,0,0,0.98585444688797,0.9953604340553284,0.9896842241287231,0.0,accept,unanimous_agreement
1107214147,10273,"maybe redis.tcl can include response_transformers.tcl? the reason i wanted that in a separate file was so that it'll be easier to read, and won't clutter redis.tcl. but for users of redis.tcl, there should be no need to include an additional file.",0,0,0,0.9854474067687988,0.9923456311225892,0.9866742491722108,0.0,accept,unanimous_agreement
1107227604,10273,let's add some comment above each big block of code (for quicker reading),0,0,0,0.9831635355949402,0.9777057766914368,0.9937012195587158,0.0,accept,unanimous_agreement
1107233428,10273,"since it's a non-common path, and we don't have a lot of them, i think it would be nice to add a comment next to each place we do the transform (specifically in redis.tcl, not in response_transformers.tcl)",0,0,0,0.9788843393325806,0.9876700639724731,0.9857682585716248,0.0,accept,unanimous_agreement
1107234820,10273,"let's add a big comment at the top explaining this file. why it is needed, what it does, and how it works.",0,0,0,0.9795316457748412,0.9678950309753418,0.9926296472549438,0.0,accept,unanimous_agreement
1107238173,10273,"p.s. looking at the final outcome, i think it's quite neat (especially considering the initial approach)",1,1,1,0.73377925157547,0.7196214199066162,0.9802583456039428,1.0,accept,unanimous_agreement
1107245159,10273,"let's consider adding an `if` in each of these units, rather than a list here. the upside is that if one of them is cloned, it keeps the if rather than remembering to add it here. another advantage is that the unit can include some tests and skip others. the disadvantage would be to add many lines, and also the closing bracket (since i think we can't just early `exit` at the top. another way could be to filter them in the tags filtering mechanism (server.tcl), and add a tag in them that they're incompatible with this mechanism. maybe another advantage for your approach is that here there's one comment and we don't need t clone it. not sure if any of these is better than what you did...",0,0,0,0.9672846794128418,0.9841963052749634,0.9801076650619508,0.0,accept,unanimous_agreement
1107279725,10273,"i don't understand this, can you please explain? maybe even better add a comment stating why it's different.",-1,0,-1,0.8421326279640198,0.8113310933113098,0.8831634521484375,-1.0,accept,majority_agreement
1107280589,10273,maybe we can handle that in redis.tcl like we handled doubles?,0,0,0,0.9838979840278624,0.9948886036872864,0.9878146648406982,0.0,accept,unanimous_agreement
1107282401,10273,or maybe not because it's the other way around. i.e. resp3 reduced the variation of replies. so maybe we can handle that with a command specific translator?,0,0,0,0.9840266704559326,0.9927412271499634,0.9900188446044922,0.0,accept,unanimous_agreement
1107292495,10273,let's mention in the top comment that one benefit of this pr is that some tests that were only been implemented using one resp are no doing both (even when not executing the special test mode the pr added).,0,0,0,0.985199809074402,0.9878985285758972,0.9937706589698792,0.0,accept,unanimous_agreement
1107294424,10273,"can you explain why there is a difference? maybe better do it in a comment, for future readers..",0,0,0,0.96917062997818,0.9885945320129396,0.9936507344245912,0.0,accept,unanimous_agreement
1107321710,10273,"whatever we decide, it goes for the change in zset.tcl as well.",0,0,0,0.9879619479179382,0.990010678768158,0.9923281073570251,0.0,accept,unanimous_agreement
1107489245,10273,"let's list all the validations this tool currently does in some comment in the code, and also add a list of additional validations we're considering in the future (i know they are in a todo bullet in the pr, but let's list them here as well)",0,0,0,0.9839539527893066,0.9895792603492736,0.9918809533119202,0.0,accept,unanimous_agreement
1107490389,10273,"please add some comments above big blocks of code in this file (classes, functions) to describe their role. e.g. in this case it's a request parser for the reqres file, right?",0,0,0,0.9879955649375916,0.9927406907081604,0.994516909122467,0.0,accept,unanimous_agreement
1107493051,10273,let's also mention what it technically does (spins up a redis-server and uses redis-cli to get the command docs),0,0,0,0.9885369539260864,0.9893797039985656,0.9942980408668518,0.0,accept,unanimous_agreement
1108054238,10273,"it doesn't run the tests so what does this validator do? if it just validates the schema is valid, we can probably keep it in ci.yml, but we'll also want one job that runs the tests and validates the replies, that one can initially be put in ci.yml, but will later need to be moved to daily or weekly.",0,0,0,0.983877420425415,0.9934188723564148,0.9909831285476683,0.0,accept,unanimous_agreement
1108206195,10273,"yes, it's here just in order to validate the schemas before merging we will move it to daily",0,0,0,0.9840493202209472,0.9914318323135376,0.9943766593933104,0.0,accept,unanimous_agreement
1108208828,10273,"if it just validates the schema, and is quick, maybe we can keep it in ci.yml",0,0,0,0.966182291507721,0.9791191220283508,0.9878833889961244,0.0,accept,unanimous_agreement
1108242903,10273,it's not quick (±12 minutes),0,-1,0,0.8165743350982666,0.5815173983573914,0.8751704692840576,0.0,accept,majority_agreement
1108293680,10273,but this job doesn't run any redis tests. what's taking so long?,-1,0,0,0.6953938007354736,0.6452413201332092,0.8993335962295532,0.0,accept,majority_agreement
1108342355,10273,see the line 89. it calls `./runtest ...`.,0,0,0,0.9876754283905028,0.9937923550605774,0.994130790233612,0.0,accept,unanimous_agreement
1108448698,10273,"ohh, i'm blind! i was looking for it, and couldn't find it.",-1,-1,-1,0.9876670837402344,0.9645775556564332,0.9923847913742064,-1.0,accept,unanimous_agreement
1108454650,10273,i think we want to keep it simple,0,0,0,0.9736193418502808,0.9074892401695251,0.9740620851516724,0.0,accept,unanimous_agreement
1108495875,10273,"the memory overhead is per-command and thus constant by nature, i don't think we should be concerned about it",0,0,0,0.9025230407714844,0.8872315287590027,0.9748834371566772,0.0,accept,unanimous_agreement
1108762943,10273,i'm not sure but i think it has too do with the fact that in resp3 config get returns a dict instead of a list and redis-cli emits it in a single line: resp2: [code block] resp3: [code block],0,0,0,0.9755244851112366,0.9625340104103088,0.971659779548645,0.0,accept,unanimous_agreement
1108765558,10273,we decided that we don't mess with `readraw`,0,0,0,0.9681801199913024,0.9887639284133912,0.9879244565963744,0.0,accept,unanimous_agreement
1111183554,10273,"it's still a lot of memory that's wasted without any reason. imagine hundred of thousands of redis instances running a certain version, all have this overhead that's not used. what's the downside of removing it? a few ifdefs in the python code that generates commands.c?",0,0,-1,0.7521612048149109,0.6431459784507751,0.7912500500679016,0.0,accept,majority_agreement
1113268884,10273,"so far, the script will fail only if one of the replies doesn't comply with its schema. we would also like the script to fail if: 1. one of the commands in commands docs doesn't have the reply_schema field (can't do that for now, we want ci to pass even if some schemas are missing, because we want ti to verify the schemas we do have) 2. the testsuite didn't execute all of the commands (but that includes cluster commands, which are covered in runtest-cluster, we will need to run them both before running the validator) 3. one or more of the branches of the reply schema (e.g. oneof, anyof) was not hit. not sure how to do that, we will need to think of something. let's keep that gh comment unresolved, and handle it when we are near the end (i.e. all commands have a reply_schema + we can run and validate runtest-cluster)",0,0,0,0.967481791973114,0.991361677646637,0.990590751171112,0.0,accept,unanimous_agreement
1113282299,10273,"note that i think the comment can list the both current and future validations (and an indication of what's implement). also, some validations can result in a warning print (without failing the execution), we can change from warning to error later on.",0,0,0,0.9878734946250916,0.9884955883026124,0.9921058416366576,0.0,accept,unanimous_agreement
1113316705,10273,additionalproperties: false,0,0,0,0.911552667617798,0.9895483255386353,0.9949480295181274,0.0,accept,unanimous_agreement
1114288567,10273,why not `oneof`?,0,0,0,0.970998764038086,0.9890402555465698,0.9792654514312744,0.0,accept,unanimous_agreement
1114294411,10273,btw i think there's a bug here... prefixitems talks about all the items (i.e. it only works just because one of the `items` happens to be a `string`),0,0,0,0.9644196629524232,0.6018035411834717,0.926291823387146,0.0,accept,unanimous_agreement
1114364113,10273,when does this happen? store? storedist? let's mention it,0,0,0,0.985949456691742,0.9894422292709352,0.9900552034378052,0.0,accept,unanimous_agreement
1114365742,10273,tbh i feel that this looks better: [code block] even if it's longer,0,0,0,0.8014490604400635,0.8953776359558105,0.8664975762367249,0.0,accept,unanimous_agreement
1114366841,10273,i think it may be easier for client writers as well (i.e. try to use oneof and anyof as far up the tree as we can),0,0,0,0.9793424606323242,0.976008117198944,0.9861437082290648,0.0,accept,unanimous_agreement
1114521538,10273,"""ass""?",-1,0,0,0.9338863492012024,0.7339697480201721,0.9805026650428772,0.0,accept,majority_agreement
1114539963,10273,why did the response transformers come back to redis.tcl? i think i suggested to include / import that file into redis.tcl (i rather not have that code actually sit in that already cluttered file),0,0,0,0.9828709363937378,0.988948941230774,0.9845772385597228,0.0,accept,unanimous_agreement
1114543887,10273,`onbtaoin` typo.,0,0,0,0.9881724715232848,0.9922593235969543,0.9862999320030212,0.0,accept,unanimous_agreement
1114551863,10273,it's a bit odd that the error only happens if you asked for verbose.,-1,-1,-1,0.8110778331756592,0.9718458652496338,0.855976402759552,-1.0,accept,unanimous_agreement
1114630537,10273,how comethe spell checker didn't find it? maybe it'snot scanning .py files?,0,0,0,0.8016453981399536,0.8673709630966187,0.9858026504516602,0.0,accept,unanimous_agreement
1114630935,10273,yeah that's not on purpose i'll fix,0,0,0,0.8883448243141174,0.8784719705581665,0.9617903828620912,0.0,accept,unanimous_agreement
1114632712,10273,"yes, but then there was a problem with cluster/run.tcl including redis.tcl",0,0,0,0.9877744317054749,0.9853886961936952,0.9843483567237854,0.0,accept,unanimous_agreement
1114633511,10273,i think it was because the paths are relative,0,0,0,0.969002366065979,0.9858680367469788,0.9841051697731018,0.0,accept,unanimous_agreement
1114634021,10273,"probably ""as""",0,0,0,0.9655818343162536,0.988896906375885,0.9821313619613647,0.0,accept,unanimous_agreement
1115363883,10273,"don't forget to change to ""daily"" and add `--verbose --fail-commands-not-all-hit` to the validator args",0,0,0,0.9844356179237366,0.9930835962295532,0.9940826296806335,0.0,accept,unanimous_agreement
1115373806,10273,"the spell checker only has a black list of common spelling mistakes, it doesn't complain about anything that's not a real word.",0,0,0,0.9426116943359376,0.6502765417098999,0.8844481706619263,0.0,accept,unanimous_agreement
1115767460,10273,[code block] seems duplicate,0,0,0,0.9604681730270386,0.9788813591003418,0.989276647567749,0.0,accept,unanimous_agreement
1115793752,10273,reminder: investigate why does this test fail?,0,0,0,0.9266413450241088,0.9684097170829772,0.975475251674652,0.0,accept,unanimous_agreement
1118380557,10273,also `exit(1)` if any command from command docs is missing a schema (can be done even before processing the reqres files),0,0,0,0.9897347688674928,0.9950127005577089,0.9952682852745056,0.0,accept,unanimous_agreement
1125642401,10273,can't we just skip both the declaration and initialization?,0,0,0,0.984752118587494,0.9929435849189758,0.9908269047737122,0.0,accept,unanimous_agreement
1125643730,10273,"maybe we wanna run this linter, or another validation in ci.yml (i.e. after moving the full test thing to daily.yaml)",0,0,0,0.9839694499969482,0.9947309494018556,0.9824352860450744,0.0,accept,unanimous_agreement
1126617257,10273,i think this one should be dropped. i don't wanna restrict which fields are in this map,0,-1,0,0.9778589606285096,0.6779916882514954,0.9605875015258788,0.0,accept,majority_agreement
1126623968,10273,"i think that memory stats shouldn't document which fields it has, and leave it free for new ones to be added.",0,0,0,0.9779993891716005,0.9774131178855896,0.9624056816101074,0.0,accept,unanimous_agreement
1126629293,10273,"i'm not sure we wanna list (document) the fields of this command. and if we don't, i'd like to put a comment here that we omitted that on purpose, so someone won't try to add them.",0,0,0,0.9445177912712096,0.5902988314628601,0.8673492074012756,0.0,accept,unanimous_agreement
1128062940,10273,"last thing to do: fix gh workflows (conditional linter in ci, full validation in daily)",0,0,0,0.9014516472816468,0.993255376815796,0.9913088083267212,0.0,accept,unanimous_agreement
1128407557,10273,let's list any non-schema changes in the top comment,0,0,0,0.988586723804474,0.9906424880027772,0.995374858379364,0.0,accept,unanimous_agreement
1128416608,10273,this one was missing from test_helper. please ack that it should be added.,0,0,0,0.9806118607521056,0.9903815388679504,0.9876629710197448,0.0,accept,unanimous_agreement
1128418499,10273,was this uncovered? same question for asking and lastsave?,0,0,0,0.9823189377784728,0.9759817719459534,0.9944568872451782,0.0,accept,unanimous_agreement
1128421427,10273,"i see we have quite a few new tests for coverage, and i guess they're just for various replies not that the command was completely uncovered. maybe we don't have to list each of these in the top comment, but let's at least make sure there's a bullet that mentions we improved test coverage and explain roughly what we did and how",0,0,0,0.8968106508255005,0.9603472352027892,0.9663515686988832,0.0,accept,unanimous_agreement
1128423906,10273,aren't these covered by tracking.tcl? or at least maybe they should be moved there?,0,0,0,0.9854652285575868,0.9950734972953796,0.9885595440864564,0.0,accept,unanimous_agreement
1128427348,10273,"if we execute each of these commands without doing anything, let's at least also validate the response in the tcl test. and maybe make sure the test title explains what we do (although maybe the word ""coverage"" is enough, specifically if it's repeated in other similar tests..",0,0,0,0.984423816204071,0.9898101091384888,0.98716938495636,0.0,accept,unanimous_agreement
1128432815,10273,"let's add the word ""coverage"" here. please go over all the changes in the tests and make sure it's consistent. i.e. i want the reader of that test to understand why it's here (considering the fact it doesn't really test anything)",0,0,0,0.9715975522994996,0.98502916097641,0.9873157739639282,0.0,accept,unanimous_agreement
1128434963,10273,did we write a better test and decided to drop it?,0,0,0,0.9690830707550048,0.9933081865310668,0.9808682799339294,0.0,accept,unanimous_agreement
1128436176,10273,why did we clone that test?,0,0,0,0.9284223914146424,0.9780023694038392,0.9872204065322876,0.0,accept,unanimous_agreement
1128437267,10273,"i'm curious, why was this added?",0,-1,0,0.732546329498291,0.5075265169143677,0.9251940846443176,0.0,accept,majority_agreement
1128530491,10273,"yes, they are, but we skip tracking.tcl when running with --log-req-res (can't remember why but there must be a good reason)",0,0,0,0.9823198914527892,0.9867790937423706,0.986283540725708,0.0,accept,unanimous_agreement
1128534840,10273,"this test does a bit more than coverage and was flaky (i've seen it fail on ""memory is not reclaimed by memory purge"") since this pr is big enough already, i don't want to add tests with ""meat""",-1,-1,0,0.7318522334098816,0.8175840973854065,0.7270951867103577,-1.0,accept,majority_agreement
1128535372,10273,"(it's a new test introduced in one of the commits of this pr, it doesn't exist in unstable)",0,0,0,0.9760040044784546,0.9918953776359558,0.9936762452125548,0.0,accept,unanimous_agreement
1128535751,10273,covergae for evalsh_ro,0,0,0,0.9848280549049376,0.9910881519317628,0.9932267069816588,0.0,accept,unanimous_agreement
1128536226,10273,there isn't a single (deterministic) test that executes decr,0,0,0,0.98625248670578,0.9784391522407532,0.9885685443878174,0.0,accept,unanimous_agreement
1128594561,10273,"so maybe move them to tracking.tcl, but without the ""tracking"" tag, and add a comment as to why...?",0,0,0,0.9772439002990724,0.9940781593322754,0.9892070293426514,0.0,accept,unanimous_agreement
1128599751,10273,"there is one in acl.tcl. but i see i was wrong, it's not a dup of the above test (eval vs evalsha)",0,0,0,0.9075103402137756,0.9820867776870728,0.9889348149299622,0.0,accept,unanimous_agreement
1130656515,10273,"we can drop it, the latency graph valgrind failure was handled in #11892 [code block]",0,0,0,0.9893213510513306,0.9921214580535888,0.9949601888656616,0.0,accept,unanimous_agreement
1130757341,10273,other pr merged to unstable,0,0,0,0.9842423796653748,0.864356279373169,0.9891452193260192,0.0,accept,unanimous_agreement
1131633614,10273,"yes, that looks like a miss.",0,0,0,0.8796614408493042,0.8163953423500061,0.9754223823547364,0.0,accept,unanimous_agreement
693677012,9406,"i think removed is a better term, ""unlink"" can be related to the unlink command [code block]",0,0,0,0.984619438648224,0.987633228302002,0.988292634487152,0.0,accept,unanimous_agreement
693680332,9406,"i think it's better to move this call to the top of the function, before any action is taken. also, please update the comment. ""when a module key is deleted"", the word ""module"" needs to be removed. [code block]",0,0,0,0.9874224662780762,0.9920476078987122,0.9928041100502014,0.0,accept,unanimous_agreement
693684220,9406,"if you agree with the ""removed"" term, please update all the remaining references.",0,0,0,0.985421657562256,0.990218460559845,0.9939258694648744,0.0,accept,unanimous_agreement
698374700,9406,"you can do this, and then there's no need for the `if` below: [code block]",0,0,0,0.9886094331741332,0.978768527507782,0.9957358837127686,0.0,accept,unanimous_agreement
698377459,9406,"i think we need to increment `d->pauserehash` here, and decrement it on the other method. and maybe add assertions in dictadd / dictdelete etc to make sure no one modifies the dict between these two calls.",0,0,0,0.9882028698921204,0.9917207956314088,0.9892125129699708,0.0,accept,unanimous_agreement
698379604,9406,"we wanna move the call for `modulenotifykeyunlink` to be before the dictdelete from the expires dict. one way to do that is to move both `modulenotifykeyunlink` and `dictfindwithplink` to the top of the function, but maybe it's easier and actually better to move the deletion from the expires dict into the `if (de)` block below.",0,0,0,0.9854715466499328,0.9936596751213074,0.9911709427833556,0.0,accept,unanimous_agreement
698380518,9406,"[code block] alternatively, maybe we can say `is being removed`, but i guess it's better to be explicit and state that it's not yet removed.",0,0,0,0.98407781124115,0.9914372563362122,0.9918302893638612,0.0,accept,unanimous_agreement
698381229,9406,"ohh, i see you handled dict rehashing here... well, maybe it's better / safer for dict.c to do that implicitly?",0,0,0,0.9549955129623412,0.9697659015655518,0.9670246243476868,0.0,accept,unanimous_agreement
698382578,9406,"maybe improve the test by actually keeping the value of the key, and validating it in the tcl code?",0,0,0,0.9851321578025818,0.9928221106529236,0.9893194437026978,0.0,accept,unanimous_agreement
698484848,9406,"i think we still need `if`, do i miss something?",0,0,0,0.9628884196281432,0.9646974802017212,0.9817227721214294,0.0,accept,unanimous_agreement
698485124,9406,"there are two `if`, i think we should merge them",0,0,0,0.9839311242103576,0.9772916436195374,0.9893591403961182,0.0,accept,unanimous_agreement
698486584,9406,at first i think we may use `dictfindwithplink` but not use `dictfreeplinkentry`. or we should always use them in pairs,0,0,0,0.9867724776268004,0.9917647242546082,0.9782577157020568,0.0,accept,unanimous_agreement
698499548,9406,can - > can't?,0,0,-1,0.9334386587142944,0.9749870300292968,0.8160642981529236,0.0,accept,majority_agreement
700858855,9406,"i meant we won't need the `if (prevhe)` and it's `else`. i.e. the `prevhe` will **always** contain the address of the pointer that leads to `he`. in theory we can even drop the `he` variable, and just use `prevhe` or rename it to `heref`",0,0,0,0.9805644154548644,0.9930996894836426,0.9897448420524596,0.0,accept,unanimous_agreement
700862919,9406,"looking at name (`dictfindwithplink`) it indeed doesn't imply that you must call the second method. but do we see any reason anyone will ever wanna use one and not the other? if we don't, maybe we can rename it (to `dicttwophaseunlinkfind` and `dicttwophaseunlinkfree`). if we do, then maybe just add some bold comment about caller needing to call `dictpauserehashing` and avoid any modifications to the dict between these calls)",0,0,0,0.980491042137146,0.9925423860549928,0.9901268482208252,0.0,accept,unanimous_agreement
701498752,9406,"if the first node, `plink` points to `prevhe`, other nodes `plink` points to `&prevhe->next`. i think we can't distinguish between them.",0,0,0,0.9844772815704346,0.9779014587402344,0.9849128127098083,0.0,accept,unanimous_agreement
702393249,9406,"i pushed a commit showing what i meant, feel free to revert if you disagree.",0,0,0,0.9187235236167908,0.933082103729248,0.9774230122566224,0.0,accept,unanimous_agreement
702507623,9406,do we need check all types or just string. it is trivial.,-1,0,0,0.5932978987693787,0.9638663530349731,0.9890322089195251,0.0,accept,majority_agreement
702600284,9406,i think just string is enough,0,0,0,0.97753643989563,0.938355565071106,0.97728168964386,0.0,accept,unanimous_agreement
702601449,9406,"i think you have to delete from the expires dictionary before releasing the main dict entry, since they share the key name pointer, and only the main dict does the freeing part.",0,0,0,0.9874309301376344,0.9905343055725098,0.9871429800987244,0.0,accept,unanimous_agreement
702602065,9406,"we need a similar change here (like what we have in the lazy freeing), remove from expires dict only after calling the module callback",0,0,0,0.986524224281311,0.9935399889945984,0.9939464926719666,0.0,accept,unanimous_agreement
703118597,9406,"after move this, i found a bug. in the callback `rm_openkey` calls `lookupkeyreadwithflags` which triggers another expire.",0,0,0,0.9679692387580872,0.9032557010650636,0.9922582507133484,0.0,accept,unanimous_agreement
703418694,9406,"interesting, let's make sure there's a consistent test for both removal of a volatile key that's not yet expired, and one that is (being expired). as a solution, maybe the only way to go is prevent lazy expiry from within this callback? (not only on that one key). i. e. we said we don't allow modifications from within that callback, so that includes lazy expiry. we can set a global flag and use it in expireifneeded to rerun 1 and abort before deleting.",0,0,0,0.9679715633392334,0.9844925403594972,0.9461686015129088,0.0,accept,unanimous_agreement
704298178,9406,i think maybe we should return 0 because we can access expired key.,0,0,0,0.9876222014427184,0.9753370881080629,0.9833180904388428,0.0,accept,unanimous_agreement
704636189,9406,"yes, sorry. we should indeed return 0, since we want the module to be able to access it, and we'll delete it when the notification callback returns.",-1,-1,-1,0.9871604442596436,0.988235592842102,0.978588342666626,-1.0,accept,unanimous_agreement
706724563,9406,"i found `dbunsharestringvalue` calls `dboverwrite`. so when i use `redismodule_stringdma`, it will call `modulenotifykeyunlink` last. i really afraid of this to cause more bugs.",-1,-1,-1,0.9816505908966064,0.6990554928779602,0.9831847548484802,-1.0,accept,unanimous_agreement
706767734,9406,"i think that in the case of of `dbunsharestringvalue`, it may have been wrong to call `dboverwrite` with all it's side effects. i.e. other places that call `dboverwrite` and `setkey` are really logically replacing the existing key with a new one, but this call doesn't intend to do that. i.e. `dbunsharestringvalue` should not call any module hooks, keyspace notifications, and so on (currently does call `modulenotifykeyunlink`). it currently does do `modulenotifykeyspaceevent(notify_removed)`, and possibly calls `mt->unlink`, but since this call is only done in case: [code block] then the `mt->unlink` call is unreachable, and i think the `notify_removed` is wrong. wdyt? i think instead of calling `dboverwrite`, `dbunsharestringvalue` should manually do a small sub-set of it's tasks.",0,0,0,0.978639841079712,0.98917818069458,0.9728216528892516,0.0,accept,unanimous_agreement
706771530,9406,"i agree, it does not really override the data nor deleting anything, it's an internal implementation detail.",0,0,0,0.975357711315155,0.9617546796798706,0.9777293801307678,0.0,accept,unanimous_agreement
708367747,9406,maybe use `suspend` instead of `stop`? or maybe it should be placed next to `active_expire_enabled` and named similarly (`lazy_expire_disabled`)?,0,0,0,0.9866142868995668,0.9954309463500975,0.993239402770996,0.0,accept,unanimous_agreement
708388064,9406,we better use some wait_for_condition here on dbsize or expired_keys rather than assume 100ms is enough.,0,0,0,0.9870331287384032,0.9928152561187744,0.9891758561134338,0.0,accept,unanimous_agreement
715970191,9406,the last thing is how should we do with this. i'm not sure.,-1,-1,0,0.7840940952301025,0.8213327527046204,0.5855188369750977,-1.0,accept,majority_agreement
716009085,9406,what do yo mean? isn't that what i mentioned here: [a link] plus the rename i mentioned above.,0,0,0,0.97517991065979,0.978444278240204,0.9904592037200928,0.0,accept,unanimous_agreement
716012479,9406,i mean this.,0,0,0,0.9031509757041932,0.9617169499397278,0.9836559295654296,0.0,accept,unanimous_agreement
716016957,9406,i may be missing something. it's just a rename. i. e. 1. rename these two functions so that it's clear both must be called. 2. increment and decrement d->pauserehash in there. 3. remove the calls to dictpauserehashing 4. maybe improve or revise the doc comment,0,0,0,0.9834844470024108,0.9926514029502868,0.9868407249450684,0.0,accept,unanimous_agreement
716145218,9406,changes lgtm,0,0,0,0.985706627368927,0.9819820523262024,0.9898213148117064,0.0,accept,unanimous_agreement
979358937,9406,"shall we make an effort to add expired and evicted? if we do, we'll have them only in the master (they'll be del in the replica until we create new commands to covey that intention) wdyt?",0,0,0,0.9860922694206238,0.9919320940971376,0.992004096508026,0.0,accept,unanimous_agreement
979359175,9406,"first, key name cannot be a plain char pointer (it could contain binary data and null chars). it must be an sds or robj. secondly, we certainly need dbid here.",0,0,0,0.9842495322227478,0.9938179850578308,0.989293336868286,0.0,accept,unanimous_agreement
979359382,9406,"i think i was expecting this code block to remain here, and just send a module event instead of a keyspace notification. i.e. we still wanna catch all the execution flows we did before, and rely on our dicttwophaseunlinkfind. it's just that we decided this signal is an event rather than keyspace-notification.",0,0,0,0.9821788668632508,0.9842671751976012,0.97365802526474,0.0,accept,unanimous_agreement
979359804,9406,"i think we want to retain that detailed test.. just move it out from ""keyspace"" unit. or actually, i don't even mind to keep it in the keyspace unit (it's an event about keys).",0,0,0,0.974496603012085,0.9651142358779908,0.9727301597595216,0.0,accept,unanimous_agreement
979909005,9406,how to import `sds` or `robj`?,0,0,0,0.9891239404678344,0.9947540760040284,0.9949659705162048,0.0,accept,unanimous_agreement
979920006,9406,should be a redismodulestring* (a.k.a robj),0,0,0,0.9861294627189636,0.9890748858451844,0.9920065999031068,0.0,accept,unanimous_agreement
979923913,9406,what about dboverwrite? should this event be fired in the same places `modulenotifykeyunlink` is called?,0,0,0,0.9886576533317566,0.9948214292526244,0.9942424893379213,0.0,accept,unanimous_agreement
979939660,9406,but we can't use it here.,0,0,0,0.7095150947570801,0.8110304474830627,0.9793469309806824,0.0,accept,unanimous_agreement
979948817,9406,[code block] maybe we need to move this block up a bit,0,0,0,0.9846610426902772,0.9895246624946594,0.9894720911979676,0.0,accept,unanimous_agreement
980053977,9406,"maybe something in `dboverwrite` is wrong. e.g. in `spopwithcountcommand`, this is really not unlink + add.",0,0,0,0.7770972847938538,0.9824513792991638,0.9498172998428344,0.0,accept,unanimous_agreement
980085460,9406,yes dboverwrite in spopwithcountcommand (and maybe others) should not fire the event dboverwite in setkey (and maybe others) should fire the event,0,0,0,0.9857307076454164,0.9938555359840392,0.9921833872795104,0.0,accept,unanimous_agreement
980381481,9406,"yes, as i commented here [a link] i think we should keep the same approach we had when this was a ksn, and call it from modulenotifykeyunlink. the only difference is that we took the hook out of ksn, but it's still something that needs to be done every time a key is removed from the database. the only thing extra i think it would be nice to add a distinction between delete, overwrite, expired, and evicted.",0,0,0,0.9772168397903442,0.9855867624282836,0.9839714169502258,0.0,accept,unanimous_agreement
981853879,9406,"can you confirm whether i get your point with the lastest commit (without tests and expired evicted). if do, i will continue.",0,0,0,0.9825750589370728,0.9861002564430236,0.9944203495979308,0.0,accept,unanimous_agreement
982179081,9406,"yes, i think that's what i meant. it's actually like your original pr, just shifting from ksn to the event infra. p.s. you should pass `key` to the event struct, not `key-ptr`.",0,0,0,0.9795497059822084,0.9165157079696656,0.9902494549751282,0.0,accept,unanimous_agreement
985190609,9406,let's add a comment to mention why we use stringdma here,0,0,0,0.9873271584510804,0.9914494156837464,0.9947360157966614,0.0,accept,unanimous_agreement
985190743,9406,i guess we wanna assert that the rm_openkey succeeded instead of ignore it?,0,0,0,0.9837188124656676,0.9898325204849244,0.9871301054954528,0.0,accept,unanimous_agreement
985190944,9406,"i don't think i understand the purpose of `nokey` (maybe because this is a superficial review), please add a comment to explain it.",0,0,0,0.6121488213539124,0.917378306388855,0.8498845100402832,0.0,accept,unanimous_agreement
985190988,9406,do we wanna handle other types as well? i.e. read the data? i'm not sure it matters. but i do think we wanted to make sure we can read the expiry information!,0,0,0,0.9211356043815612,0.9142360091209412,0.970586895942688,0.0,accept,unanimous_agreement
985191255,9406,let's test eviction as well,0,0,0,0.9539095163345336,0.9905197620391846,0.9902458190917968,0.0,accept,unanimous_agreement
985191481,9406,"we need to add one integer encoded string, to test the dma thing",0,0,0,0.98679381608963,0.9877055287361144,0.9913715124130248,0.0,accept,unanimous_agreement
985397721,9406,"for other types, it is empty when we receive event like `lpop`.",0,0,0,0.9859163165092468,0.9896501302719116,0.9932644367218018,0.0,accept,unanimous_agreement
985405799,9406,i removed `nokey` and use `redismodule_dictreplacec`.,0,0,0,0.987723708152771,0.9937695860862732,0.9948392510414124,0.0,accept,unanimous_agreement
985406382,9406,"if `kp` is null, the test will fail. so we maybe needn't to assert it?",0,0,0,0.9606577754020692,0.9773260951042176,0.9878256916999816,0.0,accept,unanimous_agreement
985694324,9406,"so maybe drop the `if`, and just let it crash? i think it looks confusing to see the `else` isn't handled. so even if assert isn't needed, maybe it makes things clearer.",0,0,0,0.7481354475021362,0.7348058223724365,0.9369468688964844,0.0,accept,unanimous_agreement
985842450,9406,i think it may be pointless (and hard) to test querying the ttl when the key expires. but it should be easy to query it on normal del and eviction.,0,0,0,0.6800420880317688,0.95676988363266,0.8619135618209839,0.0,accept,unanimous_agreement
985846134,9406,i still don't understand the `nokey` here. is it always 1? maybe at least document the output of the comment?,0,0,0,0.6348756551742554,0.6498365998268127,0.7966567277908325,0.0,accept,unanimous_agreement
985863122,9406,"we may call `hooks.is_key_removed` with a key not in `removed_event_log`, so the `nokey` is 0.",0,0,0,0.9887716174125672,0.9938607215881348,0.9931678175926208,0.0,accept,unanimous_agreement
985873939,9406,so why not rm_replywitherror when there's no entry in the dict?,0,0,0,0.980670928955078,0.9856071472167968,0.9883024096488952,0.0,accept,unanimous_agreement
986343234,9406,i just copy it from `keyspace_event`. we can use `rm_replywitherror` too.,0,0,0,0.9897542595863342,0.9940162897109984,0.9942552447319032,0.0,accept,unanimous_agreement
986559522,9406,"let's clean it up (in both places), i think it's confusing",-1,-1,0,0.9377717971801758,0.8643320798873901,0.5850337147712708,-1.0,accept,majority_agreement
987584613,9406,why do we turn off lazy expire here but not before triggering a module ksn callback? what's the difference?,0,0,0,0.90189129114151,0.9859752058982848,0.9913259148597716,0.0,accept,unanimous_agreement
987585356,9406,the module is not allowed to change the dataset (cause propagation) within this event right? should we document it somewhere?,0,0,0,0.986844539642334,0.9769378900527954,0.9933727979660034,0.0,accept,unanimous_agreement
987586460,9406,or even before calling unlink/unlink2 just a few lines below?,0,0,0,0.9872838258743286,0.9937014579772948,0.9940150380134584,0.0,accept,unanimous_agreement
987587741,9406,should we document that now the module writer can access the key from within unlink/unlink2?,0,0,0,0.989537477493286,0.9946908354759216,0.9953693747520448,0.0,accept,unanimous_agreement
990558135,9406,it's same with triggering a module ksn callback as this event is ksn callback. but i think we should turn on lazy expire after unlink/unlink2?,0,0,0,0.9872178435325624,0.9943392872810364,0.9935564398765564,0.0,accept,unanimous_agreement
996409189,9406,"i'm not certain i understand the discussion here. are we talking about other ksns? the reason we disabled it for this one is that we expect modules to do rm_openkey. in unlink/unlik2 we don't expect or promote it (also, there's no need for it since you have the value)",0,0,0,0.9633272290229796,0.8874938488006592,0.7043258547782898,0.0,accept,unanimous_agreement
996409272,9406,you're referring to rm_openkey? i don't think we wanna promote it.,0,0,0,0.9708795547485352,0.9168115854263306,0.966992199420929,0.0,accept,unanimous_agreement
996433548,9406,"i think the module can know that after right (when it will get the expired/evicted key space notification)? so, it can be a nice addition, but not a must.",0,0,0,0.8864572644233704,0.8815917372703552,0.9829045534133912,0.0,accept,unanimous_agreement
1006786936,9406,i'd like to suggest to rename the function and the argument [code block],0,0,0,0.9828327298164368,0.9866629242897034,0.9940313696861268,0.0,accept,unanimous_agreement
1006804891,9406,any reason we can't just use `expire` instead of expireat (which would make this a lot simpler)?,0,0,0,0.981352150440216,0.9924886226654052,0.98317688703537,0.0,accept,unanimous_agreement
1006947376,9406,we just want to test `assert_equal $expireat [r hooks.pexpireat not-expire]`,0,0,0,0.9875237345695496,0.9943274855613708,0.9944130778312684,0.0,accept,unanimous_agreement
1008675820,9406,"ohh, sorry, for some reason i thought this calls the expireat command",-1,-1,-1,0.98883318901062,0.9877777695655824,0.9910854697227478,-1.0,accept,unanimous_agreement
1008813830,9406,this test fails in 32bit builds. please look into it [a link],0,0,0,0.9772196412086488,0.9628740549087524,0.9854223728179932,0.0,accept,unanimous_agreement
1008828173,9406,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
1008838759,9406,"do you think we should set that flag for all ksn, and also move the decrement to after calling the unlink cb below? maybe we should.. even if we don't document that users can do rm_open, maybe it's better making this safe (also affects read-only rm_call in case someone does it in ksn)",0,0,0,0.9835858345031738,0.9906960725784302,0.987393081188202,0.0,accept,unanimous_agreement
1009089865,9406,i think that if we decide to do it here we should also do it for all ksn. we should just consider if it can be a breaking change (i believe not).,0,0,0,0.9403570294380188,0.9776597619056702,0.9755188822746276,0.0,accept,unanimous_agreement
1009090505,9406,maybe we can give the old value here on the event info? i see we already have it here?,0,0,0,0.9852930903434752,0.9913060069084167,0.9918645620346068,0.0,accept,unanimous_agreement
1009134073,9406,"i don't see why this should be a breaking change, rm_openkey and rm_call will still return the right response, just that the key isn't deleted. the only breaking possibility i can see is if someone is doing any write action from the ksn, in which case lookupkey will return null, the caller will think there's no key and try to create one, and that can crash since the key already exists. but people should not do write operations from ksn, so i think this is safe. can you please extend the effect of this flag to also cover the `unlink`/`unlink2` callback and keyspace notification callback, and mention this change in the top comment.",0,0,0,0.9455685019493104,0.9809455871582032,0.8483604192733765,0.0,accept,unanimous_agreement
1009141881,9406,"you mean so that modules will not have to do rm_openkey (improves performance by reducing the need for lookupkey and a memory allocation). it's interesting, that much of the complexity of what we did (the two phase unlinking), was done so that rm_openkey can still succeed from within that callback, so now we make part of that unnecessary. although some parts (like moving the unlinking from the expires dict are anyway necessary). i guess that if we add a redismodulekey member to the struct, we can remove the keyname and dbid ones (we have rm_getkeynamefrommodulekey and rm_getdbidfrommodulekey)",0,0,0,0.8693434596061707,0.938334584236145,0.9857929348945618,0.0,accept,unanimous_agreement
1009972923,9406,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
1028833965,9406,[code block] let's keep all the tenses consistent. generally we always use past tense.,0,0,0,0.980943500995636,0.991230010986328,0.992735743522644,0.0,accept,unanimous_agreement
1028836257,9406,"i would also slightly prefer to give an opened key to the module as opposed to a db id + key name. as mentioned, it solves the complexity that was introduced later to the two phase unlinking. from an api perspective, i think it also makes it clearer that you aren't supposed to use it with rm_call. was there some conversation about why this was left unresolved?",0,0,0,0.980972409248352,0.9892346858978271,0.929581105709076,0.0,accept,unanimous_agreement
1028838622,9406,[code block] is ki->dbnum ever not set in this flow? i would rather assert since i assume it's always set.,0,0,0,0.9845547080039978,0.992444097995758,0.9931776523590088,0.0,accept,unanimous_agreement
1028842926,9406,what does plink mean in this context stand for? it's a pointer to some link?,0,0,0,0.9735798239707948,0.9902410507202148,0.9917648434638976,0.0,accept,unanimous_agreement
1028844378,9406,are we doing this two phase unlink as an optimization just for performance? it would be good to document that somewhere.,0,0,0,0.9296265840530396,0.9802500009536744,0.9903081059455872,0.0,accept,unanimous_agreement
1028892039,9406,"it's a little odd we introduced flags, but async is not included in the flags.",-1,-1,-1,0.5229824185371399,0.8607923984527588,0.8104278445243835,-1.0,accept,unanimous_agreement
1028962561,9406,"ok, let's give an opened key, users can then get the key name and dbid from that if they want. i don't think we wanna say that you aren't suppose to do rm_call, there are many things for which we don't have a direct api for, and the only way to do them is to run a command. we did do all the work (two phase unlink), in order to make it possible. we should document that write operations are forbidden from the callback though, but i think we already did.",0,0,0,0.9714232683181764,0.9603580832481384,0.9864628911018372,0.0,accept,unanimous_agreement
1028964094,9406,"plink is the reference to the pointer that points to the entry to be removed. it doesn't really matter for the caller, it's just a variable they need to pass to the other function. what's missing here in your mind? just an explanation of what `plink` means?",0,0,0,0.967105269432068,0.9846461415290833,0.9930209517478944,0.0,accept,unanimous_agreement
1028965832,9406,"it was an optimization to avoid dictfind followed by dictdelete. i.e. the first api is a find, and it gives some info to the second one to avoid repeating the lookup. please document the purpose.",0,0,0,0.9866413474082948,0.9850299954414368,0.9929745197296144,0.0,accept,unanimous_agreement
1028968767,9406,"i see we mentioned users are not allowed to modify the key, but maybe instead we should mention that all write operations are forbidden. p.s. we did add `lazy_expire_disabled` so that read-only access to keys won't introduce deletions.",0,0,0,0.986840009689331,0.9935275912284852,0.989675223827362,0.0,accept,unanimous_agreement
1028984028,9406,"the problems are: 1. dbgenericdelete used to take an `int`, and if we change it's purpose, i'm afraid that some backports of commits from branch to branch or other forks will cause an issue without a compilation failure or a conflict. 2. callers of this function have a boolean flag variable `server.lazyfree_lazy_expire`, if we require that they'll translate it to a flag, it'll take a ternary operator and a bit longer code.",0,0,-1,0.5673668384552002,0.7880625128746033,0.5113194584846497,0.0,accept,majority_agreement
1032875383,9406,can you make that change too? i think that's the last thing remaining to merge this (over 1 year old) pr,0,0,0,0.9160082936286926,0.9787499904632568,0.994130551815033,0.0,accept,unanimous_agreement
1032876343,9406,we just use `rm_openkey` and `rm_closekey`? so need create a `ctx`?,0,0,0,0.990048885345459,0.9953110814094543,0.994394302368164,0.0,accept,unanimous_agreement
1032877356,9406,not sure i understand the question. i think redismodulekeyinfov1 should contain a `redismodulekey *key` instead of the current `dbnum` and `key`. then the user can use rm_getkeynamefrommodulekey and rm_getdbidfrommodulekey to get them. you obtain that by calling `moduleinitkey()`,0,0,0,0.9826998710632324,0.99323832988739,0.8541238307952881,0.0,accept,unanimous_agreement
1032906641,9406,"we need to create `ctx`, we need a `client` object.",0,0,0,0.987833857536316,0.9916483163833618,0.99375981092453,0.0,accept,unanimous_agreement
1032917424,9406,"yeah, `modulefireserverevent` does that for other events as well",0,0,0,0.9864110350608826,0.9938054084777832,0.9930243492126464,0.0,accept,unanimous_agreement
1034800917,9406,"i understand we need that intermediate struct since we can't open the redismodulekey in modulenotifykeyunlink. i.e. we must do it per module, after we have a context, and that in turn means that we can't create the redismodulekeyinfov1 in modulenotifykeyunlink and just pass it forward in modulefireserverevent like we do for redismodule_event_flushdb. but then, since we fill the actual struct we communicate to the module in modulefireserverevent then i think it should be the one to fill the version fields (not modulenotifykeyunlink).",0,0,0,0.9708974957466124,0.9728382229804992,0.9847292304039,0.0,accept,unanimous_agreement
1034803435,9406,"i think it's a bit off to place this struct declaration on the stack inside the `if` and use that memory outside. i know it works, but still, let's move it to the top of the function",0,0,0,0.977506160736084,0.9652310609817504,0.5755148530006409,0.0,accept,unanimous_agreement
1034809917,9406,"maybe we should still keep some test doing rm_openkey, or rm_call so that we can demonstrate that the key was not yet removed from the database and that doing dictfind won't mess things up.. i.e. we went through so much in order to support it, let's keep it covered by a test (in addition to using the key that's provided by the callback)",0,0,0,0.96034175157547,0.9935110211372375,0.9796619415283204,0.0,accept,unanimous_agreement
1034847300,9406,in fact it is wrong. i just fix it.,-1,0,0,0.7767571210861206,0.5639121532440186,0.9453436732292176,0.0,accept,majority_agreement
1187481978,9406,anyone understands / remembers why we used redismodule_write here?,0,0,0,0.9831351041793824,0.9938188195228576,0.993870496749878,0.0,accept,unanimous_agreement
1187547164,9406,seems like it should be read since the module should not try to modify the key in the cb of this event,0,0,0,0.9844613671302797,0.9894724488258362,0.9898701310157776,0.0,accept,unanimous_agreement
1238962032,9406,"yeah, i think i was just confused reading it.",-1,-1,0,0.9109618663787842,0.6470293998718262,0.5416930913925171,-1.0,accept,majority_agreement
703096543,9462,we stick pointers with the variable [code block],0,0,0,0.9876476526260376,0.9918135404586792,0.9944251775741576,0.0,accept,unanimous_agreement
703096695,9462,[code block] spaces go around the conditional.,0,0,0,0.987779974937439,0.9913705587387084,0.9935894012451172,0.0,accept,unanimous_agreement
703097023,9462,"my understanding is that blocked commands will get double counted, since it's here and in the unblocking code. it should probably just show up once?",0,0,0,0.970481812953949,0.9763710498809814,0.9879512190818788,0.0,accept,unanimous_agreement
703097295,9462,[code block] { goes on the previous line. the exception to this is if the if/while statement is multi-line,0,0,0,0.985486388206482,0.993665337562561,0.9945776462554932,0.0,accept,unanimous_agreement
703097746,9462,"would also prefer to drop unlikely unless we can observe the performance. generally compilers either do it right and cpus have branch prediction anyways, but you may know better than me about performance :)",1,1,1,0.6258904933929443,0.9753060340881348,0.9702126383781432,1.0,accept,unanimous_agreement
703098042,9462,"would prefer just to retain just `!c->latency_histogram`, since that is the real conditional. i suppose this might also be used to hide the histogram after calling reset stats, but would prefer to reset the state completely.",0,0,0,0.9852077960968018,0.9922671914100648,0.9905672669410706,0.0,accept,unanimous_agreement
703098122,9462,we basically never add information after the headname. [code block],0,0,0,0.9815188646316528,0.988892138004303,0.9865925908088684,0.0,accept,unanimous_agreement
703098301,9462,"missing `if (sections++) info = sdscat(info,""\r\n"");` here",0,0,0,0.9845557808876038,0.9939513206481934,0.994520366191864,0.0,accept,unanimous_agreement
703098852,9462,"there was a bug in redis-py at somepoint because it was doing string parsing based on `:`, since it was using that to split the key/value, but instead it was truncating most of the value. would prefer to use some other keyword here.",0,0,0,0.9627938270568848,0.9639025926589966,0.938374161720276,0.0,accept,unanimous_agreement
703099245,9462,"i have a minor preference for resetcommand resetting the state back to the launch state, so should we instead free this and set it to null? then there is an online way to reduce the memory cost.",0,0,0,0.9459015727043152,0.9811872243881226,0.9926727414131165,0.0,accept,unanimous_agreement
766844610,9462,"will try out both variations on the oss benchmark automation. if we see no real improvement on the unlikely usage, lets remote it :)",1,1,1,0.933832824230194,0.9785168766975404,0.9232680201530457,1.0,accept,unanimous_agreement
766846371,9462,:thumbs_up: agree. doing the change on the next commit,0,0,1,0.9272183179855348,0.8816455602645874,0.9620668292045592,0.0,accept,majority_agreement
772989626,9462,"agree, and fixed in latest push :)",1,1,0,0.9575175046920776,0.9835378527641296,0.7632482647895813,1.0,accept,majority_agreement
775631792,9462,your 100% correct. addressed it in the latest commit and added a test case for it.,0,0,0,0.9783747792243958,0.8667625188827515,0.8571802973747253,0.0,accept,unanimous_agreement
775659807,9462,"info section names are not sub-commands, and are usually not shown in uppercase",0,0,0,0.9852070212364196,0.9832723140716552,0.9836883544921876,0.0,accept,unanimous_agreement
775659983,9462,"""nodes"" means ""cluster nodes""? let's state that",0,0,0,0.9863932728767396,0.9931822419166564,0.991821825504303,0.0,accept,unanimous_agreement
775660425,9462,we usually have a blank line between configs. [code block],0,0,0,0.9875427484512328,0.989941418170929,0.994433581829071,0.0,accept,unanimous_agreement
775660652,9462,maybe name it `latency-tracking`?,0,0,0,0.9874639511108398,0.9940075874328612,0.9888457655906676,0.0,accept,unanimous_agreement
775661168,9462,comment outdated.. (but now i know where you copied it from :smile: ),-1,1,1,0.7624795436859131,0.9753307104110718,0.9942818880081176,1.0,accept,majority_agreement
775661640,9462,"i think this mechanism of `reset` and `append` is only relevant for `save` since due to backwards compatibility, it was able to handle multiple config file lines doing append each time. what i mean is that you can init some variable on the stack here, or apply it to the server struct directly",0,0,0,0.9839418530464172,0.9898019433021544,0.9885864853858948,0.0,accept,unanimous_agreement
775661946,9462,"why do we need to allow an empty config to avoid the defaults being used? we have a boolean config for that. maybe we wanna abandon the boolean config? anyway, if there's a need for this empty config, we may wanna document it in the conf file, if not let's disallow it.",0,0,0,0.9840294718742372,0.9904257655143738,0.9768274426460266,0.0,accept,unanimous_agreement
775662742,9462,"we can move that into the loop, and then there's no need for the conditional one at it's end",0,0,0,0.9852902889251708,0.9775847792625428,0.9894925355911256,0.0,accept,unanimous_agreement
775663090,9462,"as i mentioned in config.c, there's no need for this, it can be embedded in the parser, and in that case we won't need an incremental realloc.",0,0,0,0.9873389005661012,0.9923582673072816,0.9943081736564636,0.0,accept,unanimous_agreement
775663514,9462,"indentation is broken. considering it's a multi-line, and not inside some struct, maybe move it to before the line, in which case you'll have longer lines.",0,0,0,0.974445641040802,0.812599241733551,0.939407765865326,0.0,accept,unanimous_agreement
775663939,9462,space missing between the `if` and the `(` same in the other line above..,0,0,0,0.9560330510139464,0.9933308959007264,0.9779406785964966,0.0,accept,unanimous_agreement
775665368,9462,"i think the comment (and maybe the function name) is missing the indication that this is part of the info command. the comment should mention it, and maybe the function name should have some similarities to `genredisinfostring`",0,0,0,0.9865554571151732,0.9941900968551636,0.9727721214294434,0.0,accept,unanimous_agreement
775665484,9462,similar comment as the above function with regards to it's name and comment being related to `genredisinfostring` [code block],0,0,0,0.9881855249404908,0.9901071786880492,0.9942187070846558,0.0,accept,unanimous_agreement
775666296,9462,"considering info will some day be resp, and we don't wanna limit our options, maybe the histogram should be a separate line? i.e. instead of `latency_hist_usec_ :calls=%d, histogram=[(%d:%d),(%d:%d)]` [code block] it doesn't bind related fields together, but it does keep a consistent format with other info fields.",0,0,0,0.9781846404075624,0.9919151067733764,0.9913727045059204,0.0,accept,unanimous_agreement
775667106,9462,"this is a new concept (one section filter name, producing two sections. is there any reason not to include all the info in one section? (which has identical, one word name, which is exactly the same as it's filter string)",0,0,0,0.9840996265411376,0.989329755306244,0.9819213151931764,0.0,accept,unanimous_agreement
775667312,9462,remind me how much memory this consumes? maybe we should free it when the config is disabled?,0,0,0,0.9698901176452636,0.9852149486541748,0.9914616346359252,0.0,accept,unanimous_agreement
775667518,9462,let's give this one the same prefix of the config it controls (with a `_len` suffix). i vote for `latency_tracking_percentiles_len`. p.s. maybe the comment should state that this is a config.,0,0,0,0.9822549819946288,0.9885143637657166,0.9922864437103271,0.0,accept,unanimous_agreement
775667926,9462,maybe we can somehow add one test that actually measures latency? compare a ping and a debug sleep,0,0,0,0.9809362888336182,0.990528404712677,0.9855002760887146,0.0,accept,unanimous_agreement
775668500,9462,"ohh, i see the top comment describes memory usage..",0,0,0,0.9256879091262816,0.8946823477745056,0.9814183115959167,0.0,accept,unanimous_agreement
775969712,9462,"i know that we currently do not account the blocked_us , but maybe we should explicitly set the sample to be c->duration+reply_us?",0,0,0,0.9887433052062988,0.9931852221488952,0.9915493726730348,0.0,accept,unanimous_agreement
775971343,9462,maybe we can test the stats for modules 2?,0,0,0,0.9835822582244872,0.9942493438720704,0.9901258945465088,0.0,accept,unanimous_agreement
775994968,9462,"i prefer keeping this together on a single line. when we move it to resp, i imagine we will still want to group the histogram as a map (or list since it's ordered) under the top level command name. we could still flatten it though, so that is parsed naturally by clients. [code block] you just have to know the first argument is the calls, and the remaining are the histogram classes.",0,0,0,0.9682921171188354,0.9840890169143676,0.9706747531890868,0.0,accept,unanimous_agreement
776102872,9462,"i feel like this is self explanatory information about configs, not sure it's needed.",-1,0,0,0.9348841309547424,0.7550363540649414,0.921695590019226,0.0,accept,majority_agreement
776103453,9462,"i feel like we would save a lot of trouble by just having this be a string config that was comma separated instead of space separated. we could keep the string stored in the server struct for rewrite and get, it's not that many bytes, and on set and load we could parse the string and set it.",0,0,0,0.7723281383514404,0.9491001963615416,0.9202064275741576,0.0,accept,unanimous_agreement
776103748,9462,"we might instead omit this additional boolean flag entirely and just use`latency-track-percentile`. if latency-track-percentile is set to an empty string, it disables latency tracking.",0,0,0,0.986583173274994,0.9930731654167176,0.9927635788917542,0.0,accept,unanimous_agreement
776103922,9462,we should validate all the percentiles before starting to apply them. we don't want them half applied.,0,0,0,0.733535647392273,0.9453454613685608,0.9889413714408876,0.0,accept,unanimous_agreement
776104505,9462,"this is still here, i feel like the solution of trying to flatten the structure would be a better resolution though.",0,0,0,0.6791541576385498,0.9739974141120912,0.9487565159797668,0.0,accept,unanimous_agreement
776104583,9462,this is weirdly indented. [code block],-1,-1,-1,0.9725147485733032,0.979941725730896,0.981616735458374,-1.0,accept,unanimous_agreement
776104926,9462,this is still here.,0,0,0,0.9808872938156128,0.979278326034546,0.9941073656082152,0.0,accept,unanimous_agreement
776105931,9462,what was the result of this?,0,0,0,0.9035205245018004,0.991098940372467,0.984411358833313,0.0,accept,unanimous_agreement
776106703,9462,or perhaps just a simpler format would suffice? [code block] then when we move to resp it would look like [code block],0,0,0,0.9847954511642456,0.992521345615387,0.9912961721420288,0.0,accept,unanimous_agreement
776317292,9462,"isn't that what we already have? well, i guess that's ok.. we'll have to remember going forward that `[]` is the way to add nesting into info lines.",0,0,0,0.972908616065979,0.9499931931495668,0.976612389087677,0.0,accept,unanimous_agreement
776318578,9462,"we already have other mechanisms we should follow, like `client-output-buffer-limit`, `save`, and `oom-score-adj-values`. i think we should mimic these (all use `multi_arg_config`)",0,0,0,0.9837201833724976,0.9904589653015136,0.9924956560134888,0.0,accept,unanimous_agreement
776318830,9462,that's what i was arguing too.. similar to `save` config.,0,0,0,0.7183175086975098,0.961119532585144,0.9855768084526062,0.0,accept,unanimous_agreement
776319388,9462,"it might be a good idea, but iirc, the config infra handles rollback now. -steinberg correct me if i'm wrong.",0,1,0,0.939706325531006,0.59017413854599,0.9292972087860109,0.0,accept,majority_agreement
776320102,9462,"you removed one, and kept the other, please remove the other header print completely (including `sections++` etc)",0,0,0,0.988455295562744,0.9912938475608826,0.9952712655067444,0.0,accept,unanimous_agreement
776326041,9462,no. addressed it in the latest commit,0,0,0,0.9796955585479736,0.9873138070106506,0.9933660626411438,0.0,accept,unanimous_agreement
776331484,9462,eheh. fixed it on the new commit,0,0,1,0.9841347336769104,0.7117965817451477,0.9222820401191713,0.0,accept,majority_agreement
776332168,9462,agree. renamed it on latest commit,0,0,0,0.9761655926704408,0.9902439713478088,0.9750604629516602,0.0,accept,unanimous_agreement
776332502,9462,fixed in latest commit,0,0,0,0.9856232404708862,0.987710416316986,0.9884287714958192,0.0,accept,unanimous_agreement
776332609,9462,addressed in latest commit,0,0,0,0.9862403273582458,0.988925039768219,0.992757260799408,0.0,accept,unanimous_agreement
776337411,9462,"ohh, i see what madelyn meant. i.e. the format inside the `[]` is the same one as outside of them. i.e. `,` separated pairs using `=`. well, i guess that's a better option. p.s. another option is to completely exclude all of that from the info command, and put it in the latency command. if this data is mainly meant to be processed by humans and / or specific code designed to parse that data, then a new sub-command in latency command is preferred. if on the other hand we intend for generic monitoring systems to capture that data (like someone feeding all of redis's info fields into prometheus), then info is the right place (e.g. that's one place that the memory stats command got wrong imho). but considering that generic monitoring systems won't be able to handle that anyway (since it's a compound field), then maybe info is the wrong place for it. wdyt?",0,0,0,0.9513550996780396,0.9458319544792176,0.8912972211837769,0.0,accept,unanimous_agreement
776338712,9462,"and there might be users that are not interested in the percentiles but want to keep track of latency for the histograms exporting and merging. meaning they don't want ""latency by percentile distribution"" but only the ""cumulative distribution of latencies"". can we keep the config to enable disable this latency tracking and the config for percentiles? do you agree?",0,0,0,0.983061671257019,0.9847197532653807,0.9936762452125548,0.0,accept,unanimous_agreement
776340299,9462,the total size per histogram should sit around 40 kib. we only allocate those 40kib when a command was called for the first time.,0,0,0,0.9875071048736572,0.9919005632400512,0.9929827451705932,0.0,accept,unanimous_agreement
776353617,9462,what is the argument though? they are more annoying to orchestrate around since they have to be applied specially. we don't have to stick with a bad convention.,-1,-1,-1,0.9532515406608582,0.974859893321991,0.9605996012687684,-1.0,accept,unanimous_agreement
776365095,9462,"it's no longer annoying.. it's is now supported by the infrastructure (it can split space separated strings from the config file). it would be ugly that we have several ways to set configs that require multiple arguments (one using a generic infrastructure we created, and one that bypasses it). i would even consider the one that bypasses the infra, an ugly hack. storing a string in the server struct and parsing it at runtime is not an option imho. and storing both the string and the parsed array in the server struct is redundant. i rather re-compose the string from the array when needed, than keep two copies of the same data.",-1,-1,-1,0.9838390350341796,0.9898430705070496,0.942224621772766,-1.0,accept,unanimous_agreement
776368105,9462,so should we bother to free it if the config is disabled? assume a normal user uses some 20-40 commands (that could be some 1.5mb). i guess not a big price to pay (user will set the config and get that memory back on the next restart). wdyt?,0,0,0,0.9749765992164612,0.9679526686668396,0.9782856702804564,0.0,accept,unanimous_agreement
776377658,9462,"i meant it's annoying for users, every other parameter is a key/value pair except the couple of multi-arg ones. some clients don't support it, and there is an ugly hack in our system to handle them since the rest of the system is a key/value. i expect other systems have ugly hacks as well. i'm pretty sure the amount of code would be less if we kept around the string representation, since we don't have to do all the work to reconstruct the values and special printing. i'm not sure duplicate value is all that important, we're already spending a lot of memory on this feature. there is also another case of this in bio_cpulist, which does basically what i'm suggesting.",-1,-1,-1,0.9853819608688354,0.9887114763259888,0.9825829267501832,-1.0,accept,unanimous_agreement
776380510,9462,"`bio_cpulist` is an ugly hack.. config file parsing won't even detect a syntax error there. (probably crash on assertion or exit later on). which is arguably ok since it's an immutable config. clients should not have any problem with multi-arg configs, since we take a single string and split it. so from their perspective, both the options we're debating are the same (except for the separator char maybe)",-1,-1,-1,0.9222292304039,0.7759624719619751,0.9891303777694702,-1.0,accept,unanimous_agreement
776381212,9462,agree with about splitting this information into two places: - info will hold the per-command percentile data that is easily parsed and integrated into monitoring tools. the `latency-tracking-info-percentiles` configuration changes the default info exposed percentiles. - latency will hold the histograms and will also enable to quickly compute a set of quantiles on the fly for investigation purposes. - latency histogram [commandname] : if no commandname is passed then all then we reply all histograms to the client - latency percentile commandname percentile ... will enable to calculate on the fly any percentile for a specific command agree?,0,0,0,0.974208116531372,0.9924936294555664,0.9762143492698668,0.0,accept,unanimous_agreement
776384438,9462,"the separator character is the only difference, and it's important because the start up arguments are parsed with the same delimiter. sure, bio_cpulist should probably have validation, but i don't think that explicitly makes it a hack.",0,0,0,0.9653642773628236,0.955879807472229,0.974619448184967,0.0,accept,unanimous_agreement
776384901,9462,i'm good with that.,1,1,1,0.7352811694145203,0.7166950702667236,0.5823140144348145,1.0,accept,unanimous_agreement
776388159,9462,"a bit more reasoning behind the above conclusion (form a talk i had with filipe). * the histogram is too verbose for info, and may be required only in hands-on investigation * is it unlikely that a monitoring tool (that's only capable of working with info) will handle these histograms anyway (since the structure is nested) * so moving these histograms to a separate commands let's us output that data in resp, or maybe also add a human-readable variant (maybe latency histogram-doctor :smile: ) about the percentile: * it is calculated on report-time, that's why the config that controls it was added an `info` tag to it's name * it is much less verbose, and more useful for a quick glance * it's not a compound format, so any monitoring tool that's able to handle `info keyspace` and `info commandstats` can extract that data. * since we can report other percentiles at runtime at will, we can add a command to output that, and the config only controls what's in info. so few suggestion for changes in filipe's last post: * `latency histogram [command ]` * `latency histogram-report [command ]` (the human readable version) * `latency percentile [command ] [percentile ] ...`",1,0,1,0.5373254418373108,0.9346112608909608,0.9512449502944946,1.0,accept,majority_agreement
776390408,9462,"not sure i understand your argument about startup args delimiter.. maybe give an example. the trick in bio_cpulist is much less severe because that's an immutable argument. anyway, i feel strongly that we have an infrastructure, and several configs that use it, and that's what we should aim for... iirc the cpulist feature was a pr by an ""outsider"" that was merged without much of a review. if we still disagree, i guess we need a tie breaker. -steinberg ?",-1,0,0,0.5964505076408386,0.5418897271156311,0.5878223180770874,0.0,accept,majority_agreement
776396373,9462,moved to `latency_tracking_info_percentiles` and `latency_tracking_info_percentiles_len` given the discussion about the info topic.,0,0,0,0.987412929534912,0.9950803518295288,0.9933816194534302,0.0,accept,unanimous_agreement
776412056,9462,i've added a specifc test to verify that indeed the config is rolled back it's in `latencystats: bad configure percentiles`.,-1,0,0,0.9582170844078064,0.9902455806732178,0.8095756769180298,0.0,accept,majority_agreement
776425721,9462,"added ""latencystats: measure latency"" test, and also included the percentile check on the module's ""blocked clients time tracking..."" test.",0,0,0,0.9875447750091552,0.9944760203361512,0.9939051270484924,0.0,accept,unanimous_agreement
776426293,9462,on the latest commit i've added the latency percentiles check to one of the modules test. this should do it: [a link],0,0,0,0.9849741458892822,0.979392111301422,0.9897770285606384,0.0,accept,unanimous_agreement
776470685,9462,resolving giving the discussion on [a link],0,0,0,0.9767760038375854,0.9862500429153442,0.987152636051178,0.0,accept,unanimous_agreement
776566511,9462,"sure, for start up args you need to pass in the start up arguments as individual values like `redis-server --tracking-percentiles 1 2 3` compared to the config set which takes it as a single space delimited string `config set ""1 2 3""`. we had special code that assumed that all configs were key/value pairs, which works for the config set case but breaks since if you try to do `redis-server --tracking ""1 2 3""` it will break. so let me just clarify my two points: 1. i don't like multi-arg configs, i think they are hacky and the infrastructure around them was more for getting all the code to be generic more so than they intrinsically make sense. i think all configs should be key/value pairs. i dislike space as a delimiter since that is also what is used for the config file to split the name of the config. 2. i think just keeping a copy around of the string representation of a config you serialize into another form isn't that big of a deal. it simplifies the get/rewrite code path as you don't have to deserialize the value, and fits in with the ""apply function"" that is implemented. requirepass is an example of another config that does something similar, we transform it into a hash when we set it, but we keep it around the plaintext version in the server struct to easily do rewrite/get. i don't really feel strongly about it, so if you still disagree feel free to keep it as is. i still don't understand your point of view though.",0,0,0,0.9493519067764282,0.9044256806373596,0.9240962862968444,0.0,accept,unanimous_agreement
776587626,9462,"deferred reply has overheads (small packets, and lots of write syscalls). is it possible to predict the size of the array easily? or even make a quick counting?",0,0,0,0.9789562821388244,0.9451291561126708,0.9824497699737548,0.0,accept,unanimous_agreement
776587688,9462,shouldn't this be a map?,0,0,0,0.9622122645378112,0.9896390438079834,0.9861337542533876,0.0,accept,unanimous_agreement
776587790,9462,"this is the outer loop, so the damage of deferring reply is low (one syscall per command)",0,0,0,0.9821940660476683,0.9902260899543762,0.9901275634765624,0.0,accept,unanimous_agreement
776587912,9462,"shouldn't that one be a map (command name is the field, and the array of histogram entries the value)? in that case, we should do the same on the other variant (the one that takes command names as input). p.s. i think we can make these two share more code in some way. i.e. they're both doing exactly the same, with the exception of the loop. i don't have a concrete suggestion. just the desire to find something.",0,0,0,0.9335148930549622,0.9611923098564148,0.9813193082809448,0.0,accept,unanimous_agreement
776587981,9462,"maybe rename this to have the word ""single"" (where the other one had ""all).",0,0,0,0.9818040132522584,0.9931190013885498,0.978116512298584,0.0,accept,unanimous_agreement
776588037,9462,"maybe these should have a ""human"" suffix to make it clearer what's the difference.",0,0,0,0.9684505462646484,0.9882668852806092,0.9599671959877014,0.0,accept,unanimous_agreement
776592440,9462,"ohh. startup arguments by cli... i didn't think of that.. i think it should be the right approach to have `redis-server --tracking ""1 2 3""`, and not `redis-server --tracking 1 2 3`. and i was guessing that this would implicitly work (with the new infrastructure). my only concern is that if currently `redis-server --save ""3601 1 301 101""` is not working while `redis-server --save 3601 1 301 101` is working, then i wouldn't want to make a breaking change. but testing redis 5.0, 6.0, and 6.2 shows that neither of the methods is working. while on unstable, the later (without `""`) is working, and the first (with `""` is not working. i think we should fix that, and considering it wasn't working at all in any of the released versions, that won't be a breaking change. -steinberg please confirm",0,0,0,0.6641170978546143,0.8620367646217346,0.642783522605896,0.0,accept,unanimous_agreement
776614963,9462,"looking at the current implementation it seems like it'll work without merging the config's parameters into a single arg (without adding `""`). i can change this if we want, but maybe there's no need to. wdyt?",0,0,0,0.9847372174263,0.966151475906372,0.9837630987167358,0.0,accept,unanimous_agreement
776648674,9462,"then how can it process the next config? by looking for `--`? what if some config has `--` as part of its value? first let's confirm that this was never working in any of the released versions (i.e. not a regression of 6.2 or 6.0). then i think that it'll make sense to use `""` as that's a single argument as a single config. i.e. same as config set takes one bulk argument as value, and not multiple bulks",0,0,0,0.98395836353302,0.98946613073349,0.9911632537841796,0.0,accept,unanimous_agreement
776650521,9462,the current code looks for an arguments that starts with `--` and then assumes it's a config name. then all arguments after it (that don't start with `--`) are parameters to that config. if a parameter to a config starts with `--` then we're screwed. i'll check the old versions.,-1,0,-1,0.8438666462898254,0.6128859519958496,0.9592239260673524,-1.0,accept,majority_agreement
776666266,9462,in both 6.0 and 6.2 the logic is the same as today a cli config argument receives it's parameters as multiple command line arguments as long as it doesn't encounter a `--`. so i think we can't break the existing logic.,0,0,0,0.986031174659729,0.9885082840919496,0.9889829754829408,0.0,accept,unanimous_agreement
776682728,9462,"two questions: 1. what if the first argument is using `--`? e.g. `redis-server --dbfilename --mydb.rdb --rdbcompression no` 2. maybe for multi_arg configs, we can still break a single argument into several if we find spaces (seems consistent with config command). assuming 1 is ok, then we can let users work around that limitation of searching for `--`, by breaking with spaces. e.g. `redis-server --dbfilename ""--odd folder name--"" --loglevel verbose` will work (as it does today), but also, if there was a similar multi-arg config that could expect `--` in input it'll work `redis-server --replicaof ""--no-- --one--"" --loglevel verbose` i.e. `replicaof` is a multi-arg config, and it'll be able to take arguments that it can't today. if we do that, both `redis-server --save 20 1 --loglevel verbose` and `redis-server --save ""20 1"" --loglevel verbose` will work.",0,0,0,0.98326575756073,0.9918819069862366,0.9898923635482788,0.0,accept,unanimous_agreement
776802520,9462,renamed it to `latencyspecificcommandsfillcdfhuman` given it accepts 1 or more commands.,0,0,0,0.9866987466812134,0.9952722191810608,0.9943291544914246,0.0,accept,unanimous_agreement
776806434,9462,yes indeed. made the change on the latest commit. new look: [code block],0,0,0,0.9829279780387878,0.9769701957702636,0.9848167300224304,0.0,accept,unanimous_agreement
776806715,9462,indeed. addressed in the latest commit,0,0,0,0.9841960668563844,0.9939348101615906,0.9934260845184326,0.0,accept,unanimous_agreement
776809155,9462,to predict the array/map len we would need to go through the histogram iterator twice given we don't output the empty buckets. at max we will have 30 buckets. do you think we should do it?,0,0,0,0.9817689657211304,0.9666281938552856,0.9904268980026244,0.0,accept,unanimous_agreement
776812063,9462,"actually, redis-cli shows the resp one pretty readable. maybe we can drop the human subcommand? the only disadvantage is that there are multiple lines per command, but it is actually more readable that the one liner... maybe there's an advantage to have one that outputs csv? i guess that's the responsibility of redis-cli to convert (we have the new `--json`). i'm leaning towards dropping the human format.",0,0,0,0.7308486700057983,0.9532134532928468,0.8926833868026733,0.0,accept,unanimous_agreement
776813950,9462,"the alternative is that each command has its own write system call and it's own packet.. unless #9934 will help. we can keep the simple form, and maybe optimize in the future.. is suppose that this command doesn't require high efficient anyway, so shorter code is preferred.",0,0,0,0.9813836216926576,0.9826650619506836,0.987687647342682,0.0,accept,unanimous_agreement
776824421,9462,based on: and i'll add a note on the pr description. agree that for now the simpler the better,0,0,0,0.9434778690338136,0.9552485942840576,0.9840670824050904,0.0,accept,unanimous_agreement
776828106,9462,the less code the better imho. lets drop it :),1,1,1,0.9497418403625488,0.99437415599823,0.5938724875450134,1.0,accept,unanimous_agreement
777252138,9462,blank line between configs [code block],0,0,0,0.98343163728714,0.9894616007804872,0.9927138686180116,0.0,accept,unanimous_agreement
777252476,9462,"iirc maddy also commented that she thinks mentioning the config command here is excessive. i think you can delete these 3 lies here, and two in the next config",-1,0,0,0.7336800694465637,0.8733435273170471,0.9753310680389404,0.0,accept,majority_agreement
777252847,9462,"since we no longer have the human variant, we should drop the reference for resp i the function names and comments.",0,0,0,0.9852500557899476,0.9883588552474976,0.9932283759117126,0.0,accept,unanimous_agreement
777253396,9462,"i'm not sure there's a point to add an error reply inside the array (we almost never do that, (except in exec) we could add nils or 0 arrays, to fill the spots in the outer/ordered array, but what i now notice is that this function replies with an array where the other function replies with a map. i think we must converge them to use the same format. which you'd be a map, and we can just skip adding entries to the ones we can't find data for, or no such command.",0,0,0,0.8431301712989807,0.8250043392181396,0.969241738319397,0.0,accept,unanimous_agreement
777253579,9462,no longer needed,0,0,0,0.9583399295806884,0.9708465337753296,0.9761536717414856,0.0,accept,unanimous_agreement
777254056,9462,we're tracking `c->duration + blocked_us + reply_us` on this one. so all account for.,0,0,0,0.9882133603096008,0.9918040037155152,0.9951273202896118,0.0,accept,unanimous_agreement
777259607,9462,i've moved to replying an empty map for commands that don't exist. agree?,0,0,0,0.9838947653770448,0.6257250308990479,0.9839824438095092,0.0,accept,unanimous_agreement
777262246,9462,i've tested without the unlikely and indeed no noticeable change. removed it. numbers without `unlikely`: [code block],0,0,0,0.9859813451766968,0.9846853017807008,0.9922005534172058,0.0,accept,unanimous_agreement
777311498,9462,"i'm still uncomfortable with this (returning an entry in the map with an unknown command). i went looking for what's done in command info. there, the reply is an array (of the requested size), that holds null entry for unknown commands, and a nested array entry for known ones, in which the first entry is the command name. here we traded the outer array for a map (which despite what the resp3 spec says, should be considered unordered since that's how clients are gonna use it). regardless of the ordering, unlike the solution in command info, here we actually reply the invalid command name to the user, which is odd. i think we should just skip these and not include them in the reply at all.",-1,-1,-1,0.8847211003303528,0.9303798675537108,0.9804460406303406,-1.0,accept,unanimous_agreement
777311626,9462,line comment (change to `/*`),0,0,0,0.9881771206855774,0.9901657700538636,0.9937362670898438,0.0,accept,unanimous_agreement
777312167,9462,"i'm guessing we should skip these too. the only reason i can think of for replying with an empty map is to distinguish these from unknown commands, but with your current code they're the same, so i guess that's not the concern, but the ordering of the reply. another possible concern is that clients will be able to more easily parse this the same as non-empty ones, but for that we need to create the nested map, with the `calls` field set to 0.",0,0,0,0.9700849652290344,0.9853113889694214,0.985878884792328,0.0,accept,unanimous_agreement
777312828,9462,leftover,0,0,0,0.9792333245277404,0.9635342359542848,0.9850702285766602,0.0,accept,unanimous_agreement
777313825,9462,"i still think i'd rather eliminate `resetserverlatencypercentileparams` and `appendserverlatencypercentileparams`, and just embed their code here. i think it'll make the code clearer. (no need for an incremental realloc) i suppose the reason it's here is because it was copied from ""save"" which had other concerns in the past.",0,0,0,0.9790537357330322,0.977728545665741,0.9701664447784424,0.0,accept,unanimous_agreement
777330449,9462,"-steinberg what did we conclude here? this is unrelated to the current pr, but i see an opportunity to improve redis 7. in past redis versions, you could only do `src/redis-server --save 1 1 --save 2 2` now you can also do `src/redis-server --save 1 1 2 2` but you still can't do `src/redis-server --save ""1 1 2 2""` (although config set does take a single arg like `""1 1 2 2""`). and you can't also do `src/redis-server --dbfilename --myfilename.rdb` i think these are two things that would be nice to fix in 7.0",0,0,0,0.9569286704063416,0.9863727688789368,0.8745443224906921,0.0,accept,unanimous_agreement
777331461,9462,"i've changed it to reply with the same ""schema"" but the calls set to 0 and with an empty histogram map.",0,0,0,0.9863356351852416,0.9842560887336732,0.9933269023895264,0.0,accept,unanimous_agreement
777332801,9462,"i think we can just skip them.. why bother to add so much details (two levels of nesting) for en empty response? it's unordered anyway, and we skip empty ones in the ""all"" variant.",0,0,0,0.962680459022522,0.9538894891738892,0.971281111240387,0.0,accept,unanimous_agreement
777335271,9462,addressed it in the latest commit,0,0,0,0.9835926294326782,0.9904654026031494,0.9945536851882936,0.0,accept,unanimous_agreement
777340652,9462,addressed in the latest commit oran,0,0,0,0.985526204109192,0.9842516779899596,0.9940800070762634,0.0,accept,unanimous_agreement
777347970,9462,"i don't like this, the outer function is aware of the response layout of the inner one. if we must have that reply, we should call `fillcommandcdf` and let it handle that internally. however, i think it's excessive to add so much data for the reply, and i think that instead we should let the client realize the request came empty handed. since we don't rely on the ordering anyway, i think that's perfectly valid approach.",-1,0,-1,0.9391717910766602,0.8232183456420898,0.7848001718521118,-1.0,accept,majority_agreement
777348871,9462,case sensitive comparison is really excessive for this. [code block],-1,-1,-1,0.9508833289146424,0.8423266410827637,0.981823742389679,-1.0,accept,unanimous_agreement
777349812,9462,"the `+1` was excessive, right? i think we can make the code shorter (easier to read). [code block]",0,0,0,0.9815760850906372,0.98961079120636,0.9920620918273926,0.0,accept,unanimous_agreement
777352595,9462,addressed in latest commit :+1:,0,0,0,0.8165501356124878,0.6085917353630066,0.5003072619438171,0.0,accept,unanimous_agreement
777385561,9462,"made a pr to try that: [a link] we can continue the discussion there. but either way, i'm confident that the new config here (`latency-track-percentiles`) should behave the same as other configs we have (e.g. `save`)",0,0,0,0.9546544551849364,0.9827054738998412,0.9884350299835204,0.0,accept,unanimous_agreement
777893761,9462,seem to me that if we're in the case of the special case where we want an empty percentile configuration we need to fix the loop to run over the actual number of percentiles and to over `argc`. [code block],0,0,0,0.985398292541504,0.99128258228302,0.9888142943382264,0.0,accept,unanimous_agreement
777900796,9462,i think we're missing a space in this case. [code block],0,0,0,0.979021430015564,0.9826048016548156,0.9793997406959534,0.0,accept,unanimous_agreement
777904371,9462,why the `+1`?,0,0,0,0.976237654685974,0.9878717660903932,0.9772527813911438,0.0,accept,unanimous_agreement
777906807,9462,if in practice we only support μsecs then why did you write the whole things with nsecs as the base unit?,0,0,0,0.9798469543457032,0.9862209558486938,0.9887422323226928,0.0,accept,unanimous_agreement
777922932,9462,"-steinberg it is to get more precision on the start of the histogram. otherwise, given we have operations that take below 1 micro they would not properly show up.",0,0,0,0.980198323726654,0.9847087860107422,0.943511426448822,0.0,accept,unanimous_agreement
777926272,9462,error of mine. addressed,-1,0,-1,0.7254529595375061,0.7820495963096619,0.6801179051399231,-1.0,accept,majority_agreement
778570177,9462,"i see hdr_histogram uses indentation of 4 spaces (like redis), let's use it's style.",0,0,0,0.987086296081543,0.9899618625640868,0.9914659261703492,0.0,accept,unanimous_agreement
778570951,9462,why is this one a one liner?,0,0,0,0.9130600690841676,0.9675843715667723,0.967166543006897,0.0,accept,unanimous_agreement
778572360,9462,maybe put an overflow check here too?,0,0,0,0.985725998878479,0.9930357336997986,0.990459680557251,0.0,accept,unanimous_agreement
778573397,9462,"i suppose we only need this header in server.c? p.s. thinking of your pr to the upstream hrd_histogram, i'm not sure if they'll like it that you've taken a project of one c file and added a second one for this purpose. maybe they'll prefer to add another 30 lines to the other 1100 lines c file.",0,0,0,0.9727364778518676,0.9618260264396667,0.9809219241142272,0.0,accept,unanimous_agreement
778574597,9462,"maybe it would be safer to use macros? i.e. `#define malloc hdr_malloc` what i'm thinking of is the chance we'll merge an upgrade from upstream, and miss one use of malloc of free, so it'll pass to a different allocator (which in most cases would be the same allocator, just without the zmalloc counting). this could be very dangerous since there's a big chance we won't notice it.",0,0,0,0.6080151796340942,0.8051455020904541,0.9387526512145996,0.0,accept,unanimous_agreement
778611495,9462,`calloc` semantics require checking for an overflow and returning `null` in such cases. i think we need to assume `callocfn` does this for us and not try to do its work for it. also note the current check might cause a division-by-zero error.,0,0,0,0.9863860607147216,0.975016474723816,0.9902129769325256,0.0,accept,unanimous_agreement
778617183,9462,"i agree, i think this check needs to go to `zcalloc_num` (where we do a multiplication that could overflow).",0,0,0,0.9855318665504456,0.9880542159080504,0.9821762442588806,0.0,accept,unanimous_agreement
778668077,9462,"i used clang-format on it, and even with the 4 spaces indentation it one-lines it. i've changed it back to multiple lines definition",0,0,0,0.9822851419448853,0.9811060428619384,0.9911024570465088,0.0,accept,unanimous_agreement
778668592,9462,:+1: addressed in the new commit to achieve this i've used clang-format with the following defs: [code block],0,0,0,0.9242493510246276,0.8984724879264832,0.9880639910697936,0.0,accept,unanimous_agreement
778670829,9462,addressed on the new commit,0,0,0,0.9860177636146544,0.9833471179008484,0.9948664903640748,0.0,accept,unanimous_agreement
778671581,9462,being discussed in [a link],0,0,0,0.9857505559921264,0.987390637397766,0.9952802658081056,0.0,accept,unanimous_agreement
778674715,9462,"and -steinberg please confirm that the check for that the arguments to zcalloc(), when multiplied do not wrap is enough. given we want to handle the oom scenarios, i was required to change zmalloc_oom_handler to also log the num_items trying to allocate alongside the item size.",0,0,0,0.9882304668426514,0.9888232350349426,0.9925992488861084,0.0,accept,unanimous_agreement
778705286,9462,why uintmax_max and not size_max?,0,0,0,0.9671926498413086,0.9867513179779052,0.9886596202850342,0.0,accept,unanimous_agreement
778706286,9462,i don't like that change to `zmalloc_oom_handler`. i'm uncomfortable that this small overflow check causes so many changes. maybe we'll just log one of the operands? or instead log size_max?,-1,-1,-1,0.9830392599105836,0.9787368774414062,0.9868144989013672,-1.0,accept,unanimous_agreement
778710683,9462,"not sure we need to call `zmalloc_oom_handler`, according to the `calloc` docs passing an overflowing or 0 value should simply return `null`. also i don't see value in adding the extra `num` and `size` to the logging.",0,0,0,0.9863752722740172,0.987769901752472,0.9634421467781068,0.0,accept,unanimous_agreement
778717801,9462,no reason. it's even counterproductive given uintmax maps to `(__uint64_c(18446744073709551615))` and sizemax does not enforce the type. changing it.,0,0,-1,0.936495840549469,0.8381956815719604,0.5055295825004578,0.0,accept,majority_agreement
778725288,9462,"-steinberg i believe we must call oom_handler within the redis context even tough it's not required by the calloc definition. addressed issue [a link] specifically with the oom_handler so that we can log with further details and exit when we cannot allocate the required memory: quoting him: where malloc returned null (in linux this actually happens under specific overcommit policy settings and/or with no or little swap configured) the error was not properly logged in the redis log. with that in mind, imo, we should call the handler and return null. in that manner, we have a configurable way of deciding wether to abort on log or just expect the caller of zcalloc to handle it. agree? with regards to: i'm reverting and logging `size_max` on the scenario of overflow as suggested by .",0,0,0,0.8155930042266846,0.9838956594467164,0.907569408416748,0.0,accept,unanimous_agreement
778725744,9462,addressed it :+1:,0,1,1,0.7653771042823792,0.7392925024032593,0.9130789637565612,1.0,accept,majority_agreement
778727059,9462,you're right. thanks.,1,1,1,0.9058279395103456,0.9852307438850404,0.9877480268478394,1.0,accept,unanimous_agreement
778736327,9462,i still see a spare line,0,0,0,0.9824099540710448,0.8979072570800781,0.9886201620101928,0.0,accept,unanimous_agreement
778736558,9462,i suppose this is no longer needed,0,0,0,0.9665021896362304,0.9543455839157104,0.9847062230110168,0.0,accept,unanimous_agreement
778738546,9462,add `wait_for_blocked_client` after all `blpop`s,0,0,0,0.9861509203910828,0.9944614171981812,0.9951696991920472,0.0,accept,unanimous_agreement
778739322,9462,this test can be tagged with `needs:debug`. not specifically required at the moment because of `external:skip`,0,0,0,0.9752320647239684,0.9953369498252868,0.9952688813209534,0.0,accept,unanimous_agreement
709066853,9504,"it's worth mentioning the different approach you took for config command (splitting it to different functions) vs other commands (one entry point that's still looking at argv[0]), in the top comment.",0,0,0,0.9855550527572632,0.9917958378791808,0.9911327958106996,0.0,accept,unanimous_agreement
709067723,9504,"if you'll move these two new functions to below the help function, maybe the diff will be smaller, or at least easier to review.",0,0,0,0.9859275817871094,0.9901731014251708,0.9783665537834167,0.0,accept,unanimous_agreement
709069031,9504,"i suppose memorygetkeys isn't needed now because when usage is a command of it's own, it can just use a range spec. maybe that's worth mentioning in the notes too (not immediately clear)",0,0,0,0.9817195534706116,0.989547610282898,0.9898083806037904,0.0,accept,unanimous_agreement
709073018,9504,worth mentioning in the top comment,0,0,0,0.9668283462524414,0.9740425944328308,0.9882733821868896,0.0,accept,unanimous_agreement
709074219,9504,mention in the top comment the few missing subcommands in help messages.,0,0,0,0.9851897358894348,0.9863919019699096,0.9935321807861328,0.0,accept,unanimous_agreement
709075444,9504,"in the top comment bullet that mentions unifying the command table, maybe ad a note about redirection of the few that have different implementation and similar command name. (list them)",0,0,0,0.9864425659179688,0.9845799207687378,0.9948936700820924,0.0,accept,unanimous_agreement
709077843,9504,it's worth mentioning the effects this commit has on the command stats in the top comment (release notes),0,0,0,0.9835288524627686,0.9840633869171144,0.9920836687088012,0.0,accept,unanimous_agreement
709080657,9504,"so you made lcs a sub-command? let's list it in the top comment. maybe add a bulleted list of all ""containers"", and also a note about why sentinel and debug are not promoted.",0,0,0,0.9875189661979676,0.9932900667190552,0.9940474033355712,0.0,accept,unanimous_agreement
709084917,9504,this is a bit hard to review. so i understand that this means that you've removed the specs you recently added from the old command command. and instead added them to the new commands command. right? let's make it clear in the top comment too.,-1,0,0,0.5852873921394348,0.7856897711753845,0.9703274369239808,0.0,accept,majority_agreement
709086102,9504,"this means the the command itself (no arguments) is invalid, right? let's state that in the comment.",0,0,0,0.9860382676124572,0.99136620759964,0.9899327754974364,0.0,accept,unanimous_agreement
709088938,9504,"let's list the ""sentinel"" and ""sentinel-only"" flags here. this is where we make the difference between these two clear. i wanted to document that in the constant in server.h, but concluded that instead, it should be documented here. i.e. to say that ""sentinel"" means that the command exists in both redis and sentinel",0,0,0,0.9836385250091552,0.9922196865081788,0.9855234622955322,0.0,accept,unanimous_agreement
709091803,9504,"i think `ok-stale` should be added here. or actually to all config sub-commands. so, this would mean that there's no real change here compared to the past. right? i.e. the old code had `admin ok-loading ok-stale no-script`, but then blocked loading in all except for get. (for help we don't care)",0,0,0,0.6162316203117371,0.9733881950378418,0.9822871088981628,0.0,accept,unanimous_agreement
709119881,9504,"if we add a return above, we can reduce the indentation of this code. less indentation is better, but also it means it won't change the blame log.",0,0,0,0.9827385544776917,0.987793743610382,0.9892809987068176,0.0,accept,unanimous_agreement
709121061,9504,"it was a multiline `if`, the old style was better (and also no need to change these lines (blame log))",0,0,-1,0.9865292310714722,0.9904201626777648,0.903246283531189,0.0,accept,majority_agreement
709124302,9504,"i think this is an array, not a set. each entry is a map",0,0,0,0.9839778542518616,0.9825128316879272,0.9861104488372804,0.0,accept,unanimous_agreement
709125626,9504,looks like you should revert this line (you didn't add sub-command to the legacy),0,0,0,0.9795411229133606,0.9913081526756288,0.9904412031173706,0.0,accept,unanimous_agreement
709129469,9504,have a clue why did git decide all these lines are new / changed?,0,0,0,0.9750962853431702,0.950210690498352,0.9500259160995485,0.0,accept,unanimous_agreement
709131152,9504,"so one can do `command info config|get` maybe explain this feature, and also list all the places that this syntax works in the top comment?",0,0,0,0.9872981309890748,0.9911471009254456,0.9939551949501038,0.0,accept,unanimous_agreement
709132753,9504,"i think we discussed this, but i have second thought.. it's a bit odd that `command info` returns an array with all commands. and also `command info config ping` returns an array of just 2. maybe we should consider adding a `command all` subcommand instead? or can you remind me the reasons we did that?",-1,-1,0,0.7417871356010437,0.8642652034759521,0.7839268445968628,-1.0,accept,majority_agreement
709133719,9504,maybe this can be a set rather than an array,0,0,0,0.983343541622162,0.9905343055725098,0.9848800897598268,0.0,accept,unanimous_agreement
709134848,9504,"since getkeys is complex and common to both command and commands, maybe we should extract this code to a common function?",0,0,0,0.9829795360565186,0.9932575225830078,0.9891397356987,0.0,accept,unanimous_agreement
709140367,9504,"maybe it's worth explicitly mentioning in the release notes (top comment) that side effect. if in the past a call to `config set` would appear in cmdstat_config, it will no longer appear there. so some application that's looking for it there (rather than human eyes) will not find it.",0,0,0,0.9788632988929749,0.9920712113380432,0.9874788522720336,0.0,accept,unanimous_agreement
709140793,9504,"i think it is better to pass an input sds and accumulate to it, rather than generate an empty one and then copy it.",0,0,0,0.9833521246910096,0.9773064255714417,0.9831780791282654,0.0,accept,unanimous_agreement
709155363,9504,"can you remind me why we have `random` flag, and why only on consumers and not on groups and stream?",0,0,0,0.9849557280540466,0.9939646124839784,0.99407297372818,0.0,accept,unanimous_agreement
709165013,9504,"maybe we should actually compose a full list the ones which have different flags in sub-commands (for release notes). i.e. we used to have use-memory (affects oom error) for the entire xgroup command (including destroy and delconsumer), now we only have it for create and createconsumer.",0,0,0,0.9878859519958496,0.9943047165870668,0.9831151366233826,0.0,accept,unanimous_agreement
709166731,9504,i don't think purge needs `random`,0,0,0,0.9806867241859436,0.946858525276184,0.9614152908325196,0.0,accept,unanimous_agreement
709168610,9504,"remind me how you handled the removal of memorygetkeys? i.e. i don't see an old range spec here, and iirc the code in redis doesn't use the key-specs.",0,0,0,0.9836738109588624,0.9884196519851683,0.9942502975463868,0.0,accept,unanimous_agreement
709169327,9504,do we wanna remove the `admin` from whoami?,0,0,0,0.9875310063362122,0.99432772397995,0.9938763976097108,0.0,accept,unanimous_agreement
709175232,9504,technically len is also `random`. executing it on the replica will result in a different value. [code block],0,0,0,0.9883021712303162,0.9935451745986938,0.9915408492088318,0.0,accept,unanimous_agreement
709176326,9504,i think freq is also `random`,0,0,0,0.985839068889618,0.9893155097961426,0.9673685431480408,0.0,accept,unanimous_agreement
709176832,9504,"i did promote sentinel, just not debug",0,0,0,0.96698397397995,0.8948665857315063,0.9863410592079164,0.0,accept,unanimous_agreement
709179123,9504,i think getname and setname should not be `admin` and also not `random`.,0,0,0,0.9877585768699646,0.986527383327484,0.9878979325294496,0.0,accept,unanimous_agreement
709179414,9504,actually the `random` should be removed from most of these (only left for info and list),0,0,0,0.9895089864730836,0.9945185780525208,0.9913802742958068,0.0,accept,unanimous_agreement
709179774,9504,reply is not `admin`.,0,0,0,0.9560126066207886,0.9791321754455566,0.9930663108825684,0.0,accept,unanimous_agreement
709184228,9504,"if we remove `admin` from setname, how does it affect the acl categories? will users that are set to be blocked on the admin category be able to execute this sub-command? i guess not (yet), but i think we should look into it.",0,0,0,0.984207570552826,0.9882389307022096,0.9862132668495178,0.0,accept,unanimous_agreement
709238560,9504,shouldn't this just have the `container` flag?,0,0,0,0.9818551540374756,0.992852747440338,0.9926664233207704,0.0,accept,unanimous_agreement
709239953,9504,yes,0,0,0,0.9564858078956604,0.9659429788589478,0.9686408638954164,0.0,accept,unanimous_agreement
709242838,9504,we usually drop a line if the `if` is more than one line either we leave it like this or i will have the `if` condition in one line (anyway it will change the blame log) unless you insist,0,0,0,0.9609504342079164,0.987986385822296,0.9826799631118774,0.0,accept,unanimous_agreement
709243894,9504,why array? elements are unique and there's no order,0,0,0,0.9708243608474731,0.9744122624397278,0.9872318506240844,0.0,accept,unanimous_agreement
709245571,9504,"yes, because commands is directly after command and they have the same start and end do you want me to move it?",0,0,0,0.9855210185050964,0.9907329082489014,0.9932726621627808,0.0,accept,unanimous_agreement
709250237,9504,"i don't know, this feels more right to me... maybe can share his thoughts?",-1,0,0,0.7251114845275879,0.6533689498901367,0.8753457069396973,0.0,accept,majority_agreement
709251837,9504,i may feel better with `commands info all` wdyt?,0,0,0,0.983992874622345,0.9841952323913574,0.9714968204498292,0.0,accept,unanimous_agreement
709258803,9504,because consumers shows the idle time (depend on mstime()),0,0,0,0.9862668514251708,0.9903354644775392,0.9939982891082764,0.0,accept,unanimous_agreement
709260891,9504,"why? i think it should be fine to call xgroup destroy while oom, no? otherwise, why is del allowed?",0,0,0,0.9403398036956788,0.8447889089584351,0.96308434009552,0.0,accept,unanimous_agreement
709261846,9504,"it does - if there are only ""range"" specs it glues them together to create the legacy spec",0,0,0,0.9869224429130554,0.9931179285049438,0.9903597831726074,0.0,accept,unanimous_agreement
709265002,9504,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
709265558,9504,not necessarily (command is the only one the violates that),0,0,0,0.9593265056610109,0.9659674167633056,0.9698566198349,0.0,accept,unanimous_agreement
709266108,9504,"but there is more than one line in the `if` condition. and i don't see you changed anything in that line, so why would it change?",0,0,0,0.9619532227516174,0.9828249216079712,0.9906779527664183,0.0,accept,unanimous_agreement
709269842,9504,"it's right that each element is unique (it's a big dictionary with lots of fields, and there are no duplicate records), but i think a set is a set of simple objects like strings. we could have made it a map (if we moved the name outside the dict). i.e. a map where each entry has a command name (the map's field), and a value that's an array (or map) of metadata. but the way it is now, where each entry is a map, doesn't make sense to me as a set. if you disagree, let's seek a 3rd opinion.",0,0,0,0.8757286071777344,0.960004985332489,0.9436925053596495,0.0,accept,unanimous_agreement
709271345,9504,"ohh it's odd to see the old code being marked as new, and the new code being marked as old. maybe if we extract the getkeys implementation it'll change all that.",-1,-1,-1,0.655005156993866,0.9701159596443176,0.9324035048484802,-1.0,accept,unanimous_agreement
709272904,9504,"i like that even less.. i.e an argument that could either be a command name or an constant ""all"" string",1,1,0,0.9385921359062196,0.9704400300979614,0.9095487594604492,1.0,accept,majority_agreement
709276376,9504,"i didn't say your code is wrong. i agree with it. i'm saying that for the release notes, we should include a list of the ""side effects"" of this pr. i.e. in the past the entire xgroup had `use-memory` and now only two sub-commands have it (other sub-commands are allowed while oom). so i think we need to compose a list of all the commands that now have different flags for each sub-command, and mention that list in the top comment.",0,0,0,0.9645867943763732,0.9346041679382324,0.9600566029548644,0.0,accept,unanimous_agreement
709277521,9504,"good thing you asked, i had a bug (used kspec_bs_keyword instead of kspec_bs_index)",0,1,1,0.5088874101638794,0.7998748421669006,0.9729859232902528,1.0,accept,majority_agreement
709278272,9504,"ok, so we can theoretically drop the legacy spec from the command table now, and rely on that instead? maybe we should at least add a test for memory usage (maybe using acl)",0,0,0,0.984713852405548,0.9938516616821288,0.989591419696808,0.0,accept,unanimous_agreement
709292569,9504,"we have the same in info... ""all"" is not a section",0,0,0,0.974618434906006,0.949718713760376,0.9917850494384766,0.0,accept,unanimous_agreement
709293210,9504,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
709302382,9504,"the sections in info are not sub-commands or command arguments. it's a single argument that in theory can one day include regex or whatever. i.e. we document that as `info [ ]` but here we'll document it as `commands info ...` i don't think ""all"" applies here.",0,0,0,0.9829564094543456,0.9916428327560424,0.9896044731140136,0.0,accept,unanimous_agreement
709317256,9504,"ok, i'm starting to lean towards `commands all`, let's see what yossi thinks",0,0,0,0.9009923338890076,0.9347169399261476,0.9534293413162231,0.0,accept,unanimous_agreement
709354990,9504,should i resolve this comment?,0,0,0,0.9702491164207458,0.986388862133026,0.9897524118423462,0.0,accept,unanimous_agreement
709355857,9504,"because i saw this violation of the redis coding standard, so i fixed it...",-1,0,0,0.6551713347434998,0.95387601852417,0.9434947371482848,0.0,accept,majority_agreement
709361812,9504,"i don't mind... wdyt? the output of commands info should be a set, list, or hash (key is command name, value is its data)",0,0,0,0.954600989818573,0.5186318755149841,0.8484498858451843,0.0,accept,unanimous_agreement
709364836,9504,"if that flag doesn't indicate that the command itself is meaningless without a sub-command, then why do we need it? we can populate that flag automatically by looking at the subcommand list provided in the commands table, or better yet, we don't need the flag at all (we can just look at the subcommands dict",0,0,0,0.9754223823547364,0.9923077821731568,0.9853159785270692,0.0,accept,unanimous_agreement
709366039,9504,"ohh, sorry, i think i looked at it in the wrong direction, i need the new one is the right one.",-1,-1,-1,0.9898794889450072,0.9872646331787108,0.9869139790534972,-1.0,accept,unanimous_agreement
709372550,9504,"ok, changed it to hash (map) - lmk if you wish me to revert",0,0,0,0.9841518402099608,0.99142986536026,0.9940770864486694,0.0,accept,unanimous_agreement
709374554,9504,"that's a good question... i'll drop it and see what happens :) but i guess you're right, we don't really need it",1,1,1,0.9894384741783142,0.9950628876686096,0.9966304898262024,1.0,accept,unanimous_agreement
709375997,9504,indeed it's unused...,0,0,0,0.5279542803764343,0.8929865956306458,0.9914894104003906,0.0,accept,unanimous_agreement
710217954,9504,check: what happens if we give every subcommand its own acl id? does it break anything?,0,0,0,0.9686545133590698,0.9625933170318604,0.9906896352767944,0.0,accept,unanimous_agreement
710224062,9504,"recent update: we decided to keep the current impl, `commands info` with no args returns the info about all commands please ack",0,0,0,0.9634894132614136,0.9813966751098632,0.9930883049964904,0.0,accept,unanimous_agreement
710227432,9504,just to make sure you didn't miss it. please add a test for it using acl,0,0,0,0.948750615119934,0.9869520664215088,0.9936633110046388,0.0,accept,unanimous_agreement
710232677,9504,"ack, and also note: [a link] so: `commands info [ ...]` always returns a `map` with key being the command name, and value being a map (of the command metadata fields), by default returns all commands. this one is either users by a person from redis-cli (wanting to see one or two commands), or a software that'll want all commands. and: `commands list [filterby (module |aclcat |group |pattern )]` always returns a set of command names, by default all.",0,0,0,0.9823525547981262,0.9886599779129028,0.9778739809989928,0.0,accept,unanimous_agreement
710248221,9504,"i already added a test that uses command(s) getkeys memory usage that should be enough, no?",0,0,0,0.9852786064147948,0.9880576133728028,0.9940005540847778,0.0,accept,unanimous_agreement
710268290,9504,i suppose.. i don't remember what i had in mind. maybe i wanted to check that redis internals are using the legacy key spec properly rather than the command command metadata. but actually getkeys does that too (uses the same internal mechanism) . so i suppose that's ok,0,0,0,0.9741178154945374,0.958971619606018,0.9401426315307616,0.0,accept,unanimous_agreement
710590775,9504,is this used?,0,0,0,0.9859181642532348,0.9839692115783693,0.9943179488182068,0.0,accept,unanimous_agreement
710595721,9504,"is there a reason xgroup help is but command is not a ? i guess these are also going to be used for acls later, so unclear why they wouldn't all be consistent. also, shouldn't all the helps be allowed during loading?",0,0,0,0.9820238947868348,0.9774362444877625,0.9778939485549928,0.0,accept,unanimous_agreement
710605650,9504,i feel like we should be opinionated and pick either having a single command and checking the argument vs having the individual sub commands have their own functions. i would prefer having the individual functions for each sub commands.,0,0,0,0.7837875485420227,0.8954637050628662,0.9102312922477722,0.0,accept,unanimous_agreement
710606163,9504,i don't see the point of promoting this command to be a subcommand. i don't think we'll ever touch this again. it seems excessive to add a help here. this was one of salvatores pet projects.,-1,-1,-1,0.9566745162010192,0.5327469110488892,0.9326260089874268,-1.0,accept,unanimous_agreement
710608798,9504,"i think introducing command vs commands is just going to be confusing, since it's going to be easy to forget which is the ""new one"" and which is the ""old one"" until we deprecate the old one. i would rather introduce new sub-arguments that introduce the new behavior.",-1,-1,0,0.5134856104850769,0.5966039896011353,0.8992130160331726,-1.0,accept,majority_agreement
710972693,9504,"i think we're aiming to eventually go that way (so config is an example of how it'll look), but we don't want to refactor tons of code in this pr (easy review and less damage to blame log), so the old way is still supported.",0,0,0,0.965997040271759,0.9406190514564514,0.9830244779586792,0.0,accept,unanimous_agreement
710974948,9504,"i wish he didn't wrap lcs inside an stralgo at all (and i also wish he would split it to two commands, one works on strings and one on keys). at this point, splitting lcs into a sub-command may help a bit (to bring it closer to being a standalone command) you're absolutely right that it's not really a sub-command like others (client, acl, etc). but in some way it's a bit similar to xgroup and xinfo. i don't have any conclusive opinion here.. it stinks either way.",-1,0,-1,0.9698124527931212,0.5981756448745728,0.9946165680885316,-1.0,accept,majority_agreement
710976230,9504,the problem with the old command is that it also works with no arguments (we have no other command with sub-command that does that). so i really wanna keep it entirely unchanged (for backwards compatibility) and encourage people to use the new one. you're right that command vs commands is slightly confusing. maybe we can come up with a different name?,-1,-1,-1,0.6398579478263855,0.9116777777671814,0.55049729347229,-1.0,accept,unanimous_agreement
711201001,9504,"if we agree to eventually trend there i'm okay with that, i just don't like there is code hanging around to support both.",-1,0,-1,0.97355979681015,0.6877597570419312,0.931769609451294,-1.0,accept,majority_agreement
711203854,9504,"i get your point. it also is not that important, so i don't feel strongly either way. i would still prefer to just leave it as this weird command that has a weird required second argument (and maybe even update the docs to indicate as much).",-1,-1,0,0.9517669081687928,0.8971438407897949,0.5944011807441711,-1.0,accept,majority_agreement
711210135,9504,"can we not leave the regular `command` command in place for the old way of listing commands, and introduce the new `command list` sub-command as the new mechanism with the new structure. it seems reasonable to then say that the root command will be deprecated in 7 and clients should start using the new mechanism. we also might want to think about building a versioning scheme for the redis command set that clients can set on connect/hello. if they connect with version 1 they can issue command, but in version 2 it will throw an error since it will be deprecated.",0,0,0,0.98660010099411,0.993114411830902,0.9906444549560548,0.0,accept,unanimous_agreement
711229750,9504,"so in your suggestion drop that support in 7, old client libraries won't work with 7, and users that want to upgrade redis (to enjoy an optimization or a new feature) won't necessarily be able to do so. the other major issue to keep in mind is that client libraries won't be able to just stop using the old command anytime soon, since they still need to support old redis versions. i discussed this with guy and we concluded that it's ok to ask them to first issue the new commands and only if it fails issue the old one. it means an additional round trip on connection. i don't like to have redis explicitly support multiple versions old protocols and command sets.. currently we support all (never remove a command or a protocol), but even if we someday remove something, we can remove them one by one separately, no sense to bind them imho. and i don't see a reason to refuse something that's still actually supported if the client is using another new feature. maybe we need to discuss this in more detail in another forum?",0,0,0,0.8820264935493469,0.8998532891273499,0.9570168852806092,0.0,accept,unanimous_agreement
711304540,9504,"i'm not saying to drop support in 7, just to deprecate it so that we can remove it in some future version. i don't see why we can't have `command` and `command list` live together and have a different output?",0,0,0,0.935745894908905,0.8987431526184082,0.97376549243927,0.0,accept,unanimous_agreement
711560770,9504,"the main problem is `command info` - we broke its structure, mostly in order to remove the old first,last,step scheme (we were under the impression that as long as the ""legacy"" scheme exists, people won't put the effort in parsing the new key specs) - cmiiw i don't mind dropping commands if we can get command to: 1. output a list of all commands (just a list of strings), with the ability to filter them (for example, get only commands that belong to some module, by regex, etc.) 2. output detailed information about all commands (each such information is not backward compatible with command info, so we can't just add stuff to command info's output). it should also be able to emit information about specific commands. the most ""ugly"" thing is that, no matter what, if we choose to use command, there will be two subcommands that retrieve detailed information about commands: info (the old struct) and info2/details/list/whatever that use the new struct, with key specs and subcommands",0,0,0,0.9432911276817322,0.9188705086708068,0.9114558696746826,0.0,accept,unanimous_agreement
711573893,9504,"in theory, there's no problem to add key specs to command info (same as we have in unstable today), also also add the sub-commands and additional metadata to that array (old clients will ignore the additional entries in the response). so in that sense we can simply add command list (to just list command names) and extend command info, and do nothing else. but there are so many issues with the old command that i rather just leave it unchanged and add all the new features to a new command. the issues that bother me: 1. the fact that the command have sub-commands, but also functions as a command with no arguments too. this causes complications to the command and sub-commands listing. we may need to re-introduce the `container` flag to distinguish between and command with optional sub-commands, and one that's just a container for sub-commands. 2. the fact the response for the command metadata is array with specific indexes rather than a map with field names. (i don't like to add the `since`, `returns` or other fields we plan in #9359 to just sit in some specific index without a title) 3. some old fields that i wish to remove (firstkey etc)",-1,0,-1,0.8000155091285706,0.9832889437675476,0.8448284864425659,-1.0,accept,majority_agreement
712096877,9504,yes - it is used to populate `subcommands_dict` (much like `sflags` is used to populate `flags`),0,0,0,0.9889897108078004,0.9944091439247132,0.9939451813697816,0.0,accept,unanimous_agreement
712098937,9504,"i think that all ""help"" subcommands should be ""ok-stale ok-loading"" without any acl categories (i.e. i'll remove from xinfo/xgroup) sounds right?",0,0,0,0.9856385588645936,0.9915410876274108,0.9895601272583008,0.0,accept,unanimous_agreement
712099269,9504,"yes, we will ""convert"" all eventually resolving convo",0,0,0,0.9815949201583862,0.9881736636161804,0.9885562062263488,0.0,accept,unanimous_agreement
712099855,9504,it's still that weird command but now it has two weird second arguments :),-1,-1,-1,0.8899930119514465,0.9032710790634156,0.992551326751709,-1.0,accept,unanimous_agreement
712127043,9504,don't think we need to actively convert them.. but rather intend to phase them out gradually.,0,0,0,0.932970643043518,0.8285080790519714,0.9870266318321228,0.0,accept,unanimous_agreement
712132078,9504,"i'm not sure about the `` i agree that there's no need to restrict access them them (e.g on stale or loading states), but if someone decided to block all stream commands then help should be included. what's more important, is that if someone decided to **allow** all stream commands, help should be included. bottom line, i think the redis flags can change, but the acl category flags should should be retained.",0,0,0,0.9758328795433044,0.9574152231216432,0.9528656601905824,0.0,accept,unanimous_agreement
713002673,9504,"you do know that `setuser` is not incremental, right? this second line overrides the previous one",0,0,0,0.9859825968742372,0.9909203052520752,0.993681788444519,0.0,accept,unanimous_agreement
713004197,9504,"ohh i see a previous test here uses the same pattern, maybe i'm wrong?",-1,0,0,0.6979468464851379,0.8940441608428955,0.9448124170303344,0.0,accept,majority_agreement
713006773,9504,"i'd like to add an acl subcommand test for non-subcommand (like `select 1` allowed and `select 2` not allowed). i know people are using it, so wanna make sure we don't break it. maybe similar thing for debug",0,0,0,0.9503139853477478,0.9665004014968872,0.9701038002967834,0.0,accept,unanimous_agreement
713009128,9504,"that's a new feature that was not possible in the past, right? so in that sense this is a breaking change? either way, we should explicitly document that in the top comment",0,0,0,0.9688205122947692,0.9894986152648926,0.9755465984344482,0.0,accept,unanimous_agreement
713034855,9504,i think that comment is misplaced.. already included (kept) in the caller where it makes more sense. am i right?,-1,0,0,0.7098591923713684,0.9630248546600342,0.9450100064277648,0.0,accept,majority_agreement
713037538,9504,can you please take a closer look at this one? maybe requires more testing or test code,0,0,0,0.9818596243858336,0.9870953559875488,0.9914563298225404,0.0,accept,unanimous_agreement
713048028,9504,"i don't think we wanna mention it's an abuse.. the original design (in redis) wasn't very good and it allowed that. also, since we didn't promote debug to a container command, that's a perfect excuse for supporting this (""first argument"" filtering)",-1,-1,0,0.5244171619415283,0.60372394323349,0.661351203918457,-1.0,accept,majority_agreement
713139687,9504,"it's not a breaking change - in the past, it would have just failed i'll document in the top commet",0,0,0,0.8284928202629089,0.964982569217682,0.9889105558395386,0.0,accept,unanimous_agreement
713145222,9504,"yes, it was copied by mistake (appeared twice in the code)",0,0,0,0.986009418964386,0.9828730225563048,0.9815566539764404,0.0,accept,unanimous_agreement
713358879,9504,"all of the issues seem to be leveled at disliking the current `command` command, and your solution is to make a new command that is slightly different in many dimensions but named way to similarly. i strongly dislike ""deprecation"" for the sake of it, which is how i view removing fields and changing a list to a map. the only valid argument i'm seeing is we have new functionality, and we need to expose it, which seems like the job of `command list` or something.",-1,0,-1,0.9737274050712584,0.5980600118637085,0.9414612650871276,-1.0,accept,majority_agreement
713385553,9504,"this function could use some documentation, i didn't really follow what it did until looking at in the context of other places it's called.",0,0,0,0.9789366722106934,0.9416476488113404,0.9666014313697816,0.0,accept,unanimous_agreement
713388041,9504,"more testing yeah, i think it looks correct.",0,0,0,0.9409541487693788,0.779490053653717,0.9203535914421082,0.0,accept,unanimous_agreement
713715812,9504,"ohh, sorry, i was confusing context of #9330 (different behavior of config file parsing, vs acl command)",-1,-1,-1,0.9896285533905028,0.9886735081672668,0.9845119714736938,-1.0,accept,unanimous_agreement
713718278,9504,"please add some tests for acl getuser with sub-commands, and commands / sub-commands with firstarg",0,0,0,0.9870144128799438,0.9929730892181396,0.9954447746276855,0.0,accept,unanimous_agreement
713762105,9504,"there are two new functionalities: 1. `commands list` - returns a set of command names - has some filtering capabilities 2. `commands info` - returns detailed information about commands (like `command info`, but returns a map instead of a list, removes the first,last,step fields, and adds key_specs, and sub-command list fields) - can return details about all commands or a list of requested ones. iiuc you suggest the following alternatives (which will add the features described above as new sub-commands of the existing command): 1. `command list` 2. `command info2/details/whatever` (cmiiw) any thoughts?",0,0,0,0.9740028381347656,0.9918239712715148,0.994690477848053,0.0,accept,unanimous_agreement
713808254,9504,"i edited guy's post with a few clarifications. the 3rd options is: 3 . add the new `commands info` features we wanted to add to the existing `command` (all commands) and `command info ` (one command) as new fields, without modifying the content of old ones. what i don't like about that is: - we still support command with no argument - we still use an array of fields in specific indexes (e.g. the sub-commands will be in [9] but will not have any title to it, and people will have to just be aware that [9] is the subcommand list (and [8] is the key-specs the upside is that client libraries will still be able to make a single command call on startup and decide how to parse it by the number of fields they see, instead of issuing two commands. but i actually rather make it more explicit (i think that a completely different command will make that statement) my preference is for a completely new command (a admit that commands is a confusing name). my second choice would be option 2 from the list in the previous post.",-1,-1,0,0.9163739681243896,0.6659895777702332,0.5286899209022522,-1.0,accept,majority_agreement
714808305,9504,new `client no-evict` was added in #8687 (merged),0,0,0,0.9891853332519532,0.9923912882804872,0.9958769083023072,0.0,accept,unanimous_agreement
718568085,9504,"to me, making this accessible and practical to clients beats the other arguments. in theory we could piggy back on top of `hello` so clients can negotiate this, but i think this would be somewhat over-engineered. so assuming there's a fair number of clients that actually execute `command` when initializing a connection, i'd prefer to stick to `command` and add a 9th element. we can try (again) to validate this assumption with client authors.",0,0,0,0.9094761610031128,0.9800658226013184,0.974632441997528,0.0,accept,unanimous_agreement
719167338,9504,"we discussed this with the core team, we concluded that for now we're gonna just append more elements to the old command response, so a client can just keep issuing the old command and get both old and new metadata depending on the redis version. maybe when we'll handle the next step (commands.json), we'll decide to either add a new command or a new sub-command that has that same information in a map with field names rather than array with predefined indexes. i.e. the information will be included in the old format, and maybe **also** in a new one, and that'll be decided later. i suppose we can keep the new command list feature with the same design we planned for commands list",0,0,0,0.7593462467193604,0.986062228679657,0.9767932891845704,0.0,accept,unanimous_agreement
728053809,9504,let's add some short top comment explaining what it does and the return value,0,0,0,0.9852163791656494,0.9685575366020204,0.9937627911567688,0.0,accept,unanimous_agreement
728054860,9504,"maybe we need to put some union in commandlistfilter and fetch the command or translate acl just once in some way? maybe some lazy caching that will not force us to expose modules to the other c files. i.e. the struct will contain a union of a void* and a long, plus a boolean to indicate if already cached.",0,0,0,0.9743468761444092,0.9950072765350342,0.9886564016342164,0.0,accept,unanimous_agreement
728056500,9504,spare line,0,0,0,0.9823103547096252,0.9826955795288086,0.8810158371925354,0.0,accept,unanimous_agreement
728061365,9504,let's see if we can find something less fragile (that we won't need to repeatedly update). maybe the `` cat and a `pf*` prefix?,0,0,0,0.986793577671051,0.9844522476196288,0.9905130863189696,0.0,accept,unanimous_agreement
728122405,9504,"this sorting thing causes the output to be very misleading. i.e. if `-` is last, it'll block everything. this also means the test is weak (won't find real bugs). we must find a way around it.",0,0,0,0.7217786908149719,0.6341679096221924,0.8493148684501648,0.0,accept,unanimous_agreement
728126564,9504,i think it's a good idea to also try to test what's accessible and what's not. i.e. not only rely on getuser.,0,0,1,0.8513743281364441,0.8827930092811584,0.5719975829124451,0.0,accept,majority_agreement
728127898,9504,"i think ""container"" is too broad. maybe ""subcommands""",0,0,0,0.9602776169776917,0.7924324870109558,0.9246599078178406,0.0,accept,unanimous_agreement
728142388,9504,maybe `parent_name` should be first?,0,0,0,0.9872682690620422,0.9943346977233888,0.992624044418335,0.0,accept,unanimous_agreement
728151676,9504,now we don't validate the order between `-client` and `+client|id`. maybe we can do `+ * -client * +client|id` and another `+ * -client * +client|setname`,0,0,0,0.987250566482544,0.9937260746955872,0.9908198714256288,0.0,accept,unanimous_agreement
728153252,9504,"didn't you mean to remove this line? also, please drop the `lsort` in all the places you used it. i.e. some don't need it, and others i think you forgot and you still need to add pattern matching.",0,0,0,0.9862672090530396,0.9925547242164612,0.9915436506271362,0.0,accept,unanimous_agreement
728159376,9504,i think we're missing some doc comment that mentions how to use `rm_addcommandkeyspec` on sub-commands (i.e. the `|` thing),0,0,0,0.9846513271331788,0.9890073537826538,0.9722617268562316,0.0,accept,unanimous_agreement
728164346,9504,let's also call the sub-command (or did you do that and i missed it?),0,0,0,0.9608473777770996,0.9918928146362304,0.9941583871841432,0.0,accept,unanimous_agreement
728327508,9504,"i'm not sure we wanna mention it's a relic (now that we gave it a proper name). we can however say that it can be applied on a first arg of a sub-command, i.e. it could be argv[2]",0,0,0,0.943715512752533,0.9549526572227478,0.9449089765548706,0.0,accept,unanimous_agreement
728343144,9504,"i think you should re-order the commands and put this below rm_createcommand. you'll need to add a forward declaration, but ti'll prevent a blame log change of so many lines...",0,0,0,0.9823838472366332,0.9174254536628724,0.9841188192367554,0.0,accept,unanimous_agreement
728348051,9504,i don't think we wanna expose these flags to users.,0,-1,0,0.8549409508705139,0.7421794533729553,0.787155032157898,0.0,accept,majority_agreement
728354507,9504,this needs to be updated in redis.conf too,0,0,0,0.9874740839004515,0.9936239719390868,0.9955899715423584,0.0,accept,unanimous_agreement
728356199,9504,do we have a test for command getkeys for a command with sub-commands (other than memory usage)? maybe test some basics like get and and advance one like xgroup,0,0,0,0.9843632578849792,0.99237060546875,0.9933342933654784,0.0,accept,unanimous_agreement
728720867,9504,"there is a possibility you'll get the same string pointer pointing to a different string (malloc returning the same pointer) but also, with this solution you don't cache the repeated call to `aclgetcommandcategoryflagbyname`. i think you should add some caching capabilities to the commandlistfilter struct in some way.",0,0,0,0.9886972904205322,0.991211712360382,0.9894583225250244,0.0,accept,unanimous_agreement
730358193,9504,"i didn't have anything specific against the word ""relic"". i meant that i don't think we should document the history and how it was named, and that ""we had to keep allowed_firstargs (previously called allowed_subcommands)"". just document what it does and that it can be either `argv[1]` or `argv[2]` (when applied on a sumbommand)",0,0,0,0.9591540694236756,0.9641371369361876,0.9900586009025574,0.0,accept,unanimous_agreement
730411622,9504,"i'm not sure that this is an `admin` command, but perhaps better safe than worry.",0,0,0,0.6916559338569641,0.7361665964126587,0.5148393511772156,0.0,accept,unanimous_agreement
730426350,9504,"cluster-aware clients need some of these just for handshaking, so i think we should remove `admin` from: `countkeysinslots`, `getkeysinslot`, `info`, `nodes`, `keyslot`, `myid` & `slots`.",0,0,0,0.988390326499939,0.9944084286689758,0.9923697710037231,0.0,accept,unanimous_agreement
730458603,9504,"note that the main info command is not `admin` but it is ``, i guess due to latency concerns?",0,0,0,0.9880290627479552,0.9864115715026855,0.992298185825348,0.0,accept,unanimous_agreement
730458672,9504,make sure to update the top comment when you merge these.,0,0,0,0.9825552701950072,0.9843101501464844,0.9934812784194946,0.0,accept,unanimous_agreement
730458815,9504,"i agree, let's keep it with `admin`",0,0,0,0.9815338253974916,0.90120267868042,0.9687694907188416,0.0,accept,unanimous_agreement
730469318,9504,"i think it was marked dangerous because of the information it may reveal, latency was supposed to be greatly improved in a previous version. in any case, a cluster-aware client may require access `cluster info` just to bootstrap and/or follow up with topology changes.",0,0,0,0.8861048817634583,0.8737043738365173,0.6756186485290527,0.0,accept,unanimous_agreement
730562472,9504,"i thought info was marked dangerous because it was slow as well, in either cause `cluster info` is fast.",0,0,0,0.5454376339912415,0.7867978811264038,0.8233211040496826,0.0,accept,unanimous_agreement
730582252,9504,any other feedback on the above list itamar stated? do you agree that they should all be non-admin? do you see anything in these that should be considered dangerous or admin?,0,0,0,0.9708409905433656,0.9848139882087708,0.9836363196372986,0.0,accept,unanimous_agreement
730603985,9504,"this also doesn't really need admin, since it doesn't change anything.",0,0,0,0.973882019519806,0.9681471586227416,0.987723708152771,0.0,accept,unanimous_agreement
731745468,9504,i think you forgot to free `copy` in a couple of places.,0,0,0,0.9806466102600098,0.9554693102836608,0.9782297611236572,0.0,accept,unanimous_agreement
732502546,9504,"i dropped ""admin"" as itamar requested, please reopen this convo if you think otherwise",0,0,0,0.9861225485801696,0.9793501496315002,0.9921889305114746,0.0,accept,unanimous_agreement
763128669,9504,"somehow i think it should be changed like this [code block] in the past, we can use `sentinel simulate-failure crash-after-election crash-after-promotion`, although it is only used for testing, the code supports such use [code block] and we introduced the sub-command table, so in some sub-commands we can not check the number of parameters in sentinel sub-commands, we can do cleanup like this: [a link] it can remove a `numargserr` label, i think it's worth it... as for the other sub-commands, i think we can leave them as they are of course, we don’t need to make any changes. there is no problem with the original inspection.",0,0,0,0.6207135319709778,0.9748680591583252,0.9025864601135254,0.0,accept,unanimous_agreement
763718887,9504,"-binbin thanks! i agree with changes in the sentinel command table, can you please pr? regarding the improvements in sentinelcommand : the plan is actually to split it completely into smaller functions, so that each function is the `proc` of a subcommand (same as we did in configcommand). you're welcome to pr that too if you wish.",1,1,1,0.9658767580986024,0.9921746850013732,0.9808508157730104,1.0,accept,unanimous_agreement
763729120,9504,"oh i get it, sure i can take care of the sentinel command table one, we can hold on the other one",1,0,0,0.7511738538742065,0.8594897389411926,0.9461392760276794,0.0,accept,majority_agreement
763834762,9504,"just note, we don't wanna split the `sentinelcommand` just yet, it'll mess up the blame log unnecessarily. we can however do that for `sentinelsetcommand` since it's already split. but i think it'll look odd that some sub-commands have their own procs, and others don't.",0,0,0,0.6169095039367676,0.6107771992683411,0.7665489912033081,0.0,accept,unanimous_agreement
784472597,9504,"can we just set the `subcommand->name = fullname`? (or add a fullname field....) it seems to me now that the subcommand name are generally unusable, we must get the fullname to use it. so i suppose if we can just set the name = fullname, when we need it, we can just use it... like here, it looks like the subcommand won't get the full name (unfamiliar with modules) [a link]",0,0,0,0.9569634795188904,0.97303569316864,0.9712562561035156,0.0,accept,unanimous_agreement
784744322,9504,"interesting.. in theory changing that (past 7.0) could be a breaking change. but currently (before 7.0 is released), modules can't register sub-commands. -binbin did you conduct some search to see who's still using the simple `cmd->name` (on something that could be a sub-command) to find that one? if that's the only one, i tend to agree we wanna make `name` the full name by default and drop all the complication of `getfullcommandname`",0,0,0,0.6548911333084106,0.936822235584259,0.8399000763893127,0.0,accept,unanimous_agreement
785276139,9504,"actually no, i happen to see it (reviewing / studying some module codes.) i also tend to use the full name by default, so that we don't have to deal with `getfullcommandname`. i do some search, here are what i found: 1. latencyallcommandsfillcdf, #10103 2. aftererrorreply (we need to take care of it, it could be a subcommand i think): [code block] 3. acl cat? maybe we need to also print the subcommand in future? (for now, it only works on parentcommand) 4. command list? same as above, only print the parent command, but others one, like command docs config|get, can work on subcommand",0,0,0,0.9413549900054932,0.9848647117614746,0.977209746837616,0.0,accept,unanimous_agreement
785404957,9504,"considering sub-commands are now first class citizens, i suppose we should list them in acl cat and command list, wdyt? and iirc from -binbin findings, we might be better off just deleting `getfullcommandname` and put the full command name in `cmd->name`, which will also fix: * rm_getcurrentcommandname module api * the `critical` log warning in `aftererrorreply` * replies in `command list` and `acl cat` once we change them to include sub-commands.",0,0,0,0.9866868257522584,0.9928024411201476,0.9924519658088684,0.0,accept,unanimous_agreement
785730225,9504,"-binbin guy didn't respond yet, but i'm paranoid about forgetting this (discussion in a closed pr), and i think we must do that in 7.0 for completeness. wanna make a pr and we can continue the discussion there if needed?",-1,0,-1,0.9767875075340272,0.6617830991744995,0.6128750443458557,-1.0,accept,majority_agreement
785734544,9504,"sure, i can handle `getfullcommandname` first (i will keep in mind :)",0,1,0,0.6623083353042603,0.6159766912460327,0.9631794095039368,0.0,accept,majority_agreement
785794245,9504,"-binbin i agree. we should always store the fullname, and eliminate all uses `getfullcommandname`, except for the initial assignment of the name. we should rename `rediscommand.name` to something like `tmp_cmdname` so that the compiler will make sure we didn't miss anything. after that, we can call it `name` again. another option is to change it to `fullname` permanently in order to cause conflicts in open prs such as [a link]",0,0,0,0.9636157155036926,0.99107027053833,0.9349581599235536,0.0,accept,unanimous_agreement
785813095,9504,"i 'd like go the `fullname` option. at the same time we should also care about `subcommands_dict`, now the key is the subcommand short name. we can treat name as the short name(or rename it in some function arg name), fullname as the full name",0,0,0,0.9541419744491576,0.990455448627472,0.9907156229019164,0.0,accept,unanimous_agreement
785830956,9504,"i think that the command name is *always* the full name (also in the ubcommand_dict) to clarify, the word ""rewrite"" from `config rewrite` should **never** appear anywhere by itself, it should always be saved as ""config|rewrite""",0,0,0,0.9874152541160583,0.9923213124275208,0.989249587059021,0.0,accept,unanimous_agreement
785834462,9504,suggestion: we need to make sure that all callers to `commandaddsubcommand` already pass the subcommand with the fullname,0,0,0,0.98490309715271,0.9937548637390136,0.9944764971733092,0.0,accept,unanimous_agreement
785843516,9504,"-binbin maybe while you're working on it, you can also handle #10124 and see if we missed anything.",0,0,0,0.9749771952629088,0.9909400939941406,0.9683036208152772,0.0,accept,unanimous_agreement
627538983,8887,"i think the bloblen should be a `size_t` type, and the len a `long`. i think that's their true type, if the encoded size is smaller, it can be cast upwards, but at least in one case we can count records, which is in theory unlimited.",0,0,0,0.9847398400306702,0.9901118874549866,0.988338053226471,0.0,accept,unanimous_agreement
627540395,8887,"i think the interface should work with size_t, not unit32_t, it's not encoded yet, and iirc listpack can even encode longer strings in theory.",0,0,0,0.98660409450531,0.9878173470497132,0.9874217510223388,0.0,accept,unanimous_agreement
627548626,8887,"i'd imagine we're gonna see this ternary operator a lot, maybe it would be nice to make a macro like. (trying a terminology change the same time in this example) [code block] then to use it i'll just be: [code block]",0,0,0,0.91522216796875,0.979888081550598,0.9736484289169312,0.0,accept,unanimous_agreement
627561930,8887,"i'm trying to understand why you chose to add these adapters here, and the _lpget in listcontainer.c. arguably they should have the same fate. maybe it would be cleaner to promote the declaration of the list container interface to a header of it's own (not in server.h), and then include that header in both ziplist.c and listpack.c and have them create the types (removing the need for listcontainer.c)",0,0,0,0.9631224870681764,0.9910199046134948,0.9742034673690796,0.0,accept,unanimous_agreement
627571141,8887,why did you have to add the lp_eof check? if anything you need to break the loop after calling lpvalidatenext and before calling the callback. since lpvalidatenext may set `p` to null,0,0,0,0.9889816641807556,0.9894654750823976,0.992691457271576,0.0,accept,unanimous_agreement
627589895,8887,we need to conduct some benchmark to make sure we're not suffering a performance hit from that additional indirection,0,0,0,0.9638375639915466,0.8787806630134583,0.956917643547058,0.0,accept,unanimous_agreement
627593024,8887,"maybe create some is_packed macro for that in server.h? in combination with the packed_class macro suggestion, much of the code that works with that doesn't need to ever mention listpack or ziplist, and will remain the same if we ever add a 3rd packed encoding type. same goes for some portions of code that only need to save work with the pointer or blob, like rdb.c or defrag.c",0,0,0,0.9837903380393982,0.9949079155921936,0.9897418022155762,0.0,accept,unanimous_agreement
627599159,8887,"if we run the entire test suite in two modes, we can have a utility proc named `assert_packed_encoding` which can verify it's the expected type (i.e. it won't take an encoding name argument)",0,0,0,0.9874517321586608,0.9952605366706848,0.9936429262161256,0.0,accept,unanimous_agreement
627857844,8887,great! this is exactly the problem i've been struggling with for days (ziplistentity in ziplist) .,1,1,1,0.989035665988922,0.993474304676056,0.9969335794448853,1.0,accept,unanimous_agreement
627865728,8887,"if the next element is lp_eof, lpvalidatenext does not set the next element to null, resulting in 1 more count, this code is dead code, so there is no bug. i tried to set *pp to null in lpvalidatenext if the next entry is lp_eof, but that would cause stream validate to fail, because stream valiadte would call lpgetintegerifvalid, resulting in assert.",0,0,0,0.9831505417823792,0.8342446088790894,0.9905647039413452,0.0,accept,unanimous_agreement
627866169,8887,moving the eof check to lpvalidatenext is a better approach.,0,0,0,0.9739370942115784,0.99164879322052,0.9879083037376404,0.0,accept,unanimous_agreement
627866315,8887,i will do it.,0,0,0,0.9292978644371032,0.9751694798469543,0.8859524726867676,0.0,accept,unanimous_agreement
627866866,8887,good job!,1,1,1,0.990518033504486,0.9939982891082764,0.9946929812431335,1.0,accept,unanimous_agreement
627867115,8887,"yes, i will add these tests later, before not adding is to avoid the amount of code too much impact review.",0,0,0,0.9778582453727722,0.9758063554763794,0.9918406009674072,0.0,accept,unanimous_agreement
628836700,8887,"copy paste error, you should write your name and fix the date.",0,0,0,0.9589460492134094,0.9785847067832948,0.9581550359725952,0.0,accept,unanimous_agreement
628836809,8887,let's add some 1-2 line comment explaining what this file is for... i.e. a uniform interface for ziplist and listpack,0,0,0,0.985393762588501,0.9899436235427856,0.9922359585762024,0.0,accept,unanimous_agreement
628837091,8887,"while this is good for redis users, we need to try to think if maybe it hurts the corrupt-dump tests and the fuzzer. in which case maybe we'll need a debug trick to disable it.",0,0,0,0.9772800207138062,0.9651904106140136,0.9760532975196838,0.0,accept,unanimous_agreement
628837387,8887,"we need to think about this. on one hand, we want to eventually get rid of all ziplists. and if the user didn't wanna pay that price during upgrade (slowing it down considerably), we wanna do it gradually, but on the other hand, a full conversion of the entire ziplist here can cause significant latency. the alternative of doing it even more gradually, means to hold both a ziplist and a listpack side by side and gradually move entries from one to the other. this sounds like code complexity that we certainly don't wanna pay. wdyt? p.s if we do in some way make this optional, we need to let the corrupt-dump tests a way to skip it.",0,1,0,0.8081588745117188,0.5910540819168091,0.6604188084602356,0.0,accept,majority_agreement
628838258,8887,"i don't like these changes in the test infra. i would prefer to have something generic like the `--config` (e.g. see how it is used by daily.yml). maybe this means that want to promote this debug command into a config. we do have other configs that are used only for debugging and are undocumented (like the `key-load-delay`). unlike `set-skip-checksum-validation`, i suppose this one can't be abused, so maybe it's ok to make it an undocumented config. another alternative is to maybe add a generic mechanism that allows the test suite to execute an arbitrary command (or a list of commands) on each server right at startup. i.e. similar to `--config` but will get effective only after rdb loading. so we can do something like `./runtest --run-on-startup ""debug set-default-packed-encoding ziplist""` each `--run-on-startup` will append to a list, and when we start a server, we'll iterate on that list after it's online and before proceeding to the tests.",-1,-1,-1,0.9455049633979796,0.5335696935653687,0.8278089165687561,-1.0,accept,unanimous_agreement
628838760,8887,"my thought was that instead of spreading many of these, we can have a special proc named `assert_packed_encoding` unlike `assert_encoding`, it'll get just the key name, and it can match the encoding to be correct by sampling `config get`, or by assuming that both `ziplist` and `listpack` are valid (just confirms that it is encoded). in places were we have a test that's specific to the ziplist to listpack migration, we can keep using `assert_encoding`, since we know which one we expect. but in many other tests, where the old code used to do `assert_encoding` with ""ziplist"", we can now use that new `assert_packed_encoding` and drop the expected encoding argument so that this proc can do it on it's own.",0,0,0,0.9590463638305664,0.9912099838256836,0.9853702783584596,0.0,accept,unanimous_agreement
628844481,8887,"i would like to re-consider these type changes i suggested. i didn't expect them to have such a cascading effect on so many lines. or maybe it's due to my other comment about the type of `slen` below. i see the original signatures of these are: [code block] and we do need to consolidate them. i suppose the ziplist ones are the right ones, or at least closer to reality. i.e. the memory allocation is size_t, and the count is an integer (i think `unsigned long` is better). the listpack ones seem misguided, i don't see why they should be pinned to a 32bit encoding, specifically the `lplength` one since it doesn't just do decoding, it can also count!. so maybe we should start by reverting my next comment, and then re-consider this one.",0,0,0,0.8930570483207703,0.911733090877533,0.8938952684402466,0.0,accept,unanimous_agreement
628844482,8887,"i now see neither listpack nor ziplist can encode 64bit length strings, so my suggestion about changing `slen` to size_t may have been wrong. i didn't expect this request to have a cascading effect on so many lines. i see that previously ziplist was taking `unsigned int slen` and listpack took `uint32_t size`. so in reality, in both 32-bit and 64-bit builds, they're both 32-bit unsigned vars, and considering the encoding format can only hold up to 32bit length strings, even in 64-bit builds, i suppose that's ok (although size_t would have also be good). i suppose that they way to consolidate that to a uniform interface with minimal line change is to pick one of them. maybe `unsigned int` would be better.",0,0,0,0.9637117981910706,0.9804746508598328,0.9683722853660583,0.0,accept,unanimous_agreement
628844811,8887,"sorry for the zigzag, better late than later. i think these macros should be prefixed by `obj_` considering they're taking an `robj`. previously the code referred to `->encoding` and matched it to `obj_encoding_xxx`, but now it looks a bit vague.",-1,-1,-1,0.9883638620376588,0.9905960559844972,0.9913926124572754,-1.0,accept,unanimous_agreement
628845659,8887,"i'm still not sure about this change. certainly your previous version who called the entry_cb after progressing to the `next` element was wrong, and i do still think that the increment of `count++` should be last like before (not that it really makes any difference). but regardless, i'm not sure about the added check of lp_eof in the `while` loop. in contrast to what you wrote, lpvalidatenext does check for lp_eof and sets the output var to null. but indeed that would not cause the loop to break, since it returns `1`. setting the output to null will cause the next iteration to break, but the `count` will still be incremented. i think you're right that it should not be incremented, but then how come this check was passing (or how come your change didn't affect it)? [code block]",0,0,0,0.8005203604698181,0.8629700541496277,0.8641465902328491,0.0,accept,unanimous_agreement
628997060,8887,"i think it is reasonable that [code block] is [code block], the maximum string that listpack can store is 32 bits.",0,0,0,0.984401524066925,0.9871156811714172,0.9860206246376038,0.0,accept,unanimous_agreement
629000499,8887,"before this, [code block] of [code block] would never be set to 1, because this piece of code was dead, so the bug was never found. originally i wanted to test when next is [code block], set p to [code block], it will cause changes of [code block], so i give up and then forgot to restore [code block]. i will move [code block] to last.",0,0,0,0.9252214431762696,0.9403700828552246,0.9379414916038512,0.0,accept,unanimous_agreement
629398456,8887,"i think that when i wrote that comment i wanted to let the fuzzer (and existing consistent tests in corrupt-dump.tcl) to be able to run commands on a database full with ziplists. so that if we have some issue in for instance hrandmember that works on a corrupt ziplist, it'll still be able to find it. but now that i think of it, these issues can still be uncovered when the deep mode is disabled, in which case we won't run the listpack conversion, so the tests can still get to test ziplists.",0,0,0,0.9830268025398254,0.9860251545906068,0.9739867448806764,0.0,accept,unanimous_agreement
629420884,8887,"using [code block] causes test fail when require auth, so i changed [code block] to config, do you think this is appropriate? or should i only run [code block] if not need to require auth?",0,0,0,0.98143208026886,0.9932931661605836,0.9907194972038268,0.0,accept,unanimous_agreement
629443633,8887,"i suppose we can make that `--run-on-startup` a best effort thing. if we get auth error, we ignore it. for our use case, we add it so that we can run the entire test suite with some modification (on encoding), so it's not that bad if some test (specifically ones that test acl) will not use it (won't affect our data type / encoding tests). another benefit of the `--run-on-startup`, is that it can be used together with `--host` on a preexisting server (where we don't control the config). bottom line, i think i still prefer it because: 1. we don't promote something we wanted as a debug command into a config. 2. we create a generic mechanism that can be used for other things. the downside is that this way we don't control creation of keys when loading rdb / aof file. but the upside is that it is clear this isn't a feature of redis (it's a debug command, rather than an undocumented config), we won't have any concerns about breaking backwards compatibility if we ever delete it.",0,0,0,0.9373654127120972,0.9827882647514344,0.9256045818328856,0.0,accept,unanimous_agreement
630257363,8887,"i have added [code block], and added a task in ci for testing.",0,0,0,0.988239049911499,0.9863762259483336,0.9929972290992736,0.0,accept,unanimous_agreement
630260749,8887,"i tried adding ``config get default-packed-encoding``, but found that this change would cause the introspection test to fail, it would first ``config get *``, then ``config set``, but ``default-packed-encoding`` would not have [code block] . so i'm asserting_packed_encoding to determine if it's listpack or ziplist.",0,0,0,0.9873565435409546,0.991950273513794,0.9902644157409668,0.0,accept,unanimous_agreement
631069999,8887,any reason you didn't use an createenumconfig?,0,0,0,0.9809911251068116,0.990074336528778,0.9932998418807985,0.0,accept,unanimous_agreement
631077216,8887,"interesting.. i thought it's gonna be a list of redis commands (without the `r`) to run on startup, not a list of scripts.. but i guess your approach is more flexible.",1,0,0,0.6313129663467407,0.8578495383262634,0.5660263299942017,0.0,accept,majority_agreement
631079710,8887,"i think we need to try to ""compact"" it when the loop is over. i.e. a realloc that may end up being a nop (considering it is likely to fall into the same allocator bin)",0,0,0,0.9834752082824708,0.9811677932739258,0.9835161566734314,0.0,accept,unanimous_agreement
631122798,8887,"considering your optimized lpfind, i think it would be nice to add a benchmark that searches for something numeric too.",0,0,0,0.9363104104995728,0.968552827835083,0.9748449325561525,0.0,accept,unanimous_agreement
631128539,8887,"please make sure these new tests don't take too long (they're running in the daily ci, with valgrind too)",0,0,0,0.976201057434082,0.9897614121437072,0.9885291457176208,0.0,accept,unanimous_agreement
631136272,8887,"it would be a good idea to run the corrupt-dump-fuzzer with `--accurate` (or even edit the test and change the limits to run for a several hours). and then repeat that with valgrind. maybe we can do that later, after converting more data types to listpack.",0,0,0,0.9706507921218872,0.9923620223999025,0.9777746200561525,0.0,accept,unanimous_agreement
631142725,8887,"i missread it, on my phone. i will do it.",0,0,0,0.9122001528739928,0.9254432320594788,0.964642345905304,0.0,accept,unanimous_agreement
631144856,8887,"indeed,i missing it.",-1,0,0,0.67365562915802,0.9221744537353516,0.6996635794639587,0.0,accept,majority_agreement
631147224,8887,"stress will be a little slower, but stress is not very necessary to leave, i just carry from ziplist. i will run valgrind to check tomorrow.",0,0,0,0.8332435488700867,0.9486621022224426,0.8992612957954407,0.0,accept,unanimous_agreement
631148404,8887,i wull do it tomorrow.,0,0,0,0.8089650273323059,0.9680161476135254,0.9859490394592284,0.0,accept,unanimous_agreement
631153486,8887,"i seem to remember saying that this config should be hidden and should not be used normally, and that it was only for testing ziplist, but i can't find that reply, strange.",-1,-1,-1,0.8313357830047607,0.9497233629226683,0.9691727757453918,-1.0,accept,unanimous_agreement
631170298,8887,"i think you misunderstood me. i meant that it should be undocumented (like the `key-load-delay`). anyway, water under the bridge.. we took the debug command approach.",0,0,0,0.9311146140098572,0.6116938591003418,0.9362468719482422,0.0,accept,unanimous_agreement
631688122,8887,"[code block] felling is not necessary. the memory is already shrunk in [code block], and since we allocate a sufficient amount of memory at the beginning, [code block] does not change the listpack memory address until the realloced memory is larger than ziplsit size.",0,0,0,0.9812606573104858,0.9940146803855896,0.9935770630836488,0.0,accept,unanimous_agreement
631698388,8887,"i'm not sure i follow you. if lpinsert would compact, then making an initial big allocation is not helpful, since the first insertion will shrink it back. and if it doesn't then in case the original allocation was too big, we're left with that excess at the end of filling.",0,-1,0,0.9472936391830444,0.7040953040122986,0.6654239296913147,0.0,accept,majority_agreement
631702296,8887,"yes, the first insertion will shrink it back, when the next insert, there is still a large chunk of memory behind this chunk of memory that is not used, so when it is inserted again, only the memory size of the [code block] is changed, and no memory copy is made, which is a performance improvement.",0,0,0,0.9729906916618348,0.9887927174568176,0.9925851225852966,0.0,accept,unanimous_agreement
631703242,8887,"i'll write a test on this code(to see if the memory address changes), to see if it works in both malloc and jemalloc.",0,0,0,0.9877570867538452,0.9921312928199768,0.9914951324462892,0.0,accept,unanimous_agreement
631719187,8887,maybe write some underlying code not using `malloc` will be quicker. but the code will be ugly,-1,-1,-1,0.908619225025177,0.9718573093414308,0.9191684722900392,-1.0,accept,unanimous_agreement
632197317,8887,"[code block] the above test is fine, the pre-allocated space, shrink and then expand, the address will not change. #6281 this modification will also have the same problem, lpappendinteger will also shrink. i don't think it makes sense to shrink in lpinsert, if [code block] is not pre-allocated, shrink is nop, if memory is pre-allocated, user should execute lpshrinktofit manually. now that memory realloc no longer causes performance problems, removing the [code block] shrink code will improve performance by 2 seconds (1,000,000 keys), mainly because this code is ambiguous.",0,0,0,0.946183145046234,0.9792484045028688,0.9820260405540466,0.0,accept,unanimous_agreement
632227515,8887,"i changed it to [code block], because it can use config get to verify that the encoding is correct.",0,0,0,0.989045798778534,0.9901784658432008,0.9945770502090454,0.0,accept,unanimous_agreement
632542825,8887,stress test is fast under valgrind.,0,0,0,0.9688319563865662,0.9622589945793152,0.781432032585144,0.0,accept,unanimous_agreement
635873045,8887,"one of us is missing something. in #6281 there's a change in `lpinsert` to call realloc only if we need to increase the allocation size (see the call to lp_malloc_size), but not when it wants to shrink it. in the test you conducted above, it looks like you're adding about 60 bytes, on a pre-allocation of 100, so i think the realloc will be skipped. either that, or maybe you're not using jemalloc (libc malloc can return the same pointer even if it changes the allocation size). in that case, if we made an allocation of 100 bytes, and used only 60, we do need a realloc to shrink it (which in jemalloc will certainly allocate a new address and do a memcpy). if i'm missing something, and lpinsert does call realloc to shrink, then (at least with jemalloc) it'll allocate a new block and move the memory to a different pointer, eliminating the optimization of pre-allocation.",0,0,0,0.9605867266654968,0.9914373755455016,0.982291340827942,0.0,accept,unanimous_agreement
635903761,8887,"sorry for my lack of seriousness. the listpack shrinks only when elements are removed from the listpack, or when the length becomes smaller after replacing the element.",-1,-1,-1,0.9897902607917786,0.985059380531311,0.9898831248283386,-1.0,accept,unanimous_agreement
635912338,8887,"ok. so in this code (converting from ziplist to listpack) we only add new elements, so we never shrink, right? in that case we do need to call `lpshrinktofit` at the end.",0,0,0,0.9855415225028992,0.991041362285614,0.98677396774292,0.0,accept,unanimous_agreement
635915422,8887,yes.,0,0,0,0.969875693321228,0.98186594247818,0.9851860404014589,0.0,accept,unanimous_agreement
635950385,8887,side note: now we can just use `--config` instead of `--run-on-startup`. i do like to keep that feature in the test suite though. so maybe it's not a bad idea to keep using it here.,0,0,0,0.8878598213195801,0.9639163017272948,0.8904924392700195,0.0,accept,unanimous_agreement
655710988,8887,should we rename this to packedentry?,0,0,0,0.9828893542289734,0.9945909976959229,0.9939080476760864,0.0,accept,unanimous_agreement
655823605,8887,"yes. it will eventually be modified to [code block]. since it causes a lot of diffs, i'll leave it alone for now.",0,0,0,0.9708757400512696,0.9911126494407654,0.9860438108444214,0.0,accept,unanimous_agreement
657911236,8887,don't you need to handle obj_encoding_listpack here too? seems like a merge conflict that wasn't resolved properly...,-1,0,0,0.7638225555419922,0.930763840675354,0.9745396375656128,0.0,accept,majority_agreement
658396394,8887,"ohh, my mistake.",-1,-1,-1,0.9796690344810486,0.916894555091858,0.9634814262390136,-1.0,accept,unanimous_agreement
667430244,8887,"the function's top comment is outdated (stating 0 is returned on wrong encoding). i don't recall the history of this function, is it just an optimized combination of `lpcurrentencodedsizeunsafe + lpencodebacklen`? anyway, imho if we keep the assertion, there's no need to mention bad encoding in the top comment.",0,0,0,0.949905812740326,0.98601496219635,0.9853004813194276,0.0,accept,unanimous_agreement
667430617,8887,"maybe we wanna stick to the listpack terminology, i.e. `append`, and maybe `prepend` instead of pushhead and pushtail?",0,0,0,0.9870957136154176,0.9954946041107178,0.9887707233428956,0.0,accept,unanimous_agreement
667440397,8887,"maybe this can be an if-else, to avoid the chance of double conversion? it means maintaining another block of conversion code, but it's just a short loop, right, not many lines...",0,0,0,0.9657022953033448,0.9435445070266724,0.9751676917076112,0.0,accept,unanimous_agreement
667598650,8887,"yes, it's just an optimized combination of [code block]. it can bring very significant performance gains.",0,0,0,0.9541831016540528,0.9307476282119752,0.9904080033302308,0.0,accept,unanimous_agreement
668361763,8887,done it.,0,0,0,0.9653505682945251,0.9637441039085388,0.876763105392456,0.0,accept,unanimous_agreement
668362159,8887,"done it. but i always feel that the [code block] interface is not quite clear, i don't know if it's because i think it's not easy to type out.",-1,0,0,0.8157273530960083,0.6315871477127075,0.8790838122367859,0.0,accept,majority_agreement
668408089,8887,"i removed this method, and after testing it, i found that the improvement it brings is only due to the reduction of function call overhead, which is not needed since [code block] is already added.",0,0,0,0.9821536540985109,0.9880958795547484,0.9925169348716736,0.0,accept,unanimous_agreement
673793558,8887,"i understand you followed that advise recently? i.e. change `min_duration` or `min_cycles` to very long, and run with a long `--timeout` for several hours?",0,0,0,0.9854059219360352,0.992361545562744,0.993094563484192,0.0,accept,unanimous_agreement
673817534,8887,"shouldn't this be: ? [code block] or alternatively if we know that encoding 6bit +2 is certainly just one byte, can we make such assumptions on 12 and 32bit strings? additionally isn't the current code vulnerable to abuse (someone storing a small string (e.g. length of one char) in a large encoding type (e.g. a 32bit_str)?",0,0,0,0.973086953163147,0.990412414073944,0.9918909072875975,0.0,accept,unanimous_agreement
673824819,8887,"we need to document the meaning of `size`. i.e. since there are so many different meanings for it, like the size of the entry data and size of the encoded len, or the total including backlen.. etc. the value here is similar to what's currently returned from `lpcurrentencodedsizeunsafe` plus the backlen, right? so it includes ""the encoding byte, length bytes, the element data itself, and the backlen""",0,0,0,0.9862381219863892,0.9926213026046752,0.991782546043396,0.0,accept,unanimous_agreement
673835457,8887,"this reply was collapsed, so no wonder i couldn't see it. i did that, and ran it for two days and found a problem([a link] but now it's reverted, because of a change of [a link] i'll run it again.",0,0,0,0.8239129781723022,0.7233057618141174,0.783882737159729,0.0,accept,unanimous_agreement
673887637,8887,"ziplistrandompair does have a detailed top comment, please copy that too (and adjust). same goes for lprandompairs, and lprandompairsunique",0,0,0,0.9830217361450196,0.9855395555496216,0.9877448678016664,0.0,accept,unanimous_agreement
673909264,8887,"i hate loosing too many lines on nonsense, harder to focus on the important parts.. one option is to do something like this: [code block] another, maybe better option is to modify `lpsavevalue`, it was created as a helper for exactly one use case, so we can change it to take two inputs rather than 3, and have that if-else inside. whatever we choose, need to repeat that on the value block below, and also on the two blocks in the next function.",-1,-1,-1,0.9889788031578064,0.8814429640769958,0.992440104484558,-1.0,accept,unanimous_agreement
673909606,8887,"[code block] if we take it, we can do the same on the two assertions in the next function too",0,0,0,0.9882228970527648,0.9858792424201964,0.9938978552818298,0.0,accept,unanimous_agreement
673948779,8887,"since we now do an o(n) iteration anyway, maybe we wanna validate integrity in deep mode unconditionally (like we do for zipmaps). but maybe unlike zipmap (which we don't really expect to see), in this case we wanna make the code more efficient by doing the integrity check as part of the conversion and not in two separate loops? wdyt?",0,0,0,0.9804338812828064,0.9816815257072448,0.9889095425605774,0.0,accept,unanimous_agreement
674517314,8887,"same pattern as the one i've commented in the random generators in listpack.c, right? maybe we need a macro or an lpget wrapper for that if it's very common. maybe not... but at least i would vote for changing this into one, two or three lines instead of 6. maybe it's just my twisted brain though..",-1,-1,-1,0.967485249042511,0.8391618728637695,0.6819220185279846,-1.0,accept,unanimous_agreement
674518254,8887,another one of these.. although that one doesn't feel so bad (not a crowded function),0,-1,-1,0.8849867582321167,0.856523334980011,0.941711723804474,-1.0,accept,majority_agreement
674519444,8887,why `32` and not `long_str_size`?,0,0,0,0.984900712966919,0.9916241765022278,0.9877315163612366,0.0,accept,unanimous_agreement
674522368,8887,"it's been running for 20 hours, no problems were found.",0,0,0,0.9501949548721312,0.9316257834434508,0.9873994588851928,0.0,accept,unanimous_agreement
674522432,8887,"there is some silly overhead here converting a long to string (due to the interface of `lpappend`), so that most likely `lpappend` will convert it back to a long. maybe we should consider improving that, not necessarily now..",-1,-1,-1,0.717074990272522,0.5427995920181274,0.954288363456726,-1.0,accept,unanimous_agreement
674525792,8887,the code (comment) was changed (fixed) after you copied it. see bf92000e2dc33d484c73eaaa0af5cc47acf81b82 maybe you should check for other recent changes especially in ziplist.c and t_hash.c [code block],0,0,0,0.98577880859375,0.9950873255729676,0.9954702854156494,0.0,accept,unanimous_agreement
674531818,8887,"few issues here: first, the obvious one is that we ignore the error returned from `catch` and the test doesn't really cares if the restore failed or succeeded. this would have been ok, if we had an assertion after it that makes sure the server died on assertion. i.e. [code block] but instead we have some (outdated?) verification that makes sure there was no ziplist assertion. secondly, as i suggested in my review of rdb.c, maybe we wanna make the deep validation of ziplists unconditional, since we're anyway doing an o(n) iteration on the members, so o(2n) is not that bad. if we do that, we would be expecting a `assert_match ""*bad data format*"" $err` response from restore.",0,0,0,0.9567732214927672,0.988338053226471,0.9028118252754213,0.0,accept,unanimous_agreement
674533222,8887,"let's keep the convention of a 1/1 test/server ratio in this file. i.e. each test comes with it's own server, and each server with it's own test. i did this since we're tasting assertions and crashes.. p.s. again here, with deep sanitization, we don't expect a restore command to crash, we'd expect it to fail gracefully.",0,0,0,0.9600778222084044,0.9557470083236694,0.9598942399024964,0.0,accept,unanimous_agreement
674535319,8887,is that a listpack that you generated manually with dup records?,0,0,0,0.9837231636047364,0.9922352433204652,0.9947832226753236,0.0,accept,unanimous_agreement
674551034,8887,"i use `corrupt payload: valid zipped hash header, dup records` test data to create the listpack.",0,0,0,0.9618431329727172,0.9952006340026855,0.99490886926651,0.0,accept,unanimous_agreement
674634753,8887,"i should indeed use long_str_size, it looks like i copied it from quicklist.",0,0,0,0.9846975803375244,0.990833818912506,0.9920172691345216,0.0,accept,unanimous_agreement
674639247,8887,"this problem is also present in t_stream(`lpappendinteger`), which i will optimize after this pr.",0,0,0,0.9876009225845336,0.993605613708496,0.9942687749862672,0.0,accept,unanimous_agreement
674640688,8887,"this is a great idea, i already felt bad when i changed this.",-1,1,1,0.8829145431518555,0.8961186408996582,0.9882628321647644,1.0,accept,majority_agreement
674642039,8887,good.,1,1,1,0.9122697710990906,0.8666313290596008,0.7729474306106567,1.0,accept,unanimous_agreement
674670845,8887,"1) it should be `if (size) *size = 1 + *count + lpencodebacklen(null, *count + 1);`, it brings no significant improvement. 2) the `backlen` of 12bit and 32bit string are dynamic lengths, so we can't assume their entry length. 3) there is no way for listpack to store a small string in a large encoding type, even if `replace` operation, it will become `6bit_str` when replacing `32bit_string` to a small string.",0,0,0,0.9818166494369508,0.9934351444244384,0.9871276617050172,0.0,accept,unanimous_agreement
675376192,8887,"sorry for my mistake, i found the issue from corrupt-dump-fuzzer in the process of making changes. i don't know why it didn't come out the last time i ran it, silly me. i will carry out one more.",-1,-1,-1,0.988500952720642,0.9921634197235109,0.9946619868278505,-1.0,accept,unanimous_agreement
677168615,8887,"i meant for a case that someone produces a specially crafted restore payload, then stores a small item in a large encoding type. then maybe there's a mismatch between the encoded len and the actual prevlen bytes. i.e. the listpack can still be iterated correctly from head to tail and tail to head, and the integrity validation passes. but some piece of code that assumes it knows the prevlen bytes fails... but i guess even for forward iteration, must know the size of the prevlen bytes.. that's part of the design of the listpack...",0,0,0,0.9589989185333252,0.7857171893119812,0.9408688545227052,0.0,accept,unanimous_agreement
677172042,8887,"why did you add the integrity assertion here? the idea was that all these functions assume the input they get is already validated, and they just validate their output (e.g. in the context of lpnext). i think i documented it somewhere. since lpfirst doesn't really do any iteration or decoding, (and the header is validated even in the shallow integrity scan), i don't think we need that assertion.",0,0,0,0.9831724166870116,0.9887309670448304,0.988511085510254,0.0,accept,unanimous_agreement
677175138,8887,"1. why have this and not use the `assert_integrity` macro? the macro is in theory better since it is sure to get inlined (the `inline` is just a recommendation that the compiler can ignore). 2. why use `lpvalidatenext` (also moves to the next element, i.e. returns a new `p` which we don't use)",0,0,0,0.9860646724700928,0.9943640232086182,0.9875956773757936,0.0,accept,unanimous_agreement
677176363,8887,"these can also be replaced with the new lpgetvalue, as well as the ones in lprandompairsunique. or",0,0,0,0.9871737957000732,0.9946165680885316,0.9957185387611388,0.0,accept,unanimous_agreement
677181591,8887,"if the main purpose of this call now is the conversion, let's rename it. maybe `hashziplistconvertandvalidate` or `hashziplistconverttolistpack` and place a comment that: 1. it's safe to call on non-validated ziplists. 2. it returns false when encounter an integrity validation issue. also, we now lost the ability to convert directly from ziplist to dict, maybe that's not that bad, it shouldn't normally happen.",0,0,0,0.9613595604896544,0.9895386695861816,0.9684786796569824,0.0,accept,unanimous_agreement
677194790,8887,"for values (when `data->count` is even), it is wasteful to create the sds (at least in the case of strings). i.e. these sds strings are only needed for the dup search dict on field names. we can either make some attempt to do this sds creation only for numeric values, and avoid it for string values, or better yet, create an lpappend variant that takes a long long, and avoid creating sds strings for the values altogether. i know we discussed this in the past in the context of numerics. but here we also do excessive work on strings.",0,0,0,0.8279812335968018,0.9875040650367736,0.9423561096191406,0.0,accept,unanimous_agreement
677196233,8887,"i see you did update the comment, but we also need to update the function name, and mention what it expects of the `lp` argument. i think i would call it `hashziplistconvertandvalidateintegrity`",0,0,0,0.9807387590408324,0.9892877340316772,0.9900667667388916,0.0,accept,unanimous_agreement
677199794,8887,the comment above the test became outdated.,0,0,0,0.6425261497497559,0.9157642126083374,0.9727507829666138,0.0,accept,unanimous_agreement
677206850,8887,"`assert_integrity` does not apply, because when entry_size exceeds, `assert_integrity` does not trigger the assertion, see my new `corrupt payload: fuzzer findings - hash listpack too long entry len` test , which passes the verification in the old code.",0,0,0,0.9565219879150392,0.9951812624931335,0.9943178296089172,0.0,accept,unanimous_agreement
677209269,8887,"i recall why i added this in the first place, because i found it when i was running `fuzzer`, and i can't believe i didn't add it to the test.",-1,0,-1,0.5591998100280762,0.983989417552948,0.8059390187263489,-1.0,accept,majority_agreement
677261981,8887,"you mean that it's because it doesn't validate the prevlen part? out of the 3 places that use it, that's probably only relevant for `lpprev`, and even there, arguably it is done too late. if that's the case, i'd suggest to revert the other places and improve `lpprev` to assert on the result of lpdecodebacklen or the range it leads to. but maybe the existing call to `assert_integrity` after adjusting `p` already covers that. maybe i'm missing something, or maybe i just need to run that new test you added and debug it.. let me know.",0,0,0,0.9615616202354432,0.9817649126052856,0.9811205267906188,0.0,accept,unanimous_agreement
677268153,8887,"the stack of `corrupt payload: fuzzer findings - hash listpack too long entry len`. [code block] because this command copies data while iterating, if the entry_size is very large, `lpget` will return an illegal address.",0,0,0,0.7391546368598938,0.9784734845161438,0.9937638640403748,0.0,accept,unanimous_agreement
677271815,8887,i use `lpvalidatenext` simply because it verifies that the entry_size is not out of bounds. but i don't want it to move to the next entry.,0,0,0,0.8952165842056274,0.9571043252944946,0.9917237162590028,0.0,accept,unanimous_agreement
677321973,8887,so the violation in this case was because of lpget (after lpnext)? maybe we need to add a call to assert_integrity_len in lpget? maybe add a comment explaining it.,0,0,0,0.9829432964324952,0.994728982448578,0.992451012134552,0.0,accept,unanimous_agreement
677325862,8887,"yes. i thought about it, but `lpget` doesn't have `lp` variable, so `assert_integrity_len` can't be used in `lpget`.",0,0,0,0.9877699613571168,0.9926361441612244,0.988145351409912,0.0,accept,unanimous_agreement
677340209,8887,"actually, i wanna go back on that.. the contract i was trying to make is that when some function returns a `p`, it should validate that `p`, and when a function takes a `p` as input, it can assume it is safe to use.",0,0,0,0.982693076133728,0.9522936344146729,0.9781703352928162,0.0,accept,unanimous_agreement
677350484,8887,that's it!,1,1,1,0.7996023297309875,0.6723784804344177,0.7064263224601746,1.0,accept,unanimous_agreement
678283954,8887,fixed.,0,0,0,0.9810503125190736,0.979083240032196,0.9905837774276732,0.0,accept,unanimous_agreement
678284068,8887,fixed.,0,0,0,0.9810503125190736,0.979083240032196,0.9905837774276732,0.0,accept,unanimous_agreement
678286046,8887,i've added support for inserting integer directly into listpack.,0,0,0,0.988613486289978,0.9825534224510192,0.9893773198127748,0.0,accept,unanimous_agreement
678286114,8887,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
678286219,8887,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
680807576,8887,"we assert that there's no ""integrity check failed""? let's assert on what we do have ""dup records"" print? i see you have a few other `verify_log_message 0 ""*integrity check failed*"" 0` checks. i think they should all be replaced with what you're expecting to find, rather than what you're not expecting to find. p.s. the only exception for that are when we wanna make sure we didn't crash by signal (i.e. matching `crashed by signal` to 0), and if we wanna make sure we didn't crash at all (for that we usually just do `r ping`, with a comment)",0,0,0,0.9736061096191406,0.9880417585372924,0.986454427242279,0.0,accept,unanimous_agreement
680812868,8887,"this function now needs to be renamed too (and comment updated). it's not only a validation helper function, but also a conversion helper function.",0,0,0,0.9886364340782166,0.993416666984558,0.9947869777679444,0.0,accept,unanimous_agreement
680819636,8887,"i think maybe we can do without the `enctype` argument [code block] internally the function can maybe still use enctype like it used to use.. just the interface may be a bit cleaner> wdyt? p.s. we're also missing some documentation of `enclen`, right? obviously if we take that, we need to update the other references to `ele` in the code and comments.",0,0,0,0.9840480089187622,0.9756776094436646,0.9637768864631652,0.0,accept,unanimous_agreement
680825532,8887,"maybe mention that it can used to replace and delete too, and refer to lpinsert for details.",0,0,0,0.9874048829078674,0.9934027791023254,0.9914427399635316,0.0,accept,unanimous_agreement
680827063,8887,"shall we also add lpprependinteger, and lpreplaceinteger right away, or wait for someone that needs it? actually i see there's already one in t_stream.c, let's delete it from there and both of these additional interfaces here.",0,0,0,0.9866973757743835,0.9937784075737,0.9951613545417786,0.0,accept,unanimous_agreement
680872452,8887,"ohh, i originally wanted to design it as [code block], but i found it impossible to tell if it is deletion. the way you said it is the right way.",0,0,0,0.9341397881507874,0.9213083386421204,0.9630944728851318,0.0,accept,unanimous_agreement
681405461,8887,"i feel like you forgot to `verify_log_message`, it means there's an ""integrity check failed"". i wll add `r ping`.",0,0,0,0.7614492177963257,0.9687682390213012,0.9922338724136353,0.0,accept,unanimous_agreement
681666151,8887,`lpprependinteger` and `lpreplaceinteger` have been added.,0,0,0,0.9869857430458068,0.991111934185028,0.9935736060142516,0.0,accept,unanimous_agreement
681666438,8887,`lpinsertstring` has been removed.,0,0,0,0.9860586524009703,0.9932942986488342,0.9939770698547364,0.0,accept,unanimous_agreement
681666566,8887,fixed.,0,0,0,0.9810503125190736,0.979083240032196,0.9905837774276732,0.0,accept,unanimous_agreement
681666836,8887,fixed.,0,0,0,0.9810503125190736,0.979083240032196,0.9905837774276732,0.0,accept,unanimous_agreement
683759014,8887,"ohh, my bad. i confused it with `count_log_message`. and thought the last `0` means we're verifying that the message was **not** found in the logs.",-1,-1,-1,0.9898242354393004,0.9821560978889464,0.9904869198799132,-1.0,accept,unanimous_agreement
683767415,8887,why did you change lpreplace to take a double pointer (`**`) `p`? i suppose just for symmetry with lpreplaceinteger? let's at least document what it does with it (copy the text from lpreplaceinteger?).,0,0,0,0.989120602607727,0.9940485954284668,0.992380917072296,0.0,accept,unanimous_agreement
683886760,8887,"yes, just symmetry with `lpreplaceinteger`.",0,0,0,0.985136866569519,0.990842342376709,0.9945279955863952,0.0,accept,unanimous_agreement
684723837,8887,"i see there were some issues with merge conflicts of this file. i see this test existed twice, once with deep sanitization and once without. i see that a later commit added back, but only with sanitization. is that intended?",0,0,0,0.9850767254829408,0.973922610282898,0.9841014742851256,0.0,accept,unanimous_agreement
684723925,8887,"i see this test was deleted in the merge, was this intended?",0,0,0,0.988087832927704,0.9927656650543212,0.9936752915382384,0.0,accept,unanimous_agreement
684724912,8887,"you mean that this was forgotten (or actually a bug introduced) in #9321? (doesn't seem related to #9297) anyway, since these other prs may (or may not) be backported to 6.2, maybe we better get that fix to a pr of it's own (so it can easily get backported too).",0,0,0,0.985600471496582,0.9943291544914246,0.9874460697174072,0.0,accept,unanimous_agreement
684725446,8887,"ohh, on a second look, this line wasn't introduced by 9321, it always existed, but indeed it prevents 9297 from doing it's job. i guess it also indicates that 9297 was missing some test to cover that case... how did you discover it now? in any way, i still prefer to take this to an independent pr. if you're aware of other unrelated fixes in this pr that should be taken to another pr please let me know. (only important for fixes that actually have an impact, not ones in dead code).",0,0,0,0.9029900431632996,0.8524373769760132,0.776789128780365,0.0,accept,unanimous_agreement
684869635,8887,"i deliberately removed `hash listpack too long entry len` and `hash listpack first element too long entry len - without sanitize`, because these two tests were fixed in #9321, and this code only fixed `hash listpack first element too long entry len - without sanitize`, so i just kept it and rename it.",0,0,0,0.9801436066627502,0.9923384189605712,0.9931476712226868,0.0,accept,unanimous_agreement
684870119,8887,"yes, due to a mistake on my part, they were to be processed in #9297. i'll handle them in new pr.",0,0,0,0.9753153324127196,0.9886138439178468,0.970491349697113,0.0,accept,unanimous_agreement
1030154017,8887,"i see in here, we didn't check `deep_integrity_validation` and `hashziplistconvertandvalidateintegrity` now rename to `ziplistpairsconvertandvalidateintegrity` it always pass `deep = 1` to `ziplistvalidateintegrity` is this intentional or is it an overlook? we should check `deep_integrity_validation` or need a `stat_dump_payload_sanitizations++`?",0,0,0,0.9875747561454772,0.9947051405906676,0.9932158589363098,0.0,accept,unanimous_agreement
1030164692,8887,"yes, because ziplist is converted to listpack, so we have to do a deep sanitization, otherwise it will be wrong in subsequent operations as well.",0,0,0,0.9826201796531676,0.986985981464386,0.9890919923782348,0.0,accept,unanimous_agreement
1030246185,8887,"it's a decision we previously took. if anyway we're gonna do o(n) operation on conversion, we might as well do o(2n), and avoid complicated code.",0,0,0,0.9837353229522704,0.9897168278694152,0.9813604354858398,0.0,accept,unanimous_agreement
977457959,11303,i don't think this `if` encoding check is needed. the body of the `if` here just uses generic listtypeiterator functions and doesn't depend on encoding.,0,0,0,0.986129343509674,0.9839990735054016,0.9823989272117616,0.0,accept,unanimous_agreement
977469122,11303,i suggest adding a comment about what it returns and how.,0,0,0,0.9702903032302856,0.9711576104164124,0.9928728342056274,0.0,accept,unanimous_agreement
977551408,11303,"are these objects that are assumed to be added to the list later, to check if we need to convert before we add them? i think this could be clarified. at first, i thought this function checks some elements inside the list itself.",0,0,0,0.9863339066505432,0.9892308115959167,0.992070734500885,0.0,accept,unanimous_agreement
977563700,11303,even simpler? [code block],0,0,0,0.9858450889587402,0.9889721274375916,0.9915088415145874,0.0,accept,unanimous_agreement
977583740,11303,"a `void` function doesn't really return anything. :smile: i suggest wording like ""populates vstr"" or ""points vstr to ..."". it doesn't hurt also explaining what it means that `*vstr == null`, etc.",1,1,1,0.900783360004425,0.9860116839408876,0.9648866653442384,1.0,accept,unanimous_agreement
977586275,11303,a short comment explaining this function wouldn't hurt.,0,0,0,0.9588715434074402,0.8448691964149475,0.9682521224021912,0.0,accept,unanimous_agreement
977606528,11303,this `if` is unnecessary. the body of this uses generic listtype functions that don't depend on encoding.,0,0,0,0.9861794114112854,0.9880700707435608,0.993573009967804,0.0,accept,unanimous_agreement
977610527,11303,[code block] some distinction between the different cases can be good. the title appears in the name of test cases which is printed out when running the tests.,0,0,0,0.9645909070968628,0.9763824343681335,0.9863241314888,0.0,accept,unanimous_agreement
977614810,11303,indentation?,0,0,0,0.9771732091903688,0.9491462707519532,0.9903632998466492,0.0,accept,unanimous_agreement
977616924,11303,"if indentation isn't really correct, it can be good to add a comment about what each brace is matching. } ; # foreach type",0,0,0,0.953174352645874,0.9727501273155212,0.9927157759666444,0.0,accept,unanimous_agreement
978743994,11303,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
978744161,11303,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
978746623,11303,"i was going to change it to`p = lpseek(subject->ptr,(where == list_head) ? 0 : -1);`, and finally found that you are right, it will be more efficient.",0,0,0,0.9605563879013062,0.96464866399765,0.9710389971733092,0.0,accept,unanimous_agreement
978747457,11303,"great, i perfer it too.",1,1,1,0.7968681454658508,0.9489506483078004,0.9918286204338074,1.0,accept,unanimous_agreement
978748270,11303,"my bad, `listtypecurrentobject` is dup with `listtypegetvalue`, i removed it.",-1,-1,-1,0.9828693270683287,0.984572172164917,0.9927194118499756,-1.0,accept,unanimous_agreement
978748414,11303,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
978748531,11303,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
978748631,11303,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
978749752,11303,"i did it on purpose, i didn't want the indentation to cause more changes.",0,0,0,0.6177699565887451,0.8571019768714905,0.980860471725464,0.0,accept,unanimous_agreement
978749839,11303,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
978762546,11303,"please see again, no sure it's enough.",-1,0,0,0.8764855861663818,0.9575089812278748,0.9733330011367798,0.0,accept,majority_agreement
978762662,11303,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
978762986,11303,also mention what it means if the function returns null?,0,0,0,0.9844380021095276,0.9918295741081238,0.9940826296806335,0.0,accept,unanimous_agreement
978784468,11303,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
978898468,11303,it is also easier to read. 8-),1,1,1,0.9413251876831056,0.9930393099784852,0.9183564186096193,1.0,accept,unanimous_agreement
978945464,11303,perfect.,1,1,0,0.832798421382904,0.9134291410446168,0.6750130653381348,1.0,accept,majority_agreement
978946182,11303,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
990977601,11303,"so far, the module implementation only used the high level abstraction of the list type. i think the abstraction is better if it doesn't need to know about the internals, such as encodings. is it possible to let listtypeinsert handle conversion from listpack to quicklist?",0,0,0,0.9837051033973694,0.9919597506523132,0.9798542857170104,0.0,accept,unanimous_agreement
990978408,11303,is it possible to let listtypedelete handle the conversion from quicklist to listpack? it can be a better abstraction.,0,0,0,0.976365566253662,0.994285523891449,0.993378221988678,0.0,accept,unanimous_agreement
990985282,11303,it's dangerous to convert list in iterator. both `listtypeinsert` and `listtypedelete` have `listtypeentry` param which is obtained from iteraor. for example [code block],-1,0,0,0.5463000535964966,0.7846366167068481,0.9376479387283324,0.0,accept,majority_agreement
990998252,11303,"ah, it's dangerous.... what if we just name the functions so it doesn't expose the internals such as encoding, but rather the purpose from the caller's perspecive? for example, instead of `listtypetryconvertlistpack` it can be called `listtypemakespaceforvalues` or something like that? similarily, converting from quicklist to listpack can be called something like `listtypeshrink`. wdyt?",-1,-1,-1,0.953018307685852,0.9633969068527222,0.9430325031280518,-1.0,accept,unanimous_agreement
991107148,11303,"good idea. i prefer `listtypetryconversion` and `listtypetryconverionforvalues` more, which more clearly indicate that the encoding will be converted.",1,1,1,0.8931618928909302,0.9579998850822448,0.9842512607574464,1.0,accept,unanimous_agreement
991166826,11303,sounds good (although i think indicating that the encoding will be converted can be something internal to the list type that the caller doesn't need to know).,1,0,0,0.8020693063735962,0.6563029289245605,0.6400639414787292,0.0,accept,majority_agreement
992059822,11303,"modulecreateemptykey calls createquicklistobject, so listtypetryconvertlistpack will always nop. i guess you meant to modify modulecreateemptykey to create a listpack (makes sense since it's empty), and then this conversion (using the size of `ele` makes sense). maybe we can be more efficient and make a decision beforehand (pass a hint to the creation function), not sure it worth the complexity here though... (considering the conversion is inexpensive anyway)",0,0,0,0.9410133361816406,0.9856870770454408,0.9579348564147948,0.0,accept,unanimous_agreement
992098885,11303,"it's a little bit odd to see this in quicklist.c and not t_list.c, but maybe we don't have a choice if we wanna keep using the existing (odd) `list-max-listpack-size`. an alternative would have been to re-introduce `list-max-ziplist-entries` (i think a count based limit is enough, and there's no reason for a size based limit too. specifically since there's no real conversion work between the two encodings). i suppose what's implemented is the right thing to do, just wanted to raise a discussion to be sure.",-1,0,0,0.4960713386535644,0.6643354892730713,0.5827394127845764,0.0,accept,majority_agreement
992126986,11303,"if we do this, we need to also bump `rdb_version`, but i think we better just fake a one node quicklist. p.s. if we do that, don't forget to revert the change below, and the one in redis-rdb-check",0,0,0,0.9799640774726868,0.976230800151825,0.984224796295166,0.0,accept,unanimous_agreement
992130326,11303,"we actually know how many listpack nodes we have, so we can avoid this conversion. but it'll cause complications with plain nodes, and considering the conversion is very cheap, i guess we shouldn't bother. remind me when do we re-compress the quicklist nodes after loading?",0,0,0,0.9601671695709229,0.9040732383728028,0.9649558067321776,0.0,accept,unanimous_agreement
992161180,11303,i'd rather avoid the floating-point conversion and comparison and just use `/2` below (next to the comment that explains why it's needed).,0,0,0,0.982955038547516,0.9926882982254028,0.9842922687530518,0.0,accept,unanimous_agreement
992206744,11303,"in the end i chose `listtypetryconversion` and `listtypetryconverionforvalues`, at least they are more consistent with other conversion function like `zset` or `hash`.",0,0,0,0.9880792498588562,0.9940549731254578,0.988685131072998,0.0,accept,unanimous_agreement
992211064,11303,"how about `lpentry` (and `lpiter` for the one in listtypeiterator)? p.s. in theory these could have been unions, but i suppose we are trying to avoid a rename that's gonna cause many changes.",0,0,0,0.9774707555770874,0.9871839880943298,0.990394413471222,0.0,accept,unanimous_agreement
992212652,11303,i'm puzzled as to why quicklistsetdirection doesn't need to do that lpnext / lpprev trick internally (on iter->entry)?,0,0,-1,0.5777138471603394,0.5202841758728027,0.8079686760902405,0.0,accept,majority_agreement
992215668,11303,"btw. we can reduce the loc changes in many cases by adding the listpack case as an `else if` after the quicklist `if` and before the panic's `else`. if you do that, please handle it in a separate commit so we don't need to review all these moved code blocks. maybe it's confusing if some if-else chains are ordered in one way and others in the other way, so maybe skip that unless we can convert them all. obviously there are places where we do something with listpack and then we have an early exit return, that seems ok imho.",0,0,1,0.8981651067733765,0.9408915638923644,0.617017388343811,0.0,accept,majority_agreement
992243736,11303,is that reachable? let's make sure all flows in this function have test coverage.,0,0,0,0.9862979650497437,0.9826449751853944,0.9941959381103516,0.0,accept,unanimous_agreement
992274467,11303,"this could be an override, replacing a big item with a small one and vice versa. maybe we can somehow take this into account for the conversion.. or maybe call it again at the end (like in lrem)",0,0,0,0.9839698672294616,0.9917410612106324,0.990189254283905,0.0,accept,unanimous_agreement
992343409,11303,"if the sister pr #11290 is merged and released at the same time, i guess we'll have to bump the rdb_version anyway.",0,0,0,0.9856400489807128,0.9894882440567015,0.9818063974380492,0.0,accept,unanimous_agreement
992921246,11303,"because the quicklistiterator move does not depend on iter->entry, it depends on offset (the offset of the current entry in the node->lp), so it is enough to change the direction. as i mentioned in the top comment, the list listpack iterator always points to the next entry, but the list quicklist iterator points to the current entry.",0,0,0,0.9869188666343688,0.9930938482284546,0.9940503239631652,0.0,accept,unanimous_agreement
992926287,11303,"ah, agree with you, but i feel like we have to do it, and it actually has to do with the fact that the list listpack iterator points to the next entry. when the direction is reversed, and the last node is deleted, after call lpdelete(...,&p), p will be null, so we can only use lplast to get the penultimate node.",0,0,0,0.9549862742424012,0.9046282768249512,0.9732220768928528,0.0,accept,unanimous_agreement
992933668,11303,"yes, i really don't like this implementation (it pollutes the quicklist). the reason why i don't introduct `list-max-listpack-entries` is that i'm worried that if the user configures `list-max-listpack-entries` and `list-max-listpack-size` incorrectly, it might cause frequent converting between quicklist and listpack. like following example [code block]",-1,-1,-1,0.9825238585472108,0.9486169219017028,0.9246113896369934,-1.0,accept,unanimous_agreement
992942205,11303,the quicklist has been compressed in `quicklistappendlistpack`.,0,0,0,0.989072859287262,0.9939491748809814,0.9960773587226868,0.0,accept,unanimous_agreement
993048091,11303,done with [a link]. and fix a missing list listpack encoding check.,0,0,0,0.988917350769043,0.9912994503974916,0.9941524863243104,0.0,accept,unanimous_agreement
993067983,11303,"i know... planning to review it too soon. but still i think there's no reason to change the format for lists, and we can easily fake a one node quicklist instead.",0,-1,0,0.9334898591041564,0.6748236417770386,0.8875649571418762,0.0,accept,majority_agreement
993072646,11303,"ok (before the call to the conversion function), but that's still ok, since list-compress-depth doesn't allow compressing the edge nodes, and a list with one node will never get compressed.",0,0,0,0.9864880442619324,0.9913399815559388,0.9786803722381592,0.0,accept,unanimous_agreement
993104718,11303,"yeah, it sounds ok.",0,0,0,0.9463827610015868,0.6270482540130615,0.9347053170204164,0.0,accept,unanimous_agreement
998044540,11303,what about `lpe` and `lpi` that they seem to make the code more clear.,0,0,0,0.9846067428588868,0.9898920059204102,0.9824522733688354,0.0,accept,unanimous_agreement
998045109,11303,"this is my mistake, fixed.",-1,-1,-1,0.9448928236961364,0.7878119945526123,0.8489860892295837,-1.0,accept,unanimous_agreement
998052165,11303,"i removed the code related to quicklist_convert_threshold, mainly for 2 reasons: 1. because of the threshold, if we save the listpack as a fake quicklist, we will not be able to determine the encoding before it is saved when rdb loading. this would go against the fact that we should keep a key in the same encoding when reloading. 2. after a simple benchmarking, i found that the conversion overhead between listpack <-> quicklist is negligible.",0,0,0,0.9468745589256288,0.9912694692611694,0.9713054895401,0.0,accept,unanimous_agreement
998076223,11303,"i noticed you removed the define (due to this comment?), but looks like you didn't add `/2`",0,0,0,0.9740647077560424,0.9929857850074768,0.9886560440063475,0.0,accept,unanimous_agreement
998077411,11303,"ok. mainly wanted to avoid a one character member (and associate with a ""listpack"")",0,0,0,0.9667497277259828,0.9890835881233216,0.9876857995986938,0.0,accept,unanimous_agreement
998081057,11303,"ohh, i see the comment here: [a link] i'm slightly concerned, even if the conversion is cheap, i'm afraid of a resonance effect. i'm not sure the concern about encoding after rdb loading is that important. let's keep thinking of it.",-1,-1,-1,0.8875826001167297,0.9197524785995485,0.9176422357559204,-1.0,accept,unanimous_agreement
998131972,11303,"i'm concerned too. what about a pipeline like push, pop, push, pop, push, pop, ... where each command causes a conversion, is the overhead negligible even in this case?",-1,0,-1,0.9720979928970336,0.8262001276016235,0.8972198367118835,-1.0,accept,majority_agreement
1004596522,11303,"you are right, there is significant performance degradation when testing as you say, so let me revert this commit for now.",0,0,0,0.9645042419433594,0.8379217982292175,0.9801790118217468,0.0,accept,unanimous_agreement
1005614081,11303,"i agree with the re-introduction of the convert threshold, but i'm not certain we wanna keep the explicit rdb format. i think we can implicitly save the old format of one node quicklist, and i think that when we load it back, we can recognize that it's just one node, and if it confirms with the other thresholds, load it as a listpack instead of quicklist. this would go against the fact that we should keep a key in the same encoding when reloading. can you explain this? maybe i'm overlooking something.",0,0,0,0.9451756477355956,0.9429108500480652,0.9551191329956056,0.0,accept,unanimous_agreement
1005668974,11303,"this is because quicklist will only be converted to listpack if there is only one node and size is below the threshold. if a listpack that size exceeds the threshold, we save it as a fake quicklist, and when reload it, we have no way to know that it's a listpack, we can only treat it as a quicklist that has shrunk to only one node and hasn't reached the threshold.",0,0,0,0.9654961228370668,0.9859258532524108,0.990757405757904,0.0,accept,unanimous_agreement
1005733938,11303,"can't we check the size of the listpack on load time, and decide how to handle it? also, i don't understand the concern of `we should keep a key in the same encoding when reloading`. our rdb loader changes decides on encoding in load time in many places. e.g. here (if the config on the instance which saved it is different than the one that loads it) [code block]",0,0,0,0.9648641347885132,0.9889257550239564,0.9795231819152832,0.0,accept,unanimous_agreement
1005763393,11303,"just like these tests. [a link] [a link] they both assume that after `debug reload`, the encoding of the keys will always be the same as before. i'm also not sure if there is such a principle. without it, i should go on the way as you said.",0,0,0,0.956523060798645,0.9732815027236938,0.9832944869995116,0.0,accept,unanimous_agreement
1005830390,11303,"i don't understand that concern, and i see these assertions are very old, i think we can show flexibility here, either of these solutions is arguably ok: 1. change object encoding to always say ""quicklist"", in that case what we say that a single listpack is an optimization of a quicklist (i.e. imagine you would have done your work inside quicklist.c an a special 0 footprint quicklist) 2. change the test to accept both ""quicklist"" and ""listpack"" 3. change the test in a way that somehow it doesn't hit this problem (tune something so that size is always either big enough or small enough so that the encoding gets consistent) from a quick look, i think for both set and list tests you mentioned above, the 3rd option is the right one.",0,0,0,0.6231848001480103,0.9197845458984376,0.9355682730674744,0.0,accept,unanimous_agreement
1007679576,11303,"choice the third way, please see commit [a link]. another minor change to this commit is changing the limit length of listpack, use `list-max-listpack-size` instead of the original `list-max-listpack-size - 1`. because since we treat it as a quicklist node, we should allow it to reach the length of list-max-listpack-size.",0,0,0,0.986430048942566,0.9929938912391664,0.9929486513137816,0.0,accept,unanimous_agreement
1008849511,11303,"i can't find that commit. that's 0d5b7ca5b10ab58459ff32615873d46dc32425f3, right? you didn't change the tests to avoid that case, but instead added an ""intent"" to the convert, so that you only consider converting to quicklist when growing or converting to listpack when shrinking. i.e. you'll never consider converting to listpack when growing.",0,0,0,0.978718638420105,0.9902887344360352,0.9896609783172609,0.0,accept,unanimous_agreement
1008850642,11303,"comment should now say ""from listpack"", not ""to quicklist"", right? same for the other function below..",0,0,0,0.9869693517684937,0.9921337366104126,0.9947709441184998,0.0,accept,unanimous_agreement
1008851099,11303,"let's document that `enc` is the target encoding, and that do do that to avoid resonance. btw, maybe instead it should be ""growing"" / ""shrinking"" boolean input? that's how we use it, right?",0,0,0,0.9831601977348328,0.9917439818382264,0.9918400049209596,0.0,accept,unanimous_agreement
1008851482,11303,maybe add a comment that the above call to `listtypetryconversionforvalues` handled the other case?,0,0,0,0.9875792860984802,0.9957614541053772,0.9936649799346924,0.0,accept,unanimous_agreement
1009080231,11303,"while writing unit tests, i found that the conversion in the lset command may not work well. the main reason is that `quicklistreplaceentry` does not merge nodes after replacement, which means it does not satisfy the need to convert to a listpack (only one node). the only case where this works is when the quicklist has only one node and has not yet reached the threshold when the `lset` command is used to replace it after reaching the threshold. one alternative would be to merge after the quicklist replacement, but i'm not sure if that would cause a performance decrement.",0,0,0,0.8824350833892822,0.9766086339950562,0.9800164103507996,0.0,accept,unanimous_agreement
1009196990,11303,at the end i change `listtypetryconversionforvalues` to `listtypetryconversionforgrowing` and change `listtypetryconversion` to `listtypetryconversionforshrinking`. :-) you're right.,1,1,1,0.9672747254371644,0.9956725835800172,0.987860143184662,1.0,accept,unanimous_agreement
1009198264,11303,fixed in [a link],0,0,0,0.98800128698349,0.9866787791252136,0.9950093030929564,0.0,accept,unanimous_agreement
1009202491,11303,"this failed with crossslot error in cluster mode (ci test-external-cluster). use a tag to make sure the the source and dest keys belong to the same slot, e.g. r lmove lsrc{t} ldes{t} right right",0,0,0,0.9875950813293456,0.994272768497467,0.9923031330108644,0.0,accept,unanimous_agreement
1009205968,11303,"sorry for that. yes, i think the conversion to listpack when growing is mostly useless unless we dynamically modify `list-max-listpack-size`.",-1,-1,-1,0.989280641078949,0.9930236339569092,0.9932401180267334,-1.0,accept,unanimous_agreement
1009253128,11303,thx,0,0,0,0.9533420205116272,0.9710679054260254,0.9888715147972108,0.0,accept,unanimous_agreement
1009592957,11303,"i don't like the fact we have 3 interfaces, and not just 2 (one for either direction), or two (one with the argv argument and one without).. i also don't like the mention of ""quicklist"" in the interface (not clear if it's the source or the target). btw, i'm not sure if my ""shrinking"" / ""growing"" suggestion was what you implemented, i meant to only consider going from lp to ql when adding elements, and only consider going from ql to lp when removing elements. i didn't consider using different thresholds, but maybe i don't understand the problem well enough. anyway, if we keep the current approach, and assuming i understand it correctly (it took me very long): i understand we actually have a trinary. 1. when we know we added an item and we only consider going lp->ql. that's listtypetryconversionforgrowing (this one also has an extra set of arguments so you can call it before the item was added) 2. when we know we removed an item and we only consider going ql->lp. that's listtypetryconversionforshrinking (internally it calls listtypetryconvertquicklist with shrinking=1) 3. when we don't know what happened (e.g. item was replaced) and we wanna let the system decide what to do. in this case we call listtypetryconvertquicklist directly with shrinking=1. as i said, it took me quite a bit to realize that, so i suggest changing it. one option is to only have one interface, that takes a trinary `tip` (-1, 0, 1), or an enum (growing, shrinking, unknown) besides that we can have a fork of that api without the argv if we want. i'd rather not mention ""quicklist"" or ""listpack"" in the interface. does that sound ok?",-1,-1,-1,0.983655035495758,0.9349979162216188,0.9654019474983216,-1.0,accept,unanimous_agreement
1009615042,11303,"let's comment that we created it as a quicklist, so now we attempt to shrink it to listpack if it doesn't have a lot of data. aren't we suppose to call listtypetryconvertquicklist(shrinking=0) here? like we do on rdb.c when we're done blindly populating a quicklist? i.e. created a quicklist without knowing it if'll be required.",0,0,0,0.972469687461853,0.9913123250007628,0.9925543665885924,0.0,accept,unanimous_agreement
1009621999,11303,missing comment. i.e. this one is about considering conversion from quicklist to listpack. the opposite of listtypetryconversionforgrowing.,0,0,0,0.8276574611663818,0.9909323453903198,0.980523407459259,0.0,accept,unanimous_agreement
1009668492,11303,"i guess that you misunderstand `int threshold = shrinking ? 2 : 1;`, it's not using a different threshold, just to reuse the conversion code so that the threshold can be ignored when rdb loading.",0,0,0,0.9582342505455016,0.9749387502670288,0.9838173389434814,0.0,accept,unanimous_agreement
1009673168,11303,"yes, these interfaces have troubled me for a long time. if there is only one interface, it may take 7 parameters. i don't like so many parameters. but first let me try the way you said.",-1,-1,-1,0.9390194416046144,0.9651663303375244,0.9305354952812196,-1.0,accept,unanimous_agreement
1009674629,11303,"yes, it's same as rdb loading.",0,0,0,0.9878877401351928,0.985694706439972,0.9930315017700196,0.0,accept,unanimous_agreement
1010418592,11303,"only one interface was retained, please see the commit [a link]",0,0,0,0.9875860214233398,0.9821829199790956,0.9957042336463928,0.0,accept,unanimous_agreement
1010418955,11303,also fixed in [a link],0,0,0,0.9877580404281616,0.9883698225021362,0.9959518909454346,0.0,accept,unanimous_agreement
1010421940,11303,already removed.,0,0,0,0.9774561524391174,0.9740695357322692,0.9919995665550232,0.0,accept,unanimous_agreement
1011200897,11303,"i feel that `unknown` doesn't seem relevant, what about `on-demand`?",0,0,0,0.9157148003578186,0.9143100380897522,0.981531023979187,0.0,accept,unanimous_agreement
1011289382,11303,"let's also document the argv thing. btw, i don't mind adding an alias for this function without these argument, it'll still be clear. i.e. calling it with data that's going to be appended.",0,0,0,0.966347873210907,0.976693332195282,0.981745719909668,0.0,accept,unanimous_agreement
1011290237,11303,"it doesn't look like this function needs that `growing` argument, it can just check that argv is non-null",0,0,0,0.9562950730323792,0.989912211894989,0.9921079277992249,0.0,accept,unanimous_agreement
1011302040,11303,"that's not really true (the ""only consider"" part), we do call both conversion functions regardless of this argument. one uses it just instead of checking argv!=null, so it doesn't need that argument at all. the other uses it to decide on the threshold (to avoid resonance). i think we should remove the `growing` argument from the first one, and that we should document this enum something like: * unknown - used after we built a new list, and we want to let the function decide on the best encoding for that list. * growing - used before or right after adding elements to the list, in which case we are likely to only consider converting from listpack to quicklist. * shrinking - used after removing an element from the list, in which case we wanna consider conversion from quicklist to listpack. when we know we're shrinking, we use a lower (more strict) threshold in order to avoid repeated conversions on every list change.",0,0,0,0.9598681330680848,0.9898433685302734,0.9881802797317504,0.0,accept,unanimous_agreement
1011330706,11303,"on-demand describes *when* something happens (when needed, when required), not how or why. maybe `auto`? or if it is about growing and shringing, maybe `both`? or a bitwise-or `growing | shrinking`...",0,0,0,0.9763838648796082,0.9892653226852416,0.9878219962120056,0.0,accept,unanimous_agreement
1011749053,11303,"by unknown, i mean that the caller doesn't know if we're shrinking or growing. but auto is ok with me too (as long as the comment is good enough to mention when to use it and what it does)",0,0,0,0.979099452495575,0.9563583135604858,0.969137728214264,0.0,accept,unanimous_agreement
1012842290,11303,"done, i add a new interface `listtypetryconversionwithargv`, not sure if it's good enought.",0,0,0,0.9830065369606018,0.97199684381485,0.9884301424026488,0.0,accept,unanimous_agreement
1012842371,11303,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1012842690,11303,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
1012843128,11303,i like `auto` more.,1,1,0,0.5807098150253296,0.6682990193367004,0.5973374247550964,1.0,accept,majority_agreement
1013116376,11303,please make sure that code is reachable in the test suite and comment / resolve this comment.,0,0,0,0.9809545278549194,0.9877931475639344,0.994496524333954,0.0,accept,unanimous_agreement
1013116685,11303,please make sure that code is reachable in the test suite and comment / resolve this comment.,0,0,0,0.9809545278549194,0.9877931475639344,0.994496524333954,0.0,accept,unanimous_agreement
1013124196,11303,0 is the limit on the number of elements? should it be 1?,0,0,0,0.9776641726493835,0.9905967712402344,0.9909067153930664,0.0,accept,unanimous_agreement
1013139187,11303,"if we bothered to add an assert_encoding, let's add it on the copy as well",0,0,0,0.9888775944709778,0.994197964668274,0.9934199452400208,0.0,accept,unanimous_agreement
1013160497,11303,can't we use the `enc` as the expected encoding rather than use check_sort_store_encoding?,0,0,0,0.9870261549949646,0.9957196116447448,0.9943721294403076,0.0,accept,unanimous_agreement
1013173173,11303,don't we want to do the assert_encoding after the pushes?,0,0,0,0.9854000210762024,0.992792010307312,0.993013083934784,0.0,accept,unanimous_agreement
1013183991,11303,we use `create_$type` but then assert that it's always a `listpack`? why is that? because the rpoplpush doesn't move the `$large` item? maybe add another one to the list?,0,0,0,0.985470414161682,0.9946736693382264,0.993270218372345,0.0,accept,unanimous_agreement
1013186599,11303,"that `largevalue` doesn't seem like it's still suitable. it was born at a time where lists were either a ziplist or a linked-list, so large items were not packed at all. but now we always use listpack (or plain nodes but that's another story). i suppose we're counting on the fact that even if we pass the size of `list-max-listpack-size`, we'll still create listpack based quicklists (with one entry per listpack. if we keep this `largevalue` approach, let's add a comment that explains why it still does what we want.",0,0,0,0.9449328184127808,0.9719613790512084,0.9779781103134156,0.0,accept,unanimous_agreement
1013766432,11303,"when `list_max_listpack_size` is 0, list listpack encoding will be disabled (count in quicklistsizeandcountlimit will be 0), i will add comments in redis.conf",0,0,0,0.9877177476882936,0.9943619966506958,0.9957104921340942,0.0,accept,unanimous_agreement
1013767794,11303,but `enc `may also be `intset` or `hashtable`.,0,0,0,0.9874923229217528,0.9934711456298828,0.9940395355224608,0.0,accept,unanimous_agreement
1013773642,11303,maybe we can modify these tests by using the feature of forcing quicklist encoding when `list_max_listpack_size` is 0.,0,0,0,0.988416075706482,0.994699478149414,0.988744616508484,0.0,accept,unanimous_agreement
1013775597,11303,"i've seen it fully covered in gcov before, but let's add a more precise test to cover it.",0,0,0,0.9836515784263612,0.9864675998687744,0.9934459328651428,0.0,accept,unanimous_agreement
1014001743,11303,"ok, so `list_max_listpack_size` of `0` means a single element per quicklist node (same as `1`), but also implies it'll always be quicklist? it seems odd to me (should be an invalid config, but since we didn't block that config in the past, we can't start now. but i think it's effects should be the same as setting it to 1. iiuc the difference from the current code is that it'll still use listpack if there's a single element in the list. any downside in that?",0,0,0,0.933660924434662,0.8540336489677429,0.5922175049781799,0.0,accept,unanimous_agreement
1014006855,11303,"you mean instead of trying to control the encoding by using different item sizes, we'll control the encoding by changing the config. i think that's cleaner approach (although i'd rather set it to `1`, not `0`). i can also live with the current approach (of creating items big enough so that all listpacks end up with only one item and then as soon as there are two items in the list, it must be quicklist encoded, but if we keep that approach, i think a big comment is needed to explain that hack. maybe we can leave this change for last, and first finish with all other comments, then you can try this, and if it ends up too messy, we can easily revert it (and be sure we didn't revert any other cleanup or fix).",0,0,0,0.9226611256599426,0.9446753263473512,0.9272475242614746,0.0,accept,unanimous_agreement
1014010045,11303,"ohh sorry, i was out of context.",-1,-1,-1,0.9863492250442504,0.9911078214645386,0.9867923259735109,-1.0,accept,unanimous_agreement
1014827766,11303,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
1014827944,11303,that code has been converted by `lrem starting from tail with negative count (2)` test.,0,0,0,0.9853879809379578,0.9944062232971193,0.9941856861114502,0.0,accept,unanimous_agreement
1014828476,11303,"~~please see commit [a link]~~ ~~set `fill` to 1 when `fill` is 0, also optimize the original code that limits the quicklist.~~ ~~now when list-max-listpack-size is 0, we will also create listpack with only one element, instead of the old forced-quicklist.~~ please ignore this commit, it is wrong. this is because `sizemeetssafetylimit` prevents the quicklist node from exceeding the maximum value even fill is very large. i also found that in the cases `0`, `1` and `< -5`, the quickist node will always have only one entry. [code block]",0,0,0,0.8312844634056091,0.9811448454856871,0.9101192951202391,0.0,accept,unanimous_agreement
1014828777,11303,done with [a link],0,0,0,0.9886857271194458,0.9809236526489258,0.9957758784294128,0.0,accept,unanimous_agreement
1014828839,11303,done with [a link].,0,0,0,0.988278329372406,0.9842276573181152,0.9958213567733764,0.0,accept,unanimous_agreement
1014828945,11303,"yes, added another one to the list. ([a link]",0,0,0,0.9499828815460204,0.9764789938926696,0.992170512676239,0.0,accept,unanimous_agreement
1014841136,11303,"i fail to see where we address this concern now. i.e. `fill` is positive, and we want to avoid creating listpacks of more than 8kb. iirc this mess is here for two reasons: 1. if the user have set a limit of 128 entries (seems normal), but for some reason some entries are huge (could be 500mb each), then for efficiency, we still want to limit the size. 2. we want to absolutely avoid a case were we reach more than 64k records since then the listpack has o(n) code to get their count.",-1,-1,-1,0.9229726791381836,0.5324667096138,0.6966196894645691,-1.0,accept,unanimous_agreement
1014846099,11303,"i don't think it's appropriate to use `1`, because in this case the quicklist will become a list with only one entry per quicklist node, which will result in a lot of boundary conditions we won't be able to cover.",0,0,0,0.8882219791412354,0.7713890075683594,0.9598192572593688,0.0,accept,unanimous_agreement
1014846193,11303,"p.s. that division bothered me for quite a while and i avoided commended since it's probably just my ocd. but i imagine that the compiler uses division here, and if instead we'll do `if (shrinking) count_limit/=2, szlimit/=2;`, it'll just be two shifts. feel free to ignore.",0,0,0,0.7145419120788574,0.8513639569282532,0.4988194108009338,0.0,accept,unanimous_agreement
1014846537,11303,why did you give that up?,0,0,0,0.7482736110687256,0.8076552748680115,0.9902207851409912,0.0,accept,unanimous_agreement
1014847786,11303,"since the list length in list-quicklist.rdb is 1, it will be a listpack anyway.",0,0,0,0.9886121153831482,0.990879774093628,0.9919148683547974,0.0,accept,unanimous_agreement
1014848450,11303,i feel like i posted [a link] while you review,0,0,0,0.8255616426467896,0.8783928751945496,0.99120831489563,0.0,accept,unanimous_agreement
1014848523,11303,"ohh, right.",0,0,0,0.8581703901290894,0.82291579246521,0.9448484182357788,0.0,accept,unanimous_agreement
1014848660,11303,"yes, i reviewed the one you ended up reverting.",0,0,0,0.9748202562332152,0.9130753874778748,0.9881284832954408,0.0,accept,unanimous_agreement
1014852665,11303,"i still don't like the odd case of 0 (should be an invalid config, and if it isn't, then it should be the same as it was before (synonym for 1). maybe we should accept the fact that a list with a single element of one byte will always be a listpack, and it's ok that we have no control over it... maybe for the vast majority of the tests that runs on the two variants it doesn't have an impact?",-1,-1,-1,0.981409788131714,0.5312727689743042,0.7938604950904846,-1.0,accept,unanimous_agreement
1014853680,11303,"yes, indeed, i'm trying to modify it in a new way.",0,0,0,0.9281954169273376,0.9091377854347228,0.9839780926704408,0.0,accept,unanimous_agreement
1016284357,11303,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1016294156,11303,"i unified the limit method(`quicklistnodemeetlimit`) of quicklist node and listpack. it means that now quicklist has add two new interfaces to the outside. there are two main modifications to `list-listpack-max-size` 1. when 0, it works the same as 1 2. when < -5, it works the same as -5, if we dont do that, < -5 means disable list listpack.",0,0,0,0.988445281982422,0.9929260015487672,0.9893252849578856,0.0,accept,unanimous_agreement
1016539523,11303,"i'm not certain we wanna make this official (by documenting it), people should just use documented values.",0,0,0,0.8019305467605591,0.8137431740760803,0.5103723406791687,0.0,accept,unanimous_agreement
1016582022,11303,"* should that function now be named ""exceeds"" instead of ""meets""? i.e. it seems you negated it and it returns 1 when we cant append to the node. * i think we can drop the `else` since each `if` also returns. * since we know (and even assume) that the size and count limits are mutually exclusive (exactly one of them isn't set to max), we can just check which of them is different than max, and then do `return new_sz <= sz_limit` * the check about safetylimit is only needed if the limit is count based, and we're below the count (i.e. only if we have a chance to allow the insertion). * bottom line, i think this function can be rewritten to be more readable (and renamed)",0,0,0,0.9801079630851746,0.990548312664032,0.9869036674499512,0.0,accept,unanimous_agreement
1016583396,11303,"see we lost some `likely` statements, maybe we can re-add them (we're likely not to reach any limit)",0,0,0,0.9830337166786194,0.9819841980934144,0.9880000948905944,0.0,accept,unanimous_agreement
1016587739,11303,"so we no longer need the `lpsafetoadd` (listpack concern), because the quicklist concerns are covering this anyway?",0,0,0,0.9841585159301758,0.9947934746742249,0.9936287999153136,0.0,accept,unanimous_agreement
1016597577,11303,"i'm not sure i understand, is that different than what we had before?",-1,-1,-1,0.8571628332138062,0.5459041595458984,0.5838295817375183,-1.0,accept,unanimous_agreement
1016618052,11303,"yes, it is safe no matter the length (max size 8k) or size (4k~64k).",0,0,0,0.9850996136665344,0.9877580404281616,0.9898210763931274,0.0,accept,unanimous_agreement
1017522353,11303,"added, `unlikely` not `likely`.",0,0,0,0.9816666841506958,0.9890736937522888,0.9919054508209229,0.0,accept,unanimous_agreement
1017522425,11303,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1017522573,11303,removed,0,0,0,0.9654131531715392,0.9801433682441713,0.9591778516769408,0.0,accept,unanimous_agreement
590582640,8621,i would just add local as an input variable.,0,0,0,0.9877349734306335,0.9888662695884703,0.9926294088363647,0.0,accept,unanimous_agreement
590587222,8621,spacing,0,0,0,0.9849215149879456,0.9298945069313048,0.9880961179733276,0.0,accept,unanimous_agreement
590587621,8621,"these don't really have ""keys"", i think we have to do the node level check within the command itself like publish does for acls.",0,0,0,0.984473705291748,0.989798903465271,0.9878125786781312,0.0,accept,unanimous_agreement
590589258,8621,channellist(),0,0,0,0.9815201163291932,0.969826877117157,0.9919935464859008,0.0,accept,unanimous_agreement
590590995,8621,localb?,0,0,0,0.9858623147010804,0.9793881177902222,0.9882225394248962,0.0,accept,unanimous_agreement
590599756,8621,"since this is ""local"", should we be propagating it? some thoughts here: 1. always require it on a primary and then replicate it normally. 2. don't replicate it and require consistent behavior from the clients about where you are connecting.",0,0,0,0.9806519746780396,0.9919989705085754,0.9865893125534058,0.0,accept,unanimous_agreement
590602942,8621,"i don't think you should be able to subscribe to multiple different slots, and i think that needs to be within the function.",0,0,0,0.958505153656006,0.9535880088806152,0.977594256401062,0.0,accept,unanimous_agreement
612560657,8621,isn't this information intended (among other things) for cluster clients to select node by key slot using command and command getkeys? i think we get stuff for free here if we regard the channels as keys.,0,0,0,0.987476646900177,0.9921512603759766,0.9890553951263428,0.0,accept,unanimous_agreement
612673641,8621,"it's also used for client tracking among other things. i agree with would be a shortcut to getting some support, but i think we shouldn't consider them as keys.",0,0,0,0.9713054895401,0.986653745174408,0.985946238040924,0.0,accept,unanimous_agreement
642381589,8621,"i believe we should replicate it within the (master, replica) set. otherwise, i believe we are restricting the data to a single instance. i don't see any advantage to always publish the data on master. we should allow the client to publish data irrespective of a master or a replica.",0,0,0,0.9321000576019288,0.9766355752944946,0.979124128818512,0.0,accept,unanimous_agreement
642383306,8621,"as per our discussion, i've moved it to a static creation.",0,0,0,0.9850972890853882,0.991869330406189,0.99497389793396,0.0,accept,unanimous_agreement
642413719,8621,"it was already getting handled with `crossslot keys` error, i've put an additional check and message `-crossslot channels in request don't hash to the same slot`",0,0,0,0.9861836433410645,0.9933143258094788,0.9952150583267212,0.0,accept,unanimous_agreement
642526564,8621,"thanks for the heads up, i've handled the scenario(s). still using the path used for keys for local channels slot mapping.",1,1,1,0.764919638633728,0.9330978989601136,0.9609420299530028,1.0,accept,unanimous_agreement
642759731,8621,"i really don't like this notion that these are ""fake"" keys. i think we should be modeling this as a separate namespace which is also hashed. i really don't like having all of these if/else sprinkled int he code looking for the cmd_pubsub flag, it seems really fragile. also, unless i'm mistaken, it's mostly just a change to ""getnodebyquery"" which seems not that hard to generalize and is much clearer.",-1,-1,-1,0.9843475818634032,0.984401524066925,0.9846051931381226,-1.0,accept,unanimous_agreement
642767759,8621,"in cluster mode, you can issue publish commands to replicas and they get propagated to primaries through the clusterbus. pubsub local doesn't do that, it expects it to go to the primary to be replicated. this seems like weird behavior to break. this is especially odd since we don't make publish consistent (at least i think) and don't redirect it to primaries by default.",-1,-1,-1,0.9382272362709044,0.951370120048523,0.9740309715270996,-1.0,accept,unanimous_agreement
643647856,8621,i think we've used the terms type and spec elsewhere in redis to describe this type of structure.,0,0,0,0.9868107438087464,0.9803915023803712,0.9881579279899596,0.0,accept,unanimous_agreement
643649003,8621,is this related?,0,0,0,0.9724814891815186,0.9862993359565736,0.9905855059623718,0.0,accept,unanimous_agreement
643649139,8621,unsubscribelocal [channel ...] ?,0,0,0,0.9698553681373596,0.9917041063308716,0.9920388460159302,0.0,accept,unanimous_agreement
643649882,8621,can we move this comment down to where this logic actually is?,0,0,0,0.9835330247879028,0.9925219416618348,0.9896079897880554,0.0,accept,unanimous_agreement
643651998,8621,prefer to not touch this unless you have to.,0,0,0,0.5061288475990295,0.959305226802826,0.9560238122940063,0.0,accept,unanimous_agreement
643653230,8621,"unlike getkeysinslot, it doesn't like like we ever strictly return string objects (which is why this function returns string objects). we could just call rax recursivefree with the callback that disconnects all the clients.",0,-1,0,0.9077102541923524,0.58005291223526,0.982644259929657,0.0,accept,majority_agreement
643654194,8621,"do we need to maintain this separate structure for the count? it seems only to ever be used as an optimization in one place, it seems easier to just loop over the rax in that instance.",0,0,0,0.9779621362686156,0.9902082085609436,0.985554039478302,0.0,accept,unanimous_agreement
643656633,8621,pubsublocalbunsubscribeallclients,0,0,0,0.9873222708702089,0.9556596875190736,0.990616261959076,0.0,accept,unanimous_agreement
643657243,8621,i'm not sure clients know what to do about this. i would have expected we disconnect them and they can reconnect to the right client.,0,-1,-1,0.5324414372444153,0.8136711120605469,0.7938492298126221,-1.0,accept,majority_agreement
643657626,8621,why does this have a notify argument?,0,0,0,0.939132034778595,0.9777617454528807,0.9905099272727966,0.0,accept,unanimous_agreement
643658489,8621,would be good to document why? i would also do: [code block] to reduce indentation and make the flow clearer.,0,0,0,0.9839277863502502,0.977974772453308,0.9933695793151855,0.0,accept,unanimous_agreement
643661474,8621,"i still don't think we should be treating them as keys. pubsub local will have to be implement specifically for clients, since it doesn't operate on keys like other commands. i may be over hesitant here to conflate the two.",0,-1,0,0.7817171812057495,0.5479740500450134,0.7295476794242859,0.0,accept,majority_agreement
655017641,8621,not required.,0,0,0,0.961223840713501,0.9249237775802612,0.9903457760810852,0.0,accept,unanimous_agreement
655017769,8621,shouldn't we send at least a notification that the client is getting disconnected from this channel ?,0,0,0,0.9434404373168944,0.9869809746742249,0.9921208620071412,0.0,accept,unanimous_agreement
655020242,8621,missed the slottochannelflush method call here.,0,0,0,0.8400649428367615,0.9890522360801696,0.9526560306549072,0.0,accept,unanimous_agreement
655020727,8621,"yeah saw `type` in few places, proceeding with `type`.",0,0,0,0.9867522716522216,0.9915046095848083,0.988648235797882,0.0,accept,unanimous_agreement
655021096,8621,thanks for clarifying this. i've fixed the implementation to support pubsub local commands to work on the master/replica and data broadcast to happen through clusterbus within a slot.,1,1,1,0.9149950742721558,0.9552297592163086,0.9501590132713318,1.0,accept,unanimous_agreement
655021643,8621,"makes sense. i was following this [a link] should we update these (unsubscribe, punsubscribe) as well?",0,0,0,0.9865628480911256,0.9899049401283264,0.9871411323547364,0.0,accept,unanimous_agreement
655023568,8621,"yeah, seems like a unnecessary optimization. just traversing the rax suffices.",-1,0,-1,0.5194242596626282,0.5255324244499207,0.5610567331314087,-1.0,accept,majority_agreement
655024902,8621,that's true. i was planning to add a command like `cluster getchannelsinslot` later on. do you think it will be meaningful information for the user? like before slot migration verifying if there are any slots with active channels.,0,0,0,0.9839953780174256,0.991324782371521,0.9910492897033693,0.0,accept,unanimous_agreement
655025134,8621,slottochannelflush is no longer required as per the other comment. resolving.,0,0,0,0.9791569709777832,0.989591419696808,0.9952248334884644,0.0,accept,unanimous_agreement
655030084,8621,makes sense. will address this refactoring at the end.,0,0,0,0.9809311032295228,0.9828482866287231,0.9795284271240234,0.0,accept,unanimous_agreement
663418640,8621,if they're getting disconnected i'm not sure it matters.,-1,-1,0,0.7584067583084106,0.7151504755020142,0.6309342980384827,-1.0,accept,majority_agreement
713463813,8621,?,0,0,0,0.9320514798164368,0.9557723999023438,0.9296892285346984,0.0,accept,unanimous_agreement
714149306,8621,this isn't needed any more right?,0,0,0,0.9309402704238892,0.9180771708488464,0.9915687441825868,0.0,accept,unanimous_agreement
714154638,8621,"redis generally doesn't use camel case for variable names, either nodesforslot or nodes_for_slot is more common.",0,0,0,0.98792564868927,0.992639183998108,0.9890996813774108,0.0,accept,unanimous_agreement
714165585,8621,"""the command has no key or local channel arguments"" ? might be clearer then adding the large addendum to this comment.",0,0,0,0.990075409412384,0.9921219348907472,0.9842304587364196,0.0,accept,unanimous_agreement
714170224,8621,"if we can, let's merge this into the normal slot migration tests.",0,0,0,0.9877358078956604,0.9914319515228271,0.993306577205658,0.0,accept,unanimous_agreement
714175709,8621,we can probably simplify these tests a bit by setting up a cluster and migrating the same slot back and forth. there is a lot of code that is re-iterated over and over again between these tests.,0,0,0,0.9806445240974426,0.9871706366539,0.9772995710372924,0.0,accept,unanimous_agreement
714176567,8621,maybe contentious to put that phrase.,0,-1,0,0.6953900456428528,0.6155046224594116,0.804629385471344,0.0,accept,majority_agreement
714176941,8621,seems like this should get merged into the previous test since it is small.,0,0,0,0.9819292426109314,0.9924836754798888,0.9859641790390016,0.0,accept,unanimous_agreement
714178149,8621,is this still needed?,0,0,0,0.9838026762008668,0.986221969127655,0.9937742948532104,0.0,accept,unanimous_agreement
714179594,8621,"i don't think all of these functions that don't take arguments need to be functions, we can just include a pointer to the object in the type and reference the pointer instead of calling a function.",0,0,0,0.9804291725158693,0.9800034165382384,0.9820737838745116,0.0,accept,unanimous_agreement
715296799,8621,"a completely separate conversation that was had is that slots_to_keys is now no longer a a radix tree, but a linked list. this intuitively makes more sense as a radix tree here though, since we expect the total number to be smaller.",0,0,0,0.9784326553344728,0.98459792137146,0.9916774034500122,0.0,accept,unanimous_agreement
715297111,8621,"this can't be the current node right, since it's being removed from the cluster? i'm not clear why we need to remove the channels in the slot.",0,0,0,0.9661667943000792,0.6435362696647644,0.9809691905975342,0.0,accept,unanimous_agreement
715298378,8621,this intuitively makes more sense to me. [code block],0,0,0,0.975597321987152,0.8464962244033813,0.9870284795761108,0.0,accept,unanimous_agreement
715298781,8621,"didn't quite follow this, we remove the slot universally later.",0,0,0,0.9505035281181335,0.9365270733833312,0.9858351349830629,0.0,accept,unanimous_agreement
715299556,8621,"maybe we should steal bytes for a flag instead of making a net new message. we have 8 bytes, i find it much more likely we will make this more configurable as opposed to trying to trying to put a new value there. [a link] that should hopefully simplify a lot of this code.",0,0,0,0.9696452021598816,0.9822359085083008,0.9765332341194152,0.0,accept,unanimous_agreement
715300149,8621,"purely stylistic, but i think it's usually easier to follow code that is written where validation happens and returns if it fails instead of having if/else blocks. [code block]",0,0,0,0.97880220413208,0.9393776059150696,0.9619153738021852,0.0,accept,unanimous_agreement
715300397,8621,"i'd still throw -crossslot, clients understand this error message already.",0,0,0,0.9779683947563172,0.7765863537788391,0.9677183032035828,0.0,accept,unanimous_agreement
715300888,8621,my understanding is that today we still serve publish/subscribe even when the cluster is no ok? not sure it really makes sense to change that behavior here?,0,0,0,0.8153178691864014,0.8707370758056641,0.9153608083724976,0.0,accept,unanimous_agreement
715301214,8621,general preference is to not touch code you aren't changing to make git history easier to follow.,0,0,0,0.9654104709625244,0.956305205821991,0.9830339550971984,0.0,accept,unanimous_agreement
715302446,8621,"if might be easier to follow this code changing the if/else chain to be: [code block] it's a little duplication, but i think it'll help with readability.",0,0,0,0.9746991395950316,0.9233171939849854,0.9158309698104858,0.0,accept,unanimous_agreement
715303900,8621,i'm not clear why you pass in argv if you don't use it. i also think removing it makes the previous line fit into 80 characters :),0,1,0,0.442215085029602,0.7532424926757812,0.5797927379608154,0.0,accept,majority_agreement
715304258,8621,i don't think so? there is no way to list all of the channels today right? i don't see a compelling reason to ever need to do that.,0,0,0,0.5308150053024292,0.5033338665962219,0.9625139832496644,0.0,accept,unanimous_agreement
715305507,8621,"let's put this in pubsub.c, since it's not needed by the rest of redis.",0,0,0,0.9886258244514464,0.994229793548584,0.9925954937934875,0.0,accept,unanimous_agreement
715307120,8621,pattern?,0,0,0,0.9842286109924316,0.9828636050224304,0.9896416068077089,0.0,accept,unanimous_agreement
715307600,8621,looks like some debugging code.,0,0,0,0.9780969023704528,0.97950941324234,0.9609904885292052,0.0,accept,unanimous_agreement
715308779,8621,i don't understand this test. both of these tests are sending the publish to the primary and reading on the replica.,0,-1,-1,0.8227266073226929,0.740165114402771,0.7392435669898987,-1.0,accept,majority_agreement
730181804,8621,would this cause confusion as it is crossslot but across different nodes ?,0,0,0,0.8879677057266235,0.9735384583473206,0.9569190740585328,0.0,accept,unanimous_agreement
730182139,8621,i thought we wanted to introduce a flag to let the user decide the behaviour.,0,0,0,0.9821085929870604,0.9844285249710084,0.985341489315033,0.0,accept,unanimous_agreement
730184701,8621,sure. updated.,0,0,0,0.9570444226264954,0.980701506137848,0.9864272475242616,0.0,accept,unanimous_agreement
730184735,8621,looks cleaner to me.,0,0,0,0.940323293209076,0.9101950526237488,0.9705243706703186,0.0,accept,unanimous_agreement
730184757,8621,"did try that, it's not possible to reference as it is not a compile-time constant. [code block]",0,0,0,0.9757861495018004,0.9917888045310974,0.9926936626434326,0.0,accept,unanimous_agreement
730195528,8621,"yeah my bad, removed the reverse replication.",-1,-1,-1,0.9850505590438844,0.988572120666504,0.9897186756134032,-1.0,accept,unanimous_agreement
730295109,8621,"my bad, removed.",-1,-1,-1,0.983235001564026,0.989253580570221,0.9949541687965392,-1.0,accept,unanimous_agreement
741274322,8621,what do you mean by across different nodes?,0,0,0,0.978472113609314,0.9764383435249328,0.991874635219574,0.0,accept,unanimous_agreement
741278530,8621,this doesn't seem to be addressed.,0,0,0,0.7121177315711975,0.8975528478622437,0.8488495349884033,0.0,accept,unanimous_agreement
742484796,8621,"discussed: in a given call, only channels of a single slot will be accepted.",0,0,0,0.984727144241333,0.9908202290534972,0.9905789494514464,0.0,accept,unanimous_agreement
742485007,8621,memcpy is done at the first byte of placeholder data array. unable to use it.,-1,0,0,0.5721665620803833,0.9454761147499084,0.9843372702598572,0.0,accept,majority_agreement
742507058,8621,i think we should at least describe the implications of setting this as yes or no.,0,0,0,0.9689987897872924,0.9781423211097716,0.9746549725532532,0.0,accept,unanimous_agreement
742507578,8621,"i still think we can optimize this a bit, since the code between these two sections is basically the same. it looks like just the pubsub publish command that is called is different.",0,0,0,0.9821359515190125,0.9532371759414672,0.9714105725288392,0.0,accept,unanimous_agreement
742508121,8621,"i know we talked about this, but it looks like this is called generally anytime a slot is deleted, even if it's not one we own.",0,0,0,0.984891414642334,0.981963276863098,0.988010823726654,0.0,accept,unanimous_agreement
742508901,8621,so do we still need cluster_redir_cross_node_channel ?,0,0,0,0.9888547658920288,0.9939411878585817,0.9944061040878296,0.0,accept,unanimous_agreement
742509836,8621,should probably clarify this is local pubsub,0,0,0,0.9862094521522522,0.9816327095031738,0.9908319115638732,0.0,accept,unanimous_agreement
742512693,8621,"still not clear why this can't just be a pointer to an robj, and instead has to be a function that returns an robj.",0,0,0,0.9513090252876282,0.9335820078849792,0.7186655402183533,0.0,accept,unanimous_agreement
742513232,8621,i don't understand how this test is working. publishing to a replica in cluster mode disabled shouldn't allow it to be read on the master.,-1,-1,-1,0.5656929016113281,0.7012969851493835,0.7321370244026184,-1.0,accept,unanimous_agreement
742514946,8621,"let's also verify the position of the unsubscribelocal, which is when the migration happens, not when it's set to importing.",0,0,0,0.987009346485138,0.9924351572990416,0.9937158226966858,0.0,accept,unanimous_agreement
742515112,8621,is there a reason you set the subscribe client to deferrered twice?,0,0,0,0.9768868088722228,0.9846062660217284,0.9945900440216064,0.0,accept,unanimous_agreement
742515416,8621,"[code block] which is true in several places, unless you are explicitly trying to setup a new connection.",0,0,0,0.9872086644172668,0.9936800003051758,0.9946699738502502,0.0,accept,unanimous_agreement
742515888,8621,yes,0,0,0,0.9564858078956604,0.9659429788589478,0.9686408638954164,0.0,accept,unanimous_agreement
742956233,8621,"as discussed, making it inplace to avoid exposing it unless required.",0,0,0,0.9769957065582277,0.9898622035980223,0.993582010269165,0.0,accept,unanimous_agreement
742958050,8621,local variable was useful to not handle the unsubscribe flow in certain cases. made the cluster variable initialization global and handled the state correctly in methods.,0,0,0,0.9867756962776184,0.9936503767967224,0.9728082418441772,0.0,accept,unanimous_agreement
744330594,8621,"you're right, it's incorrect. strangely the test is succeeding and the test behaviour is also same for pubsub global semantics. manually tested for cmd, publish to replica doesn't propagate to master. i've removed it, will try to figure out later why it's succeeding.",0,0,0,0.5573785305023193,0.7741674184799194,0.9825531244277954,0.0,accept,unanimous_agreement
744330654,8621,changed the naming to pubsublocal.,0,0,0,0.9835174083709716,0.9899193048477172,0.9931423664093018,0.0,accept,unanimous_agreement
744330853,8621,"if i were to use the variables from `shared`, then there is compile time error. if we want to use an robj, i can create a new object for the struct `pubsubtype`.",0,0,0,0.982583463191986,0.9935258626937866,0.9916537404060364,0.0,accept,unanimous_agreement
744532563,8621,added a condition to verify if the node is the owner of the slot and then cleanup.,0,0,0,0.9879143834114076,0.9921017289161682,0.9951382875442504,0.0,accept,unanimous_agreement
744915466,8621,i've merged the two conditional block into one.,0,0,0,0.9865767955780028,0.9791145324707032,0.9936259984970092,0.0,accept,unanimous_agreement
744915853,8621,added some info.,0,0,0,0.9846470355987548,0.9812663793563844,0.990446925163269,0.0,accept,unanimous_agreement
745126148,8621,"i misunderstood your comment, updated the code. thanks for the suggestion.",1,1,1,0.9382795095443726,0.6700351238250732,0.9540548920631408,1.0,accept,unanimous_agreement
745172465,8621,"as per your suggestion, added some publish/subscribe to verify if the client is still receiving messages.",0,0,0,0.9874154925346376,0.9912436008453368,0.995230197906494,0.0,accept,unanimous_agreement
747898096,8621,"thought about it some more, i could only think of the following case when you would want this to be set to yes. [code block]",0,0,0,0.9815630912780762,0.9877060055732728,0.9857126474380492,0.0,accept,unanimous_agreement
747899111,8621,"slightly weird you added a function for non-local channels, but didn't add one for local channels. would suggest making it consistent.",-1,-1,-1,0.975368857383728,0.985887348651886,0.9756442904472352,-1.0,accept,unanimous_agreement
748631020,8621,i had actually but then removed it :|,-1,0,-1,0.9026542901992798,0.8275837302207947,0.9947711825370787,-1.0,accept,majority_agreement
767257545,8621,"do we wanna add key-specs here? and maybe also `firstkey`, lastkey`, etc? so some clients can automatically forward these commands to the right node? also, don't we wanna use the `getkeys_proc` here (`getchannelsfromcommand`)? need to see how this'll affect: * module api * command getkeys * acl note that this may make some of the other modifications unnecessary (like the one in processcommand)",0,0,0,0.9862522482872008,0.9945335388183594,0.993587851524353,0.0,accept,unanimous_agreement
767257892,8621,"nit pick, i'd rather declare these above `select`, so we don't have to modify the `bulkhdr` line.",0,0,0,0.9883239269256592,0.9932135343551636,0.9902177453041076,0.0,accept,unanimous_agreement
767257965,8621,indentation. [code block],0,0,0,0.9878809452056884,0.9898148775100708,0.9949744939804076,0.0,accept,unanimous_agreement
767369062,8621,"an earlier version had something similar to what you suggested, before keyspecs were merged though. i was against adding keyspecs primarily since they aren't keys and only have a single point of overlap which is verifying the query is sent to the right node. other use cases like client side tracking, acls, and modules required adding code to exempt them. it does give a hint to clients about about publishlocal, but subscribelocal and unsubscribelocal will still require explicit handling since they change flow of code. it's also worth noting that subscribelocal and publish have different behavior from regular key based commands, in that they don't be default re-direct to the primary. that's why i didn't want to expose them like other keys, which doesn't stop us from exposing them in a different field. thoughts?",0,0,0,0.9687304496765136,0.9890884160995485,0.9872681498527528,0.0,accept,unanimous_agreement
767463478,8621,"did you mean the current code? or a theoretical case in which we'll add key-specs? can you explain that? so anyway, you're saying that although there's some overlap with keys, since it's not a complete overlap, and because there are some behavior differences, we should not use the key name mechanisms (keys-specs, command getkeys, etc), and instead since this is just one special type of command (unlike commands that work on keys, in which new ones are added every release), clients will just have to learn how to explicitly handle these commands, and will not rely on any of the automatic mechanisms we created for keys?",0,0,0,0.9803187251091005,0.9855223894119264,0.988455295562744,0.0,accept,unanimous_agreement
768312009,8621,"yes, the current code does provide hint to the client in case of `publishlocal`. it follows the same mechanism and error response like in case of treating keys. `subscribelocal` and `unsubscribelocal` are bit more nuanced as we wanted to allow these commands on the replicas hence the client(s) need to be smart. yeah, as this is a special type of command, we believe we could keep the two separate in terms of parsing the `keys`/`channels` out.",0,0,0,0.9219391345977784,0.9881220459938048,0.9897181987762452,0.0,accept,unanimous_agreement
768538894,8621,"you mean it'll respond with a moved error, but that requires another round trip. some clients get data from command command on startup, so they know which node to use without a trial-and-error ping-pong, others implement some hard coded logic for a certain set of commands, and use command getkeys fallback for other commands.",0,0,0,0.9853315353393556,0.9816977381706238,0.9837913513183594,0.0,accept,unanimous_agreement
769809617,8621,"maybe we should add a new key flag for ""publish"" and ""subscribe"" keyspecs, so that clients can discover where they should route these requests. i'm not sure of how many clients really use get keys, we could print them here for compatibility, i don't think that is the right behavior. i see most people rely on the ""moved"" messages as opposed to the `command getkeys` command. redis-py-cluster for example already implements this logic as well, and just assumes they are going to act like keys.",0,0,0,0.8969373106956482,0.9818642139434814,0.9771375060081482,0.0,accept,unanimous_agreement
770441424,8621,"i didn't look a lot info client library code, but i do remember some libraries that use the output of command command (using `firstkey`, etc), implementing special logic for eval, and falling back to getkeys for anything else. maybe it was the go client.. anyway, i don't want to rely on a round-trip (neither moved, nor getkeys). so it's either we assume these 3 commands will get special handling by clients, or we support some way for discovery via command command. how about making them behave as keys (like supporting command getkeys, and key-specs), but adding another flag (to the command or the key-spec) that specifies these are not really keys?",0,0,0,0.8624262809753418,0.9071940779685974,0.9567170739173888,0.0,accept,unanimous_agreement
771900967,8621,i like the idea of adding them as a keyspec with a special flag. can you update the code so that we use the new keyspec functionality to define them with a special flag?,1,1,1,0.9504632353782654,0.8281406760215759,0.6761484742164612,1.0,accept,unanimous_agreement
773667483,8621,"i don't think we wanna do that. the whole point was that an innocent client, who doesn't know anything about the command, will be able to forward it to the right cluster node. so it is likely that such an innocent (old) client, is using the lagacy spec)",0,0,0,0.7837453484535217,0.6603084206581116,0.9252759218215942,0.0,accept,unanimous_agreement
773668802,8621,the container and function seem wrong.,-1,0,-1,0.7972554564476013,0.7686778903007507,0.8111472129821777,-1.0,accept,majority_agreement
773669343,8621,the container and function seem wrong.,-1,0,-1,0.7972554564476013,0.7686778903007507,0.8111472129821777,-1.0,accept,majority_agreement
773669694,8621,"i suppose sentinel can be removed, right? (same for the other commands)",0,0,0,0.9887127876281738,0.991848349571228,0.9925915002822876,0.0,accept,unanimous_agreement
773671102,8621,can this be reverted now? (together with the variable) maybe a few other things can be reverted as well?,0,0,0,0.9864437580108644,0.9945610165596008,0.9946730732917786,0.0,accept,unanimous_agreement
773671282,8621,indentation,0,0,0,0.982236921787262,0.822169840335846,0.9911677837371826,0.0,accept,unanimous_agreement
773671781,8621,"if we're changing all these lines anyway, let's improve the indentation of the comments.",0,0,0,0.9837100505828856,0.9810370206832886,0.9832399487495422,0.0,accept,unanimous_agreement
773834286,8621,i'm slightly confused regarding the keyspecs interaction with shard channel. let me sync up with again and update here.,-1,-1,-1,0.502682089805603,0.8838631510734558,0.5231999158859253,-1.0,accept,unanimous_agreement
773835164,8621,"i have introduced two subcommands under `pubsub` so i believe the function and container are correct. the subcommand has the history, since `7.0.0`.",0,0,0,0.9852026104927064,0.9883628487586976,0.9916160702705384,0.0,accept,unanimous_agreement
773850037,8621,damn. method rename by the ide caused it. :|,-1,-1,-1,0.989673376083374,0.9914541244506836,0.996730089187622,-1.0,accept,unanimous_agreement
773888327,8621,ohh sorry. my bad.,-1,-1,-1,0.9893559813499452,0.9938495755195618,0.9953741431236268,-1.0,accept,unanimous_agreement
774675009,8621,"no, that was not the point. innocent clients can continue to be inefficient and do multi-hops. if a client wanted to be smart, they can use the newer keyspecs to understand the topology. the legacy ranges already have gaps that clients have to work around. most cluster clients don't use this information, and just hack around it: [a link]",-1,0,0,0.7553266286849976,0.7927154302597046,0.9556013345718384,0.0,accept,majority_agreement
774677260,8621,"ok, so here's a counter example: [a link] (one that uses the legacy firstkey)",0,0,0,0.986850917339325,0.9857476353645324,0.9919577836990356,0.0,accept,unanimous_agreement
774680422,8621,"reverting this would also require us to go back and introduce a bunch of changes in places like acls and tracking to flag the keys returned here as ""not really keys"".",0,0,0,0.979784905910492,0.9247074723243712,0.98089337348938,0.0,accept,unanimous_agreement
774681323,8621,"and another one: [a link] so by exposing this info in the legacy firstkey, we may be getting implicit support by old clients",0,0,0,0.9868236780166626,0.9924566745758056,0.9939122200012208,0.0,accept,unanimous_agreement
774682841,8621,"i admit i didn't review the code deeply, so i'm not sure what you mean. i imagined that when we make these look like keys (even though they're not), the amount of special checks will be lower, not higher. i.e. in most cases the check of what to do with the command and it's arguments will benefit by making these look like keys. and we'll need to add special checks in just one or two places. e.g. maybe this one can be reverted: [a link]",0,0,0,0.7718445658683777,0.9132834672927856,0.893464982509613,0.0,accept,unanimous_agreement
774688711,8621,"amusingly the redis-py case won't actually work, since it'll find the pubsub flags and decide that it has ""no-keys"" since it is not one of the hard coded list of commands associated with pubsub.",0,0,0,0.9208365082740784,0.7854483723640442,0.594196081161499,0.0,accept,unanimous_agreement
774692990,8621,"yeah, it's a tradeoff between a touchpoint here: #8621 (comment) and in getnodesforquery() (where it's looking for keys for cluster stuff) and touch points in modules, acl, and tracking (where it's looking for keys for key related stuff). with more code refactoring i think all of these can be simplified though by relying on the full keyspecs instead of the legacy one, so i don't want to use that as a sticking point for which decision we pick.",0,0,0,0.9521512985229492,0.9768885970115662,0.9689383506774902,0.0,accept,unanimous_agreement
774714305,8621,"hari and i talked it over, and we decided to go with your suggestion. i believe the other touch points should eventually be resolved when we move more completely to key specs and can read the flags. we'll also update the documentation to make it clear that for compatibility reasons sharded-channels are considered keys for `command info`, `command`, and `command getkeys`.",0,0,0,0.9470949172973632,0.9465051293373108,0.8228088617324829,0.0,accept,unanimous_agreement
774736329,8621,"ok.. please try, and feel free to revert if you feel it's doing more damage than good... another alternative is to somehow exclude them in the legacy spec inside redis, but reflect them anyway in the output of command command, for the benefit of clients (excluding the ones that did explicit code to skip it, like reids-py did in the current version). i feel that it's likely that in my approach there are more places that will implicitly work, and less that need explicit handling than the alternative.. but try it and see what you end up with.",0,0,0,0.8415521383285522,0.8255298137664795,0.8510903120040894,0.0,accept,unanimous_agreement
780309993,8621,`while the the cluster` maybe typo?,0,0,0,0.986778736114502,0.9893240332603456,0.9869183897972108,0.0,accept,unanimous_agreement
780316384,8621,"`pubsubpublishmessageshard(channel, message)` parameters have space but `pubsubpublishmessage(channel,message);` don't have space. what about this? `pubsubpublishmessage(channel, message);`",0,0,0,0.983153998851776,0.992256999015808,0.9936785101890564,0.0,accept,unanimous_agreement
737615512,9656,need to add value_arg_abset and edit the script,0,0,0,0.9861593842506408,0.9939706325531006,0.9944039583206176,0.0,accept,unanimous_agreement
737618303,9656,"correction: make command->group and arg->type to enums. then we don't need it (to know which of the value union it is, check type==oneof or type==block make sure to have type_absent",0,0,0,0.9744755625724792,0.9897284507751464,0.9944696426391602,0.0,accept,unanimous_agreement
740033025,9656,"re-thinking that huge doc-comment again, if we keep it here in this form, we'll have it twice in our repo. i suppose there's no sense in having it next to the generated code, and there's probably no sense having it in the generator script. the best place to have it would be next to the ""code"" we keep editing (like we had in the past, where it was next to the command table), so now that would be the individual json files, where we obviously don't want it. so let's figure out where we would look for the doc when we edit the json files. it's probably not commands.c or the generator script.. maybe move to server.h next to the rediscommand struct?",0,0,0,0.8434184789657593,0.6343404054641724,0.9326645731925964,0.0,accept,unanimous_agreement
740038302,9656,"this looks much better. i wonder what would be the doc for something like zpop it differs between resp2 and resp3 by both the fact the reply is a nested array, but also by the fact the the score is double rather than a string. i guess this would still be a single entry in the ""returns"" array, right? i suppose that for human readers that's enough, but maybe clients would want to further parse it and understand the nested types? maybe not, i remind myself that the whole purpose of resp3 is that clients don't need to understand the command in order to process the reply.",0,0,0,0.6581480503082275,0.937250018119812,0.5523549318313599,0.0,accept,unanimous_agreement
740039190,9656,"i wouldn't sort things in the json file alphabetically at all. i think the short one liners should be at the top, and the long ones at the bottom. summary should probably always be the first one, then the other one liners (since, group, function, arity, etc), then the big ones by this order: [history, keyspecs, returns, arguments]. i think this will be most convenient to edit.",0,0,0,0.9711106419563292,0.9301784634590148,0.968010425567627,0.0,accept,unanimous_agreement
751160767,9656,"i think we need to describe just the immediate return-type, and not dive into specifics.. but i'll add it as a question",0,0,0,0.9718815684318542,0.9655237197875975,0.9866743683815002,0.0,accept,unanimous_agreement
758381548,9656,out dated,0,0,0,0.9606872797012328,0.8757746815681458,0.9889050722122192,0.0,accept,unanimous_agreement
758382039,9656,will be handled in [a link],0,0,0,0.987321138381958,0.9906573295593262,0.9946123361587524,0.0,accept,unanimous_agreement
758467968,9656,"it's not possible to add a `,` after the last element in an array in json, right? it sucks since adding another element will change two lines. p.s. maybe we should add a newline at the end of file, some tools give an annoying silly warning for that.",-1,-1,-1,0.968907356262207,0.9897398948669434,0.9955257773399352,-1.0,accept,unanimous_agreement
758470424,9656,"just to be on the safe side, did you validate that the command command output before and after this pr is the same (i.e. no copy paste errors or other bug in the pipeline of the processing of keyspecs and such)?",0,0,0,0.9889344573020936,0.9913913011550904,0.99326890707016,0.0,accept,unanimous_agreement
758471017,9656,didn't we want to add some mapping to refer from a key argument to the keyspec index?,0,0,0,0.9858986139297484,0.9939157366752625,0.9928491115570068,0.0,accept,unanimous_agreement
758472089,9656,"so ""history"" is an array of pairs? i.e. allows multiple changes per version..",0,0,0,0.9843232035636902,0.9921703934669496,0.9937680959701538,0.0,accept,unanimous_agreement
758474525,9656,"`stale` and `loading` are misleading, these used to be `ok-stale` or `allow-stale`",0,0,0,0.9681634902954102,0.9894315004348756,0.9351956844329834,0.0,accept,unanimous_agreement
758476736,9656,"maybe we do want to keep some of the acl categories implicit (i.e. automatically added by the command flags)? it may be a bit confusing, but at least there's no redundant info and a chance for a conflict.",0,0,0,0.9150350093841552,0.9862582683563232,0.958371639251709,0.0,accept,unanimous_agreement
758478442,9656,"in theory the command itself doesn't block redis's main thread for long, so it's o(1). but also, maybe it's ok to skip this field or leave it empty for some commands?",0,0,0,0.9834627509117126,0.992764174938202,0.9892041087150574,0.0,accept,unanimous_agreement
758489139,9656,this is gonna change soon in #9748 (not sure which one is gonna get merged first),0,0,0,0.9797065258026124,0.9871715903282166,0.9687753319740297,0.0,accept,unanimous_agreement
758581880,9656,"yes, it sucks. i'll ask itamar to add newlines",-1,-1,-1,0.9895837903022766,0.9932077527046204,0.995194375514984,-1.0,accept,unanimous_agreement
758582197,9656,will do,0,0,0,0.9603245854377748,0.957181751728058,0.9619618058204652,0.0,accept,unanimous_agreement
758582672,9656,"yes, is that ok with you?",0,0,0,0.9834017753601074,0.973795473575592,0.9893875122070312,0.0,accept,unanimous_agreement
758582802,9656,"i'll add it to ""open issues""",0,0,0,0.9863005876541138,0.9877198338508606,0.9946410655975342,0.0,accept,unanimous_agreement
758584753,9656,we discussed this and reached the conclusion that it's better if the input flags (in the json files) are the same as the output flags (in command) do you wish to re-open that discussion?,0,0,0,0.987151265144348,0.9894782900810242,0.9942725896835328,0.0,accept,unanimous_agreement
758586340,9656,"it was generated from command's reply, i guess we can reverse-engineer it and omit acl categories that were implicitly added sounds good?",0,0,0,0.980938196182251,0.989309787750244,0.9544563293457032,0.0,accept,unanimous_agreement
758587299,9656,i will make it optional,0,0,0,0.9857930541038512,0.9729582667350768,0.9938156604766846,0.0,accept,unanimous_agreement
758588415,9656,probably 9748 - let's try to remember to update this json when the other pr is merged,0,0,0,0.9850168228149414,0.9931662678718568,0.9895171523094176,0.0,accept,unanimous_agreement
758671107,9656,actually this pr changes the current command table so once one of the prs is merged the other will get conflicts,0,0,0,0.9632720947265624,0.9888837337493896,0.9900701642036438,0.0,accept,unanimous_agreement
759049806,9656,ran it and indeed there was a bug in the generation script. fixed.,0,0,0,0.9820597171783448,0.9897247552871704,0.9891904592514038,0.0,accept,unanimous_agreement
759051027,9656,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
759147724,9656,i suppose.. it can't be a map. the alternative is that each version holds an array of changes. i don't mind that much.,0,0,0,0.6065686941146851,0.780491292476654,0.809518039226532,0.0,accept,unanimous_agreement
759148714,9656,"ohh, i remember. so the flags in command are already part of redis api, and we want to align with them..",0,0,0,0.9580433964729308,0.9614117741584778,0.922672688961029,0.0,accept,unanimous_agreement
759149529,9656,"so now in some sense the json files are different than what command command generates, right?",0,0,0,0.9836140871047974,0.988385796546936,0.9905451536178588,0.0,accept,unanimous_agreement
759157051,9656,"needs a doc comment. (mention the limitations in which it'll error) p.s. let's list all interface changes in the top comment, including the new module api.",0,0,0,0.9873892068862916,0.9835642576217652,0.9947578310966492,0.0,accept,unanimous_agreement
759157812,9656,the doc comment is outdated. p.s. let's note in the top comment that you're changing existing (unreleased) apis (and why),0,0,0,0.9491634368896484,0.9846011400222778,0.9908919930458068,0.0,accept,unanimous_agreement
759160571,9656,"all of these need to be documented, and maybe explained that their only impact is the output of command command?",0,0,0,0.9813973903656006,0.9925588369369508,0.9914082884788512,0.0,accept,unanimous_agreement
759162086,9656,"the api must be documented (purpose and input (space separated)) also, we didn't add hints yet to any of the redis commands or documented their purpose. i guess we need to either keep this api out and introduce it later, or add some note here about the purpose and a reference to some non-existing redis.io page (and a todo item or an issue to complete that) either way, make sure it's listed in the top comment.",0,0,0,0.9856089949607848,0.9910746216773988,0.993783712387085,0.0,accept,unanimous_agreement
759167455,9656,did we change the type? how did this work till now?,0,0,0,0.9778552055358888,0.9896195530891418,0.9935126900672911,0.0,accept,unanimous_agreement
759169735,9656,these will need to be documented in module.c,0,0,0,0.9841193556785583,0.9934566617012024,0.9958957433700562,0.0,accept,unanimous_agreement
759171218,9656,mention this fix in the top comment.,0,0,0,0.9834888577461244,0.9910832643508912,0.9946455955505372,0.0,accept,unanimous_agreement
759172411,9656,let's put a comment on the other end too. same for the other enums below.,0,0,0,0.9876378774642944,0.9924512505531312,0.996166467666626,0.0,accept,unanimous_agreement
759175871,9656,"let's mention this fact in the top comment where we describe the interface changes (i.e. the mix of array of fixed indexes, and a map). p.s. we'll need a big redis-doc pr to describe all of that, and in theory maybe we wanna avoid merging this pr until the doc is ready. not doing so can lead to two things: 1. we'll forget or run out of time, and release this undocumented. 2. we'll get some new realizations when documenting it about the usefulness or clarity of something and it may be too late to fix. 3. it may be easier for other reviewers to review the docs rather than the code. please add a todo bullet in the top comment for docs.",0,0,0,0.8615870475769043,0.9709780812263488,0.9778083562850952,0.0,accept,unanimous_agreement
759191652,9656,"did we agree that this refers to the module version or the redis version? (needs to be clearly documented, and maybe the example should reflect it). maybe this is another thing to mention in the top comment. not sure how useful it is for clients...",-1,0,0,0.8809515833854675,0.9677714109420776,0.8316314220428467,0.0,accept,majority_agreement
759192167,9656,leftover?,0,0,0,0.9728609323501588,0.9780583381652832,0.988727331161499,0.0,accept,unanimous_agreement
759195180,9656,"i'm not sure i understand what each of the old 3 tests attempted to test, and why the new one has two? one tries to create a dup sub-command, and the other tries to create a sub-sub-command? the 3rd one attempted to create a sub-command on a non-existing command? (the equivalent of passing null and crashing in the new code). maybe a one line comment next to each can help.",0,0,0,0.7950381636619568,0.9073168635368348,0.5726522207260132,0.0,accept,unanimous_agreement
759196203,9656,"when i saw the module code, i imagined that maybe you're matching the response against the non-module xadd response. maybe that's not a bad idea? (on the other hand my suggestions about versions would kill that idea, not sure which one is better).",0,0,0,0.6241046190261841,0.8877217173576355,0.9089320302009584,0.0,accept,unanimous_agreement
759197978,9656,"maybe just `lindex` or `dict get` the relevant entry, instead of matching the whole reply?",0,0,0,0.9867268800735474,0.9928367733955384,0.987941563129425,0.0,accept,unanimous_agreement
759201927,9656,leftover?,0,0,0,0.9728609323501588,0.9780583381652832,0.988727331161499,0.0,accept,unanimous_agreement
759203293,9656,"example of what we emit? that's nice but: 1. maybe we want to include the words ""output example:"" so it'll be clearer. 2. why do we have it just in one function and not others?",0,1,0,0.6490434408187866,0.576056718826294,0.7650806903839111,0.0,accept,majority_agreement
759203666,9656,leftover?,0,0,0,0.9728609323501588,0.9780583381652832,0.988727331161499,0.0,accept,unanimous_agreement
759522122,9656,it used to be `char *` and now it's `const char *`,0,0,0,0.9826723337173462,0.9934004545211792,0.9931342601776124,0.0,accept,unanimous_agreement
759543184,9656,we agreed it's the module version.. i'll add a comment in the test module,0,0,0,0.9709392189979552,0.9429304003715516,0.9953212141990662,0.0,accept,unanimous_agreement
759557763,9656,"but is it an sds? if not then this casting is invalid. if yes, then maybe it should be typed correctly.",0,0,0,0.969947874546051,0.989277720451355,0.9925387501716614,0.0,accept,unanimous_agreement
759587330,9656,"it's sds only for module commands, const char * fo native commands",0,0,0,0.9879605174064636,0.9518114924430848,0.9953629970550536,0.0,accept,unanimous_agreement
759903020,9656,"ok, a little bit awkward. i hope it doesn't bite us some day.",-1,-1,-1,0.8188056349754333,0.9812249541282654,0.977343738079071,-1.0,accept,unanimous_agreement
759975895,9656,"for now we use the module version and not redis i will compare the result against xadd's i also made a comment in the test module that we use the redis version just for testing, and it should actually be the module version i added this issue under ""open issues""",0,0,0,0.9829983115196228,0.988896369934082,0.994281530380249,0.0,accept,unanimous_agreement
759976946,9656,"yep, added comments (indeed the third test in not applicable anymore)",0,0,0,0.9875673055648804,0.987661838531494,0.9927929639816284,0.0,accept,unanimous_agreement
759978745,9656,ok please note that currently both rediscommandresp2type and rediscommandresp3type are unused should we keep them (it'll be helpful for [a link],0,0,0,0.980453610420227,0.7337422370910645,0.995072305202484,0.0,accept,unanimous_agreement
759990192,9656,"addacllogentry calls sdsnew not matter what, i think we should change it to take `const char*` wdyt?",0,0,0,0.9802315831184388,0.9895529747009276,0.9922237396240234,0.0,accept,unanimous_agreement
759992385,9656,i guess we should trim them and add them in the later pr. but i'm also ok with adding them now and use later.,0,0,0,0.9650888442993164,0.8983737230300903,0.9748323559761048,0.0,accept,unanimous_agreement
759993997,9656,"or, considering the function takes an sds, it should have used `sdsdup` (faster)",0,0,0,0.9867013096809388,0.9940245747566224,0.9901524186134338,0.0,accept,unanimous_agreement
760056401,9656,"yes, but that would cause a crash now either we make sure it gets a real a sds or we decide it gets a const char* your call",0,0,0,0.9605780243873596,0.9041974544525146,0.9854971766471864,0.0,accept,unanimous_agreement
760088966,9656,"if it takes an sds, and someone passes a non-sds, should crash, and we need to either change the arg type or fix the caller. but why would it crash? the code we're looking at already has an sds, is the same object (command) used elsewhere as a char*? anyway, please try to fix it, if you can make it a real sds and use sdsdup with minimal changes, let's do it. but if in many cases we have to create an sds, just in order to dup it, let's use char* so please try to sort it up and decide which one is better.",0,0,0,0.9615010023117064,0.8965105414390564,0.8179639577865601,0.0,accept,unanimous_agreement
760114154,9656,right,0,0,0,0.9538289308547974,0.8996442556381226,0.9678029417991638,0.0,accept,unanimous_agreement
760114608,9656,so i'll keep them,0,0,0,0.9747593998908995,0.9800193309783936,0.9687669277191162,0.0,accept,unanimous_agreement
760154027,9656,"so maybe we should make them even more different, to make sure no one uses them by mistake instead of getting them from redis. first, we can change `loading` back to `ok-loading`, but maybe we can do something even more drastic to guarantee no one uses them?",0,0,0,0.974084496498108,0.990388810634613,0.9874812960624696,0.0,accept,unanimous_agreement
760824576,9656,is this a bugfix? let's list it in the top comment.,0,0,0,0.8689747452735901,0.9859126210212708,0.9951759576797484,0.0,accept,unanimous_agreement
760827897,9656,so now module commands can get arity check before being executed (instead of doing their own checks and do `redismodule_wrongarity`? maybe we should specify that in the top comment. (iirc we did say that all of these are just for command command output),0,0,0,0.986098051071167,0.9929718375205994,0.9932235479354858,0.0,accept,unanimous_agreement
760832815,9656,let's refer here to the placeholder md file in redis.io,0,0,0,0.9886589646339417,0.9911254048347472,0.9954590797424316,0.0,accept,unanimous_agreement
760846805,9656,redismodule_arg_type_oneof is repeated twice.,0,0,0,0.9867658615112304,0.9877888560295104,0.9918931722640992,0.0,accept,unanimous_agreement
760847564,9656,not specifically related to this block: please run the script that generate an md from this doc and open it in some md viewer to see that the syntax is displayed correctly.,0,0,0,0.9872259497642516,0.9892645478248596,0.9946340322494508,0.0,accept,unanimous_agreement
760853898,9656,didn't you say that for modules the command name is an sds (hence the casting before this change)? maybe i'm missing something (superficial review),0,0,0,0.6331620216369629,0.9776158928871156,0.9740083813667296,0.0,accept,unanimous_agreement
760854167,9656,please be sure to run valgrind on this branch.,0,0,0,0.977609634399414,0.9902756214141846,0.9902061820030212,0.0,accept,unanimous_agreement
760856130,9656,just making sure you also updated the example in the docs with these changes,0,0,0,0.9836437106132508,0.987396776676178,0.9937785267829896,0.0,accept,unanimous_agreement
760856881,9656,please add a short comment before this huge block explaining what it does.,0,0,0,0.9709789752960204,0.9594376683235168,0.9651052355766296,0.0,accept,unanimous_agreement
760858030,9656,please add a short comment before this huge block explaining what it does.,0,0,0,0.9709789752960204,0.9594376683235168,0.9651052355766296,0.0,accept,unanimous_agreement
760858121,9656,please add a short comment before this huge block explaining what it does.,0,0,0,0.9709789752960204,0.9594376683235168,0.9651052355766296,0.0,accept,unanimous_agreement
760858228,9656,please add a short comment before this huge block explaining what it does.,0,0,0,0.9709789752960204,0.9594376683235168,0.9651052355766296,0.0,accept,unanimous_agreement
760859602,9656,please add a short comment before this huge block explaining what it does.,0,0,0,0.9709789752960204,0.9594376683235168,0.9651052355766296,0.0,accept,unanimous_agreement
761985045,9656,"not really a bug fix, but we kinda decided that constant literals should be uppercase (that's how they are going to appear in the command syntax) i'll mention it in the top comment",0,0,0,0.973460853099823,0.9595243334770204,0.9358850121498108,0.0,accept,unanimous_agreement
761988482,9656,i did [code block],0,0,0,0.9856239557266236,0.985258162021637,0.9940557479858398,0.0,accept,unanimous_agreement
761990630,9656,"the sentence is correct, it is the ""value"" that should be null (if it's a pure-token there's no value/placeholder/content or whatever we decide to call it)",0,0,0,0.984874427318573,0.992660105228424,0.9928491115570068,0.0,accept,unanimous_agreement
761991371,9656,how do i do that?,0,0,0,0.9624471068382264,0.9632811546325684,0.9893975257873536,0.0,accept,unanimous_agreement
761992987,9656,you are correct but here c->cmd is most likely not a module command (we are in rm_call) i could check the cmd_module flag and call sdsnew or sdsdup accordingly...,0,0,0,0.9874064326286316,0.9910529255867004,0.992222249507904,0.0,accept,unanimous_agreement
761994890,9656,"actually i didn't but it doesn't really matter (i adjusted the code itself just to fit xadd's json, but it's just names of things...)",0,0,0,0.9087986946105956,0.9727894067764282,0.9815896153450012,0.0,accept,unanimous_agreement
761995498,9656,i did add the `-1` where needed cause otherwise it wouldn't compile,0,0,0,0.9883778691291808,0.9933828115463256,0.993385136127472,0.0,accept,unanimous_agreement
762002830,9656,-steinberg i think we should first merge your doc pr and then we will re-generate the jsons so that config-set.json will include that fix,0,0,0,0.9715776443481444,0.9804900288581848,0.9593275785446168,0.0,accept,unanimous_agreement
762542104,9656,"`ruby modules/gendoc.rb` to generate the md file. you can maybe post it in gh gist editor or something, but the truth is that redis-io renders md files a bit differently, so try to follow this: [code block] you can probably ask yoav / itamar / viktor for help",0,0,0,0.97516930103302,0.9928386807441713,0.992407500743866,0.0,accept,unanimous_agreement
762542252,9656,"ok, so the reason this casting was working till now is because internally the acl code didn't use the sds header.. so now it's cleaner, and there's no decrease of efficiency... thanks.",1,1,1,0.9366608262062072,0.9785754680633544,0.9774338603019714,1.0,accept,unanimous_agreement
762575097,9656,why do we need that? maybe an indication that something should be moved to server.h?,0,0,0,0.9846168756484984,0.9835785627365112,0.9814429879188538,0.0,accept,unanimous_agreement
762576028,9656,just merged with updated _commands.json_,0,0,0,0.987180769443512,0.9933897256851196,0.9950037598609924,0.0,accept,unanimous_agreement
764826803,9656,note the following doc pr: [a link] and sister code pr: #9914 once merged this should be updated.,0,0,0,0.9867622256278992,0.9772711396217346,0.9946901798248292,0.0,accept,unanimous_agreement
767603439,9656,"why do we refer to this as a ""proxy""? i think it's a confusing term, and we could just call this a `redismodulecommand`.",0,0,0,0.615548849105835,0.7788333892822266,0.5246375799179077,0.0,accept,unanimous_agreement
767610259,9656,"consider specifying all possible errors, and the fact this is intended for and restricted for current module's commands only.",0,0,0,0.9847043752670288,0.9894340634346008,0.9916310906410216,0.0,accept,unanimous_agreement
767613912,9656,"what's our future proofing approach to new commands flags? as it is, future modules using new flags on older versions will simply fail and have no idea why.",0,0,0,0.7963930368423462,0.8989469408988953,0.9442296624183656,0.0,accept,unanimous_agreement
767614542,9656,describe in what conditions this can fail?,0,0,0,0.9496804475784302,0.9661402106285096,0.9926868677139282,0.0,accept,unanimous_agreement
767616544,9656,need to validate there's no user implementation for the parent command?,0,0,0,0.9731740951538086,0.9885069131851196,0.9933279752731324,0.0,accept,unanimous_agreement
767618907,9656,consider freeing in case this gets called twice?,0,0,0,0.9839290380477904,0.9912386536598206,0.9929034113883972,0.0,accept,unanimous_agreement
767619979,9656,same as above - consider freeing.,0,0,0,0.9844927787780762,0.989840030670166,0.9920405745506288,0.0,accept,unanimous_agreement
767635488,9656,"i'm thinking about how a module with many commands and arguments going to look like, and i wonder if we've considered also the option of making this completely declarative, i.e. the module makes a single call and provides a complex nested structure with everything. this is of course not mutually exclusive and modules may even take that approach internally and still call these commands, but i'm asking myself if that's even possible and if it is - what would be a better api design. another thing that came up in different places is how we're going to handle backwards compatibility as we move on, i.e. handling of unsupported keyspecs / argument types / flags / etc. when provided by future modules compatible with future versions of redis.",0,0,0,0.749164879322052,0.754199206829071,0.8833351135253906,0.0,accept,unanimous_agreement
767719988,9656,isn't it the same as `rm_createcommand`? so modules will have to detect the redis version and avoid passing flags that it doesn't support (otherwise it'll error),0,0,0,0.9767890572547911,0.9892238974571228,0.9923985600471495,0.0,accept,unanimous_agreement
767725891,9656,"the sub-commands will obviously need to be called separately if the module wants to provide a separate function pointer for each. but i suppose that all the metadata about the command can be provided with some json string. this would still be ""abi"" compatible, but we'll have to: 1. add some json parser in redis core. 2. handle parts of the errors in parsing that json internally (backwards / future compatible), instead of just error one api call and let the module decide how to proceed. other notes: * i might be narrow minded, and just wishing to stick to what's been working so far. * i do understand the module code is gonna look ugly, and that in any case they don't have a high incentive to use this new api. * i don't like adding a json parser to redis core at the moment.",0,0,0,0.7808465361595154,0.969828486442566,0.972575545310974,0.0,accept,unanimous_agreement
769432597,9656,anything to add?,0,0,0,0.981289565563202,0.9896838665008544,0.9926506876945496,0.0,accept,unanimous_agreement
769439572,9656,it depends if we want to let users create ugly stuff like command which has subcommand but is also valid with argc=0 i guess we don't.,-1,0,0,0.8270806074142456,0.5897630453109741,0.8025161027908325,0.0,accept,majority_agreement
769486148,9656,make sure to document this (top comment and future docs),0,0,0,0.9647793769836426,0.9853283762931824,0.9934019446372986,0.0,accept,unanimous_agreement
769615226,9656,"i think we still need this method to run at runtime and apply the implicit flags. i.e. we removed the string compare, but we still need some runtime processing. we could also do that in the python script, but i think it's better here.",0,0,0,0.9743757247924804,0.975480020046234,0.9815634489059448,0.0,accept,unanimous_agreement
769615355,9656,same,0,0,0,0.9733930826187134,0.8844984173774719,0.9850570559501648,0.0,accept,unanimous_agreement
769615559,9656,same,0,0,0,0.9733930826187134,0.8844984173774719,0.9850570559501648,0.0,accept,unanimous_agreement
769615877,9656,same,0,0,0,0.9733930826187134,0.8844984173774719,0.9850570559501648,0.0,accept,unanimous_agreement
769622286,9656,this is no longer required,0,0,0,0.971487045288086,0.9840006828308104,0.99435955286026,0.0,accept,unanimous_agreement
769625401,9656,"how come? how do you distinguish between ones that are ""also in sentinel"" and ones that are ""only in sentinel""?",0,0,0,0.9836663007736206,0.979710578918457,0.9892300963401794,0.0,accept,unanimous_agreement
769628148,9656,"ohh, i see you just listed both in the json file. isn't it cleaner to just list the sentinel_only in the json file, and have the other one implicit?",0,0,0,0.9781081676483154,0.9866402745246888,0.9838125705718994,0.0,accept,unanimous_agreement
769662981,9656,"i think i prefer the only implicit thing here is acl categories and not command flags... we can revisit that in the future specifically for sentinel i doubt there would be other ""only_sentinel"" commands ok?",0,0,0,0.9473280906677246,0.9831368327140808,0.9559615850448608,0.0,accept,unanimous_agreement
769683579,9656,"for a moment i thought that maybe should avoid renaming these to protect the blame log, but since we also created a new variable for them `acl_categories`, i suppose renaming is better, otherwise we risk them being check against the wrong flag somewhere (other branches).",0,0,0,0.9603809714317322,0.9880732893943788,0.97474604845047,0.0,accept,unanimous_agreement
769685868,9656,"if we move these to be above the categories, maybe they won't show in the blame log?",0,0,0,0.9734030961990356,0.993133544921875,0.9694005846977234,0.0,accept,unanimous_agreement
769697647,9656,"it was decided to take the module api out of this pr, and handle in another one.",0,0,0,0.9854415655136108,0.9918015599250792,0.9932141304016112,0.0,accept,unanimous_agreement
769699982,9656,"not in this scope, in a broader scope i think this is a not optimal and we should probably improve that - maybe add a way to indicate some flags are optional and may silently fail.",0,0,0,0.9304558038711548,0.9305461049079896,0.8737083077430725,0.0,accept,unanimous_agreement
769732454,9656,not sure... is it important? i changed in-line comments so the blame log would change anyway,0,-1,0,0.8464220762252808,0.5842809677124023,0.6166031956672668,0.0,accept,majority_agreement
769775310,9656,is this the number of config parameters in redis? or the config parameters requested? i think n*m,0,0,0,0.9780486822128296,0.9878994822502136,0.9938403367996216,0.0,accept,unanimous_agreement
769776923,9656,"i suppose that since n is the number of total configs in redis, and it's constant and low, it's ok to list it as o(1). so that's applicable on my comment above too, which makes n the number of requested configs? i'm not an expert on that matter.. ?",0,0,0,0.9131503105163574,0.9454256892204284,0.9792494177818298,0.0,accept,unanimous_agreement
769778121,9656,"i think the complexity is o(n), when n is the number of queued commands.",0,0,0,0.9848747849464417,0.9835211038589478,0.985541045665741,0.0,accept,unanimous_agreement
769779460,9656,"is ""na"" now part of the ""protocol""? maybe we better leave empty? wdyt? p.s. isn't it an o(1) command?",0,0,0,0.9760343432426452,0.9921823143959044,0.9927697777748108,0.0,accept,unanimous_agreement
769781312,9656,isn't that o(n) where n is the number of latency events recorded? maybe graph is too?,0,0,0,0.9833523035049438,0.9926953315734864,0.9934525489807128,0.0,accept,unanimous_agreement
769782017,9656,"again, i think this is o(1)",0,0,0,0.857593834400177,0.9723238348960876,0.9857365489006042,0.0,accept,unanimous_agreement
769782246,9656,"same question about ""na"" vs empty string.",0,0,0,0.9616215229034424,0.9661536812782288,0.9869760870933532,0.0,accept,unanimous_agreement
769782752,9656,it could be slow... but we really can't tell anything.,-1,-1,-1,0.6003497838973999,0.8352336883544922,0.5619682669639587,-1.0,accept,unanimous_agreement
769782871,9656,could be slow.,0,0,0,0.95437753200531,0.5376064777374268,0.6972895264625549,0.0,accept,unanimous_agreement
769784883,9656,bgrewriteaof was o(1),0,0,0,0.972952663898468,0.9598449468612672,0.991622507572174,0.0,accept,unanimous_agreement
769825997,9656,"n and m being..? if any of them is the number of configurations in redis, remember it's constant",0,0,0,0.9849879145622252,0.8927616477012634,0.9782091379165648,0.0,accept,unanimous_agreement
769827308,9656,oh ok just saw this comment iirc itamar and i discussed it and since the number of configurations is indeed constant it shouldn't count in the big o notation,0,0,0,0.8589934706687927,0.764804482460022,0.9617894291877748,0.0,accept,unanimous_agreement
769828443,9656,said that the number of events is capped by some constant,0,0,0,0.9837587475776672,0.9817386269569396,0.9909061193466188,0.0,accept,unanimous_agreement
769829421,9656,"""complexity"" is just free text, doesn't have to comply with any rules we left ""na"" so that it'll be easy to grep all the places that are missing this information",0,0,0,0.9715766310691832,0.9333239197731018,0.9915112853050232,0.0,accept,unanimous_agreement
769829833,9656,yes but this is foreground,0,0,0,0.9826043248176576,0.9560890793800354,0.9882289171218872,0.0,accept,unanimous_agreement
769832758,9656,"yes, realized that later, so i suggest [code block]",0,0,0,0.9854259490966796,0.981702983379364,0.9933307766914368,0.0,accept,unanimous_agreement
769835960,9656,`#define latency_ts_len 160`,0,0,0,0.9817720651626588,0.991378903388977,0.9919034838676452,0.0,accept,unanimous_agreement
769836806,9656,"well, ok. but what's the difference between `na`, a missing field, or one set to `""""`?",0,0,0,0.97394198179245,0.9761009812355042,0.9830915331840516,0.0,accept,unanimous_agreement
769837220,9656,"it should at least be uniform, i feel that a missing field is better if we don't have anything to say",0,0,0,0.8337239623069763,0.9383508563041688,0.9117199778556824,0.0,accept,unanimous_agreement
769837767,9656,"ohh, so it's the same as flushall. what did we write there?",0,0,0,0.9637485146522522,0.9742661714553832,0.9795883893966676,0.0,accept,unanimous_agreement
769844391,9656,"since it's free text, let's mention that it could be slow, and depends among others, on how much memory is allocated.",0,0,0,0.984982132911682,0.9596003293991088,0.981374740600586,0.0,accept,unanimous_agreement
769867694,9656,[code block] not so accurate but ok,0,0,0,0.9769487977027892,0.9787566661834716,0.7059217691421509,0.0,accept,unanimous_agreement
776037233,9656,"this will not be rendered as a list, because there is no blank line before the bullet list. (sorry i didn't see this before. you sneaked in this new api in the huge pr.)",-1,-1,-1,0.985258936882019,0.984079658985138,0.9850490689277648,-1.0,accept,unanimous_agreement
776037752,9656,"this will not be rendered as a list, because there is no blank line before the bullet list.",0,0,0,0.9832958579063416,0.9882247447967528,0.9914548397064208,0.0,accept,unanimous_agreement
776171478,9656,can you please make a pr?,0,0,0,0.980867326259613,0.991252601146698,0.9949423670768738,0.0,accept,unanimous_agreement
795037812,9656,[code block] should we change it to? [code block] i see in set.json [code block] in pexpireat.json or expireat.json [code block] make a demo commit: [a link],0,0,0,0.9886830449104308,0.9938892126083374,0.9946687817573548,0.0,accept,unanimous_agreement
795046559,9656,"-binbin if you find a problem or an inconsistency on an already merged pr, please just post a pr (rather than a comment in the closed one). p.s. i'm not sure if milliseconds timestamp could be technically considered a ""unix-time"" but i see it already is in some fields, so let's at least be consistent.",0,0,0,0.9704679846763612,0.980036199092865,0.918873965740204,0.0,accept,unanimous_agreement
857114574,9656,[code block] please confirm it should be 0 here?,0,0,0,0.9897330403327942,0.9936507344245912,0.995781183242798,0.0,accept,unanimous_agreement
857115770,9656,"you're right. there's only one key-spec, so it can't be at index 1. please make a pr. p.s. how did you find that? maybe we can benefit from some mechanism that validates there.",0,0,0,0.9622730016708374,0.8355766534805298,0.9843754172325134,0.0,accept,unanimous_agreement
857134054,9656,"just found out while looking at the code, i haven't checked the rest of the commands.",0,0,0,0.9392293095588684,0.9805923700332642,0.9855695366859436,0.0,accept,unanimous_agreement
857134359,9656,"we might have to think of other ways to make sure other commands don't go wrong, rather than fixing one by one.",0,0,0,0.9682111740112304,0.9638703465461732,0.948817253112793,0.0,accept,unanimous_agreement
857427741,9656,"thanks, will you create a pr, or should i? and yes, we need to figure out a better way to spot these issues... got any ideas?",1,1,0,0.6746838092803955,0.6419727802276611,0.603543758392334,1.0,accept,majority_agreement
857431563,9656,idea: one of the python scripts for handling the json files could do some validation.,0,0,0,0.9853464365005492,0.9890133142471312,0.9886131286621094,0.0,accept,unanimous_agreement
857432461,9656,"is it possible to check whether the index is valid in generate-command-code.py and whether the key_spec contains an unused index. `rename` and `renamenx` also has problem. (have 2 index, but just use key_spec_index: 0)",0,0,0,0.9640966653823853,0.99513041973114,0.9931554198265076,0.0,accept,unanimous_agreement
881218394,9656,"i write a small ugly test script, and find out these, you guys can check on it, in case you guys forget this one - lcs: key2 key_spec_index error - rename: have unused key_spec - renamenx: have unused key_spec - watch: key_specs missing flags? - sunsubscribe / spublish / ssubscribe are not_key, i suppose they are ok - restore-asking: missing arguments, should it be like restore? - pfdebug: missing arguments, this is a debug command, so i suppose it is ok",0,0,-1,0.5466390252113342,0.7273648381233215,0.9472429156303406,0.0,accept,majority_agreement
881266512,9656,"-binbin how ""ugly"" is your script? i think we need it in a test case or a separate ci job.",-1,-1,-1,0.967359185218811,0.5920661091804504,0.6697360873222351,-1.0,accept,unanimous_agreement
882381469,9656,"-binbin thank you for reminding us.. looks like we forgot it. so first thing's first, let's fix them, please make a pr. if your test script is tcl based, let's put it in the test suite. alternatively, we could set some assertions in the c code. or put another test in the utils folder and somehow run it in some ci or manually from time to time (not preferred)",1,0,1,0.9460631012916564,0.5331488251686096,0.9315958619117736,1.0,accept,majority_agreement
882395665,9656,"i just write some logic in generate-command-code and the check spec_key logic base on my understanding i just wanted to see if we have any other commands that have the same problem first (we can fix it first and then try to find a way to check it) ok, i can summery it and then let's discuss it in other thread. can see it in #10779",0,0,0,0.926374852657318,0.94130676984787,0.9797770380973816,0.0,accept,unanimous_agreement
1058521543,11659,"repost: i don't like this approach since it's cumbersome for adding more arguments. i think i suggested something else in the internal pr, but i'm going to suggest something else this time: we can completely reprocess the command, going back through the normal code path after the unblock, based on the work being done in [a link] this will be slightly less performant, given all of the code it's executing, but it is only once per connection so i think we can pay that cost and it should simplify the implementation a bit. we still need some simple state to track where we are in the auth chain, but other than that it should work fine.",-1,-1,-1,0.9562515616416932,0.6022873520851135,0.497949868440628,-1.0,accept,unanimous_agreement
1058522234,11659,"a general naming question for others. i don't think the word ""custom"" is adding much here, and would prefer just having this feature be called redismoduleauth.",0,0,0,0.9781752824783324,0.9711554646492004,0.9781952500343324,0.0,accept,unanimous_agreement
1058524784,11659,"i'm not convinced this api is needed. other functionality such as configs lack this mirror api, since you have a strategy which is to just unload and reload the module. happy to hear other thoughts.",1,1,1,0.9674042463302612,0.8800885677337646,0.8478448390960693,1.0,accept,unanimous_agreement
1058537018,11659,more typical style. [code block],0,0,0,0.9846585988998412,0.9896602630615234,0.9827086329460144,0.0,accept,unanimous_agreement
1058537323,11659,"this flag ""implies"" it's blocked. i wonder if instead of this we can just check if it's blocked and has the custom handler set.",0,0,0,0.8185981512069702,0.8716102242469788,0.9832240343093872,0.0,accept,unanimous_agreement
1058539078,11659,"repost: i also don't know if we need both of these return codes, i might combine them into one. whether or not auth succeeded should depend on whether or not the user was authenticated. thinking more, maybe we should combine succeeded, denied, and blocked together. the behavior being moduled by the apis that were called.",0,0,0,0.8866748213768005,0.9131656289100648,0.9888216257095336,0.0,accept,unanimous_agreement
1058540189,11659,"if we take an earlier suggestion of just reprocessing the command repeatedly, i think this code also becomes unneeded.",0,0,0,0.9657160043716432,0.977194368839264,0.9874979257583618,0.0,accept,unanimous_agreement
1058540460,11659,"repost: i'm not convinced we need to build two modules, and i'm also not convinced these need to be separate from the auth.c file.",0,0,0,0.6681994795799255,0.7249852418899536,0.9809426069259644,0.0,accept,unanimous_agreement
1058541297,11659,"i'm not sure we should silently return null on input validation. i would almost rather assert fail, since this means we're calling in an invalid context.",0,-1,0,0.5952840447425842,0.5635059475898743,0.7036093473434448,0.0,accept,majority_agreement
1058543019,11659,"this seems like a highly coupled function, i would have just left this in the calling function site. you also left a comment at the calling site describing the functionality of this function, which isn't great.",-1,-1,-1,0.5199768543243408,0.8358944058418274,0.9691821932792664,-1.0,accept,unanimous_agreement
1058558220,11659,this makes sense - i agree that module unload can be used instead.,0,0,0,0.977290689945221,0.929869830608368,0.9873580932617188,0.0,accept,unanimous_agreement
1060929943,11659,resolved in [a link],0,0,0,0.987494170665741,0.9891554713249208,0.9955808520317078,0.0,accept,unanimous_agreement
1060946144,11659,"if we reduce the 4 codes into 2 codes, we can have: `redismodule_auth_handled` and `redismodule_auth_not_handled`. to authenticate, the module can use the `rm_authenticate*` apis and return `redismodule_auth_handled`. to block a client on module based auth, the module can use the `redismodule_blockclientonauth` api and return `redismodule_auth_handled`. to deny authentication, the module will need to return `redismodule_auth_handled` without successfully using either of the apis above. to indicate that the module does not want to take any action related to auth, the module can return `redismodule_auth_not_handled`. this works fine - although denying authentication from the module is not very explicit since we don't have a specific return code or an api to deny auth. i can make the update to reduce the 4 codes to 2 (`redismodule_auth_handled` and `redismodule_auth_not_handled`) if this sounds good",0,0,0,0.9826889038085938,0.9950405955314636,0.9916530251502992,0.0,accept,unanimous_agreement
1061039120,11659,reposting an internal comment. perhaps we could use startup arguments so we can load the same module twice but have it register slightly different values.,0,0,0,0.8672621846199036,0.9661454558372498,0.9915803074836732,0.0,accept,unanimous_agreement
1061041240,11659,"that's true. they can be explicit by calling the denyauth api if they want, but if they call handled but don't do anything. i think this behavior, if you aren't authenticated you then throw an error is ok. however, one nuance is if you are using `hello` or `auth` on an *already* authenticated user, we won't be able to detect anything. perhaps we do need redismodule_auth_denied then.",0,0,0,0.9822110533714294,0.981809377670288,0.9734930396080016,0.0,accept,unanimous_agreement
1061057804,11659,"we are able to differentiate using the client flag. the `client_custom_auth_result` flag will be momentarily (only within the command handling context/duration) added to the client flags when the module uses the `rm_auth*` apis & is removed right before replying to the client. if this flag is missing, we will know that the module did not successfully authenticate the client with custom auth and in this case, we can reply to the client with an err message if the module returned `redismodule_auth_handled`. so, the 2 code approach (if you aren't authenticated through the ongoing auth/hello, you then throw an error) seems possible - but it is not the cleanest solution.",0,0,0,0.9848153591156006,0.9946828484535216,0.9923904538154602,0.0,accept,unanimous_agreement
1066440796,11659,"having multiple modules loaded adds a bit more test coverage as we have some marker concept to iterate over all the modules processed. if we can load the same module twice with different names, that should also work.",0,0,0,0.975807011127472,0.9876447319984436,0.9919718503952026,0.0,accept,unanimous_agreement
1066442829,11659,it does seem redundant. i also incline with the above.,0,0,0,0.9320544004440308,0.8167114853858948,0.8070534467697144,0.0,accept,unanimous_agreement
1066444477,11659,i did suggest the same during the internal discussion. this also removes the cyclic call between acl.c -> module.c -> acl.c.,0,0,0,0.9889786839485168,0.9926620721817015,0.994752049446106,0.0,accept,unanimous_agreement
1068749259,11659,removed this api in - [a link],0,0,0,0.987854778766632,0.9907728433609008,0.9964537620544434,0.0,accept,unanimous_agreement
1068752122,11659,"we will continue to have the second module for testing until there is an api / mechanism to properly support loading the same module (.so file) twice. right now we can load the module twice, however, we do not have a way to allocate internal data and access it later on through the rmcontext. if we try storing info in a pointer in the context of module 1, the pointer gets overwritten by module 2. if we have a mechanism to hold info for a module in the engine through the rmcontext and access it later, this option can be used and the second testing module can be removed.",0,0,0,0.9826231002807616,0.991866171360016,0.9906216859817504,0.0,accept,unanimous_agreement
1070166484,11659,i have switched to using 2 codes in this commit: [a link],0,0,0,0.986056923866272,0.9894545078277588,0.995060384273529,0.0,accept,unanimous_agreement
1070166707,11659,this function is removed in [a link],0,0,0,0.986710011959076,0.9927406907081604,0.9959564805030824,0.0,accept,unanimous_agreement
1070167658,11659,this code is used to check if the client was authenticated through custom authentication (via the rm_authenticate* apis),0,0,0,0.9885241389274596,0.9924365878105164,0.9958862662315368,0.0,accept,unanimous_agreement
1070169178,11659,"no, this flag does not imply that the client is blocked, it just means that the client is attempting custom authentication. this flag is used in multiple places - (1) to check if any custom auth is ongoing in any client and to return err during module unloads if so (2) to allow auth chains to exist by avoiding resetting the client args between blocking auth callbacks (3) to queue the client for reprocessing if custom auth has not concluded after one cycle of a blocking auth callback (in this case the next cb will be attempted) (4) to assert that the rm_blockclientonauth can be used because the client is in the context of custom auth there are other cases where this is needed as well",0,0,0,0.983662724494934,0.9943240880966188,0.9941210150718688,0.0,accept,unanimous_agreement
1070169744,11659,"i am looking into re-processing the client in the case where a client is unblocked and yet, still in the middle of custom authentication. here, we can reprocess the client to attempt the next auth callback. i will try out this approach to see if it is possible. (1) to maintain the state of what custom auth callback was previously attempted, we will store a custom auth context inside the client struct as a void pointer (2) to avoid updating stats an additional time, we need to have some control flow to see that this is a reprocessed command",0,0,0,0.9714311361312866,0.9878986477851868,0.9507791996002196,0.0,accept,unanimous_agreement
1070446432,11659,added reprocessing logic here - [a link],0,0,0,0.988239049911499,0.9766262173652648,0.9958978295326232,0.0,accept,unanimous_agreement
1080557976,11659,"with this new introduction, if `prev_custom_auth_ctx` is not null and client-eviction/client-kill logic picks this client to be evicted, do we need to handle any logic in `freeclient` ? should we add tests for client-eviction/client-kill while client is blocked on auth ?",0,0,0,0.9860002398490906,0.99554044008255,0.9933075904846193,0.0,accept,unanimous_agreement
1080797172,11659,i added a test for the scenario where a client is killed in the middle of blocking custom auth here - [a link],0,0,0,0.9827336072921752,0.991934895515442,0.994091808795929,0.0,accept,unanimous_agreement
1097900638,11659,"i don't think you fully got my previous point about reprocessing the command. the idea was that if the auth and hello commands were fully re-entrant, we would be able to keep calling them over and over again until they succeeded without all this back code. let me know if my comment still isn't clear.",0,0,0,0.9651422500610352,0.898314893245697,0.9755948185920716,0.0,accept,unanimous_agreement
1097901320,11659,"i don't think you fully got my other comment, so afaik my comment is still true. in my suggestion there aren't auth results that are sticky outside of the call stack, as we immediately respond to the client.",0,0,0,0.9567302465438844,0.9407923817634584,0.982959508895874,0.0,accept,unanimous_agreement
1097902037,11659,"i think the confusion is that clients only retain some authentication state when they are blocked, in all other cases all the state is retired. just do go through your points: 1) this can only happen in the context of blocking, since in all other cases the client will immediately give up the state. 2) that is for blocking commands right? so my point seems appropriate here? 3) this is also in the context of blocking. 4) this is also in the context of blocking. generally speaking i don't want flags when there is other state that directly reflects the functionality we are modulating, which i think in this case is blocking context.",0,0,0,0.9405558705329896,0.9285118579864502,0.9728129506111144,0.0,accept,unanimous_agreement
1098035082,11659,"i don't know i fully understand this choice, why would we automatically reply with an authentication error in a timeout scenario?",0,0,0,0.6256242394447327,0.8936842083930969,0.6786758303642273,0.0,accept,unanimous_agreement
1098038530,11659,"the second point was that most of this should just be in auth.c is still valid, let's not just add more modules for very specific functionality.",0,0,0,0.9826512932777404,0.9897392392158508,0.9916375279426576,0.0,accept,unanimous_agreement
1100632025,11659,"this callback times out a blocking operation. it does not close the client. so, because the blocking operation is in the context of a command, we will need to reply to the client. this is just handling the case where the other blocking apis are used in the context of a custom authentication. however, invoking a timeout callback is not possible from a blocking custom auth operation. so, instead of handling it, we can server assert here .",0,0,0,0.9830297827720642,0.9904576539993286,0.9849945902824402,0.0,accept,unanimous_agreement
1101011225,11659,why not just check if client is blocked? (c->flags & client_blocked),0,0,0,0.9832131266593932,0.9903098940849304,0.9933250546455384,0.0,accept,unanimous_agreement
1101023102,11659,again can we expect client to be blocked because something else? or that is was previously blocked? i think not and we should avoid peeking inside blocking state.,0,0,0,0.9715365767478944,0.9793581366539,0.9864389896392822,0.0,accept,unanimous_agreement
1101088375,11659,wondering why we can't set the client_pending_command on an auth blocked client. this is basically indicating that we still have a pending command to reprocess and then handle it again on reprocess,0,0,0,0.9643536806106568,0.936446249485016,0.9638516306877136,0.0,accept,unanimous_agreement
1101104568,11659,"i understand the motivation here, but i am not sure why we can't just keep reprocessing the client and again block on auth? is this an issue with statistics?",0,0,0,0.7594683170318604,0.5861585736274719,0.9652379751205444,0.0,accept,unanimous_agreement
1102107619,11659,we can use `(c->flags & client_blocked)` instead. i will make the update,0,0,0,0.98847895860672,0.9909743666648864,0.9956845045089722,0.0,accept,unanimous_agreement
1102107716,11659,we can use `(c->flags & client_blocked)` instead. i will make the update,0,0,0,0.98847895860672,0.9909743666648864,0.9956845045089722,0.0,accept,unanimous_agreement
1103307578,11659,"these return codes don't seem to be set or used. maybe we should delete them, since they aren't set for moduleauthentication here.",0,0,0,0.9861447811126708,0.9820902347564696,0.9898313879966736,0.0,accept,unanimous_agreement
1103411353,11659,[code block] i attempted this change and saw that it raises this warning,0,0,0,0.9841294288635254,0.9829519391059875,0.9951950907707214,0.0,accept,unanimous_agreement
1103437714,11659,addressed here: [a link],0,0,0,0.985734224319458,0.9880650639533995,0.9955266118049622,0.0,accept,unanimous_agreement
1103437818,11659,addressed here: [a link],0,0,0,0.985734224319458,0.9880650639533995,0.9955266118049622,0.0,accept,unanimous_agreement
1103548540,11659,i replaced the `client_custom_auth` client flag with the `isclientmoduleauthinprogress` macro here - [a link],0,0,0,0.9888581037521362,0.9885228872299194,0.9955873489379884,0.0,accept,unanimous_agreement
1103549790,11659,i replaced the `client_custom_auth` client flag with the `isclientmoduleauthinprogress` macro in this commit - [a link],0,0,0,0.988636076450348,0.9876341819763184,0.9953319430351256,0.0,accept,unanimous_agreement
1103680508,11659,"we have two options: 1) prevent the module from using other module blocking apis (`rm_blockclient`, `rm_blockclientonkeys`, `rm_blockclientonkeyflags`) by adding a `serverassert` in these functions to ensure custom module authentication is not in progress. 2) add `serverassert` in the `moduleblockedclienttimedout` to make sure timeouts do not exist in the case of this module blocked client (since the 3 other blocking apis should not have been used in module based blocking authentication). which one of the 2 options seems better? adding one line of server in each of the other 3 blocking api functions seems like a better approach since it prevents any other incorrect behavior.",0,0,0,0.9834094047546388,0.995064914226532,0.9936637878417968,0.0,accept,unanimous_agreement
1103694766,11659,thanks - i am looking into using `client_pending_command`,1,1,1,0.9194018840789796,0.7775530219078064,0.8688570261001587,1.0,accept,unanimous_agreement
1103991779,11659,"i updated the client flags to have the `client_pending_command` flag when it is in the middle of blocking custom auth in this commit - [a link] with this new commit, the change you highlighted is removed. thanks. regarding reprocessing the client as part of the `modulehandleblockedclients` routine, there are a few changes needed to support multiple module based blocking operations in a single command call - it is possible, but will require some changes in this function and the `client` structure to hold the moduleblockedclient as this is needed for reply callbacks and free private data callbacks, blocked client counters etc. i will summarize this in a comment below.",1,0,1,0.834299623966217,0.4982915222644806,0.9520074725151062,1.0,accept,majority_agreement
1103991836,11659,"i updated the client flags to have the `client_pending_command` flag when it is in the middle of blocking custom auth in this commit - [a link] with this new commit, the change you highlighted is removed. thanks",1,1,1,0.9635076522827148,0.7636223435401917,0.895789384841919,1.0,accept,unanimous_agreement
1106417068,11659,i would prefer the first one.,0,0,0,0.957780122756958,0.9701371192932128,0.9503973126411438,0.0,accept,unanimous_agreement
1106463208,11659,"i'm not going to format this, but think about it. [code block] i also think we should include a blocking example.",0,0,0,0.9689676761627196,0.9531535506248474,0.9857527613639832,0.0,accept,unanimous_agreement
1106475471,11659,"we probably want a better error message than this? since it's not actually a blocking module command, it's blocking auth.",0,0,0,0.9611088633537292,0.9603541493415833,0.9551586508750916,0.0,accept,unanimous_agreement
1110401445,11659,"in this commit ([a link] - we are now preventing modules from using other module blocking apis (rm_blockclient, rm_blockclientonkeys, rm_blockclientonkeyflags) when custom auth is ongoing by replying with an `err` and setting the `module_blocked_handle` to null. modules can then use rm_unblockclient to clean up. the highlighted code is removed now",0,0,0,0.9860519170761108,0.993297517299652,0.9937199354171752,0.0,accept,unanimous_agreement
1113607932,11659,i'm trying to remember the issue. i thought that on some systems it was still throwing the warning because sds isn't a valid string. i think (char *) is the most consistent.,0,0,0,0.9636977314949036,0.9479978084564208,0.97601580619812,0.0,accept,unanimous_agreement
1113608530,11659,these error codes are now not set.,0,0,0,0.9377588033676147,0.953093945980072,0.9865748286247252,0.0,accept,unanimous_agreement
1113613698,11659,"we should consider making this a robj, so that the module can dynamically generate a response instead of just having to reply with a static object.",0,0,0,0.986523687839508,0.991058111190796,0.9918681979179382,0.0,accept,unanimous_agreement
1113616505,11659,"[code block] i still think generally the documentation is confusing because of the reference to ""ongoing custom auth"". i'm not clear why we aren't saying ""blocked on auth"" in all those cases.",-1,0,0,0.7071292996406555,0.652934730052948,0.7283449172973633,0.0,accept,majority_agreement
1113619044,11659,"my understanding is that this is being pushed back through the normal command flow, won't this be removed at the end anyways?",0,0,0,0.973629891872406,0.9901386499404908,0.9905461072921752,0.0,accept,unanimous_agreement
1113621164,11659,"document what this state means. either that, or make checkmoduleauthentication a ternary return code that includes this case. alternatively, maybe rename this state c->flags & client_blocked_on_module_auth, which is very clear what the state is.",0,0,0,0.98902028799057,0.9919288158416748,0.992880403995514,0.0,accept,unanimous_agreement
1113653561,11659,"i think this should probably return an enum with the different possible states (auth_ok, auth_err, auth_not_handled, auth_blocked), instead of having the calling sites have to infer everything. this documentation block is not immediately super clear, i think the return codes would make it a lot more readable.",0,0,0,0.9790793657302856,0.98374605178833,0.9690257906913756,0.0,accept,unanimous_agreement
1113654801,11659,[code block] zfree() internally does a null check.,0,0,0,0.9872810244560242,0.9929978847503662,0.9933398365974426,0.0,accept,unanimous_agreement
1113672075,11659,"yes, thanks. i removed it here: [a link]",1,1,1,0.8560895919799805,0.9552459716796876,0.6909980177879333,1.0,accept,unanimous_agreement
1113675451,11659,thanks - i removed the null check here: [a link],1,1,1,0.7770673632621765,0.9127289652824402,0.828916072845459,1.0,accept,unanimous_agreement
1113676913,11659,i committed the suggestion above,0,0,0,0.983076810836792,0.9627527594566344,0.9890563488006592,0.0,accept,unanimous_agreement
1113683811,11659,i refactored this in this commit: [a link],0,0,0,0.986993670463562,0.9800499081611632,0.995088517665863,0.0,accept,unanimous_agreement
1113693175,11659,need to clarify this is potentially a breaking command.,0,0,0,0.6253877878189087,0.8920906782150269,0.9587885737419128,0.0,accept,unanimous_agreement
1113694701,11659,"not required, but you can make a lot of these one shots. [code block]",0,0,0,0.9738497138023376,0.992719292640686,0.993177890777588,0.0,accept,unanimous_agreement
1113695024,11659,"this error message is automatically added from the engine from existing code in the `moduleblockclient` function if we try blocking a client (in the middle of lua or multi) from a module. [code block] i could add conditional logic here to say something like, ""blocking auth command invoked from a transaction"" - if the client is in the middle of module authentication. but, i don't think we should be expecting clients to see this error message because the modules should avoid calling `rm_blockclient*` apis since they have the ability to detect if the client is in the middle of lua or multi. because of this, i thought we can just reuse the same / existing error message",0,0,0,0.9749651551246644,0.9937200546264648,0.9913513660430908,0.0,accept,unanimous_agreement
1113707791,11659,"thinking about this more, should we allow this? if a module fails to load, it will also fail to unload since it's registered auth callbacks which can fail unload. maybe we should just think this through more.",0,0,0,0.971365213394165,0.9517216682434082,0.9799052476882936,0.0,accept,unanimous_agreement
1113709681,11659,it might be easier to add the top of this function do: [code block] since users are retained in between tests. makes tests a bit easier to read,0,0,0,0.980026125907898,0.9856491684913636,0.9898782968521118,0.0,accept,unanimous_agreement
1113710116,11659,"errno codes are set through inner function calls in `aclcheckusercredentials`. [code block] but because this is not directly done inside this (`aclauthenticationuser`), i removed it as suggested. [a link]",0,0,0,0.9893388152122498,0.994172990322113,0.9948424696922302,0.0,accept,unanimous_agreement
1113716720,11659,"from what i see this is needed for a proper clean up. the `client_pending_command ` flag is added in `rm_blockclientonauth`, but there are cases where blocking does not go through successfully. the one case that i know of is if the api was used in the middle of multi/lua. it is needed for any other case like this where the client does not actually go through the normal blocking / unblocking flow. it can be avoided by only adding the flag in `rm_blockclientonauth` if the client was successfully blocked. [code block]",0,0,0,0.9814729690551758,0.9938068985939026,0.9888179302215576,0.0,accept,unanimous_agreement
1113721969,11659,i made this change here: [a link],0,0,0,0.982239842414856,0.9816052317619324,0.9957043528556824,0.0,accept,unanimous_agreement
1113728101,11659,"i committed this suggestion, formatted it, and added an example of non blocking module based auth here. [a link] keeping the comment open to check whether we should add a blocking example.",0,0,0,0.9867299795150756,0.981695294380188,0.9927934408187866,0.0,accept,unanimous_agreement
1113777668,11659,i renamed this client_custom_auth_has_result to and also updated the documentation here: [a link],0,0,0,0.9870664477348328,0.984812557697296,0.995415449142456,0.0,accept,unanimous_agreement
1113779582,11659,"all tests use the same redisuser (it is hardcoded in the module to check that the user is `foo`) so doing this is tricky. some tests need to switch to have the same foo user on a different mode (with defaultpwd, no password, disabled etc) - so it is easier to configure this on the individual tests",0,0,0,0.5863198041915894,0.9801009893417358,0.9687874913215636,0.0,accept,unanimous_agreement
1114760979,11659,i made the change here: [a link],0,0,0,0.9841852188110352,0.9809569120407104,0.995617151260376,0.0,accept,unanimous_agreement
1115033035,11659,i made this change here: [a link] however the module should not free the `redismodulestring` since it is freed by the engine. i specified this in the documentation for the `rm_registercustomauthcallback` fn,0,0,0,0.9844670295715332,0.9901403784751892,0.995524764060974,0.0,accept,unanimous_agreement
1115171764,11659,i made this change here: [a link],0,0,0,0.982239842414856,0.9816052317619324,0.9957043528556824,0.0,accept,unanimous_agreement
1115287855,11659,"yes, that is a good point. we can prevent both module load and module unload operations while module based authentication is going on on any client to prevent this from happening.",1,0,0,0.7250144481658936,0.7779108881950378,0.7339102029800415,0.0,accept,majority_agreement
1115889765,11659,i was expecting a corresponding change in the module so it actually used the username instead of just continuing to hardcode the username.,0,0,0,0.9816548824310304,0.982633411884308,0.9884026646614076,0.0,accept,unanimous_agreement
1115962406,11659,"this will not work since the string might get freed in decrrefcount, which will make it unavailable. in the error reply.",0,0,0,0.9632326364517212,0.9666823148727416,0.9746323227882384,0.0,accept,unanimous_agreement
1115993463,11659,fixed here: [a link],0,0,0,0.9866117238998412,0.9899377822875975,0.9952822327613832,0.0,accept,unanimous_agreement
1116069498,11659,fixed here: [a link],0,0,0,0.9866117238998412,0.9899377822875975,0.9952822327613832,0.0,accept,unanimous_agreement
1121107469,11659,"addressed here: [a link] instead of preventing loading during custom auth, we are just unregistering the custom auth callbacks before calling `moduleunload`",0,0,0,0.9885204434394836,0.9932156205177308,0.9955421090126038,0.0,accept,unanimous_agreement
1122127056,11659,is there a specific rationale for fifo and not lifo ordering? this is somewhat more consistent with how we treat redis itself - a more recently loaded module has the ability to override those that were loaded earlier.,0,0,0,0.9850085973739624,0.9909176230430604,0.9917930960655212,0.0,accept,unanimous_agreement
1122155102,11659,"i'm not sure this is going to work in the real world, where there's potentially a never-ending flux of new connections and new clients authenticating. one solution is to unregister the auth callback immediately or flag it disabled, so clients will drain and iterating module unload will eventually succeed.",0,0,-1,0.7920785546302795,0.7733003497123718,0.6718651652336121,0.0,accept,majority_agreement
1122171535,11659,"did you consider making it possible to pass `privdata` here as well? the original `rm_blockclient` also doesn't provide a way to do that until the client is unblocked, but this is suboptimal and has proved to be a limitation in the past.",0,0,0,0.9842894673347472,0.9845050573349,0.9866329431533812,0.0,accept,unanimous_agreement
1122625672,11659,"from the examples i considered, the only use case of private data is when we unblock the client from a background thread and have some data (like a auth result) and want it to be accessed from the context of a reply callback. i could not think of a situation where the module provides data on blocking the client (`rm_blockclient`) and wants to access this later. is there an example you had in mind where a module wants to provide data while when using `rm_blockclient `? / is there an example of how this would work?",0,0,0,0.975100576877594,0.982946276664734,0.987212598323822,0.0,accept,unanimous_agreement
1122804189,11659,"maybe we can move the string to be returned as output argument by validateclientname, so that we don't need to repeat it?",0,0,0,0.9886809587478638,0.9942803382873536,0.9907537698745728,0.0,accept,unanimous_agreement
1122807067,11659,maybe fix the comment to also cover the auth_err case.,0,0,0,0.9845640659332277,0.9918137788772584,0.9871798157691956,0.0,accept,unanimous_agreement
1122847058,11659,styling nit pick. no newline between `}` and `else`,0,0,0,0.9835793375968932,0.690325915813446,0.5178672075271606,0.0,accept,unanimous_agreement
1122872630,11659,"that look is capable of being huge (possibly 30k clients). if we need that capability, we'll have to add a list of clients that are mid auth.",0,0,0,0.9819143414497375,0.9714528322219848,0.990077257156372,0.0,accept,unanimous_agreement
1122877119,11659,"maybe we can just prevent modules with such a callback registered from being unloaded (like we do for modules with data types). also, note that currently it is unsafe to even load a module that just registered commands (no data types of callbacks / hooks), see #10177. so module unloading is not really properly supported, and i think we can just give up that effort and forbid it. p.s. styling thing about `} else`",0,0,0,0.9529346823692322,0.9673734903335572,0.97798091173172,0.0,accept,unanimous_agreement
1122887341,11659,this variable name seems negated to me. maybe a better name would be `handle_next_callback`?,0,0,0,0.9828715324401855,0.8988590836524963,0.9890056252479552,0.0,accept,unanimous_agreement
1122890191,11659,"btw, i think the code would be nicer with an early `if` and `continue` instead indentation for the main part of the work, and the handling of the skipping at the bottom of the function.",0,0,0,0.9826872944831848,0.9900062680244446,0.9769556522369384,0.0,accept,unanimous_agreement
1122899620,11659,"how about a case were the module initiated some request to a remote provider and wants to keep the request id, or the connection on which it issued it?",0,0,0,0.9860897064208984,0.9928559064865112,0.988182008266449,0.0,accept,unanimous_agreement
1122908163,11659,"styling nit pick, no newline between `{` and `else`. i guess in this case the comment should go into the `else` block.",0,0,0,0.9886793494224548,0.9360120296478271,0.9771740436553956,0.0,accept,unanimous_agreement
1122911830,11659,"i guess we need to document this change / feature. first, so that people know they can pass null, and secondly, so people who use it will understand it's incompatible with old versions.",0,0,0,0.9693610072135924,0.9817495346069336,0.9623146057128906,0.0,accept,unanimous_agreement
1123600782,11659,"this still doesn't make much sense to me. what exactly are we attaching the private data to? who is reading it? if we sent it to a remote provider, that background job needs the information. i think it would make more sense if redis was tracking the request and unblocking it, so it could re-add the private data.",-1,0,0,0.5098423361778259,0.9157596826553344,0.5930701494216919,0.0,accept,majority_agreement
1123604422,11659,"i'm generally okay with module unloading being more of a ""testing thing"", and not something we really expect people to use much in production. iirc, the original motivation of unload was to make it easier to rapidly test functionality, not that is was being used much in production.",0,0,0,0.9451104998588562,0.7657945156097412,0.7877338528633118,0.0,accept,unanimous_agreement
1123758972,11659,addressed here: [a link],0,0,0,0.985734224319458,0.9880650639533995,0.9955266118049622,0.0,accept,unanimous_agreement
1123759383,11659,i addressed both comments here: [a link],0,0,0,0.9818173050880432,0.9722849130630492,0.993763029575348,0.0,accept,unanimous_agreement
1123763824,11659,i made the change here to switch to lifo: [a link],0,0,0,0.9858602285385132,0.9815015196800232,0.9958446621894836,0.0,accept,unanimous_agreement
1123765359,11659,addressed here: [a link],0,0,0,0.985734224319458,0.9880650639533995,0.9955266118049622,0.0,accept,unanimous_agreement
1123855046,11659,addressed here: [a link],0,0,0,0.985734224319458,0.9880650639533995,0.9955266118049622,0.0,accept,unanimous_agreement
1123855628,11659,addressed here: [a link],0,0,0,0.985734224319458,0.9880650639533995,0.9955266118049622,0.0,accept,unanimous_agreement
1123993530,11659,i updated the documentation here: [a link],0,0,0,0.982868194580078,0.9669079184532166,0.9947366118431092,0.0,accept,unanimous_agreement
1125084544,11659,"we talked internally and realized we do not need any special handling of module unload for custom module authentication. so, we are removing all new conditional logic added to module unload. it will behave exactly the same as it does currently. if there is any client that is blocked on a module x (`module->blocked_clients`), then module unload is prevented for module x. this logic exists today in the moduleunload fn [code block] if a module does not have any blocked clients associated with it, we will just unregister all the custom auth contexts belonging to the module. this should not impact other ongoing clients in the middle of custom authentication. we can think of this module auth chain. module1.callback->module2.callback->module3.callback if a client is still blocked on module1.callback, it is fine is unload module2 and module3. if a client is blocked on module2.callback, we cannot unload module 2, but we can unload module1 and module 3",0,0,0,0.9800062775611876,0.9919936656951904,0.9760538339614868,0.0,accept,unanimous_agreement
1125087562,11659,with this ([a link] this loop will be removed,0,0,0,0.982692003250122,0.9856900572776794,0.9959456324577332,0.0,accept,unanimous_agreement
1125132183,11659,this is removed in this commit: [a link],0,0,0,0.9864999055862428,0.9928303360939026,0.9961280822753906,0.0,accept,unanimous_agreement
1125132401,11659,i made the change for the above comment here: [a link],0,0,0,0.9855389595031738,0.9686669111251832,0.995425283908844,0.0,accept,unanimous_agreement
1125609067,11659,"i think we need to document the version from which we started doing that, so module authors know that if they rely on that, their module isn't compatible with older versions. wdyt?",0,0,0,0.9850618243217468,0.807571530342102,0.9858998656272888,0.0,accept,unanimous_agreement
1125610465,11659,"not sure i understand the question, shouldn't the private data be attached to the blocked connection? my thinking is that the module needs to associate each request to the remote provide with a specific client connection. i suppose it'll be possible to track the client id, but the module may need to create some dictionary mapping client id to each remote provider id, so letting it store that in the client can make it easier.",0,0,0,0.9636772274971008,0.9653700590133668,0.9152294397354126,0.0,accept,unanimous_agreement
1125613006,11659,"if we want to attach information to a client from a module, it seems we could benefit from a more generic solution (because this is not just related to the blocking client on authentication module api). each time a module wants to store information on the client context, it can attach it through a separate api and fetch it through another api by client id. this can help avoid having a dictionary mapping inside the module for client id -> private data. this would be useful for both blocking and non blocking scenarios",0,0,0,0.9699921011924744,0.991028606891632,0.9620009660720824,0.0,accept,unanimous_agreement
1125644488,11659,"it could be nice, but if the module needs that for multiple purposes (one for auth, and another for something else), it'll need t manage some struct with all the info it may need for various tasks. instead, letting the module store an additional data when registering a callback (each call back), seems like a standard thing to do, and could be easier for the module to handle (and quicker to figure out how)",0,0,0,0.8651015758514404,0.939888060092926,0.9648968577384948,0.0,accept,unanimous_agreement
1127308119,11659,"i guess i still think i would rather the module be fully explicit here and pass in an object. it seems like that might be more useful for then authentication failure on hello, when it really failed on some module callback.",0,0,0,0.9798190593719482,0.9727319478988647,0.9621458649635316,0.0,accept,unanimous_agreement
1127308727,11659,"if we feel strongly about it, i would rather have a mechanism that applies to both module blocking mechanisms like using an api like karthik suggested. i'm still not really convinced in the use case, it's not that hard to store a separate map with a usedid -> requestid mapping.",0,0,0,0.7406294941902161,0.9609677195549012,0.8467116951942444,0.0,accept,unanimous_agreement
1128645130,11659,i reverted changes to this api here - [a link],0,0,0,0.9857693314552308,0.9703576564788818,0.995512068271637,0.0,accept,unanimous_agreement
1133124634,11659,[code block] to streamline a bit.,0,0,0,0.9873389005661012,0.9897053837776184,0.993239164352417,0.0,accept,unanimous_agreement
1133125831,11659,"this is clunky, and kind of awkward since end modules might actually want to log failures for users that don't exist. i'm not sure if we want to add a new api just for acl errors, that doesn't actually require the user to exist, similar to how we do it internally. thoughts?",-1,-1,-1,0.9676449298858644,0.9801771640777588,0.984652578830719,-1.0,accept,unanimous_agreement
1133125881,11659,this reminds me that we should probably have an api for static lifetime strings so we're not constantly creating them for little stuff like this. maybe i'll go add it to the backlog.,0,0,0,0.8990005850791931,0.9664371609687804,0.972317636013031,0.0,accept,unanimous_agreement
1133134350,11659,fixed here: [a link],0,0,0,0.9866117238998412,0.9899377822875975,0.9952822327613832,0.0,accept,unanimous_agreement
1133134374,11659,fixed here: [a link],0,0,0,0.9866117238998412,0.9899377822875975,0.9952822327613832,0.0,accept,unanimous_agreement
1133134400,11659,fixed here: [a link],0,0,0,0.9866117238998412,0.9899377822875975,0.9952822327613832,0.0,accept,unanimous_agreement
1133134431,11659,fixed here: [a link],0,0,0,0.9866117238998412,0.9899377822875975,0.9952822327613832,0.0,accept,unanimous_agreement
1133167738,11659,"yes. right now, during custom auth, if a module checks the credentials and finds them to be invalid, it still has to create a redismoduleuser just so that it can use the `redismodule_acladdlogentry ` api to add a acl error log entry. this api requires the redismoduleuser to be provided, but internally, it only uses this to obtain the username. instead it could accept the username as a redismodulestring function parameter. [code block] but changing this api will be another breaking change. we could update this api (independently from the custom auth change), to make its module usage easier",0,0,0,0.9683040976524352,0.9864959120750428,0.9807642698287964,0.0,accept,unanimous_agreement
1133196351,11659,"we can't break the api, but i suppose we need to add another one. if we do that, we can consider allowing a null `object`.",0,0,0,0.9857198596000672,0.9737437963485718,0.9888535737991332,0.0,accept,unanimous_agreement
1133196503,11659,"that's a problem since it'll require allocating them on the stack, which would mean that they can't be opaque.",0,0,0,0.922006905078888,0.8575679659843445,0.6260883808135986,0.0,accept,unanimous_agreement
1133330537,11659,"i'm not sure we're talking about exactly the same thing. i was also just thinking about a way to expose redisstrings that have a ""shared"" refcount, so they could be allocated at init and used repeatedly without memory allocations. you can technically do the same thing by repeatedly retaining, as well.",0,0,0,0.9310348033905028,0.8210100531578064,0.9759283661842346,0.0,accept,unanimous_agreement
1133331207,11659,"i'm inclined to just leave it as is, it's a bit clunky, but it's not really that much extra inefficiency.",-1,-1,0,0.9041215777397156,0.8312501311302185,0.7189545035362244,-1.0,accept,majority_agreement
1133332268,11659,"[code block] still going to suggest this naming. do you have any thoughts on this, adding ""custom"" to modules seems redundant.",0,0,0,0.9493230581283568,0.8563439249992371,0.9674884676933287,0.0,accept,unanimous_agreement
1133549428,11659,"i'm not sure i'm an authority on that subject. to me it feels ok, it's not that the module is custom, here, it's that it's a ""custom auth"", i.e. the module is intervening in another mechanism. usually modules register commands, and data types, and configs, all of which only affect the module mechanisms (and the module's commands). so maybe when the module affects redis, auth, file system, compression, network, we can call these custom? i also don't have a problem with your suggestion to drop the ""custom"" part, i don't think it'll cause any confusion if we remove it.",0,0,0,0.8478671908378601,0.9010143876075744,0.7745766639709473,0.0,accept,unanimous_agreement
1135648824,11659,note that an api for adding private data for any blocked client is being added in #11568,0,0,0,0.9885050654411316,0.9924867153167723,0.9922297596931458,0.0,accept,unanimous_agreement
1136533140,11659,added the new api here: [a link],0,0,0,0.9874228239059448,0.975154995918274,0.9955821633338928,0.0,accept,unanimous_agreement
1136576226,11659,i made the renaming change here: [a link],0,0,0,0.986546516418457,0.9754334688186646,0.9955704808235168,0.0,accept,unanimous_agreement
1226050284,11659,"i see a crash in the daily test, maybe someone have the clue to fix it: [a link] [code block]",0,0,0,0.9011550545692444,0.9854472875595092,0.9561139345169068,0.0,accept,unanimous_agreement
719774353,9572,do we want to add an assert here? [code block],0,0,0,0.988888680934906,0.9922322034835817,0.9957550764083862,0.0,accept,unanimous_agreement
724172800,9572,if this is all `lookupkeyreadwithflags()` does then why not chuck it and just call `lookupkey()` instead?,0,0,0,0.9846982359886168,0.990730345249176,0.9891570806503296,0.0,accept,unanimous_agreement
724176138,9572,is this for preserving the original logic? are we sure we don't want to fix the code so we do notify and account stats in all cases regardless of if this is a read/write command? maybe i need some background here. also perhaps just [code block],0,0,0,0.982267439365387,0.9889515042304992,0.9935358762741088,0.0,accept,unanimous_agreement
724177765,9572,see below comment.,0,0,0,0.9814343452453612,0.9848719239234924,0.9933604598045348,0.0,accept,unanimous_agreement
724195215,9572,this is why: [code block],0,0,0,0.9815503358840942,0.990052044391632,0.9945876598358154,0.0,accept,unanimous_agreement
724198161,9572,"yes, it's for preserving the old logic. i used the `readflags` variable to make the code more readable (give the flags a name) and to keep the lines shorter. with your change, it's a very long line.",0,0,0,0.9526524543762208,0.976610541343689,0.9903138279914856,0.0,accept,unanimous_agreement
725597141,9572,can you provide some background explaining the old logic? when do we use `lookupkeyread` vs `lookupkeywrite` in the current approach? when should the different flags be used? or point me to where this has been previously discussed?,0,0,0,0.987821638584137,0.9940451383590698,0.9947803020477296,0.0,accept,unanimous_agreement
725638885,9572,"maybe we should prepend it with `_`, add `internal` suffix, or remove that note about low level (i don't mind anyone calling it directly). however, i don't want to chuck `lookupkeyread[withflags]`, since i don't wanna modify all the lines that call these. let's keep them as wrapper / convenience method.",0,0,0,0.9737048149108888,0.8974950313568115,0.9840993881225586,0.0,accept,unanimous_agreement
725639124,9572,lookup_write is not listed.,0,0,0,0.978873610496521,0.9886925220489502,0.989152193069458,0.0,accept,unanimous_agreement
725639389,9572,"i think that the `nostats` and `nonotify` where both innocent bugs. people added code to lookupkeyreadwithflags and forgot to update lookupkeywrite.. i think we should drop these flags, and modify the top comment of the pr (to state the behavior change). the stats are certainly not a breaking change (just stats). the key-miss notification change should just be reflected in the release notes.",0,0,0,0.9140638709068298,0.8223510980606079,0.9436026811599731,0.0,accept,unanimous_agreement
725639700,9572,"again, i think the flags are a bug due to an innocent mistake",-1,-1,0,0.7727756500244141,0.8331040740013123,0.935369312763214,-1.0,accept,majority_agreement
725640823,9572,"so this assertion will fire if someone calls lookupkeywrite in a read command when that command runs on a read-only replica, right? i'd like to catch these cases, but since we don't have much tests running on a writable replica, i don't think it'll catch them. instead how about just asserting that `c->cmd->flags` has `cmd_write`? (with a proper comment) this will crash a lot sooner if we have such a bug.",0,0,0,0.9368718266487122,0.782609224319458,0.9825579524040222,0.0,accept,unanimous_agreement
725641211,9572,again i think this was a bug due to an innocent mistake and that we should fix the behavior in all these calls and mention it in the release notes.,0,0,0,0.6218797564506531,0.7539137005805969,0.9400293827056884,0.0,accept,unanimous_agreement
725658404,9572,"if we want to make it internal, we can just remove the prototype from server.h. in general, think it's good to expose as little as possible to other modules.",0,0,0,0.955511212348938,0.8881930708885193,0.9805174469947816,0.0,accept,unanimous_agreement
725658622,9572,"so exactly which flags should it be here? lookup_nostats, lookup_nonotify or none?",0,0,0,0.9874217510223388,0.9939836859703064,0.993931531906128,0.0,accept,unanimous_agreement
725659556,9572,"for a cache, you wouldn't want writes to count as cache misses nor hits. i think we'll get complaints if we change this. the typical use case for a cache is 1. lookup for read (`get key`) 2. * if it's a hit, use the value * otherwise, compute the value and store it (e.g. `set key value ex 3600`), and use it if we count cache misses for set, we'd get two misses in this scenario.",0,0,0,0.9781816601753236,0.9763665199279784,0.9543479681015016,0.0,accept,unanimous_agreement
725691266,9572,"thing is that we do expose the flags anyway, so i think the other wrappers are just there for either convenience or in order to avoid messing up existing lines. i don't mind too much either way...",0,0,1,0.8052879571914673,0.5605392456054688,0.5373289585113525,0.0,accept,majority_agreement
725691525,9572,"i think none, i think it could be a plain lookupkeyread. i.e. in the past it was lookupkeywrite because of that mess we clean up (or something that we're still missing). but i'm quite sure the part about stats and key-miss was unintended, so if we fix both we're left with a plain lookupkeyread.",0,0,0,0.9302762746810912,0.9587611556053162,0.9795097708702089,0.0,accept,unanimous_agreement
725692175,9572,"ok, that's a good point, but: first, in that case the source key of sunionstore we do want to count it as a miss, right? i'd argue that for incr we want that too. you have a good point about set, but then i'd say: great, so let's add separate stats, and even notification about write-misses. if we do that, we can simplify things and consider incr a write-miss.",1,1,1,0.8425453901290894,0.8497765064239502,0.8807533979415894,1.0,accept,unanimous_agreement
725927072,9572,"for sunionstore and friends, sure, let's make those plain lookupkeyreads. i'll go ahead and do that. so, just to be clear, do we re-purpose our current hits/misses to be read stats, so we don't break legacy too much, and then we can add write hits/misses later? is that the plan? out of curiosity i looked up memcached (the main inspiration for redis as a cache?). they have separate stats for each command. there's only a handful commands, but still: `delete_hits`, `delete_misses`, `incr_hits`, `incr_misses`, ... (i couldn't find it in the docs but here are the test cases: [a link]",0,0,0,0.9295185804367064,0.9371113181114196,0.9458408951759338,0.0,accept,unanimous_agreement
725964657,9572,"well, i don't think lookupkeyread should be used with the write flag... i'll move all this to the lookupkey top comment.",0,0,0,0.981709897518158,0.9836281538009644,0.9916450381278992,0.0,accept,unanimous_agreement
725982889,9572,"yes, let's have separate read and write hit/misses. i'm on the fence about renaming the old `keyspace_hits` info field to `keyspace_hits_reads` or keep it as is. let's start with the backwards compatible approach and see what feedback we get from the rest of the team. regarding the per-command hits, i'm not sure what it would be used for, i don't think we should get into that in this pr anyway.",0,0,0,0.7713927030563354,0.8339366316795349,0.9707543849945068,0.0,accept,unanimous_agreement
726221249,9572,"i tried adding an assert and it catches some stuff already: * current command can be exec, debug loadaof, eval or evalsha, which don't have the cmd_write flag. it works if we check for these too (four more lines), or we just check for the cmd_readonly flag instead. i did the latter. * lookupkeywrite is called from handleclientsblockedonkeys. here, we don't know if the key is blocked by a read or a write command. xread is readonly for example, so if that's called on a replica, we have a problem. i'm changing this to lookupkeyread. * pfcount does lookupkeywrite, but it's a readonly command. i'm changing it to lookupkeyread.",0,0,0,0.9428309202194214,0.9900887608528136,0.9399914741516112,0.0,accept,unanimous_agreement
726238666,9572,i've added todo comments for write stats in lookupkey.,0,0,0,0.9881693124771118,0.989267349243164,0.995010256767273,0.0,accept,unanimous_agreement
726278607,9572,"considering i had to fix some test modules which marked themselves as ""readonly"" when they were not, we may break some other modules with this pr. something to highlight for the release notes.",0,0,0,0.9838594198226928,0.9475507736206056,0.983226716518402,0.0,accept,unanimous_agreement
726280610,9572,"did you use `c->cmd` or `c->last_cmd`? i don't mind using the readonly flag, but in theory commands that access the keyspace, should have one or the other, not both or none. the commands that'll have none are the ones that you mentioned, as well as ping / client etc, i.e. not touching the keyspace, so i think we better resolve this than switch to the other flag. i'd like to resolve this too (i.e. i want xread to use read, and blpop to use write). maybe we can somehow check which clients are waiting for that key, and look at `c->last_cmd` and decide which lookup to use according to the right flag? i.e. if at least one is a write, we'll use write? pfcount is an odd command, it's marked as read-only but it does modify the key and replicates itself. i'm not yet sure what to do, but let's think of the consequences and not dismiss that just yet.",0,0,0,0.9053719639778136,0.9681025743484496,0.9744160175323486,0.0,accept,unanimous_agreement
726292672,9572,"i used `c->cmd`. what's the difference? for the blocking commands, we can use lookupkeyread with nostats flags to check if the key exists check its type, and delegate to the handler per type. then, there can be another lookupkey depending on command. ok?",0,0,0,0.9873271584510804,0.9936783909797668,0.9864431619644164,0.0,accept,unanimous_agreement
726330263,9572,that may mean that we can't afford to add that assertion. we need to be abi compatible with old modules. maybe exclude module commands from that assertion?,0,0,0,0.9798214435577391,0.911010444164276,0.9902294278144836,0.0,accept,unanimous_agreement
726345898,9572,"iirc `c->cmd` will change inside exec to point to the actual command that's running, and `last_cmd` will remain pointing to exec. `realcmd` (in `call`) will be like `c->cmd` but is not modified when the command gets re-written (like geoadd being redirected to zadd). i think `c->cmd` should have worked correctly for you, please check again. i don't like to do double lookup (efficiency).. maybe we should add another method for just adding stats and call it in these blocked commands processing?",0,-1,0,0.8540164232254028,0.5399572849273682,0.9491621851921082,0.0,accept,majority_agreement
726603534,9572,"ok, thx. so, i can confirm that during exec, `server.current_client->cmd` is the queued command, but when handleclientsblockedonkeys is called afterwards, `server.current_client->cmd` is exec. although the command function (e.g. blockinggenericzpopcommand) is passed a client, lookupkey and expireifneeded aren't. they only have access to `server.current_client`, which is not the same client in this case. a test case which crashes is `""multi/exec is isolated from the point of view of $pop""` in unit/zset.tcl. for eval, the situation is very similar to exec: the current client's cmd is set to eval while the unblocked client is running the blpop command (or similar). one idea is to set `server.current_client` to the client which is being served (running zpopmin, blmove, etc.) so that the assert in expireifneeded works, and change it back to the old current_client (the one which triggered the unblocking using exec or eval) afterwards. it feels like a hack though. for debug loadaof, similarily, maybe it's possible to temporarily set `server.current_client` to the fake client which executes commands from the aof file. setting `current_client` seem like a hack, right? passing the client around to lookupkey and expireifneeded might be a better idea but it's a lot of work to do it everywhere. another option is to just scrap the assert...",0,0,0,0.9810407757759094,0.9843420386314392,0.9674193263053894,0.0,accept,unanimous_agreement
726797070,9572,maybe we should assert here that `lookup_write` is off?,0,0,0,0.9867196679115297,0.9947233200073242,0.9897012710571288,0.0,accept,unanimous_agreement
726800402,9572,"ok, i didn't realize that we're discussing blocked clients here too... but then i don't understand how this is related to exec (blocking commands aren't working in a transaction. correct me if i'm wrong, but it's not just the fact the current_client is not set, and the client is not passed to lookupkey. the problem is that the lookupkey is done before looping on the list of clients that are blocked on that key (so it's one lookup possibly for serving many clients and many different commands). in that case the only way out imho is to tell lookupkey not to record stats, and instead have the individual blocked command handlers update the stats later. please note that in unstable this is already handled (#9422), i think you should update your branch. seems right, please go ahead. yes, the use of globals in redis may be a problem some day, but let's not deal with it now. i think this assert may be very useful, if we write any code that relies on these flags, this assert will give us an indication that we're not introducing bugs.",0,-1,0,0.8190277218818665,0.6464643478393555,0.7022771239280701,0.0,accept,majority_agreement
726818963,9572,"let's start a separate discussion on this one, and the implications of doing lookupkeyread. first, the main difference here is how it behaves when used in a replica on an expired key, right? in the past it would have meant that a user could access an expired key successfully. now after our change, that difference between lookupkeyread and lookupkeywrite is gone (both do expiration check), and the main difference is stats and notifications. the above is true for all the other places we changed between these functions (e.g. sunionstore), but what's special about this command is that it's a readonly command, but it **does** modify the value (and can cause some inconsistency between the master and the replica). but that fact mentioned above is not changed by our pr. so the question is if anyone sees any other special concern about this command in this pr?",0,0,0,0.9766163229942322,0.9885701537132264,0.9642337560653688,0.0,accept,unanimous_agreement
728303346,9572,"i looked up how pfcount works. it is using and updating a cache which is stored in the key, which is also accessible as a string using get and set. i can see ~~two~~ three alternatives: 1. if the cache is invalid, compute the pfcount from the hll but don't update the cache if it's read-only replica (or if writes are forbidden for any other reason, like what?). this might make the hll a bit slow until the master has propagated an updated pfcount cache to the replica. 2. remove the readonly flag from pfcount and mark it as a write command instead. 3. update the cache on read-only replicas anyway. pfcount is not changing the *existence* of a key, which is probably the most important point regarding replication, isn't it? is (1) acceptable?",0,0,0,0.9757401943206788,0.9737197160720824,0.9723188281059264,0.0,accept,unanimous_agreement
728306227,9572,"if you want, but i don't think anyone will pass that by mistake.",0,0,0,0.91011381149292,0.780512273311615,0.9634624123573304,0.0,accept,unanimous_agreement
728372793,9572,"i don't like [1] since it impacts performance and in a transparent way. i could say that i don't care much about writable replicas, but it'll actually impact the read-only ones (the common case). i don't like [2] for the same reason, it'll block this command on read-only replicas, and also some acl use cases. [3] is what we had till now (the command would have modified the db even on read-only replicas or read-only acl user on master), so i think we can accept that. afaict the only thing that changes now is it's behavior around volatile keys on replicas (both read-only and writable replicas), and the hits / misses stats / notifications. with regards to hits / misses, i think it's ok that it'll behave like read-only command (we can say that we're actually fixing a b bug now) with regards to volatile keys on replica: in the past since it used lookupkeywrite (and was allowed on read-only replicas), it would have been able to access expired keys on replicas. and now because of our changes (both using lookupkeyread and our changes in lookupkey), it'll not be able to access volatile keys. am i right? so considering that, i think we can keep your current change, and we need to document the bugfix in the top comment. i.e. other than fixing the fact that writable replicas were able to access expired keys, for pfcount this applies also for read-only replicas.",-1,0,0,0.9534786343574524,0.7525452375411987,0.5130056142807007,0.0,accept,majority_agreement
728474754,9572,"the blocked client (e.g. blpop) is not in a transaction. it's another client which unblocks the blocked client by e.g. rpush in a transaction (exec) or lua (eval). nice! i didn't see that. i will update and then do the same for debug loadaof. (i was just starting to implement a lookupkeyforclient with an extra client parameter, only for use when the client is not the current client. the old lookup functions would remain and use server.current_client as a default. but i didn't get that far.)",1,1,1,0.9556258320808412,0.9797102212905884,0.8828924894332886,1.0,accept,unanimous_agreement
728477741,9572,"ok, sounds good. we'll stick with (3) and i'll see if i can come up with a test case for the bugfix. :-)",1,1,1,0.9859058856964112,0.9914611577987672,0.9946253895759584,1.0,accept,unanimous_agreement
729015050,9572,"done. see updated top comment and commit messages. the assertion now looks like this: [code block] now i can see two risks: 1. modules will break (module write commands without the write flag) 2. this scenario: * (client 1) `blpop k` * (client 2) `eval 'multi; rpush k 42; exec'` -> when blpop is unblocked, `server.in_eval` is 1 and the lua_client's current command is exec, so the assertion might fail. (i'll need a test case to be sure.) (2) can be mitigated by just modifying the assert a little, but (1) is intentional. i think (1) needs to be in the release notes. i had to update many test modules and it may very well happen to real modules out there.",-1,0,0,0.5392442941665649,0.9835749864578248,0.9607794880867004,0.0,accept,majority_agreement
729019757,9572,"i've added a test case. i've also confirmed that it fails without this fix, so you are right, it was using the value of an expired key.",0,0,0,0.9792138934135436,0.980035960674286,0.9923875331878662,0.0,accept,unanimous_agreement
730375749,9572,"i think we have to exempt modules from that assertion. the new redis release needs to be compatible with old modules, we need to consider the implications of modules using the wrong lookup. the main difference in redismodule_write, is that rm_openkey returns a non-null redismodulekey even if the key is not found in redis, in which case `kp->value` will be null. and modules that do that, expect that and could still use rm_moduletypesetvalue and rm_moduletypereplacevalue, and unlike redis (e.g. incrdecrcommand) don't attempt to access the robj directly without checks. so let's try to consider the implications of our change (assuming the assertion is skipped). we moved the expiration attempt from lookupkeyread to lookupkey, so it now affects redismodule_write too. and the difference is only when used on a replica (readonly or writable, since modules could use that on ro commands), when a command is executed from the non-master client. and the implication would be that both before and after our fix, rm_openkey succeeds, however after our fix, any attempt to access the value rm_hashget will fail (only if the key already expired), and in the past it would have succeeded. either way, with or without our fix, rm_moduletypesetvalue and rm_moduletypereplacevalue will succeed and do the same thing. anything i'm missing? regarding blpop, can you please describe the flow in the code itself? afaict `handleclientsblockedonkeys` is only called by `processcommand` so would only be called when eval returns.",0,0,0,0.9445838928222656,0.9879520535469056,0.9771645665168762,0.0,accept,unanimous_agreement
730378392,9572,"maybe the comment needs some representation next to where we do lookupkeyread? (we do have some comment in the command table explaining the flags). in any case, i'd like to extend it to state the considerations and implications that we now discussed. i.e. the command is flagged as read-only, and uses lookupkeyread (which will not let it access an already expired value), but it does mark things to be propagated (as explained in the current comment).",0,0,0,0.986325979232788,0.991800844669342,0.987865388393402,0.0,accept,unanimous_agreement
730378779,9572,don't you need to do that on the master?,0,0,0,0.9844879508018494,0.9906888008117676,0.9928390383720398,0.0,accept,unanimous_agreement
730378928,9572,"same about the writes, don't we need to do them on the master (and then `wait_for_ofs_sync` or something)",0,0,0,0.9885817170143129,0.9924299120903016,0.992216944694519,0.0,accept,unanimous_agreement
730703813,9572,"for the purpose of this test case, i think it doesn't matter, but if you want a less contrived example, i can change it to what you're saying.",0,0,0,0.9655619263648988,0.972518801689148,0.9801895022392272,0.0,accept,unanimous_agreement
730706131,9572,"depends on what you mean by ""need"". i think it works like this (but maybe active expire doesn't run on replicas anyway so this does nothing), but a more realistic scenario is to write on the master, sure.",0,0,0,0.9709941744804382,0.9770111441612244,0.9868842363357544,0.0,accept,unanimous_agreement
731028203,9572,"yes, replicas normally don't do active expire anyway, but indeed there's that odd mechanism for `slavekeyswithexpire`. i don't care to test that crap. i rather test a more realistic scenario. let's move the writes to the master, disable the active expire there, and wait for sync.",-1,-1,-1,0.9354502558708192,0.5254710912704468,0.9127073884010316,-1.0,accept,unanimous_agreement
733962758,9572,done. please have a look.,0,0,1,0.960557460784912,0.8251293897628784,0.6118800640106201,0.0,accept,majority_agreement
733963140,9572,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
733963461,9572,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
733969229,9572,"makes sense. i've added cmd_module to the assert, meaning that all module commands can use lookupkeywrite. technically, we don't need the commit adding the write flag to all the test modules ""fixup: modules test commands marked as readonly"" 068e7a1 and ""add write flag to all test module write commands"" 32a7045. should i revert them? i was wrong here. multi and exec can't be used from within lua scripts, so this can't happen. btw, i'm sorry for the rebase and force-push. it was sort of automatic from my side, since many other projects forbid merge commits. it does make sense if you always make squash commits though. i'll do merge from now on.",-1,-1,-1,0.9888318777084352,0.9861307740211488,0.9198547601699828,-1.0,accept,unanimous_agreement
735127169,9572,"i suppose we should enhance the comment explaining why we exclude modules (so that we don't break old modules). p.s. for some reason i can't respond to the comment in [a link] (please resolve it if all the concerns were addressed). i don't think you should revert these commit. this is the proper way to use the api, and in some cases people may take code from the tests as an example, so it's a good idea to make it ""correct"". maybe add a note on the top comment explaining why you did these changes (at least to make it clear that it's just a cleanup, and not directly needed for the changes in the pr)",0,0,0,0.9346784353256226,0.8922649025917053,0.9644923806190492,0.0,accept,unanimous_agreement
735128149,9572,"we wanna wait for the key to be logically expired. and both servers are on the same clock, why wouldn't `after 10` be enough? if we have to wait longer than 10ms, and we understand why we do, i'd suggest to have some `wait_for_condition` loop (which will usually be faster), rather than a constant sleep. e.g. we can loop until exists return 0",0,0,0,0.979808747768402,0.987500786781311,0.9879955649375916,0.0,accept,unanimous_agreement
735552167,9572,"yeah, i don't know why it failed with `after 10` (clock out of sync?), but i'm adding an `exists` check to the `wait_for_condition` just above.",0,0,0,0.971510112285614,0.9641621708869934,0.9752630591392516,0.0,accept,unanimous_agreement
735577696,9572,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
735616317,9572,"while at it, maybe `lookup_write` should have a more obvious name?",0,0,0,0.985926389694214,0.992238461971283,0.9785330891609192,0.0,accept,unanimous_agreement
735643776,9572,any obvious suggestion?,0,0,0,0.9631270170211792,0.980387270450592,0.9828513860702516,0.0,accept,unanimous_agreement
735648504,9572,"maybe lookup_delete_expired_even_in_replicas? the idea behind the name lookup_write is to indicates the *purpose* of the lookup, that it's a lookup for writing. the *effect* of it (to delete expired keys even in replicas) is to make sure that replicas stay consistent with master as long as they don't do writes, but it could potentially involve other things and the caller doesn't necessarily need to care about that.",0,0,0,0.9705671668052672,0.9938507080078124,0.9914885759353638,0.0,accept,unanimous_agreement
735649988,9572,thanks for reviewing btw!,1,1,1,0.9519378542900084,0.8952240347862244,0.9071072936058044,1.0,accept,unanimous_agreement
735662563,9572,"yes i realize that now, after seeing how it's used everywhere. makes sense! oh, and i should say - thank you for sorting the mess! :grinning_face_with_smiling_eyes:",1,1,1,0.978912889957428,0.9501392245292664,0.9901716113090516,1.0,accept,unanimous_agreement
736339929,9572,"maybe just to make the condition above clear, the failure message should be ""keys didn't replicate or didn't expire"" or alike.",0,0,0,0.982213854789734,0.9860893487930298,0.963290810585022,0.0,accept,unanimous_agreement
736399046,9572,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
741749489,9572,"here the flag with `lookup_write` would cause delete the expired key on replica, but that may lead data inconsistency if the replication delayed, for example: we have a key (e.g. `hash`) with ttl 10, and apply a `hset` command on master, and then before ttl 10 we apply `persist` command on it. but replica receives the `hset` and `persist` after ttl 10, the `lookupkeywrite` would delete the key.",0,0,0,0.984385311603546,0.9926971793174744,0.9873132109642028,0.0,accept,unanimous_agreement
741753516,9572,"i don't like the `lookup_write` and `lookup_noexpire` flag, the `lookup_noexpire` flag is only used in `swapdb`, but i think `scandatabaseforreadylists` has no reason don't delete expired keys in this case. the `lookup_write` is designed for writable-replica which is a mess that doesn't deserve any forward development",-1,-1,-1,0.972861349582672,0.9707263112068176,0.9912093877792358,-1.0,accept,unanimous_agreement
741768375,9572,"one of the purposes of this pr is to solve problems in writable replicas, they're an odd configuration but i think for now we need to keep supporting them (unlike slavekeyswithexpire which i care even less for). i.e. the other purpose of this pr is a cleanup for code that makes more sense. note that lookup_write may have other purposes soon, like updating write hit / miss statistics maybe. i don't recall why we use lookup_noexpire in swapdb, maybe it's just to prevent unintended changes of the refactoring? do you recall? but anyway, i can think of one reason not to expire in this case: it can cause a flood of expiration that will freeze the server and cause replicas to drop.",0,0,0,0.9356349110603333,0.9465603232383728,0.9332955479621888,0.0,accept,unanimous_agreement
741775180,9572,"it was not supposed to do that. either you found an unintended bug, or we're missing something. lookup_write was only supposed to prevent expiration on a replica when the command did not originate from the master client. i.e. since it must be a write command, it's only about writable-replicas. but indeed when looking at the current code i fail to find the place where we make that decision (i.e. look at `server.current_client == server.master` or check the `client_master` flag. are we missing something? if we don't, then i wonder how come the tests didn't find that bug (i'm quite sure we have a test for it)",0,0,0,0.9688590168952942,0.6987059712409973,0.8449657559394836,0.0,accept,unanimous_agreement
741778216,9572,"that's right, noexpire is just to keep the exact same behaviour as before when refactoring. (it's used in a function that calls lookupkey directly, which didn't do expire before. expire was done in lookupkeyread and lookupkeywrite only.) i'm trying now to delete the noexpire flag and run the tests locally. it seems to pass, but i'll run the cluster and module tests too. if it works, we can get rid of this flag.",0,0,0,0.9715135097503662,0.9789513945579528,0.9684475064277648,0.0,accept,unanimous_agreement
741836948,9572,"do you mean when lookupkeywrite is called in during replication? i didn't think about this scenario. i don't know if we have tests for it. i guess it's a race condition which is hard to catch(?). i think what has changed is this line in expireifneeded: [code block] before, replicas never deleted the expired key here and now they do. indeed i think we need to add a check for `server.current_client == server.master` or check the `client_master` flag.",0,0,0,0.9639376997947692,0.867142379283905,0.991101861000061,0.0,accept,unanimous_agreement
741858361,9572,"i have deleted noexpire. the write flag is for writable replicas, it's true. i also don't like them, but if we can't deprecate them, it's better to make them a little more consistent. also, maybe you can accept oran's explanation:",0,0,0,0.9025245904922484,0.7884211540222168,0.8541406989097595,0.0,accept,unanimous_agreement
741872266,9572,"it's a trivial case of incr being executed on a volatile key on the master, and how the replica will handle that command when is propagated to it. the old code had this check `server.current_client != server.master` which prevented the key from being evicted and let the lookup succeed despite being already expired. i didn't notice we lost it, but we must re-add it. the test for it is not too complicated: 1. disable active expire on the master 2. create a volatile key with the value of 1 and expiration of 1 second 3. suspend the replica using sigstop 4. run incr on the master. 5. wait 1 second. 6. unpause the replica 7. wait for replication offset to sync 8. use debug object to check that the key exists, and maybe extend it so we can also make sure it's still volatile. 9. or, instead, promote the replica and use ttl and get to see that it was incremented (value is 2) and volatile.",0,0,0,0.8922634124755859,0.9654389023780824,0.9483822584152222,0.0,accept,unanimous_agreement
741902422,9572,"i have some concern about this change, i'm not certain this behavior of not doing expiration on swapdb wasn't on purpose. in theory, if we would have scanned a lot of keys, we can cause a freeze to the server and blow up the replication buffers with dels.. expiration efforts must be gradual and not all in one go. in practice we only scan keys that some clients are being blocked on, so maybe it's not that many keys. also possibly when we return from the swapdb command, we'll lookup these keys again and expire them anyway, is that right? can you look into that, and maybe also into the blame log and history of swapdb and scandatabaseforreadylists?",-1,0,-1,0.5288532972335815,0.7665516138076782,0.8592703342437744,-1.0,accept,majority_agreement
741902783,9572,"i see you fixed it, but please add that test too (and make sure it fails on the buggy version). thanks.",1,1,1,0.9447911381721495,0.7921652793884277,0.9752893447875975,1.0,accept,unanimous_agreement
742008457,9572,"yes, a useless lookup of the expire dict is the potentially costly part here. we can preserve the old behaviour here if we just lookup the dict manually, without calling lookupkey. with all those flags, the only thing we actually want to do here is look up the dict anyway. i can do that. btw, my plan is to update the 'hasexpire' pr when this one is merged.",0,0,0,0.6298282146453857,0.9746983647346495,0.9626484513282776,0.0,accept,unanimous_agreement
742034088,9572,"you mean that if the key already expired, then this event loop cycle will release it (possibly slow operation for a complex key), and propagate del anyway.. i.e. it'll happen in scandatabaseforreadylists instead of handleclientsblockedonkeys, right? let's add a test for that if there isn't already one. i.e. make sure we have a test for `swapdb that awakes a blocked client`, and also write one for `swapdb that awakes blocked client, but the key already expired`. i suppose that's a good option if we anyway try to avoid all the checks and side-effects of lookupkey. i.e. technically this function isn't done on behalf of a command, it's not really looking up the key but rather checks what's in the dict. so i vote for it. sure, that's the next step (it's the one that has awaken this pr)",0,0,0,0.9812470078468324,0.9869741201400756,0.9834988713264464,0.0,accept,unanimous_agreement
742741306,9572,test added as suggested. i have confirmed that it fails when i comment out the line `if (server.current_client == server.master) return 0;` in expireifneeded.,0,0,0,0.9879818558692932,0.992687463760376,0.994176745414734,0.0,accept,unanimous_agreement
742742969,9572,swapdb tests added. using dictfind instead of lookupkey in scandatabaseforreadylists. i think it's ready to merge unless there is anything else.,0,0,0,0.984193742275238,0.9611075520515442,0.9689468741416932,0.0,accept,unanimous_agreement
742877436,9572,we now have wait_for_ofs_sync,0,0,0,0.9875560402870178,0.9920331835746764,0.9948595762252808,0.0,accept,unanimous_agreement
742880188,9572,let's add a comment here stating that this makes sure the incr arrives to the replica after the key is logically expired,0,0,0,0.988477885723114,0.9918550252914428,0.9949793219566344,0.0,accept,unanimous_agreement
742881365,9572,"i would be nice to add another `wait_for_ofs_sync` after this set. in the past we propagated expire rather than expireat, and in that case the test should have failed to achieve it's purpose.",0,0,0,0.938054084777832,0.9934768080711364,0.9886431097984314,0.0,accept,unanimous_agreement
742884338,9572,"i think the propagation of incr (with the bug) would still mean the key exists. i.e. it would be deleted as expired, and it would create a new non-volatile key with the value of 1. so what i think we should do to verify is disable active expiry on the replica too. then promote it, and use ttl and get to check the value.",0,0,0,0.9858852624893188,0.9891988635063172,0.98688006401062,0.0,accept,unanimous_agreement
742887766,9572,"that select is excessive (for this test), and needed to just to restore the client state for the next state, let's move it to the end and add a comment? also, maybe it'll be nice to explicitly select 9 on the rd",0,0,0,0.9775499105453492,0.9912830591201782,0.9886578917503356,0.0,accept,unanimous_agreement
742890321,9572,we're relying on the timeout.. i don't like it that much. maybe instead add an assertion to confirm the client is still blocked and then client unblock it?,-1,-1,-1,0.9828109741210938,0.9628596901893616,0.9864928126335144,-1.0,accept,unanimous_agreement
742938127,9572,"the line above checks that `exists k` returns 0, which means that the key is expired (which implies that it is (or was) volatile). without the fix in expireifneeded, exists returns 1 here.",0,0,0,0.9891230463981628,0.9947848916053772,0.9943528175354004,0.0,accept,unanimous_agreement
742939026,9572,good point. i'll use that instead.,1,1,1,0.9135515093803406,0.6756584048271179,0.9800955057144164,1.0,accept,unanimous_agreement
742949269,9572,"why would it.. i think the sequence looks like this: 1. the key has a value of 1, and is volatile 2. incr arrives, it detects the key is expired and deletes it. 3. then incr creates a new (non-volatile) key with a value of 1 4. at the end we have a non-volatile key with 1, rather than a volatile key with 2.",0,0,0,0.9745293259620668,0.9829128980636596,0.914125680923462,0.0,accept,unanimous_agreement
743007415,9572,"... because if we have a non-volatile key at the end, the line `assert_equal 0 [$slave exists k]` would fail.",0,0,0,0.9312363862991332,0.9718381762504578,0.9738431572914124,0.0,accept,unanimous_agreement
743010207,9572,"without the check `server.current_client == server.master` in expireifneeded, the sequence is like you described and but then the assert fails because `exists k` returns `1`.",0,0,0,0.9835635423660278,0.9938177466392516,0.9949653744697572,0.0,accept,unanimous_agreement
743010923,9572,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
743082940,9572,"ohh, ok, not because the key is volatile vs non-volatile, but because we know that if it's volatile, it's also already logically expired. and because active expiry is disabled and there are no other activity on the master so it shouldn't send a del, so we can trust that.",0,0,0,0.970852553844452,0.9198237657546996,0.9700417518615724,0.0,accept,unanimous_agreement
743165806,9572,"exactly. focus on ""expired"", not on ""volatile"". i avoided the word ""exists"" in the comments because logically it doesn't exist. but it's still there, in the dict in the replica.",0,0,0,0.9561718106269836,0.9929746389389038,0.991560399532318,0.0,accept,unanimous_agreement
754045250,9572,"only one suggestion: remove the `expire_on_replica` argument, just check if this is a writable-replica in `expireifneeded` by itself, do not let the writable-replica issue pollute the `lookupkeyread/write` function.",0,0,0,0.9875934720039368,0.9944638609886168,0.9902554154396056,0.0,accept,unanimous_agreement
754068088,9572,"i have tried, but if we remove this parameter, we instead need an `is_write` parameter. otherwise we can't easily fulfil the request to keep the expired key on lookup for read.",0,0,0,0.9849778413772584,0.9902344942092896,0.9939028024673462,0.0,accept,unanimous_agreement
756096913,9572,"i think this looks better. i also dislike indenting to a specific offset since it'll need to get adjusted if any other argument is added or the function renamed. so if i had to indent it, i would just indent it by 4 [code block]",-1,0,1,0.8661669492721558,0.5783220529556274,0.7143797278404236,,review,no_majority_disagreement
756102012,9572,"i also feel a bit uncomfortable with the name of this flag. it doesn't really indicate when it is set (for that it should be called `from_write_command`). and it doesn't really indicate what it should trigger (for that maybe we need to call it `delete_key`, and maybe move the checks about the server being a replica of the client being a master to the caller). maybe a better name could be `force_deletion`, or `skip_replica_client_check` to indicate better what it does. what do you think about these suggestions?",-1,-1,-1,0.959379494190216,0.8193307518959045,0.9047407507896424,-1.0,accept,unanimous_agreement
756148389,9572,"sure. i like when lines are not more than 80 so they fit in a half-screen wide editor window on laptop, but sure. without parentheses even better. (i added them just to make automatic indentation work.)",1,0,1,0.7769315242767334,0.718549907207489,0.8073791265487671,1.0,accept,majority_agreement
756173122,9572,"i guess it depends on your laptop 8-). what about screen split to 3? or a 10"" laptop? anyway, jokes aside we don't have a strict limit, each piece should be formatted so that it (and the code surrounding it) is readable. in this case i think the line wrap just make is less readable, but i won't insist on it.",0,0,0,0.5459363460540771,0.7958502173423767,0.9366239309310912,0.0,accept,unanimous_agreement
756187277,9572,"i'll rename it to `force_delete_expired` and move the assert to `lookupkey()`. i agree, the meaning of the parameter is more clear that way.",0,0,0,0.9838083386421204,0.9793939590454102,0.9901633858680724,0.0,accept,unanimous_agreement
756198695,9572,i think parts of that comment you delete are still wanted (good description of the scenario of a del that didn't yet arrive). maybe you can revive that whole block and add the part describing force_delete_expired just below it?,0,0,0,0.9841099381446838,0.9915748238563538,0.9821925759315492,0.0,accept,unanimous_agreement
756212541,9572,"in this case, a line wrap makes it less readable, except if you get a soft line wrap in a different place because of your old school terminal width. ;-) i know there's no strict limit, but i was mislead by how it looks for me. 80x24 is a very old standard for terminals, because it is the same size as two punch cards (80x12). it's the most common according to [a link]. ![a link]",1,1,1,0.9434034824371338,0.9354662299156188,0.9868066906929016,1.0,accept,unanimous_agreement
756222798,9572,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
756617082,9572,"lol that's old. maybe the difference between us is that i don't use word wrapping. if a line is too long (in case i'm using a side by side diff on a small computer), i just let it go out of view, and scroll left if i really need to. the majority of times, when reading the code i need to understand what the code does (which functions it calls), and usually don't care much about the details near the end of the line, so i rather get more lines in my view, and better looking indentation (no word wrapping), than see the entire line. plus, i usually use very large monitors (40"" when docked, and 17"" when not) although i also do much of my work on my ""cosmo communicator"" android phone (6"")",-1,1,1,0.5776684880256653,0.9859321117401124,0.9092004299163818,1.0,accept,majority_agreement
756627014,9572,"yes, turning off line wrapping also works, but it's annoying when you type if it scrolls automatically, it's visually not so nice. in some projects it's just not possible to use a small editor window, but with redis it works well because most of the code is carefully wrapped at 80. if you're interested, nowdays, i use a 15"" monitor (never docked) and emacs with fairly large font size. i rarely read code on the phone. (in a previous project i needed two large monitors for remote desktop environments, test frameworks which opened up 10 small terminals to visualize stuff, large diagrams, etc. but not now.) can you merge this one now so we can forget about writable replicas? :-)",-1,-1,-1,0.9397849440574646,0.9770673513412476,0.9121686816215516,-1.0,accept,unanimous_agreement
765473296,9572,"[a link] the test failed once on my ci (freebsd), looks like was a timing issue. i took a look, here are my thoughts: - the key expired before `incr` was executed, because the execution time of `wait_for_ofs_sync` exceeded one second. (or maybe related the kill). i didn't think of a good way: 1. maybe we can use $slave debug sleep ? (but there are also such problems) 2. add a retry also there was a typo (locigally)",0,0,0,0.6847221255302429,0.9110677242279052,0.9454377293586732,0.0,accept,unanimous_agreement
765654044,9572,"good catch! thanks for looking into it. i don't understand how debug sleep can help...? add a retry, yes i guess it can work. we can double the expire time at every retry, so starting with 1 second, then 2, 4, 8 etc. we can add a check before the first `wait_for_ofs_sync` that k didn't expire and if it did, we retry. wdyt?",1,1,1,0.9917641282081604,0.9908656477928162,0.9960596561431884,1.0,accept,unanimous_agreement
765675891,9572,"oh i mean that maybe we can use debug sleep to replace the kill as for retry. the double is a good idea. maybe we can start from ms, reduce the running time. edit: #11548",1,0,1,0.5788301229476929,0.8741739392280579,0.6517937779426575,1.0,accept,majority_agreement
800179373,9572,this assert assume that opening a key for write can’t be called from a redis command but in redisgraph when a save command end we delete the temporary keys we created during the save process we need to be able to workaround this assertion this crashes redis in our tests stack trace example: [code block],0,0,0,0.9852575659751892,0.9860926270484924,0.9859617352485656,0.0,accept,unanimous_agreement
800180150,9572,"we didn't want to break modules, and assumed that `c->cmd` will be a module command, but with notifications and events, that could be done from other random contexts. iirc this assertion was just there in order to help us find native redis commands that are not flagged correctly. it could have been sufficient to test that we're not on a writable-replica, but we thought that coverage for such a test will be low, and preferred to check our assumption on masters too. as far as i can tell, our options now are: 1. remove that assert completely (as was argued before, right?) 2. make it run only on writable replicas 2. find another way to exclude modules please share your thoughts, and remind me what i forgot.",0,0,0,0.9586076736450196,0.9812794923782348,0.9722306132316588,0.0,accept,unanimous_agreement
800237704,9572,"just to be sure i understand what's happening: is the `rm_openkey` triggered by something other than a module command, e.g. a keyspace notification or event, which is fired after some real command (save) has executed? or before? if that's the case, can we set `c->cmd` to null before the firing the event? if we do, then this code will not appear to be part of any command, which i think is better than appearing as being run as part of some read-only command. another question: can this ever happen on a readonly replica? if yes, then perhaps we should set `force_delete_expired` to false here if we're on a read-only replica to keep it consistent with its primary, rather than only bypassing the assert. if we do, then i guess we can drop the assert entirely.",0,0,0,0.9529783129692078,0.989001989364624,0.973666250705719,0.0,accept,unanimous_agreement
800364704,9572,"from what i know of redisgraph, when this code happens on a replica, should always be in a fork child, but it could still be from within a command. i.e. when a sync command is received and triggers an immediate fork, the fork child process will have `c->cmd` still set on the stack. what i don't like about nullifying `c->cmd` in the various event dispatches in module.c is that it's very far from the assertion. i.e. we'll have to backup, nullify, and restore `c->cmd` and add some comments explaining that it's done to avoid an assertion on the other side of town.",-1,0,-1,0.7268838882446289,0.5872865915298462,0.5499882102012634,-1.0,accept,majority_agreement
800380919,9572,agree. this assert looks at things far away too... i think we can remove the assertion and never set `force_delete_expired` on a writable replica: [code block],0,0,0,0.9744165539741516,0.9805394411087036,0.9722904562950134,0.0,accept,unanimous_agreement
800383768,9572,please make a pr.,0,0,0,0.9775705337524414,0.9767104983329772,0.9925699830055236,0.0,accept,unanimous_agreement
1921617777,13740,not sure what sentinel flag means but i am pretty sure we do not need it here.,0,0,0,0.8290460705757141,0.8043038845062256,0.7592606544494629,0.0,accept,unanimous_agreement
1921618059,13740,"wonder why we did not do the same trick with `no-monitor` and `no-slowlog`. i believe we should at least be consistent. i you ask me, it is better to check for the internal flag where we check the `cmd_noscript` other then explicitly add flags to the command. it should not be a lot of places.",0,0,0,0.9299821257591248,0.943092405796051,0.9424304962158204,0.0,accept,unanimous_agreement
1921618214,13740,maybe this comment should go to the `c` flag section?,0,0,0,0.987799882888794,0.9944851994514464,0.9881051778793336,0.0,accept,unanimous_agreement
1921618423,13740,no need to free `msg`?,0,0,0,0.9878751635551452,0.9918279647827148,0.9955137372016908,0.0,accept,unanimous_agreement
1921618844,13740,"i would say that the user must provide `len`, otherwise how would he know the size of the secret (we do not promise it is a c string right)? if so maybe we should assert `len != null`",0,0,0,0.9813326597213744,0.9928666353225708,0.9927767515182496,0.0,accept,unanimous_agreement
1921619061,13740,lets make sure this has the exact same format as the unknown command message above.,0,0,0,0.9876883625984192,0.9907744526863098,0.9912749528884888,0.0,accept,unanimous_agreement
1921619394,13740,lets add a comment here as well that module should not expose the internal secret and that this is for testing purposes only.,0,0,0,0.9863561391830444,0.993084192276001,0.9946916699409484,0.0,accept,unanimous_agreement
1921619576,13740,"this function and the one above are almost the same, should we unified them?",0,0,0,0.9850305914878844,0.9906418919563292,0.9933844208717346,0.0,accept,unanimous_agreement
1921619626,13740,lets use threadsafecontext,0,0,0,0.9883520007133484,0.989634931087494,0.994312047958374,0.0,accept,unanimous_agreement
1921619763,13740,"same comment as above, lets unified.",0,0,0,0.9787720441818236,0.9860053062438964,0.993205189704895,0.0,accept,unanimous_agreement
1921818286,13740,"it means that the command exists in sentinel mode. not sure we need it, but took inspiration from the `auth.json` command definition.",0,0,0,0.9883201122283936,0.9888442158699036,0.9917398691177368,0.0,accept,unanimous_agreement
1921820504,13740,"we decided to start off with statistics being reported for internal commands, e.g., monitor and slow-log. yes it's not a lot of places, i can modify the conditions explicitly, although i think this is cleaner.",0,0,0,0.9716711640357972,0.9729605317115784,0.965321958065033,0.0,accept,unanimous_agreement
1921834109,13740,"no, it is free'd automatically later (registered via `automemoryadd()` in `cleanup`).",0,0,0,0.9886853694915771,0.9929924011230468,0.99318128824234,0.0,accept,unanimous_agreement
1921843917,13740,"agree, i'll add an assertion",0,0,0,0.9839012026786804,0.974489152431488,0.9899362325668336,0.0,accept,unanimous_agreement
1921847504,13740,"it indeed is, verified locally as well.",0,0,0,0.983456552028656,0.9855027198791504,0.989488422870636,0.0,accept,unanimous_agreement
1921872557,13740,"without blocking the client, isn't it the same (even should use detached)?",0,0,0,0.9799663424491882,0.9887702465057372,0.9910047054290771,0.0,accept,unanimous_agreement
1922354008,13740,no need for this command on sentinel.,0,0,0,0.9830551147460938,0.9869644045829772,0.992457628250122,0.0,accept,unanimous_agreement
1922354768,13740,i think that it should not be hard to support slow-log and monitor.,0,0,0,0.9656561613082886,0.8999789953231812,0.9754904508590698,0.0,accept,unanimous_agreement
1922356546,13740,"so where are the `with args beginning with:`? not sure it is that critical, but still.",0,0,0,0.9350207448005676,0.9588285684585572,0.9777211546897888,0.0,accept,unanimous_agreement
1922358053,13740,detached context should only be created at the module initialization. even if it is the same it might break in the future so lets use it correctly.,0,0,0,0.9805580973625184,0.9923725128173828,0.9915114045143129,0.0,accept,unanimous_agreement
1922362245,13740,lets user `redismodule_stringtolonglong`,0,0,0,0.9861131310462952,0.9936701059341432,0.994320273399353,0.0,accept,unanimous_agreement
1922365574,13740,"maybe we should name those modes to make it more readable. or alternatively, keep the 3 different commands and use the mode internally to call the shared code?",0,0,0,0.9866408705711364,0.9942060708999634,0.9894775748252868,0.0,accept,unanimous_agreement
1922418323,13740,what do you mean support? remove the internal commands from there?,0,0,0,0.9869832992553712,0.988553524017334,0.9911454319953918,0.0,accept,unanimous_agreement
1922468424,13740,didn't think it was critical as well. added.,0,0,0,0.8973225355148315,0.7153178453445435,0.9605125784873962,0.0,accept,unanimous_agreement
1922479058,13740,yeah i can keep the three commands and route internally,0,0,0,0.9849627017974854,0.9737507104873656,0.9918093085289,0.0,accept,unanimous_agreement
1923164112,13740,"a static temporary secret, to be changed to the actual secret once it is added to the cluster (before merging of course).",0,0,0,0.987060546875,0.9937294721603394,0.9876403212547302,0.0,accept,unanimous_agreement
1925718055,13740,yes,0,0,0,0.9564858078956604,0.9659429788589478,0.9686408638954164,0.0,accept,unanimous_agreement
1929677123,13740,"is it feasible to only gossip the mini secret? here we just want to reach an agreement on the secret, every node just learn the mini secret and set the secret as its own, even just gossip its own secret, this way may converge quickly and reduce ping message size. do i miss something?",0,0,0,0.9136084914207458,0.9789419174194336,0.976815104484558,0.0,accept,unanimous_agreement
1929968675,13740,is it necessary? i saw you define arity 2 in internalauth command json,0,0,0,0.9887596368789672,0.9932170510292052,0.9957987666130066,0.0,accept,unanimous_agreement
1929969292,13740,"please use redis comment style, `/**/` instead of `//` and bellow",0,0,0,0.987478494644165,0.9948636889457704,0.9942514896392822,0.0,accept,unanimous_agreement
1929972660,13740,"for the file name, the command name is `internalauth`, so the file name should be internalauth.json instead of internal-auth.json, we use `-` to concatenate the command and subcommand",0,0,0,0.9876232147216796,0.9945993423461914,0.9948575496673584,0.0,accept,unanimous_agreement
1929980535,13740,promote-internal-conn? is it more clear?,0,0,0,0.9856542944908142,0.9909523725509644,0.9938364624977112,0.0,accept,unanimous_agreement
1930057534,13740,"how about shouldreplyinternalcommand? i think you want to judge if the internal command can be replied, right?",0,0,0,0.9854652285575868,0.987881064414978,0.9936580061912536,0.0,accept,unanimous_agreement
1930083860,13740,what aboult `command only available on cluster instances`?,0,0,0,0.9843623638153076,0.9864697456359864,0.9917770624160768,0.0,accept,unanimous_agreement
1930116540,13740,[code block] maybe more blank space will be better,0,0,0,0.9768962264060974,0.9903289079666138,0.9836607575416564,0.0,accept,unanimous_agreement
1930155201,13740,"i think that what you are suggesting has a potential of never converge. if, for example, node 1 secret x then get secret y from node 2 and embrace it. in this time node 2 gets secret x from node 1 and embrace it. they can continue exchanging secrets this way forever. maybe i misunderstood your suggestion but i believe that if eventually everyone sees everyone internal secrets then it is promised that eventually everyone will chose the same secret (the minimal one).",0,0,0,0.6997326612472534,0.8881636261940002,0.9049475789070128,0.0,accept,unanimous_agreement
1930191199,13740,"the node will only embrace the secrets smaller than yourself for example, node 1 has 000xxx001, node2 has 000xxx002, node3 has 000xxx003. when node 3 gets the secret from node2, it will update its secret to 000xxx002. if node 1 gets the secret from node2, it will reject since the secret is bigger than its. but node 2 gets the secret from node1, it will update its secret to 000xxx001, finally, they will have the same secret, right? that is, each node will only gossip the secret it considers the smallest. and when calling `clustergetsecret`, just read its own secret instead of comparing all nodes'",0,0,0,0.9353700280189514,0.978413701057434,0.97222101688385,0.0,accept,unanimous_agreement
1930255241,13740,the only downside i see with this approach it that it might take longer to converge because anyone just tell about himself and not telling what he knows about the others. notice that not all the nodes talks to all the nodes all the time.,0,0,0,0.9458608627319336,0.9145780801773072,0.9398640394210817,0.0,accept,unanimous_agreement
1930261281,13740,lets continue the discussion here: [a link],0,0,0,0.9845566749572754,0.9826425313949584,0.9935850501060486,0.0,accept,unanimous_agreement
1930604195,13740,"no, you're right, fixed.",0,0,0,0.967992663383484,0.653239905834198,0.9354516267776488,0.0,accept,unanimous_agreement
1930763657,13740,"fixed, thanks.",1,1,1,0.7894600033760071,0.8161105513572693,0.623163640499115,1.0,accept,unanimous_agreement
1930765185,13740,"np, modified.",0,0,0,0.9848830103874208,0.963934063911438,0.9930651187896729,0.0,accept,unanimous_agreement
1930771567,13740,"i guess it's a bit clearer, how about `promote-conn-internal`?",0,0,0,0.9801945686340332,0.971701979637146,0.9863515496253968,0.0,accept,unanimous_agreement
1930795308,13740,"the thing is, that this command is not necessarily internal, so i was aiming for something like ""do i want to reply the command, internal-wise"". i'll fix the comment above to `returns true if the command is not internal, or the connection is internal.`.",0,0,0,0.9761980175971984,0.9822918176651,0.9904558062553406,0.0,accept,unanimous_agreement
1930808675,13740,"i actually prefer the negative way a bit. will look for other such errors that we can take inspiration from, and maintain consistency.",0,0,0,0.7837048172950745,0.8773438930511475,0.8053886294364929,0.0,accept,unanimous_agreement
1931136402,13740,"since i am now using this for monitor filtering, i changed it to `commandaccessibleforclient`, how does that sound?",0,0,0,0.9534730315208436,0.9900333285331726,0.9942796230316162,0.0,accept,unanimous_agreement
1933343026,13740,let's avoid unnecessary changes to files this pr doesn't change,0,0,0,0.9703105092048644,0.954301416873932,0.985695779323578,0.0,accept,unanimous_agreement
1933344088,13740,"we agreed not to add any new command. instead use `auth ""internal connection"" ` since acl users aren't allowed to use spaces, this won't collide with anything""",0,0,0,0.9862822890281676,0.9888942837715148,0.995461642742157,0.0,accept,unanimous_agreement
1933345401,13740,redis uses block comments (not `//`),0,0,0,0.9884312152862548,0.9914293885231018,0.9917423725128174,0.0,accept,unanimous_agreement
1933346449,13740,use block comment. and in other places below.,0,0,0,0.9870284795761108,0.9927727580070496,0.9829952120780944,0.0,accept,unanimous_agreement
1933348161,13740,i didn't see this flag being documented (in the module api docs),0,0,0,0.9873992204666138,0.9833942651748656,0.9737282991409302,0.0,accept,unanimous_agreement
1933349310,13740,you mean: ``` /* check if the command is an internal command (we already know the client isn't an internal connection) */,0,0,0,0.9857080578804016,0.9937022924423218,0.9930785298347472,0.0,accept,unanimous_agreement
1933354590,13740,revert the changes to this file when changing to use auth,0,0,0,0.979116141796112,0.9928748607635498,0.9948904514312744,0.0,accept,unanimous_agreement
1933355031,13740,let's beef up this documentation to explain this feature a little bit more,0,0,0,0.9767167568206788,0.9687072038650512,0.9904757142066956,0.0,accept,unanimous_agreement
1933356502,13740,"maybe ""visible"" or ""exposed"" instead of ""accessible""? we're using this in command and monitor, right?",0,0,0,0.985773265361786,0.9947787523269652,0.98635071516037,0.0,accept,unanimous_agreement
1933386942,13740,we need to patch commandcountcommand too,0,0,0,0.988062620162964,0.9933465719223022,0.994830310344696,0.0,accept,unanimous_agreement
1933390616,13740,"maybe it's a better idea to do this: 1. move the check for internal connections to right after the call to lookupcommand, and just nullify the command if it isn't exposed to the connectoin. 2. patch aclcheckallusercommandperm to return without a check for internal connections i think this can simplify both rm_call and processcommand",0,0,0,0.9424594044685364,0.993311047554016,0.9736933708190918,0.0,accept,unanimous_agreement
1933391872,13740,maybe we want to add a flag in client list?,0,0,0,0.987559735774994,0.9944003224372864,0.992813527584076,0.0,accept,unanimous_agreement
1933480091,13740,"ok, returned",0,0,0,0.9817333221435548,0.9610097408294678,0.9908938407897948,0.0,accept,unanimous_agreement
1933561832,13740,adopted,0,0,0,0.975535213947296,0.9044428467750548,0.9695111513137816,0.0,accept,unanimous_agreement
1933607944,13740,"that makes sense, but we wanted the internal command validation to be conducted only when the `c` flag is used, and to succeed otherwise. do you think the validation should always take place, regardless of the `c` flag?",0,0,0,0.9871811270713806,0.9922466278076172,0.991816222667694,0.0,accept,unanimous_agreement
1933610992,13740,"ok if this is agreed upon, i will make the changes.",0,0,0,0.9827089309692384,0.9698870182037354,0.9908764958381652,0.0,accept,unanimous_agreement
1933632163,13740,"added documentation here below (line 1239), was that your meaning or is there somewhere else?",0,0,0,0.987600803375244,0.9940137267112732,0.9951736330986024,0.0,accept,unanimous_agreement
1933755408,13740,"regarding the usage - yes. bought ""visible"" :thumbs_up:",0,0,1,0.914758801460266,0.7361980676651001,0.9893779158592224,0.0,accept,majority_agreement
1933759399,13740,"ok, will modify it to loop over the commands and count internal ones for internal connections only as well.",0,0,0,0.9884949326515198,0.9909796714782716,0.9934871196746826,0.0,accept,unanimous_agreement
1933784128,13740,i don't see it. it should be above `rm_createcommand` (where `allow-busy` is documented),0,0,0,0.9807733297348022,0.9892205595970154,0.9320851564407348,0.0,accept,unanimous_agreement
1933785633,13740,"note that in rl's fork there's a refactoring around this (for command, command count, and command info). maybe copy that refactoring here now. (will reduce future conflicts)",0,0,0,0.9858928322792052,0.9943528175354004,0.9936364889144896,0.0,accept,unanimous_agreement
1933800215,13740,looks good,1,1,1,0.9521219730377196,0.9680178165435792,0.8849130272865295,1.0,accept,unanimous_agreement
1933808099,13740,"i see what you discussed with oran, new name sounds good",1,1,1,0.9527130722999572,0.9493040442466736,0.7354045510292053,1.0,accept,unanimous_agreement
1933848821,13740,"yup, added there",0,0,0,0.9380340576171876,0.8800450563430786,0.9902731776237488,0.0,accept,unanimous_agreement
1934065062,13740,"for `processcommand` i need to keep it separate, to address the case of `client_reprocessing_command`",0,0,0,0.9876454472541808,0.9936257600784302,0.9946112632751464,0.0,accept,unanimous_agreement
1934118538,13740,"are you sure? if it failed the internal connection test, it won't get to re-process the command",0,0,0,0.9846717715263368,0.9829736948013306,0.9926498532295228,0.0,accept,unanimous_agreement
1934135040,13740,the command lookup occurs in the `!client_reprocessing_command` bracket. we would need to have two conditions if we want to put it there,0,0,0,0.9868263006210328,0.9934845566749572,0.9950053095817566,0.0,accept,unanimous_agreement
1934201850,13740,reverted,0,0,0,0.9771652221679688,0.9411051869392396,0.976313292980194,0.0,accept,unanimous_agreement
1934241176,13740,added the unified version from rl,0,0,0,0.9828552007675172,0.992192566394806,0.9948329925537108,0.0,accept,unanimous_agreement
1934286614,13740,"good idea, added thanks",1,1,1,0.9797662496566772,0.9884724020957948,0.99273419380188,1.0,accept,unanimous_agreement
1934442577,13740,i think we need to use time_independent_strcmp. to protect from brute force attacks,0,0,0,0.9799134731292723,0.974835216999054,0.9839445948600768,0.0,accept,unanimous_agreement
1934445663,13740,in oss these redis instances are called nodes [code block],0,0,0,0.98845636844635,0.99441659450531,0.995337963104248,0.0,accept,unanimous_agreement
1934453437,13740,"maybe ""promote"" is not the right term. it's true that internal connection has more capabilities than normal connections, but maybe i'll some day have other capabilities, like being hidden from client list. let's call it ""mark-internal-client""",0,0,0,0.9401515126228333,0.9830368161201476,0.9667011499404908,0.0,accept,unanimous_agreement
1934454113,13740,maybe it can also take an integer and be able to remove the flag?,0,0,0,0.987000584602356,0.993947982788086,0.9915927648544312,0.0,accept,unanimous_agreement
1934465572,13740,reverting unnecessary leftover change [code block],0,0,0,0.965925395488739,0.9871984124183656,0.9873759746551514,0.0,accept,unanimous_agreement
1934468306,13740,multi-line ifs have brackets in a separate line [code block],0,0,0,0.9874048829078674,0.993375837802887,0.9950841069221495,0.0,accept,unanimous_agreement
1934469227,13740,let's add a comment above this block,0,0,0,0.986071527004242,0.9820735454559326,0.9948392510414124,0.0,accept,unanimous_agreement
1934470759,13740,aren't we colliding with the flag above? i.e. this needs to be 52,0,0,0,0.9691380262374878,0.9905607104301452,0.9920212626457214,0.0,accept,unanimous_agreement
1935111094,13740,we are :disappointed_face: fixed thanks.,1,1,-1,0.3887975215911865,0.9690657258033752,0.996094286441803,1.0,accept,majority_agreement
1935132052,13740,"good idea, how about an optional argument ""unmark""?",1,1,1,0.704749345779419,0.8227546215057373,0.8909340500831604,1.0,accept,unanimous_agreement
1935149842,13740,"great, thanks.",1,1,1,0.9771390557289124,0.9874780178070068,0.9829909801483154,1.0,accept,unanimous_agreement
1935209542,13740,"in debug command we don't have to keep to any standards, and we can even change things and it won't be considered a breaking change, so you can do whatever you want. i think the easiest is to follow the convention of `set-active-expire` and just take an integer.",0,0,0,0.9761025905609132,0.9704976677894592,0.981445610523224,0.0,accept,unanimous_agreement
1935304154,13740,"i don't think anyone needs it, but i suppose it won't hurt.",0,0,0,0.8911126255989075,0.6834632754325867,0.8772700428962708,0.0,accept,unanimous_agreement
1935309124,13740,"you described the condition, but let's describe the action. i.e. nullify the command so that it'll be rejected like an unknown command will.",0,0,0,0.9815515875816344,0.9854229688644408,0.9922996163368224,0.0,accept,unanimous_agreement
1935310711,13740,why did you do that? i think all he callers of that function expect to get client_type_normal,0,0,0,0.9587966799736024,0.96648770570755,0.991032063961029,0.0,accept,unanimous_agreement
1935312907,13740,"again, why do we need it?",0,0,0,0.9650453925132751,0.968921422958374,0.9246471524238586,0.0,accept,unanimous_agreement
1935317797,13740,sorry these changes were supposed to be removed.,-1,-1,-1,0.986333668231964,0.9877481460571288,0.9925151467323304,-1.0,accept,unanimous_agreement
1935317998,13740,same as above.,0,0,0,0.9746477603912354,0.9857698678970336,0.9922299981117249,0.0,accept,unanimous_agreement
1935355382,13740,"redis doesn't use stdbool, please remove.",0,0,0,0.9844851493835448,0.9847716689109802,0.9879522919654846,0.0,accept,unanimous_agreement
1935360786,13740,also don't need it anymore..,0,0,0,0.5957561135292053,0.974120318889618,0.9621898531913756,0.0,accept,unanimous_agreement
1939050410,13740,"test are not really testing what it should, it fails on running `internalauth.internal_rmcall_detachedcontext` because it is, by itself, internal",0,0,0,0.9272966384887696,0.977038323879242,0.9821832180023192,0.0,accept,unanimous_agreement
1939051961,13740,also add a test and none internal command that runs rm_call with internal command succeed (if used without the `c` flag).,0,0,0,0.9884926676750184,0.9944875836372375,0.9955922961235046,0.0,accept,unanimous_agreement
1939054336,13740,not sure what you are testing here? that the eval command are shown in the monitor?,0,0,0,0.9585101008415222,0.9819642305374146,0.9864104390144348,0.0,accept,unanimous_agreement
1939066443,13740,i do not think you need redis cluster for this test right?,0,0,0,0.9748674035072328,0.9093974828720092,0.991835594177246,0.0,accept,unanimous_agreement
1939069956,13740,will remove,0,0,0,0.9818933010101318,0.9702575206756592,0.9864876866340636,0.0,accept,unanimous_agreement
1939070473,13740,let authenticate as internal connection and make sure that the internal command are not shown even when the command succeed.,0,0,0,0.9851657748222352,0.9816567301750184,0.994131863117218,0.0,accept,unanimous_agreement
1939079541,13740,i am missing your you create the monitor connection internal? also not sure how come this test passes and the first test (`internal commands are not reported in the monitor output for non-internal connections`) also pass.,0,0,0,0.7675928473472595,0.9404680132865906,0.930263340473175,0.0,accept,unanimous_agreement
1939087450,13740,"we should probably do it now via an internal connection, we are still internal client from the test above this.",0,0,0,0.9863048791885376,0.9917717576026917,0.9925388693809508,0.0,accept,unanimous_agreement
1939089644,13740,"lets also not do it from internal connection, just to make sure.",0,0,0,0.9533233046531676,0.983217477798462,0.9894128441810608,0.0,accept,unanimous_agreement
1939090135,13740,i believe you do not need cluster deployment for those tests.,0,0,0,0.9072092175483704,0.9702157974243164,0.9874845147132874,0.0,accept,unanimous_agreement
1939091035,13740,i believe we do not need cluster for this test.,0,0,0,0.849727988243103,0.9605756402015686,0.9832153916358948,0.0,accept,unanimous_agreement
1940038795,13740,"i need the internal connection, can also be reached via a debug command but the regular flow is in cluster mode",0,0,0,0.9872755408287048,0.9878929257392884,0.9916715025901794,0.0,accept,unanimous_agreement
1940041086,13740,"mainly for the regular internal connection authentication flow, otherwise can be reached via the non-standard debug command. any reason not to use a cluster and the regular flow?",0,0,0,0.9880101084709167,0.9815745949745178,0.99425607919693,0.0,accept,unanimous_agreement
1940045068,13740,"right, this is a bug. thanks",1,-1,1,0.9270366430282592,0.8808586597442627,0.9724950194358826,1.0,accept,majority_agreement
1940052592,13740,not sure i follow your meaning of doing it now via an internal connection. i can switch to a non-internal connection so that we make sure we get this there as well,0,0,0,0.925528883934021,0.9657121896743774,0.9134331345558168,0.0,accept,unanimous_agreement
1940053384,13740,sure,0,0,0,0.9371067881584167,0.9137381911277772,0.9422702193260192,0.0,accept,unanimous_agreement
1940057122,13740,this is actually a duplicate of a test above - removing.,0,0,0,0.9837030172348022,0.9881503582000732,0.9934670329093932,0.0,accept,unanimous_agreement
1940696713,13740,this is not actually replicating no? it is not using `!`.,0,0,0,0.6997182369232178,0.8798315525054932,0.8742535710334778,0.0,accept,unanimous_agreement
1940701852,13740,why you need cluster here?,0,0,0,0.9811999201774596,0.9827460050582886,0.9865381717681884,0.0,accept,unanimous_agreement
1940702279,13740,"yeah i call `redismodule_replicateverbatim` later on. i can switch that with the `!` in the rm_call, makes more sense.",0,0,0,0.9848504066467284,0.9923203587532043,0.9891828894615172,0.0,accept,unanimous_agreement
1940704186,13740,"it will be faster to deploy, i believe we better use this and just promote the connection with debug command. also simplify the test.",0,0,0,0.9067702889442444,0.9281916618347168,0.9730343818664552,0.0,accept,unanimous_agreement
1940705608,13740,so the command still fails here no?,0,0,0,0.946198582649231,0.9687619805336,0.9887961149215698,0.0,accept,unanimous_agreement
1940707999,13740,ohh ok it is down bellow :+1:,-1,1,1,0.3617680370807647,0.9852389097213744,0.9881439805030824,1.0,accept,majority_agreement
1940711653,13740,yes this is what i meant.,0,0,0,0.9609695672988892,0.9734668135643004,0.9852104783058168,0.0,accept,unanimous_agreement
1940712923,13740,i don't. changed to standalone.,0,0,0,0.8355945348739624,0.9529936909675598,0.9711535573005676,0.0,accept,unanimous_agreement
1940714095,13740,"ok, lets keep it so we also check the `auth` command flow.",0,0,0,0.9880117177963256,0.9911250472068788,0.9945291876792908,0.0,accept,unanimous_agreement
1940716329,13740,"ok, i can change to use a standalone server",0,0,0,0.985526204109192,0.9848506450653076,0.9937637448310852,0.0,accept,unanimous_agreement
1943885772,13740,"-mon the size of `flags` is 17, now `p` might be out of this range. this one was discovered by coverity.",0,0,0,0.9835577607154846,0.992032825946808,0.985602855682373,0.0,accept,unanimous_agreement
1944165138,13740,"this was known in development time, preferred we don't update the size of the flags, as some of them do not coexist.",0,0,0,0.9862375259399414,0.9920960664749146,0.9933606386184692,0.0,accept,unanimous_agreement
760958693,9872,should we update this comment? with default configs (i.e server.shutdown_timeout=10) three ctrl+c is now needed to quit asap without waiting for disk writings (unless i have missed something..) it looks like the second ctrl+c will now trigger a call to finishshutdown() which does aof and rdb file writings.,0,0,0,0.9843494296073914,0.9930419921875,0.9940457344055176,0.0,accept,unanimous_agreement
761036972,9872,"you're right. it's good that you highlight this. i don't know if we need this or if it's enough to just exit(1) on the second ctrl+c. the downside is that if we're waiting for replicas and exit, we don't even try to write the rdb file, but if you press ctrl+c twice, i guess you can live with data loss either way. any strong opinions?",1,1,1,0.8300821185112,0.937128245830536,0.9418335556983948,1.0,accept,unanimous_agreement
763972458,9872,"thinking out loud here, maybe it's better to reply ok, and let that client (and others) monitor the shudown, instead of blocking it? i.e. i imagine we better add some info field that they can monitor, or even decide to respond to ping with some shuttingdown message? on the other hand, doing this would be somewhat of a breaking change, since the docs mention this command never replies when it succeeds..",0,0,0,0.8876795172691345,0.8688169121742249,0.9249523878097534,0.0,accept,unanimous_agreement
763972481,9872,"maybe we want to add a `now` flag to allow bypassing this instead of requiring a config before shutdown? it reminds me of the case shutdown is refused because we're generating the initial aof, where there are cases (in the test suite) in which we have to do `config set appendonly no` before terminating an instance to guarantee compliance",0,0,0,0.9804208278656006,0.9932403564453124,0.9865168333053588,0.0,accept,unanimous_agreement
763975607,9872,i think we may want to indicate these in info,0,0,0,0.9864377975463868,0.9566186666488647,0.9911694526672364,0.0,accept,unanimous_agreement
764666452,9872,"why should we pause clients with a timeout (the pause has timeout)? when the shutdown timer expires, we'll exit. so in what case do we want to let clients write again after shutdown was initiated?",0,0,0,0.9788118004798888,0.9622558951377868,0.9919552206993104,0.0,accept,unanimous_agreement
764753223,9872,"i'm guessing we don't care. i.e. if the timeout is long enough (or even with the default of 10 seconds), maybe a replica that just connected, will succeed in getting a full sync in time. we can let it try and abort if it doesn't make it.",0,0,0,0.5067377090454102,0.9492514133453368,0.9586912393569946,0.0,accept,unanimous_agreement
764757518,9872,"can't you use a slow ""initial"" aofrw for your test?",0,0,0,0.9853096604347228,0.9845300912857056,0.9876788258552552,0.0,accept,unanimous_agreement
764759030,9872,"in the past, we didn't reset this, and would have kept trying to shutdown endlessly (or until success), right? maybe we don't wanna change that behavior?",0,0,0,0.8278211951255798,0.9277799725532532,0.9171413779258728,0.0,accept,unanimous_agreement
764760554,9872,i think i rather not modify all these lines,0,0,0,0.9662572741508484,0.8195816278457642,0.9413271546363832,0.0,accept,unanimous_agreement
764762454,9872,why not 0?,0,0,0,0.9567375779151917,0.9650174379348756,0.975656509399414,0.0,accept,unanimous_agreement
764763653,9872,"you probably want to set this config before calling replicaof, but actually, why do we want this test to insist on diskless replication? let's let it use the default. (same for the master)",0,0,0,0.984977960586548,0.9919722080230712,0.991975486278534,0.0,accept,unanimous_agreement
764765055,9872,"i'd rather not have an inherent delay of 1 second. maybe instead we can check the master is still responding (get command and info command) maybe in addition to that, set the cron hz to a high number, and have an `after` of 2 cron intervals?",0,0,0,0.9845081567764282,0.9893873929977416,0.984849452972412,0.0,accept,unanimous_agreement
764766911,9872,let's see if we can make this test faster. we already know (from the previous test) that the master waits for the replica (or at least that it still runs the event loop and responds to clients),0,0,0,0.985392153263092,0.984140396118164,0.9867114424705504,0.0,accept,unanimous_agreement
764768322,9872,"maybe instead of this const delay, we can wait for the master to be done (pid or log file check)",0,0,0,0.987193524837494,0.99257493019104,0.9812698364257812,0.0,accept,unanimous_agreement
764768650,9872,maybe check that the incr didn't get to the replica?,0,0,0,0.9812791347503662,0.9917131662368774,0.9898618459701538,0.0,accept,unanimous_agreement
764796567,9872,"yeah, it's worth considering. i went for blocking since it's backwards compatible. i imagine there are scripts using `redis-cli shutdown` in a synchronous way (like [a link] that was mentioned in issue #9355 recently).",0,0,0,0.9672784209251404,0.97550767660141,0.9610409140586852,0.0,accept,unanimous_agreement
764798497,9872,"it looked like it needs a timeout, but i didn't dive deep enough. i guess something like 0 or -1 is used for no timeout... i'll find out and use that instead.",0,0,0,0.9013007283210754,0.923185169696808,0.9439128041267396,0.0,accept,unanimous_agreement
764800074,9872,do we also want to bypass the refusal to shutdown when writing the aof or rdb files fail? maybe force or kill is a more descriptive flag name then? or do you want to separate these cases with different flags?,0,0,0,0.9753446578979492,0.9903005361557008,0.9932597279548644,0.0,accept,unanimous_agreement
764801782,9872,don't know :-) i guess i though it might have some special meaning... i'll use 0.,1,1,1,0.96453195810318,0.9836216568946838,0.9935145378112792,1.0,accept,unanimous_agreement
764802832,9872,"ok, i can use the default, but with rdb replication, i need to write much more keys to fill up the socket buffers so that it fails without this pr. the rdb file is more compact.",0,0,0,0.9680063128471376,0.9864913821220398,0.9915919303894044,0.0,accept,unanimous_agreement
764803800,9872,the data loss problem is more serious in diskless setups. (we're using diskless so it's more relevant to us. i'm biased.),-1,-1,-1,0.9116876125335692,0.8833324313163757,0.6330695152282715,-1.0,accept,unanimous_agreement
764815130,9872,do we want this line? ideally we'd want a replica wait for sub-replicas to catch up. there might be more things to check for this case though. wdyt?,0,0,0,0.9803631901741028,0.968665361404419,0.9919872283935548,0.0,accept,unanimous_agreement
764817699,9872,i don't know how to do that. is it reliable? another way would be to add an undocumented shutdown flag (shutdown debug-fail).,0,-1,0,0.7426403164863586,0.609417736530304,0.9071475267410278,0.0,accept,majority_agreement
764818593,9872,"no, shutdown_asap = 0 was in the cron function. i just moved it here. the behaviour isn't changed.",0,0,0,0.9788016080856324,0.990501880645752,0.9916990995407104,0.0,accept,unanimous_agreement
764830368,9872,"i'll use llong_max for the timeout (seen in other places) and i'll add unpauseclients() under the error label. if shutdown fails (for whatever reason), i think we want to allow writes again.",0,0,0,0.9871661067008972,0.9906722903251648,0.9925224184989928,0.0,accept,unanimous_agreement
764839307,9872,"it only works if we fill the buffers with junk, like in the first test case. otherwise, the replica will still receive the incr even after master has shut down, due to flushslavesoutputbuffers() in finishshutdown. filling up with junk makes the test very slow in some builds so i was hoping we only need to do that in one of the test cases. [code block]",0,0,0,0.936250627040863,0.9829748272895812,0.98659086227417,0.0,accept,unanimous_agreement
764844285,9872,"i can set it to `1` second, ok? it's the lowest possible value to still allow a second client to call shutdown.",0,0,0,0.9779094457626344,0.9912223815917968,0.9913961291313172,0.0,accept,unanimous_agreement
764892495,9872,in the `# server` section? always present or only during shutdown? any specific ideas regarding names of fields and values?,0,0,0,0.9874672293663024,0.9948418736457824,0.9934773445129396,0.0,accept,unanimous_agreement
764925657,9872,"ok, let's keep the blocking, but maybe add an info field? thinking out loud again maybe we can also reject write commands? in normal pause_writes we don't wanna reject the commands since we can get un-paused and run them. if shutdown is terminal, we can refuse them right away. if we do that, maybe we should also have some new ping response too? however, iiuc our shutdown is not always terminal (we can abort it), and also, it's expected to be rather quick (just a few seconds), so let's only add the info field.",0,0,0,0.8958994150161743,0.9684845209121704,0.9768884181976318,0.0,accept,unanimous_agreement
764929573,9872,"my first thought is that we should have different flags. if the user is also gonna run the risk of losing his aof file (enabled but not yet created), it's a different than giving up on replicas, (since the configured timeout might anyway not get to do what it aims) but i think to document that difference is too complicated, so maybe just one force flag to bypass both. let's document that detail in the top comment, and then see what others think.",0,0,0,0.8835678100585938,0.6949779987335205,0.966129183769226,0.0,accept,unanimous_agreement
764931663,9872,"i suppose that they're such a niche, that maybe we should only have them during shutdown. but let's document that and seek feedback.",0,0,0,0.95921528339386,0.97954660654068,0.9693720936775208,0.0,accept,unanimous_agreement
764933156,9872,"i don't want to add debug flags to other commands, i rather use the debug command over that. but i do think that we can use the initial aofrw to reliably trigger that. it'll add some 10 lines of test code, but maybe it's better than adding 5 lines of redis code.",0,0,0,0.9713147282600404,0.97551029920578,0.9757802486419678,0.0,accept,unanimous_agreement
764936322,9872,"i don't understand what difference you're talking about with regards to the socket buffers. we're not using key-load-delay here, and rely on catching the replica while it's loading the rdb. we're letting it get a full sync completely, then pause it and add some writes to the master. we don't care how it does the initial full sync.. am i missing anything?",-1,-1,0,0.9371107816696168,0.7247719764709473,0.5401201844215393,-1.0,accept,majority_agreement
764936801,9872,i guess we don't have any other choice.. ok,0,0,0,0.6065678000450134,0.3832482993602752,0.6046885848045349,0.0,accept,unanimous_agreement
764940133,9872,"you mean we need to write enough data that will not fit into the os socket buffers? i guess that's the realistic test we need to write in order to cover the actual problem we're dealing with. i think we can very quickly fill 10mb and it won't cause any issues. or even better, keep feeling until introspection shows that there's unwritten data still pending (so it'll work even on a system with huge socket buffers) let's try.",0,0,0,0.9158434867858888,0.8952280282974243,0.9042463302612304,0.0,accept,unanimous_agreement
764941377,9872,"i think you're right, sub-replicas should also wait. by more things to check you mean write another 100 line test?",0,0,0,0.9748490452766418,0.9742836952209472,0.9668912291526794,0.0,accept,unanimous_agreement
764980794,9872,"i'm not sure how it works, but when i designed the test case before i started implementing anything and i expected it to fail but it didn't. i turns out that (in unstable) if master shuts down, it flushes the replication buffer and exits. then, even a few seconds later, the replica can still receive this data. data loss only occurs if we have more replication data than what fits in the buffer. that's why i added the junk to the replication buffer before the incr. without the diskless config, i needed much more junk before the incr to make it fail. i don't know why (just guessing). if we instead just test that the master is reachable (get or info) and check the info output as you wrote in another comment, we don't really need the junk and the test case can be faster and more reliable on slow machines, but then we don't really test the same thing. i guess this is enough though.",0,-1,0,0.8537028431892395,0.7812852263450623,0.8425251245498657,0.0,accept,majority_agreement
764987239,9872,"to check that it responds to info and get isn't the same thing as checking that it actually waits for the replica offset, but it's a pretty good indication. if we instead rely on the new info shutdown lines that i'll add, then we don't need this delay.",0,0,0,0.92493999004364,0.913449227809906,0.7597907185554504,0.0,accept,unanimous_agreement
764992050,9872,exactly. interesting idea. i don't know how to introspect the pending unwritten data though. is it in info?,1,1,1,0.9077081084251404,0.8785256147384644,0.950676202774048,1.0,accept,unanimous_agreement
764995923,9872,"no, i meant that if the master has exited, there is no way that the replica can catch up with the master and then it's no point letting it wait for sub-replicas to catch up because it will never happen. master -> replica -> sub-replica so, maybe we want to stop waiting if we lost connection with the master? or something like that if (server.master_host != null && server.master == null) return 1; /* i'm a replica and i lost my master */",0,0,0,0.5241321325302124,0.8791009187698364,0.9862918257713318,0.0,accept,unanimous_agreement
765024064,9872,"there must be something we're missing, i don't see why diskless should affect that. the only thing i can think of is that diskless has a re-sync delay (`repl-diskless-sync-delay`), so maybe it dropped and wasn't able to re-sync, in contrast to disk-base that could. other than that i don't see any reason why the socket buffers will behave differently, but i do think we need to write more than they could swallow. this shouldn't be slow if you use big keys or pipeline (deferring client), maybe you can use the `proc populate` util.",0,0,0,0.9243810176849364,0.9756399393081664,0.9757569432258606,0.0,accept,unanimous_agreement
765027288,9872,"i think that if we know that the shutdown thing is attempted at cron, and we set the hz to be fast and wait for a few cron triggers, it's enough. when you think of it, that 1 second delay isn't a guarantee of anything either... why 1 and not 5?",0,0,0,0.964566707611084,0.9507509469985962,0.9590979218482972,0.0,accept,unanimous_agreement
765031943,9872,"i suppose setting a small `repl-backlog-size`, and watching `mem_total_replication_buffers` is one way. the other way is do `client list` and look at the `tot-mem` of the replica client.",0,0,0,0.988155484199524,0.9937160611152648,0.989940583705902,0.0,accept,unanimous_agreement
765034694,9872,"for the point of that discussion i don't care about the master. i think as a middle replica (one that has a sub-replica), when we shut down, we only care about data we have, which we didn't yet pass to our sub-replica.",-1,0,0,0.8793536424636841,0.9509465098381042,0.949307918548584,0.0,accept,majority_agreement
765089798,9872,ok. i'll just delete this line then.,0,0,0,0.9846467971801758,0.9764093160629272,0.9909991025924684,0.0,accept,unanimous_agreement
765091503,9872,"in a middle-replica, i suppose `server.master_repl_offset` is the middle-replicas offset, not the actual master's offset. (the middle-replica acts as master towards the sub-prelica. thus my slight confusion.)",0,0,0,0.9692493677139282,0.938158929347992,0.9751442074775696,0.0,accept,unanimous_agreement
766226428,9872,"i'll append these to the server section only during shutdown: * `shutdown_in_milliseconds:nnnn` (remaining time to wait for repl, calculated) * `shutdown_flags:snw` (value is a string where s = save, n = nosave, w = waiting for repl.)",0,0,0,0.9880123138427734,0.9934967756271362,0.9952483773231506,0.0,accept,unanimous_agreement
766594345,9872,i made a helper function to fill up the os socket buffers. please check the assumptions make sense. i'm resolving this for now.,0,0,0,0.97009539604187,0.9769498109817504,0.9890868663787842,0.0,accept,unanimous_agreement
766595542,9872,i write junk until `mem_total_replication_buffers` > 1m. please check if it makes sense.,0,0,0,0.9674842357635498,0.6559329628944397,0.9754593372344972,0.0,accept,unanimous_agreement
766598333,9872,"while implemented, i realized the two flags are very different, so i made separate flags: now and force. i also removed shutdown_wait_repl and made that the default, which is disabled by now. i don't think it'll be hard to document it.",0,0,0,0.9589401483535768,0.9417459964752196,0.9661592245101928,0.0,accept,unanimous_agreement
766742967,9872,"the last ci test run failed on this (but the sanitizer test run passed). i don't know how to reliably fill the os socket send buffer. do you? from within redis it'd be possible to call setsockopt() and getsockopt() with `so_sndbuf`. from the test case, perhaps it's possible to use `ss` to inspect the sockets as in [a link]. wdyt?",0,0,0,0.973494291305542,0.9639939665794371,0.9861308932304382,0.0,accept,unanimous_agreement
767277507,9872,"ok, the usability of these is a bit limited, but i guess that for someone that really needs to monitor the shutdown it's enough. let be sure to document them (and their elusive pretense) in the top comment and later on in redis.io",0,0,0,0.977747917175293,0.9236747622489928,0.9317840933799744,0.0,accept,unanimous_agreement
767278204,9872,you have a comment saying `upp` in a few places.,0,0,0,0.9870100021362304,0.974433660507202,0.9910023808479308,0.0,accept,unanimous_agreement
767278461,9872,"let's explain `idx` in the doc comment. the alternative is to move it to first optional argument like in `proc s` and such. i suppose that considering `num` is always positive, we can do that, but i don't like that too much.",-1,0,-1,0.9613116979599,0.6620621085166931,0.7387161254882812,-1.0,accept,majority_agreement
767280667,9872,"this thing became too complicated. we do have a plan to soon promote this list of commands to command flags, which will be ok for script kill since it's a sub-command, but will not be ok for shutdown. i suppose the only way out is to permit the shutdown command, and add some explicit check inside `shutdowncommand` to fail with a similar error as the one processcommand uses.",0,0,-1,0.6406131386756897,0.8354291915893555,0.8687876462936401,0.0,accept,majority_agreement
767281374,9872,"lgtm. i guess we need to run it on daily ci (freebsd, valgrind, etc). i remember the client eviction pr had some similar issues and in some cases it didn't behave as initially expected. (maybe we can copy some logic from there, so suffice by running the above tests)",0,0,0,0.9737025499343872,0.9892593622207642,0.97765851020813,0.0,accept,unanimous_agreement
767281548,9872,"i'd rather not. -steinberg please take a look at this, you faced similar problems in the client eviction pr.",0,0,-1,0.7489507794380188,0.8737173080444336,0.8119063973426819,0.0,accept,majority_agreement
767281617,9872,lgtm,0,0,0,0.9795994758605956,0.7242414951324463,0.9618706703186036,0.0,accept,unanimous_agreement
767306436,9872,"i believe it's not possible to reliably saturate a socket. there is no guarantee that only the send and receive buffers can store data in transit. in a network, data can also sit in routers. even within the same machine, there kernel might have other internal buffers between the send and receive sockets. thus, i suggest that we send a large amount, e.g. 10mb, in the first test cases (the test case where the master waits for the replica). only 100k is enough on my machine to make it fail without this pr, so 10m is a bit extra. if the feature is broken, this test will fail on at least some machines. for the negative test case where shutdown times out, i suggest we simply don't try to saturate the socket. we just check the logs on master. -steinberg, does this make sense?",0,0,0,0.7760744094848633,0.8371750712394714,0.9729870557785034,0.0,accept,unanimous_agreement
767308309,9872,"i don't have any concrete objection to your suggestion, but i don't agree with the reason. at some point we'll saturate all the buffers there are, we just need to write code that's robust enough, and doesn't assume anything, eventually the socket will be blocked, and every byte you add will be kept in the client output buffers. on some machine 100k will be enough, on others it'll take 10mb, if we add proper exit condition to the loop, we'll be able to trigger what we came to test. i'd like to try to avoid constants (times and sizes), and instead add loops that break out when it's right. maybe the filling loops should have a short sleep, and keep writing until it observes that everything it wrote in the last cycle is sitting in the client buffers.",0,0,0,0.862031877040863,0.8577595353126526,0.8725060224533081,0.0,accept,unanimous_agreement
767320202,9872,"sure, i'll document it. do you have a better idea for fields and values?",0,0,0,0.9738991260528564,0.973712682723999,0.976306140422821,0.0,accept,unanimous_agreement
767321220,9872,"not really. but i can share some random thoughts.. i'm not sure if the flags are needed. i saw you use them in the tests but didn't look closely if that was really necessary. the other thought i had was that other places in the past that showed eta, or bytes left, we later realized that it wasn't enough in order to calculate progress (i.e. the total was also needed). but i'm not sure if it's applicable in this case. it's probably enough to have a boolean, and if instead we have a countdown, that's probably sufficient.",0,0,0,0.8370651006698608,0.5250217914581299,0.8641427755355835,0.0,accept,unanimous_agreement
767385550,9872,"good, i'll skip the flags and keep `shutdown_in_milliseconds` only. we can always add more fields later.",0,0,0,0.957054853439331,0.9405048489570618,0.6440163850784302,0.0,accept,unanimous_agreement
767621816,9872,"thx. (""upp"" means ""up"" in swedish, so guess my fingers subconsciously auto-corrected.)",0,0,0,0.8688241243362427,0.8820472359657288,0.9246246218681335,0.0,accept,unanimous_agreement
767756824,9872,"i'm not sure force should be here, in that case if user passes force|save, we may save data breaking the atomicity of the script. maybe you meant `(shutdown_nosave|shutdown_force) != (flags & (shutdown_nosave|shutdown_force))`? but i don't think that's necessary nosave should be enough to allow this guard to be bypassed.",0,0,0,0.9572212100028992,0.95795339345932,0.9827850461006165,0.0,accept,unanimous_agreement
767757403,9872,let's add a comment on that line saying that the command itself has more checks around this.,0,0,0,0.9846338629722596,0.9871048927307128,0.9936912059783936,0.0,accept,unanimous_agreement
767783499,9872,let's mention this change in the top comment,0,0,0,0.9848737716674804,0.9863104820251464,0.9951334595680236,0.0,accept,unanimous_agreement
767784359,9872,let's mention this change in the top comment. (killing an bgrewriteaof child in case aof is off),0,0,0,0.5425436496734619,0.9786392450332642,0.993305504322052,0.0,accept,unanimous_agreement
767800232,9872,"ok, i understand. we'll require nosave. (i assumed it's ok to break anything if force is given.)",0,0,0,0.9475762248039246,0.9684962630271912,0.959890604019165,0.0,accept,unanimous_agreement
767801250,9872,"i'm reverting this cleanup, because there are some failing test cases that i'd love to avoid spending hours debugging... see the commit message with the revert.",-1,0,0,0.6357952952384949,0.5540258288383484,0.6413937211036682,0.0,accept,majority_agreement
767823189,9872,tbh i don't know what an initial aofrw is. i don't know much about aof.,-1,-1,0,0.7861623167991638,0.778023898601532,0.8595092296600342,-1.0,accept,majority_agreement
767825212,9872,"writing 1m at a time, with 10ms sleep between each round, until mem_total_replication_buffers > 2m seems to work.",0,0,0,0.985594630241394,0.9825750589370728,0.98958158493042,0.0,accept,unanimous_agreement
767826680,9872,done. top comment is up to date with current implementation.,0,0,0,0.9675003290176392,0.965121328830719,0.9688107967376708,0.0,accept,unanimous_agreement
767845638,9872,i never found a reliable way to saturate the kernel output buffers by assuming a fixed size will work and playing around with linux/socket tweakables. i ended up just writing a loop and waiting until the client's output buff (or total client memory) reached the size i was aiming for (via `client list`).,0,0,0,0.6160352230072021,0.8481700420379639,0.9624096751213074,0.0,accept,unanimous_agreement
767851051,9872,"ok, that's what i tried, using `client list` and `info`, but i didn't quite get it right until now. when writing 1m, the repl buffer grows to 1m even when it succeeds writing all of it to the socket. however, it only reaches 2m when the socket is full. thus, my last attempt seems to work. i hope it's a safe assumption.",0,0,0,0.7847757935523987,0.8501291871070862,0.5718768835067749,0.0,accept,unanimous_agreement
768500874,9872,"ok, i don't understand why it fails, and it's only one test, so probably easy to solve, but we can circle back to it some other time. p.s. looking at the reverted commit again, it seems you didn't set the nosave flag in that flow.",0,0,0,0.9266667366027832,0.9632136225700378,0.9568907618522644,0.0,accept,unanimous_agreement
768507276,9872,"i'll explain then (for your benefit). normally if redis starts configured to persist to aof, it either loads one, or creates one when redis is empty. in these cases, every write that is executed is appended to the file, and the user can shutdown redis whenever it likes. i assume you know what an aofrw means, but i'll just mention that if the files grows by more and more appends, eventually we start a fork to generate a new one based on the data we have in ram (some form of compaction) there is an odd situation which happens when redis starts without aof enabled, and then aof is enabled at runtime (after redis already has data). in that case, redis starts an aofrw process, and responds to the config set command with ok (agreeing to a new persistence contract), but the data is not yet ""safe"", it'll only be safe when the rewrite is completed, and this is why it refuses to terminate in that scenario.",0,0,0,0.9469382762908936,0.9645925164222716,0.9693433046340942,0.0,accept,unanimous_agreement
768533771,9872,thanks for explaining! so it's basically just to set a config value to yes? but i don't see how we can reliably do this just when the replica catches with the master (just before we send sigcont to the replica?) and how we can rely on that this aofrw takes enough time so that finishshutdown is called exactly during this time. replicas report their offset only once per second.,1,1,1,0.7576483488082886,0.9133363366127014,0.9797526597976683,1.0,accept,unanimous_agreement
768537187,9872,shutdown_nosave is set in prepareforshutdown if `server.loading`. this is already in unstable.,0,0,0,0.9838936924934388,0.9876495003700256,0.9948697090148926,0.0,accept,unanimous_agreement
768545243,9872,"can't `rdb-key-save-delay` do that? i.e. we'll make the master do an aofrw that takes forever, then unfreeze the replica and issue a shutdown, the replica will be done before the aofrw. maybe i forgot (or didn't understand) what we wanted to test though.",0,0,0,0.9538205862045288,0.970355987548828,0.9577823877334596,0.0,accept,unanimous_agreement
768622212,9872,a hidden config trick! makes sense; i'll try it.,1,-1,1,0.6848672032356262,0.3869704902172088,0.8897877335548401,1.0,accept,majority_agreement
768707030,9872,"i now realized that servercron doesn't run during loading. we send sigterm to the replica to ask that it'll die, but it ignores it and keep on reading the rdb file. i think the solution is that the signal handler should call `prepareforshutdown(force|now|nosave) && exit(0)` instead of just `exit(0)`",0,0,0,0.9780927896499634,0.989646017551422,0.978851556777954,0.0,accept,unanimous_agreement
768785852,9872,"for reference: in a chat, we decided to postpone this to another pr. the signal handler should only touch variables declared `volatile sig_atomic_t` or similar, like `shutdown_asap`. another option is to call prepareforshutdown from whileblockedcron, but the test cases still fail, possibly because they don't write enough data to trigger whileblockedcron. maybe it's enough to tweak the test cases a bit.",0,0,0,0.969772219657898,0.9912129044532776,0.9911261200904846,0.0,accept,unanimous_agreement
769298687,9872,"maybe we should use this opportunity to add a replconf getack to the slave buffers, so that when they get it, they'll send an ack right away, instead of waiting for the periodic one (i.e. what we wait for in isreadytoshutdown). i.e. extract the code from `beforesleep` which uses `shared.getack` into a function and use it here.",0,0,0,0.9878512024879456,0.994986891746521,0.9860279560089112,0.0,accept,unanimous_agreement
769301401,9872,"let's log the replstate too, and maybe other things logged in info replication (like last ack time / lag)?",0,0,0,0.9884757995605468,0.9944722056388856,0.9942169189453124,0.0,accept,unanimous_agreement
769303552,9872,maybe we need to also delete the temp file here?,0,0,0,0.985241711139679,0.9928207993507384,0.9876114726066588,0.0,accept,unanimous_agreement
769307106,9872,"technically speaking, in current code, i guess we can change this to `server.aof_state == aof_on`, since in wait_rewrite there's no ""current"" file to flush to. however, soon, in #9788 this is gonna change, and in case the state is wait_rewrite, we'll want to delete the new part. please confirm what i state above, and let's change that code in this pr to be: 1. safe / correct in current unstable 2. make sure it'll cause a merge conflict in your pr so that you'll handle that case there too.",0,0,0,0.9499996304512024,0.9829692840576172,0.9522980451583862,0.0,accept,unanimous_agreement
769425870,9872,"good idea! it could speed up the completion. promised bonus points for this in the issue. (oran, we can share the points 50/50.)",1,1,1,0.988191783428192,0.9911057353019714,0.9965499639511108,1.0,accept,unanimous_agreement
769465508,9872,fyi: i can't simply set the flag `get_ack_from_slaves` because beforesleep won't be sent if clients are paused.,0,0,0,0.9669051766395568,0.9854754209518432,0.9887285232543944,0.0,accept,unanimous_agreement
769478085,9872,"right, as i suggested, you must do that manually before calling `pauseclients`",0,0,0,0.9872298836708068,0.9931507110595704,0.9935638308525084,0.0,accept,unanimous_agreement
769661157,9872,killappendonlychild is called a few lines below. it deletes the temp file.,0,0,0,0.9883059859275818,0.9889559149742126,0.9890379905700684,0.0,accept,unanimous_agreement
769788369,9872,shoudln't the getack be eabove the pause?,0,0,0,0.9726560711860656,0.9904678463935852,0.9875553250312804,0.0,accept,unanimous_agreement
769801272,9872,"does it matter? pauseclients only prevents incoming write commands, right?",0,0,0,0.9824149012565612,0.9644302725791932,0.975389838218689,0.0,accept,unanimous_agreement
769803458,9872,do you want me to change to `server.aof_state == aof_on` in this pr? i don't think #9788 affects this.,0,0,0,0.9819204211235046,0.9881753921508788,0.9931017160415648,0.0,accept,unanimous_agreement
769804914,9872,"not really, it also prevents expiration, eviction, replica pings, and even hints modules that they must not do anything that results in replication. maybe it doesn't affect a direct call to replicationfeedslaves, but there might be an assert there some day, so i think it's a good idea to swap them. come to think of it, what if we where already in a pause? maybe in that case we should avoid asking for ack, but also what if the earlier pause is removed earlier? i suppose all it'll do is that the shutdown will be completed when we reach our timeout? please look into this.",0,0,0,0.9201012253761292,0.9315752983093262,0.9175356030464172,0.0,accept,unanimous_agreement
769807229,9872,"why did you need to change this? it already changed `repl-ping-replica-period` to high value? please explain what was the problem. i'm not sure if comparing to a static pre-sampled offset is right, and if we do that maybe we need to use `>=` (which i think can hide bugs)",0,0,0,0.9584486484527588,0.9473522305488586,0.954537272453308,0.0,accept,unanimous_agreement
769812002,9872,"ok, i'll skip getack if clients are already paused. if clients are already paused, we still call `pauseclients(llong_max, client_pause_write)` here and unpause if and when shutdown fails, so if they were already paused before, the pause mode and timeout will be lost. i think we can accept this.",0,0,0,0.9779322743415833,0.9774962663650512,0.973147451877594,0.0,accept,unanimous_agreement
769819380,9872,"i changed this because replconf getack affects the offset and this broke the asserts later in the test case. it seems that the offset is incremented by exactly 37 when replconf getack is sent. if the purpose of the test case has anything to do with the master not knowing that the replica is up to date (because it is; it's checked in this `wait_for_condition` loop), then we can't do this, but otoh with this pr the master will send getack during shutdown and wait for the replicas anyway, so the high value of `repl-ping-replica-period` isn't effective anyway. my though was that `>=` would hide bugs, so i didn't want to do that. what if we use `shutdown now` to restart the master? or equivalently `debug restart`. that prevents the replconf getack...",0,0,0,0.9790234565734864,0.9430075883865356,0.9902310967445374,0.0,accept,unanimous_agreement
770410308,9872,added replstate and lag as in info.,0,0,0,0.9822079539299012,0.993312418460846,0.9949668049812316,0.0,accept,unanimous_agreement
770413062,9872,"i did the latter and used `$master debug restart` instead of `restart_server 0 true false`. it uses shutdown_now, preserving the old behaviour of the test case.",0,0,0,0.9890478253364564,0.993303120136261,0.9921837449073792,0.0,accept,unanimous_agreement
770477516,9872,"i think it's the right thing to do (change that condition), specifically if this pr is the last one, and then we publish a release. but considering that we're going to change things again soon, and considering that this pr didn't break anything (the condition was wrong to before, and it has no actual implications. let's keep the current code in this pr.",0,0,0,0.959184229373932,0.9745689630508424,0.9084042310714722,0.0,accept,unanimous_agreement
770481933,9872,"so assuming we don't bother to re-pause or send a getack if already paused, two possible things can go wrong: 1. the other pause will expire before ours expires, which will mean: 1. more traffic is forwarded to the replicas 2. we don't have a chance to shutdown in reasonable time and wait till the timeout 3. when the timeout is reached, we shudown and induce partial data loss 2. our shutdown timeout will expire first 1. if we end up shutting down, that's fine 2. if the shutdown fails, and we unpause, we could cause some damage to the original pause intent. `2.ii` is solvable if we don't unpause what we didn't pause. `1.i` can be maybe solved if pause has a reference count, so the clients will only be unpaused if bother pausers ask to unpause (i don't like it) wdty?",0,0,0,0.9551302194595336,0.9305900931358336,0.9769710898399352,0.0,accept,unanimous_agreement
770492684,9872,"these tests used to use debug restart in the past. it upsets valgrind and causes other test suite issues, which is why i introduced restart_server and used it everywhere. let's add an argument to restart_server to specify how it should be shut down.",0,0,0,0.9558550715446472,0.982470154762268,0.9922707080841064,0.0,accept,unanimous_agreement
770498757,9872,"after thinking a bit more about it, it occurred to me that maybe this exposes a bigger problem. maybe that extra getack feature can cause real issues of a repl offset mismatch between the rdb file and the replicas. specifically if the timeout is short. but looking again ad your change (which you now reverted), i understand that at least in that test, this extra getack feature didn't cause any replication issues (psync still succeeded). all it did is fail an assertion in the test, right? so considering that, maybe i'm ok with that change (which you reverted). but also, maybe we do want to run this test on both modes (sigterm, and shutdown now). maybe we should modify one test to use one approach, and the other to use the other approach (just in order to avoid running 4 tests instead of 2)",0,0,0,0.7783301472663879,0.9615680575370787,0.8265030384063721,0.0,accept,unanimous_agreement
770541436,9872,"it's not good to let pause timeout happen during shutdown (1.3). i don't think we should let that happen. better set pause timeout to long_max so it can't timeout during shutdown. if shutdown fails and we unpause clients that should otherwise remain paused (2.2), i don't think we need to bother. if shutdown fails, we have a serious problem anyway. what if clients are paused in mode all and we change it to write? it will allow some requests during shutdown which would otherwise have been blocked. perhaps it's better to keep all in that case and only set the timeout...? what if clients are unpaused explicitly, for example if client unpause is called or cluster failover is completed while shutdown is ongoing, which triggers unpauseclients, how bad is that? i think it's acceptable. if you think it's not acceptable, we can tweak unpauseclients so that it checks if shutdown is ongoing and refuse to unpause clients.",-1,-1,-1,0.6298518180847168,0.877302885055542,0.8858581185340881,-1.0,accept,unanimous_agreement
770882192,9872,"ohh, i now notice that my previous message wasn't properly formatted, so it showed numbers from 1 to 7, instead of creating 2 levels like i meant to (edited). but looking at your response, it looks like somehow you figured out what i meant? anyway, this is becoming a little bit messy. another way out (which i don't like either), is to introduce a separate pause flag or variable for each purpose, so that they don't override each other, and the pause is effective as long as either of them is set. if we don't go that way, i think we need to make some compromises, and just decide which one is better.. obviously as you said, when we start out pause, we must not cause the pre-existing pause be less effective (like demoting an all, to write). but i'm a bit paranoid about cases that one of them will expire first and cause damage to the other. maybe that shouldn't really happen, since it's unlikely that failover and shutdown will be triggered at the same time (user who does that might be misguided). please propose a solution and analyze it and it's edge cases, and we'll see if we can agree on it.",-1,-1,-1,0.9194916486740112,0.9021314978599548,0.7446550130844116,-1.0,accept,unanimous_agreement
771738879,9872,"clientpause never demotes all to write and never decreases a pre-existing timeout. it only extends them (all > write > off). [code block] (1) we can preserve the original pause timestamp if we pause with an `end` timestamp matching the shutdown-timeout (instead of long_max) and don't explicitly unpause after a shutdown failure. then, if clients were already paused for some other reason, they will remain paused after a shutdown failure. (this is what i had done originally and reverted in c941a29a2131267568b69221163c6bc54d13ae95.) the downside of this is that if shutdown-timeout is high and replicas catch up fast, clients will remain paused until the original shutdown timeout is reached. it can be a long time depending on the shutdown-timeout config. ---- (2) the other very simple alternative is what we currently have in this pr: unpause explicitly on a failed shutdown. i did a grep for unpauseclients. it's called after a failover, both cluster failover and standalone, both after a successful and after a failed failover. given this, i think it's totally fine to do the same after failed shutdown. note that we don't demote all to write in any case. ---- (3) any complex logic where we keep more than one timestamp, i don't think is worth the complexy. i prefer option 2.",0,0,0,0.9778130054473876,0.9827149510383606,0.9916212558746338,0.0,accept,unanimous_agreement
771753240,9872,"that's right, all it did was fail an assertion in the tests. the assertion checked that the offset reported by the replica matches the offset reported by the master, but it didn't check that the master had received the offset (ack) from the replica. if it hadn't received the ack, it would wait for replicas and send getack to speed up the ack. so, i agree, i don't think the getack can cause any serious issues. if the replicas are already up to date, it will not be sent. if they're not, the getack will speed up the shutdown. now, i solved the test cases by sending shutdown now using a deferred client just before calling the `restart_server` proc. the `restart_server` and `kill_server` don't care if the server is already dead, so this works perfectly. i hope you agree. :)",0,0,0,0.9576810598373412,0.9868077635765076,0.9154866933822632,0.0,accept,unanimous_agreement
771753548,9872,"i don't think we need to run these test cases in both modes (both signal and shutdown now) because, again, all it affects is that assert.",0,0,0,0.9706032276153564,0.9810088872909546,0.9817124009132384,0.0,accept,unanimous_agreement
771802880,9872,"i'm paranoid that in some cases we send the getack and immediately exit (saving an rdb), imagine a case where the shutdown timeout is very short. in that case, that getack might be the thing that destroys the ability to psync later. i know that we think currently there's no risk since e skip sending that getack when there's no need for it. but i still like to have these tests check both shutdown with and without timeout (i.e. now an and sigabrt)",-1,0,-1,0.9596685767173768,0.731782853603363,0.8792615532875061,-1.0,accept,majority_agreement
771803651,9872,i would rather this be a feature of the re restart_server proc,0,0,0,0.9860771894454956,0.9935990571975708,0.9895371198654176,0.0,accept,unanimous_agreement
771857406,9872,or maybe [code block],0,0,0,0.985588312149048,0.9917560815811156,0.99367094039917,0.0,accept,unanimous_agreement
771908706,9872,"""in minutes""? you mean seconds.",0,0,0,0.9623945355415344,0.9887841939926147,0.8676342368125916,0.0,accept,unanimous_agreement
771908735,9872,edited the suggestion above.,0,0,0,0.9840077757835388,0.9857959747314452,0.9910428524017334,0.0,accept,unanimous_agreement
771981731,9872,"i think i'll prefer something like ""o(n) when saving, o(1) otherwise"".",0,0,0,0.9560940861701964,0.9659708738327026,0.9837639331817628,0.0,accept,unanimous_agreement
771983824,9872,"ok, i can do that, but first i want to show another possible approach: taking the offset when shutdown is ongoing and getack has been sent. in this way, we get the final offset before the master exits without using now. [code block] :+1: or :-1: ?",0,0,0,0.9804766178131104,0.9527777433395386,0.9856224656105042,0.0,accept,unanimous_agreement
771989808,9872,"i feel it's awkward that the test does both shutdown and restart_server. i.e. we rely on the fact restart_server will be ok with it. i'd rather restart_server will take an optional argument indicating how to shutdown. the other thing that bothers me the risk of the extra getack somehow messing up the ability of the replica to psync. i know that today we avoid sending the getack if the replica is already in sync, so all of that won't matter, but i still think it's a good idea to use one shutdown approach in one test and the other approach in the other test (since we have two of them anyway)",-1,-1,-1,0.9596313834190368,0.9474664926528932,0.9757971167564392,-1.0,accept,unanimous_agreement
771989879,9872,"i think we should mention what's ""n"" when we specify o(n).",0,0,0,0.9847397804260254,0.983777642250061,0.9860426783561708,0.0,accept,unanimous_agreement
771992875,9872,"yes, i said ""something like"", not exactly this. i'll add a commit tomorrow.",0,0,0,0.974550724029541,0.921065628528595,0.9908818006515504,0.0,accept,unanimous_agreement
771993608,9872,i asked to take a look at it (he's doing something else in that area),0,0,0,0.9740549325942992,0.9358009099960328,0.9743452668190002,0.0,accept,unanimous_agreement
771993761,9872,"ok. i completely forgot that clientpause already has a mechanism for ""conflict resolution"". so in that case it would have been best to just hand it with the request and let it solve it. we do that with the pause_type, but not with the timeout, instead we try to keep manual control over it, and that can fail. it's interesting that the failover command doing exactly the same (manual unpause), but maybe it's not as severe when there's just one player that does that, and it becomes more severe when there are two doing that trick. we need to realize that the result of such a clash is partial data loss (doing an unpause, and then either shutting down or failing over, and losing writes) since we can't seem to find a good solution, maybe we need more input. please sum up the details and concerns of this issue as an open question in the top comment, and we'll call the core-team to review and respond. one last note, i see failover uses llong_max, since mstime_t is long long, and we're using long_max, they're the same on 64bit, and i don't like to take any risk of different behavior in edge cases on 32 bit, so lets converge.",0,0,0,0.7231001257896423,0.9449692368507384,0.674563467502594,0.0,accept,unanimous_agreement
772229851,9872,"i added a similar comment in the last test too, so all 3 tests in this suite have a comment at restart_server. don't worry about the force-push. i added a file by mistake only in the last commit and amended it a few seconds later.",1,0,1,0.5440534353256226,0.9822428226470948,0.5945101380348206,1.0,accept,majority_agreement
772642731,9872,"are you sure about having an arbitrary max value limit? in cases where this feature may come in handy, might it make sense to simply wait forever (or until the replica drops, or someone force kills the server)?",0,0,0,0.9846513271331788,0.9778788089752196,0.9831838011741638,0.0,accept,unanimous_agreement
772688692,9872,"good question. i don't have a strong opinion about it. also, i don't have a use case to wait forever. :-) one reason to set the maximum relatively low is that it's always possible to increase it in the future, but it won't be possible to decrease it without breaking backward compatibility. what do you suggest? uint_max? or should we use a magic value such as -1 to wait forever?",1,1,1,0.9727932214736938,0.994091808795929,0.9954777359962464,1.0,accept,unanimous_agreement
772886125,9872,"in the past i've advocated for supporting a list of independent timeout events with their own pause level. since we don't expect many of these timeouts, we can be inefficient in our storage and make the code simple. this code has caused a good bit of confusion, so even making it clearer would be a win.",0,0,0,0.838538646697998,0.8559867739677429,0.9163017868995668,0.0,accept,unanimous_agreement
772916333,9872,"we discussed this in a core-team meeting, we would like to proceed by adding a separate pause flag per purpose so that pause is effective until the last one is cleared. please look into that and see what you come up with.",0,0,0,0.9625604152679444,0.9832621812820436,0.9744763374328612,0.0,accept,unanimous_agreement
776408427,9872,"per purpose... i can identify 3 purposes: shutdown, failover (cluster or standalone) and client pause. or do you have a different idea of purpose? currently, i think client unpause works when clients are paused during failover. we'll break that, so it's a breaking change. ok? if client pause is called twice with different timeouts and modes, the last one overwrites the previous ones, because it's the same purpose. ok?",0,0,0,0.9462868571281432,0.9162023067474364,0.9244245886802672,0.0,accept,unanimous_agreement
776467396,9872,"i think for client pause we should keep the current logic of taking the longer pause and the stronger pause ""level"". and since we have an explicit failover abort, i do think client unpause should not affect it (yes it's a breaking change). and i guess we might wanna add shutdown abort.",0,0,0,0.9707757234573364,0.9800770878791808,0.9864952564239502,0.0,accept,unanimous_agreement
776470595,9872,"let's use int_max (just avoid any possible issues with overflow... alternatively, we can define ""infinite"" as one week maybe? (an hour may be too short for some insane users, but a week should do it?)",0,0,0,0.7878229022026062,0.8725587725639343,0.9810115098953248,0.0,accept,unanimous_agreement
776516026,9872,"i added a commit ""separate client pause/unpause per purpose"" to this pr now. i hope it's acceptable. :grimacing: shutdown abort we do in a later pr?",-1,1,-1,0.9751841425895692,0.916437804698944,0.99440997838974,-1.0,accept,majority_agreement
776677379,9872,"at least for client pause command, we wanted to take the max end time and most restrictive mode if called twice. it's a bit odd that client unpause cancels both, but i think acceptable. iirc failover is rejected if one is already in progress. and shutdown can just silently join the existing shutdown (or we can merge the timeouts, max or min, i don't care)",0,0,0,0.7229868769645691,0.9303092956542968,0.8972985148429871,0.0,accept,unanimous_agreement
776698013,9872,":facepalm: you're right. i wanted (but forgot...) to set them to max(old, new) for all purposes, although it only matters for client pause.",0,0,-1,0.9438737630844116,0.9664700031280518,0.8929271697998047,0.0,accept,majority_agreement
776728607,9872,"shutdown abort added in this pr, with tests.",0,0,0,0.986236810684204,0.9916187524795532,0.9899946451187134,0.0,accept,unanimous_agreement
776731565,9872,maybe wait for the log message here?,0,0,0,0.9826662540435792,0.991713285446167,0.9819496273994446,0.0,accept,unanimous_agreement
850257911,10536,why does this need a null-terminator when `name` doesn't need it?,0,0,0,0.9592524766921996,0.9899135828018188,0.978270411491394,0.0,accept,unanimous_agreement
850639032,10536,"the node description string is created with sdscatfmt, which doesn't support `width` but now that you mentioned it, the null terminator does look out of place. i can switch to sdscatprintf and drop the null terminator. i don't think `clustergennodedescription` is used on any performance critical path so the argument of sdscatfmt being more performant is probably moot. readability is more important.",0,0,0,0.9771445393562316,0.981475591659546,0.9878391027450562,0.0,accept,unanimous_agreement
889414071,10536,"more recently we've tried to name dicttypes by the type of information they have, not by the feature they implement.",0,0,0,0.9800058603286744,0.9850666522979736,0.9834578037261964,0.0,accept,unanimous_agreement
889414758,10536,i would prefer to avoid most of the whitespace changes to preserve githistory.,0,0,0,0.9704273343086244,0.9804018139839172,0.9732619524002076,0.0,accept,unanimous_agreement
889415884,10536,"i think shards are more likely to be artificially imposed than node ids. i think we should have some mechanism to preserve a shard on all nodes failing. in this flow, you might remove all nodes and then add a new one which will get a new shard id. my thought is either we should allow a config to specify a nodes shard_id. if a node becomes a node and has to generate a shard_id, it should use the provided one, otherwise it should generate its own.",0,0,0,0.9595930576324464,0.9834457039833068,0.9779220819473268,0.0,accept,unanimous_agreement
889416342,10536,"maybe we should update this to `clustergetnodesinmyshard`. the weird wording was because ""shard"" wasn't a concept yet.",-1,0,-1,0.8434441685676575,0.6007087230682373,0.5652509331703186,-1.0,accept,majority_agreement
889416621,10536,not sure this assert is necessary.,-1,0,0,0.6743191480636597,0.9109757542610168,0.670451819896698,0.0,accept,majority_agreement
889417887,10536,do we want to change this structure to loop over the shards instead of hunting down the primaries?,0,0,0,0.9773827195167542,0.9904995560646056,0.9893654584884644,0.0,accept,unanimous_agreement
889418061,10536,the node might just be failed though on its own. maybe instead we should rely on the shard id to see if there is another node serving the slots?,0,0,0,0.9753645062446594,0.9826349020004272,0.9881560802459716,0.0,accept,unanimous_agreement
889419200,10536,"this should be necessarily, zfree works on null and we're just zeroing information.",0,0,0,0.97589111328125,0.9862536191940308,0.9858397245407104,0.0,accept,unanimous_agreement
889421307,10536,what does ep stand for? the name doesn't really make any sense to me.,-1,0,-1,0.8455986380577087,0.5526019930839539,0.511688232421875,-1.0,accept,majority_agreement
889421623,10536,i would throw an error if the value is not cluster_namelen and not load something random.,0,0,0,0.9455679655075072,0.9477460384368896,0.9777144193649292,0.0,accept,unanimous_agreement
889422133,10536,"shouldn't we do some validation that our master has the same shard id as us here? which one do we override if they disagree. based on my previous understanding, we want nodes to be connected to shards and not to specific masters anymore.",0,0,0,0.9562764167785645,0.9861429333686828,0.9893072247505188,0.0,accept,unanimous_agreement
889423781,10536,we can just extract the pointer and pass it to updateshardid(). doing a copy here is just extra work since we're going to copy it again later anyways.,0,0,0,0.9867650270462036,0.9881977438926696,0.992675006389618,0.0,accept,unanimous_agreement
893067884,10536,this dictionary tracks shard membership so would `clustershardmemberdicttype` be a better name?,0,0,0,0.9879589080810548,0.9949485063552856,0.9936842322349548,0.0,accept,unanimous_agreement
893068696,10536,endpoint - since this is the endpoint column that is being parsed. would `endpoint_argc` work better?,0,0,0,0.9872447848320008,0.994998574256897,0.9942069053649902,0.0,accept,unanimous_agreement
893069287,10536,good point. will bail to `fmterr`,1,1,1,0.9670438170433044,0.8903753161430359,0.9613855481147766,1.0,accept,unanimous_agreement
893071373,10536,agreed. i think i will bail to `fmterr` if the two don't agree on the shard id.,0,0,0,0.9697665572166444,0.8380001783370972,0.917262613773346,0.0,accept,unanimous_agreement
893071459,10536,ack,0,0,0,0.9720376133918762,0.8596508502960205,0.9149930477142334,0.0,accept,unanimous_agreement
893071826,10536,thanks.,0,1,0,0.5150366425514221,0.5804154276847839,0.5270382761955261,0.0,accept,majority_agreement
893072115,10536,+1,0,0,0,0.696722686290741,0.7702900171279907,0.9816582202911376,0.0,accept,unanimous_agreement
893072734,10536,agreed.,0,0,0,0.9702104926109314,0.9005043506622314,0.954565167427063,0.0,accept,unanimous_agreement
893076525,10536,"i agree with you that there is value in allowing admin to control the shard id. the implementation should be straightforward. i am not sure though about the mechanism or interface that you have in mind. are you suggesting a new cluster command like setshardid or something else? fwiw, there is an odd way to reuse/customize the shard_id for a new node, which is through a manually crafted nodes.conf.",0,0,0,0.865690290927887,0.9207828640937804,0.9495327472686768,0.0,accept,unanimous_agreement
893076684,10536,+1,0,0,0,0.696722686290741,0.7702900171279907,0.9816582202911376,0.0,accept,unanimous_agreement
893077073,10536,+1,0,0,0,0.696722686290741,0.7702900171279907,0.9816582202911376,0.0,accept,unanimous_agreement
893077618,10536,got it. old habit.,-1,-1,0,0.7395772933959961,0.8705152869224548,0.6568740010261536,-1.0,accept,majority_agreement
893078144,10536,+1,0,0,0,0.696722686290741,0.7702900171279907,0.9816582202911376,0.0,accept,unanimous_agreement
893081060,10536,"if the node just failed and no new primary has been elected, its slot count should be non-zero (assuming non-empty shard) so it will get picked up. i like your suggestion of refactoring this loop to go over the shards dictionary instead so this non-so-intuitive check can be removed i believe",1,0,0,0.8904126882553101,0.9690951704978944,0.6154627203941345,0.0,accept,majority_agreement
893155763,10536,"i think she meant the *dict type* can potentially be used for other dicts, so we shouldn't name it after the dict it's used for. something like sdstolistdicttype i suppose.",0,0,0,0.985817849636078,0.9843607544898988,0.9851935505867004,0.0,accept,unanimous_agreement
893742443,10536,got it. is there still a preference for the `cluster` prefix? `clustersdstolistdicttype`?,0,0,0,0.9856551289558412,0.9929497241973876,0.8724707961082458,0.0,accept,unanimous_agreement
893819748,10536,went with `clustersdstolistdicttype`,0,0,0,0.9863505959510804,0.9938378930091858,0.995031714439392,0.0,accept,unanimous_agreement
902029903,10536,yes please :),1,1,0,0.9594671726226808,0.9934915900230408,0.8347711563110352,1.0,accept,majority_agreement
902039276,10536,"so i see two options: 1. set a config like, 'shard_id'. primaries who aren't attached to other nodes would automatically start with the given shard_id. for replicas, they would use this shard-id to join a specific shard of a cluster, implying replication. 2. use an api like `setshardid`, to allow configuring a node to a specific shard. this couldn't be configured at startup, but could be sent after a node has joined the cluster. initially i thought option 1 be a better approach since it better allows configuration at ""startup"". however, realistically you will have nodes join the cluster with arbitrary shard ids, then you would call meet to coral them into a specific shard. so option 2 sounds more sane?",0,0,0,0.9272575378417968,0.9877322912216188,0.9763104915618896,0.0,accept,unanimous_agreement
902043246,10536,"since we moved this to a dictionary, we can set the length up front instead of using a deferred length. [code block]",0,0,0,0.9888359904289246,0.9898539185523988,0.9955936074256896,0.0,accept,unanimous_agreement
902045742,10536,"although not consistent, this is the preferred multi-line bracket placement. [code block]",0,0,0,0.9878893494606018,0.9928752183914183,0.9910396933555604,0.0,accept,unanimous_agreement
902046603,10536,i suppose all the numbering is not correct anymore.,0,0,0,0.9218544363975524,0.8579111695289612,0.9799360036849976,0.0,accept,unanimous_agreement
902085169,10536,"how about a `joinshard` primitive? i think it makes more sense to expose a high level construct around shards, as opposed to letting admins manipulate the shard-id directly. specifically, i propose the below: a node `n` can explicitly join a shard `s` as identified by its ` ` via `cluster joinshard ` * if shard `s` is not empty, `n` will try locating its primary `p` and initiate replication, as long as it sees one live node in `s` * otherwise, if all nodes in `s` are permanently down, `n` should attempt a manual failover * otherwise, there is no node in `s` and this means that the cluster is not aware of this shard at all. i'd propose we fail the `joinshard` request. for completeness, the following two have been implemented in this pr: 1. a new node `n` always starts out in its own shard with an auto-generated shard-id 2. a node `n` implicitly joins an existing shard via `cluster replicate `",0,0,0,0.9787609577178956,0.9914985299110411,0.9915209412574768,0.0,accept,unanimous_agreement
902086594,10536,good catch. will update the numbering.,1,1,1,0.96479469537735,0.9588879942893982,0.9917612075805664,1.0,accept,unanimous_agreement
902142196,10536,sounds good to me! it generally follows the paradigm of cluster v2 as well.,1,1,1,0.9895050525665284,0.9910524487495422,0.9953888654708862,1.0,accept,unanimous_agreement
905608415,10536,what do you think about the logistics here? do you prefer to having `joinshard` implemented as part of this pr or you are open to a follow up pr?,0,0,0,0.9813506603240968,0.9922795295715332,0.9861426949501038,0.0,accept,unanimous_agreement
913073903,10536,followup is fine.,0,0,0,0.962986946105957,0.8405357599258423,0.965647280216217,0.0,accept,unanimous_agreement
913249031,10536,created #10935 to track the work on `joinshard`,0,0,0,0.9878107905387878,0.9951871633529664,0.99513441324234,0.0,accept,unanimous_agreement
963214878,10536,which version should i use for `since`?,0,0,0,0.9854751825332642,0.992746889591217,0.993905246257782,0.0,accept,unanimous_agreement
963360877,10536,this is identical to `clusternodesdicttype`. can we use the same for both?,0,0,0,0.9894792437553406,0.9945249557495116,0.9955898523330688,0.0,accept,unanimous_agreement
963368880,10536,"it seems that aux fields can only be present if hostname is present. what if hostname is missing and shardid is present? do we have two commas like this: `1.2.3.4:1234,,shardid=abcdef1234567890abcdef1234567890abcdef12`? if that's the case, the syntax is instead `ip:port[][,hostname[,aux=val]*]`.",0,0,0,0.9871227741241456,0.9937467575073242,0.9909850358963012,0.0,accept,unanimous_agreement
963396770,10536,"just noticing this comment. we could store plaintext port in an aux field too, in a future pr. should we?",0,0,0,0.9831081032752992,0.982637345790863,0.9356150031089784,0.0,accept,unanimous_agreement
963480134,10536,i think the next minor version is 7.2.0,0,0,0,0.9762335419654846,0.9846461415290833,0.9862176775932312,0.0,accept,unanimous_agreement
964353875,10536,good catch! yeah hostname is optional. will update the comment.,1,1,1,0.9916571378707886,0.9934045672416688,0.9962424039840698,1.0,accept,unanimous_agreement
964354462,10536,not exactly the same as there is a value destructor here. [code block],0,0,0,0.9793757796287536,0.990982472896576,0.9874284863471984,0.0,accept,unanimous_agreement
964354579,10536,will do,0,0,0,0.9603245854377748,0.957181751728058,0.9619618058204652,0.0,accept,unanimous_agreement
964354789,10536,will do.,0,0,0,0.9548023343086244,0.9864637851715088,0.9465230703353882,0.0,accept,unanimous_agreement
964362520,10536,"my understanding is that the plaintext port comes from the server config. if we persist it here again, then we will have to deal with any potential conflicts. curios to know what value does it bring us if we were to persist it in nodes.conf as well?",0,0,0,0.9848814010620116,0.986295759677887,0.990359902381897,0.0,accept,unanimous_agreement
964362620,10536,will do,0,0,0,0.9603245854377748,0.957181751728058,0.9619618058204652,0.0,accept,unanimous_agreement
964516191,10536,"ah, ok.",0,0,0,0.95599627494812,0.844211757183075,0.9501436352729796,0.0,accept,unanimous_agreement
964519144,10536,"the pport is a server config so the server which has it configured will know it, but if other nodes persist it too, they are able to report it in e.g. cluster slots after a restart, before they get a gossip message from the node with pport configured.",0,0,0,0.9871646165847778,0.9941824078559875,0.9945695996284484,0.0,accept,unanimous_agreement
966322285,10536,"yeah, i think given that it's a rather large change we need to do it in 7.2",0,0,0,0.9382487535476683,0.9510434865951538,0.9797057509422302,0.0,accept,unanimous_agreement
966652128,10536,this sounds like a useful thing if nodes in the same cluster are configured with different ports. is this also related to the deployment that uses nat or port forwarding?,0,0,0,0.9825724363327026,0.9803128838539124,0.9813371300697328,0.0,accept,unanimous_agreement
967716947,10536,"naming convention wise, probably either num_elements or numelements(). it looks like min and max are just using camel case, so i suppose numelements.",0,0,0,0.9837860465049744,0.9901395440101624,0.987620174884796,0.0,accept,unanimous_agreement
967717194,10536,"`cluster-myid` is marked as deterministic, so unclear why this is.",0,0,0,0.948945701122284,0.9870269894599916,0.986527144908905,0.0,accept,unanimous_agreement
967717698,10536,"a node should never exist outside of a shard, so i think it makes more sense to server assert here. edit: i see there are some places where the shard map isn't consistent with the individual nodes, so maybe we shouldn't hold this as an invariant, but it would be a nice invariant to have.",0,0,0,0.929102063179016,0.9589800238609314,0.8642402291297913,0.0,accept,unanimous_agreement
967718119,10536,i would also like to see us store the plaintext port. i think i mentioned it in the original port meta data pr that on restart we will not show the correct port for a bit. it would be a good improvement.,1,1,1,0.9192630648612976,0.6488254070281982,0.7287054657936096,1.0,accept,unanimous_agreement
967718487,10536,this comment is inconsistent with the list of allowed characters earlier.,0,0,0,0.8751103281974792,0.974406123161316,0.8670156598091125,0.0,accept,unanimous_agreement
967718897,10536,"in all cases, don't we expect `node->shard_id = shard_id`? so wouldn't the signature of `clusterremovenodefromshard(clusternode *node);` make more sense?",0,0,0,0.9851546883583068,0.995090126991272,0.9940415024757384,0.0,accept,unanimous_agreement
967719856,10536,"this doesn't seem quite right. the master's shard id might have been automatically generated, up on line 433, and will have a random shard_id. the replica will be assigned the random shard_id, but the master may have its id actually set later. generally it seems like we should resolve these shard_ids after we're done loading all of the nodes and we can also do the validation then.",0,0,0,0.955267071723938,0.9917231202125548,0.8199032545089722,0.0,accept,unanimous_agreement
967719955,10536,"would probably be good to add a comment block here, or earlier, defining what the aux fields are.",0,0,0,0.9809735417366028,0.991374671459198,0.9907649755477904,0.0,accept,unanimous_agreement
967720401,10536,"this is weird, if the role is master we issue `cluster failover` to it? shouldn't this this be if the role is slave",-1,-1,-1,0.9852880239486694,0.9890669584274292,0.9880734086036682,-1.0,accept,unanimous_agreement
967833531,10536,"oops. this was originally `if { [regexp ""master"" [r $id role]] == 0 } {` which i suggesting changing to `eq` because it's simpler, but it should of course have been `ne`.",0,0,-1,0.714309573173523,0.5678191184997559,0.9493191242218018,0.0,accept,majority_agreement
969168465,10536,sounds good to me. logged #11260 to track the proposal.,1,1,1,0.9808616042137146,0.810207724571228,0.8963730931282043,1.0,accept,unanimous_agreement
969174657,10536,"it doesn't look like there is a consistent style for macros with parameters in the redis codebase but as far as server.h is concerned, the majority seems to be camel cased. `run_with_period` and `stringify` seem to be the only exceptions. will change to `numelements` next.",0,0,0,0.9770151376724244,0.9937204122543336,0.9832916855812072,0.0,accept,unanimous_agreement
969182307,10536,"this is because a node's shard_id can change over time. for instance, when a node is first introduced to the cluster via `cluster meet`, a random shard_id is generated and assigned to it. later on, an admin might decide to make it a replica of another node and as a result this node will pick up the new primary's shard_id.",0,0,0,0.9814645648002625,0.9932899475097656,0.9908531308174132,0.0,accept,unanimous_agreement
969207452,10536,"right, there is only one place where this invariant doesn't hold and this is on the nodes.conf loading path when a primary node is ""referenced before defined"". i have added serverasserts in all other places. the alternative is to make `clustergetnodesinmyshard` aware of the loading state. it doesn't look very clean to me so i gave it up. let me know if you have a strong preference or other ideas.",0,0,0,0.9689633250236512,0.8487021923065186,0.9668088555336,0.0,accept,unanimous_agreement
969210695,10536,"good catch. make sense. the mental model is that we always remove a member node and if a node is a member of a shard, its shard_id should be equal to the shard's id.",1,1,1,0.951513409614563,0.96523517370224,0.9918586611747742,1.0,accept,unanimous_agreement
969218867,10536,"correct. no. the replica will be inheriting the primary's randomly generated shard_id on line 440 even when the loading logic hasn't encountered the definition for the primary node on line 291 and 456. later on, the loading logic will first hit line 291 where it will find out a `clusternode` has been created already (by line 433). it then sees ""-"" and takes the branch on line 451 to add itself to the shard created by one of its replicas. the primary will not reset its shard_id.",0,0,0,0.9830896854400636,0.9928895235061646,0.9841104745864868,0.0,accept,unanimous_agreement
969230651,10536,will do.,0,0,0,0.9548023343086244,0.9864637851715088,0.9465230703353882,0.0,accept,unanimous_agreement
969231646,10536,duh!,-1,-1,-1,0.8392528295516968,0.9817424416542052,0.4183171689510345,-1.0,accept,unanimous_agreement
970184442,10536,"i don't have a strong preference, we can leave the code.",0,0,0,0.6124125719070435,0.8018152713775635,0.9587748646736144,0.0,accept,unanimous_agreement
973797393,10536,it turns out that `role` prints out more information than just the role so i had to revert back to the regex logic. not sure though why the tests passed all the time in the ci/cd pipeline.,0,0,0,0.9501459002494812,0.9582703113555908,0.967777132987976,0.0,accept,unanimous_agreement
975704797,10536,"any suggestion on the return value from the setter callback? would c_ok/c_err be more preferable? i am essentially using ""boolean"" here.",0,0,0,0.9850749969482422,0.987878143787384,0.9924222826957704,0.0,accept,unanimous_agreement
975725028,10536,"imho boolean is good if the name of the function hints that it's a boolean, such as `isvalidauxchar`, whilst for a setter i think ok/err is better (or void if it can't fail).",0,0,0,0.948612630367279,0.9774488806724548,0.97297203540802,0.0,accept,unanimous_agreement
975735285,10536,make sense. yeah this setter can definitely fail (for malformed values).,0,0,0,0.6593506932258606,0.787900447845459,0.9350646734237672,0.0,accept,unanimous_agreement
977966587,10536,"from yossi's comment, we should drop the shard id from here.",0,0,0,0.9807384610176086,0.9938039779663086,0.9882164597511292,0.0,accept,unanimous_agreement
1318051439,10536,"i see we used to use `addreplylonglong` and now it is `addreplybulklonglong`. and i did not see we mentioned it in the top comment, is this expected? if so, we should update the docs (in the doc its response is integer). [a link]",0,0,0,0.9840677976608276,0.9886367917060852,0.9922021627426147,0.0,accept,unanimous_agreement
1318920454,10536,"no, i think we should revert it back the previous behavior. it was probably unintended.",0,0,0,0.7311221957206726,0.6633773446083069,0.983345091342926,0.0,accept,unanimous_agreement
1319437627,10536,#12561,0,0,0,0.9764917492866516,0.9669987559318542,0.990298867225647,0.0,accept,unanimous_agreement
657080434,9127,"end_id is unused.. bug? also, what happens if the stream has entries 1 thru 10, when 3 and 7 have been xdeleted and i call this function with start=1, end=6? it'll return 1 even though the range isn't continuous",0,0,0,0.5361215472221375,0.7102612257003784,0.8810831904411316,0.0,accept,unanimous_agreement
657081918,9127,"minor: there's already an `streamgetedgeid` (which does the same, but includes tombstone entries) maybe somehow unite them and add `int include_tombstones`?",0,0,0,0.9882130026817322,0.9951462149620056,0.990269422531128,0.0,accept,unanimous_agreement
657085387,9127,not sure i got that part..,-1,-1,0,0.937710165977478,0.5570852756500244,0.6685550808906555,-1.0,accept,majority_agreement
657162977,9127,"that's definitely good idea - initially i used it but the tombs were problematic. otoh, maybe just keep a ""first_id"" at the stream level?",0,1,1,0.630979061126709,0.8730874061584473,0.9352163076400756,1.0,accept,majority_agreement
657172459,9127,"assume a stream with at least one entry, then delete all entries with xdel so length == 0. the offset of the last id will be smaller than the next (and first in the stream) xadd, so it can be used for any id that is leq than the last id.",0,0,0,0.987756609916687,0.9931331276893616,0.9936525821685792,0.0,accept,unanimous_agreement
657828996,9127,"you're very correct, end_id is unused - fixed. after the fix the ""what happens"" will not happen.",0,0,0,0.9816213250160216,0.9467746615409852,0.9743669033050536,0.0,accept,unanimous_agreement
657829721,9127,"rethinking about streamgetedgeid, that would mean bringing into it most of the logic streamiteratorgetid, so maybe i'll just stick with that for now.",0,0,0,0.977672517299652,0.989424467086792,0.9843848943710328,0.0,accept,unanimous_agreement
659747020,9127,"i'm not certain we need / want to create a new encoding type. maybe it is easier / better to just keep using `rdb_type_stream_listpacks` and look at the rdb version as a judgement if these fields should be read or not (pass rdbver to rdbloadobject, like we do for rdbloadmillisecondtime). this is essentially the same encoding format (listpacks and metadata) as before, with a small twist. to the best of my knowledge, all the other tools i know that parse rdb file will refuse loading an rdb file if the version is unknown (rather than ignoring the version and hoping the rdb file will not contain any unknown opcode / type)",0,0,0,0.9385915994644164,0.9756917357444764,0.9674479961395264,0.0,accept,unanimous_agreement
659756324,9127,"we need to move that reading code to above the riogetreaderror check (it checks the error of several reads before making use of the data we read) also, the `cg_offset` variable needs to be a 64 bit type.",0,0,0,0.988129198551178,0.994079887866974,0.9942131638526917,0.0,accept,unanimous_agreement
659838869,9127,i see you documented the `tombstone` argument but didn't add it yet.,0,0,0,0.9881205558776855,0.9899689555168152,0.9888695478439332,0.0,accept,unanimous_agreement
659843754,9127,"the interface and purpose of these two is similar, but the implementation is so much different that i think they can remain separate. on the other hand, having two separate api for a similar purpose, increases the chances someone will use the wrong one by mistake (not noticing the difference, and what's worse, it's likely they won't even notice the bug), so maybe we should unite these into one even if it hosts two different implementations, just so that we force people to notice the flag?",0,0,0,0.7585486769676208,0.709345817565918,0.96822988986969,0.0,accept,unanimous_agreement
659862464,9127,"it looks as if you're missing an `end` argument. but actually in this method the end is the last record in the stream, right? or the doc comment needs an update (and a better explanation of what it does and how it works).",0,0,0,0.9830383062362672,0.9892316460609436,0.9868441820144652,0.0,accept,unanimous_agreement
659866223,9127,"nitpick, i'd rather see here `>0` and `<0`, not `==1` or `==-1` same applies for other cases, i'd rather see `<=0` rather than `<1`. i.e. i'm looking for positive, negative or equal, in relation to 0, not to 1 or -1",0,0,0,0.965133011341095,0.9801825284957886,0.984079658985138,0.0,accept,unanimous_agreement
660309455,9127,"maybe extend that comment to explain why the next entry must exist (because some of the previous checks validated that we're not looking for something in the far future or the past?), and add an assertion?",0,0,0,0.982763409614563,0.990839183330536,0.9884586930274964,0.0,accept,unanimous_agreement
660310264,9127,"why do we return the logical start offset here? i'm looking at all the return values in this function, they're all either `0`, `s->offset`, `s->offset - s->length`, or off by one from the above. i.e. they're all handling special cases. i can't find the one that can actually return a ""random"" offset that's not the head or tail.",0,0,0,0.9783891439437866,0.9426203966140748,0.9858638644218444,0.0,accept,unanimous_agreement
660313799,9127,"maybe you should update the 1,2,3 list of additional tasks this method does in the top comment.",0,0,0,0.9874518513679504,0.9919963479042052,0.9864346981048584,0.0,accept,unanimous_agreement
660314946,9127,"please add a comment that explains what we do here. also, this call includes an iteration (raxseek), are we sure we can afford the extra work / complexity here? isn't that a nested loop?",0,0,0,0.9870360493659972,0.9908411502838136,0.9949656128883362,0.0,accept,unanimous_agreement
660316389,9127,"i don't think you want the `++` to be part of the condition, i'd rather have +1 here and put the increment inside. in the current form (since offset is the last one in the if-else chain) it doesn't cause any harm, but if more options will be added, it can mess up the parsing). nitpick: i vote against line wrapping.",0,0,0,0.9557061195373536,0.965555727481842,0.9103571772575378,0.0,accept,unanimous_agreement
661405741,9127,"so yeah, the only reason for the new type was to avoid passing rdbver around. i changed that per your suggestion.",0,0,0,0.9860553741455078,0.9768478870391846,0.9929674863815308,0.0,accept,unanimous_agreement
661406256,9127,added another call to riogetreaderror so the error message is accurate. fixed the 64b type.,0,0,0,0.986860454082489,0.9887930750846864,0.9936634302139282,0.0,accept,unanimous_agreement
661406550,9127,resolved by removing the comment.,0,0,0,0.9805346131324768,0.9913137555122375,0.9926526546478271,0.0,accept,unanimous_agreement
661406977,9127,doc comment fixed and improved.,0,0,0,0.9679355025291444,0.967766284942627,0.922253966331482,0.0,accept,unanimous_agreement
661407406,9127,i love nitpicks and have adopted your suggestion here and going forward.,1,1,1,0.9800609350204468,0.9887370467185974,0.9945490956306458,1.0,accept,unanimous_agreement
661407644,9127,"comment improved, assertion added.",0,0,0,0.981855034828186,0.940988838672638,0.9902209043502808,0.0,accept,unanimous_agreement
661408105,9127,added a comment to explain - please lmk if it makes sense now.,0,0,0,0.9786728024482728,0.9867860674858092,0.9857192635536194,0.0,accept,unanimous_agreement
661408279,9127,"added 4 to 1,2,3.",0,0,0,0.9818846583366394,0.9938257932662964,0.9920638203620912,0.0,accept,unanimous_agreement
661409783,9127,"added a comment. wrt to extra work, although the iterator is used in the worst-case, it is still a valid concern. i'm not sure how to respond short of trying to benchmark a little. on the other hand, this looks like an argument in favor of keeping 'first_id' as part of the stream struct.",0,0,0,0.6594876050949097,0.844975471496582,0.947240114212036,0.0,accept,unanimous_agreement
661410336,9127,understood and agreed. (also unwrapped line(s)).,0,0,0,0.979034662246704,0.979409158229828,0.7253626585006714,0.0,accept,unanimous_agreement
662191894,9127,i think these line wraps only make the code harder to read. is your screen too narrow? or does your editor forces that on you automatically?,0,0,0,0.9395079612731934,0.7390892505645752,0.8654933571815491,0.0,accept,unanimous_agreement
662611368,9127,"lol - actually considering to move to the mpb 16"" no, but due to legacy considerations, i have a ruler at the 80-character column. will try looking only at the 100 ruler form now on.",0,1,1,0.7117810249328613,0.8930293917655945,0.9682867527008056,1.0,accept,majority_agreement
662721694,9127,"fyi, i noticed a few other places in the diff you had these. imho it just makes the code harder to read..",-1,-1,0,0.905295431613922,0.8300171494483948,0.8441909551620483,-1.0,accept,majority_agreement
663358941,9127,"fyis, regardless of the interface/s question, this also adds a 'first_id' field to the stream struct.",0,0,0,0.988270938396454,0.9940258264541626,0.9945737719535828,0.0,accept,unanimous_agreement
663857303,9127,the two were merged with a boolean flag.,0,0,0,0.9862797260284424,0.991273820400238,0.994128942489624,0.0,accept,unanimous_agreement
663857851,9127,changed the naming to something that will tell that the ids can only be tips,0,0,0,0.986977517604828,0.9927438497543336,0.9906600117683412,0.0,accept,unanimous_agreement
663871606,9127,"p.s. i think you should explain in the top comment / commit comment the reasons why we chose to refactor this function. i.e. it'll also make it clear to the reviewer, that it doesn't change it's outcome (isn't intended to fix a bug).",0,0,0,0.9795763492584229,0.9879751801490784,0.95554119348526,0.0,accept,unanimous_agreement
663872632,9127,don't we need to use the streamiteratorstart anyway? i.e. [code block],0,0,0,0.9871779680252076,0.9940893650054932,0.9932774901390076,0.0,accept,unanimous_agreement
663874720,9127,i think the check for skip_tombstones to be true is excessive [code block],0,0,-1,0.8628173470497131,0.9836392998695374,0.7567588090896606,0.0,accept,majority_agreement
664070694,9127,added to top.,0,0,0,0.9792898893356324,0.9857565760612488,0.9934072494506836,0.0,accept,unanimous_agreement
664072280,9127,"i don't think so - if we don't want tombstones included, and the stream's length is 0 then we don't need to iterate and can jump to min/max response.",0,0,0,0.9808805584907532,0.9714312553405762,0.9716121554374696,0.0,accept,unanimous_agreement
664072899,9127,:facepalm: fixed,0,0,-1,0.977275550365448,0.9799723029136658,0.9871719479560852,0.0,accept,majority_agreement
664269377,9127,"ohh, ok. i think this form is easier to understand, but also let's add a comment (both to explain what that block does, and also the condition) [code block]",0,0,0,0.9164856672286988,0.6853579878807068,0.962433397769928,0.0,accept,unanimous_agreement
716251444,9127,are you sure argc shouldn't be 6?,0,0,0,0.9857890009880066,0.9811218976974488,0.9888581037521362,0.0,accept,unanimous_agreement
716627463,9127,"thanks, you're of course right.",1,1,1,0.6924245953559875,0.9075540900230408,0.90193772315979,1.0,accept,unanimous_agreement
728753695,9127,let's mention that in the top comment for reviewers that won't bother to read the code? i.e the fact that we decided to keep using the old `rdb_type_stream_listpacks=15` and conclude if it includes the new metadata by looking at the rdb version. this can possibly cause some issues to other parsing libraries?,0,0,0,0.9835147857666016,0.994127631187439,0.9924450516700744,0.0,accept,unanimous_agreement
728760809,9127,"this would also set the first_id if the stream has only tombstones, right? that's desired, right?",0,0,0,0.988792359828949,0.9940833449363708,0.9954664707183838,0.0,accept,unanimous_agreement
728775347,9127,"should this limitation be more clearly noted in the top comment? if not, then at least in the redis.io documentation of this feature, right?",0,0,0,0.9885130524635316,0.9923993945121764,0.9883151054382324,0.0,accept,unanimous_agreement
728782639,9127,the top comment of the pr doesn't list these command argument changes.,0,0,0,0.9790153503417968,0.9785467982292176,0.9899336695671082,0.0,accept,unanimous_agreement
728786382,9127,"please mention the new argument for xsetid in the top comment, and also mention it is used in propagation (aof / replicas)",0,0,0,0.9868828654289246,0.9918811917304992,0.9952257871627808,0.0,accept,unanimous_agreement
728788777,9127,mention in the top comment that xinfo was extended.,0,0,0,0.9858659505844116,0.992517113685608,0.9946474432945251,0.0,accept,unanimous_agreement
728790793,9127,is that the only way to get the lag? is it only an introspection feature? maybe we want to add some xlag command?,0,0,0,0.9674431681632996,0.9941253662109376,0.9907820820808412,0.0,accept,unanimous_agreement
728816124,9127,why did you have to change these indexes? is it because the reply is a map and the test ignores it and is coupled with a specific indexes? lets see of we can improve.,0,0,0,0.9811455607414246,0.984321355819702,0.99209326505661,0.0,accept,unanimous_agreement
744757752,9127,"touched the top, but i don't about other parsing libs... maybe this should be changed to a new encoding?",0,0,0,0.9658024907112122,0.8801930546760559,0.9883667826652528,0.0,accept,unanimous_agreement
744762716,9127,"i guess it'll be the safe thing to do.. we probably won't regret changing the encoding, but there is a chance we'll regret not doing that...",-1,0,0,0.718769907951355,0.5680246353149414,0.598853588104248,0.0,accept,majority_agreement
744764551,9127,"yes, if the stream had only tombstones before the new entry is appended, this will fire and is desired.",0,0,0,0.988264799118042,0.9899667501449584,0.9930444359779358,0.0,accept,unanimous_agreement
744777334,9127,"agreed, both should happen. adding to the top.",0,0,0,0.9790980815887452,0.9837130308151244,0.9633487462997437,0.0,accept,unanimous_agreement
744796568,9127,addressed.,0,0,-1,0.9813690185546876,0.9869421124458312,0.8090953826904297,0.0,accept,majority_agreement
744797059,9127,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
744800103,9127,"yep, that's the only way to get it. yep, it's only for introspection/monitoring (potentially triggering a client-side scaling event). an xlag command would be sugar-syntax for `xinfo`, so i'm not sure the functionality deserves the api bloat.",0,0,0,0.9110501408576964,0.8775691390037537,0.9458346962928772,0.0,accept,unanimous_agreement
744801870,9127,"are you talking about resp3 tests? :) sure, that was the hardest part of this pr (aligning the indices)... oh tcl wizard, please provide guidance for improvement.",1,1,1,0.986828863620758,0.9959108829498292,0.9919153451919556,1.0,accept,unanimous_agreement
744985895,9127,"ok, i'll go with a new encoding. should i also revert, in this case, the changes i made to carry rdbver into rdbload? iirc this was the only reason to do so.",0,0,0,0.9837563037872314,0.9849089980125428,0.9881056547164916,0.0,accept,unanimous_agreement
745715438,9127,"sorry for the late response. these `rdbver` changes don't cause harm and may be useful in the future, but i suppose it's better to revert rather than introduce something we don't actually need.",-1,-1,-1,0.9866214990615844,0.9876059293746948,0.9900640845298768,-1.0,accept,unanimous_agreement
745736778,9127,"yes, we can do one of two things (which i think we must apply to all these tests that mess with xinfo output and hard coded indexes). 1. use `hello 3` and then we can process a map. the downside is that we may want to change protocol before and after each xinfo call, so that the rest of the test is in resp2 (although i don't think it's a must). 2. pass the return value of xinfo though some zipping function that will translate it to a dict 2 is basically this: [code block]",0,0,0,0.8680681586265564,0.984348475933075,0.9825316071510316,0.0,accept,unanimous_agreement
757790589,9127,sure - resolved via 6ea72d188,0,0,0,0.9856821894645692,0.9887059926986694,0.9909372925758362,0.0,accept,unanimous_agreement
757934586,9127,"resolved via 72a101513, without having to convert the list as tcl allows it :)",1,1,1,0.5931887030601501,0.9544488787651062,0.5251700282096863,1.0,accept,unanimous_agreement
759803216,9127,it seems that `xsetid` is forgotten in redis-doc.,0,0,0,0.9780356884002686,0.9913622736930848,0.9903082251548768,0.0,accept,unanimous_agreement
759833512,9127,this eliminates the need to create `min_id` and `max_id`. [code block],0,0,0,0.9890568852424622,0.9931899905204772,0.9951950907707214,0.0,accept,unanimous_agreement
759864397,9127,whether the following `else` also need to determine `!si->skip_tombstones`.,0,0,0,0.9859912991523744,0.9934810400009156,0.9928585290908812,0.0,accept,unanimous_agreement
760329721,9127,rdbver is unused,0,0,0,0.9842304587364196,0.9847756028175354,0.9927042722702026,0.0,accept,unanimous_agreement
760337997,9127,^,0,0,0,0.4896445572376251,0.947323441505432,0.970213770866394,0.0,accept,unanimous_agreement
760342415,9127,can you please add `serverassert(cg->offset == 0);` ?,0,0,0,0.9874529242515564,0.9945632815361024,0.9963248372077942,0.0,accept,unanimous_agreement
760342700,9127,typo pffset -> offset,0,0,0,0.98774391412735,0.9923034906387328,0.9916511178016664,0.0,accept,unanimous_agreement
760434930,9127,"maybe rename to `streamestimatedistancefromfirsteverentry` and please document the 4 return option (0, offset, s->offset - s->length, s->offset - s->length +1) and in which cases each is returned",0,0,0,0.9856799840927124,0.9936659932136536,0.9947463274002076,0.0,accept,unanimous_agreement
760438847,9127,i think we can revert the change in verifydumppayload,0,0,0,0.988393485546112,0.9750670194625854,0.9905248284339904,0.0,accept,unanimous_agreement
760439896,9127,"maybe rename to `entries_added` and the one in cg to `entries_consumed` if yo do, also the offset token in xgroup setid",0,0,0,0.9879873991012572,0.9954181909561156,0.994238018989563,0.0,accept,unanimous_agreement
760446810,9127,redundant,0,-1,0,0.9539549946784972,0.8220753073692322,0.8288995623588562,0.0,accept,majority_agreement
760928761,9127,"i feel that `streamiscontiguousrange` does not reflect the true usefulness of this method, perhaps `streamiscontaintombstonerange` is more appropriate, 8-).",0,0,0,0.9661993980407716,0.9877869486808776,0.9858185648918152,0.0,accept,unanimous_agreement
760943737,9127,should it be better? [code block],0,0,0,0.9877248406410216,0.9929041266441344,0.9919525980949402,0.0,accept,unanimous_agreement
760987970,9127,"`xgroup setid mystream mygroup 0 1` will cause `last_id` to be zero, and `offset` is 1. i'm confused about the `offset` param in `xgroup setid`, how do users know what the `offset` of `last_id`.",0,0,0,0.8081287741661072,0.6559862494468689,0.7081723213195801,0.0,accept,unanimous_agreement
762572603,9127,"yep. this is ""by the original design"" as the command is only supposed to be used internally for replication. that said. i'm not sure it shouldn't have a man page with a proper warning saying don't use it :)",1,1,1,0.8071522116661072,0.9865515232086182,0.9696808457374572,1.0,accept,unanimous_agreement
762574803,9127,"i think we wanna document it (same as other commands invented for the purpose of aof). side note: we're gonna delete rewriteappendonlyfilerio and friends soon, which should make it unneeded, but i do think there are other tools that will want to use such commands. e.g. a tool that parses an rdb file and translates it to a stream of commands.",0,0,0,0.9814119935035706,0.9830049276351928,0.9845103621482848,0.0,accept,unanimous_agreement
762589026,9127,"`entries_added` could make sense in place of offset, but `entries_consumed` is misleading. it does count the number of xreads, but it is initialized to the `offset/entries_added` opportunistically. wdut?",0,0,0,0.9586576223373412,0.993192732334137,0.9581835865974426,0.0,accept,unanimous_agreement
762590224,9127,thanks - resolved via 5165321a4,0,1,0,0.5116010904312134,0.8934633135795593,0.8425614833831787,0.0,accept,majority_agreement
762590266,9127,"agreed, resolved via 5165321a4",0,0,0,0.9810588955879213,0.9878437519073486,0.9790841341018676,0.0,accept,unanimous_agreement
762590331,9127,:person_facepalming: :man_bowing::man_bowing::man_bowing: resolved via 5165321a4,0,0,0,0.9392353892326356,0.9777517914772034,0.9894463419914246,0.0,accept,unanimous_agreement
762590375,9127,"yep, forgot that leftover. resolved via 5165321a4",0,0,0,0.9801007509231568,0.9785994291305542,0.972301185131073,0.0,accept,unanimous_agreement
762590387,9127,resolved via 5165321a4,0,0,0,0.9866330623626708,0.9909467697143556,0.9954953193664552,0.0,accept,unanimous_agreement
762590414,9127,please see the attempt to resolve via 5165321a4,0,0,0,0.9858794808387756,0.9852772355079652,0.9952982068061828,0.0,accept,unanimous_agreement
762590428,9127,resolved via 5165321a4,0,0,0,0.9866330623626708,0.9909467697143556,0.9954953193664552,0.0,accept,unanimous_agreement
762590473,9127,i tried improving upon your suggestion :) see 5165321a4,1,1,0,0.9597636461257936,0.9938802719116212,0.599585771560669,1.0,accept,majority_agreement
762590492,9127,definitely less verbose - resolved via 5165321a4,0,0,0,0.9795674085617064,0.9228188395500184,0.985234558582306,0.0,accept,unanimous_agreement
762718705,9127,comments should also be reverted.,0,0,0,0.9698840975761414,0.98584645986557,0.9609859585762024,0.0,accept,unanimous_agreement
762858661,9127,should the return value be: 0: no tombstone. 1: contains tombstone. now it's opposite.,0,0,0,0.9661974906921388,0.989565134048462,0.9920572638511658,0.0,accept,unanimous_agreement
804737283,9127,resolved in redis-doc,0,0,0,0.9855115413665771,0.9901387691497804,0.9923230409622192,0.0,accept,unanimous_agreement
804738800,9127,"resolved. they don't have to know - they can put any positive integer there, and the logic sanitizes it (i.e. it must be the before first, first or last ids).",0,0,0,0.9836312532424928,0.9706838130950928,0.9927557110786438,0.0,accept,unanimous_agreement
804739597,9127,"changed to entries_added and entries_read. note: entries_read is only correct, name-wise, in a perfect world.",0,0,0,0.6371672749519348,0.9934492707252502,0.9903178215026855,0.0,accept,unanimous_agreement
804740173,9127,"resolved, thanks.",1,1,1,0.827928364276886,0.8331229090690613,0.604794979095459,1.0,accept,unanimous_agreement
804740468,9127,"changed the name again, rather than the return.",0,0,0,0.9743471741676332,0.9897837042808532,0.979379415512085,0.0,accept,unanimous_agreement
808099614,9127,tyop enries,0,0,0,0.9876513481140136,0.9179487824440002,0.993428647518158,0.0,accept,unanimous_agreement
808166448,9127,what about simply: [code block],0,0,0,0.984667181968689,0.9916041493415833,0.9883805513381958,0.0,accept,unanimous_agreement
808170724,9127,"maybe move this block before `copy start id, if given, or default to 0-0`?",0,0,0,0.9873299598693848,0.9951120018959044,0.9943162798881532,0.0,accept,unanimous_agreement
808173833,9127,"1. it makes more sense to check if stream range **has** tombstones, rather than if it doesn't (i know it used to be like that, what changed?) 2. for a clean api please add `streamid *end` (which will always be passed as null for now)",0,0,0,0.9824519753456116,0.9929713606834412,0.9888622164726256,0.0,accept,unanimous_agreement
808175702,9127,"please start with `valid = 0` (i know it's gonna take more lines, but it's gonna be clearer",0,0,0,0.9705490469932556,0.9803855419158936,0.990715742111206,0.0,accept,unanimous_agreement
808191595,9127,"why do you check `cg->entries_read` here? seems like `if (streamrangedoesnotcontaintombstone(s,&cg->last_id))` is enough, no?",0,0,0,0.9851755499839784,0.9937939643859864,0.993723690509796,0.0,accept,unanimous_agreement
808196861,9127,"maybe it's to ensure that cg->last_id is not 0-0..? in which case maybe it's better to: ``` if (!s->entries_added) { /* the lag of a newly-initialized stream is 0. */ lag = 0; } else if (streamideqzero(&cg->last_id)) { serverassert(cg->entries_read == 0); if (streamrangedoesnotcontaintombstone(s,null)) { /* the group is at 0-0 of a non-fragmented stream. */ lag = s->length; } else { valid = 0; } } else if (streamrangedoesnotcontaintombstone(s,&cg->last_id)) { serverassert(cg->entries_read != 0); /* no fragmentation ahead means that the group's logical reads counter * is valid for performing the lag calculation. */ lag = s->entries_added - cg->entries_read; } else { /* attempt to retrieve the group's last id logical read counter. */ uint64_t entries_read = streamestimatedistancefromfirsteverentry(s,&cg->last_id); if (entries_read) { /* a valid counter was obtained. */ lag = s->entries_added - entries_read; } else { valid = 0; } }",0,0,0,0.9862142205238342,0.992295265197754,0.9912670254707336,0.0,accept,unanimous_agreement
808200391,9127,"so after our discussion, an ""invalid"" group->entries_read is uint64_max rather than 0, right?",0,0,0,0.9866642951965332,0.9660828113555908,0.9915481209754944,0.0,accept,unanimous_agreement
808203377,9127,"i feel that we should add the entriesadded modifier in all commands that can take it (same with max_deleted_entry_id, i.e. add maxdeletedentryid)",0,0,0,0.9809482097625732,0.9875132441520692,0.9887689352035522,0.0,accept,unanimous_agreement
811703210,9127,resp3 says: [code block],0,0,0,0.9888837337493896,0.991851270198822,0.9945295453071594,0.0,accept,unanimous_agreement
811705841,9127,why was this removed?,0,0,0,0.9225016236305236,0.9856475591659546,0.990842342376709,0.0,accept,unanimous_agreement
811709494,9127,the var type is still signed. but maybe our decision to use unsigned was wrong. maybe instead we should use llong_min as the special value?,0,0,0,0.95396226644516,0.979714334011078,0.9897055625915528,0.0,accept,unanimous_agreement
812702134,9127,i think that it should be ok to always use `long long` (i.e. the member `entries_read` of the cg struct should be `long long` rather than `uint64_t`) and have `-1` denote that the value is invalid. llong_max is 9223372036854775807 which is way more than enough. so we need to revert all related changes in networking.c,0,0,0,0.9795539379119872,0.9924283623695374,0.9800292253494264,0.0,accept,unanimous_agreement
812702691,9127,what was wrong with the previous version of the block?,0,0,0,0.7661957144737244,0.9911901950836182,0.9696379899978638,0.0,accept,unanimous_agreement
812703049,9127,same here,0,0,0,0.982987642288208,0.9628711938858032,0.99204421043396,0.0,accept,unanimous_agreement
812703881,9127,maybe also `#define stream_cgroup_invalid_entries_read -1`,0,0,0,0.9868735671043396,0.995140552520752,0.9946095943450928,0.0,accept,unanimous_agreement
812705449,9127,"is this the first-ever id? or the current first? i.e. if i add 100-0 and 100-1 and then xdel 100-0 what will be s->first_id? if it's 100-1 i think it should just be called ""first-id"" and not ""recorded-first-entry-id""",0,0,0,0.9882964491844176,0.9908854365348816,0.9908939599990844,0.0,accept,unanimous_agreement
812708527,9127,"does that mean that resp3 does not support anything bigger than llong_max as a ""number""?",0,0,0,0.978783130645752,0.9851797819137572,0.9891387820243835,0.0,accept,unanimous_agreement
812710660,9127,but maybe with this nitpick: [code block],0,0,0,0.9843090772628784,0.99078369140625,0.9826166033744812,0.0,accept,unanimous_agreement
812800319,9127,"yes, that's how it looks like in the spec. of course since that's just a string, you can put bigger values, but not sure what the client will do with that.",0,0,0,0.9766802191734314,0.9558196663856506,0.9869304895401,0.0,accept,unanimous_agreement
812883018,9127,sure :),1,1,0,0.96258282661438,0.984525740146637,0.9888246655464172,1.0,accept,majority_agreement
812922044,9127,"1. i honestly don't remember... last time i added the ""not"" instead of switching the reply's type",-1,-1,0,0.8946681618690491,0.9598568081855774,0.900439441204071,-1.0,accept,majority_agreement
812923320,9127,"it would be 100-1, and it should be call ""first-id"" in the info but we already have another ""first-id"" there (the two are supposed to be identical).",0,0,0,0.9880173206329346,0.9932414293289183,0.991798996925354,0.0,accept,unanimous_agreement
812924816,9127,i realized it was redundant given s->first_id.,0,0,0,0.978440284729004,0.988061785697937,0.9812925457954408,0.0,accept,unanimous_agreement
812925932,9127,yep.,0,0,0,0.9806315898895264,0.8970574736595154,0.9245200753211976,0.0,accept,unanimous_agreement
1436902615,9127,"entries_read can be `scg_invalid_entries_read`, which is -1. and here `rdbsavelen` take a `uint64_t` input, so what is actually written here is another value, such as 18446744073709551615 and then when we load this `entries_read` back, we will convert it from `uint64_t` to `long long`, it just happened to be -1 again, so everything was fine. do we need to make changes here?",0,0,0,0.835075318813324,0.9905070066452026,0.99155992269516,0.0,accept,unanimous_agreement
1436941638,9127,"recently pointed out to me that rm_savesigned has a similar problem (and that rdb_module_opcode_sint is unused). the implication is that unlike rdbencodeinteger (used for values of keys), these are less efficient in their file size consumption. fixing these would mean a new rdb format, and for new versions to be able to properly handle the old one. since unstable already has an rdb version bump, we can try tackling these two issues if we want. not a real priority imho.",0,0,0,0.949385941028595,0.9680794477462769,0.8548460602760315,0.0,accept,unanimous_agreement
1436987900,9127,"the most recent one was in #11099, released in 7.2. yes, it is not a real priority, i have some spare time these day, just ping me if you want me to fix it",0,0,0,0.921762764453888,0.8999494314193726,0.9754056930541992,0.0,accept,unanimous_agreement
1436990615,9127,the main benefit for that would be disk space reduction for modules that heavily use rm_savesigned. if you have time you can try to see if this gets complicated (including tests for backwards compatibility).,0,0,0,0.9797077178955078,0.982260525226593,0.9910764694213868,0.0,accept,unanimous_agreement
783855121,10108,i suggest we allow `key_spec_index` to be 0 (and still interpret it as -1 when type isn't key). this will allow it to be left out in compound literals such as this one. all the other fields are zero or null by default so it's fine to leave them out already. only this one needs to be set to -1 in a lot of places.,0,0,0,0.9810949563980104,0.9945216178894044,0.9906390905380248,0.0,accept,unanimous_agreement
783857530,10108,"a single key at a fixed position seems to be very common. perhaps we can allow `find_keys_type` to be left out in this case and let it default to range {0,1,0}?",0,0,0,0.9861122965812684,0.9924522042274476,0.9914844632148744,0.0,accept,unanimous_agreement
783971585,10108,"following my own suggestion, i added commit ""allow .key_spec_index = -1 to be omitted"". i'll revert it if it's not acceptable.",0,0,0,0.9763908386230468,0.9889870285987854,0.9930578470230104,0.0,accept,unanimous_agreement
783990765,10108,i see no benefit whatsoever with this approach. the macros and types all disappear at compile time anyway. i suggest removing the v1 indirection. did i miss anything?,0,0,0,0.8756240606307983,0.9643445014953612,0.9246702194213868,0.0,accept,unanimous_agreement
784000097,10108,an alternative to listing all the flags here is to `#define _redismodule_cmd_key_next (1<<5)` and then use `_redismodule_cmd_key_next - 1` as the set of all flags. what's the reviewer's preference?,0,0,0,0.987586259841919,0.9942025542259216,0.9944962859153748,0.0,accept,unanimous_agreement
784163108,10108,how can we maintain backward compatibility if we don't version the struct in redismodule.h,0,0,0,0.9843217134475708,0.9937449097633362,0.9856436252593994,0.0,accept,unanimous_agreement
784163939,10108,there should be a `version` field at the beginning of each struct,0,0,0,0.98713219165802,0.99384742975235,0.9948025941848756,0.0,accept,unanimous_agreement
784168308,10108,"maybe we really don't need that #define (it's useful only if the writer is agnostic to the version and just passes the struct to the core. see `test_clientinfo`: if we didn't have that #define, the module would have to update the code in case it compiled with a newer redismodule.h, which has v2)",0,0,0,0.979642391204834,0.9945452213287354,0.9779728651046752,0.0,accept,unanimous_agreement
784169668,10108,"in our case we fill the structs, so we have to be aware of the version we're using (if we want to work with a newer redismodule.h we would have to update the module code + make sure we work with a new-enough server)",0,0,0,0.986236810684204,0.987589716911316,0.9914186000823976,0.0,accept,unanimous_agreement
784169956,10108,"but anyway, we must provide the version of each struct we pass to redis",0,0,0,0.9862099289894104,0.9909114241600036,0.9935247898101808,0.0,accept,unanimous_agreement
784184416,10108,"when we add v2, we can rename the structs to xxxv1 and add that `#define redismodulecommandinfo redismodulecommandinfov1`, can't we?",0,0,0,0.987503945827484,0.9943963289260864,0.994798183441162,0.0,accept,unanimous_agreement
784187983,10108,"if the same api should be able to accept both infov1 and infov2 structs, we need something inside the struct to tell the version, e.g. something like this: (don't we?) [code block]",0,0,0,0.9171371459960938,0.9937047362327576,0.9930311441421508,0.0,accept,unanimous_agreement
784190107,10108,either that or the api will take `void*` and assume the first 8 bytes are the `version`,0,0,0,0.9883838891983032,0.993891716003418,0.9927797913551332,0.0,accept,unanimous_agreement
784190153,10108,... like the event structures which have a `1` inside them: [code block],0,0,0,0.9827088117599488,0.9892317652702332,0.9851099252700806,0.0,accept,unanimous_agreement
784198055,10108,"if we add a version tag inside the struct, i think we only need it for the top-level struct redismoduleinfo. everything inside it can be assumed to be v1, don't you think? another thing: do we still want to support v1 in the future, so v2 is opt-in? if yes, then we can let redismoduleinfo always be v1 and use the new name redismoduleinfov2 for the new one...?",0,0,0,0.9782999753952026,0.9871702790260316,0.9719783663749696,0.0,accept,unanimous_agreement
785564116,10108,"the version tag makes it a bit awkward to write info literals, especially if we need a version tag in every struct in a nested struct literal. an alternative is to add another api when we need to add more info (e.g. `rm_setcommandmoreinfo`). it's slightly ugly but it's very clear in terms of backward compatibility and of what's availability in each redis version.",-1,-1,-1,0.683613657951355,0.9419551491737366,0.9077703952789308,-1.0,accept,unanimous_agreement
785766304,10108,"i do agree that any struct we take from the user should have a version field as a first field, and that in this case it should only be present in the top level struct we take as pointer, and probably not in any of the nested structs. as for the define, the only reason to use a define is if we want modules to by default use a struct name without version, so then when they compile with a newer version of the header, they'll implicitly use the new struct and won't need to manually edit their code to use the new one (change ""v1"" suffix to ""v2"" suffix). in that case, they're also expected to populate the version field with some ""dynamic"" define (e.g. `redismodule_type_method_version`). the downside of this is that as soon as the module compiles with the new header, it is automatically bound to the new struct and looses backwards compatibility with old redis versions. if we don't go with that `define` approach, then a module will only move to `v2` when there's a field it wants to use, that didn't exist in v1. i think in this case we should model this after other input structs we get (i.e. `redismoduletypemethods`, not `redismoduleclientinfo`) wdyt?",0,0,0,0.9668585658073424,0.9918761253356934,0.9827576279640198,0.0,accept,unanimous_agreement
785845296,10108,"fair enough. it's a good compromise. observations about redismoduletypemethods: * redismoduletypemethods has a version field. * redismoduletypemethods has no version in it's name (defined nor typedeffed). * the struct pointer parameter has type `void *` (in `rm_createdatatype`). * the version macro is changed ""synchronistically"" when redis is updated. ""syncronistically"" [code block] * `rm_createdatatype` is backward compatible with modules compiled with older versions of this struct, because the size of the struct doesn't matter. the version field is checked before fields added in version x are accessed. * `rm_createdatatype` is forward compatible. future (unknown) versions are accepted and their fields simply have no effect on older redis. version checks use `>=` and allow the version to be any number > 0. the forward/backward compatibilty relies on the fact that there may be unused/unknown fields in the end of the struct. this doesn't work for arrays of structs such as redismodulecommandkeyspec (which are packed side-by-side in memory) but it works for the top-level redismodulecommandinfo, which is what matters. i think we shall adopt the this approach, apart from the type `void *` which i don't see the point of.",0,1,1,0.7004692554473877,0.6050442457199097,0.9750887751579284,1.0,accept,majority_agreement
785854504,10108,"ok. so the top level struct will be backwards compatible like the datatype struct, and any nested structs in it can probably be handled using the version field of the top level one. if / when we made changes to any of these structs, i guess we can always decide to keep the old struct definitions if we want new modules, that use the new header, keep using the old api. or we can force them to use the new one. either way, redis has a way to be abi compatible with old ones. i didn't invest enough time thinking about this.. hope i'm not wrong. maybe we can make an experiment later (inventing some additional field and see what it leads to)",0,1,0,0.9338860511779784,0.7895930409431458,0.5277522802352905,0.0,accept,majority_agreement
785856351,10108,should be renamed to `tips`,0,0,0,0.9863459467887878,0.9921833872795104,0.9951481223106384,0.0,accept,unanimous_agreement
786084252,10108,"yes, when your tips pr is merged, i'll update this.",0,0,0,0.9818084836006165,0.9786649346351624,0.9941977262496948,0.0,accept,unanimous_agreement
786855411,10108,done. should and i'll revert.,0,0,0,0.8847278356552124,0.9644439220428468,0.979191243648529,0.0,accept,unanimous_agreement
786856678,10108,"done: version field added, defines for struct names removed.",0,0,0,0.9890540838241576,0.9918882250785828,0.9928523898124696,0.0,accept,unanimous_agreement
789010605,10108,"just to make sure we are on the same page: 1. in a year from now we decide that we need some `newmember` in `keyword` in `redismodulecommandkeyspec` 2. we need to define another struct `redismodulecommandkeyspec2` with `newmember` 3. we need to add `redismodulecommandkeyspec *key_specs2` to `redismodulecommandinfo` (q1: we decided that `redismodulecommandinfo` can only expand, we can't change the already-existing content right?) 4. now let's imagine two situations: - module that compiled with old redismodule.h runs with new server: the server takes the struct from user (where the last accessible member is `args`), sees the version is `1` and never tries to access `key_specs2` - module that compiled with new redismodule.h runs with old server: the module passes a struct with `key_specs2` and version `2` but the server is only aware of version `1` so it's not aware that there's anything after `args` questions/thoughts that require your reply: 1. q1 above ^ 2. is the scenario above describes our design? 3. maybe we should document it in the code? to never modify `redismodulecommandinfo`, just add stuff if needed",0,0,0,0.9225075840950012,0.9917209148406982,0.9927027225494384,0.0,accept,unanimous_agreement
789014138,10108,"maybe in order to encourage people to stop using the legacy range spec we should fail this api if rm_createcommand was called with anything other than `0,0,0` for the range spec? it will also simplify this code block ^",0,0,0,0.969458281993866,0.6531176567077637,0.98823082447052,0.0,accept,unanimous_agreement
789014288,10108,wdyt?,0,-1,0,0.9751594066619872,0.614355742931366,0.9878125786781312,0.0,accept,majority_agreement
789014993,10108,redundant empty line,0,0,0,0.9393986463546752,0.8577157258987427,0.6371645927429199,0.0,accept,unanimous_agreement
789017981,10108,pr merged,0,0,0,0.9731366038322448,0.9789121747016908,0.9825725555419922,0.0,accept,unanimous_agreement
789018465,10108,we also have more flags now [a link],0,0,0,0.9805261492729188,0.9859306812286376,0.9952019453048706,0.0,accept,unanimous_agreement
789018958,10108,thanks,1,0,1,0.6094269156455994,0.5400217771530151,0.8643599152565002,1.0,accept,majority_agreement
789022434,10108,what's the purpose of that `0`?,0,0,0,0.9788383841514589,0.9891936182975768,0.991641640663147,0.0,accept,unanimous_agreement
789023010,10108,debug print?,0,0,0,0.9893010258674622,0.9794915914535522,0.992717146873474,0.0,accept,unanimous_agreement
789024675,10108,actually now xadd has a real tip: nondeterministic_output so we don't have to fake them anymore,0,0,0,0.9832062125205994,0.9760254621505736,0.7671733498573303,0.0,accept,unanimous_agreement
789074780,10108,"if keyspecs are provided in the info struct, i think it makes sense to require legacy (0,0,0). otherwise, info doesn't touch keyspecs and then i don't think we should fail.",0,0,0,0.980591118335724,0.9832491874694824,0.9884589314460754,0.0,accept,unanimous_agreement
789078482,10108,"oh, i added it intentionally. i think the following comment and code are better separated from the start of the function... but i can delete it the empty line if you prefer.",0,0,0,0.982187807559967,0.9578994512557985,0.9845022559165956,0.0,accept,unanimous_agreement
789079941,10108,"yes, i'm handling them in my merge conflict right now.... :confounded:",-1,-1,-1,0.9824200868606568,0.9835166335105896,0.9953796863555908,-1.0,accept,unanimous_agreement
789082683,10108,"it's zeroed keyspec marking the end of the keyspec array. this style is used for other arrays too. i though you introduced this style(!?!?)! [edit] oh *that* 0 on line 52.. it's to say that all other fields are zeroed out, i think. there was some gcc warning without this 0, iirc.",0,0,-1,0.8753302097320557,0.3918976783752441,0.6912293434143066,0.0,accept,majority_agreement
789092745,10108,"maybe i misunderstood that `if` so what's you're saying is that we will fail if: 1. user used the legacy range in rm_createcommand (i.e. not 0,0,0); and 2. user gave key specs in rm_setcommandinfo is that true? if so, do we already have that check in the code? other than that i guess you're right... if user used the legacy range and just wants to set the summary or something, we should not fail it",0,0,0,0.8586915731430054,0.9508070945739746,0.9640617370605468,0.0,accept,unanimous_agreement
789093960,10108,interesting... i always thought the default behavior of a partial struct initialization is to zero out everything else,0,0,1,0.6397548913955688,0.6260337233543396,0.7698732018470764,0.0,accept,majority_agreement
789140689,10108,"i'm not sure i understand everything (short in time), but i'd like to raise this concern (which we did discuss in the past). a new module is compiled with a new redismodule.h, but that module wants to still be abi compatible with old redis versions. so it registers its commands with the old api, and then calls the new one only if it's non-null. this module will still wanna pass the legacy key-spec to the initial command registration.",0,0,0,0.9590286016464232,0.8987703323364258,0.8611477613449097,0.0,accept,unanimous_agreement
789154911,10108,the compiler does zero all the uninitialized fields. and it does also issue a warning. but our makefile disables it `-wno-missing-field-initializers`,0,0,0,0.9882875084877014,0.993790566921234,0.9943337440490724,0.0,accept,unanimous_agreement
789186438,10108,"that's what the pr does now. (the if statement here just checks that setcommandinfo hasn't been called before for the same command, mainly to avoid freeing the old allocated info.) agree? if yes, resolve?",0,0,0,0.98362398147583,0.9901276230812072,0.9919211864471436,0.0,accept,unanimous_agreement
789187707,10108,"yes, good catch ;)",1,1,1,0.989376425743103,0.9957565665245056,0.9866439700126648,1.0,accept,unanimous_agreement
789457734,10108,"ok, resolved (for some reason the ""resolve"" button disappeared.. i can only comment)",0,0,0,0.976690709590912,0.9177781343460084,0.9536213278770448,0.0,accept,unanimous_agreement
789458127,10108,maybe we want to add that -w to the modules' makefile?,0,0,0,0.9869306087493896,0.9948200583457948,0.992730677127838,0.0,accept,unanimous_agreement
789527720,10108,"it's pretty hard to debug why a commandinfo is invalid, so some form of debug log would be helpful for module developers. is calling `serverlog(ll_debug, ""description of what's invalid"")` from validatecommandinfo a good idea?",0,0,0,0.8903608918190002,0.845247209072113,0.9672605991363524,0.0,accept,unanimous_agreement
789712822,10108,debug logging added as described.,0,0,0,0.988318145275116,0.9861533641815186,0.9927819967269896,0.0,accept,unanimous_agreement
790145453,10108,what's that? i don't see any reference to it in docs or code. actually i also don't see any reference to bs_invalid. are you just trying to avoid a value of 0 being used by mistake?,0,0,0,0.88938307762146,0.7622556090354919,0.959339439868927,0.0,accept,unanimous_agreement
790145728,10108,"since all this text doesn't go to the documentation anyway, maybe we should avoid duplicating it (could easily get outdated), and instead just add a comment that refers to server.h? or do we thing it's very valuable for someone who copied this header file into his module?",0,0,0,0.977194368839264,0.9900195598602296,0.9854088425636292,0.0,accept,unanimous_agreement
790146443,10108,"so pretty soon, we'll add the reply schema ([a link] increment the version and add one more field at the end f the struct? similarly, we can also add fields in any other struct, like redismodulecommandarg",0,0,0,0.974353849887848,0.9846241474151612,0.9938602447509766,0.0,accept,unanimous_agreement
790146677,10108,let's mention all these details in the pr top comment.,0,0,0,0.9834374189376832,0.987737774848938,0.9951338171958924,0.0,accept,unanimous_agreement
790147009,10108,maybe mention that this can replace the replace the arity check inside the module call. and that 0 means no checks,0,0,0,0.9864845871925354,0.993829071521759,0.9913536906242372,0.0,accept,unanimous_agreement
790147509,10108,"isn't it much easier for the module to ""decleratively"" provide one space separated string? also a bit more consistent with the command flags for rm_createcommand",0,0,0,0.977687656879425,0.9902713298797609,0.9927594661712646,0.0,accept,unanimous_agreement
790147693,10108,"we need to document how this is related to rm_iskeyspositionrequest and the `getkeys-api` flag. afaict the key-specs are now used for command info (i.e. clients), and acl. anything else (e.g. cluster, and command getkeys) is using the old way. maybe at this point we rather not document that (which one uses what), but make sure to tell modules they need to support both.",0,0,0,0.986061990261078,0.9911513924598694,0.9910418391227722,0.0,accept,unanimous_agreement
790147806,10108,"i think the ""may be null"" is confusing (when comes after the memset zero). maybe instead start the sentence by saying it's optional?",0,0,0,0.567791223526001,0.9451554417610168,0.6528153419494629,0.0,accept,unanimous_agreement
790147888,10108,we need to tell the module what this is used for. i.e. this field is only used to generate command docs (not used by redis). let's do that for each of the fields of the redismodulecommandinfo struct.,0,0,0,0.9879799485206604,0.9938898086547852,0.9937815070152284,0.0,accept,unanimous_agreement
790148188,10108,this block is outdated. delete it?,0,0,0,0.8557276129722595,0.9667103886604308,0.982608437538147,0.0,accept,unanimous_agreement
790148289,10108,let's do the todos,0,0,0,0.960119605064392,0.9656932353973388,0.9891200065612792,0.0,accept,unanimous_agreement
790148433,10108,"do we need to document that redis doesn't keep pointers to any of the input to this function? the module is free to release them... alternatively, considering that most modules will have these declared statically, we're just wasting memory.. maybe instead of duplicating all these strings we should document that the module should keep them available?",0,0,0,0.5501356720924377,0.9705109000205994,0.9076242446899414,0.0,accept,unanimous_agreement
790148713,10108,"the use of calloc here seems excessive (we're gonna override all the fields except the first). if this pattern is all over the place, i'd rather use malloc and set the last one to null.",-1,0,0,0.5062630772590637,0.9372122287750244,0.8318017721176147,0.0,accept,majority_agreement
790148975,10108,let's comment that the assertion is ok because we validate that in modulevalidatecommandinfo same in the other assertion below.,0,0,0,0.9883926510810852,0.9850153923034668,0.993887722492218,0.0,accept,unanimous_agreement
790149242,10108,value flags are not mutually exclusive. only 3 for write are.,0,0,0,0.9818146824836732,0.9886291027069092,0.9940755367279052,0.0,accept,unanimous_agreement
790149563,10108,i didn't see that `bs_unknown` and `fk_unknown` are documented. i suppose we wanna state they mean that there's no way to find the keys of the command other than using the `getkeys-api` mechanism.,0,0,0,0.9871311783790588,0.8935202956199646,0.9842617511749268,0.0,accept,unanimous_agreement
790149894,10108,considering these logs are the only way a module developer can realize what he did wrong. i think that: 1. let's document that. 2. let's make them ll_warning,0,0,0,0.9418362975120544,0.9665961861610411,0.9704781174659728,0.0,accept,unanimous_agreement
790157243,10108,"ohh, now i understand `redismodule_kspec_fk_omitted`). would have been better to use it here. (and in the other `case 0:`). and comment in the declaration of `fk_omitted` that it has to be 0 for that reason. i now realize that you want the module to rely on the struct initialization to 0, rather than explicitly use `fk_omitted` in it's code i suppose that for many modules that need just one key in a constant position, that shorthand is saving a few chars. but also, for these, there's actually no need to define the key spec, right? the legacy keyspec set by rm_createcommand, so i'm not sure there's a lot of value in that trick.",0,0,0,0.894438624382019,0.9354003071784972,0.8832345008850098,0.0,accept,unanimous_agreement
790158431,10108,"i don't understand how we test here the legacy range gluing if the command is registered with 0,0,0 (no keys)? correct me if i'm wrong, but the idea is that simple 1 key commands don't need to declare key-specs at all (unless they wanna provide flags). i suppose we need to test these: 1. module that's only using the basic rm_createcommand. we wanna test that command info does show one spec (without flags). 2. module that's using rm_createcommand to register the spec (to be backwards compatible with old redis versions), and later provides the same spec using rm_setcommandinfo to add the flags. 3. module that declares one spec using rm_createcommand and adds another using rm_createcommand (i.e. gluing, this is what `createkspeccomplex1` below seems to test) i suppose we also wanna document this (provide recommendation on how it should be used). please provide feedback. p.s. when combining this with the `getkeys-api` flag and the `rm_keyatpos`, this topic is a complete mess.",0,0,0,0.9280887246131896,0.9467830061912536,0.9347903728485109,0.0,accept,unanimous_agreement
790174759,10108,exactly. sensible behaviour when the field is omitted.,0,0,0,0.9214133620262146,0.9706798791885376,0.9835730195045472,0.0,accept,unanimous_agreement
790174940,10108,good point. i'll remove most of it.,1,1,1,0.9238014817237854,0.9629860520362854,0.9510382413864136,1.0,accept,unanimous_agreement
790175413,10108,"adding a field to the top-level struct is fine, but adding a field to the arg struct is problematic. args is an array so the size matters. key specs too.",0,0,0,0.9762616157531738,0.9902111887931824,0.6615622043609619,0.0,accept,unanimous_agreement
790175936,10108,"sure, i can change it. key spec flags could also be a space-separated string. change that too?",0,0,0,0.9851462244987488,0.9927813410758972,0.9887274503707886,0.0,accept,unanimous_agreement
790176079,10108,"sure, or i just delete ""may be null"". before the list it' already stated that all fields are optional except version.",0,0,0,0.9889017343521118,0.991849422454834,0.9875959157943726,0.0,accept,unanimous_agreement
790176199,10108,i'm thinking that examples should be on a separare page in the documentation. maybe the module intro page.,0,0,0,0.985268533229828,0.9775020480155944,0.980144739151001,0.0,accept,unanimous_agreement
790176456,10108,"ohh, right. well, making these an array of pointers will defeat the purpose of ease of use. i guess we'll have to find another way to provide the extra data when the day comes. the other alternative i see is add another spare / reserved pointer in each. for key-specs, i'm starting to consider a per-spec description soon.. e.g. on sort we have 3 specs, and it's hard even for us to keep track of what each of them means and why it's there. so maybe add 2 reserved pointer in each? (args, and specs)",0,0,0,0.7099227905273438,0.750782310962677,0.6580361723899841,0.0,accept,unanimous_agreement
790176876,10108,"these are not really examples, they just refer to an equivalent argument in a standard redis command, so it's easier to understand the flag. it's just enough to say something like `like the xxx arg in yyy`",0,0,0,0.9530762434005736,0.9891037940979004,0.987231433391571,0.0,accept,unanimous_agreement
790177074,10108,wdyt? i'm thinking that it's both easier (shorter) and more consistent with other api. but the downside is that there's no compile time validation. (but that's not covering the mutually exclusive concern which is anyway runtime only),0,1,0,0.9529120922088624,0.485255628824234,0.9617457389831544,0.0,accept,majority_agreement
790177802,10108,"tbh i didn't know exactly what they mean, only that they exist. i suppose what you suppose. i'll doc like that.",1,0,0,0.5738946795463562,0.588416576385498,0.9109792113304138,0.0,accept,majority_agreement
790190140,10108,"the legacy triple is updated when keyspecs is set and a default key-spec is creates from the old triple, so why do they need to set both? brw, isn't it high prio to make cluster and getkeys use the new key-specs?",0,0,0,0.9767587184906006,0.9894519448280334,0.9926889538764954,0.0,accept,unanimous_agreement
790190480,10108,so in practice we can require that all `const char *` are literals (or at least static) but we'll copy everything else? that's good because atm we nees to cast the strings to `char *` to free them.,0,0,0,0.974663257598877,0.9640935659408568,0.9818060398101808,0.0,accept,unanimous_agreement
790190891,10108,"if we want to be able to add fields to these struct arrays, we can instead use pointer arrays. it would allow us to add fields, but afaik it kills the possibility to write the whole info in one big nested literal. or do you have another solution to this?",0,0,0,0.9769281148910522,0.9305682182312012,0.978571116924286,0.0,accept,unanimous_agreement
790191643,10108,you wrote these tests originally? maybe you know what the idea was? i merely converted them to the declarative style.,0,0,0,0.9803135991096495,0.9842731952667236,0.9914152026176452,0.0,accept,unanimous_agreement
790192966,10108,keyspecs are only needed to set flags in that case. don't we want modules to provide flags?,0,0,0,0.9875738024711608,0.989186942577362,0.992774248123169,0.0,accept,unanimous_agreement
790234832,10108,"as i said: so no, i think we should keep it as is, but let's add two spare pointers in each of these structs",0,0,0,0.9784688353538512,0.9794940948486328,0.9932215213775636,0.0,accept,unanimous_agreement
790235301,10108,"by both, i didn't mean the initial triple, and key specs. although that too might be true. i.e. that modules need to use the initial triple if they want to be compatible with old redis versions (and still show something in command command). what i meant about both is both key-specs (i consider the initial triple to be part of the key-spsc), and the `getkeys-api` mechanism. i.e. some mechanisms in redis user only the later, and some only the first. and also need to keep in mind the fact that some complicated commands may not be possible to define with key-specs, in which case they need to use the invalid spec and implement the `getkeys-api`. so we somehow need to document all of that. maybe we don't want to document which mechanism in redis uses which, but we do want to mention that both need to be handled (i.e. both specs, and getkeys-api)",0,0,0,0.9724931120872498,0.9896296858787536,0.9759312272071838,0.0,accept,unanimous_agreement
790235478,10108,i think that'll be a good approach (don't dup these strings). ?,0,0,1,0.7997583150863647,0.9459357857704164,0.564697265625,0.0,accept,majority_agreement
790235676,10108,"yes, we do... we must: [a link] i suppose i'm ok with this omitted thing. just needs some additional comments.",0,0,0,0.970400094985962,0.946398675441742,0.8657544255256653,0.0,accept,unanimous_agreement
790235777,10108,"i think the idea was to make sure specs are merged (i remember discussing case 3 with him), but looking at the test i think it's missing part of the point. please extend the tests to cover all these cases.",0,0,0,0.9789344668388368,0.9821719527244568,0.9888831973075868,0.0,accept,unanimous_agreement
790256130,10108,i think i actually prefer copying. memory is probably going to be insignificant and it provide a more decoupled interface.,0,0,0,0.8918057084083557,0.90744948387146,0.9378310441970824,0.0,accept,unanimous_agreement
790260018,10108,"is there a real use case for [3]? regarding `getkeys-api`, maybe it's time to deprecate it? possibly produce a warning if command info is attached to a command that has it enabled? i realize some commands may not be keyspecs-compatible but in the long term we do want module developers to align with keyspecs.",0,0,0,0.970634400844574,0.9917774200439452,0.9882726073265076,0.0,accept,unanimous_agreement
790269659,10108,"let me try to analyze two separate concerns: 1. what modules had to do for redis 6.0. for 6.0, modules had to use both the initial triplet (for cluster aware clients), and also the getkeys-api (for everything else, inside redis, and command getkeys) 2. what we expect modules to do for 7.0. for 7.0, we can maybe rely only on key-specs, but the fact is that they're a lot more work to declare, so maybe for simple modules, that require only one key, we can let them keep using the initial triplet (in theory, that can serve them for anything, including acl, except for cases where acl is used with explicit read or write permissions). note however that this is not yet the case. current code in unstable still replies on getkeys-api for anything other than acl (and command command). i.e. it uses that for command getkeys, client side tracking, cluster decisions, and rm_getcommandkeys. modules that want to support two versions of redis, will be able to implement both methods, i.e. use the old api, and also the new api when it's available. so the use case for [3] is that a module which was written for redis 6, has to declare the initial triplet (for cluster aware clients), but also use the `getkeys-api` in for the sake of well, anything else. and declare key-specs for 7.0 acl. i don't see any way around this since acl (at least per key read and write permissions) must rely on key-specs, and in order to support redis 6.0, the module must provide both getkeys-api and the initial triplet.",0,0,0,0.9508681297302246,0.9905186295509338,0.970255434513092,0.0,accept,unanimous_agreement
790318394,10108,this makes sense. but what about option [3] above? why would a module provide an incomplete triplet and later pass that using command info?,0,0,0,0.9809480905532836,0.9901413321495056,0.9893681406974792,0.0,accept,unanimous_agreement
790324958,10108,"it'll pass the first triplet to be compatible with redis 6.0 and cluster aware clients. it can later pass the same triplet again in key-specs in order to provide flags. and it can pass additional specs (e.g. a store argument) which it couldn't expose before. i don't recall what the ""gluing"" term was about (in the original key-specs pr). it could have meant to glue two adjacent range specs into one.",0,0,0,0.9831371903419496,0.9931023120880128,0.9906907081604004,0.0,accept,unanimous_agreement
790519630,10108,"key-specs flags are given in the form of or-ed bit masks and i don't think we should be dealing with strings... command tips, on the other hand, are always strings... so for tips i guess it's ok if we use a space-separated string",0,0,0,0.970112681388855,0.9697378873825072,0.966947078704834,0.0,accept,unanimous_agreement
790561837,10108,i also don't like that we cast `const` stuff just to release it but i think we should still copy due to yossi's points,-1,-1,-1,0.9782293438911438,0.8198457956314087,0.9579516053199768,-1.0,accept,unanimous_agreement
790562646,10108,maybe use serverpanic instead of serverassert?,0,0,0,0.9857285618782043,0.9911105632781982,0.9842588901519777,0.0,accept,unanimous_agreement
790712720,10108,"discussed this with , and another option is for the module to populate the `sizeof` of each array type (possibly hidden behind some macro). on the redis side, this will allow us to do pointer arithmetic and be able to properly handle the array even if the module's `sizeof` has increased (because it's a newer version).",0,0,0,0.9876700639724731,0.9931821227073668,0.9938644766807556,0.0,accept,unanimous_agreement
790895184,10108,any idea how this would look like?,0,0,0,0.963619589805603,0.9582581520080566,0.9883515238761902,0.0,accept,unanimous_agreement
791005373,10108,"yes, this is a mess. it's too much to require both from a module. when documenting this, i'd like to at least mention when/why the getkeys-api is needed, but we shouldn't mention too much because we want to change it... ideally, the getkeys-api is only needed for unknown keyspecs and movable keys without keyspec. can we improve this in a separate pr?",-1,-1,-1,0.964189887046814,0.958013951778412,0.9861733913421632,-1.0,accept,unanimous_agreement
791089502,10108,"i think i'd rather finish this discussion in this pr, so we can look at the outcome and decide if we're happy with it. p.s. we did decide that we're surely not including this in rc1.. don't wanna make any rush decisions.. we need time to process this and be sure we have a solid api.",1,0,1,0.4623523354530334,0.5913478136062622,0.6923790574073792,1.0,accept,majority_agreement
791091910,10108,"btw, i spoke with guy about that test and the ""gluing"" part. the test attempted to test that two separate range key-specs that are defined with the new api (e.g. each one with different flags), are shown in the legacy part of command command output as one range. i.e. the gluing is not about gluing key-specs together, or gluing them with what's defined in rm_createcommand. it's about the output of the legacy part of command command.",0,0,0,0.9663215279579164,0.9822613000869752,0.9785487055778505,0.0,accept,unanimous_agreement
791093355,10108,ok. conclusion? should i add some comments?,0,0,0,0.977465033531189,0.9643731713294984,0.9884180426597596,0.0,accept,unanimous_agreement
791094083,10108,tips changed to space-separated. key-specs flags not changed.,0,0,0,0.9841817021369934,0.9928319454193116,0.9913482069969176,0.0,accept,unanimous_agreement
791097369,10108,"idea: `redismodule_setcommandinfo` can be defined as a `static inline` function (or a macro) in `redismodule.h`, which sets the version and size fields and then calls the real (but undocumented) api function.",0,0,0,0.9887159466743468,0.9952569603919984,0.9927707314491272,0.0,accept,unanimous_agreement
791098817,10108,keeping dup for now. resolved?,0,0,0,0.9589274525642396,0.9453870058059692,0.985201895236969,0.0,accept,unanimous_agreement
791099463,10108,"i think 1. add comments about the gluing and what this test verifies (the legacy response of command), please verify that the test really does that. 2. add comments in the gluing code that specifies that too (that it's for the output of command command) 3. we don't need the registration of key-specs to amend what's given in the first triplet. but we do need it to be able to override it (to add flags), please add a test for it. 4. we do need to document that both key-specs and getkeys-api are needed. 5. we do need to document that the triplet for rm_createcommand is needed if you wanna also support old versions of redis.",0,0,0,0.9700703620910645,0.9903799295425416,0.976529598236084,0.0,accept,unanimous_agreement
791107988,10108,yes. resolving.,0,0,0,0.9603719711303712,0.9584689140319824,0.9788691401481628,0.0,accept,unanimous_agreement
795796754,10108,"hset is a bad example imho (it's non variadic form has them mandatory, so they only reason it's a block is because it's an hmset). let's search for some optional group that's not for the purpose of being variadic. maybe the optional limit block of zrange?",-1,-1,-1,0.9158133864402772,0.8422186374664307,0.9670615196228028,-1.0,accept,unanimous_agreement
795800008,10108,let's check if this trick works well enough for other languages (rast / java?) i assume they'll need to call `rm_setcommandinfo_` and populate the version and size fields manually? -steinberg ?,0,0,0,0.985544979572296,0.9900220036506652,0.99284827709198,0.0,accept,unanimous_agreement
795804520,10108,"i must say i don't like this pattern. both the multi-line `for`, but more importantly a loop with no body. if we're wasting so many lines, it might as well be a simple `while` that increments the `count` in the body.",-1,-1,-1,0.9060031771659852,0.9473780393600464,0.966835618019104,-1.0,accept,unanimous_agreement
795818689,10108,we probably need to expose variable_flags too. which means that the flags provided by the key-spec may be different than the ones provided by the getkeys-api (more specific to the exact args passed),0,0,0,0.9882336854934692,0.9923627376556396,0.993627667427063,0.0,accept,unanimous_agreement
795819720,10108,wanna add a variant of `rm_keyatpos` that takes flags as part of this pr? or the next one?,0,0,0,0.9870498776435852,0.9956504702568054,0.9943291544914246,0.0,accept,unanimous_agreement
795821742,10108,key-specs now have a new notes field. let's expose it.,0,0,0,0.986199140548706,0.9816970229148864,0.9938615560531616,0.0,accept,unanimous_agreement
795859766,10108,"ok, i'll change to [code block]",0,0,0,0.9877941608428956,0.9878326654434204,0.9928394556045532,0.0,accept,unanimous_agreement
795863180,10108,this is the problem with keeping prs for a long time. this pr was ready before variable_flags and keyspec notes existed. :-) so i think we can postpone to the next pr adding the keyatposwithflags and making the keypos-api smarter by infering positions from keyspecs when possible.,1,1,1,0.6654590368270874,0.9918268918991088,0.9892171621322632,1.0,accept,unanimous_agreement
795890772,10108,"i understand the general problem and principle, not sure it's applicable in this case. i don't mind postponing this, but for the sake of arguing... the reason this pr was postponed was because its priority was demoted, and the reason the variable flags pr was promoted is because it became urgent. we had to resolve certain things before the release and it was ok to leave other out. i wouldn't want to add content to this pr if it was controversial and deciding on it or implementing it could have delayed the rest of this pr. but this api is kinda trivia. and i think certain things are better be judged together (so we can make sure we understand the final picture before merging) (unlike we what we had with the commands and functions projects that kept changing again and again with each pr)",0,-1,0,0.6733107566833496,0.6315490007400513,0.5873521566390991,0.0,accept,majority_agreement
795911906,10108,"on a second thought, it should be judged together with another change (acl, and tests), so let's leave it out.",0,0,0,0.96846741437912,0.9920405745506288,0.9840067028999328,0.0,accept,unanimous_agreement
796178379,10108,variable_flags added.,0,0,0,0.9858060479164124,0.9894641637802124,0.9954097867012024,0.0,accept,unanimous_agreement
796580981,10108,"done. there is already a very detailed comment at the definition of `populatecommandlegacyrangespec` in server.c. it's used by non-module commands too. it starts like this: *the purpose of this function is to try to ""glue"" consecutive range key specs in order to build the legacy (first,last,step) spec used by the command command. (...)* i added a brief comment at the call to this function in module.c too, to explain what it does. if you by ""amend"" mean combine information from the triplet with keyspecs, then i'm with you. the legacy triple is simply overridden by `populatecommandlegacyrangespec`, which is called if any key specs are provided. this test is verifying that, isn't it? if not, i don't see what test you're asking for here. updating the legacy triple is done in the same way for module commands as for builtin commands. adding this in the rm_setcommandinfo docs: ""note that key-specs don't fully replace the ""getkeys-api"" (see rm_createcommand, rm_iskeyspositionrequest and rm_keyatpos) so it may be a good idea to supply both key-specs and a implement the getkeys-api."" adding this in the rm_setcommandinfo docs: ""key-specs cause the triplet (firstkey, lastkey, keystep) given in rm_createcommand to be recomputed, but it is still useful to provide these three parameters in rm_createcommand, to better support old redis versions where rm_setcommandinfo is not available.""",0,0,0,0.8107717633247375,0.9821779727935792,0.8154319524765015,0.0,accept,unanimous_agreement
796612975,10108,"by ""amend"" i meant glue specs that seem consecutive into one. too lazy / busy to check.. is it overridden just in case they're matching (range spec with the same first/last/step)? or does any spec added by key-specs overrides what's defined in command creation? i prefer to override only if they're matching. haven't looked at the test yet. i think we should verify: 1. a key-spec that's added which is the same as the one used in command creation (being overwritten). 2. a key-spec that's added in addition to the one in command creation. 3. in both cases we need to check the key-specs in command output (and their flags), but also the legacy output of command command.",-1,0,0,0.6378201246261597,0.6522647738456726,0.6993789076805115,0.0,accept,majority_agreement
796649790,10108,"i'm reluctant to treating module commands differently than native commands. this is the function in server.c that populates the (first,last,step) triple for all native redis commands. (it's called by populatecommandtable which infers everything that isn't specified in in the command json data). tl;dr: it glues consecutive keyspec ranges into one triple when it's strait-forward to do so. if it isn't possible, the function leaves the legacy triple unchanged. thus, it's always safe to call it, regardles of whether an explicit legacy triple has been set or not. [code block] only one thing above is incorrect: it doesn't set the triple to (0,0,0) on failure. it simply leaves the triple unchanged on failure. (it matters only if it had any value before this function was called).",0,0,0,0.4962722063064575,0.7345821261405945,0.9342778325080872,0.0,accept,unanimous_agreement
796663792,10108,"the difference between modules and native redis commands, is that native command don't declare this triple, they only declare key-specs, and this code populates that triple for the benefit of the output of command command. an example is lmove which has two key-specs, that are glued together for a single range triple in command output. for module commands, they do provide the triple, so only here we're facing the dilemma of overwriting or gluing. since we do want modules (e.g. ones with a single key argument) to use both (one for compatibility with old redis versions, and the other for the key-spec flags), we need to handle an overwrite case. i.e two examples and how i think they should be handled: 1. a command with a single key argument. will use the initial triple for old version compat, and a key-spec for new redis versions (with flags), in this case we certainly wanna override. 2. a module with a command like lmove, may be using a 2 key triple in the command registration, and then define two key-specs. i suppose the first spec can override the initial triple, and then the second spec be glued (for a 2 key output in the legacy triple of command command)",0,0,0,0.9525471925735474,0.9867870807647704,0.9839648008346558,0.0,accept,unanimous_agreement
796713979,10108,it's seems that you disagree (for the sake of arguing? :grin:) but in the last example we actually seem to agree. this can also be seen as both specs together override the triple. isn't this gluing (range-concatenation) and amending the same thing?,0,0,1,0.6967182159423828,0.5422807931900024,0.9651134610176086,0.0,accept,majority_agreement
796767704,10108,"not for the sake of arguing. trying to break it down and figure out what's right. i the beginning of this discussion i thought key-specs are glued (as key-specs), or that the initial triple can be glued with key-spec. but now i understand that gluing is only needed for the purpose of the backwards compatible output of command command. and that the module api for command registration is just for compatibility with old modules, and should be overwritten by key-specs completely (if defined). however, when key-specs are defined, several specs could be glued into one triple of command output, that's the same as with redis native commands. but not glued into the one defined by the command creation triple. not sure which gaps we still have, but i suppose seeing either the implementation of the tests, we can spot them.",0,0,0,0.889166533946991,0.9855167269706726,0.7524653077125549,0.0,accept,unanimous_agreement
798011596,10108,"i've reviewed the code and tests again (finally bothered to look at the fact and not just talk about them). first, in contrast to what it was in the past, key-specs are not defined incrementally, they're declared in one go. when that happens, if there are any range specs, they completely override the legacy spec that's defined in the command creation (and if there's an opportunity to glue several specs into one legacy spec we do that). if there are no range specs, then whatever was defined at command creation remains in the legacy spec. the tests cover these cases (the overwrite). what i think the tests don't cover is: 1. a case where a module doesn't declare key-specs at all. the test can verify that there are no key-specs, but the triple in command info exists. 2. a case where the module declares only non-range specs, so the legacy range in command creation survived? (i'm not certain if that's the right behavior, we could have also wiped it, but i'm not sure why a module would do such a thing). p.s. in one of my previous comments i said: ""a key-spec that's added in addition to the one in command creation."", i guess that's wrong. we never create key-specs from the initial triple, and when key-specs are defined we should always override that triple if possible, not amend to it.",0,0,0,0.9241795539855956,0.9872288703918456,0.8563866019248962,0.0,accept,unanimous_agreement
798292729,10108,"i believe this should work just fine (for sure in rust, in java there will be probably another wrapper that will be able to call `redismodule_setcommandinfo`).",0,0,0,0.8847007751464844,0.9779285788536072,0.9413133263587952,0.0,accept,unanimous_agreement
798304940,10108,maybe you wanna take a look here too (comment if you see any problem with this trick),0,0,0,0.9756213426589966,0.9733276963233948,0.9827769994735718,0.0,accept,unanimous_agreement
798437486,10108,"yes, obviously all key-specs come in one go, in an array. (i though it's so obvious i didn't even explain it, thus confusion.) i've added the two tests mentioned, without changing any implementation for now. in the second case (only non-range specs), the legacy triple is wiped. i guess the comment in server.c is right actually, and it can be seen from the first line in the function (memset): [code block] wdyt? should we avoid clearing the triple for module commands?",0,0,0,0.942452311515808,0.9673888683319092,0.9747390151023864,0.0,accept,unanimous_agreement
798476383,10108,"thanks. i'm actually ok with that behavior too (as noted in my previous post), maybe i was reading some doc comment that caused me realize it would work otherwise (or maybe it's just that i missed that memset when reading the code). so from my perspective, it's good that this is defined and tested...",1,1,1,0.9581809639930724,0.972977578639984,0.9910752773284912,1.0,accept,unanimous_agreement
798477177,10108,so that comment is invalid..,0,0,0,0.7259284257888794,0.7904415726661682,0.944748044013977,0.0,accept,unanimous_agreement
798589295,10108,"this is not relevant anymore. for reference: we'll use a regular api function and add version field in the info struct. version is a struct pointer, typically to a static const defined in redismodule.h.",0,0,0,0.9848371148109436,0.9939957857131958,0.9929293990135192,0.0,accept,unanimous_agreement
798695752,10108,the gendoc.rb script is confused about the linebreak on this line. i'll fix it.,0,0,0,0.8760494589805603,0.7995977997779846,0.9831657409667968,0.0,accept,unanimous_agreement
1037499519,11568,please be aware of #11012 fyi,0,0,0,0.981823980808258,0.9594517946243286,0.9848175644874572,0.0,accept,unanimous_agreement
1037505390,11568,"there are some grammar issues here, but regardless, as i noted earlier, i'm not sure i like this approach, starting a thread here to discuss the alternative.",-1,0,-1,0.7863225936889648,0.8406860828399658,0.7569223642349243,-1.0,accept,majority_agreement
1045192696,11568,?,0,0,0,0.9320514798164368,0.9557723999023438,0.9296892285346984,0.0,accept,unanimous_agreement
1045273272,11568,"maybe we should also check that we are not still blocked? in #11012 we will be reprocessing the command when unblocked, but that could theoretically mean that the client was re-blocked due to another reason (like write postpone).",0,0,0,0.9858006834983826,0.9912824630737304,0.9866625666618348,0.0,accept,unanimous_agreement
1111213254,11568,i have updated the code and the top comment with the api changes we discussed (rm_call returns a promise object that allow to set the unblock handler). let me know what you think.,0,0,0,0.9822695851325988,0.9625738859176636,0.942598819732666,0.0,accept,unanimous_agreement
1111214050,11568,"added this check, any advice how to test it?",0,0,0,0.9822207093238832,0.9925127029418944,0.9937140345573424,0.0,accept,unanimous_agreement
1111214849,11568,"in theory, this should be some abstraction interface (not the module interface), and module.c should do the conversion. but i suppose changing this will just complicate things (more code that's harder to follow), and we can always change it when we'll want.",0,0,0,0.88760906457901,0.981049418449402,0.9396750330924988,0.0,accept,unanimous_agreement
1111215261,11568,"please avoid line comments. also, i don't think the comment is clear enough.",0,0,0,0.7723079919815063,0.790614128112793,0.9251955151557922,0.0,accept,unanimous_agreement
1111217967,11568,"maybe the name of this function should include ""command"" or ""call"" or ""reply""? i.e. unblocked from what operation?",0,0,0,0.9851239323616028,0.9927391409873962,0.9880024194717408,0.0,accept,unanimous_agreement
1111218098,11568,maybe use just one method to return this trio (with output arguments)?,0,0,0,0.984043300151825,0.9937472343444824,0.9887951612472534,0.0,accept,unanimous_agreement
1111218213,11568,let's avoid line comments (and excessive brackets imho too),0,0,0,0.8462997078895569,0.953043520450592,0.954833447933197,0.0,accept,unanimous_agreement
1111218457,11568,i don't think we wanna call an rm_ api here (and i don't see we're doing that on other places). let's just do selectdb (and remove the forward declaration you added),0,0,0,0.9858947992324828,0.9755244851112366,0.9902188181877136,0.0,accept,unanimous_agreement
1111219557,11568,i wonder if this api should take a context (from which we can take a module)? maybe this should be the place where we set the module pointer in the reply object (rather than when it was created) or maybe we should match here the module used by the caller with the one in the reply object?,0,0,0,0.961560070514679,0.9936572909355164,0.9843919277191162,0.0,accept,unanimous_agreement
1111220024,11568,p.s. i'm not sure about the name of this api either. please advise.,0,0,0,0.9657830595970154,0.7088308930397034,0.9682226181030272,0.0,accept,unanimous_agreement
1111224833,11568,maybe we can assert that someone doesn't try to free this reply object before the blocked command finishes?,0,0,0,0.9787479639053344,0.9908536672592164,0.9896732568740844,0.0,accept,unanimous_agreement
1111231542,11568,"let me make sure i understand. this complication (thread safe context, and calling unblockclient), is because we also blocked the caller that triggered our rm_call. if somehow this rm_call would not be a result of a real client which we had to block, then it would be simpler, right?",0,0,0,0.9688873291015624,0.97785621881485,0.9828758835792542,0.0,accept,unanimous_agreement
1111232471,11568,"so if we are invoked in a context in which we can't block, we create a thread safe context for the call? maybe we can do that only in case we got blocked? and don't bother if our rm_call doesn't get blocked? maybe mention that capability and complication in the comments?",0,0,0,0.9838783740997314,0.9901813864707948,0.993668496608734,0.0,accept,unanimous_agreement
1111241705,11568,what happens if the module sets the `k` flag and forgets to call this handler? seems like it could be a common mistake. maybe we wanna add a test for it?,0,0,0,0.9161187410354614,0.9623231887817384,0.9834448099136353,0.0,accept,unanimous_agreement
1111246926,11568,you have tabs (indentation) in this file,0,0,0,0.987753689289093,0.9910489320755004,0.994981586933136,0.0,accept,unanimous_agreement
1111247651,11568,"please add `wait_for_blocked_client` here, and anywhere else where you create a client that should get blocked before proceeding.",0,0,0,0.9818288087844848,0.9937646389007568,0.9945118427276612,0.0,accept,unanimous_agreement
1111620579,11568,"i do not see why this api should get a context, all the other call reply are not getting a context, and we have the module from the ctx used to initiate the rm_call.",0,0,0,0.9708677530288696,0.9787301421165466,0.9714980721473694,0.0,accept,unanimous_agreement
1111625607,11568,"yes, the blocked client are just to unblock the initiator of the command. if a module just want to call some blocking command regardless of a client, there is no need to handle any blocked clients.",0,0,0,0.9849461317062378,0.9868873953819276,0.9929348826408386,0.0,accept,unanimous_agreement
1111628390,11568,"maybe i will just return an error if blocking is not allowed, indicating that we can not run this command in this case..",0,0,0,0.9237826466560364,0.925698459148407,0.9798941016197203,0.0,accept,unanimous_agreement
1111632228,11568,i thought you did all of that because you wanted to test some flow that would otherwise be untested.,0,0,0,0.9803898930549622,0.962126076221466,0.9719942808151244,0.0,accept,unanimous_agreement
1111633916,11568,"taking it back, my test is testing it when block is not allowed. i will rearrange the code then ..",0,0,0,0.9774905443191528,0.6821389198303223,0.9912084341049194,0.0,accept,unanimous_agreement
1111640222,11568,"then its a fire and forget, you run the command and you do not care about the response. i will update the docs and add a test.",-1,0,0,0.9321170449256896,0.9587555527687072,0.5275441408157349,0.0,accept,majority_agreement
1111676504,11568,"i was mainly pointing out that this code might better be placed inside the following check together with processpendingcommandandinputbuffer (wrapped in if (c->flags & client_module) ), also any reason not to call beforenextclient?",0,0,0,0.9850537180900574,0.9892075061798096,0.9927882552146912,0.0,accept,unanimous_agreement
1111993000,11568,shouldn't we write here a resp protocol?,0,0,0,0.9813397526741028,0.9928590059280396,0.9935717582702636,0.0,accept,unanimous_agreement
1111999003,11568,i don't think so. we also do that in other pipeline tests ([a link],0,0,0,0.9705434441566468,0.9694060683250428,0.9817501306533812,0.0,accept,unanimous_agreement
1112139442,11568,"if we already have a module, do you see other reasons for a context?",0,0,0,0.981058657169342,0.9907387495040894,0.9932838678359984,0.0,accept,unanimous_agreement
1112168081,11568,"no, it just feels odd to me that we provide a callback pointer in one place, and the module pointer in another.",-1,-1,-1,0.8865923881530762,0.9370782375335692,0.6961491703987122,-1.0,accept,unanimous_agreement
1112179064,11568,"i agree that with the initial test code meir wrote, it could be that redis will execute the lpush before the ping reached redis, we can use `$rd flush` but that's not necessarily sufficient, so it's best to just write them in one `$rd write`. we don't have to use resp, inline protocol is enough.",0,0,0,0.9778624773025512,0.965989351272583,0.984652578830719,0.0,accept,unanimous_agreement
1112186222,11568,"i think that is what i offered, no?",0,0,0,0.9717260599136353,0.9576049447059632,0.9913397431373596,0.0,accept,unanimous_agreement
1112188509,11568,"1. let's add a comment for easier reading, i.e. that it just a getter for 3 parameters. 2. let's change one of them to use the return value, so it's possible to make a distinction between a successful return and an early return.",0,0,0,0.9847374558448792,0.9903727769851683,0.9915634393692015,0.0,accept,unanimous_agreement
1112190790,11568,where does this sds.h come from? we can't use redis internals.,0,0,0,0.9846338629722596,0.9598674774169922,0.9897097945213318,0.0,accept,unanimous_agreement
1112193421,11568,you can do the same thing (of not creating the blocked client in advance) in the other function as well.,0,0,0,0.9877451062202454,0.9901604652404784,0.9920721650123596,0.0,accept,unanimous_agreement
1112629720,11568,"the runtime linker links us to the sds in redis. but you are right, will change to avoid using sds.",0,0,0,0.9765201807022096,0.9897632598876952,0.9938015341758728,0.0,accept,unanimous_agreement
1114364442,11568,we'll need to reset these flags later. probably in `resetclient` (called from `modulereleasetempclient`),0,0,0,0.9894949793815612,0.9954081177711488,0.9948469400405884,0.0,accept,unanimous_agreement
1114365219,11568,maybe it's time to change resetclient to reset everything and preserve just select flags..,0,0,0,0.9692286252975464,0.9869641661643982,0.985663652420044,0.0,accept,unanimous_agreement
1114481969,11568,"in other test units (iirc misc.c) we abandoned this approach of matching the function name, and instead passed the flags and first argument to the function (before the arguments it passes on to rm_call's argv). this makes the tests more flexible in the sense that you control everything from the tcl file and don't need to add features to the c file every time. on the other hand, we can argue it's less readable, unless you consider these rm_call flags a well known thing, and everyone know what `!` and `k` does. so let's consider converting the several usage of this approach in this file, let me know what you think,",0,0,0,0.948999285697937,0.9824342131614684,0.9855539202690125,0.0,accept,unanimous_agreement
1114496819,11568,", on `modulereleasetempclient` we are reseting the client flags and only keep `client_module`: [code block] [a link]",0,0,0,0.9876132011413574,0.994016170501709,0.9938911199569702,0.0,accept,unanimous_agreement
1114498421,11568,"sure, i can match to this approach but notice that then the `tcl` tests will have those flags pass on each call so not sure it will be cleaner..",0,0,0,0.8699681758880615,0.8759347200393677,0.955724596977234,0.0,accept,unanimous_agreement
1114502635,11568,"what i do not notice now is that maybe we want to have a max capacity to `moduletempclients` today we do not have it. i guess its because we assume it can not grow to much (only on nested rm_call), but now with blocking rm_call it has a potential to grow? wdyt?",0,0,0,0.9333910942077636,0.9282658100128174,0.9716550707817078,0.0,accept,unanimous_agreement
1115310569,11568,"i don't think we want to limit it... we do have a mechanism to limit the cache size or actually to release it gradually when unused, i think that's sufficient, and if module or app will abuse it, we better let the resource utilization grow (assuming there are resources on the machine), rather than block something that could succeed.",0,0,0,0.9625925421714784,0.9609923362731934,0.9738309383392334,0.0,accept,unanimous_agreement
1115312566,11568,"we can pass only the explicit ones, and keep some implicit. also, we can make the `!` implicit, unless `?` is added, but that's a little bit confusing. what we have now is also ok, but it means we need to add code to the c file every time we need a new flag. i'm looking for something that's easiest for the reader.. the key point is not to force the reader of the tcl code to go look at the c code when reading each individual tcl test, so that's already covered. if we can clean the c code without compromising that, let's do it, otherwise, we can skip",0,0,0,0.8153796792030334,0.820232093334198,0.9302121996879578,0.0,accept,unanimous_agreement
1118058043,11568,"i am not follow why you think it should be there, we do not really need to call this function in case of a fake module client. there is nothing else that need to be processes on this fake client. maybe i am missing something?",0,0,0,0.7503103017807007,0.7379506230354309,0.8631590008735657,0.0,accept,unanimous_agreement
1118071162,11568,"i agree there is not much point in doing so for the current items in beforenextclient and yhis is not urgent to make this flow go through beforenextclient - but i do feel that taking a different code route could present issues in the future in case some new logic will be placed inside the beforenextclient and we will miss it in case of fake client. we can wait for such future case and fix it then, or we can try to make this new flow to follow as much steps as the regular code flow.",0,0,0,0.8516276478767395,0.9341670274734496,0.9568639397621156,0.0,accept,unanimous_agreement
1118305319,11568,"it could be that some day the code that's executed in beforenextclient will be also needed for these modules, but it could also be that some future code in beforenextclient will have to be avoided for them, and if we'll call it we'll have to remember to add a exception (we are likely to forget). maybe the safest thing we can do now is either to call it, and add some `if (c->flags & client_module) return;` or instead write there a comment about this case and mention `processunblockedclients`",0,0,0,0.9757677316665648,0.9914464950561525,0.9822410941123962,0.0,accept,unanimous_agreement
1121268206,11568,"we need to document here what is allowed and not allowed in the context of the unblock handler. because we took the permissive approach to the api and provided a redismodulectx, we need to provide this guidance at the documentation level.",0,0,0,0.9842063188552856,0.9894782900810242,0.9944157600402832,0.0,accept,unanimous_agreement
1127368015,11568,"yes i think it will really be confusing. i can make the command get the flags a the first argument, but then we will have to pass it on all the tests. or we can stay with the current version. let me know what you prefer.",-1,-1,-1,0.6259417533874512,0.6740071773529053,0.5963624119758606,-1.0,accept,unanimous_agreement
1127386421,11568,i added a comment.,0,0,0,0.9832298159599304,0.9690238833427428,0.975155234336853,0.0,accept,unanimous_agreement
1127388509,11568,"thanks, i updated the docs. i did not specify each and every api that can or can not be used. wrote that in general you can call more redis command using rm_call and replicate data to replica and aof. also mentioned that any api that involve a real client interaction (such as rm_reply* api's) is disallow. let me know what you think.",1,1,1,0.7630614638328552,0.8989089131355286,0.9573087096214294,1.0,accept,unanimous_agreement
1127402846,11568,let's keep the current one. i suppose in this case it's more explicit and easier to read.,0,0,0,0.97639662027359,0.9677908420562744,0.984815239906311,0.0,accept,unanimous_agreement
1127412191,11568,allow -> allowed,0,0,0,0.9804727435112,0.9791984558105468,0.9309041500091552,0.0,accept,unanimous_agreement
1127412407,11568,more -> additional,0,0,0,0.96358323097229,0.9645996689796448,0.9875109195709229,0.0,accept,unanimous_agreement
1127413183,11568,shouldn't these be indented more?,0,0,0,0.877169668674469,0.9903562068939208,0.9866172075271606,0.0,accept,unanimous_agreement
1127416732,11568,"i do not know know, how can i check that?",0,-1,0,0.5421826839447021,0.6841097474098206,0.9280701279640198,0.0,accept,majority_agreement
1127445010,11568,"ohh, my bad. for some reason i thought it's a sub-section of the bullet above. i now see it's a separate list, so i think we need a blank line in between the end of the previous list and the header of the next one.",-1,-1,-1,0.9902432560920716,0.979409396648407,0.9879429936408995,-1.0,accept,unanimous_agreement
1127463119,11568,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1135326303,11568,"i'm always paranoid about changing the role or actions of a widely used function, that in some fork or branch, we have another call to it that will be forgotten and it'll cause bugs without any compilation errors or merge conflicts. i see that there are two calls left to the plain unblockclient (in areas this pr modifies anyway). maybe we can rename that function, or maybe instead of creating a new one, we can introduce a flag, e.g. `void unblockclient(int quque_for_reprocessing);` wdyt?",-1,-1,-1,0.9402324557304382,0.6571425795555115,0.8208097219467163,-1.0,accept,unanimous_agreement
1135338726,11568,i think either-or should be one sentence. [code block],0,0,0,0.9860023260116576,0.9924489259719848,0.9849607348442078,0.0,accept,unanimous_agreement
1135355080,11568,why is the initial refcount 2? let's document that...,0,0,0,0.9750611186027528,0.986560583114624,0.9932369589805604,0.0,accept,unanimous_agreement
1135357174,11568,"can you explain this change (i'm not to clear on the details, and rather not spend time figuring it out)",0,0,0,0.9788867235183716,0.7747980952262878,0.9680476188659668,0.0,accept,unanimous_agreement
1135361291,11568,"maybe we better pass an argument to enterexecutionunit if it should update the cached time.? will be easier to add other things in the future, and code will look slightly cleaner (still keeping the comment but it'll be shorter)",0,0,0,0.9804919958114624,0.9885823726654052,0.9878882765769958,0.0,accept,unanimous_agreement
1135363842,11568,"i think i preferred an explicit flag in the first place (now we only depend on the check in `processcommand`, which propagates to `call()`, than having two different ways to discover that). please take a look at some changes in this pr. note the change below in which we always set the client_executing_command flag (even on nested fake clients). maybe we should assert that it's not already set? (if it is, then it would be wrong to clear it when this function exits)",0,0,0,0.9775623083114624,0.9892298579216005,0.9814545512199402,0.0,accept,unanimous_agreement
1135369810,11568,"so now `call_timer` may be outdated. the previous code made sure to always call `ustime()` and get a fresh `call_timer`, and yet, avoid getting the system time twice, by passing that time to `updatecachedtimewithus`. i think we must sort things out to get that functionality back.",0,0,0,0.965556502342224,0.9907517433166504,0.9850652813911438,0.0,accept,unanimous_agreement
1135384190,11568,let's get the client id and kill just the desired client.,0,0,0,0.940037727355957,0.9727041125297546,0.9902715086936952,0.0,accept,unanimous_agreement
1135385319,11568,maybe add an assert that we have 0 blocked clients? or actually wait for the blocked clients to drop to 0 (`wait_for_blocked_clients_count`),0,0,0,0.9839640259742736,0.9944678544998168,0.9911585450172424,0.0,accept,unanimous_agreement
1135425212,11568,i am not sure there is an issue with that but just in case we can save the flag value before setting it and just restoring it back once we return not blocked,0,0,0,0.9682281613349916,0.8336145281791687,0.9563798904418944,0.0,accept,unanimous_agreement
1135439766,11568,any reason we explicitly do all the current_client+ after_command and nesting arithmetic? afaik this is already done in processcommandandresetclient,0,0,0,0.9904028177261353,0.9915891289711,0.9912371635437012,0.0,accept,unanimous_agreement
1135480565,11568,"sure, will revert it and add a flag",0,0,0,0.9858474135398864,0.9667959213256836,0.993381142616272,0.0,accept,unanimous_agreement
1135481850,11568,"it is hold by the client and by the promise reply, will document it.",0,0,0,0.9874638319015504,0.98470276594162,0.9950209856033324,0.0,accept,unanimous_agreement
1135483039,11568,"seems like today we can not hold the call reply object for longer time then the context, in case there is no auto memory set i do not see a reason why not to allow it?",0,0,0,0.9375240206718444,0.809127926826477,0.9896404147148132,0.0,accept,unanimous_agreement
1135486148,11568,"ohh you are right, this is used to check the time it took to run the command. i will fix it.",0,0,0,0.5791517496109009,0.7432559132575989,0.9009833335876464,0.0,accept,unanimous_agreement
1135517655,11568,so let's mention this in the top comment.,0,0,0,0.9827104210853576,0.9864474534988404,0.9934056997299194,0.0,accept,unanimous_agreement
1135519991,11568,"if this state should be impossible, let's assert rather than backup and restore the flag.",0,0,0,0.9856317043304444,0.966541826725006,0.9866498112678528,0.0,accept,unanimous_agreement
1135577115,11568,mentioned,0,0,0,0.9614673852920532,0.9557328820228576,0.9501405954360962,0.0,accept,unanimous_agreement
1135601073,11568,"this can happened on blocking commands, we leave this flag on until we reprocesses the command.",0,0,0,0.9858613014221193,0.990881323814392,0.9936231970787048,0.0,accept,unanimous_agreement
1135602862,11568,and its also wrong to cache it and return the cache value because in this case we really want to turn off the flag even if it was on before.,-1,0,0,0.5415246486663818,0.8076185584068298,0.8648691177368164,0.0,accept,majority_agreement
1135680913,11568,i believe my comment bellow answer that. we want the reprocessing of the command and the command handler to be atomic.,0,0,0,0.9467982649803162,0.9058151245117188,0.9933797121047974,0.0,accept,unanimous_agreement
1135687769,11568,"ok, i suppose we are covered by tests. maybe we should add a comment so that someone else will not wonder about it in the future.",0,0,0,0.9718623757362366,0.9863579273223876,0.980878472328186,0.0,accept,unanimous_agreement
1135785340,11568,question - can this be that a module called a command which was postponded? (in which case we will not execute it),0,0,0,0.9844706058502196,0.9879747629165648,0.9887393712997437,0.0,accept,unanimous_agreement
1135785553,11568,ohh you mean you want the module handler to be in the same execution unit as the command processing... i failed do understand that for the comment : ``we must set the current client here so it will be available * when we will try to send the the client side caching notification * of 'aftercommand'. */`` maybe we should state that it is meant for the module handler?,-1,0,0,0.7474930882453918,0.963063418865204,0.9801846146583556,0.0,accept,majority_agreement
1136482406,11568,"i don't get this comment, we can't use enterexecutionunit and then we immediately call it?",0,0,0,0.9324594140052797,0.9278630018234252,0.9870421886444092,0.0,accept,unanimous_agreement
1136580756,11568,"comment is outdated :smile: we fixed the problem that prevented the use of this function (by passing an argument), and forgot to update or delete the comment.",0,1,1,0.5415188074111938,0.8722023963928223,0.991471230983734,1.0,accept,majority_agreement
1136581335,11568,"i actually wanted to suggest the same, and decided to leave it. meir, remember to update the header file as well.",0,0,0,0.9843212366104126,0.9670135974884032,0.9940940737724304,0.0,accept,unanimous_agreement
1136696846,11568,"i will try to clarify that in the comment, thanks.",1,1,1,0.6657337546348572,0.6939529776573181,0.727698564529419,1.0,accept,unanimous_agreement
1136698441,11568,"good catch, will update.",1,1,1,0.9647451043128968,0.92983740568161,0.987472116947174,1.0,accept,unanimous_agreement
1136717762,11568,let me know if its better now.,0,0,0,0.9735493063926696,0.9819502830505372,0.9716913104057312,0.0,accept,unanimous_agreement
1136718189,11568,updated,0,0,0,0.968149185180664,0.968669593334198,0.7592994570732117,0.0,accept,unanimous_agreement
1136719662,11568,"not following the question, do you mean that the unblock handler will call more blocking commands?",0,0,0,0.9655486941337584,0.9820627570152284,0.9916513562202454,0.0,accept,unanimous_agreement
1136776633,11568,please update the argument name in server.h as well,0,0,0,0.9878788590431212,0.9924877882003784,0.9955453872680664,0.0,accept,unanimous_agreement
1136779215,11568,[code block] there are other two places in callreply.c and module.c,0,0,0,0.9880175590515136,0.9941338896751404,0.9954711198806764,0.0,accept,unanimous_agreement
1136976084,11568,"i suppose postponed is in case it's a write command called during client pause write. but these can't be module type clients, right?",0,0,0,0.9885770082473756,0.9806971549987792,0.9897785782814026,0.0,accept,unanimous_agreement
1137620728,11568,"just to make sure, this code path is new, right? i.e. before this pr, module (fake) clients didn't get blocked, so that increment didn't affect them regardless of this condition.",0,0,0,0.9812930226325988,0.987060546875,0.9923505187034608,0.0,accept,unanimous_agreement
1137681059,11568,"yes right, before this pr we could not get to this code with module client.",0,0,0,0.9807906150817872,0.9791945815086364,0.9922524094581604,0.0,accept,unanimous_agreement
1138212667,11568,that was basically my question. in case a module will call a command which will be postponed (either by having writes paused or by another busy module operation) will in that case the module client will just terminate? or do we want it to be reprocessed?,0,0,0,0.9773823618888856,0.9600160717964172,0.988477349281311,0.0,accept,unanimous_agreement
1138213838,11568,yes. thank you!,1,1,1,0.9741729497909546,0.9847007989883424,0.9906896352767944,1.0,accept,unanimous_agreement
1138239525,11568,"if the module's command is a write command it wouldn't have been executed, after it started, if an rm_call gets blocked, it'll not get postponed (module fake client don't participate in that postpone game). maybe that's an issue (module blocked clients violating write pause), but the reverse is impossible (a postponed (module) client that will then get blocked)",0,0,0,0.9658336639404296,0.949461042881012,0.9840669631958008,0.0,accept,unanimous_agreement
1138240941,11568,"the issue of violating write pause probably exists whenever a module blocks the calling client (and does something in the background), regardless of rm_call",0,0,0,0.9701530933380128,0.9676901698112488,0.9833799004554749,0.0,accept,unanimous_agreement
1138328288,11568,", i understand that postpone module fake clients will probably get paused by the original client executing the module command, but isn't it possible that module client be issued from a keyspace or other kind of event which is not write context (like key miss)? maybe i am mixing and messing things up :) but i think that looking forward it is possible we would like to support more blocking cases which we would like to apply to module client, and i wanted to verify this will not hold us back. for example maybe we can introduce a processpendingcommand function that will process a command in case the pending flag is on and also call the the modulecallcommandunblockedhandler?",1,1,1,0.920533299446106,0.9820683598518372,0.9310450553894044,1.0,accept,unanimous_agreement
1138353799,11568,"i discussed this at length with meir (he's adding a commit with a doc comment). normally when an rm_call gets blocked the module will block the original client as well, no writes will happen during failover pause, and the blocked client will remain blocked, and then the failover completed the demotion will abort the root client which the module should catch and abort the blocked fake client. so other than documentation, i think the current code is good. i'm not sure i understand your processpendingcommand suggestion above, maybe you can describe an example scenario you aim to handle, or suggest the exact code change you're proposing (maybe you did?)",0,0,1,0.7715310454368591,0.8355014324188232,0.7941282987594604,0.0,accept,majority_agreement
1138377074,11568,[code block] do we wanna mention something about the fire-and-forget thing?,0,0,0,0.9835899472236632,0.9862213134765624,0.9767770171165466,0.0,accept,unanimous_agreement
1138428117,11568,what i meant is that we can create the following function: [code block] so that we can use it in the context of unblockclientonkey and processpendingcommandandinputbuffer called from processunblockedclients,0,0,0,0.9829182624816896,0.9922627210617064,0.9920350909233092,0.0,accept,unanimous_agreement
1138435476,11568,"in any case according to what you explained, i do not recognize a bug with the current implementation, so we can also decide to refactor later on...",0,0,0,0.9831136465072632,0.9629149436950684,0.98882395029068,0.0,accept,unanimous_agreement
1138443936,11568,mentioned,0,0,0,0.9614673852920532,0.9557328820228576,0.9501405954360962,0.0,accept,unanimous_agreement
1147229156,11963,wraped with `do while(0)`?,0,0,0,0.9875748753547668,0.9938325881958008,0.9925560355186462,0.0,accept,unanimous_agreement
1147229344,11963,there are many more places below. [code block],0,0,0,0.9837950468063354,0.9901626110076904,0.9952056407928468,0.0,accept,unanimous_agreement
1147232607,11963,it seems that they can't be negative. [code block],0,0,0,0.9686189293861388,0.988968312740326,0.985162913799286,0.0,accept,unanimous_agreement
1147236768,11963,forget to remove?,0,0,0,0.8802942037582397,0.9797536730766296,0.8943114876747131,0.0,accept,unanimous_agreement
1147291113,11963,"above this line, `durationstartmonitor` assigned its value in microseconds, but below this line, `latencyaddsampleifneeded` takes value in milliseconds.",0,0,0,0.9878768920898438,0.9934915900230408,0.9943860769271852,0.0,accept,unanimous_agreement
1147295853,11963,this does make it safer but is not necessary. this should always be used in an independent line.,0,0,0,0.9750604629516602,0.9868339896202089,0.9910969734191896,0.0,accept,unanimous_agreement
1147318453,11963,"indeed, we can only ensure that it has no side effects as much as possible. on the other hand, `durationstartmonitor(..);` will be expanded as [code block]",0,0,0,0.984173059463501,0.9923822283744812,0.9933955073356628,0.0,accept,unanimous_agreement
1147789811,11963,i still believe this should be a histogram and not an arbitrary max value that decays.,0,0,0,0.896456778049469,0.9284552335739136,0.9454572200775146,0.0,accept,unanimous_agreement
1147793467,11963,"this isn't a real representation of the io read, since on linux the epoll will also execute part of the tcp stack to see if there is data available to read.",0,0,0,0.9873114824295044,0.9666365385055542,0.9856956601142884,0.0,accept,unanimous_agreement
1147909354,11963,"i believe this double counts multi-commands, since it will count the outer and inner time,",0,0,0,0.9663695693016052,0.9822346568107604,0.9870252013206482,0.0,accept,unanimous_agreement
1148577855,11963,"the monotonic clock itself already has a fallback to clock_gettime (which iirc is a system call similar if not faster than gettimeofday), why do we need the ustime fallback?",0,0,0,0.9777911305427552,0.9864756464958192,0.9896798133850098,0.0,accept,unanimous_agreement
1148578887,11963,"unlike the latency monitor, which is an infrastructure that has a ton of sample points and a generic command to extract them, here we have some 6 different metrics, hard wired to the info command. i'm not sure we want to have the overhead of dict lookup, it would be faster to just directly access dedicated server struct variables.",0,0,0,0.9541782140731812,0.921794891357422,0.8346885442733765,0.0,accept,unanimous_agreement
1148835935,11963,"yes, but can we measure the time consumed in epoll? this may be inaccurate but at least it can provide a clear message when io read is heavy, right?",0,0,0,0.9710187911987304,0.9719702005386353,0.9839776158332824,0.0,accept,unanimous_agreement
1149080749,11963,"+1. the users usually care more about p99 or p999 latency than average latency, so just exposing sum and count may be not enough, we need more fine grained metrics. instantaneous metrics somehow mitigates it. another way is recording all latency at the cost of more memory assumption.",0,0,0,0.9282354712486268,0.973973274230957,0.970385491847992,0.0,accept,unanimous_agreement
1149174335,11963,let's move this to to be the last item in the enum rather than explicitly defined.,0,0,0,0.9861773252487184,0.9905609488487244,0.99375981092453,0.0,accept,unanimous_agreement
1149175618,11963,i'm not sure we need the macros.. it seems simple enough if the code would just explicitly call getmonotonicus,0,0,0,0.771859347820282,0.858793318271637,0.9585009813308716,0.0,accept,unanimous_agreement
1149178145,11963,"that could be interesting (to use `hdr_histogram`), but then what will we want to expose? i don't think we'll want to expose 6 different metrics for each of our measurement in info. so if we go that way, we'll want to expose just 2 in info and have a dedicated command to get the rest?",0,0,0,0.97264963388443,0.9846612811088562,0.9821841716766356,0.0,accept,unanimous_agreement
1149985692,11963,"ok, a histogram does make more sense..",0,0,0,0.9616827964782716,0.9691623449325562,0.9838005900382996,0.0,accept,unanimous_agreement
1149987337,11963,"i agree with madlyn, that histograms would be a lot more useful. if info output size is a concern, should we just add a separate section to the info that will not be printed by default and use something like `info eventloop` to print this data?",0,0,0,0.8431499004364014,0.9039795994758606,0.9553892612457277,0.0,accept,unanimous_agreement
1156538447,11963,i don't know of a way to measure the epoll time.,-1,-1,0,0.5814918279647827,0.5856719017028809,0.7983124256134033,-1.0,accept,majority_agreement
1157265748,11963,"i think we should leave this out of scope. we're trying to give some visibility on command latency by showing where the event loop spends time (before sending replies), and what portion of the event loop is consumed by each chore. what linux does inside epoll should be out of scope imo.",0,0,0,0.9736393690109252,0.9802471399307252,0.9693087339401244,0.0,accept,unanimous_agreement
1157282803,11963,"i think it's odd that this is zeroed in both resetserverstats and latencymonitorinit. i would say that this feature is part of server stats, not the ""latency monitor"", parts of it are implemented in latency.c, but not part of the ""monitor"" framework. let's remove the init from `latencymonitorinit()`, and instead zero `server.el_start` in `initserver()`",0,0,0,0.8261234760284424,0.6235777735710144,0.5821336507797241,0.0,accept,unanimous_agreement
1157296846,11963,"if you don't have time to look into the histogram part yet, and we all agree that the count and sum part should be in info (for easy stats collection by a monitoring software), and the histogram in a different command (like we did in #9462).. maybe for now we should remove the `max` info field and leave the histogram for later.. this will a least give us some visibility on what the event loop is doing. see [a link]",0,0,0,0.9451096653938292,0.9857804179191588,0.9836524724960328,0.0,accept,unanimous_agreement
1161223464,11963,"it's a little odd to see this zeroing moved but the memset of server.duration_stats wasn't. the fact is that globals are all zeroed anyway, so this is all unnecessary anyway.",0,-1,-1,0.6276502013206482,0.8771185278892517,0.6211006045341492,-1.0,accept,majority_agreement
1161227516,11963,"let's improve the comment here, it's quite confusing. first, let's mention that cron duration includes beforesleep chores (let's add that comment in the header variable declaration too). secondly, maybe it'll look nicer if we create a dedicates stack variable for the beforesleep measurement, and add it to server.el_cron_duration at the end (it'll appear less confusing than deducting and accumulating time directly to the server variable)",-1,0,0,0.5971433520317078,0.9718675017356871,0.54674232006073,0.0,accept,majority_agreement
1161228440,11963,"let's comment here (and below) that we exclude io (aof) from the cron duration measurement. again, i think the code will also look cleaner if we add another stack based variable to track the aof part, and deduct it from the other stack based variable at the end.",0,0,0,0.9869937300682068,0.9864181876182556,0.9897935390472412,0.0,accept,unanimous_agreement
1161228580,11963,"btw, maybe we can use this variable to track the aof duration instead of the changes you made in flushappendonlyfile",0,0,0,0.9861961603164672,0.9937626719474792,0.9920193552970886,0.0,accept,unanimous_agreement
1161234001,11963,please add some comment explaining what this function does and how. maybe by explaining the differences from the other one above.,0,0,0,0.9840826392173768,0.9870420694351196,0.9925582408905028,0.0,accept,unanimous_agreement
1161236621,11963,maybe we can move the `mstime()` call to outside? (it's silly that it is called inside a loop),-1,-1,-1,0.9358068108558656,0.9305091500282288,0.8277502655982971,-1.0,accept,unanimous_agreement
1161238064,11963,"it is silly that this `mstime()` is called inside the loop (can be sampled once before it), but also, i don't feel comfortable with `stats_metric_rate_count` (it's declaration seems odd, there are two constants with the value of `6`), and the coupling between how it's initialized and how it is used, is risky. i'd rather all the initialization be the same, and also the extraction (getinstantaneousmetric) the same, and the only difference is if trackinstantaneousavgmetric or trackinstantaneousratemetric is called. in that case, how about setting the initial last_sample_time to be 0 in both cases, and just make sure to skip the first time trackinstantaneousratemetric is called (only do the init and exit right after) what do you think?",-1,-1,-1,0.9770538210868835,0.9418694972991944,0.9733304977416992,-1.0,accept,unanimous_agreement
1161406549,11963,good idea,1,1,1,0.9742737412452698,0.97594553232193,0.9905905723571776,1.0,accept,unanimous_agreement
1161406784,11963,"we already have a time measurement in `flushappendonlyfile` used by latency monitor, let's just use that instead of making another measurement.",0,0,0,0.9888637065887452,0.9937449097633362,0.9935894012451172,0.0,accept,unanimous_agreement
1161479047,11963,"yes, but we also in any case also now have a time measurement before and after the aof portion in beforesleep. so considering we're gonna keep both anyway, i think it's nicer to have all the event loop stats updated in server.c (beforesleep, servercron, etc), and not mix them up with the code in aof.c (could also some day be called not as part of the event loop). also, it'll mean the code in aof.c is unmodified.",0,0,0,0.9719109535217284,0.9812661409378052,0.9753718972206116,0.0,accept,unanimous_agreement
1161480345,11963,"please remove the `max`, we'll add a histogram later",0,0,0,0.9881129860877992,0.992583990097046,0.995008111000061,0.0,accept,unanimous_agreement
1161541643,11963,"ohh, i see what i was missing. i was aiming to completely drop `duration_before_aof` and `duration_after_write`, and instead measure in one variable the entire duration of beforesleep, and in another the entire duration of the aof part and then deduct one from the other. (would not have required to add any additional time sampling call). but i missed the fact we also need to skip counting handleclientswithpendingwritesusingthreads as cron. well, looking at that, since handleclientswithpendingwritesusingthreads is only called from one place (here), i think we can move it's measurement from inside the function to outside of it (and avoid the complication of a separate measurement when that function early exits due to no threaded io). that would mean we're also counting a few other minor things as if they are io, i.e. spinning up threads, and doing memory accounting, but i think that's acceptable. in that case we'll have beforeslep measure it's total time (one measurement at at the beginning and one at the end. and we'll have an additional 3 calls to time sampling (before the aof part, between the aof and writes, and after writes), computing two additional variables (aof duration and write duration) to be deducted from the total time at the end. wdyt?",0,0,0,0.7323322296142578,0.8003955483436584,0.9058151245117188,0.0,accept,unanimous_agreement
1161563738,11963,"it is a little bit asymmetric taking samples of io reading inside of `handleclientswithpendingreadsusingthreads`(i don't think we should move it outside as this function also processes commands), but take samples of io writing outside of `handleclientswithpendingreadsusingthreads`. ...but i guess it is ok, since i already moved the sampling of aof into `beforesleep`.",0,0,0,0.980163276195526,0.9673900604248048,0.975515365600586,0.0,accept,unanimous_agreement
1161599859,11963,"ohh, right. i now notice it calls processpendingcommandandinputbuffer, we can't count that as either io or cron chores. i think we need both the counting inside that function as io, and also the counting outside it to deduct the whole thing from cron chores. i.e. your current code. i also notice that it processpendingcommandandinputbuffer is called from a few other places (i missed that earlier, must have been looking at a different branch.",0,0,0,0.8888806104660034,0.9294724464416504,0.9276494979858398,0.0,accept,unanimous_agreement
1161609825,11963,"took another look at beforesleep, i see we currently include the calls in processunblockedclients, handleclientsblockedonkeys in the measurement, i think we must skip them. i don't feel comfortable re-ordering that function, but i also don't like a ton of measurements (hard to maintain). need to think what to do here.. maybe change the plan...",-1,-1,-1,0.971344828605652,0.9371519088745116,0.901037335395813,-1.0,accept,unanimous_agreement
1161793327,11963,"maybe it should be exclusive rather than inclusive, we do want: * clusterbeforesleep * activeexpirecycle * modulefireserverevent optional: * modulehandleblockedclients - can be considered a server side thing (doesn't represent commands or io) * evictclients - i'm assuming it's usually not very intensive (unlike io, or something like commands that can have unexpected complexity) * trackingbroadcastinvalidationmessages - same * freeclientsinasyncfreequeue - same * handleblockedclientstimeout - same exclude (io and commands): * flushappendonlyfile * handleclientsblockedonkeys * handleclientswithpendingreadsusingthreads * handleclientswithpendingwritesusingthreads so either we measure everything and exclude 4 blocks (the last list above). or we include just 3 specific blocks (the first list above). please advise.",0,0,0,0.967528998851776,0.991671621799469,0.9870217442512512,0.0,accept,unanimous_agreement
1162236662,11963,"i was expecting we would check for recursive commands here, doesn't eval and modules that issue rm_call() also double count now?",0,0,0,0.9862194657325744,0.9666778445243835,0.9898165464401244,0.0,accept,unanimous_agreement
1162240132,11963,"i very strongly disagree. i think we're scope creeping by adding this. if the data is not that reliable, i don't think we should be adding it. we actually don't need to care for command latency. the real proxy of command latency is el time and time from el wakeup until command being written out to client.",-1,-1,-1,0.8819526433944702,0.8849297761917114,0.8176872134208679,-1.0,accept,unanimous_agreement
1162242078,11963,"not sure about the ask. i think we should measure everything and exclude the four blocks to have an ""other"" category, i wouldn't call it a cron.",0,-1,0,0.6665778756141663,0.5361185669898987,0.8278701901435852,0.0,accept,majority_agreement
1162266557,11963,"yes, and fcall.",0,0,0,0.9800891876220704,0.9886578917503356,0.9829995036125184,0.0,accept,unanimous_agreement
1162425568,11963,"ok, so you suggest that beforesleep takes some 5 samples of the time in order to deduct the ones we wanna exclude from the ""other"". meaning we'll have: * eventloop_duration_sum - the total breakdown (changing the names): * eventloop_duration_cmd_sum * eventloop_duration_io_read_sum * eventloop_duration_io_write_sum/ * eventloop_duration_aof_sum * eventloop_duration_other_sum how about a slightly different naming pattern: * `eventloop_duration_sum` (or `eventloop_duration_sum_total`) * `eventloop_duration_sum_cmd` * `eventloop_duration_sum_read` * `eventloop_duration_sum_write` * `eventloop_duration_sum_aof` * `eventloop_duration_sum_other`",0,0,0,0.9774159789085388,0.9910807013511658,0.991409957408905,0.0,accept,unanimous_agreement
1162433522,11963,"ohh, now i see your other comment below. so you just wanna keep the `total` (from beforesleep to aftersleep), and `cmd`. and drop all the io and cron chores? i think it is important to know what's slowing things down besides commands, and if it's io or other things. we do have latency history measurement for aof, expire and defrag, but not for others. why do you think it's half baked? maybe the ""other"" is, but not the rest... maybe we can drop ""other"" and keep the io / aof? in theory users (or even the server) can deduct the io and aof from the total and conclude how much the rest takes, but i was concerned that there might be other things so i wanted to measure beforesleep and servercron so it'll be possible to find out that there's something else that we don't measure.",0,0,0,0.9164762496948242,0.915813684463501,0.8564620614051819,0.0,accept,unanimous_agreement
1162448430,11963,"again, i'm ashamed i have missed it. so checking `server.execution_nesting==1` should fix both exec and eval, we well as rm_call from within a module command. it would also avoid measuring rm_call from a thread or a timer event (since it'll be incremented when a module context is created and again in `call()`), which i suppose is good (i.e. module actions are in anyway ""internal"" and not ""commands"" from the perspective of the event loop.",-1,-1,-1,0.984731912612915,0.9163899421691896,0.9845424890518188,-1.0,accept,unanimous_agreement
1162453790,11963,"maybe i'm missing your point. you're arguing that since during the time redis's user space is sleeping on epoll, the kernel runs system space code (on our process time) that handles io (tcp), and we should include that in our io measurement? i'm trying to add a breakdown of the composition of the event loop. i.e. we know how much time it took from wakeup to sleep, and i wanna know what where the components of that.. i.e. commands, io, or other ""cron"" chores.",-1,0,0,0.69912189245224,0.8819087147712708,0.644741415977478,0.0,accept,majority_agreement
1163194669,11963,put a comment on this line indicating that it must remain the last entry in the enum.,0,0,0,0.9831225275993348,0.9916442036628724,0.992830455303192,0.0,accept,unanimous_agreement
1163201582,11963,"why are all of these prefixed with `el_`? the enum type is `durationtype`. try to make the prefix match the type name. i really think the whole ""event loop"" slant on this is incorrect. these are not metrics from the event loop. this is quite clear, given that `ae.c`/`ae.h` are not being touched. i'm not sure what else to call it though. these enumerations each need commenting. please document the intent for each. what period of time/what operation is being measured. without specific documentation, it's unclear how to maintain these metrics. are each of these cumulative durations?",0,-1,0,0.7231523990631104,0.6539642214775085,0.6584717035293579,0.0,accept,majority_agreement
1163206247,11963,"i generally dislike `unsigned`. but for a cumulative, always increasing, value - i tend to use unsigned. if there's any reason to decrement, avoid unsigned. why is one variable unsigned, and the other isn't?",-1,-1,-1,0.9486128687858582,0.5751800537109375,0.5133061408996582,-1.0,accept,unanimous_agreement
1163208025,11963,i generally find indexing notation to be easier to read here. [code block],0,0,0,0.984838604927063,0.9809409976005554,0.9773750901222228,0.0,accept,unanimous_agreement
1163210906,11963,i think a pattern that's a little clearer is this: [code block],0,0,0,0.9789606332778932,0.9732624292373656,0.976980686187744,0.0,accept,unanimous_agreement
1163215506,11963,"trying to reuse the `duration` variable is a bit confusing here. this is assigning a timestamp, not a duration.",-1,-1,0,0.8907619118690491,0.867128849029541,0.6173476576805115,-1.0,accept,majority_agreement
1163219190,11963,"you can see how this continues to be confusing... it almost looks like we are trying to accumulate a duration, but why would be subtract a ""duration"" from a timestamp? there's no sin to creating an additional, well-named, variable. the compiler will optimize it out anyway. it just improves readability.",0,0,0,0.8113299608230591,0.7510803937911987,0.5504555106163025,0.0,accept,unanimous_agreement
1163220449,11963,`= 0` unnecessary,0,0,0,0.968953549861908,0.9786289930343628,0.6352786421775818,0.0,accept,unanimous_agreement
1163223547,11963,"i'm always bothered by the word ""instantaneous"" being applied with the word ""rate"". ""rate"" is some activity over time. you can't measure a rate without time. so implying that a rate is instantaneous - occurring over 0 time - is false. what is `current_time`? i hope this is a time from the monotonic clock. it would be much clearer to use `monotime` if that is the case. i have no idea what `long long` represents with respect to time.",-1,0,-1,0.94446462392807,0.5489215850830078,0.9148774147033693,-1.0,accept,majority_agreement
1163227059,11963,"looks like this is now a duration. let's name it ""duration"" rather than ""t"". is this us? ms?",0,0,0,0.978154480457306,0.990182101726532,0.9881682991981506,0.0,accept,unanimous_agreement
1163230837,11963,"if `t` (duration) is very small, `ops_sec` may suffer from extreme extrapolation. here, it's looking like `current_time` is somehow represented in milliseconds. wouldn't it be clearer and more consistent to use `monotime` all the way through?",0,0,0,0.9803355932235718,0.9822340607643129,0.9755080342292786,0.0,accept,unanimous_agreement
1163234386,11963,"`getmonotonicus` returns a timestamp, not a duration. either the variable is mis-named, or we're trying to reuse the variable for 2 different purposes.... looking below, i see that we're temporarily overwriting the `el_cron_duration` with the start time. i'd recommend defining a local variable instead (`monotime el_cron_start`). if not for clarity, consider that global variables might (in theory) be read across threads. changing the duration to a timestamp - and then back to a duration - could cause problems.",0,0,0,0.9751392602920532,0.9883460402488708,0.9838606119155884,0.0,accept,unanimous_agreement
1163235643,11963,why not use the monotonic clock here?,0,0,0,0.953158438205719,0.9898576736450196,0.98654443025589,0.0,accept,unanimous_agreement
1163237465,11963,"if another variable was used above, this could be written like [code block] note the rename of `el_cron_duration` to `el_cron_duration_us` - it's helpful to tag units to time duration variables.",0,0,0,0.9858443737030028,0.9945915341377258,0.99439537525177,0.0,accept,unanimous_agreement
1163238060,11963,"again, very confusing as this is not a ""duration"" (at this point).",-1,-1,-1,0.8178218603134155,0.9706557393074036,0.8404658436775208,-1.0,accept,unanimous_agreement
1163244356,11963,"let's not use the word ""instantanous"" and let's properly define the time units. can we call this ""current_eventloop_cycles_per_sec""?",0,0,0,0.9718323349952698,0.992494821548462,0.991174340248108,0.0,accept,unanimous_agreement
1163244979,11963,"this makes no sense to me. what the heck is an ""instantaneous average""?",-1,-1,-1,0.9817214012145996,0.9859924912452698,0.9744337797164916,-1.0,accept,unanimous_agreement
1163546013,11963,"these metrics are taken in servercron, beforesleep, and some file events, which i believe are all part of eventloop. yes they are all cumulative.",0,0,0,0.9840710163116456,0.9868191480636596,0.9925411939620972,0.0,accept,unanimous_agreement
1163562317,11963,"`server. el_cron_duration` is used to measure time duration of `severcron` and a part of `beforesleep`, so we need a global variable to record the value.",0,0,0,0.9885737895965576,0.9943038821220398,0.9928014278411864,0.0,accept,unanimous_agreement
1163568298,11963,"well, words like ""instantaneous"" and ""t"" are just old history code that i didn't bother to rename, and i just followed it to avoid too much change in code. as for naming and readability, maybe i am just used to the ""code style"" in redis, i think some of your suggestions are unnecessary. however they do make sense, so if you insist, we can improve the code.",0,0,0,0.9396151900291444,0.9616745114326476,0.8254494667053223,0.0,accept,unanimous_agreement
1163874033,11963,"i also dislike the term ""instantaneous"", used in redis for short term metrics (representing the last second or so), but that ship has sailed, we can't change it now...",-1,-1,-1,0.983371376991272,0.9712085723876952,0.9786085486412048,-1.0,accept,unanimous_agreement
1163884592,11963,"the word ""instantaneous"" in info means recent or short-term. i.e. in contrast to other metrics that are ever increasing counters. i don't want to start using a new term (""current"") for this",0,0,0,0.7892940640449524,0.8618472218513489,0.97223961353302,0.0,accept,unanimous_agreement
1163958081,11963,"i agree many of jim's suggestions are not strictly necessary, but they do improve the code, so specifically in new code or places that are changed anyway, i think we should implement them (more variables that their name matches their usage, and the better matching type). regarding ""instantaneous"" i think we must keep it and maybe find another way to make it slightly less awkward. i see other metrics in this group all have units in their name (""per_sec"" and ""kbps"") so maybe we can drop the ""average"" part and make it: `instantaneous_eventloop_duration_usec` or `instantaneous_eventloop_usec`. and `instantaneous_eventloop_cycles_per_sec`",0,0,0,0.8206031918525696,0.9611114859580994,0.8830903172492981,0.0,accept,unanimous_agreement
1164274302,11963,"i understand. but here, you're not recording a duration. you're temporarily storing the start-time for the duration. you shouldn't store the start time in the global variable. use a local variable to record the start time, and then later, update the duration.",0,0,0,0.9791492819786072,0.9843400716781616,0.9807674288749696,0.0,accept,unanimous_agreement
1164837799,11963,"i see. it does make sense. when we finally decide what to measure, i will improve it.",0,0,0,0.7113104462623596,0.8544474840164185,0.6692286729812622,0.0,accept,unanimous_agreement
1164857804,11963,so do we have a conclusion here?,0,0,0,0.97625732421875,0.9830758571624756,0.9905893802642822,0.0,accept,unanimous_agreement
1168121264,11963,"i'm saying i don't care about this data, and don't believe in exposing useless metrics simply because we can compute them. i don't think the io is particularly useful in aggregate. i think the one useful metric being exposed here is the one about total event loop time, which gives a nice proxy for command execution time.",-1,0,-1,0.9438127875328064,0.5536488890647888,0.6074334979057312,-1.0,accept,majority_agreement
1168123309,11963,"i agree about sticking with instantaneous for consistency, +1 about the per_sec though, all the other instantaneous metrics do include the units. another problem i see with ""current"" is it is used extensively to refer to some ""current ongoing process"", like ""current_active_defrag_time"". so, ""instantaneous_eventloop_cycles_per_sec"".",0,0,0,0.9714609384536744,0.9794039726257324,0.9719932675361632,0.0,accept,unanimous_agreement
1168125464,11963,"i suppose ""usecs per seconds"" is a rate. i almost feel like this should be `instantaneous_eventloop_usec_per_second`, which is the rate (or ratio) of time spend in the event loop per second.",0,0,0,0.962718904018402,0.9855732321739196,0.9851977229118348,0.0,accept,unanimous_agreement
1168129903,11963,"i don't think we're working back from end users and what problems they will be solving with this information. the original issue was about command latency. in the thread we identified that event loop time was an easy an accessible metric that basically gave this information. as el time increased, latency would likely go up proportional to it. so, `eventloop_duration` metrics seems useful. command information also seems useful. end users have the detailed breakdown of all the commands, they can go and see what commands are taking a lot of time and make some decisions based off of that. we also already have this information being calculated, so it seems useful to have it aggregated. i'm not sure what the other metrics are really adding. if they see high write io, what are users going to do about it. i want to keep as much code off the hot path as possible and i want redis to be as simple as possible.",0,0,0,0.8705832958221436,0.8428332209587097,0.7820475697517395,0.0,accept,unanimous_agreement
1168308562,11963,"you're right that some of these are not useful for users, but in some cases metrics in info are for us (developers) not users. i.e. if someone submits an issue, we ask for info output and try to figure out what's wrong in their deployment and how we can either improve redis, or advise them what's their problem (even if they can't make sense of these metrics). i'm not saying i'm certain which way to go here, just saying i'd like to have more detail next time i'm looking at such issues and be able to know where the time is spent. maybe we should add a section for `experimental` or `dev` / `debug` info fields? p.s. i think that in anyway, our backwards compatibility contract for info fields is a little bit more flexible than commands, and we can drop / change some (ones we think are unlikely to be used by an application / script)",0,0,0,0.5149103999137878,0.852323591709137,0.946689248085022,0.0,accept,unanimous_agreement
1168928776,11963,"i'll throw in my $0.02 and agree with . in my experience, the one metric here that is useful is the event-loop cycle time. under heavy load, once redis caps out on throughput, the event loop cycle time increases. in extreme cases, with slow & pipelined commands being executed, i have observed scenarios where the event loop cycle time reaches several minutes in length. it's important to consider this edge case. how will this ""instantaneous"" metric function if the event loop takes 5 minutes to cycle? imo, 2 metrics would be useful: * a rolling average of event loop cycle time over roughly a minute * an ""instantaneous"" cycle time (over roughly a second) and we need to understand how both of these will perform when the cycle time is insanely large (like 5 minutes). also, i agree that adding metrics just because we can is a dangerous strategy. our metrics are not clearly documented. end-users don't know how to interpret some of the values. each metric increases the real-time requirements for info all. and (probably most importantly) each metric adds a backwards compatibility burden. an ill-conceived metric must be maintained for backward compatibility purposes. , i agree that maybe an ""experimental"" section might be a solution. if so, it should be explicitly stated that items in that section will change without notice and will not be considered a backward-compatibility concern. i'd suggest that: * the experimental sections should not appear for info all * the experimental sections should be clearly documented that they may change without notice * we should consider adding this documentation to the live output... something like: [code block] * we could add a parameter on the info command like `info experimental `",0,0,0,0.557563304901123,0.922810435295105,0.9385007619857788,0.0,accept,unanimous_agreement
1169126930,11963,"i don't think this is true. afaik we've never broken these outside of major versions, and we should call these out as breaking changes. i agree that we should be more okay removing these, but i don't think the contract is weaker. maybe we should add a section for experimental or dev / debug info fields? redis is missing a good way to ""introspect"" into what is going on and allow sophisticated users or tools to debug what is going on. i think if we want to target this use case, we should think holistically about the feature.",0,0,0,0.8843408823013306,0.9437584280967712,0.9007520079612732,0.0,accept,unanimous_agreement
1169679373,11963,"the io read metrics should not be interesting until they unexpectedly are if the connection layer is unexpectedly slow. and since it's now extensible, i think the chances of that happening are not zero.",0,0,0,0.9068028926849364,0.9492164254188538,0.9823030829429626,0.0,accept,unanimous_agreement
1169716978,11963,how about simply exposing an event loop counter?,0,0,0,0.9793333411216736,0.9778131246566772,0.9916471242904664,0.0,accept,unanimous_agreement
1174512012,11963,[code block] i now realize that here we're already after `exitexecutionunit()`.,0,0,0,0.9884782433509828,0.9890156388282776,0.9933506846427916,0.0,accept,unanimous_agreement
1174512582,11963,let's change last_sample_time and current_time (now current_time_us) from long long to monotime.,0,0,0,0.9862427711486816,0.990649163722992,0.9933683276176452,0.0,accept,unanimous_agreement
1174512899,11963,that's an indication that we don't have a test for it. please see if you add some trivial test.,0,0,0,0.952805995941162,0.9418601989746094,0.9898192286491394,0.0,accept,unanimous_agreement
1174513519,11963,"re-posting this as a code comment text so for easier discussion (thread that can be resolved: another interesting metric could be the number of commands per event loop cycle, specifically the max. considering that we now intend to introduce an experimental section, maybe we can add `eventloop_cmd_per_cycle_max` and maybe re-add `eventloop_duration_max` to have them temporarily until histograms are present? wdyt? is the non-`default` (and non-`all`) ""debug"" section hidden enough to add these temporarily, or you still rather avoid them for now?",0,0,0,0.9676598906517028,0.9872639179229736,0.9898843765258788,0.0,accept,unanimous_agreement
1174537076,11963,i wonder how we can test this... we can send `multi` `debug sleep 1` `exec` and then check how much time is added to the metric. but i don't feel it is necessary...,-1,0,0,0.9606845378875732,0.6978667378425598,0.9695997834205629,0.0,accept,majority_agreement
1174541466,11963,"with the bug above, nothing will get logged when a plain command is executed, so that's easy to test (just check that we have some value in that metric). i don't have a strong objection to that debug sleep test, but i'm also ok with just having a trivial test that checks the metric isn't empty.",0,0,0,0.9283899068832396,0.928687334060669,0.9290700554847716,0.0,accept,unanimous_agreement
1174542540,11963,"this isn't really a monotime (timestamp), it's a duration. we can maybe add a union, but maybe that's excessive. at least the monotime tells us what are the units. maybe some comment can improve things a bit. e.g. `current_time_sum is a the total duration of that metric in microseconds`",0,0,0,0.973315954208374,0.9886326193809508,0.9799582362174988,0.0,accept,unanimous_agreement
1174542619,11963,the comment needs an update of units,0,0,0,0.9866674542427064,0.9894636869430542,0.9947766065597534,0.0,accept,unanimous_agreement
1174561381,11963,why not use `[s eventloop_duration_cmd_sum]`?,0,0,0,0.9855952262878418,0.9941080808639526,0.9937817454338074,0.0,accept,unanimous_agreement
1174569934,11963,i am not so familiar with this tcl test framework... i forgot about this proc.,-1,-1,0,0.9739446640014648,0.9503185153007508,0.6945052742958069,-1.0,accept,majority_agreement
1182322814,11963,i think an explicit section that's not default or all is good enough.,0,0,0,0.9661614894866944,0.9285226464271544,0.8979282975196838,0.0,accept,unanimous_agreement
1185805368,11963,"i don't think we need to put temporary metrics for an unstable version, since eventually we will have histograms.",0,0,0,0.9667151570320128,0.956873655319214,0.9685248732566832,0.0,accept,unanimous_agreement
1186040300,11963,"imho, the rate and avg are both average, the only difference is the dividend and divisor, the arguments `current_reading` and `current_time` here are unclear, i prefer rename them and reuse the original `trackinstantaneousmetric` like: [code block] [code block]",0,0,0,0.9775713086128236,0.9927672147750854,0.9891000390052797,0.0,accept,unanimous_agreement
1186763658,11963,i'm okay with this.,0,0,0,0.9061513543128968,0.6698853373527527,0.6740703582763672,0.0,accept,unanimous_agreement
1186792525,11963,sounds like a good idea.,1,1,1,0.9611578583717346,0.9228842258453368,0.906455934047699,1.0,accept,unanimous_agreement
1189381784,11963,"shouldn't this be `1` instead of `factor`? i.e. in the other metric we count rate per second, so the factor scales up the delta time to a full second. but here we measure an average duration per cycle so `sum` is the duration and `cnt` is the cycle count. `sum` is in microseconds, and we want the result to remain in microseconds, so `factor` should be 1, right?",0,0,0,0.9783626794815063,0.98959082365036,0.9889935851097108,0.0,accept,unanimous_agreement
1189386150,11963,......i was being careless,-1,-1,-1,0.9870253205299376,0.972595512866974,0.9915567636489868,-1.0,accept,unanimous_agreement
1190660124,11963,isn't it simpler to use `server.stat_numcommands` instead of `server.duration_stats[el_duration_type_cmd].cnt` and then in beforesleep as well.,0,0,0,0.98789644241333,0.9938183426856996,0.9899410605430604,0.0,accept,unanimous_agreement
1190660545,11963,"actually, what you're summing is the max event loop command **duration**, and i meant to measure the command count. maybe there's a reason to keep both?",0,0,0,0.979944348335266,0.962838351726532,0.9908972382545472,0.0,accept,unanimous_agreement
1190663853,11963,"let's allow some tolerance, and also make sure a failure prints the bad value [code block]",0,0,0,0.9749116897583008,0.9467140436172484,0.9897502064704896,0.0,accept,unanimous_agreement
1190666637,11963,"maybe we can add a resetstat, and then we can put some boundaries on the values? i.e. we know we have roughly 2 commands, 3 cycles, and duration is probably very low (in any case below 100) it'll mean we can't use the `foreach`, but that's also a benefit, since we'll have just one `after 110` for all 3 metrics, instead of having 3 sleeps.",0,0,0,0.9487075805664062,0.9882358312606812,0.9879592657089232,0.0,accept,unanimous_agreement
1190667367,11963,let's add a comment next to each `after` explaining what we're waiting for. e.g. [code block],0,0,0,0.9840869307518004,0.989982545375824,0.994712769985199,0.0,accept,unanimous_agreement
1190671655,11963,"let's add a test that makes sure these are not included in the default info, and info all",0,0,0,0.9846985936164856,0.991125762462616,0.9934335947036744,0.0,accept,unanimous_agreement
1190672796,11963,"aof is disabled, it's ok to keep it like so, but maybe add a comment? let's also test the other two new metrics.",0,0,0,0.9852272272109984,0.9902238249778748,0.9922615885734558,0.0,accept,unanimous_agreement
1190717254,11963,"actually this `cnt` is the command count (represents how many samples are already taken). command duration is stored in `sum`. [code block] when we measure command duration, we take `exec` and every command in the transaction as one command, as we take samples only when `server.execution_nesting == 0`. but `server.stat_numcommands` counts every `call()`. so perhaps we should use `server.duration_stats[el_duration_type_cmd].cnt` here.",0,0,0,0.985055446624756,0.9950428009033204,0.9935312867164612,0.0,accept,unanimous_agreement
1190792867,11963,"ohh you're right. but actually, i think i'd rather count the elements inside multi-exec too for this metric, so knowing that, i think i'd rater start_numcommands. either way, specifically if we keep what you wrote, i'd rather add a comment clarifying that concern.",0,0,0,0.8292539715766907,0.8022926449775696,0.9474642872810364,0.0,accept,unanimous_agreement
1190801629,11963,"""allowing some tolerance"" reminds me that, such tests including time measurement may fail due to performance jittering, and we may end up with allowing a huge tolerance. i don't feel like to do so...",-1,-1,-1,0.9839684963226318,0.8998993635177612,0.9803783297538756,-1.0,accept,unanimous_agreement
1191361342,11963,"even a huge tolerance (100 times what we expect) can catch some bugs, in comparison, the `>=` seems a little bit useless. but anyway, i'm also ok keeping what we have now. i'll try to find some time for manual testing, and then i'll merge it. or if you can acknowledge that you did that already (monitor these metrics on a server under traffic, and on an idle one), i'll skip it and merge sooner. thank you.",1,1,1,0.8911678194999695,0.960205614566803,0.8603852391242981,1.0,accept,unanimous_agreement
1191841365,11963,i already did manual testing and the results looks ok. also added some upper boundaries in the test.,0,0,0,0.9588494896888732,0.9528217911720276,0.7023407816886902,0.0,accept,unanimous_agreement
1225672385,11963,"i think we forget to document this on the info documentation page. unrelated, reply_buffer_expands is also not documented, i wonder if there are others not documented as well.",0,0,0,0.9119831323623656,0.9784543514251708,0.9700945019721984,0.0,accept,unanimous_agreement
1226040760,11963,just raised a pr: redis/redis-doc#2439,0,0,0,0.97212415933609,0.9918352365493774,0.9944701194763184,0.0,accept,unanimous_agreement
773885602,9822,"this looks a little odd, `buf_peak` will never be exactly equal to `buf_usable_size`, and `buf` does not seem to be shrunk normally.",-1,-1,-1,0.6348006725311279,0.8768895864486694,0.568183958530426,-1.0,accept,unanimous_agreement
773896378,9822,we usually try to write as much as possible to the client reply buffer and if filled completely (c->bufpos == c->buf_usable_size) we continue to reply list allocations. regarding the shrinking - i am not sure i follow the problem... maybe you can elaborate?,0,0,0,0.917127251625061,0.8091201186180115,0.9677505493164062,0.0,accept,unanimous_agreement
774280975,9822,"because in the normal case, in the old code, unless the reply we send to the client exceeds `buf_usable_size`, `bufpos` is not equal `buf_usable_size`, so `buf_peak` is not necessarily equal to `buf_usable_size`.",0,0,0,0.9830018877983092,0.991227090358734,0.9918377995491028,0.0,accept,unanimous_agreement
774341393,9822,- correct! that is exactly what this change is aiming to. we want the client buffer to be extended only when the buffer was filled.,0,1,1,0.9618957042694092,0.7551714777946472,0.8969248533248901,1.0,accept,majority_agreement
797451401,9822,"these are stats, right? let's add a stat_ prefix and put together with other stats.",0,0,0,0.9831315279006958,0.9922299981117249,0.9911009669303894,0.0,accept,unanimous_agreement
797523305,9822,this allocation should now be counted in getclientoutputbuffermemoryusage or at least in getclientmemoryusage,0,0,0,0.9880081415176392,0.993303120136261,0.9954622387886048,0.0,accept,unanimous_agreement
797554973,9822,"redis has a mechanism that attempts to scan through all clients once a second, but it also handles at least 10 in each cron, so if there are not a lot of clients, they can be scanned faster. this means that resetting the peak value on each cron, can behave differently when there are a lot of clients vs just a few. i think it makes sense to add a mechanism to avoid doing this job (and reset the peak) too often.",0,0,0,0.968600571155548,0.9857326149940492,0.9805617928504944,0.0,accept,unanimous_agreement
797556522,9822,styling.. multi-line `if` gets the brace in a separate line. [code block],0,0,0,0.987627387046814,0.9903788566589355,0.9933077096939088,0.0,accept,unanimous_agreement
797556908,9822,"styling.. if-else chain, the brace is with the else [code block]",0,0,0,0.9875195026397704,0.9814279079437256,0.9943554401397704,0.0,accept,unanimous_agreement
797558357,9822,"aren't we a `min` with proto_reply_min_bytes here? is that the minimum threshold for resize, or the minimum size?",0,0,0,0.9866095185279846,0.9953578114509584,0.9938516616821288,0.0,accept,unanimous_agreement
797560254,9822,"i think ran is right.. these days we try to fill it to the last byte (it wasn't like that in the past). however, i'm afraid that the *2 and /2 thing can somehow cause a resonance effect, especially considering that we don't get the size we asked for (we can get up to 30% more due to internal frag). maybe we should go with *2 and /4 ?",-1,0,0,0.5348052978515625,0.5795214772224426,0.8849083185195923,0.0,accept,majority_agreement
797597841,9822,ack - i will move that to the stats section and add the prefix.,0,0,0,0.9877544045448304,0.9783697724342346,0.9898586869239808,0.0,accept,unanimous_agreement
797599950,9822,ack - good catch - i will add the buf_usable_size to the sum.,1,1,1,0.9472194910049438,0.9511106014251708,0.9604889750480652,1.0,accept,unanimous_agreement
797631662,9822,the limit is on the minimum size. i can change it to check `c->buf_usable_size/2 >= proto_reply_min_bytes `,0,0,0,0.9878007173538208,0.9942463040351868,0.9953938722610474,0.0,accept,unanimous_agreement
797634253,9822,"that's also a possibility.. then it becomes the minimum resize threshold, not min size..",0,0,0,0.978464126586914,0.9916212558746338,0.9947721362113952,0.0,accept,unanimous_agreement
797640177,9822,"we will toggle these sizes [1024,2048,4096,8kib,16kib] which matches the jemalloc size classes i agree that in case these values will change in the future the code would be potentially 25%-30% extra size (like the jump from 8kib size class to 10kib) but we will still make use of the extra size in our attempt to shrink and expend the buffer. i just feel 4 times shrinkage might be too aggressive. also i thought a lot about the 1kib min limit which is basically 2 times larger than my plan. since our analysis of customer data sizes shows most cases value sizes are up to 512 bytes.",-1,0,0,0.6062021255493164,0.886569619178772,0.953018844127655,0.0,accept,majority_agreement
797644776,9822,"i think it is possible to throttle the total buffer reallocations, or we can try to avoid re-sizing the same client too often by skipping it in case it did not pass enough cron cycles. but i wonder if that will not get back to us with dynamic list allocations?",0,0,0,0.959556519985199,0.9473760724067688,0.986404538154602,0.0,accept,unanimous_agreement
797648811,9822,ok.. i don't think the current code can actually cause a resonance effect. it's just a paranoia i have of two thresholds being too close to each other. but i suppose in this case it's ok,0,0,0,0.5421855449676514,0.7794120907783508,0.8643678426742554,0.0,accept,unanimous_agreement
797650357,9822,"i'm sorry, i suppose it wasn't clear what i commented on (i selected one line, but the context in gh shows more). i was specifically referring to: [code block]",-1,-1,-1,0.9890909790992736,0.988371193408966,0.9807807803153992,-1.0,accept,unanimous_agreement
797814951,9822,i agree that we can soften the peek value reset in some way. i thought that keeping a new per-client indicator for how many cron iterations visited that client can help in more future cases and can help avoid reseting the peek too often in this case.. alternatively i can just keep the last servertime visiting this client in cron... what do you think? would that answer your raised concerns?,0,0,0,0.9365134835243224,0.937663197517395,0.9013439416885376,0.0,accept,unanimous_agreement
797879341,9822,"not sure i understand how counting cron iterations will help. i think we need to remember the peak reset time, and avoid checking these thresholds (and resetting the peak) too soon. maybe it could be some generic clientscron mechanism that can serve other per-client cron tasks later. i.e some clients cron are better be done as soon as possible, but others should not be done too soon. so there could be a block in clientscron that's executed just once a second, saving the last time it run in the clients struct.",0,0,0,0.966005265712738,0.9720215201377868,0.9251152873039246,0.0,accept,unanimous_agreement
798389093,9822,what i meant is that keeping a per-client track of how many times it was handled by the clients cron can be used in different scenarios to make operations based on estimated time without having to keep a dedicated variables for each. for example in this case i can reset the peak every (client_cron_ticks % (100/server_hz)) but i think we can currently keep it simple and just make sure we reset the peak value each 5 seconds. does that sound better?,0,0,0,0.9689486622810364,0.9773849844932556,0.9837816953659058,0.0,accept,unanimous_agreement
798404213,9822,"since in certain cases a client can be hit every cron tick, and in others just once a second, i don't think incrementing a counter every time we hit that client is good. i.e. i assume you mean some mechanism like run_with_period, but that can work only if you know you're incrementing as a roughly constant pace. maybe i'm misunderstanding you, so writing some pseudo code, or just posting the implementation could help. we could instead save the value of `server.cronloops` on the last time we hit that client, but i don't even see how this would help to serve multiple purposes, since we have to reset that variable when we perform the action, so if we have multiple actions with different timing requirements, we'll need multiple variables. my suggestion is able to serve multiple purposes with one variable, just because it defines that all these purposes need a one second intervals. i.e. the clientscron is divided into two groups, one runs on every call, and the other is throttled to once a second.",0,0,0,0.5692744851112366,0.9543540477752686,0.9612110257148744,0.0,accept,unanimous_agreement
798515532,9822,"i agree with all you are saying. correct me if i am wrong but the current clients cron is exactly an attempt to operate each client every second. i believe that most of these operations do not really need to be operated exactly once every second but rather as an estimation to prevent keeping the server busy. my main point was trying to make peak resets happen less often which is why i suggested to keep track of cron ticks and perform the operation once every x ticks. i understand that this will cause some difference between scenarios of few and many clients but i am not sure that is a problem. in case of few clients the peak will be checked more often but also the transmit operations, so in case the client is taking on more work i would also expect the peak to reflect the correct reply buffer usage. in order to reduce the risk i currently set the peak reset period to be once every 5 seconds which is fine as we are mainly worried about un needed shrinks. i just do not want this to become a very complicated solution and keep the clients cron simple and fast.",0,0,0,0.5931828618049622,0.857533872127533,0.7050045728683472,0.0,accept,unanimous_agreement
798540131,9822,"that's right, but the mechanism is to make sure they're handled **at least** once a second, and it could be much faster. not sure why you say that, i don't see the correlation between client count and the amount of work / data they induce.",0,0,0,0.913613259792328,0.8055272698402405,0.972809910774231,0.0,accept,unanimous_agreement
798724334,9822,"i understand. actually i meant exactly something like run_with_period (just was not familiar with it) in any case my last update makes each client reset the peak every 5 seconds, so it should resolve the few clients issue. unless i missed something :)",1,1,1,0.9459088444709778,0.9840817451477052,0.9902476668357848,1.0,accept,unanimous_agreement
800575488,9822,outdated comment,0,0,0,0.5482138991355896,0.9271469712257384,0.9380747675895692,0.0,accept,unanimous_agreement
800575700,9822,spare blank lines,0,0,0,0.9829134345054626,0.9446619153022766,0.9687267541885376,0.0,accept,unanimous_agreement
800579980,9822,"i think this check could mean that in some cases, we'll never manage to shrink the buffer, since there's a chance it'll always have data. this brings me to two other realizations: 1. when bufpos is 0, there's no need for a realloc (it might be faster to free and malloc (no need to memmove). 2. i see we update buf_peak in _writetoclient. this means that when we append to the buffer, it's used size (`bufpos`) can be larger than the peak. so when we remove this check (`bugpos != 0`), we better move the updates of the peak to `_addreplytobuffer`",0,0,0,0.9334527254104614,0.9886045455932616,0.9742470383644104,0.0,accept,unanimous_agreement
800581884,9822,please list all the interface changes in the pr's top comment (the ones for info and for client list) i.e. add a section about interface changes.,0,0,0,0.9870228171348572,0.9886146783828736,0.9947834610939026,0.0,accept,unanimous_agreement
800744217,9822,i don't like that these are upper case. they are variables and should be lower case.,-1,-1,-1,0.9780877828598022,0.9816505312919616,0.9838922023773192,-1.0,accept,unanimous_agreement
800750992,9822,"i also don't understand this check. `bufpos` isn't relevant to us. only the peak is relevant. we might want to add an assert that `bufpos` <= `buf_peak`. we might also want to add an assert that `buf_preak` <= `buf_usable_size`. regarding `realloc` i think it'll be always faster to `zmalloc`, `memcpy` `bufpos` bytes and then `free` than to use `realloc`.",0,0,0,0.9626774787902832,0.9883053302764891,0.9622191190719604,0.0,accept,unanimous_agreement
800758024,9822,are these reset in `resetserverstats()`? if not please add them.,0,0,0,0.986666738986969,0.99517422914505,0.9955037236213684,0.0,accept,unanimous_agreement
800820372,9822,i agree. this was initially panic check and i agree it can be removed. regarding moving the peak handling into _addreplytobuffer i will do that.,0,0,0,0.9324032068252563,0.8144962787628174,0.9101153016090392,0.0,accept,unanimous_agreement
800820821,9822,sure - will be done once i push the next changes,0,0,0,0.9673148989677428,0.976201057434082,0.9882727265357972,0.0,accept,unanimous_agreement
800821108,9822,-steinberg o.k i will make this change,0,0,0,0.7540808916091919,0.9649085402488708,0.9618818163871764,0.0,accept,unanimous_agreement
800822114,9822,-steinberg you are totally correct. i missed that one. will be fixed asap,1,0,1,0.9212842583656312,0.5523234605789185,0.6847972869873047,1.0,accept,majority_agreement
800850462,9822,-steinberg i agree that since we are switching size classes the realloc would probably not operate in-place. however since realloc follows the same logic as allocate->copy->free i prefer using an existing api rather than implementing about the same logic. do you feel that it brings noticeable performance cost?,0,0,0,0.9564087986946106,0.9804783463478088,0.9230135083198548,0.0,accept,unanimous_agreement
801056420,9822,-steinberg multi-line `if` statements have the `{` in a separate line (less confusing). you meant to reply to yoav's followup on my [a link]. i'll respond there,0,0,0,0.9858367443084716,0.9646264910697936,0.9485953450202942,0.0,accept,unanimous_agreement
801057292,9822,"-steinberg i suggested to use free+malloc, in case `bufpos` is 0, instead of realloc. not to use malloc+memcpy+free.",0,0,0,0.98007994890213,0.9932345747947692,0.969782054424286,0.0,accept,unanimous_agreement
801560916,9822,i edited the pr comment. take a look when you have the time and tell me if it is well explained.,0,0,0,0.9741859436035156,0.9510481357574464,0.9885242581367492,0.0,accept,unanimous_agreement
801563250,9822,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
801563819,9822,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
801564532,9822,i have implemented the suggestion. if that looks reasonable to you i will resolve that case issue.,0,0,0,0.9694381952285768,0.9544042348861694,0.9868200421333312,0.0,accept,unanimous_agreement
801574648,9822,what -steinberg requested seems more intuitive to me and it provides a simpler rules for other developers as for a single line if we request the '{' on the same line. but i would go with whatever is the current convention in our code i looked at this example [a link] which is like what suggested at first. so i will change it back,0,0,0,0.9339518547058104,0.9506801962852478,0.9740025997161864,0.0,accept,unanimous_agreement
801577457,9822,"we must avoid lowering the peak to below the used size, it could later cause us to shrink to that size and lose data. [code block]",0,0,0,0.9797261357307434,0.9871053695678712,0.9831488132476808,0.0,accept,unanimous_agreement
801580149,9822,"since you saved one call by using zrealloc_usable, we can do that here too. [code block]",0,0,0,0.9847645163536072,0.988913118839264,0.9953626394271852,0.0,accept,unanimous_agreement
801586480,9822,"styling: `if` condition with multiple lines, should have the open `{` in a separate line. otherwise, it's hard to distinguish between the condition and the actions. p.s. the alignment of the additional condition lines should probably either be indented by 4 compared to outer scope, or indented to after the `if` opening `(`. see the indentation of the `else-if` below. p.p.s that `else-if` is also missing a space before the `(`",0,0,0,0.9810574054718018,0.993503987789154,0.990575909614563,0.0,accept,unanimous_agreement
801591699,9822,"for growing, it makes sense to grow incrementally, i.e. each time the peak==usable it means we reached the max we could reach, and we can grow to *2. but for shrinking, if a client suddenly became silent, or started issuing small commands, there's no need to incrementally shrink it by half each time. maybe we can do better, like shrink it to the size of the peak? or maybe to double the size of the recent peak?",0,0,0,0.9721569418907166,0.9820563197135924,0.9774128794670104,0.0,accept,unanimous_agreement
801605817,9822,i agree,0,0,0,0.934429407119751,0.8392824530601501,0.9744842648506165,0.0,accept,unanimous_agreement
801662772,9822,i agree. that sound reasonable. i can change it to shrink to last peak size + 1,0,0,0,0.7879063487052917,0.5068125128746033,0.6334165334701538,0.0,accept,unanimous_agreement
801726855,9822,"for a moment i preferred last peak * 2, but actually, malloc is likely to give you some 30% extra, so +1 is good.",1,0,0,0.9351781606674194,0.911512553691864,0.7711382508277893,0.0,accept,majority_agreement
801730104,9822,great - can you please help me in running the tests again? i cannot trigger them myself and i think the results are outdated,1,1,1,0.6556984186172485,0.9609982967376708,0.7579783201217651,1.0,accept,unanimous_agreement
807225755,9822,"the code is synchronous, why use async `after`? i.e. why not just: [code block]",0,0,0,0.9831936359405518,0.9941412806510924,0.9937392473220824,0.0,accept,unanimous_agreement
807227554,9822,"if we have this here, why do we need the other test?",0,0,0,0.9639310240745544,0.9845949411392212,0.9893562197685242,0.0,accept,unanimous_agreement
807229900,9822,"even with this one, i think we better re-write it without the async `after`, might be easier to understand with a simple loop that runs 500 times and sleeps 100.. p.s. since all of this could be running on a slow machine and redis might be starved of cpu, we need longer timeouts. or alternatively, just wait for the effect we aim for, and then assert for how long it took",0,0,0,0.9584776759147644,0.9730142951011658,0.9745551347732544,0.0,accept,unanimous_agreement
807230715,9822,"since all these tests are very slow, i'd rather add an `if {$::accurate)` which will prevent them from running in the normal execution of `./runtest`. alternatively, maybe the 5 seconds interval we chose for the peak adjustment is too high? setting it to 1 second could have meant that this test will be over in 3 rather than 15.",0,0,0,0.9745965600013732,0.9798229336738586,0.9769392609596252,0.0,accept,unanimous_agreement
807770454,9822,if we're shrinking and `c->buf` == 1 then the realloc here might do an implicit memove of `new_buffer_size` instead of just 1. because we're shrinking to half the size (or less) then it's almost certain the realloc wll perform a new allocation and won't keep the original one. so i think it's better to to a `zmalloc_usable` regardless of `bufpos`. and then do a memcpy from the old pointer to the new of `bufpos` size (0 being a nop).,0,0,0,0.9828851222991944,0.9899277091026306,0.9879945516586304,0.0,accept,unanimous_agreement
807849272,9822,i feel that making the tests fast shouldn't drive setting constant values. so i'm for keeping it at 5. of course this can be a hidden config which we'll set in the tests to make them quicker.,0,0,0,0.7955777645111084,0.9486005902290344,0.97611802816391,0.0,accept,unanimous_agreement
807863062,9822,i think the test can be independent from the 5 sec constant by using a `wait_for_condition` call. we need to verify the buffer starts large (missing in the current test) and then goes down to 1k.,0,0,0,0.9868674278259276,0.9917365908622742,0.9894278645515442,0.0,accept,unanimous_agreement
807866883,9822,might be good to show that the size doesn't go over 16k even if we read a variable larger than 16k. and also might be worth checking that we grow to intermediate values like 4k (although less critical).,0,0,0,0.939908504486084,0.9915035963058472,0.9867245554924012,0.0,accept,unanimous_agreement
808136383,9822,-steinberg i also agree. i suggested at some point that maybe we can allow tuning this feature in the debug command?,0,0,0,0.93960040807724,0.9726352095603944,0.9601331949234008,0.0,accept,unanimous_agreement
808142488,9822,-steinberg - good suggestion - i will add this,1,1,1,0.8726515173912048,0.9909268617630004,0.9882425665855408,1.0,accept,unanimous_agreement
808145523,9822,-steinberg i initially started to check intermediate values. but i wanted to first introduce the basic cases. the main problem is that the malloc tests will fail since it will not be aligned to the same size classes imo.,0,0,0,0.9328259229660034,0.9639787673950196,0.8781346082687378,0.0,accept,unanimous_agreement
808710574,9822,"yes, look at the implementation of `""key-load-delay""` config variable. this is probably where something like this should be (assuming agrees).",0,0,0,0.9877150058746338,0.9915577173233032,0.9940555095672609,0.0,accept,unanimous_agreement
808712687,9822,"i think just checking that the buffer's under 16k but over 1k is enough to verify ""intermediates"". doesn't need to be exact or assume specific size classes.",0,0,0,0.986066997051239,0.981206715106964,0.9831311702728271,0.0,accept,unanimous_agreement
808717551,9822,"i'm not certain that this mechanism justifies a hidden config. (loading delay is heavily used by many tests). i agree that generally, it would be wrong to change the threshold of the code just because we want the test to be fast, but in this case i'm not sure why we chose the 5 seconds threshold. i remember arguing that we can't rely on the rate of the clientscron since it could sometimes be much faster, but that doesn't mean we can't limit it to 1 second. on the other hand, since this test it not that important, i don't mind running it only when `--accurate` is given (daily ci and before release)",0,0,0,0.7248477935791016,0.9155399203300476,0.8691443800926208,0.0,accept,unanimous_agreement
808732586,9822,+1 for `--accurate`.,0,0,1,0.9014115333557128,0.9730542302131652,0.8442180156707764,0.0,accept,majority_agreement
810587256,9822,"so we'll wait an additional 5 seconds per client? that's unacceptable. even waiting 5 seconds after the loop for all clients to be resized (one 5 seconds delay in contrast to one per client) would be too much. we should either find some trick to avoid the buffer being resized (keep a high peak), or we add a hidden config for this this shrinking and set to very high value.",-1,-1,-1,0.9435333609580994,0.8278601169586182,0.9505704045295716,-1.0,accept,unanimous_agreement
810589422,9822,"the clients are no expected to wait 5 seconds. i mainly did that in order to provide some upper limit. the clients are starting idle, so i only want to make sure the cron will shrink their buffers (does not require 5 seconds peak reset) however i am supportive for some feature disablement mechanism. i offered to support a debug sub command to disable this feature but a config is also possible.",0,0,0,0.7151309847831726,0.9041787385940552,0.978659689426422,0.0,accept,unanimous_agreement
810590524,9822,"ohh, i now realize that setting `buf_peak_last_reset_time` to 0 at client creations means that it's gonna get resized for the first time very quickly, possibly before it manages to send anything. maybe that's not wise? maybe we should either set `buf_peak_last_reset_time` to ""now"" on client creation, or if we set it to 0, we should probably set the startup `c->buf` to `proto_reply_min_bytes` instead of `proto_reply_chunk_bytes`. setting it to min_bytes (and setting `reset_time` to 0) could cause a bigger performance regression, so from performance standpoint, we better keep the big allocation, and use ""now"". on the other hand, using min_bytes will make our tests easier... but as noted earlier, test shouldn't influence production decisions. so please use ""now"" and add a debug control for this threshold (i think it's slightly better than a hidden config for this purpose).",0,0,0,0.9151710867881776,0.9606208205223083,0.824637234210968,0.0,accept,unanimous_agreement
810645085,9822,"not a real concern, but let's use the same approach used elsewhere in this file, and call getlongfromobjectorreply",0,0,0,0.985255002975464,0.9871156811714172,0.8563855290412903,0.0,accept,unanimous_agreement
810645743,9822,"while we're at that. let's change the resolution here to milliseconds. currently use're using either 0, 5 or infinite. but maybe we'll find use for fractions of a second soon. also, it makes much more sense, that a client that connected just one millisecond before the `unixtime` changed, will get handled a full second earlier, than a client that connected 1 millisecond after the `unixtime` changed.",0,0,0,0.9689472913742064,0.9880841374397278,0.9829831123352052,0.0,accept,unanimous_agreement
810646587,9822,"this test now needs to be tagged with `needs:debug`. and also maybe we should vert that setting at the end, for the case the test runs against an external server, so it's the same server used for other units later. p.s. is that the only test that was flaky?",0,0,0,0.9788599014282228,0.9931623935699464,0.9871709942817688,0.0,accept,unanimous_agreement
810646778,9822,"we can now drop the accurate, and maybe use 100ms peak-reset-time to still validate that things aren't reset too soon or too late? p.s. the comment below about 5 seconds, is outdated. and also, let's reset the peak-reset-time back at the end, for a case the test is run against an external server. also same comment about `needs:debug` tag",0,0,0,0.9844197630882264,0.9909942746162416,0.994009017944336,0.0,accept,unanimous_agreement
810650845,9822,yes that was the only test that failed.,0,0,0,0.9325551986694336,0.9828451871871948,0.9725462198257446,0.0,accept,unanimous_agreement
810659418,9822,"made this change. i also migrated to use the clientscron taken ""current time"" to be more accurate",0,0,0,0.984631359577179,0.9866926074028016,0.993699550628662,0.0,accept,unanimous_agreement
810847312,9822,"i think i meant to use `server.mstime` instead of `server.unixtime` i'm not sure why clientscron samples `mstime()` on it's own.. but well, don't care either way.",-1,0,0,0.6045072674751282,0.8061960935592651,0.8228675723075867,0.0,accept,majority_agreement
810847866,9822,"fyi, when m said ""reset"" i thought that the test suite will just set it back to 5.. but this way is ok too.",0,0,0,0.95377779006958,0.9463417530059814,0.670163631439209,0.0,accept,unanimous_agreement
810853771,9822,i see my report indicated a few other tests failed: [a link] please look into this and let me know when done.,0,0,0,0.9728964567184448,0.9293887615203856,0.98716402053833,0.0,accept,unanimous_agreement
810871993,9822,i initially did use the server mstime. but felt now_ms would be even more precise :),1,1,1,0.9381993412971495,0.9872905611991882,0.9771881103515624,1.0,accept,unanimous_agreement
810872820,9822,i think it is better to keep defaults located at a single place so that in case we will decide to change it in the future will not have to cover many places...,0,0,0,0.9669137001037598,0.9731141328811646,0.9772868156433104,0.0,accept,unanimous_agreement
810880615,9822,"1. the error in ""evict clients in right order"" was fixed. the issue was related to the fact that the last clients was not freed due to the memory optimization (it was reducing memory under 128k) 2. the error in replybufsize test was as a result of using libc malloc and not jmalloc. i made several fixes there and is should not fail. 3. the third error (use takeover to bring slaves back: failed: caught an error in the test err you should send cluster failover to a replica err you should send cluster failover to a replica) i was unable to reproduce again when i run the daily on a private branch. but in case the upcoming daily will fail i can look into it...",0,0,0,0.8654192090034485,0.9877389073371888,0.680513322353363,0.0,accept,unanimous_agreement
810925561,9822,what changes did you make for the `replybufsize.tcl` failures?,0,0,0,0.9739779233932496,0.995215892791748,0.994562327861786,0.0,accept,unanimous_agreement
810928212,9822,mainly checking that the value is between 1kib to 2kib after shrinkage,0,0,0,0.9770203828811646,0.9854499101638794,0.9903742074966432,0.0,accept,unanimous_agreement
1417307871,12822,i think we wanna keep calling it `expires`,0,0,0,0.9830931425094604,0.9585867524147034,0.9800087213516236,0.0,accept,unanimous_agreement
1417337995,12822,"i think we should still have dbfind, that's a wrapper over dafind, and implicilty finds the slot (dict index).",0,0,0,0.9888694286346436,0.9836519956588744,0.9855117201805116,0.0,accept,unanimous_agreement
1417345174,12822,"i wonder if the term ""slots"" is right in that context? maybe it should be dicts, and dictindex? i.e. the hashing and slot indexing is still calculated from outside (db.c), right? so the dict-array is just a generic array of dictionaries, nothing specific to hash-slots? and the dbxxxx interfaces are the ones that do the slot magic?",0,0,0,0.9668560028076172,0.9929481744766236,0.9691939353942872,0.0,accept,unanimous_agreement
1418261513,12822,should i wrap all `da*` apis that take a slot with a `db*` function that calls `getkeyslot`?,0,0,0,0.9873383045196532,0.9951711297035216,0.9948055148124696,0.0,accept,unanimous_agreement
1418262356,12822,"yes, i guess i can just call it `length` and `length_bits`?",0,0,0,0.9878929257392884,0.9880287051200868,0.9928089380264282,0.0,accept,unanimous_agreement
1418882476,12822,"not sure about all, but certainly the common ones. (find, and maybe add and remove)",0,0,0,0.9674688577651978,0.9674581289291382,0.9397008419036864,0.0,accept,unanimous_agreement
1418886207,12822,"we need to consider all the other references to ""slot"" and ""slots"" in this file. it could be ""length"" / ""count"" and ""index"". or ""num_dicts"" and ""dict_idx"". i suppose the right way to find out is to try and rename them all and see what feels right.",0,0,0,0.9797458052635192,0.9916933178901672,0.9872283935546876,0.0,accept,unanimous_agreement
1419477763,12822,"i don't like introducing acronyms for brevity unless they are common, since it just increases the time it takes for folks to understand something. db is a very common one and i have no other association outside of database, da to me is a district attorney (it's also yes in russian).",-1,-1,0,0.9734774231910706,0.595064103603363,0.5121743679046631,-1.0,accept,majority_agreement
1419491140,12822,"yeah, we discussed this in the per-slot dictionary pr, but it didn't really fit there. i agree, we should just rename stuff and see what sticks.",0,0,0,0.9519296884536744,0.9711437821388244,0.975494384765625,0.0,accept,unanimous_agreement
1431028182,12822,i rather avoid adding members to the `dict` struct. maybe this can still be part of `dicttype`?,0,0,0,0.9715057015419006,0.994380533695221,0.9900813698768616,0.0,accept,unanimous_agreement
1431570770,12822,i wonder why we had that dictsize call? is it completely excessive? or was there some hidden reason? can you check the blame log?,0,0,0,0.5087865591049194,0.7695428729057312,0.88536137342453,0.0,accept,unanimous_agreement
1432234677,12822,"i'm open to suggestions but i don't think ""db"" is a good choice because it should be an abstract ds (in addition, it doesn't necessarily represent a database, because also we use it to hold all volatile keys, which are just a subset of the whole database)",0,0,0,0.952073574066162,0.9165552854537964,0.9549187421798706,0.0,accept,unanimous_agreement
1432235222,12822,"i'm keeping this comment open for now because i think ""volatile_keys"" is a better name... let's see what others think",0,0,0,0.9424968957901,0.9689913988113404,0.8707178235054016,0.0,accept,unanimous_agreement
1432240913,12822,"it dates back to before 2010, a lot of code movements in these early years, i gave up after 5-6 such commits my guess is that it was just an attempt to save some cpu cycles for hashing the keyname in case there are no volatile keys? perhaps in case a user doesn't even work with volatile keys at all? should i revive that check? or better yes, early-exit inside dictdelete if the dict is empty?",0,0,0,0.8909419775009155,0.9368715286254884,0.9893871545791626,0.0,accept,unanimous_agreement
1432370917,12822,"maybe `dictarr` or `darr`? i.e. we don't want to invent a new a 2 letter abbreviation, but we're ok to create a new term / class name as long as it's easily distinguishable / grep-able, right? we said we're gonna use `didx` instead of `slot`, right? and then `count` or `dcount` instead of `slot_conut`? i'd vote for: * `dictarr` for function prefix * `didx` instead of `slot` * `dcount` for length",0,0,0,0.9615330100059508,0.99277263879776,0.9850016832351683,0.0,accept,unanimous_agreement
1432371103,12822,"we need to make sure that `_cursor` doesn't use more than `64-num_dicts_bits` bits, otherwise `adddictindextocursor` will mess up",0,0,0,0.9032946825027466,0.9867669939994812,0.9852243661880492,0.0,accept,unanimous_agreement
1432373086,12822,"i think we should add some code to detect this case, and then fail scan with some error. since it's a runtime error, and not a logical error in the code, i don't think killing the process with an assert is right. wdyt?",0,0,0,0.9753625988960266,0.6382907032966614,0.9789846539497375,0.0,accept,unanimous_agreement
1432526610,12822,"ok, but i prefer `darr` as function prefix objections?",0,0,0,0.986478626728058,0.9853817224502563,0.9932838678359984,0.0,accept,unanimous_agreement
1432528100,12822,"for the record, this problem exists in unstable today",0,0,0,0.9748477935791016,0.5891586542129517,0.9836986064910888,0.0,accept,unanimous_agreement
1432540086,12822,i'm ok with it (4 letters is better than 2). let's wait for madelyn's input.,0,0,1,0.968933880329132,0.881722092628479,0.6241917014122009,0.0,accept,majority_agreement
1432543340,12822,"dictfind has an early abort if the dict is empty. anyway, fine. let's dismiss it.",0,0,0,0.9566943645477296,0.926645040512085,0.9929053783416748,0.0,accept,unanimous_agreement
1432548944,12822,"ok, so i'm leaving the code as-is and resolving this comment",0,0,0,0.9800866842269896,0.9799883365631104,0.9931017160415648,0.0,accept,unanimous_agreement
1433097057,12822,"yeah, we are relying on some assumption that we can only support 2^48 items in a dictionary, which is far beyond what we could practically support. (the dictionary would be at least 1pb in size alone) we could consider adding a static assert here to bound the size of the number of dicts, just so it's clearer.",0,0,0,0.961792528629303,0.9767816066741944,0.891779899597168,0.0,accept,unanimous_agreement
1433964880,12822,makes sense (to add a an assert on the number of dicts).. i didn't bother to do the math.,0,0,0,0.8901881575584412,0.9588569402694702,0.9842921495437622,0.0,accept,unanimous_agreement
1433966080,12822,"please comment on the above terminology, and maybe generally what you feel about merging this pr.",0,0,0,0.9801988005638124,0.976498246192932,0.9876871705055236,0.0,accept,unanimous_agreement
1440981737,12822,"my impression is that after we do this refactoring, completely rewriting the internal storage of how we store kv in redis should have ""zero"" impact outside of db.c. i think this command should stay as dbscan, modules shouldn't care what the underlying implementation of the db is and shouldn't need deep knowledge into what is below the interface.",0,0,0,0.9325072765350342,0.966618835926056,0.9684504270553588,0.0,accept,unanimous_agreement
1440983204,12822,this seems like it's exposing a lower abstraction than should be visible.,0,0,0,0.9284607768058776,0.9203270673751832,0.7785068154335022,0.0,accept,unanimous_agreement
1440991343,12822,"so, my three main thoughts on naming are: 1. i don't think the dictarray should be so widely visible inside of redis. i think we want to abstract away the actual in-memory storage of key/values inside of db.c as much as possible with clear apis. if this pr reflected that abstraction, i think the naming of dictarray is fine, as it is the current datastructure we are using. however, the current pr exposes it in server.h and calls the apis from all over the place. 2. do we want to be naming it based on the physical implementation or the role that it fills. it is physically an array of dictionaries, but we could also just call it `rediskv` and basically get the same result. it would have a more fixed api over. 3. i don't really like dictarray, as my first guess would be a merging of a dict + array. (like an associative array backed dictionary that is has very fast scanning i guess). i remember soloestoy had some suggestion like dicts or multidict which i think better captures the structure. (this is not something i would fight very hard about) you also mentioned using something like darr as an abbreviation, we can spend the couple of bytes to use `dictarray` can't we?",0,0,0,0.8320325016975403,0.974937617778778,0.9469101428985596,0.0,accept,unanimous_agreement
1440992747,12822,"we don't normally add copy right information in the header files, it's normally the actual code files.",0,0,0,0.9832883477211,0.9911518692970276,0.991258442401886,0.0,accept,unanimous_agreement
1440994821,12822,"i don't know what dict extension means, i assumed this was going to be growing the dicts which seems related to the rehashing but there is also a debug command here.",0,0,0,0.9707204699516296,0.8363778591156006,0.943544626235962,0.0,accept,unanimous_agreement
1441001069,12822,"i mean. i think volatile_keys is a better name, but i'm not convinced changing it for the sake of change is a great idea.",1,0,0,0.8794922232627869,0.776897668838501,0.6689680814743042,0.0,accept,majority_agreement
1444290977,12822,"ok, we can place wrappers for dbscan and dbsize in db.c, like we have for dbfind. i wonder if this is the only dependency of module.c with the db dicts, if not, maybe we should leave it for the day we actually need to decouple them.",0,0,0,0.9536453485488892,0.9919386506080629,0.9848021864891052,0.0,accept,unanimous_agreement
1444294665,12822,i'm in favor of just keeping the same variable name we had in 7.2. i.e. this pr will make the diff between 8.0 and 7.2 slightly simpler (compared to what's in unstable now),0,0,0,0.9667049050331116,0.984740436077118,0.9694281220436096,0.0,accept,unanimous_agreement
1444297445,12822,"i was ok with `dictarray`, but i actually like the suggestion of `rediskv`. how about `kvstore` instead? (not to mention redis in the name)",1,0,0,0.6025537848472595,0.8786114454269409,0.6414778828620911,0.0,accept,majority_agreement
1444501508,12822,so all the `db*` wrappers will not take the actual struct as a parameter (work on `keys` implicitly),0,0,0,0.9883588552474976,0.994513988494873,0.9941166639328004,0.0,accept,unanimous_agreement
1444504535,12822,i think in this case (the memory satats command) it should be low level. i.e. this function is conceptually part of db.c (found itself in object.c by coincidence),0,0,0,0.9864539504051208,0.9915384650230408,0.9876947402954102,0.0,accept,unanimous_agreement
1445840679,12822,changed to `kvstore` can i resolve this comment?,0,0,0,0.9883347749710084,0.992134928703308,0.9955571293830872,0.0,accept,unanimous_agreement
1445873948,12822,added `dbscan` which takes a `redisdb*` can i resolve this comment?,0,0,0,0.9894573092460632,0.9938176274299622,0.9959272742271424,0.0,accept,unanimous_agreement
1457608969,12822,looks like you forgot to remove it from the server struct,0,0,0,0.9734233617782592,0.9843549728393556,0.9902342557907104,0.0,accept,unanimous_agreement
1457692428,12822,couldn't it still be null?,0,0,0,0.9482701420783995,0.9902918934822084,0.9726154804229736,0.0,accept,unanimous_agreement
1457693957,12822,"wtf! and also !! that's why i never trust mass search and replace, i do them manually one by one.",-1,-1,-1,0.9913082718849182,0.9939246773719788,0.9949093461036682,-1.0,accept,unanimous_agreement
1457707776,12822,don't we have dbfind again now? or did you do that to avoid calling getkeyslot twice (it should have internal cache),0,0,0,0.9856404066085817,0.9928684830665588,0.9907093048095704,0.0,accept,unanimous_agreement
1457734561,12822,just want to comment that i wasn't happy with these loops (and enum itself). happy to see them go away.,-1,1,1,0.934115469455719,0.6365980505943298,0.9435631036758424,1.0,accept,majority_agreement
1457740163,12822,let's document the input argument. that's log2 of the size (and 0 indicating one dict),0,0,0,0.987223982810974,0.9907495379447936,0.994354009628296,0.0,accept,unanimous_agreement
1457752305,12822,"the comment is outdated. also, please double check that a call to dbfindexpires returns asap if it's completely empty",0,0,0,0.9481764435768129,0.9847191572189332,0.9925836324691772,0.0,accept,unanimous_agreement
1457774669,12822,missing some doc comment,0,0,0,0.8948582410812378,0.9677335023880004,0.9742910861968994,0.0,accept,unanimous_agreement
1457789267,12822,i noticed we lost all the warning and debug logging from this method not sure they were absolutely necessary though.,0,0,0,0.5199612975120544,0.932971715927124,0.9398989081382751,0.0,accept,unanimous_agreement
1457805017,12822,let's add some header explaining what this class does / why / how.,0,0,0,0.9767693877220154,0.9790144562721252,0.9939942955970764,0.0,accept,unanimous_agreement
1457807441,12822,let's document why we do these assertions,0,0,0,0.9821200966835022,0.9730625748634338,0.993688941001892,0.0,accept,unanimous_agreement
1457810463,12822,we're missing the size of the kvstore struct itself.,0,0,0,0.9444513320922852,0.9859116077423096,0.9829095602035522,0.0,accept,unanimous_agreement
1457819705,12822,again. i'm happy.. this is so much better (all the logic about creating and destroying the data structure isn't duplicated 8 times),1,1,1,0.9889674782752992,0.995237112045288,0.993063986301422,1.0,accept,unanimous_agreement
1457826522,12822,so you folded htneedsshrink (from server.c) into dictshrinktofit (and renamed it)? let's mention that in the top comment (it took me a moment to figure this out),0,0,0,0.985171914100647,0.9904178977012634,0.9913105964660645,0.0,accept,unanimous_agreement
1457834139,12822,note to self: re-review all the rehashing changes in server.c and kvstore.c after the next rebase (skipped them now),0,0,0,0.9828299880027772,0.993822693824768,0.989093542098999,0.0,accept,unanimous_agreement
1457836643,12822,does that comment require an update?,0,0,0,0.9800265431404114,0.9934104084968568,0.9939284324645996,0.0,accept,unanimous_agreement
1457839748,12822,"so we have another 8 bytes of memory usage per dict, that's 16384*2*8 (~200k). but maybe with internal frag it's more?",0,0,0,0.9838829636573792,0.9855452179908752,0.9908843636512756,0.0,accept,unanimous_agreement
1457869763,12822,"that would be a regression, right? kvstore does'nt destroy the dict when it becomes empty, right?",0,0,0,0.9750025272369384,0.9788397550582886,0.98679381608963,0.0,accept,unanimous_agreement
1457870782,12822,"with regards to the above comment, if we fix this, we need to revive this condition",0,0,0,0.9796282649040222,0.9925945401191713,0.9853472709655762,0.0,accept,unanimous_agreement
1457871405,12822,same here.,0,0,0,0.9813250303268432,0.9755119681358336,0.9916109442710876,0.0,accept,unanimous_agreement
1457889881,12822,"the references to ""cluster"" should be changed.",0,0,0,0.9843644499778748,0.9901187419891356,0.9900944828987122,0.0,accept,unanimous_agreement
1457890651,12822,why did you move from serverassert to assert? i think we can afford to include redisassert.h,0,0,0,0.9808757305145264,0.9901419281959534,0.9931672215461732,0.0,accept,unanimous_agreement
1457956830,12822,some leftovers using the `da` prefix?,0,0,0,0.9816245436668396,0.9943872690200806,0.9944085478782654,0.0,accept,unanimous_agreement
1457963295,12822,"please mention in the top comment, that you changed pubsub_channels to kvstore and why. please also mention the reason in the code (e.g. here, and maybe somewhere in pubsub.c)",0,0,0,0.9870490431785583,0.9928913116455078,0.993575632572174,0.0,accept,unanimous_agreement
1461641708,12822,"no, kvstore's dicts always exist",0,0,0,0.9807074666023254,0.9878994822502136,0.9922083020210266,0.0,accept,unanimous_agreement
1461644663,12822,oopsie,-1,-1,-1,0.5412648916244507,0.7886216640472412,0.7876375913619995,-1.0,accept,unanimous_agreement
1461648255,12822,"i wanted to avoid getkeyslot the caching only works if `server.current_client->slot` is valid, if it's not, two calls to getkeyslot will actually calculate the hash twice",0,0,0,0.9832005500793456,0.987531840801239,0.986478328704834,0.0,accept,unanimous_agreement
1461648489,12822,me too,0,0,0,0.9384154081344604,0.9069059491157532,0.9800850749015808,0.0,accept,unanimous_agreement
1461656072,12822,"why is the comment outdated? and yes, it does",0,0,0,0.9030842781066896,0.953973114490509,0.9871376752853394,0.0,accept,unanimous_agreement
1461713484,12822,"yes, it didn't feel right calling `serverlog` from `kvstore.c` wdyt?",0,0,0,0.9423137307167052,0.9747971296310424,0.9862629175186156,0.0,accept,unanimous_agreement
1461728896,12822,"there is no `serverassert` in all other core ds (dict.c, listpack.c, etc.)",0,0,0,0.9879443645477296,0.9939380884170532,0.993378758430481,0.0,accept,unanimous_agreement
1461741482,12822,"it's technically correct, but i think it's redundant (it's obvious the metadata affects the total overhead)",0,0,0,0.9390867352485656,0.9548473358154296,0.968148946762085,0.0,accept,unanimous_agreement
1462696215,12822,correct,0,0,0,0.9691285490989684,0.8340582847595215,0.98023784160614,0.0,accept,unanimous_agreement
1462696857,12822,"not sure what you mean by ""regression"" in this case correct, kvstore's dicts always exist, even if empty",0,0,0,0.9633737802505492,0.9196993112564088,0.9229646921157836,0.0,accept,unanimous_agreement
1462702884,12822,"done, but couldn't find an appropriate place to mention it in pubsub.c",0,0,0,0.982555627822876,0.949685513973236,0.977742612361908,0.0,accept,unanimous_agreement
1462846582,12822,"the comment was for code that did `dictsize` before doing `dictfind`. now that you call `dbfindexpires` without any checks, it's no longer relevant.",0,0,0,0.9500689506530762,0.9939163327217102,0.9918550252914428,0.0,accept,unanimous_agreement
1462850819,12822,"i agree, but i'm not sure how much we need them, and if we wanna still make some effort to show them, e.g. special return value from kvstoreexpand. i.e. these are cases where the expansion failed (skipped) because of insufficient memory.",0,0,0,0.9761691689491272,0.7331198453903198,0.9747886657714844,0.0,accept,unanimous_agreement
1462852370,12822,"for our knowledge, can you calculate the diff when taking internal frag into account? wdyt?",0,0,0,0.9854561686515808,0.9450230598449708,0.9925009608268738,0.0,accept,unanimous_agreement
1462854344,12822,"i mean that the previous code dismissed the unused dicts, and now they always exist. maybe we should modify kvstore to be able to dismiss empty dicts? maybe we don't want that in the main db keys, but we do want that in pubsub? wdyt?",0,0,0,0.9854726195335388,0.9820601940155028,0.989404559135437,0.0,accept,unanimous_agreement
1462855577,12822,"ohh, right. it uses `#include ""redisassert.h""`, and this one does too.",0,0,0,0.962593674659729,0.9705067276954652,0.9734727144241332,0.0,accept,unanimous_agreement
1462953757,12822,let's take this opportunity to attribute some of this code to vitaly / hpatro / aws who invested a lot of effort in dict.c and didn't that line there. please advise.,0,0,0,0.9115679860115052,0.9036112427711488,0.9841164946556092,0.0,accept,unanimous_agreement
1464113250,12822,"i'm against adding this type of copyright for a specific person/company since it's almost always not accurate, since other people contribute. i think we should just say, [code block] this is also not legally binding based on what i've been told, so it doesn't matter what we put here, so i would rather us just be inclusive and generic to avoid people trying to update it.",-1,0,0,0.5270137786865234,0.8653768301010132,0.6629263758659363,0.0,accept,majority_agreement
1464122576,12822,i don't really want to pay an extra 200kb just because? what is the material value of adding this as opposed to the previous implementation.,0,0,-1,0.8710107803344727,0.5218663215637207,0.7078015804290771,0.0,accept,majority_agreement
1464123509,12822,"yeah, we did that for the pubsub dictionaries to avoid the unnecessary overhead when it wasn't being used (since we expect many users wouldn't use it at all).",0,0,0,0.9857893586158752,0.9914237856864928,0.9845257997512816,0.0,accept,unanimous_agreement
1464128934,12822,"[code block] i don't know why people started putting underscores in method names, we use static to indicate it's private most places.",0,0,0,0.912622332572937,0.9849084615707396,0.9790562987327576,0.0,accept,unanimous_agreement
1464132396,12822,"i don't get the abstraction if you can: 1. get the underlying dict to directly manipulate it. (kvstoregetdict) 2. have high level apis to set data in the underlying store. (kvstoredictsetkey) there is a bunch actions where you can do the same thing two ways, and i would rather us be opinionated. either you should always call kvstoredictfind() and then operate on it or always call the higher level apis (what i would prefer).",0,0,0,0.8949061036109924,0.7917596697807312,0.9070613980293274,0.0,accept,unanimous_agreement
1464132944,12822,"might have missed something, but i don't see this used anywhere.",0,0,0,0.7821320295333862,0.9285162687301636,0.8786829113960266,0.0,accept,unanimous_agreement
1464135138,12822,"while we're here, why is this in acl.c? should we push this over to pubsub.c?",0,0,0,0.9733664393424988,0.993371605873108,0.9933613538742064,0.0,accept,unanimous_agreement
1464140517,12822,"does this need to be a separate struct? it seems to just add a lot of ""->state."" everywhere, which doesn't seem that useful.",0,0,0,0.8575242757797241,0.9481797814369202,0.8417494893074036,0.0,accept,unanimous_agreement
1464140871,12822,"can we make this an opaque pointer, i.e. only define it inside the .c file, so external users go through the apis and don't try to access anything. same with the iterator i suppose.",0,0,0,0.988069474697113,0.9886094331741332,0.9923580288887024,0.0,accept,unanimous_agreement
1464363604,12822,"yeah i can do that i guess thoughts? but how often does it happen that we run out of memory while expanding a dict? i mean, if we're that close to oom, why shouldn't we just panic while expanding instead of the next time someone inserts one key too much?",0,0,0,0.7032638192176819,0.8133974671363831,0.8525698781013489,0.0,accept,unanimous_agreement
1464366158,12822,"in the previous implementation redis itself managed the `rehashing` list of rehashing dicts, and thus it could trigger the rehashing-related functions in the correct `kvstore` (either main or volatiles) we want all `kvstore`'s logic to be self-contained, so we need each dict to have a reference to its `kvstore` instance having said that, i'm open to suggestions, maybe there's a way to keep everything contained to kvstore.c without the 200k additional overhead",0,0,0,0.9799724221229552,0.974658191204071,0.9912607073783876,0.0,accept,unanimous_agreement
1464368775,12822,"so what's the verdict? do we want `kvstore` to deallocate empty dicts? if so, why shouldn't we do it in the main `kvstore`? i'm assuming that if clustering mode is used, there's probably more than one shard, and assuming fair distribution, maybe it's safe to assume that >0/5 of the hash slots are unused in every shard.",0,0,0,0.982030749320984,0.9889960289001464,0.9855319857597352,0.0,accept,unanimous_agreement
1464373978,12822,"it's actually not about being close to oom, it's about someone requesting more memory than the total memory the system has (i.e. asking got 80gb on a 64gb machine), if it comes from rdb parser, we panic, and if it comes from debug reload, we gracefully skip it. come to think of it then, i'm ok dropping these prints then.",0,0,0,0.7465955018997192,0.8865700364112854,0.8532446026802063,0.0,accept,unanimous_agreement
1464376087,12822,"maybe the rehashing list should be global? i.e. declared in the kvstore struct as static? that would solve it, right?",0,0,0,0.9851962327957152,0.9941646456718444,0.9882281422615052,0.0,accept,unanimous_agreement
1464378705,12822,"yes and no. there are few concerns: 1. if sharded pubsub is completely unused, let's not allocate all these dicts. 2. for the sharded keyspace, indeed we'd rather not allocate dicts for slots that aren't assigned to the current node. 3. but on the other hand, we'd rather not de-allocate a dict every time it becomes empty, and re-allocate it when a key is added again. maybe the easiest way forward is to add a per-kvstore flag, so that pubsub can behave differently than the keyspace ones?",0,0,0,0.9489854574203492,0.9915146827697754,0.9784029722213744,0.0,accept,unanimous_agreement
1464382096,12822,i did it because `dictmetadatasize` was already defined as a macro in dict.h i'll add the `kvstore` prefix instead of an underscores,0,0,0,0.9863907098770142,0.9938045740127563,0.9934492707252502,0.0,accept,unanimous_agreement
1464387260,12822,please see the top comment i'm all in favor of dropping `kvstoregetdict` and wrap every dict-specific action with a `kvstoredict*` function ?,0,0,0,0.9859731197357178,0.9851436018943788,0.99261075258255,0.0,accept,unanimous_agreement
1464418634,12822,"i think some low level operations may still need to access the dict directly. maybe like in db.c, and defrag.c. which is why i wanted to wrap most common apis, but avoid wrapping the rarely used complex / low level ones. can you sum the gaps here (a quick list of places that use dict directly and which function)?",0,0,0,0.9856398105621338,0.9844558238983154,0.985741138458252,0.0,accept,unanimous_agreement
1464533527,12822,"good idea, i'll add it in a seperate commit",1,1,1,0.8432682156562805,0.9288552403450012,0.9737711548805236,1.0,accept,unanimous_agreement
1464535704,12822,"i'd try to argue that the ones in rdb.c, evict.c, defrag.c, and db.c are ok to use low level dict access. and that maybe the pubsub and cluster ones should be resolved. this means adding kvstoresizeatindex(), kvstoreget[safe]iteratoratindex(), and kvstorefetchvalue(). is that right? let's wait for madelyn's response before acting.",0,0,0,0.9793691039085388,0.9936771988868712,0.9884222149848938,0.0,accept,unanimous_agreement
1464550992,12822,"i'd love that, but it won't make sense to have everything opaques and still give direct dict access relates to [a link]",1,1,1,0.961198627948761,0.9841464161872864,0.9646732807159424,1.0,accept,unanimous_agreement
1464554573,12822,"it's not only the rehshing list, it also needs to update `bucket_count` whenever a dict is done rehashing",0,0,0,0.9861181378364564,0.9916748404502868,0.9922795295715332,0.0,accept,unanimous_agreement
1464610352,12822,do we want to trouble ourselves with constant memory overheads? same goes for that other 200k overhead,0,0,0,0.8784951567649841,0.773099958896637,0.9336379170417786,0.0,accept,unanimous_agreement
1464614560,12822,imho it's all or nothing - i want to get rid of `kvstoregetdict` and turn `kvstore` opaque,0,0,0,0.7706581950187683,0.9215500950813292,0.9816161394119264,0.0,accept,unanimous_agreement
1464782119,12822,"ohh, before that we had different callback for each, and the callback knew which counter to increment. well, maybe we can do that here too somehow. (not suggesting to generate code on the heap this time :stuck_out_tongue: ) the easiest way would be to add a callback user_data, and add it to the dicttype struct. this way, each kvstore instance, will have a different cloned dicttype struct (actually it already does), and the user_data pointer in that struct will be a pointer to the kvstore instance. so instead of 8 extra bytes per dict, we have 8 extra bytes per kvstore.",0,0,0,0.832697331905365,0.9834409952163696,0.5457977652549744,0.0,accept,unanimous_agreement
1465723506,12822,i'm in agreement with personally. we want to make it more of a modular interface to better abstract the code.,0,0,0,0.9324585795402528,0.8569004535675049,0.9610466361045836,0.0,accept,unanimous_agreement
1465885159,12822,"i fear it'll not really be opaque or abstracted. some mechanisms could require intimate knowledge of the dict. so we'll just end up wrapping a lot of very low level functions. anyway, i don't care too much either way. for all i care we can leave it for later, or we can do that and re-consider and break later.",-1,-1,-1,0.960204780101776,0.8943225741386414,0.8611374497413635,-1.0,accept,unanimous_agreement
1465892783,12822,"i was wondering why it was like that. i suppose it was an attempt to release a dictentry value, without assuming anything about which destructor this value uses. i see it was added in c84248b5d2 in place of `dictfreeval(db->dict, &auxentry)` i suppose it's not that bad for db.c to assume it knows how values are destructed, but wanted to raise that for discussion. fyi.",0,0,0,0.4437375366687774,0.8207578659057617,0.6077283620834351,0.0,accept,unanimous_agreement
1465898284,12822,"this is 1mb, not 200k, i.e. in case sharded pubsub isn't used at all. and it's another ~2mb on shards that don't have a lot of slots (for keys and expires). i do think we should make an effort to reduce there. i can imagine some cases with many small shards in which it'll cause a significant impact. i don't think this pr should bother to make a distinction between slots that are unassigned, and ones that are simply empty. but it is quite easy to avoid regression compared to what's before this pr, and avoid keeping empty pubsub dicts (1mb), and avoid the extra per-dict kvstore pointer in [a link] so let's do that.",0,0,0,0.8903185129165649,0.8908017873764038,0.9661213159561156,0.0,accept,unanimous_agreement
1467002679,12822,i think i wrote it for some reason of abstraction. don't remember why. calling decrrefcound directly is totally fine.,1,0,0,0.6761783957481384,0.923367977142334,0.9299116134643556,0.0,accept,majority_agreement
1468258009,12822,"this was the core of my original objection to this pr. if someone needs to know what is behind it, then i don't want this abstraction. the idea right now is that structure is index + key -> value, it shouldn't strictly matter what is behind it as long as we are upholding that abstraction.",0,0,0,0.6523573398590088,0.6626385450363159,0.643292248249054,0.0,accept,unanimous_agreement
1470889858,12822,"i think this comment is outdated also, maybe part of it now belongs in kvstoretryresizedicts?",0,0,0,0.9608733654022216,0.9889147877693176,0.982871413230896,0.0,accept,unanimous_agreement
1472557170,12822,"use of ""da""",0,0,0,0.9714410305023192,0.9906244874000548,0.9917750358581544,0.0,accept,unanimous_agreement
1473841772,12822,"please comment if you think we should drop this flag. it means that a cluster node will only allocate a dict when the slot is assigned to it and populated, but on the other hand, when the slot is unassigned, the dict will remain allocated. till now all 16k dicts were always allocated. i'm worried that someone will find it odd. p.s. maybe we can add a kvstore interface to explicitly release a specific empty dict, and call it when a slot is unassigned?",-1,-1,-1,0.9527119994163512,0.978771150112152,0.9785287380218506,-1.0,accept,unanimous_agreement
1478426990,12822,maybe you wanna look into that?,0,0,0,0.9758475422859192,0.99015873670578,0.980840027332306,0.0,accept,unanimous_agreement
1479151459,12822,"there seems to be something missing here: `kvs->resize_cursor = (didx + 1) % kvs->num_dicts;` otherwise, there is no way to proceed with resize_cursor, i will test it #13031",0,0,0,0.9700304269790648,0.9908533692359924,0.9934107661247252,0.0,accept,unanimous_agreement
1479325744,12822,"we keep falling on that test in daily because it is skipped in the ci cycle. in retrospect, i should have run daily on such a big pr before merging it.",0,0,0,0.5518650412559509,0.966602861881256,0.671409010887146,0.0,accept,unanimous_agreement
1479398743,12822,"there seems to be something wrong here. kvstoredictdelete will release the dict if the dict become empty, and in the next loop, we will call dictnext. on my local machine, 25-pubsubshard-slot-migration.tcl will fail: [code block] i currently add this to avoid errors: [code block] #13033",0,0,0,0.9317898750305176,0.9868052005767822,0.7153923511505127,0.0,accept,unanimous_agreement
1479527849,12822,"the fix looks good. can you make a pr, and also search for other similar issues with pubsubshard_channels? (which is the only one currently deleting dicts that become empty)",1,1,1,0.9465433359146118,0.8953840732574463,0.9652920365333556,1.0,accept,unanimous_agreement
1491811791,12822,"it's not that annoying. it's a bit weird that for static configurations there won't be the extra overhead, but there will be if you scale out and add move slots to other nodes. i don't think it's likely a big issue, and now that there is an interface we can improve it later.",-1,-1,-1,0.975164532661438,0.9900143146514891,0.4842104017734527,-1.0,accept,unanimous_agreement
1492307888,12822,i'm bothered by two things: 1. after resharding there's wasted memory which we can reclaim. 2. the memory usage depends on the history and not just current state. isn't it really simple to solve? some 10 trivial lines of code?,-1,-1,-1,0.9728956818580629,0.8234571814537048,0.9787351489067078,-1.0,accept,unanimous_agreement
1495412092,12822,i see madolson also reacted with a thumbs up emoji. i try to add it in #13072,0,0,0,0.9716640710830688,0.7003431916236877,0.7220020890235901,0.0,accept,unanimous_agreement
722914454,9564,is there a reason you are putting it first? it seems like the code we way shorter if was just added as an optional field at the end.,0,0,0,0.971175253391266,0.9919195175170898,0.981310248374939,0.0,accept,unanimous_agreement
722914674,9564,"this file is autogenerated, so let's not touch this.",0,0,0,0.6688107252120972,0.9640966653823853,0.992733359336853,0.0,accept,unanimous_agreement
757925962,9564,"during upgrades new nodes won't be able to exchange messages with old nodes, since the layout of data has changed. take a look at this pr, [a link] which adds a way to add extensions (it's not merged but hopefull will be soon). i also don't think we need to gossip the hostname, as nodes will eventually learn the hostname through regular ping/pong messages.",0,0,0,0.9731231927871704,0.9878316521644592,0.9899175763130188,0.0,accept,unanimous_agreement
757926086,9564,"my guess is this makes more sense as a config, since you'll want to set it at startup.",0,0,0,0.9835875630378724,0.971206784248352,0.9736180305480956,0.0,accept,unanimous_agreement
757926372,9564,"i think we should maybe do something like, ""pining node ( )"", or something to indicate it's the name and not sure the word after.",0,0,0,0.9758999943733216,0.980819046497345,0.9813056588172911,0.0,accept,unanimous_agreement
757926527,9564,"you tried to fix this, but there is actually a tab here which is causing the incorrect spacing.",0,0,0,0.9782368540763856,0.7501566410064697,0.9857444167137146,0.0,accept,unanimous_agreement
757926594,9564,"if a human readable name is not set, this looks like it will break. we still need to be backwards compatible. i don't really have answer to this since the cluster nodes format doesn't allow additional fields since slots is variadic. we could add more optional fields at the end.",0,0,0,0.8956501483917236,0.8741047978401184,0.951849639415741,0.0,accept,unanimous_agreement
798161459,9564,"now i regret not spending the effort to try to make this structure more extensible. i don't feel strongly against how it's currently implemented, but if you want to spend some time trying to make it extensible, i think that would be useful. my thinking was we could add a format like ""aux: "" which can be placed before the slot ranges but after the required arguments.",-1,0,-1,0.8061845302581787,0.6244544982910156,0.9623687863349916,-1.0,accept,majority_agreement
798162059,9564,also would need a corresponding redis.conf change.,0,0,0,0.9895465970039368,0.9933589100837708,0.9946908354759216,0.0,accept,unanimous_agreement
798162297,9564,"i wasn't thinking of this as a different endpoint type, just a way to identify a node in a cluster logically. the use case i had in mind was being able to assign an ec2 id to a node to be able to look it up separately.",0,0,0,0.9589260220527648,0.9739514589309692,0.9845897555351256,0.0,accept,unanimous_agreement
798162529,9564,"someone else made the fair comment that hostname should have been an sds, since we frequently call strlen. probably should update this to sds.",0,0,0,0.9864140152931212,0.9796594977378844,0.987859070301056,0.0,accept,unanimous_agreement
798162740,9564,"if we're going to do this, we should probably just call sdscatfmt multiple times, incrementally adding on the data.",0,0,0,0.9863798022270204,0.985121726989746,0.983667016029358,0.0,accept,unanimous_agreement
798163131,9564,this is the main use case i was thinking about for node name. you can print it out here so that the logs have information that is useful to humans.,0,0,0,0.9843481183052064,0.9700835347175598,0.9920560717582704,0.0,accept,unanimous_agreement
798163570,9564,looks like all of this is removed now.,0,0,0,0.9652830362319946,0.9772672653198242,0.9859707951545716,0.0,accept,unanimous_agreement
815973657,9564,i add a new item in redis.conf for cluster-announce-nodename,0,0,0,0.9884594082832336,0.9914699196815492,0.9949329495429992,0.0,accept,unanimous_agreement
815975195,9564,"update it to sds as the ""hostname""",0,0,0,0.9886187314987184,0.993932008743286,0.9954147338867188,0.0,accept,unanimous_agreement
815997051,9564,yeah what you're saying makes sense. so we don't need the cluster_endpoint_type_nodename then? i have removed the relevant code to this. let me know if you think that is fine. thanks,1,1,1,0.9598345160484314,0.9249398708343506,0.9750305414199828,1.0,accept,unanimous_agreement
847781581,9564,were you going to add the name here?,0,0,0,0.9850500226020812,0.99289071559906,0.9921568632125854,0.0,accept,unanimous_agreement
847791338,9564,[code block] maybe something like this so it's clear that there is an empty name there? otherwise it'll look like there is an awkward 2 spaces there. not a strong opinion here.,-1,0,-1,0.7494730949401855,0.82331383228302,0.8944535255432129,-1.0,accept,majority_agreement
850454805,9564,"yes i agree that would be a better formatting, i have changed to this now. thanks you",1,1,1,0.976462423801422,0.9663383960723876,0.987024426460266,1.0,accept,unanimous_agreement
902281851,9564,i have a similar extension in review (#10536) and then has another (#10869) in the pipeline. i think comma separated strings are general enough and can continue to work in the foreseeable future (until we settle on a new format). can you please review [a link]? please expand cluster.c and check out line 255 in the new version). i have also refactored the extension building logic so that it is relatively easier to add new extensions.,0,0,0,0.9725705981254578,0.985823392868042,0.8519945740699768,0.0,accept,unanimous_agreement
902561575,9564,"afaict my pr ""gossip forgotten nodes"" doesn't touch this address information. it uses the node name only. regarding the format, i suggested an uri query string form for optional key-value pairs: `ip:port?hostname=example.com&nodename=asdfasdfasdf&shardid=1234652347653`",0,0,0,0.9776284098625184,0.9899600744247437,0.9905186295509338,0.0,accept,unanimous_agreement
902695057,9564,"sure, thanks i will review it.",1,1,1,0.8877230286598206,0.6192505955696106,0.8305440545082092,1.0,accept,unanimous_agreement
903327896,9564,that is a clever hack! it is just that the hostname extension is already out now. we would have to think about whether/how to upgrade the clusters that enable hostname. also the string here is part of the `cluster node` output - would a uri query string format cause more confusion to the existing clients than a comma-separated-string?,1,1,1,0.6447109580039978,0.907450556755066,0.9460694789886476,1.0,accept,unanimous_agreement
903329843,9564,"since hostname is already there, we can just start with optional stuff after hostname: `ip:port,example.com?nodename=asdfasdfasdf&shardid=1234652347653`. i don't think so. why would it?",0,0,0,0.9649890065193176,0.9914905428886414,0.9867005944252014,0.0,accept,unanimous_agreement
905611565,9564,"it is just a hunch - the hostname introduced the `,` separator and it feels safer (don't know how to quantify that) if we continue with that pattern. uri queries seem like a new game for all kinds of parser out there. so there seem to be 3 proposals 1. the uri query string (but keep the hostname as is) 2. the continuation of `,` 3. the `-` vote? can you please chime in when you get a chance too? for me, it will be 2, 1 and 3 from high to low, preference-wise",0,0,0,0.830194890499115,0.8941479325294495,0.9544098377227784,0.0,accept,unanimous_agreement
908019512,9564,"we have the benefit that we restrict what is allowed in a hostname, alphanumberic dashes and dots, so we should be able to use ? as a delimiter. i would prefer not to use the uri just because of parsing. i will still re-advocate my proposal, which is that we can add fields at the end as long as they don't start with numbers. some format like `field:value` as long as they don't have spaces. besides that, i would agree with 's ranking.",0,0,0,0.9146476984024048,0.6833989024162292,0.9671064615249634,0.0,accept,unanimous_agreement
908019607,9564,yeah.,0,0,0,0.9548547267913818,0.9600284695625304,0.9681332111358644,0.0,accept,unanimous_agreement
908020355,9564,"so, sort of a last thing? thoughts about calling this either: 1. cluster-announce-human-node-name 2. cluster-announce-human-node-id nodename might be a bit confusing, since it's overloading the more normal ""nodename"" associated in fqdns and the nodeid. injecting in human or human readable seem like it would be good.",0,0,0,0.8916202783584595,0.9791224598884584,0.9775334000587464,0.0,accept,unanimous_agreement
908320034,9564,"... so 3 (dash) is out because hostnames can contain dashes. it sounds like you're suggesting `?field1:value1?field2:value2`. it is very similar to `?field1=value1&field2=value2`. i suppose the complexity of the uri parsing you're referring to is the percent encoding. how about we just skip that? we don't have any characters that would need to be percent-encoded anyway (yet) and we can avoid adding fields with such values. parsing is simple, but in languages with a uri query parser in the standard library, they can use that too.",0,0,0,0.9629114270210266,0.977581262588501,0.9747048020362854,0.0,accept,unanimous_agreement
908826413,9564,"right old 3) (`-`) is out. so the new list 1) aux (like this?) `823ca5eb86404530a2cd1f6beee7ed9c00e786fb 127.0.0.1:30001,host-name master aux1:val1 aux2:val2 aux3:val3 ... - 0 1656441238093 1 connected 0-5460` 2) uri query strings `823ca5eb86404530a2cd1f6beee7ed9c00e786fb 127.0.0.1:30001,host-name?field1=val1&field2=val2&field3=val3... master - 0 1656441238093 1 connected 0-5460` 3) the "","" separator `823ca5eb86404530a2cd1f6beee7ed9c00e786fb 127.0.0.1:30001,host-name,val1,val2,val3,... master - 0 1656441238093 1 connected 0-5460`",0,0,0,0.9660670161247252,0.9930819869041444,0.9896910190582277,0.0,accept,unanimous_agreement
913071869,9564,"the example that pingxie outlined in 1 is what i'm suggesting. i was actually suggesting putting it after the slot ranges, but it can go any place.",0,0,0,0.986681342124939,0.972528636455536,0.9916290044784546,0.0,accept,unanimous_agreement
943694666,9564,i suppose people were maybe looking to me to make a decision here. i'm ultimately indifferent between option 1 and 3 outlined here. do you have any preference.,0,-1,-1,0.501075804233551,0.7557855844497681,0.7574467658996582,-1.0,accept,majority_agreement
944532773,9564,"i prefer the option1, becuase the option3 is a little bit wired (or we call it is not traditional) for admin side. thanks",1,1,1,0.9660221338272096,0.9411841630935668,0.970340371131897,1.0,accept,unanimous_agreement
952128072,9564,"ok, will you have a chance to implement that here, otherwise can implement it on his pr.",0,0,0,0.9823318123817444,0.9766119122505188,0.9937404990196228,0.0,accept,unanimous_agreement
952320923,9564,"if a client splits each line by spaces and assume that each element (column) has a fixed position, these clients will break when we introduces more elements separated by spaces. that was my concern, but i haven't found any such client (though i haven't searched thoroughly either). for cluster routing, most clients seem to use cluster slots nowdays and they should probably switch to cluster shards in the future.",0,0,0,0.947559654712677,0.9807066917419434,0.9502024054527284,0.0,accept,unanimous_agreement
952332309,9564,i found one client that assumes the slot ranges start at column 8: [a link],0,0,0,0.9854834079742432,0.9774696230888368,0.9941744208335876,0.0,accept,unanimous_agreement
953230753,9564,"you aren't supposed to be using `cluster nodes` for topology discovery. i know some clients do use it though, we should probably be encouraging them to move to `cluster shards`.",0,0,0,0.9847516417503356,0.9901302456855774,0.9827053546905518,0.0,accept,unanimous_agreement
953388035,9564,"agreed that we should move folks off of `cluster nodes`. i think as part of this exercise, we can codify it at [a link] when the dust settles. what do you guys think about a hybrid of option 1 and 3? ` 823ca5eb86404530a2cd1f6beee7ed9c00e786fb 127.0.0.1:30001,host-name,aux1=val1,aux2=val2,aux3=val3,... master - 0 1656441238093 1 connected 0-5460 ` both aux names and values can be of alphnum only. the order of these new aux fields is insignificant. not the most intuitive format but seems to have the lowest appcompat risk while being more explicit and easier to work with than the original option 3 (comma-separated). thoughts?",0,0,0,0.9301904439926147,0.9828118681907654,0.9778939485549928,0.0,accept,unanimous_agreement
953436394,9564,"agree, but old clients which do this will stop working with new redis. also, clients are very often designed to work with multiple versions of redis, so they need to use cluster slots or cluster nodes at least as a fallback. as you know, cluster nodes is more efficient than cluster slots for fragmented slot intervals. splitting by space and assuming things about the positions might also be exploited by other tools and scripts. i think we can avoid this breaking change if we can. i like ping's last suggestion.",0,1,0,0.5615971684455872,0.8595992922782898,0.7666510939598083,0.0,accept,majority_agreement
956177431,9564,"i like your suggestion, let's do that. any parsing that's already broken by the hostname stuff will just be further broken, so that seems like a good trade-off for readability.",1,1,1,0.7609429359436035,0.837909460067749,0.7957984805107117,1.0,accept,unanimous_agreement
956502204,9564,sounds good! should i add it to my pr next?,1,1,1,0.9875727891921996,0.976794183254242,0.9909421801567078,1.0,accept,unanimous_agreement
957880930,9564,"sure, we can merge that one first, and then rebase and merge this one.",0,0,0,0.985629141330719,0.990431010723114,0.9877200722694396,0.0,accept,unanimous_agreement
959771438,9564,"sorry, just notice this comment. i will update this part and rebase this pr",-1,-1,-1,0.9897283315658568,0.9927803874015808,0.9909061193466188,-1.0,accept,unanimous_agreement
959907879,9564,"could you please add this on the top desceiption of your pr? 823ca5eb86404530a2cd1f6beee7ed9c00e786fb 127.0.0.1:30001,host-name,aux1=val1,aux2=val2,aux3=val3,... master - 0 1656441238093 1 connected 0-5460 then we could know much clearer for the final format for cluster infomation,",0,0,0,0.978595733642578,0.9894997477531432,0.9956010580062866,0.0,accept,unanimous_agreement
959908269,9564,"please let me know when you finish your part, thanks",1,1,1,0.9224468469619752,0.7481772899627686,0.9371596574783324,1.0,accept,unanimous_agreement
960243499,9564,will do. i have been swapped by some other issues on my end recently but hopefully i can get to it next week.,0,0,0,0.5966741442680359,0.9591514468193054,0.5891323089599609,0.0,accept,unanimous_agreement
1133118822,9564,"[code block] is there a reason that nodename can't be an aux field? the idea was that aux fields would be generic and we could add more later, it should remove some of this parsing code ideally.",0,0,0,0.9877523183822632,0.9949522018432616,0.9933733940124512,0.0,accept,unanimous_agreement
1133119347,9564,"[code block] hostnames don't need to be ip addresses, they can be fqdn as well.",0,0,0,0.988006055355072,0.9930393099784852,0.9951477646827698,0.0,accept,unanimous_agreement
1133119403,9564,should this almost implement the nodename as well?,0,0,0,0.9878249168395996,0.9926151037216188,0.9920781254768372,0.0,accept,unanimous_agreement
1133120132,9564,"i don't think we have such a strong requirement for naming here, so i think we can use isvalidauxstring() in cluster.c for this.",0,0,0,0.9771058559417723,0.9767464399337769,0.987722098827362,0.0,accept,unanimous_agreement
1133120238,9564,"we had a previously conversation about this, but i still don't think we should have this be an endpoint type. the main use case for me is for administrators to assign useful names to nodes for debugging. a client would need a lot of custom logic to support this, so unless you feel strongly i would drop all of this.",0,0,0,0.8349716663360596,0.8934955596923828,0.9733405709266664,0.0,accept,unanimous_agreement
1133120306,9564,"this seems like it's left over from the pr that moved a bunch of changes to notices, i think this should still be a notice.",0,0,0,0.9782931208610536,0.9761568903923036,0.973511815071106,0.0,accept,unanimous_agreement
1133121504,9564,the other use case for the human node name is that in these messages you could print out the human readable node name. i thought in a previous iteration of this pr we had done that.,0,0,0,0.9862691760063172,0.990456759929657,0.9929301142692566,0.0,accept,unanimous_agreement
1140556271,9564,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
1140556447,9564,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
1140557658,9564,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
1140557800,9564,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
1140558673,9564,"we are not using this procedure to read nodename or hostname, here i made this change to make sure we read the shard-id correctly from cluster nodes command output because in aux field now we have nodename and shard-id and nodename is optional parameter.",0,0,0,0.9872812628746032,0.9951575398445128,0.9938775897026062,0.0,accept,unanimous_agreement
1159995489,9564,this spacing is trippy [code block],0,0,-1,0.9837254881858826,0.98775452375412,0.9819621443748474,0.0,accept,majority_agreement
1159998081,9564,"[code block] we know these are null terminated strings, but people like to report that we aren't using ""safe"" functions.",0,0,0,0.9081955552101136,0.9604238271713256,0.894899308681488,0.0,accept,unanimous_agreement
1160010892,9564,let's update the function in cluster.c to accept char * + length so this can become: [code block],0,0,0,0.9871580004692078,0.9901469349861144,0.9940710663795472,0.0,accept,unanimous_agreement
1160013722,9564,"this spacing was done in other tests to just keep git history. i probably should have documented that, but we can do normal spacing here.",0,0,0,0.9826662540435792,0.9912257790565492,0.988464057445526,0.0,accept,unanimous_agreement
1160015050,9564,[code block] the test this was copied from probably doesn't need replicas either,0,0,0,0.9863697290420532,0.9788151383399964,0.9918226599693298,0.0,accept,unanimous_agreement
1160032084,9564,do we still need this test?,0,0,0,0.982935667037964,0.9903447031974792,0.9924907088279724,0.0,accept,unanimous_agreement
1160039900,9564,let's move these into cluster_util.tcl so we can deduplicate them with the other test.,0,0,0,0.9875714778900146,0.9949949979782104,0.9930887818336488,0.0,accept,unanimous_agreement
1160049756,9564,i'm going to stick behind we probably don't want this in the shards output. there was another discussion where we should probably have an admin variant of shards: [a link] i think this would be appropriate there.,0,0,0,0.9778941869735718,0.7918704748153687,0.9725775718688964,0.0,accept,unanimous_agreement
1163242486,9564,"sure , i have removed the nodename from shards output.",0,0,0,0.988554298877716,0.9912147521972656,0.991672933101654,0.0,accept,unanimous_agreement
1163244021,9564,"sure, removed the unnecessary spacings.",0,0,0,0.9863065481185912,0.9613866209983826,0.9927710890769958,0.0,accept,unanimous_agreement
1163245064,9564,i have replaced strcmp with strncmp as suggested.,0,0,0,0.9855855107307434,0.984411895275116,0.994619369506836,0.0,accept,unanimous_agreement
1163245363,9564,i have replaced sdscpy with sdscpylen as suggested.,0,0,0,0.986699104309082,0.986282765865326,0.9949500560760498,0.0,accept,unanimous_agreement
1163246809,9564,yes we don't need replicas for this test . i have updated the test.,0,0,0,0.9838723540306092,0.9713899493217468,0.9921435117721558,0.0,accept,unanimous_agreement
1163247815,9564,"no , we don't need this test. i might have missed to remove the test case while removing the nodename from shard output. i have removed it now.",0,0,0,0.983817994594574,0.9765869975090028,0.992656409740448,0.0,accept,unanimous_agreement
1163248981,9564,"i have moved the procedures to cluster_util.tcl, and removed it from both hostname and humand_announced_nodename test files.",0,0,0,0.9876705408096312,0.9947482943534852,0.994625985622406,0.0,accept,unanimous_agreement
1163249999,9564,"i have updated isvalidauxstring function in cluster.c, so that it can be used in config.c",0,0,0,0.9846583604812622,0.9798704385757446,0.9929948449134828,0.0,accept,unanimous_agreement
1163336284,9564,corrected the code indendation,0,0,0,0.9836417436599731,0.8734256625175476,0.9910011887550354,0.0,accept,unanimous_agreement
1167252883,9564,"[code block] now that the test is gone, this is no longer necessary.",0,0,0,0.9728114008903505,0.9898837804794312,0.9944685697555542,0.0,accept,unanimous_agreement
1167254426,9564,"[code block] i think the intention is we would add these incrementally. i don't think this actually matters, but for future aux fields i assume we'll want this pr to set a good precedent for how to add more.",0,0,0,0.9795498251914978,0.9692206978797911,0.9884047508239746,0.0,accept,unanimous_agreement
1167274022,9564,"hello i believe we don't need the af_start as well. as we are only using it for, for loop initialization and no where else. if it is okay, i would like to remove it.",0,0,0,0.7984967231750488,0.5221000909805298,0.9775376319885254,0.0,accept,unanimous_agreement
1167281898,9564,sounds ok to me.,0,0,0,0.9582507014274596,0.8058957457542419,0.9437352418899536,0.0,accept,unanimous_agreement
1167309763,9564,"great, i have updated all the changes related to enum !",1,1,1,0.9845645427703856,0.991138756275177,0.9933202266693116,1.0,accept,unanimous_agreement
1167755949,9564,"so that's a ""soft"" (backwards compatible) protocol change?",0,0,0,0.9852207899093628,0.9886998534202576,0.9920118451118468,0.0,accept,unanimous_agreement
1167764410,9564,"so we have two configs, one for ""hostname"" (explicitly handled above) and one for ""human nodename"" (handled implicitly in this aux fields loop). the user can config either or both and they'll both be displayed if set? i.e. it's not that one can replace the other.",0,0,0,0.9876355528831482,0.9941840767860411,0.9937153458595276,0.0,accept,unanimous_agreement
1168655213,9564,"hello , hostname is not the aux field and it is handled separately , and yes, both will be displayed based on the configuration, they cannot replace each other. below are the three cases and how they are being displayed. 1. both hostname and nodename is not configured 2. nodename is configured ,but hostname is not 3. hostname is configured , but nodename is not. ![a link]",0,0,0,0.9657171368598938,0.9003633856773376,0.4804960787296295,0.0,accept,unanimous_agreement
1170204392,9564,"yes, it is not only backwards compatible, and it provides more scalability so that cluster nodes could display more items in the future. the previous code is hard code.",0,0,0,0.9788852334022522,0.9658604264259338,0.9893359541893004,0.0,accept,unanimous_agreement
880478330,10515,temp change? i suppose this prevents `help zadd` from showing the command syntax (i.e. needed for the help part that's not suggestions).,0,0,0,0.9869917631149292,0.9713239073753356,0.9858223795890808,0.0,accept,unanimous_agreement
880583642,10515,"`ignorematches` the ""ignore"" part confuses me. maybe `unfiltered`? or `emit_all`?",0,0,0,0.7524535655975342,0.9881900548934937,0.8284092545509338,0.0,accept,unanimous_agreement
880681244,10515,"for ""any order"", don't we want one that does `zrange k 1 2 rev` and see that it suggest `[byscore|bylex]`?",0,0,0,0.9863146543502808,0.994292974472046,0.9930556416511536,0.0,accept,unanimous_agreement
884298704,10515,"yes, the flag name is confusing, but so is its semantics (imo). i'm not satisfied with this function in general. it's overcomplicated and confusing, and i'm hoping to find a way to improve it.",-1,-1,-1,0.9679436087608336,0.9726744294166564,0.9748463034629822,-1.0,accept,unanimous_agreement
884299061,10515,yes. i'll add some test cases here.,0,0,0,0.9815887212753296,0.979540228843689,0.9909907579421996,0.0,accept,unanimous_agreement
884299369,10515,"yes, this was not meant to be committed. i didn't mean to break `help`. will fix.",0,0,0,0.9376543164253236,0.7426416277885437,0.9553899765014648,0.0,accept,unanimous_agreement
895125881,10515,"what's the problem here? this is the test that proves `any` isn't hinted anymore, and it seems to work on your last version",0,0,0,0.9333464503288268,0.9821011424064636,0.9482499957084656,0.0,accept,unanimous_agreement
895171873,10515,"simple - the problem is that i forgot to uncomment the test case... yes, it works.",0,0,0,0.956852376461029,0.9678929448127748,0.9048178791999816,0.0,accept,unanimous_agreement
901077121,10515,"the way i see it, there are a few options: 1. with an old server, fall back to the old matching logic (this is what the code currently does) 2. with an old server, disable arg matching entirely; just give an initial hint with the entire help string and then stop hinting. 3. with an old server. use some heuristics to translate the static syntax strings into a guessed arg spec structure, and use that to support the new matching logic. this might not be too bad, though it wouldn't be that great either. 4. somehow use the command spec tables in `commands.c` as a fallback source for cli hinting. currently that's not practical since `commands.c` includes the `server.h` header file, and we don't want the cli to do that. but maybe we could solve that somehow. we could even use the `since` fields to avoid hinting unsupported commands/args. this wouldn't give hinting for module commands, though. thoughts?",0,0,0,0.8754334449768066,0.9447843432426452,0.9009158611297609,0.0,accept,unanimous_agreement
901082067,10515,"a variant of 4 would be to embed a cached copy of commands.json inside the cli (instead of the help.h we have now). then when command docs fails, we issue an info server instead and use the `since` fields in our cached json to do filtering. maybe in some way it would be easier to store the resp response of command docs in some way, instead of parsing a json. anyway, it looks like a big investment, so we have to consider the pros and cons, since arguably we can maybe drop the hinting entirely (2). what i don't like about the current approach (1) is that it looks like a bug, and also that there's probably quite a lot of code to back it up (including help.h). so arguably, if we invest some effort in either parsing a json, or compiling commands.c into the cli, we'll still be deleting a lot more code that we're adding (since the majority of the code is shared with the case command docs does exits).",0,0,0,0.9478841423988342,0.9244409203529358,0.8296830058097839,0.0,accept,unanimous_agreement
901113896,10515,"the cli currently has code to parse the resp response into an internal structure. it would be annoying to have to add parallel code to do the same for json. if we could store the resp, all that would be missing would be the version filtering. (plus, of course, we still wouldn't have filtering for module commands.)",0,-1,-1,0.9020445942878724,0.8485445380210876,0.9716904759407043,-1.0,accept,majority_agreement
901144830,10515,"it parses resp by using hiredis, it's not the same as handing it a blob of bytes.",0,0,0,0.9545139074325562,0.988275408744812,0.9794892072677612,0.0,accept,unanimous_agreement
901149193,10515,"what i meant is that there is code to read the redis reply structure into the command args table. a similar chunk of code would be needed to consume json instead (actually, in addition). but yeah, we'd also need the resp parser.",0,0,0,0.9839380383491516,0.9886767864227296,0.9905560612678528,0.0,accept,unanimous_agreement
901150748,10515,"looking some more at commands.c, i'm not that happy about compiling it into the cli. the command table currently combines the command arg specs and docs with pointers to the actual implementation functions for the commands. it's both a syntax table and a dispatch table, and probably some other things too. integrating it into the cli code exposes the client to stuff that rightfully should stay server-side. if we want to go that route (of precompiling the arg specs table) i think the ""right"" way to do it is to autogenerate a separate command table for the cli. basically, a replacement for help.h that would fill in the whole `commanddocs` table, including all the arg specs. it would not be necessary to parse anything at runtime, or to have access to the json or resp specs. but it's a lot of data to keep around just for backwards-compatibility - commands.c is 7,400 lines long, and it would presumably be similar. help.h is just 1,850.",-1,-1,-1,0.7055116891860962,0.6079213619232178,0.5187294483184814,-1.0,accept,unanimous_agreement
901150908,10515,"(the *.json files are 18,000 lines!)",0,0,0,0.9743115305900574,0.9846600890159608,0.9923866987228394,0.0,accept,unanimous_agreement
904714578,10515,"okay, i've spent some more time on the issue of legacy servers. a workable solution involves the following: 1. generating a new `cli-commands.c` file containing c structs with only the client-side part of the argument specs. this comes to about 4500 lines of generated code, plus 250 lines of python to generate it. 2. adding code to populate the help tables from that data if `command docs` is not available, filtering by `since`. that adds about 50 lines of code to redis-cli.c, i think. this would give us full hinting support for legacy servers, except for module commands. is it worth it? should i finish the implementation?",0,0,0,0.8047871589660645,0.9682469367980956,0.9397927522659302,0.0,accept,unanimous_agreement
905197464,10515,"if only we could rely on having python available at compile time, then we wouldn't have to maintain these 4500 lines in the repo. maybe we can change the existing python script to add some preprocessor macros to commands.c so that when included from redis-cli.c it'll not include the parts we don't want? this would mean that the current commands.c will be slightly bigger, but we won't have another 4500+250 extra lines sitting in the repo.",0,0,0,0.9771186709403992,0.9921118021011353,0.9827804565429688,0.0,accept,unanimous_agreement
905249722,10515,"bear in mind that this would replace `help.h` (1860 lines) and `generate-command-help.rb` (150 lines), so at least there's that. i don't think macros would solve this cleanly, since there are a lot of struct fields in commands.c we don't need/want, in particular the function pointers. maybe if we `#define` the function names to null... it starts to get very ugly.",-1,-1,0,0.9703811407089232,0.850295901298523,0.5861324667930603,-1.0,accept,majority_agreement
905296116,10515,"that seems easy to resolve. instead of generating lines like this: [code block] it can wrap the reference to the command proc with `cmd_proc()` macro. [code block] then, it can do this on the top: [code block] all that's left is for redis-cli.c to declare `#define cmd_proc(proc) null` before including commands.c.",0,0,0,0.9721654653549194,0.9761733412742616,0.9863516092300416,0.0,accept,unanimous_agreement
905300098,10515,"hmm... that could work... i'll take another look. (though again, there's a lot more ""stuff"" on that line not relevant to the cli. preprocessing it all away won't be pretty. i'm not sure it's better than maintaining two parallel generated files that each contain only what they're supposed to have.)",-1,0,0,0.5612327456474304,0.570706307888031,0.733792781829834,0.0,accept,majority_agreement
905316687,10515,"similar thing can be done with other pieces of information that we don't want. like extracting the key-specs to an external object, like we do for args.",0,0,0,0.9788211584091188,0.9856921434402466,0.988839328289032,0.0,accept,unanimous_agreement
906848860,10515,"okay, i tried extracting key-specs to external tables, and everything compiles and the tests pass... and hinting works for legacy servers. **except** it seems to have broken the module api. (see latest tests.) i don't know the module code well enough to understand how i broke it. all i did was change `key_specs_static` from an embedded array in the command struct to a pointer to an external array.",0,-1,0,0.9199215173721312,0.6628561615943909,0.9100517630577089,0.0,accept,majority_agreement
906880094,10515,never mind - i fixed it. expecting all tests to pass now.,0,0,1,0.9186445474624634,0.8665282726287842,0.6069856882095337,0.0,accept,majority_agreement
907055199,10515,"ptal. iirc this static thing was an optimization to achieve two things: 1. be able to initialize the command table in a declarative way. 2. avoid heap allocations and reallocs, specifically in module.c i suppose there was never any intention to have it a single block of memory (we don't avoid the deference since we don't use it at runtime), and we don't really care about cache efficiency. maybe it is no longer needed, and we can just create it at the right size?",0,0,0,0.7301264405250549,0.9645522832870485,0.958181619644165,0.0,accept,unanimous_agreement
907059941,10515,"i don't understand, we generate another commands.c file (cli_commands.c)? i don't see it added to the repo, and it looks like redis-cli.c does include the normal commands.c is this a leftover?",0,0,0,0.9817739129066468,0.9749553203582764,0.9358536005020142,0.0,accept,unanimous_agreement
907060965,10515,"i don't like to repeat all of these, let's extract them from server.c into commands.h same for the args struct and docs. any reason we can't share the same ones? regarding the macros, since they affect commands.c, i think it's nicer to declare them right before including commands.c, this can either be done directly from redis-cli.c (if there's not much content left in this header), or we can move the include of commands.c here.",0,0,0,0.886166512966156,0.5072214603424072,0.9444687366485596,0.0,accept,unanimous_agreement
907072759,10515,where were these till now? please review the changes in this file.,0,0,0,0.9853553771972656,0.9889993071556092,0.995274007320404,0.0,accept,unanimous_agreement
907073666,10515,"i think we can use the same struct, and just omit some fields as nulls to avoid link errors.",0,0,0,0.9868659377098083,0.9754462838172911,0.9864766597747804,0.0,accept,unanimous_agreement
907075299,10515,leftover? let's delete,0,0,0,0.9798989295959472,0.9890716075897216,0.9535351395606996,0.0,accept,unanimous_agreement
907078239,10515,where was this till now? i must be missing something.,0,0,0,0.7707698941230774,0.8026012182235718,0.6978112459182739,0.0,accept,unanimous_agreement
907079939,10515,"what's new with that `len`? was that suppose to be a runtime calculate field (to support the declarative approach)? i.e. since we went with a generated approach and not a declarative one (commands.c shouldn't be readable or editable), maybe we can change our original intention. ?",0,0,0,0.9854423999786376,0.9942421317100524,0.99044668674469,0.0,accept,unanimous_agreement
907081221,10515,"maybe we should have a more purpose specific define? e.g. command_header_to_include, and if missing we'll include server.h?",0,0,0,0.988103449344635,0.9954230189323424,0.9873758554458618,0.0,accept,unanimous_agreement
907116145,10515,"let's note that in the pr top comment. i.e. that now redis-cli sends an info server at startup (in addition to command, command docs, and possibly hello / auth, right?)",0,0,0,0.9875690340995787,0.9802656769752502,0.9942100048065186,0.0,accept,unanimous_agreement
907118621,10515,"does this assumes the `redis_version` is the first field? i don't think that's good. i rather search the lines until the expected field is found. p.s. maybe we can skip this in case we used hello (extract the version from there). i.e. in the most common case, we save one round trip.",0,0,0,0.980703592300415,0.958686113357544,0.9734228849411012,0.0,accept,unanimous_agreement
907157456,10515,leftover - deleted it.,0,0,0,0.9677966833114624,0.9793161749839784,0.9756592512130736,0.0,accept,unanimous_agreement
907165617,10515,"this enum could be extracted to a header file without a problem. the args struct we could find a way to share, but there are fields used by client and not the server (the arg matching fields), and vice versa (key spec, deprecated, summary). the redis command struct cannot realistically be shared by both. the `rediscommand` struct is massive, and it pulls in many other data types, including the command function pointer, histogram, key specs, get key function pointer, the module command data, etc. separating it from server.h is possible but very difficult and not likely to be clean.",0,0,0,0.9648310542106628,0.9806204438209534,0.9801650047302246,0.0,accept,unanimous_agreement
907166396,10515,i don't have a strong opinion regarding where to define the macros.,-1,-1,-1,0.9126156568527222,0.7516700029373169,0.5567614436149597,-1.0,accept,unanimous_agreement
907169702,10515,"the existing command arg structure stores a single binary flag field with the multiple flags or'd together. i think it's cleaner to have separate boolean fields, which is what i did for the client code. so the script now writes out both the or'd flags and the individual flags, and each macro selects which one to use. but i suppose it's better to standardize on one or the other approach. the number of subargs is not currently used in the struct; it's a null-terminated list and the length is counted at runtime. i don't see why the length can't be available at compile time, so i added it.",0,0,0,0.9605474472045898,0.9826085567474364,0.9840030074119568,0.0,accept,unanimous_agreement
907170074,10515,yes. sorry.,-1,-1,-1,0.987332284450531,0.991940975189209,0.9950159192085266,-1.0,accept,unanimous_agreement
907174084,10515,"there is the group name (""generic"") and a group enum value (command_group_generic). the existing command struct stores the enum value; the cli code stores the string, so i added the string output here. probably better to standardize the code on the same approach. will fix.",0,0,0,0.9822542071342468,0.99136883020401,0.9927617907524108,0.0,accept,unanimous_agreement
907174939,10515,"yes, commands.c contains null-terminated arrays and the length is computed at runtime. but we know the length at compile time and it seems simpler to output it.",0,0,0,0.986346423625946,0.9914280772209167,0.9911303520202636,0.0,accept,unanimous_agreement
907175372,10515,maybe. i don't have a strong preference.,-1,-1,0,0.8529135584831238,0.7205443382263184,0.8355931043624878,-1.0,accept,majority_agreement
907175789,10515,it will only send info server if command docs is not supported.,0,0,0,0.9871348738670348,0.9452475905418396,0.994569718837738,0.0,accept,unanimous_agreement
907176199,10515,"no, it will find the first appearance of `redis_version` regardless of which line it's on.",0,0,0,0.9870977997779846,0.9912755489349364,0.9891296625137328,0.0,accept,unanimous_agreement
907178439,10515,hello does look like a more efficient way to get the version number. what do you recommend?,0,0,0,0.9507400989532472,0.8961493968963623,0.989620566368103,0.0,accept,unanimous_agreement
907297442,10515,"i must be missing something, but i don't understand how there are fields that are used by the cli and not by the server. after all, till now, anyone who used any info from the json files did it by taking it from command command (possibly converted into json). i imagine that it could be that one day we'll have other tools in our repo that want to include this commands.c file, and they might need other bits of info. it easy to filter out the proc and getkeys proc from the data (replacing it with null). regarding the other excessive fields on rediscommand struct, which we don't want to pull into the header file, i suppose we should take this opportunity to split this struct into two parts, anything below the `runtime populated data` comment should move into another struct, and then one struct should point to the other. i.e. either the runtime struct will have a pointer to the static struct, or the static struct will have a `void*` member that's set to a heap allocated runtime struct (i prefer the first approach, will make a cleaner code). another advantage of that would be smaller executable size, since we don't reserve the histogram and other fields in the data segment.",0,0,0,0.943041205406189,0.9700461626052856,0.8530576229095459,0.0,accept,unanimous_agreement
907298935,10515,"i didn't look into the code, but i think redundancy is bad, and i think that bit flags is better than extra boolean fields.",-1,0,-1,0.817488968372345,0.7437905073165894,0.6007125377655029,-1.0,accept,majority_agreement
907301491,10515,"i prefer it.. as i said in another comment, i can see that other tools in our repo might wanna use this too... i think we could include commands.h, and additionally include server.h (by default), or another file if specified by the caller (we can have redis-cli instruct it to include commands.h again)",1,0,1,0.7355511784553528,0.9538707137107848,0.923047661781311,1.0,accept,majority_agreement
907302554,10515,"ok, let's not it in the top comment, it's an important detail imho. also, in case we used hello as an auth, we can take the version from there and skip the call to info.",0,0,0,0.984879195690155,0.8870051503181458,0.978949010372162,0.0,accept,unanimous_agreement
907304746,10515,"ohh, i missed it. hello is only supported starting redis 6.0, and redis-cli only uses it `--user` or `-3` was used. i don't think we can rely on it, but we can use it as an optimization.",-1,0,0,0.8162506818771362,0.8853204846382141,0.907383382320404,0.0,accept,majority_agreement
907361743,10515,"the argument matching code in the cli adds runtime fields to the arg struct to mark which parts have been matched. those fields are not needed by the server. i could use a different mechanism to associate those fields with the args, such as a dict for example.",0,0,0,0.9887265563011168,0.9942038655281068,0.9949064254760742,0.0,accept,unanimous_agreement
907362942,10515,or we could leave a void* field for use as a runtime scratchpad by users of the arg struct.,0,0,0,0.984412968158722,0.9925951361656188,0.9923158884048462,0.0,accept,unanimous_agreement
907391932,10515,"turns out this is harder than i expected. the problem is `const char *command_group_str[]`, a constant array defined in server.c. to make the cli command struct consistent, the cli would also need access to that array to retrieve the group name from the enum code. but it's currently only used in server.c and it's linked internally there. c doesn't let you forward declare a constant array, since the size is unknown. in short, it's much simpler to populate the group name as a string in the generated code than to propagate the enum to both. i guess the array of strings could be defined in commands.c and access to it wrapped in a function...",0,0,0,0.8339265584945679,0.9861069917678832,0.9365394115447998,0.0,accept,unanimous_agreement
907394550,10515,"i still think splitting the rediscommand struct - as much as i agree that it needs to happen - is a much bigger job than you realize. it drags with it several other nontrivial structs and typedefs, some of which are themselves also used elsewhere. and all the code that accesses those fields will need to be modified, along with the code that populates them. this will end up being a significant refactoring to tack on to this pr.",0,0,0,0.850411593914032,0.9233295917510986,0.8485017418861389,0.0,accept,unanimous_agreement
907432041,10515,"i agree it's gonna add some additional dereferecing and touch many lines. but i have a feeling it's the right thing to do (separate the static part from the runtime part, reduce binary size, allow flexibility for other tools to use it). maybe a 3rd option i can think of is to have redis copy the data from the static struct to a runtime one, if it's mainly pointers to static data and not copying the data itself, then it won't increase heap size by mucy..",0,1,0,0.7903085350990295,0.6876295804977417,0.8229747414588928,0.0,accept,majority_agreement
907453639,10515,"if you want to do this, i'd suggest implementing the refactoring in a separate pr which does only that: move the command-related headers from `server.h` to `commands.h` and split `rediscommand` into two structs. the this pr can be rebased onto that.",0,0,0,0.9887725710868835,0.9937865734100342,0.994206428527832,0.0,accept,unanimous_agreement
907708577,10515,"ok, but neither of them is gonna be merged soon (we decided that considering such a big change, the feature isn't justifying the risk of breaking something in a patch level release). so i rather not wait, and keep progressing here. we can make another pr, and merge the same commits here. or add the commits here, and later before merging, extract them to another pr.",0,0,0,0.9731436371803284,0.970819652080536,0.9401456117630004,0.0,accept,unanimous_agreement
907714517,10515,"we can add the array in commands.c , but also i think the strings values of the command command don't have to be the same, so arguably it's ok for redis-cli to define its own array too (as long as there's some static assertion to make sure it's the same size as the enum). but commands.c is probably better..",0,0,0,0.9038845300674438,0.9599049091339112,0.9828755855560304,0.0,accept,unanimous_agreement
943340276,10515,so for now i won't be splitting `rediscommand` - that's too big a change. i haven't changed the args struct either - for now the server and cli have different structs due to the runtime data. if you still think it's important i'll take another look at that.,0,0,0,0.9709283113479614,0.9420450925827026,0.9891383051872252,0.0,accept,unanimous_agreement
943340438,10515,changed back to bit flags.,0,0,0,0.9808279871940612,0.9890366196632384,0.9920043349266052,0.0,accept,unanimous_agreement
943340977,10515,"okay, i moved the array to `commands.c` with a wrapper function exposed in `commands.h`.",0,0,0,0.971955955028534,0.9894087314605712,0.9905691146850586,0.0,accept,unanimous_agreement
943341536,10515,i changed this - i hope i understood your intention. i had to add defines to disable the subtables not needed by the cli.,0,0,0,0.8376896977424622,0.8670620918273926,0.7766464352607727,0.0,accept,unanimous_agreement
943341907,10515,"updated the top comment, and added code to read the version from hello if it's called.",0,0,0,0.986622393131256,0.9913881421089172,0.994097113609314,0.0,accept,unanimous_agreement
943342150,10515,"okay, added a clarifying comment.",0,0,0,0.9830148220062256,0.9635439515113832,0.991203546524048,0.0,accept,unanimous_agreement
943350284,10515,"i agree, let's cut our losses and keep separate structs.",0,0,0,0.9634522199630736,0.9300190210342408,0.8279421329498291,0.0,accept,unanimous_agreement
943368809,10515,"sounds good to me don't we have other places like that? we have some c code for counting arguments too, iirc",1,1,1,0.9378962516784668,0.8267932534217834,0.8595276474952698,1.0,accept,unanimous_agreement
943369987,10515,"i didn't read the whole pr, but how can we keep it declarative if it isn't static?",0,0,0,0.9166995882987976,0.9689031839370728,0.9682573676109314,0.0,accept,unanimous_agreement
943427777,10515,comment can be removed,0,0,0,0.9862093329429626,0.9897183179855348,0.9796491265296936,0.0,accept,unanimous_agreement
943439219,10515,"i think what we have now is already a proof that it doesn't need to be static. i think the way it works is that we declare them in one place and then use the pointer in the command struct, much like what we do with args. i think the reason we had to have static in order for it to be declarative is when we attempted to declare the key-specs from the same block that declares the command (before we really went into the code-generation approach). please try to delete this member. i.e. both `key_specs_static` and the `static_key_specs_num` and see if you succeed. or, if you don't feel comfortable, maybe guy or myself can make a poc branch to try that out and show you what we did.",0,0,0,0.9729737639427184,0.9782446026802064,0.9806560277938844,0.0,accept,unanimous_agreement
943517124,10515,i assume we can compute these at compile-time too no?,0,0,0,0.9825543761253356,0.9861193895339966,0.9915981292724608,0.0,accept,unanimous_agreement
943547243,10515,i assume. probably should too.,0,0,0,0.969190001487732,0.9795759916305542,0.9584004878997804,0.0,accept,unanimous_agreement
943548187,10515,"btw, is key_specs_max even used anywhere? i can only find where it's set.",0,0,0,0.989352822303772,0.9864994287490844,0.988331973552704,0.0,accept,unanimous_agreement
943560255,10515,"yes, it seems it's obsolete (even before this pr) iirc the purpose was to contain the capacity of key_specs (in case we didn't use key_specs_static and had to allocate an array, we might have allocated more than we needed to prevent calls to realloc) anyway, at some point it probably became irrelevant, so i guess we can delete it now",0,0,0,0.9776853919029236,0.9892396926879884,0.98735910654068,0.0,accept,unanimous_agreement
943785934,10515,yes. done.,0,0,0,0.9706167578697203,0.819446325302124,0.910619020462036,0.0,accept,unanimous_agreement
943787145,10515,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
943788664,10515,yes. i removed that too.,0,0,0,0.9803963899612428,0.9848235845565796,0.9921448826789856,0.0,accept,unanimous_agreement
945292044,10515,let's drop that comment.,0,0,0,0.9608723521232604,0.9709847569465636,0.9635618925094604,0.0,accept,unanimous_agreement
945292340,10515,i think that's your leak? you need to release the old pointer,0,0,0,0.9847044944763184,0.9660547375679016,0.9909138679504396,0.0,accept,unanimous_agreement
945293126,10515,"now that we emit these 3 lens, we no longer need the arrays to be null-entry-terminated. note, it may expose some use case that still used to search for that entry, and now needs to use the length.",0,0,0,0.9882959723472596,0.9922677874565125,0.9937745332717896,0.0,accept,unanimous_agreement
945333139,10515,looks like it. thanks.,1,1,1,0.9420533180236816,0.9656366109848022,0.9714942574501038,1.0,accept,unanimous_agreement
945333143,10515,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
945333168,10515,done. didn't seem to cause any problems.,0,0,0,0.9463551044464112,0.900752604007721,0.966560423374176,0.0,accept,unanimous_agreement
1131064621,10515,"including a .c file in another .c file? that file has a macro that controls which file to include instead of ""server.h"", in this case redefined to ""cli_commands.h"" that defines some stuff required in commands.c... it looks a little too much like spaghetti to me. can't this be structured in a slightly nicer way? i have an idea: 1. the code generated from json can be in a file that doens't end in `.c`, for example `commands.def`. this file shoudn't have boilerplace c code such as `#include ""server.h""`. it only has the actual command definitions. 2. `commands.c` is a small file that defines the macros to commands structs used by `redis-server`, includes `server.h` and then includes `commands.def`. this file is compiled to `commands.o` and linked with redis-server. 3. `cli_commands.c` is another small file that defines what's needed for the cli hints, includes `cli_commands.h` and then includes `commands.def`. this file is compiled to its own .o file and linked with redis-cli.",-1,-1,-1,0.5489361882209778,0.7937106490135193,0.7286468148231506,-1.0,accept,unanimous_agreement
1131097360,10515,why isn't testhint() enough? i.e. can't the tests in tcl call `redis-cli --test_hint` for each of the hints to be tested? would that be too slow?,0,0,0,0.9438297748565674,0.9784100651741028,0.985268771648407,0.0,accept,unanimous_agreement
1131102002,10515,this hint helper code is so large that it could be considered to place it in a separate .c file. `redis-cli` is close to 10k lines.,0,0,0,0.9867167472839355,0.9946686625480652,0.9923405647277832,0.0,accept,unanimous_agreement
1132319309,10515,that was my design. i love preprocessor made pasta.. i suppose your suggestion is okay as well. or maybe i had some reason why i didn't wanna move commands.c. don't recall.,1,1,1,0.978565752506256,0.9901220202445984,0.9888707995414734,1.0,accept,unanimous_agreement
1132438077,10515,"my suggested change isn't huge if github is able to detect that a file is renamed with a few changes. well, i've shared my thought. now it's up to you to decide what you want to merge. :)",1,1,1,0.9787577986717224,0.9948721528053284,0.9931198358535768,1.0,accept,unanimous_agreement
1132439463,10515,"i don't have a strong preference for how this should be done. the main point is that both the client and server code should get the parts of the command specs they need, without making the client dependent on `server.h`.",0,0,0,0.8375428318977356,0.949582815170288,0.9474509954452516,0.0,accept,unanimous_agreement
1132440843,10515,"i honestly didn't try it that way. it was just convenient for me to have all the tests in one file. again, whatever works is fine.",0,1,1,0.9190775156021118,0.4013309776782989,0.8763242959976196,1.0,accept,majority_agreement
1132442166,10515,"i agree, in principle. in practice, when i tried separating out the hint code it turned out to be more complicated than i expected, due to some interdependencies (i don't remember specifically which).",0,0,0,0.9693534970283508,0.9654752612113952,0.967177152633667,0.0,accept,unanimous_agreement
1132489174,10515,"yeah i get that and sure this works. but i think maintainability and readability are important too. what i don't like very much is the part of `utils/generate-command-code.py` that generates c code like this: [code block] it's not a very clean interface. if we forget to define some of these macros, it will get a default that is intended for server.h and error messages about rediscommandarg not being defined. better imo to describe what macros are required by the generated code and force the user of the generated code to define them before including the generated code. for example like this: [code block] [code block]",0,0,0,0.5079428553581238,0.5342272520065308,0.6698042750358582,0.0,accept,unanimous_agreement
1133306491,10515,"yes, the test suite txt file is really nice. i was just thinking maybe the test orchestration should be in a test script or so, but it's no big deal. or perhaps wrapped in an `#ifdef redis_test` or so. we do that in some other tests within c files, e.g. dict.",1,1,1,0.5826340913772583,0.9567663669586182,0.9896479249000548,1.0,accept,unanimous_agreement
1133306680,10515,"ok, the globals are messy in this file. leave it then. :+1:",0,-1,1,0.761134922504425,0.987631618976593,0.977325439453125,,review,no_majority_disagreement
1151633559,10515,"i tried following this design and run into some problem. the base of them is the recent reply schema validator (#10273) and the makefile changes in it. the trick there was that when we build redis with the reply schema mode, we use a different commands.c (with different contents), and in order to avoid committing it by mistake, we generate a different file name and link with a different `.o` file name. if we make the same trick here (generating `commands_with_reply_schema.def`), we'll need to keep just one commands.c and commands.o (since they do have some boilerplate code that's not generated). this way we still avoid the risk of committing `commands_with_reply_schema.def` by mistake, but maybe we have a risk of using a wrong command.o during a build. please take a look at [a link] please comment as well. if we don't like that commit, i'll revert it, and we'll keep generating a c file and including it from another c file...",0,0,0,0.9600911140441896,0.9349319934844972,0.8546730875968933,0.0,accept,unanimous_agreement
1151653645,10515,thanks for doing this. i like it! i too realized that it changed with the reply schema version of commands.c and i didn't quite get the time to fix it.,1,1,1,0.9916736483573914,0.9921425580978394,0.9966236352920532,1.0,accept,unanimous_agreement
1151677470,10515,"regarding the build dependencies in your last commit: [code block] the `.c` files are not generated anymore. only the `.o` files depend on the `.c` files and the `.def` files. shouldn't we have rules like `commands.o: commands.c commands.def` instead, or am i missing something? one possibility is to put that boilerplate (`#define make_cmd ...`) in yet another file to include. `commands_boilerplate_glue.h` or whatever... possibly, to avoid using the wrong `commands.o` by mistake: [code block]",0,0,0,0.9798234701156616,0.9944286346435548,0.9882182478904724,0.0,accept,unanimous_agreement
930092041,10966,i'm not sure it is required to propagate the error...,-1,-1,0,0.8480032086372375,0.8912923336029053,0.8556422591209412,-1.0,accept,majority_agreement
930095556,10966,"this method should be part of the acl api, as `aclsetuser()`",0,0,0,0.9879369139671326,0.9948797225952148,0.995796799659729,0.0,accept,unanimous_agreement
930705425,10966,"i'm not sure about this. as name is for when we create the user via this mechanism, unsure thats valid from an rm function",-1,-1,0,0.5085585713386536,0.5446675419807434,0.6944758892059326,-1.0,accept,majority_agreement
930706857,10966,"if we fail to parse the string, isn't it import to know why? the other option would be for it not to be a return value but for the fucn to take a redismodule ** and return it that way.",0,0,0,0.9860939979553224,0.9771432876586914,0.9901887774467468,0.0,accept,unanimous_agreement
933981331,10966,are we sure we want to set the use in case it was taken from `moduletempclients` ?,0,0,0,0.9887399077415466,0.9954146146774292,0.9935212731361388,0.0,accept,unanimous_agreement
933982265,10966,i think we should enforce `rm_user` for this api call. no user scenario should use `rm_call()` explicity.,0,0,0,0.9890925884246826,0.9917866587638856,0.9881088137626648,0.0,accept,unanimous_agreement
933984202,10966,is `user->user == null` is valid? if yes - what are your expectations in this case?,0,0,0,0.983017086982727,0.993198037147522,0.9947683811187744,0.0,accept,unanimous_agreement
934330100,10966,style,0,0,0,0.9586904048919678,0.937432587146759,0.583770751953125,0.0,accept,unanimous_agreement
934331185,10966,actually just get rid of dirty and just free the string.,-1,0,0,0.5900465250015259,0.8919396996498108,0.9822163581848145,0.0,accept,majority_agreement
934408860,10966,"i don't see how user->user can be null. if user isn't null, user->user should be a redis internal user.",0,0,0,0.9613051414489746,0.9469584822654724,0.9554131627082824,0.0,accept,unanimous_agreement
934462450,10966,"so this is a question, should this be an error. if you pass in a null rm_user should it be an error, or should it be treated as null (i.e. root user in redis internal usage)",0,0,0,0.9723862409591676,0.9921546578407288,0.9893147945404052,0.0,accept,unanimous_agreement
935493671,10966,"all moduletempclients reset to null at the end, so should be ok.",0,0,0,0.9875211715698242,0.9907111525535583,0.9909831285476683,0.0,accept,unanimous_agreement
935493983,10966,see comment i made below noting this q,0,0,0,0.984216809272766,0.9803738594055176,0.9946183562278748,0.0,accept,unanimous_agreement
946538163,10966,`reply` has been added to auto memory which will result in double free. [a link],0,0,0,0.9887972474098206,0.990017592906952,0.9944559931755066,0.0,accept,unanimous_agreement
946868708,10966,this change is somewhat in the direction of one of the changes i was planning for [a link],0,0,0,0.9777047634124756,0.987130343914032,0.9923682808876038,0.0,accept,unanimous_agreement
946872267,10966,"i'd like to see how we can arrange the code in a way that won't cause git to think all these lines were deleted and re-added. it's hard to review, and may cause unnecessary conflicts.",0,0,0,0.9078509211540222,0.7037423253059387,0.9237791299819946,0.0,accept,unanimous_agreement
946878914,10966,"i guess this api isn't really necessary, right? it can be done with a combination of rm_getcurrentusername, rm_getmoduleuserfromusername, and rm_aclcheckcommandpermissions. despite being cumbersome, i think there's an advantage with working with smaller building blocks that can achieve more rather than an api for each specific purpose.",0,0,0,0.9599923491477966,0.9736358523368835,0.8495758175849915,0.0,accept,unanimous_agreement
946879737,10966,so this api comes in place of [a link] ?,0,0,0,0.9894786477088928,0.9908626079559326,0.994474470615387,0.0,accept,unanimous_agreement
946882671,10966,"maybe it would be more flexible to expose an rm_setcurrentuser (to mess with ctx->client, and then revert is when the context is destroyed), and then use a plain rm_call? if we expose this capability, there's no need for a new api, and it also enables other apis that count on the current user to be affected by this.",0,0,0,0.9832199215888976,0.9938044548034668,0.9833549857139589,0.0,accept,unanimous_agreement
947009133,10966,is this true? i thought one an still free things with automemory? i.e. i thought you can manually free strings even when you create a redismodulestring with a ctx?,0,0,0,0.9866515398025512,0.9901672601699828,0.989827275276184,0.0,accept,unanimous_agreement
947012425,10966,"ok, so that would probably mean, renaming rm_call to the internal name, so only change that line, and then create a new rm_call elsewhere?",0,0,0,0.987332046031952,0.9933561086654664,0.9917281866073608,0.0,accept,unanimous_agreement
947014149,10966,"yes, except a comment we had that this was a lot of allocations for each call when in practice we didn't need to to do any of them and that was ""bad"". want to chime in?",-1,-1,-1,0.866222620010376,0.8758496642112732,0.6005838513374329,-1.0,accept,unanimous_agreement
947024316,10966,"so, its possible, we do get acls out of that already. in the future we might think we might need a greater ability, what i call callwithclient. i.e. the ability of modules to manage the lifcycle of clients themselves. this would be for watch/multi/exec to work correctly for us to be able to have consistent ""client session"" mapping across all nodes in the cluster. i.e. a client issues a watch, it needs to be marked dirty and have exec fail consistently across all nodes. as redis already does that at the client object level, this seems to be the best way to do it, but that's future work.",0,0,0,0.9588724970817566,0.9907954335212708,0.9836033582687378,0.0,accept,unanimous_agreement
947134614,10966,"maybe.. you'll probably need some forward declarations. maybe there's a way to break the code into functions and lay the lines of the code as close as how they were. keep in mind that the comment needs to be right next to rm_call in order to make it in the generated docs. anyway, it doesn't have to be perfect, but let's at least try to get something better.",0,0,0,0.9332773685455322,0.9769338965415956,0.962472915649414,0.0,accept,unanimous_agreement
947139806,10966,"even then, we could maybe change the client that's used by the context too (same as we can change the user). and there's no need for a specific rm_call variant (and possibly other apis) for these.",0,0,0,0.9878102540969848,0.9917734265327454,0.993601143360138,0.0,accept,unanimous_agreement
947468945,10966,"yes, it was just to avoid 2 unnecessary allocations + a lookup. let's have a benchmark, see if we really need this. maybe we can consider something in the middle, introducing a bit more generic `rm_getcurrentuser()` (single allocation) and then calling `rm_aclcheckcommandpermissions()`.",0,0,0,0.9853172898292542,0.9909706115722656,0.9882744550704956,0.0,accept,unanimous_agreement
947488045,10966,"ohh, my bad, missed the ctx in `redismodule_freecallreply`.",-1,-1,-1,0.9882681965827942,0.954836130142212,0.9902209043502808,-1.0,accept,unanimous_agreement
947669050,10966,"if error starts with `-`, `callreplycreateerror` will not add `\r\n` at tail. [code block]",0,0,0,0.9881067276000975,0.9951600432395936,0.994941234588623,0.0,accept,unanimous_agreement
952380365,10966,"ok, based on discussion below, removed / revert all the withuser changes and now have a rm_setcontextmoduleuser that if set will cause rm_call to run the client as that. the issue we have is how this will work if the underlying user is freed on you somewhere else (i.e. users aren't referenced counted, maybe they should be?). a thought to solve this, would be that the expectation is that you do a rm_setcontextmoduleuser() and then an immediate rm_call() each time and the user is then invalidated after used by the rm_call, so if you did rm_setcontextmoduleuser() rm_call() rm_call() this second call would run as the root/null user. therefore don't really have lifetime management issues.",0,0,0,0.9685482382774352,0.9888339638710022,0.9904907941818236,0.0,accept,unanimous_agreement
952380934,10966,"removed this code for now. can put it back if needed, less needed if we have dry run (and made more efficient)",0,0,0,0.9836252331733704,0.9913151860237122,0.9876567125320436,0.0,accept,unanimous_agreement
952381909,10966,"so i sort of did this, no messing with ctx->client, messing with ctx and using that to pass to the 'temp client' that is allocated in rm_call",0,0,0,0.921012043952942,0.9889186024665833,0.992629051208496,0.0,accept,unanimous_agreement
952382890,10966,so this code was reverted for now.,0,0,0,0.9817502498626708,0.9863255620002748,0.9905235171318054,0.0,accept,unanimous_agreement
952517043,10966,"i don't think we should revert it after rm_call, i think we should revert it when the context is destroyed. maybe on long lived contexts we have an issue, but then don't we have that issue anyway? p.s. shouldn't it be rm_setmodulecontextuser (i.e. modulecontext instead of contextmodule)?",0,0,0,0.9822889566421508,0.9800270199775696,0.9879629015922546,0.0,accept,unanimous_agreement
952608777,10966,please remove,0,0,0,0.9778056144714355,0.9842276573181152,0.9812001585960388,0.0,accept,unanimous_agreement
952651325,10966,"going backwards: i was thinking of it as set the context's moduleuser (as it's called a redismoduleuser struct). in general we don't have ""free floating"" user objects like this. i.e. it be attached to a client (and then it invalidate/disconnect the client when we fee the object). in this case, i dont think its safe to keep it valid long term. with that said, the same argument can be made i guess if this done in an external thread, then any use of redismoduleuser is probably just as problematic as can be freed on main thread without one's knowledge in thread.",0,0,0,0.9274413585662842,0.971991777420044,0.9509159922599792,0.0,accept,unanimous_agreement
952671871,10966,"no need this check again, `u->acl_string` is null for sure, since it was validated at the beginning of this method.",0,0,0,0.987632155418396,0.992456555366516,0.9935014843940736,0.0,accept,unanimous_agreement
952692871,10966,", so can we #10369?",0,0,0,0.9870681762695312,0.9933804273605348,0.990060567855835,0.0,accept,unanimous_agreement
953481050,10966,"so, what i think the answer is here, is to pass in a redismodulestring ** to the function. if it's not null, we generate a string, otherwise we don't. and then return value is just redismoule_ok/err and if caller wants a string with the error, they'll get it.",0,0,0,0.9875171780586244,0.9901448488235474,0.9861477017402648,0.0,accept,unanimous_agreement
953488449,10966,just to note renamed to aclstringsetuser,0,0,0,0.989161491394043,0.991956353187561,0.9947993755340576,0.0,accept,unanimous_agreement
953489514,10966,closed it.,0,0,0,0.9767709970474244,0.9729147553443908,0.9836156964302064,0.0,accept,unanimous_agreement
953490342,10966,"not resolving this yet, as unsure if what i did was what you want",-1,0,-1,0.5183344483375549,0.6587362289428711,0.6041392683982849,-1.0,accept,majority_agreement
953524590,10966,cleaned up.,0,0,0,0.9441537857055664,0.9234303832054138,0.983881950378418,0.0,accept,unanimous_agreement
953526534,10966,"or decrement, it will never exist here.",0,0,0,0.8275725245475769,0.974802553653717,0.8115144371986389,0.0,accept,unanimous_agreement
953871151,10966,"i see the code before was using a plain `%s`, why did you choose to add `%.` and `sdslen`? also, the code before went though `addreplyerrorformatinternal`, which strips off any newlines, we need to check if it's critical here or not (maybe applicable to the other error below).",0,0,0,0.9879697561264038,0.9934056997299194,0.9938135147094728,0.0,accept,unanimous_agreement
953881488,10966,"is this suppose to be used by modules? (i don't see it documented in the doc comments in module.c) also, i don't think it a good idea to add another link time symbol? we basically currently have none (redismodule_getapi is passed as an argument to redismodule_init, and from there it all gets resolved via a dictionary). to be honest, i still don't quite understand why we need that, please describe in more detail.",0,0,0,0.8600877523422241,0.9652876257896424,0.7924020290374756,0.0,accept,unanimous_agreement
953894993,10966,"this api needs to be heavily documented here. we should note that by default rm_call uses a ""super user"" that's unrestricted. and that by using this api, it means the command are actually executed by this user (not only affecting the acl validations rm_call does, but also ones done by the command redis executes)",0,0,0,0.986052393913269,0.9851679801940918,0.9909548163414,0.0,accept,unanimous_agreement
953896594,10966,"we should improve the documentation of argv_check_acl to mention that by default it uses the user who executed the calling module command, but it can be changed by using the new api",0,0,0,0.9851069450378418,0.9943093061447144,0.9926624298095704,0.0,accept,unanimous_agreement
953897436,10966,needs doc comment. explain the difference from rm_setmoduleuseracl,0,0,0,0.9888870120048524,0.9922730326652528,0.995433747768402,0.0,accept,unanimous_agreement
953898771,10966,"iirc, a blank line between the comment and the api, means the script won't recognize the doc.",0,0,0,0.9692469835281372,0.7309846878051758,0.985178768634796,0.0,accept,unanimous_agreement
953902208,10966,"maybe we better take a redismodulestring input? but anyway, sdssplitargs takes a plain char*, why clone the string here?",0,0,0,0.9833950996398926,0.9892954230308532,0.9861010909080504,0.0,accept,unanimous_agreement
953911164,10966,"i'm not sure if the ""with"" and ""without"" (both here, and in the module implementation), refer to the acl check performed by rm_call (the ""c"" flag), or the fact we set a user via rm_setcontextmoduleuser. i think it could be nice to test combinations of the above. maybe the rm_call flags could be controlled by the caller like we do in misc.c, this will make the code in the module's c file smaller, and the reader of the tcl code will not need to go look at the module as much to understand what the test does.",0,0,0,0.9683212637901306,0.9891848564147948,0.9600146412849426,0.0,accept,unanimous_agreement
954974079,10966,"don't know, think i was conflating multiple different things (thinking its an sds so have to use len, but then i should have just used s). changed it to how it was.",0,0,0,0.7344653606414795,0.861459493637085,0.6618821024894714,0.0,accept,unanimous_agreement
954979719,10966,"my understanding is that redis has a concept of a null user which is treated as the ""root"" user. (i.e. until now how rm_call primarily issued commands.). so the q is, if we call `rm_setcontextmoduleuser(ctx, null)`, we are really just unsetting the user, not setting the user the ""null"" user. what's the problem? if we call `rm_call()` with the `c` check acl flag, we will then be using the user that is part of the context's client (if it exists), not the ""null/root"" user. this is a way to use `c` with the that null/root user, even if the ctx itself has a user. the counter argument is, if you want this to execute as the ""null/root"" user, just don't use the 'c' flag and `rm_setcontextmoduleuser(ctx, null)` befoe you issue the `rm_call`.",0,0,0,0.9679492115974426,0.9877901077270508,0.9829567670822144,0.0,accept,unanimous_agreement
956685196,10966,added a comment,0,0,0,0.9853251576423644,0.9825007319450378,0.985995590686798,0.0,accept,unanimous_agreement
956685665,10966,"dont see any doc comments that discuss this check, just a bit inside the code. where do you think it should go?",0,0,0,0.9399247169494628,0.9122376441955566,0.9878394603729248,0.0,accept,unanimous_agreement
956686149,10966,added something,0,0,0,0.981891930103302,0.9593533873558044,0.9912849068641664,0.0,accept,unanimous_agreement
956686390,10966,removed,0,0,0,0.9654131531715392,0.9801433682441713,0.9591778516769408,0.0,accept,unanimous_agreement
956687881,10966,this one: [code block],0,0,0,0.987570345401764,0.9888753890991212,0.9947904348373412,0.0,accept,unanimous_agreement
956689264,10966,"how about call_without_user (regular rm_call) call_with_user (set user, regular rm_call) call_with_user_and_acl (set user and rm_call with 'c' flag)",0,0,0,0.9875662326812744,0.9942281246185304,0.9945420622825624,0.0,accept,unanimous_agreement
956708898,10966,i think i addressed this in latest push,0,0,0,0.9736513495445251,0.95565664768219,0.9894606471061708,0.0,accept,unanimous_agreement
956709261,10966,ok added something.,0,0,0,0.9827805757522584,0.9830233454704284,0.9871188402175904,0.0,accept,unanimous_agreement
956731054,10966,"ok, i see it now, so the caller needs to choose between 1. setting the user explicitly 2. using the root / super user 3. using the user assigned to the calling client. so null can either mean [2] or [3], but as you mentioned, if the caller aims for [2] (root), then there's no need to use `c`. they'll use `c` only when they want validations, and then with null it'll mean [3], and non-null is a specific user. the next thing to consider is the actual user that executes the command, and here i'd argue that the default of null is a root user, and if the caller wants to select the user of the calling client, they need to explicitly extract it and set it (becomes a non-null). i agree it's a bit odd, that null means option [3] in one case, and option [2] in the other, but maybe it's not that bad? (part of it is mandatory to keep backwards compatibility).",0,0,0,0.9780289530754088,0.9834022521972656,0.9654141664505004,0.0,accept,unanimous_agreement
956949741,10966,"i'm still afraid of protocol violation here. in case someone executes an acl command with newline as part of one of the args, it'll respond with a text that includes that arg, and since it doesn't go now though the newline trimming of `addreplyerrorformatinternal`, it can mess up the protocol. maybe we need to create a new addreplyerrorsdssafe, and use it instead of addreplyerrorsds",-1,-1,-1,0.9759979844093324,0.8407098650932312,0.9337742924690248,-1.0,accept,unanimous_agreement
956952167,10966,"""toexecute"". p.s. i don't think we're using double spaces after periods elsewhere.",0,0,0,0.9791300892829896,0.9581648707389832,0.9917216897010804,0.0,accept,unanimous_agreement
956954597,10966,"i see you added documentation for `nulluser` in module.c, but i don't think the documentation generator will catch that. so instead the documentation about it should be in `rm_setcontextmoduleuser`. but anyway, due to the points above i still think we should completely dismiss it. * it create a new link time abi requirements that we didn't have so far (no globals) * i think it's unnecessary, the plain null / default is probably enough, if documented properly.",0,0,0,0.9595884680747986,0.9868677854537964,0.967888593673706,0.0,accept,unanimous_agreement
956957663,10966,"i think i meant do document that where the `c` flag is documented. note that there's s script in the utils folder that extracts the documentation above each rm_* function and generates the reference in [a link] so any doc we want to be visible to it, must be in these comments.",0,0,0,0.984228491783142,0.9848767518997192,0.9928830862045288,0.0,accept,unanimous_agreement
956966947,10966,"i still think that considering that call_with_user and call_with_user_and_acl are identical except the flag we better just let the tcl code pass the flags, and then it can also use other flags. so we'll have just two commands, one uses a user and one that doesn't. p.s. where you say ""with acl"", i think it should say ""with acl checks"", to make a difference between setting up acl user, and asking rm_call to do the checks.",0,0,0,0.9699336290359496,0.9829720854759216,0.9819239974021912,0.0,accept,unanimous_agreement
956984110,10966,"ok, removing it.",0,0,0,0.9769251346588136,0.9805595874786376,0.9876285791397096,0.0,accept,unanimous_agreement
957179752,10966,"ok, added/moved",0,0,0,0.98319810628891,0.9569461345672609,0.99139004945755,0.0,accept,unanimous_agreement
957193061,10966,took out the the comment here and replaced it in a much simpler manner. /* modifies the user that rm_call will acl check commands as */,0,0,0,0.9839096665382384,0.9929509162902832,0.9945218563079834,0.0,accept,unanimous_agreement
957260497,10966,"i'm unconvinced that they are equivalent. call_with_user doesn't check acl, just sets the user on the context, while acl actually calls it with acl checking. i.e. we have 3 ways to do the call 1) base rm_call (should be effectively same as before) 2) with user - but as not specifying acl, nothing should change (should behave the same as regular rm_call) 3) with acl - now, this is where the difference is.",-1,0,-1,0.7510373592376709,0.9722432494163512,0.679077684879303,-1.0,accept,majority_agreement
958202060,10966,", as pointed out in his comment - setting the user will affect not only the acl validation.",0,0,0,0.9842453598976136,0.991194486618042,0.9873008728027344,0.0,accept,unanimous_agreement
958204383,10966,"i think that in case `rm_setcontextmoduleuser` was called, and the module sets a module user, we should use it, no matter which flags we have. but i wonder, when do we reset this behavior? should the module set the user to null after there is no use in the context?",0,0,0,0.9255357384681702,0.9859797358512878,0.97800612449646,0.0,accept,unanimous_agreement
958205939,10966,"so , do we need both comments?",0,0,0,0.9834400415420532,0.9887968301773072,0.9894319772720336,0.0,accept,unanimous_agreement
958207623,10966,", it's still here - please remove",0,0,0,0.9705494046211244,0.9344664216041564,0.7748141288757324,0.0,accept,unanimous_agreement
958208653,10966,"not sure this include is needed, please check.",0,0,0,0.9061123728752136,0.9841087460517884,0.919219732284546,0.0,accept,unanimous_agreement
958216963,10966,^^^,1,0,1,0.770495593547821,0.8203395009040833,0.9902409315109252,1.0,accept,majority_agreement
958232440,10966,"we ""are"" using it, but i argue its more consistent to say we only really use it if the ""c"" argument is given. basically i view this set function now as an override for whatever it would think it would be (either not set or something else). basically, if you want acl checking, you need to use ""c"", if you dont want acl checking you don't use ""c"".",0,0,0,0.9715201258659364,0.9826496839523317,0.9862895011901855,0.0,accept,unanimous_agreement
958233108,10966,"ah, the extern yes. missed that",-1,0,0,0.9144781827926636,0.9118741750717164,0.9060373306274414,0.0,accept,majority_agreement
958234388,10966,removed both and the printf for debugging,0,0,0,0.9868952631950378,0.9876543879508972,0.9908581376075744,0.0,accept,unanimous_agreement
958253509,10966,is `user` used only for acl checking? i'm not sure...,0,0,0,0.8008029460906982,0.6653979420661926,0.9636796712875366,0.0,accept,unanimous_agreement
958372960,10966,"ok, would returning the errors like this be better [code block]",0,0,0,0.985519289970398,0.9907137155532836,0.9863868951797484,0.0,accept,unanimous_agreement
959653424,10966,"my point was that the two functions are identical except for the flags that are passed, so if we pass them from outside we have: 1. more flexibility to the caller (can add other flags) 2. all the context about the test is in one place. i.e. the reader needs to read less c (not that many functions with a ton of code in each), and when he gets to read the tcl code, he can still remember what each c command does. when i read these module tests code, i often have a problem where i need to run back and forth between the tcl code and the c code on each line of tcl code that i'm reading. if the c code is simple, and i can clearly understand what each module command does, then it's sufficient to read just the tcl code (assuming i know the rm_call feature and meaning of the flags, since if i don't know that, i need to also switch between a tcl file and 2 c files). maybe if we take if further, we can even have just one rm_call wrapper command, and control the selected user using a specific command that does just that. anyway, i won't insist on that.. just a suggestion for something that can maybe make the tests more readable.",0,0,0,0.9074692130088806,0.9564810991287231,0.9570141434669496,0.0,accept,unanimous_agreement
959665130,10966,"ok, so if i understand correctly, it would be a call_with_user and call_with_user_flags like in misc.c, where right now it just be used with the acl flag of 'c'",0,0,0,0.9816362857818604,0.9919686913490297,0.9895538091659546,0.0,accept,unanimous_agreement
959668708,10966,"indeed it depends if the user is only used for acl. i can see the day where users will have other feature, like rate limiting or whatever.. probably done by a module with some hooks and user awareness. so it seems logical to me that we always apply the user if it is set. however, then we run into an odd problem that some acl checks depend on the ""c"" flag, and others do not (i.e. if a command does it's own acl checking, like scripts do, sort does, and like publish used to do at some point), these engage even if you didn't pass the ""c"" flag. and we can't expect the caller to keep track of our internal implementation.. i'm a bit on the fence here, considering that that built in features of users are just acl, but it may be extended in the future, and also already be done by modules. i think i'm leaning towards setting the user regardless of the ""c"" flag.",0,0,0,0.9275475144386292,0.851641833782196,0.966497540473938,0.0,accept,unanimous_agreement
959671182,10966,"i don't like this solution (with no explanation what it's for... i think it should be inside an addreplysdssafe function. i suppose we only have this concern when returning replies to clients, not when errors to a module api.",-1,-1,-1,0.9809733033180236,0.9736602902412416,0.9851638078689576,-1.0,accept,unanimous_agreement
959834675,10966,"would we want another flag then? 'u'? i.e. run as user (where user is either, ctx->client->user or ctx->user (preference being ctx->user). i.e. could use 'u' without setcontextmoduleuser and 'c' and would run scripts not as unrestricted user, but as the appropriate user. might still be unrestricted.",0,0,0,0.9879783391952516,0.9925357103347778,0.9923323392868042,0.0,accept,unanimous_agreement
959834932,10966,"ok, will look into that.",0,0,0,0.9818618893623352,0.98485666513443,0.9819951057434082,0.0,accept,unanimous_agreement
959851529,10966,think i did this added a addreplyerrorsdssafe and use it in acl return to user.,0,0,0,0.987230122089386,0.9913289546966552,0.9921145439147948,0.0,accept,unanimous_agreement
959861797,10966,"so i thought about this some more. ""c"" as i'm arguing to redefine is effectively setting the user for everything. yeah, it might make sense to not be ""c"" and be ""u"" and set user and acl check, but i don't see any case where it makes senes to do one and not do the other. i.e. if assigning a user to the client, i'd argue you should be acl checking throughout, and as demonstrated for scripts if acl checking at rm_call really should be assigning it to client to impacts script execution",0,0,0,0.8970654606819153,0.9821844100952148,0.9576150178909302,0.0,accept,unanimous_agreement
961084767,10966,i believe i now handle it better - addreplyerrorsdssafe() that does the mapping on reply.,0,0,0,0.965041160583496,0.9810734987258912,0.9322935938835144,0.0,accept,unanimous_agreement
961092535,10966,"ok, rewrote this.",0,0,0,0.9846373200416564,0.980241060256958,0.99198180437088,0.0,accept,unanimous_agreement
961104028,10966,"so in the commit i just pushed, no ""u"", ""c"" is just renamed from acl_check to run_as_user. this does change script semantics that are run via rm_call so needs to be noted. acl checking is just a side effect of ""running as user"".",0,0,0,0.9825059175491332,0.9930636286735536,0.995142936706543,0.0,accept,unanimous_agreement
962291251,10966,don't think we need that comment (it doesn't even say what was validated),0,0,0,0.8446851372718811,0.7959035634994507,0.9636552929878236,0.0,accept,unanimous_agreement
962310985,10966,so now `call_with_user` is identical to `call_without_user`? delete one?,0,0,0,0.987536370754242,0.994621515274048,0.9939014911651612,0.0,accept,unanimous_agreement
962315016,10966,"i was leaning towards using the user set via rm_setcontextmoduleuser even without ""c"", but now that you've re-purposed ""c"", it actually makes sense that way too. however, this is a behavior change causing scripts that used to work to stop working when redis is upgraded. but since it only happens with ""c"", and its purpose was to check acl, which scripts actually bypassed, i think we can consider that a bugfix. please ack. please make sure to reflect that in the pr's top comment. also, i see you opened #11231, i'm not sure why (it covers the same purpose that you fixed here, right)? shall we set it to be closed when this one is merged? p.s. how is that in terms of symmetry with our intents in #11161 (a flag that tells rm_call to affect commands in scripts the same way it affect normal commands)",0,0,0,0.7562236785888672,0.9156599640846252,0.7338336706161499,0.0,accept,unanimous_agreement
962371159,10966,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
962371344,10966,"i dont think they are quite the same (but perhaps close enough). call_without_user is normal rm_call. call_with_user is calling rm_setcontextmoduleuser before rm_call, but without any flags, so in practice similar, but more a test to ensure semantics dont change in future. call_with_user_flags is calling rm_setcontextmoduleuser and then whatever flag we use (presumably 'c') to make use of that call. if you dont think its neccessary, can remove, but that was my logic.",0,0,0,0.9556841850280762,0.9820212125778198,0.9802097082138062,0.0,accept,unanimous_agreement
962371904,10966,"yes, i opened #11231 to make this a discussion of this being a bugfix or not. i.e. that if we needed 'c' semantics to stay the way they are, perhaps we deprecate 'c' (i.e. we still support it, but note that it doesn't do what one might expect for scripts) and add a 'u' that is much more clear of what happens in this case. (as i describe in the comment) i can imagine it also possibly being useful for other modules (not sure how they would use, but my imagination says it might be possible), as a way to ""sandbox"" modules. i.e. a module could restrict itself by always running as a more restricted user. unsure this is really necessary, but perhaps others could take it and run with it.",0,0,0,0.9246367812156676,0.9761465191841124,0.979908525943756,0.0,accept,unanimous_agreement
962562093,10966,removed,0,0,0,0.9654131531715392,0.9801433682441713,0.9591778516769408,0.0,accept,unanimous_agreement
962755196,10966,"look again. in the last version you posted call_with_user doesn't call rm_setcontextmoduleuser, so it's identical to call_without_user. also, if you want to test a case of using rm_setcontextmoduleuser without the c flag, you can still do that with call_with_user_flags.",0,0,0,0.9879196882247924,0.993532657623291,0.9927594661712646,0.0,accept,unanimous_agreement
973894050,10966,fyi `{}` will generate an empty string.,0,0,0,0.9856921434402466,0.9605409502983092,0.9918984174728394,0.0,accept,unanimous_agreement
977343908,10966,"i still have trouble with this api name. both the words ""context"" and ""module"" seem a bit excessive. looking at another api that does a similar thing: `rm_authenticateclientwithuser` so the difference is that one works on the client and the other on the context, and that one is more permanent than the other. i think we can drop the word ""module"", i think it is implied. if we'll ever have a similar api that takes a non-module user, we'll call it setcontextusername. same as we have rm_getcurrentusername vs rm_getmoduleuserfromuser**name**, and the similar rm_authenticateclientwith**acl**user vs rm_authenticateclientwithuser",-1,-1,-1,0.9587969779968262,0.6384695172309875,0.8057414293289185,-1.0,accept,unanimous_agreement
977362794,10966,don't think we have a strong objection for renaming it to `rm_setcontextuser()` - will do it. :folded_hands:,0,0,1,0.941628098487854,0.9705702066421508,0.8997488617897034,0.0,accept,majority_agreement
453270379,6929,"this file is auto generated, please revert these and instead make a pr to [a link] instead.",0,0,0,0.9873637557029724,0.9891557097434998,0.9923800230026244,0.0,accept,unanimous_agreement
453270507,6929,"i feel maintaining that list is not wise. maybe we just need to leave it as it was, or instead give 3 commands as an example? please provide additional input.",-1,0,0,0.8832403421401978,0.8437347412109375,0.9028448462486268,0.0,accept,majority_agreement
453270772,6929,let's rename to `getpoppushcmdname`,0,0,0,0.98679381608963,0.9920439720153807,0.9953049421310424,0.0,accept,unanimous_agreement
453270804,6929,let's rename to `getpoppushcmdproc`,0,0,0,0.985673725605011,0.991448163986206,0.9953214526176452,0.0,accept,unanimous_agreement
453271265,6929,"i think the space between the comment and the command function needs to be trimmed (like it used to be, and like other commands. also, too many spaces above the comment. then, for the command functions below, maybe add a short one line comment referring to rpoplpushcommand.",0,0,0,0.9846493601799012,0.98640114068985,0.9738584160804749,0.0,accept,unanimous_agreement
453271978,6929,"how about we add one element to the target list before the operation, so that we can use lpop here and see that it got pushed into the right place? consider that change on all 4 tests in that group?",0,0,0,0.9844133853912354,0.992553412914276,0.9938271641731262,0.0,accept,unanimous_agreement
453272430,6929,"for these 4 tests, i'd replace the `after 1000` with a `wait_for_condition` for `[s blocked_clients] == 1` that would make all 4 run after than the original 1 too. then i'd also suggest to put something in the target list before the operation, and then check that by using the right kind of pop, we get the right item. this (together with the above/previous non-blocking test), makes sure that both code paths, push to the right place.",0,0,0,0.9811402559280396,0.9899360537528992,0.9911531805992126,0.0,accept,unanimous_agreement
453272560,6929,"for these 4 tests, again, let's take this opportunity to replace the `after 1000` with a `wait_for_condition` for `[s blocked_clients] == 2`",0,0,0,0.9866092801094056,0.9915881752967834,0.9942142367362976,0.0,accept,unanimous_agreement
453272690,6929,"there's really no value in adding these 3 tests. although they don't take time, let's trim them.",0,0,0,0.9596998691558838,0.9053336381912231,0.8542293310165405,0.0,accept,unanimous_agreement
453272882,6929,for these 3 i also don't see any value in repeating. i think we can trim them (and replace the `after 1000` in the original one).,0,0,0,0.9862889051437378,0.9772916436195374,0.9886992573738098,0.0,accept,unanimous_agreement
453272928,6929,"i think we can trim these 3 tests, they don't add value.",0,0,0,0.9856022000312804,0.9726877808570862,0.969035267829895,0.0,accept,unanimous_agreement
453273006,6929,"i think we can trim these 3, don't add real value",0,0,0,0.9820353984832764,0.94339120388031,0.9691122770309448,0.0,accept,unanimous_agreement
453273302,6929,"in order to gain more value in these, let's add some pre-existing value in list3, so that we can check the element got pushed to the right place? or alternatively, if we think we got that covered already, and this test is just to check that a series of linked operations work, let's trim the additional 3 tests. (and maybe use two different types of bxpopxpush in the original one test).",0,0,0,0.9833213090896606,0.9924890995025636,0.9930522441864014,0.0,accept,unanimous_agreement
453273344,6929,"i think these 3 don't add value, let's trim them.",0,0,0,0.9825818538665771,0.9604933857917786,0.967542290687561,0.0,accept,unanimous_agreement
453273372,6929,"i think these 3 don't add value, let's trim them.",0,0,0,0.9825818538665771,0.9604933857917786,0.967542290687561,0.0,accept,unanimous_agreement
453273411,6929,"these 3 don't add real value, let's trim them.",0,0,0,0.9837069511413574,0.9592557549476624,0.9156081676483154,0.0,accept,unanimous_agreement
453273428,6929,"these 3 don't add real value, let's trim them.",0,0,0,0.9837069511413574,0.9592557549476624,0.9156081676483154,0.0,accept,unanimous_agreement
453273456,6929,"these 3 don't add real value, let's trim them.",0,0,0,0.9837069511413574,0.9592557549476624,0.9156081676483154,0.0,accept,unanimous_agreement
453273952,6929,"these 3 don't add real value, let's trim them. p.s. we can improve the original test, which is quite silly (removing the `after` will make no difference). something like: [code block] if you feel like improving the one, and trimming the 3 dups, that would be great.",1,1,0,0.9499712586402892,0.6999393105506897,0.459130197763443,1.0,accept,majority_agreement
453274107,6929,"no value in these 3, let's trim",0,0,0,0.9842548370361328,0.9817926287651062,0.9735933542251588,0.0,accept,unanimous_agreement
453274138,6929,"no value in these 3, let's trim",0,0,0,0.9842548370361328,0.9817926287651062,0.9735933542251588,0.0,accept,unanimous_agreement
453274171,6929,"no value in these 3, let's trim",0,0,0,0.9842548370361328,0.9817926287651062,0.9735933542251588,0.0,accept,unanimous_agreement
453274195,6929,"no value in these 3, let's trim",0,0,0,0.9842548370361328,0.9817926287651062,0.9735933542251588,0.0,accept,unanimous_agreement
453342055,6929,done: [a link],0,0,0,0.9865983724594116,0.9105059504508972,0.9949890971183776,0.0,accept,unanimous_agreement
453342111,6929,"ok, i reverted changes to this file.",0,0,0,0.9787439703941344,0.986789047718048,0.9928109049797058,0.0,accept,unanimous_agreement
453342115,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342120,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342121,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342196,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342328,6929,"done. instead of checking the result with a pop, i just modified the assert adding the existing element in the right place.",0,0,0,0.9865940809249878,0.9864518642425536,0.9898870587348938,0.0,accept,unanimous_agreement
453342341,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342362,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342366,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342385,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342390,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342579,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342585,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342599,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342611,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342616,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453342940,6929,i removed the additional tests and used a different poppush as you suggested.,0,0,0,0.9828754663467408,0.9897404909133912,0.9938735961914062,0.0,accept,unanimous_agreement
453343404,6929,"removed the dups and improved the existing one as suggested. i used two wait_for_condition calls, i believe it improves it according to what you expected.",0,0,0,0.9506577849388124,0.9767054915428162,0.9773056507110596,0.0,accept,unanimous_agreement
453343409,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453343418,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453343440,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
453343459,6929,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
458066527,6929,i think rename as `isblockpoppushcommand` is more suitable,0,0,0,0.9844470024108888,0.9904860854148864,0.9886801242828368,0.0,accept,unanimous_agreement
460048532,6929,done!,0,0,1,0.514024555683136,0.6890168786048889,0.6799882054328918,0.0,accept,majority_agreement
499210953,6929,"i'm not sure about rewriting the command and calling the other command proc. i see that all the other places that use `rewriteclientcommandvector` do it just for the sake of propagating a different command to the aof / replicas. maybe it is better to call some `lmovegenericcommand` that takes right and left arguments, and avoid changing the command vector? one advantage is that if the user uses the old rpoplpush command (didn't start using new commands), we'll keep propagating the old command too, so that the aof file is still compatible with old versions (although we don't intend to guarantee that). however if we wanna do that properly, we must also handle it in serveclientblockedonlist and that would be ugly. what do you think?",0,0,0,0.9239007830619812,0.9499355554580688,0.9426713585853576,0.0,accept,unanimous_agreement
499215123,6929,"i don't like the fact that we use `0` which is the same as `list_head` it is ignored since `target` is null, but maybe we want to change `list_head` etc to start from 1, and/or used some `list_none` constant. also, maybe we want to pass some struct? so that other places can just pass a single null? not sure about that.",-1,-1,-1,0.9651678800582886,0.8296009302139282,0.8637747168540955,-1.0,accept,unanimous_agreement
499215924,6929,"i don't like too much the fact that one command simply calls another command's entry point. although this situation existed in t_list.c before your changes. i rather have some lmovegeneric function, this will also reduce the need to call `getlistpositionfromobjectorreply` again after it was already called.",-1,-1,-1,0.9681332111358644,0.506561815738678,0.7380205392837524,-1.0,accept,unanimous_agreement
499232677,6929,"i agree with that, i think it's useful to think of `lmove` as a new command and thus avoid breaking compatibility in cases where we don't have to. slight code smell but better user experience.",1,0,0,0.5745447874069214,0.8134376406669617,0.7324547171592712,0.0,accept,majority_agreement
499298444,6929,"i thought about passing -1 since it's a signed int, maybe we could define list_none as -1? the struct seems like a good option too, i'll experiment with that.",0,0,0,0.931453824043274,0.9747433066368104,0.968368113040924,0.0,accept,unanimous_agreement
499298851,6929,since i'll be adding a lmovegenericcommand already (to stop using rewriteclientcommandvector) we can just use that.,0,0,0,0.9892542362213136,0.9937483072280884,0.9927893280982972,0.0,accept,unanimous_agreement
499298860,6929,ok!,0,1,0,0.9285968542099,0.7309839725494385,0.9387575387954712,0.0,accept,majority_agreement
499361506,6929,i suppose -1 is ok too,0,0,0,0.9744677543640136,0.956401824951172,0.9837348461151124,0.0,accept,unanimous_agreement
499978248,6929,done!,0,0,1,0.514024555683136,0.6890168786048889,0.6799882054328918,0.0,accept,majority_agreement
500770754,6929,"`r` (the last server spawned) is the master, we want to look into the command stats of the replica. [code block]",0,0,0,0.9883644580841064,0.9924092292785645,0.9945045113563538,0.0,accept,unanimous_agreement
618199600,8687,"we can. the performance implication is negligible, but maybe it'll make the code clearer.",0,0,0,0.982017457485199,0.9539262652397156,0.9730703830718994,0.0,accept,unanimous_agreement
618211385,8687,looks like i added it in [a link] probably because i saw that code calls `processpendingcommandsandresetclient` it can be removed.,0,0,0,0.9876426458358764,0.9919009804725648,0.9913955330848694,0.0,accept,unanimous_agreement
618370993,8687,"should the minimum value be set to a larger value, too small a value may cause the user to be disconnected as soon as connected.",0,0,0,0.9713122248649596,0.9611818790435792,0.9650622010231018,0.0,accept,unanimous_agreement
618514694,8687,"currently a value of 0 means no limit. it makes sense to have a lower bound (something like 1mb), but then how will we handle the special case of no-limit?",0,0,0,0.984064519405365,0.98232102394104,0.9844642281532288,0.0,accept,unanimous_agreement
618888521,8687,"or add a policy? like[code block]. [code block] will it also be deprecated? maybe user only wants to limit query, not output, i can set the policy to [code block].",0,0,0,0.9876515865325928,0.9941712021827698,0.9930490255355836,0.0,accept,unanimous_agreement
619830066,8687,this function is missing some top comment to describe the buckets mechanism. maybe just something short with a reference to the doc in server.h,0,0,0,0.97936350107193,0.9920487999916076,0.9883548021316528,0.0,accept,unanimous_agreement
619831596,8687,"let's mention that we do that **before** key eviction, per-command (after the previous client or command consumed client buffers)",0,0,0,0.9882553815841676,0.9934698343276978,0.992802917957306,0.0,accept,unanimous_agreement
619831709,8687,are we sure we really need this in cron too?,0,0,0,0.9807361364364624,0.9913109540939332,0.9907079935073853,0.0,accept,unanimous_agreement
619832078,8687,"we can't afford a loop on all clients in info. but this can be either moved in some way to client list, or a new client subcommand.",0,0,0,0.9844916462898254,0.9755980968475342,0.9905981421470642,0.0,accept,unanimous_agreement
619833195,8687,"we should certainly improve. skipping the wasted first 14 buckets is a must. i think something simple, elegant and easy to understand is preferable.",1,0,0,0.8965191841125488,0.8812432885169983,0.9340352416038512,0.0,accept,majority_agreement
619833397,8687,"+1 (iirc my suggestion), let's do that.",0,1,0,0.8728666305541992,0.524458646774292,0.9706812500953674,0.0,accept,majority_agreement
620899628,8687,"this was a debugging tool i added, note that `mem_usage_sum` is calculated per bucket just for debugging. the first question is do we even need this (after we're done debugging). if not i'll just delete the whole thing. if we do want it then i'll think where best to put it. wdyt?",0,0,0,0.9774730205535888,0.8568209409713745,0.959939420223236,0.0,accept,unanimous_agreement
620900483,8687,"yes, it was your suggestion.",0,0,0,0.9799480438232422,0.982778012752533,0.9857931733131408,0.0,accept,unanimous_agreement
620918982,8687,we need it in the cron in order to make sure the other (non client eviction) stats are also updated. there are also edge cases where a normal client has large buffers but is marked as `client_no_evict` and has no activity on it anymore. then the user turns off this flag but no new commands are executed and the write event never happens. in this case we need the cron in order to put the client into some bucket.,0,0,0,0.9846044182777404,0.9871302247047424,0.993103563785553,0.0,accept,unanimous_agreement
620939936,8687,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
620940049,8687,removed.,0,0,0,0.9311882257461548,0.9782117605209352,0.9612457156181335,0.0,accept,unanimous_agreement
620940267,8687,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
620940371,8687,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
621125234,8687,"added skipping of first 14bits and added new high buckets (2gb,4gb,+8gb). this seems good enough for me. there's a still a comment in the code about the 2 layer bucketing idea, i'll archive it in this pr and remove it from the code once we feel ok with the current implementation.",1,0,0,0.7804624438285828,0.8656587600708008,0.7494600415229797,0.0,accept,majority_agreement
621190278,8687,"maybe drop a hint in the comment about this for future reference.. i.e. you already did, but i think it may be better to improve it.",0,0,0,0.9744307994842528,0.9819459319114684,0.982307195663452,0.0,accept,unanimous_agreement
621191907,8687,"i suppose we don't need it. if we do, then a debug sub-commend is the right place. the other alternatives of a new client sub-command, or an additional field in client list, are not desired imho since this is detail about internal implementation that may change some day.",0,0,0,0.9868773221969604,0.9857304096221924,0.9798546433448792,0.0,accept,unanimous_agreement
621226588,8687,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
621331825,8687,"done, please review it.",0,0,0,0.97585129737854,0.9654801487922668,0.9912971258163452,0.0,accept,unanimous_agreement
621876558,8687,"i'd rather use assert_equal and assert_range in separate lines. the difference is that when they fail, we see the value (the assert proc gets it as an argument, and not just a boolean). also, it could be nice to add an `if {$::verbose}` that will print these, so that we know how close we usually get to the threshold, and see if we need to tune it.",0,0,0,0.983038067817688,0.9926453828811646,0.9786737561225892,0.0,accept,unanimous_agreement
621878043,8687,"all `puts` must be inside a `$::verbose` condition. normally, when the tests run in parallel by multiple runners, you don't want them to print anything to stdout on their own (instead they send messages to the parent to print on their behalf).",0,0,0,0.9852504134178162,0.9903891682624816,0.993299126625061,0.0,accept,unanimous_agreement
623046565,8687,"my bad, forgot to remove it.",-1,-1,-1,0.982910931110382,0.9874647855758668,0.9939364790916444,-1.0,accept,unanimous_agreement
623046709,8687,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
625866829,8687,moved to `debug client-eviction` and removed the iteration over all clients.,0,0,0,0.9824382662773132,0.9927071928977966,0.9943907856941224,0.0,accept,unanimous_agreement
631176817,8687,i suppose you left this debug print by mistake? or temporary to be trimmed later?,0,0,0,0.9852666854858398,0.9804651737213136,0.9860795140266418,0.0,accept,unanimous_agreement
631600014,8687,"yes, my mistake. fixed it.",-1,-1,-1,0.9218958616256714,0.8010702133178711,0.6069176197052002,-1.0,accept,unanimous_agreement
631911131,8687,"[a link] can we name this better. i don't want to have two separate things be referred to as ""protecting clients""",0,0,0,0.9119978547096252,0.9534514546394348,0.9776327610015868,0.0,accept,unanimous_agreement
631912628,8687,evictclients() ?,0,0,0,0.9845554232597352,0.9908850789070128,0.9914080500602722,0.0,accept,unanimous_agreement
650515207,8687,maybe `evict-disable`? or `evict-protect`? [code block],0,0,0,0.9884949326515198,0.9936927556991576,0.993486225605011,0.0,accept,unanimous_agreement
651730783,8687,i'll change to `no-evict`. sounds reasonable?,0,0,0,0.9846840500831604,0.9886454343795776,0.9903547763824464,0.0,accept,unanimous_agreement
651732350,8687,:+1:,0,0,0,0.7570654153823853,0.9166757464408876,0.9328674077987672,0.0,accept,unanimous_agreement
652748100,8687,"one of the benefits (or side effects) of this flag, was that we skip searching the list. maybe add a listnode pointer in the client so we don't need an o(n) search?",0,0,0,0.9797200560569764,0.9886404275894164,0.988284468650818,0.0,accept,unanimous_agreement
652750430,8687,"i'm not sure if this is not already documented somewhere (i don't read docs), but if not, then maybe the fan-out / fan-in design should be documented here?",0,0,0,0.9180025458335876,0.976606547832489,0.916440725326538,0.0,accept,unanimous_agreement
652758091,8687,"i think you need to also declare these variables as `redisatomic`. we need some comment somewhere explaining how this works with io threads, and all the eventual consistent idea. if this is gonna be at the head of the next function, maybe you need some cross references (one here)",0,0,0,0.9829699993133544,0.9874457120895386,0.9864407181739808,0.0,accept,unanimous_agreement
652771358,8687,i suppose we need to collapse the rest of the flags (rather than leave 29 empty.,0,0,0,0.9494662880897522,0.9719297289848328,0.985914707183838,0.0,accept,unanimous_agreement
653310728,8687,right. note that the previous code was also inefficient because we still search in the pending reads list. i decided to remove this for now and do o(n) just to make sure we can safely know if we're in an io thread context without relying on flags. i'll improve this later. good point.,1,1,1,0.9326003789901732,0.7770333886146545,0.8487971425056458,1.0,accept,unanimous_agreement
653341874,8687,"this will cause ""blame"" mess. i think it's better not to collapse but rather re-use the space next time we need a flag. note that using an enum would have solved this issue.",0,-1,-1,0.6911226511001587,0.5188668966293335,0.670447826385498,-1.0,accept,majority_agreement
653366962,8687,"ok, so let's put some placeholder line here to make it visible that 29 is free. this line should somehow stand out (maybe by being shorter, or have no comment)",0,0,0,0.9738737940788268,0.9891125559806824,0.9886845946311952,0.0,accept,unanimous_agreement
655906907,8687,"thanks for finding the typo, committed a fix.",1,1,1,0.6898926496505737,0.5291049480438232,0.8563653230667114,1.0,accept,unanimous_agreement
687837047,8687,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
687857527,8687,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
688190277,8687,forget release bucket_info.,0,0,0,0.7977405190467834,0.987782895565033,0.8623571991920471,0.0,accept,unanimous_agreement
690094853,8687,thanks. fixed.,1,1,1,0.8839593529701233,0.9529776573181152,0.921301543712616,1.0,accept,unanimous_agreement
692185298,8687,"maybe we can resolve it at runtime with some formula, i.e. when we come to use it, and it's !=0, we clamp values lower than 1m to 1m",0,0,0,0.9776910543441772,0.991724967956543,0.9835487008094788,0.0,accept,unanimous_agreement
692185414,8687,p.s. this config is currently undocumented in redis.conf.,0,0,0,0.9870207905769348,0.9926117062568665,0.9927050471305848,0.0,accept,unanimous_agreement
692253561,8687,"did you do? any reason not to do now? if we don't do, let's at least convert it to a block comment 8-)",1,1,0,0.5021234154701233,0.9088589549064636,0.5536627173423767,1.0,accept,majority_agreement
692272428,8687,i think you're missing a similar call in tracking.c (see `client_tracking_redirection`),0,0,0,0.9880530834197998,0.9929303526878356,0.9883557558059692,0.0,accept,unanimous_agreement
692281705,8687,did you do?,0,0,0,0.9799982905387878,0.982438623905182,0.9869640469551086,0.0,accept,unanimous_agreement
692287070,8687,"we call this (beforenextclient) function again there, right? so if someone adds more jobs in this this (beforenextclient) function, it'll automatically be covered? [code block]",0,0,0,0.9882673621177672,0.9937501549720764,0.9937083721160888,0.0,accept,unanimous_agreement
692295472,8687,"did we discuss these? in theory, argv_len_sum is about string sizes, not memory (due to a limitation, or actually a performance constraint. see the comment you moved to getclientmemoryusage). in the past i see i added `zmalloc_size(c->argv)` explicitly, if you wanna avoid calling zmalloc_size, maybe just add `argc*sizeof(robj*)` in the place where we use it, instead of storing it to the argv_len_sum? if we chose not to do that, maybe at least update the doc comment about that field (both server.h and the detailed one in getclientmemoryusage).",0,0,0,0.9840582013130188,0.9942295551300048,0.9930545687675476,0.0,accept,unanimous_agreement
692309145,8687,"fyi, new sub-command",0,0,0,0.9834463000297546,0.9568106532096864,0.9937273263931274,0.0,accept,unanimous_agreement
692313120,8687,"i suppose you need to revert this and the related changes, otherwise you may get it a second time when you rebase.",0,0,0,0.9790793657302856,0.9608219861984252,0.9885089993476868,0.0,accept,unanimous_agreement
692314036,8687,did you mean to add `unit/client-eviction` to the list of tests in test_helper.tcl and forgot?,0,0,0,0.9775776863098145,0.995003879070282,0.9925783276557922,0.0,accept,unanimous_agreement
692328747,8687,better add a short top comment on these explaining what they do (for faster reading),0,0,0,0.9723668694496156,0.9214590191841124,0.9922866821289062,0.0,accept,unanimous_agreement
692412354,8687,first assert is a leftover?,0,0,0,0.9803435802459716,0.9878997206687928,0.990232229232788,0.0,accept,unanimous_agreement
692413608,8687,this is not a very realistic test (mget of one huge key). i assume it was the other way around and was changed in order the make the test predictable?,0,0,0,0.7619084715843201,0.510985791683197,0.9271962642669678,0.0,accept,unanimous_agreement
693488529,8687,did it but didn't have any tests yet. added tests now.,0,0,0,0.9847446084022522,0.9837687611579896,0.9916736483573914,0.0,accept,unanimous_agreement
693566965,8687,right done. added test.,0,0,0,0.9532216787338256,0.9744604825973512,0.954907774925232,0.0,accept,unanimous_agreement
694559770,8687,i already rebased. if i'll need to rebase again before the final merge then i'll handle it during the rebase.,0,0,0,0.985176920890808,0.9831251502037048,0.9927893280982972,0.0,accept,unanimous_agreement
694560988,8687,"you mean `all_tests`? thought it scanned the dir, apparently not. i'll add it to the list.",0,0,0,0.988267719745636,0.9908716082572936,0.9932910203933716,0.0,accept,unanimous_agreement
694622129,8687,"right, thanks.",1,1,1,0.7093445062637329,0.8352673053741455,0.555232584476471,1.0,accept,unanimous_agreement
694630104,8687,"i think this could have been a `get` command and doesn't need to be `mget`. the idea is to have many clients with big output buffers. what do you mean ""not a very realistic tests""?",0,0,0,0.9636446833610536,0.7563586831092834,0.9851089715957642,0.0,accept,unanimous_agreement
694677847,8687,fixed: added `argc*sizeof(robj*)` where needed (please review).,0,0,0,0.9844606518745422,0.9942863583564758,0.989011526107788,0.0,accept,unanimous_agreement
694681237,8687,"so if someone adds more jobs in this this (beforenextclient) function, it'll automatically be covered? correct",0,0,0,0.9845433831214904,0.9926867485046388,0.9947362542152404,0.0,accept,unanimous_agreement
694691253,8687,checked and updated comment accordingly. we still need `freeclientsinasyncfreequeue()`.,0,0,0,0.9858685731887816,0.9928575754165648,0.992720365524292,0.0,accept,unanimous_agreement
695514717,8687,"the typical case of `keys *` like scenario that cases mass eviction is a burst of mgets filling the output buffer. i think this is typically a lot of mget calls on many key by many clients. so i just commented that iirc when this test was initially created (added the tests before the code to fix them), it was a more typical case, and it was change to be something that's easier to test (considering we know the actual problem can be triggered by one command on a single key too). just a random comment, we can dismiss it.",0,0,0,0.9466426968574524,0.968315601348877,0.9796900749206544,0.0,accept,unanimous_agreement
696550803,8687,"ok, i understand. what's important to me here is the ""lots of clients"" and less the ""lots of keys"". i agree that this can be a bit closer to the typical case but for now i'm leaving it as is.",0,0,0,0.8815215229988098,0.963028371334076,0.939141571521759,0.0,accept,unanimous_agreement
696553620,8687,"this is fine, but before implementing i'd like to propose another idea of using a negative value as a percentage of `maxmemory`. this way we can have some default of 5% for example?",0,0,0,0.9845320582389832,0.9843563437461852,0.9884315729141236,0.0,accept,unanimous_agreement
696571261,8687,"we have that mechanism in [a link] but i'm not sure we wanna have it here too. i.e. there it's just doing some push back, and here it'll cause disconnection of clients. so maybe for nicer backwards compatibility, this new feature should be off by default?",0,0,0,0.9635644555091858,0.9330568313598632,0.9713148474693298,0.0,accept,unanimous_agreement
697539914,8687,see last commit: * cap to a minimum * add `maxmemory` percentage option (+test) * `redis.conf` doc,0,0,0,0.985079288482666,0.992492973804474,0.9953781366348268,0.0,accept,unanimous_agreement
698272612,8687,"you'll need to rebase and find a way to resolve this, the memory config infrastructure is now unsigned. maybe we'll need to add a flag memory_perc, and actually support a notation like `10%` rather than rely on negative number and document that?",0,0,0,0.9879155158996582,0.990384578704834,0.9917608499526978,0.0,accept,unanimous_agreement
698273856,8687,no need to warn imho.,0,0,0,0.9707300066947936,0.9524819850921632,0.9561504125595092,0.0,accept,unanimous_agreement
699298472,8687,the problem with that is that our config system performs its parsing and validation upon update and then stores the value in some global var under the `server` struct. so once the data is stored we don't have any more metadata (like the `%` notation or flag) to know how to use it. the only other possible option instead of using a negative value is having two config variables `maxmemory_clients` and `maxmemory_clients_p`? probably sounds familiar from somewhere... so three options (my preferred is bold): * have `maxmemory-clients` and `maxmemory-clients-p` * **use a negative value and a custom numericconfigset for percentages** * skip the idea of using percentage for `maxmemory-clients`,0,0,0,0.9386743903160096,0.9853277802467346,0.6650269031524658,0.0,accept,unanimous_agreement
699856322,8687,"truncation may occur in 32 bits, max of `maxmemory` is `ullong_max`.",0,0,0,0.9876768589019777,0.9925413131713868,0.9943258166313172,0.0,accept,unanimous_agreement
700089567,8687,"i run test on macos, keys evict will be triggered after execution here, causing the test to fail when `client_eviction` is `true`. on macos the max memory will be 10574672 bytes, while in ubuntu it is 9676648 bytes. macos: [code block]",0,0,0,0.987301230430603,0.9941158294677734,0.9947235584259032,0.0,accept,unanimous_agreement
700213611,8687,"i think calc `maxmemory_clients_actual` can be a separate method, and if it returns 0, we can eliminate the need for the while loop in `evictclients`.",0,0,0,0.9888613820075988,0.9930239915847778,0.9862945675849916,0.0,accept,unanimous_agreement
700815889,8687,i see. but why is `maxmemory` an `unsigned long long`? shouldn't it be a `size_t`. how can i have more than 4g mem on 32bit?,0,0,0,0.9847474098205566,0.976531744003296,0.9911218881607056,0.0,accept,unanimous_agreement
700817102,8687,"yes, i don't understand why `maxmemory` is `unsigned long long` either.",0,0,0,0.940962553024292,0.8714303970336914,0.9817797541618348,0.0,accept,unanimous_agreement
700824034,8687,"i don't know.. maybe historical reasons, but i think it's safer to keep it this way.",0,0,0,0.5642333030700684,0.8784278035163879,0.9359816312789916,0.0,accept,unanimous_agreement
700845768,8687,added range check. i think we should change to `size_t` in the near future as part of 7.0.,0,0,0,0.9844197630882264,0.9936854243278505,0.992299497127533,0.0,accept,unanimous_agreement
700922491,8687,:+1:,0,0,0,0.7570654153823853,0.9166757464408876,0.9328674077987672,0.0,accept,unanimous_agreement
700975584,8687,this might be an edge case. can you run the same tests but with the following patch applied? [code block],0,0,0,0.989448308944702,0.9896211624145508,0.9915093183517456,0.0,accept,unanimous_agreement
701542751,8687,tested fine after changing to 11m.,0,0,0,0.9577163457870485,0.986769676208496,0.9798555374145508,0.0,accept,unanimous_agreement
701737094,8687,thanks. fixing.,1,1,1,0.8857271075248718,0.9640805125236512,0.9177507162094116,1.0,accept,unanimous_agreement
701769709,8687,"i rebased and added a flag enabling config values to optionally be a percent and store the value as a negative so we know to treat it as such. i'm not sure this is such a great idea, but it seems to be ok. please review.",0,0,1,0.6504130959510803,0.6262305378913879,0.8792009353637695,0.0,accept,majority_agreement
701863885,8687,"another `error writing ""sock11"": protocol wrong type for socket` error caused the test to fail under macos, ubuntu does not appear.",0,0,0,0.9317654371261596,0.9632764458656312,0.9884923696517944,0.0,accept,unanimous_agreement
702248321,8687,"[code block] `thow` is supported after `tcl8.6`, whereas we require `tcl8.5`.",0,0,0,0.9890815019607544,0.9939957857131958,0.994175374507904,0.0,accept,unanimous_agreement
702248449,8687,here's another one.,0,0,0,0.9816921949386596,0.9878316521644592,0.9849171042442322,0.0,accept,unanimous_agreement
702374876,8687,"i suggest to keep integer_config and memory_config (don't rename them), so you don't end up modifying all the numeric config lines (unnecessary conflicts with other prs)",0,0,0,0.9855802059173584,0.9886736273765564,0.9933242201805116,0.0,accept,unanimous_agreement
702908854,8687,"thanks, fixed.",1,1,1,0.6975147128105164,0.8492836356163025,0.8536084890365601,1.0,accept,unanimous_agreement
702909054,8687,:+1:,0,0,0,0.7570654153823853,0.9166757464408876,0.9328674077987672,0.0,accept,unanimous_agreement
702923390,8687,very weird. looks like a macos kernel bug: [a link] i'll adopt the regex accordingly.,-1,-1,-1,0.9888190627098083,0.9904198050498962,0.9936271905899048,-1.0,accept,unanimous_agreement
702952747,8687,:+1: fixed.,0,0,0,0.9501408338546752,0.955139458179474,0.8309786915779114,0.0,accept,unanimous_agreement
703131216,8687,"i run test: `./runtest --single unit/client-eviction --stop --loop --only ""client evicted due to percentage of maxmemory""` this test fails easily(whether it's macos or ubuntu), i print out `$e` which is empty, then when i try to add more small strings of wirte and flush operations after it, the test doesn't fail. [code block]",0,0,0,0.9700967669487,0.9785038828849792,0.9903544187545776,0.0,accept,unanimous_agreement
703484436,8687,"i don't think we have to have an alias, maybe just move these to the top instead of the other ones. it's true that they don't have a proper prefix, but what's the point of having a badly named alias and a proper name that's not really used? if we don't move them, maybe add a comment here explaining why they're here.",0,0,0,0.8686033487319946,0.9321243166923524,0.9522197246551514,0.0,accept,unanimous_agreement
704292017,8687,"thanks, i see the issue. i wonder why it fails, the `flush` should verify the write completed and the write does fail, i see it evicted the client in the logs. i'll investigate a bit since i don't want to add the extra writes without understanding this...",1,1,1,0.558042585849762,0.5742339491844177,0.5745389461517334,1.0,accept,unanimous_agreement
704650130,8687,"first, your change seems to affect all groups (including binary), please fix.. secondly, for alpha, are you sure we want that? i'm not sure what did salvatore choose to add many other (printable) chars, i assume some of them can expose issues, that why i only filtered one char in tat range recently. which char gave you trouble, and why? maybe for your purpose we wanna create a new group, rather than modify the old one?",0,-1,0,0.844285786151886,0.5186998248100281,0.7977443933486938,0.0,accept,majority_agreement
704997887,8687,"thanks, fixed. i wanted to generate client names and not fuck up my `client list` parsing code. i saw there's a function for only alpha(+digits) random str but its implementation didn't make sense. that makes sense, but then i'll modify the old one and create a new group called `printable` which is what the old group should have been called. and fix the code accordingly. do you want me to do this cleanup?",1,1,1,0.4549297392368316,0.850770890712738,0.968943178653717,1.0,accept,unanimous_agreement
705096730,8687,"seems ok, unless there are tons of places using `alpha`, in which case maybe we should find another name rather than rename the current one",0,0,0,0.9812326431274414,0.9829370379447936,0.98385089635849,0.0,accept,unanimous_agreement
705117753,8687,turns out there are over 20 places...so i'm not sure it's great to do this rename. don't have a good name for my new one. i'll try `simplealpha`.,-1,-1,-1,0.9789443016052246,0.9377189874649048,0.9271961450576782,-1.0,accept,unanimous_agreement
705129453,8687,"wanted to have good names, but you suggested blame noise, so tried to compromise. anyway i'll use the original naming.",0,-1,0,0.9445374608039856,0.81619793176651,0.8553712368011475,0.0,accept,majority_agreement
705242299,8687,i changed most of the tests to just verify the client was evicted as expected instead of detecting a socket error. this is more robust as i saw in the logs that everything actually works fine it's just that the `write` somehow succeeds without throwing an error even though the server does the eviction. anyway it's much more stable now. if you find anything else let me know..,0,1,1,0.9101102352142334,0.5661702156066895,0.7511560916900635,1.0,accept,majority_agreement
706774636,8687,"this needs to be updated with the percentage config. also, maybe mention it in the top comment.",0,0,0,0.986887514591217,0.9937267303466796,0.9950048327445984,0.0,accept,unanimous_agreement
707026638,8687,"thanks, done.",0,1,1,0.5097339749336243,0.8752812743186951,0.7876916527748108,1.0,accept,majority_agreement
714038432,8687,nit: missing `void`.,0,0,0,0.939822256565094,0.9752402305603028,0.9807568192481996,0.0,accept,unanimous_agreement
728647778,6891,"these days we also have the ""everything"" group",0,0,0,0.817003607749939,0.9849442839622498,0.9795825481414796,0.0,accept,unanimous_agreement
728648189,6891,"so if someone does `info default commandstats`, he'll get just default, and no commandstats?",0,0,0,0.9860997796058656,0.9907451868057252,0.99160635471344,0.0,accept,unanimous_agreement
728648881,6891,if someone asks for `info memory memroy` he'll get it twice. which i suppose is no big deal.,0,0,0,0.8986481428146362,0.9078040719032288,0.9622262120246888,0.0,accept,unanimous_agreement
753852427,6891,you can't modify a module api (has to be backwards api / abi compatible). modules will still need to call this function multiple times (unless we add a new api),0,0,0,0.9880080223083496,0.9843586683273317,0.9893019795417786,0.0,accept,unanimous_agreement
753853519,6891,these excessive allocations and frees are an overhead. maybe we can use a dict that works on plain char*?,0,0,0,0.7652818560600281,0.9268425107002258,0.89336758852005,0.0,accept,unanimous_agreement
753854179,6891,"i don't like to repeat that list, or the logic. maybe we can find a better way? disclaimer: i don't know that sentinel info command that well. what does it do? just forwards the call to redis's info and adds a `sentinel` section? what's special of the 4 sections mentioned here (server, clients, cpu, stats)? are these the only sections supported by sentinel info? if i understand it correctly, i wanna propose this: 1. extract the code that generates the new dict and two booleans in server.c to a new function, one that will be used by both infocommand and sentinelinfocommand. 2. in sentinel, after calling it, purge any unknowns section names. 3. if the `all` or `everything` flags are set, just add the 4 default sections (server, clients, cpu, stats) 4. call geninfostring and avoid passing the 2 booleans. will that do the trick?",-1,-1,-1,0.4916695356369018,0.7741317749023438,0.9246561527252196,-1.0,accept,unanimous_agreement
762214476,6891,"hey oran, your understanding is right. i have extracted the code that generates the two dicts from server and sentinel and moved it to geninfostring, it should be a cleaner code now. please take a look. thank you",1,1,1,0.9680674076080322,0.9786360859870912,0.99028217792511,1.0,accept,unanimous_agreement
762214835,6891,changed the dictionary so now we don't need a sds variable to find in the dictionary.,0,0,0,0.9868857860565186,0.9918535351753236,0.9942521452903748,0.0,accept,unanimous_agreement
762558245,6891,"i think you misunderstood me, or maybe i wasn't clear or my instructions were not valid. i didn't mean that the logic that creates the dict should be moved from `infocommand` into `genredisinfostring`, and everyone just calls it. what i meant was to extract that code to a new function, one that returns a dict. then `infocommand` calls that new function and passes it to `genredisinfostring` and `sentinelinfocommand` calls that new function to, then sanitizes it's output before calling `genredisinfostring`, i think `genredisinfostring` should still take a dict and two booleans. this will avoid the code duplication you had in your previous commit (parsing user request), and still keep the logic of parsing the user request and generating the output string separate. is there anything wrong it that approach which lead you to what you did?",0,0,0,0.7955911159515381,0.943192422389984,0.6150020360946655,0.0,accept,unanimous_agreement
763123508,6891,"i understand what you're saying, i think what you're saying is good. i'll change it to that. the reason for adding the logic to `genredisinfostring` was that with that approach the default sections array then would not be needed and just default could've been added to the dictionary. also for the if statement at the end of `genredisinfostring` which generates the info for the modules sections, should we assume that there was only one argument for the infocommand for example ""info mudulesection"" or do we want it for multiple sections too?",1,0,1,0.5226014256477356,0.8508920073509216,0.94174325466156,1.0,accept,majority_agreement
763128498,6891,"i think we want it to support multiple sections. so `redismoduleinfoctx` will contain that dict rather than just one string, and `rm_infoaddsection` will search that dict instead of doing string compare.",0,0,0,0.9867509007453918,0.9894850850105286,0.9899404644966124,0.0,accept,unanimous_agreement
767484583,6891,"why don't we use ""all"" here?",0,0,0,0.9595878720283508,0.9873681664466858,0.9888398051261902,0.0,accept,unanimous_agreement
767487825,6891,"this solution won't take ""sentinel"" in any other argv position (or detect that ""all"" / ""default"" was used). once again, why not take my advise of having the function that populates a dict and returns too booleans, and then this method will trim all elements from that dict except for the few it allows??",0,0,0,0.9835023283958436,0.7996691465377808,0.9466375708580016,0.0,accept,unanimous_agreement
767490659,6891,"again, why not extract this code to a separate function that returns a dict and two booleans? then genredisinfostring will take this input, but it means in between them the sentinel can modify it.",0,0,0,0.9882651567459106,0.979085385799408,0.9906593561172484,0.0,accept,unanimous_agreement
767492689,6891,we need to pass the entire dict to `modulescollectinfo` not just argv[1],0,0,0,0.9882296323776244,0.9947117567062378,0.9945340156555176,0.0,accept,unanimous_agreement
775255878,6891,"some styling fix, and a better function name. [code block] please also add a comment describing what this function does, and its input and outputs (especially important when you have output arguments, and it's not clear who's responsible of releasing things).",0,0,0,0.9841698408126832,0.990047037601471,0.9747062921524048,0.0,accept,unanimous_agreement
775256289,6891,"iirc, this is not what we agreed. we agreed that sentinel will get the dict this method returns and trim undesired sections from it. i.e. even if we used `server.sentinel_mode` here to define a different set of default sections, we still need to trim undesired sections that the user explicitly defined (sentinel only support a very specific set of sections). not sure what you attempted to do with the string compare with ""sentinel"" maybe i'm missing something.",0,0,0,0.8901571035385132,0.8335049748420715,0.9048701524734496,0.0,accept,unanimous_agreement
775256329,6891,"styling, the `*` is next to the variable name. [code block]",0,0,0,0.9887351393699646,0.9937625527381896,0.9944361448287964,0.0,accept,unanimous_agreement
775256362,6891,styling (fix in other places too) [code block],0,0,0,0.9888678193092346,0.991360366344452,0.9950265288352966,0.0,accept,unanimous_agreement
775256539,6891,"i don't think we should pass `c`. maybe pass `argv+1` and `argc-1` (so that it's possible to pass `null, 0` in debug.c",0,0,0,0.9863392114639282,0.9914030432701112,0.9804781079292296,0.0,accept,unanimous_agreement
775256709,6891,indented too much,-1,0,-1,0.8870483636856079,0.4980491399765014,0.6948615312576294,-1.0,accept,majority_agreement
775256914,6891,"i don't understand these string matching. to the best of my understanding from the design we discussed, the only string matching that should have been here is for `all`, `default` and `everything` (to set the output flags).",0,0,-1,0.8680976629257202,0.8652974367141724,0.77867591381073,0.0,accept,majority_agreement
775257401,6891,why are we aborting when current_client is null? we do still wanna log the server info...,0,0,0,0.9682509899139404,0.778156042098999,0.9833295345306396,0.0,accept,unanimous_agreement
775257475,6891,why not just pass the two booleans forward?,0,0,0,0.9642775058746338,0.9878867864608764,0.982910692691803,0.0,accept,unanimous_agreement
775258617,6891,don't we need to lowercase the module name too? or use case insensitive dict (like #9984),0,0,0,0.9877222776412964,0.9937078952789308,0.9910047054290771,0.0,accept,unanimous_agreement
775258750,6891,i think we need `&& !everything`,0,0,0,0.8263006806373596,0.8871014714241028,0.97299325466156,0.0,accept,unanimous_agreement
776465946,6891,addressed the style.,0,0,0,0.9754402041435242,0.9823948740959167,0.9911393523216248,0.0,accept,unanimous_agreement
776467241,6891,addressed the style.,0,0,0,0.9754402041435242,0.9823948740959167,0.9911393523216248,0.0,accept,unanimous_agreement
776467893,6891,addressed the style.,0,0,0,0.9754402041435242,0.9823948740959167,0.9911393523216248,0.0,accept,unanimous_agreement
776999907,6891,"didn't we say that passing some empty dict is better here? i.e. the code is not a time critical code, so there's no down side of another allocation or extra call to `geninfosectiondict`. on the other hand if this leads to some code path that's not normally executed (not covered by the test suite), who doesn't have a check for a null dict (e.g maybe module.c) it'll blow up",0,0,0,0.8974720239639282,0.9863531589508056,0.9773094654083252,0.0,accept,unanimous_agreement
777000000,6891,shouldn't this be `&section`?,0,0,0,0.9849756360054016,0.9930892586708068,0.9929497241973876,0.0,accept,unanimous_agreement
777000399,6891,how come this is the only change n that function? the code below still refers to `c`? i now realize you pushed a partial commit that doesn't work. i'll stop the review. let me know when ready.,0,0,0,0.9783933758735656,0.9163208603858948,0.909789741039276,0.0,accept,unanimous_agreement
779814744,6891,"hi oran, yes, we agreed with here to use an empty dict. but when i do coding practice, i found creating an empty dict makes thing complex. because the second parameter is 1 which means ""all"", then in our code genredisinfostring function (server.c), it has the short circuit statement: **if (all_sections || (dictfind(section_dict,""server"") != null))** . it means even we only pass a null as parameter in the **genredisinfostring(null,1,0)**; it does not have harmful to this function. this is why i change mind to pass null instead of passing an empty dict, do you agree with this idea? thanks.",0,0,0,0.9606010317802428,0.980504274368286,0.9382069706916808,0.0,accept,unanimous_agreement
779817022,6891,"sorry, oran, i do not get your point here. i think keeping the current condition is fine. and i test here, we could pass any parameter here, including everything. thus, sorry i have no idea why we need && !everything. thanks",-1,-1,-1,0.9909408688545228,0.9584743976593018,0.9877991676330566,-1.0,accept,unanimous_agreement
779822087,6891,"here, i use sdstolower(full_name) lower module name.",0,0,0,0.9888484477996826,0.9923650026321412,0.9942553639411926,0.0,accept,unanimous_agreement
779839928,6891,"hi oran, i want to explain why i add a fake part ""input-modules"" here. below are the output results when user inputs 5 different cases. ![a link] you can find if user inputs are ""info"", ""info default"", ""info modules"", the variable out_all = 0 and out_everything = 0. we have no way to difference between ""info"" and ""info modules"". thus i add a fake ""input-modules"" as an indicator. otherwise, we need to change the geninfosectiondict input parameter to add another int* out_default. current solution is based on the discussion result between us a few days ago. thanks",0,0,0,0.7496193647384644,0.9501562118530272,0.7421717047691345,0.0,accept,unanimous_agreement
779843382,6891,now codes are changed based on our discussion a few days ago. and ci is passed. please take sometime to take a look. thanks,1,1,1,0.9718800783157348,0.9486629366874696,0.9761868715286256,1.0,accept,unanimous_agreement
780758945,6891,"i'm afraid we'll miss some check in some `if` and that this code will not be covered by the test suite. since this is a crash report code, i don't think performance matters, and i'll feel better passing an empty dict.",-1,-1,-1,0.932646095752716,0.902259886264801,0.8666419386863708,-1.0,accept,unanimous_agreement
780759921,6891,"maybe i'm wrong. i.e. this code is already only reachable if someone asked for `everything || modules`, or a specific section that was not found, so i guess the current code is ok. i.e. if user passed `everything` or `modules`, then we'll get here with an empty section list and skip the section name based filter. and if the user passed a specific section, we do the filter by it's name.",0,0,0,0.8218868374824524,0.9884800910949708,0.9503848552703856,0.0,accept,unanimous_agreement
780760315,6891,"yes, but you only lowered the `full_name` (module + section). the other part of the `if` is on `ctx->module->name` which should also be lowered. unless we'll use a case-insensitive dict hash + compare (e.g. dictgencasehashfunction)",0,0,0,0.9889425039291382,0.9948327541351318,0.9939881563186646,0.0,accept,unanimous_agreement
780761758,6891,"i see the problem. we actually have two sections for `modules`. one is for the module list, printed by the genredisinfostring and included by default, and the other is the module generated sections (not included by default, but is added by either `everything`, or `modules` args). i think it will be clearer (and maybe also less code), if we change the default section list to include `module_list` instead of `modules`. then the code in genredisinfostring that generates the module list will depend on this section name (it'll still emit `# modules` to be backwards compatible. but when the user asks for ""modules"" we'll treat this as a request for the module generated sections.",0,0,0,0.9412660002708436,0.9867411255836488,0.94595468044281,0.0,accept,unanimous_agreement
780792058,6891,"no need for malloc, just keep it on the stack",0,0,0,0.9782721996307372,0.988319993019104,0.9934321045875548,0.0,accept,unanimous_agreement
780793702,6891,"once again, i think sentinel must sanitize the returning dict (i.e. remove any unknown section from the dict before calling `genredisinfostring`), and not induce any changes on this function. in any case, if the user types `info replication`, you need to delete that entry from the dict, right? so why bother changing the default?",0,0,0,0.9854241013526917,0.9894838929176332,0.9893091917037964,0.0,accept,unanimous_agreement
780793871,6891,"what's ""info""? do we have an `info info`? i don't see any reason to handle `argc == 1` differently than the loop on all arguments.",0,0,0,0.9601990580558776,0.9816323518753052,0.9896910190582277,0.0,accept,unanimous_agreement
780794225,6891,"according to my proposal, this would be: [code block] and `modules_list` will be added to the default sections.",0,0,0,0.9878073334693908,0.9919628500938416,0.9947799444198608,0.0,accept,unanimous_agreement
780794594,6891,"if you follow my advise, and remove have sentinel sanitize the section list before calling this function, you will not need the sentinel check here, and in any other sections in this function. (of course it should avoid passing the all or everything flag, and instead just set a static list of sections in the dict) [code block]",0,0,0,0.9829158782958984,0.9896631836891174,0.9933617115020752,0.0,accept,unanimous_agreement
780794970,6891,"i think we should go here on `info everything`, `info modules`, and any case where a requested section was not found (i.e. the number of emitted sections is lower than the number of requested sections) [code block]",0,0,0,0.9885968565940856,0.9937220215797424,0.990758180618286,0.0,accept,unanimous_agreement
781468300,6891,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
781469423,6891,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
781469766,6891,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
781471479,6891,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
781472545,6891,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
781488472,6891,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
781576817,6891,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
782271960,6891,"address, i update the code to robj *argv[1];",0,0,0,0.9891084432601928,0.9930740594863892,0.9948334693908693,0.0,accept,unanimous_agreement
782403784,6891,update codes: add module_list in default section list,0,0,0,0.9887723326683044,0.9938151836395264,0.9943049550056458,0.0,accept,unanimous_agreement
782404207,6891,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
782404257,6891,addressed,0,0,-1,0.9792097806930542,0.9635511636734008,0.5785259008407593,0.0,accept,majority_agreement
782405640,6891,"sorry, oran. here i am a little bit confused why you think ctx->module->name should be lowered as well. when i do test, i do not find the reason and i am not familiar with the module part. could you please give me one example on this. thanks.",-1,-1,-1,0.9877459406852722,0.9872393012046814,0.9787771701812744,-1.0,accept,unanimous_agreement
782406454,6891,i add a dict instead of using a null in the genredisinfostring function according to your comments,0,0,0,0.9853150844573976,0.9937375783920288,0.9954741597175598,0.0,accept,unanimous_agreement
782539471,6891,"rm_createdatatype says [code block] so a module name could have upper case characters, and in info we wanna do case-insensitive matching for the section names, so the module section (in case the module didn't explicitly define a section name) could be uppercase.",0,0,0,0.9892983436584472,0.99384742975235,0.9941202998161316,0.0,accept,unanimous_agreement
782542646,6891,"now that i think of it, maybe we wanna return this also if the `modules` section was requested. i.e. this `if` will check both `modules` and `module_list`",0,0,0,0.9861977696418762,0.9898287653923036,0.9842426776885986,0.0,accept,unanimous_agreement
786123832,6891,"since the module name is case sensitive, there appears to be a risk that a case-insensitive search on the module name could generate false matches. is that acceptable behavior?",0,0,0,0.9666185975074768,0.9887475967407228,0.9828770756721495,0.0,accept,unanimous_agreement
786150160,6891,"you're right. but since info sections are case-insensitive, i think i'd rather return two sections in case there are two modules with similar name, rather than not return a section because the info command was used with non-exact case.",0,0,0,0.9733628034591676,0.94410902261734,0.9739767909049988,0.0,accept,unanimous_agreement
797409290,6891,"these 4 segments are nearly identical, let's run them in a for loop, each time using a different input, with the same validations.",0,0,0,0.9851880073547364,0.9588983654975892,0.9894858598709106,0.0,accept,unanimous_agreement
797409956,6891,"i think it's enough to test just one section (we're testing the infrastructure, not the actual per section implementation)",0,0,0,0.9739954471588136,0.9803224205970764,0.9791918396949768,0.0,accept,unanimous_agreement
797411298,6891,"same here, it's enough to test just one pair of sections, and an additional one test of a combination of `all` and a section. i.e. two segments of tests instead of 4.",0,0,0,0.985791563987732,0.9928817749023438,0.9924834370613098,0.0,accept,unanimous_agreement
797412755,6891,"it's enough to test just a few fields. i.e. version, memory, sentinel, and cmdstats.",0,0,0,0.9859376549720764,0.9922459721565248,0.9936240911483764,0.0,accept,unanimous_agreement
797414491,6891,"same here, this could be shorter, similar to the above, just expecting a different outcome for cmdstat",0,0,0,0.9853237867355348,0.979333221912384,0.9889752864837646,0.0,accept,unanimous_agreement
797414680,6891,let's combine this into the same test that passes no arguments in a for loop,0,0,0,0.9840813875198364,0.9901690483093262,0.991612195968628,0.0,accept,unanimous_agreement
797415007,6891,this can be unified with the one that takes `all` in a for loop,0,0,0,0.9857894778251648,0.9942915439605712,0.9943600296974182,0.0,accept,unanimous_agreement
797416113,6891,"i'd drop these two last segments. enough to test `cpu`, sentinel` (not supported), and maybe `commandstats` (not in default)",0,0,0,0.9876205325126648,0.99174565076828,0.9931001663208008,0.0,accept,unanimous_agreement
797418415,6891,test that we didn't get some stat twice. i.e. we can check that this fails: `*used_cpu_user*used_cpu_user*,0,0,0,0.932346522808075,0.9879790544509888,0.9927473664283752,0.0,accept,unanimous_agreement
797422833,6891,"lets make this shorter, it is enough for each of these tests to include just one non-module info field or section name",0,0,0,0.985775589942932,0.9916715025901794,0.9893236756324768,0.0,accept,unanimous_agreement
800073705,6891,"how about doing the default sections dict static and re-use it, instead of re-generating it every time?",0,0,0,0.981374740600586,0.9861811995506288,0.9908438920974731,0.0,accept,unanimous_agreement
800075143,6891,"you mean only in the case of info with no args, right? since when the user provided any inputs, we could modify the dict. also, we'll need to make sure to skip this optimization from sentinel since it modifies that dict. and we'll need to add some trick to avoid releasing it when done. do you think these complications are worth it?",0,0,0,0.9717442989349364,0.9770824909210204,0.9792390465736388,0.0,accept,unanimous_agreement
800079066,6891,"yes, i was only referring to the default list. it's probably a good idea this doesn't introduce a regression, because some clients use `info` quite extensively.",0,0,0,0.9617164134979248,0.6942119002342224,0.98383766412735,0.0,accept,unanimous_agreement
800096777,6891,please have a look at my last commit.,0,0,0,0.9501760005950928,0.9673027396202089,0.9903385043144226,0.0,accept,unanimous_agreement
801091850,6891,"this uses sdsfree so it's not just for cstrings, also you only store sds in this dictionary anyways. so it's not very clear why this isn't just an sdssetdicttype. you could also further use the existing case insensitive compare functionality to avoid the sdstolower() called later.",0,0,0,0.9869118928909302,0.988965392112732,0.9927505254745485,0.0,accept,unanimous_agreement
801406920,6891,"the entries in that dict are sds, but the lookup (hash / compare) callbacks work with c string. let's document that better... regarding case-insensitive compare, it came up before, i don't recall why we didn't go there. let's try again (using `dictgencasehashfunction`, and `strcasecmp`) can you look into it?",0,0,0,0.9841471910476683,0.9846591949462892,0.99273020029068,0.0,accept,unanimous_agreement
801509008,6891,"never mind.. had a few spare minutes and took care of it, don't understand / recall why it wasn't done before.",0,0,0,0.6168679594993591,0.8170588612556458,0.812260091304779,0.0,accept,unanimous_agreement
557455789,8242,"i would like to avoid creating a new file for that one function. i think it roughly fits into anet.c. the majority of the fds we need to modify are sockets, and i don't think it's a big violation to put there a generic function and use it on other file descriptors. come to think of it, we already do that using `anetsetblock` on pipes.",0,0,0,0.9359548091888428,0.9553632140159608,0.9764629602432252,0.0,accept,unanimous_agreement
557456684,8242,"i suppose this change isn't needed, right? (although it doesn't cause any harm either)",0,0,0,0.944705605506897,0.9518845081329346,0.976836085319519,0.0,accept,unanimous_agreement
557458146,8242,looks like you added a trailing white space here.,0,0,0,0.985420286655426,0.975350558757782,0.9853944778442384,0.0,accept,unanimous_agreement
557479954,8242,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
557480910,8242,"this file might be opened in redis server as well as sentinel, so it's reasonable to enable this flag here.",0,0,0,0.98767751455307,0.9928017854690552,0.9943972826004028,0.0,accept,unanimous_agreement
557481086,8242,fixed.,0,0,0,0.9810503125190736,0.979083240032196,0.9905837774276732,0.0,accept,unanimous_agreement
557484529,8242,"`sentinel` and `cluster` are two different things. when redis runs in sentinel mode it'll never reach this code. one can argue (being right), that it's better to have this flag (may come in hand one day in the future), but currently it's not needed. i don't feel strongly either way. just making a point.",-1,0,0,0.8695876002311707,0.8122223615646362,0.7540754079818726,0.0,accept,majority_agreement
557494308,8242,"i see your point now, but let's keep this flag here just in case, and it has no harm for that.",0,0,0,0.894858717918396,0.8860196471214294,0.9569298624992372,0.0,accept,unanimous_agreement
559169659,8242,"styling.. as far as i can tell, redis always has braces in loops. [code block]",0,0,0,0.9833093285560608,0.9508390426635742,0.987101435661316,0.0,accept,unanimous_agreement
559170387,8242,"there are never any modules in sentinel. maybe we can consider to make the call to `moduleinitmodulessystem` from `main` conditional (can be moved to the `else` of `initsentinel`. however, if we do that, we may need to at least zero some of the globals it initializes. i suppose there's no harm in keeping this change though. maybe it'll come in useful in the future.",0,0,0,0.9702746868133544,0.9888066053390504,0.9620038270950316,0.0,accept,unanimous_agreement
559171321,8242,"i think it would be nicer to check for `instances == null`, and document that that's how to use this recursion. if we can't then maybe split this method so that the wrapper is exposed in the header (with no arguments), and the main body here is only used by the wrapper internally. please review too",0,0,0,0.9551202058792114,0.9868378043174744,0.9875828623771667,0.0,accept,unanimous_agreement
559172515,8242,"this function (`prepareforshutdown`) is only called before `exit`, so there's no leak possible. the comment says that the only reason we close the listening socket, so for faster restarts (not sure why). other than that, redis counts on the os to clean up after it, so i think we should remove that new block of code (it's comments are certainly false)",0,0,0,0.9825976490974426,0.9889728426933287,0.9899699091911316,0.0,accept,unanimous_agreement
559172803,8242,i would like to move that file into the `tests/sentinel/tmp/` folder.,0,0,0,0.9849895238876344,0.9933911561965942,0.9941158294677734,0.0,accept,unanimous_agreement
559173285,8242,"lets `cat` that file into the stdout, this way we know the output on github actions and such environment (where we only have the standard output). something like `exec cat $filename` would do",0,0,0,0.9882800579071044,0.9908822774887084,0.9931032657623292,0.0,accept,unanimous_agreement
559174642,8242,"did you mean `ls -l` each fd in a separate line? what's `3`? do you mean the access to `/proc/ /fd` itself? it won't always be in 3. seems to me that this would hide a leak of fd `10`, and even `17` and `71`?",0,0,0,0.9806159734725952,0.9910135865211488,0.9925877451896667,0.0,accept,unanimous_agreement
559175144,8242,why should we change it from `flags = r | fd_cloexec` to `flags |= fd_cloexec`?,0,0,0,0.984567165374756,0.994481921195984,0.9923034906387328,0.0,accept,unanimous_agreement
559175442,8242,"ohh, sorry. my bad.",-1,-1,-1,0.9892470240592957,0.993221879005432,0.9952367544174194,-1.0,accept,unanimous_agreement
559176087,8242,"in that case, the code of `sentinelreleaseinstanceconnections` function should also be erased?",0,0,0,0.985637366771698,0.9953060746192932,0.9944632649421692,0.0,accept,unanimous_agreement
559176262,8242,"actually, this file would be created in that path by the current code: warning: sentinel test(s) failed, there are leaked fds in sentinel, see output file: /data/c/redis/tests/sentinel/tmp/sentinel_fd_leaks for more details.",0,0,0,0.9878607392311096,0.9934293627738952,0.9945441484451294,0.0,accept,unanimous_agreement
559177721,8242,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
559179752,8242,"'^[0|1|2|3]$' will fix the leftover fds, as for the `/proc/ /fd`, any concise way to exclude it?",0,0,0,0.977807343006134,0.9928575754165648,0.992839217185974,0.0,accept,unanimous_agreement
559181104,8242,then let's keep this function for future uses.,0,0,0,0.9861463904380798,0.9844830632209778,0.9919174313545228,0.0,accept,unanimous_agreement
559182072,8242,"i was worried about creating an endless loop if the `ri->slaves` or `ri->sentinels` is `null`, so change the condition from `instances == null` to `master == 1`.",-1,0,0,0.9063091278076172,0.845465898513794,0.9798281788825988,0.0,accept,majority_agreement
559184708,8242,"after a second thought, i think it would be better to split this function, and expose no arguments to server.c, after all that the server.c doesn't need to know about the `sentinel.masters`.",0,0,0,0.9807325005531312,0.9910948276519777,0.9820021390914916,0.0,accept,unanimous_agreement
559185380,8242,"if closing sockets makes the restart faster, isn't it (sentinelreleaseinstanceconnections) supposed to achieve the same effect on a restart of sentinel?",0,0,0,0.9802163243293762,0.9937471151351928,0.9929505586624146,0.0,accept,unanimous_agreement
559187376,8242,i think that only applies for listening sockets. the commit that added it isn't very specific 80e87a461a7d2ee54430127bdb6ac014778c54c5 but i suppose it means that then new process that comes up is able to bind successfully immediately. i don't think it applies for other (non listen) sockets,0,0,0,0.9712150692939758,0.9823175668716432,0.9832635521888732,0.0,accept,unanimous_agreement
559187444,8242,"so, yeah, if that's the only use for the new `sentinelreleaseinstanceconnections` let's drop that function too.",0,0,0,0.9843485951423644,0.9911977648735046,0.9938283562660216,0.0,accept,unanimous_agreement
559188253,8242,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
559188508,8242,"only way i can think of is to use `ls -l` and match that `*/proc/*/fd` pattern. so either that (and improve the regex), or we can maybe keep the current code and add some comment. [code block]",0,0,0,0.9872100353240968,0.9932987093925476,0.9931233525276184,0.0,accept,unanimous_agreement
559188692,8242,"so now that we removed the call in prepareforshutdown, we can remove this function",0,0,0,0.9892917275428772,0.9919825196266174,0.9939393997192384,0.0,accept,unanimous_agreement
559188843,8242,i suppose we no longer need to print the file name if we print it's content,0,0,0,0.9878401160240172,0.9694523215293884,0.98768949508667,0.0,accept,unanimous_agreement
559189143,8242,i would prefer to keep the current code because the `notify.sh` is an extremely simple shell script where the fd 3 is typical for this kind of shell script to open for its `/proc/self/fd` and there's only a very small probability that it will open another fd for it.,0,0,0,0.9795788526535034,0.985767126083374,0.9828081727027892,0.0,accept,unanimous_agreement
559189906,8242,this output file could be for users to persist the fd leaks result in their local environment in case they miss the std output (by any chance)?,0,0,0,0.9892616271972656,0.9892519116401672,0.9928283095359802,0.0,accept,unanimous_agreement
559190171,8242,"but then they'll miss the warning message above, and this message which states the path to the file anyway.",0,0,0,0.9761927723884584,0.9822631478309632,0.9765688180923462,0.0,accept,unanimous_agreement
559190540,8242,i was talking about the case that it's not their first run for this test suite and already know where this file will locate.,0,0,0,0.9717568159103394,0.9855588674545288,0.9771012663841248,0.0,accept,unanimous_agreement
559190848,8242,i thought we are gonna keep this function for future uses?,0,0,0,0.985301911830902,0.9861282110214232,0.985608458518982,0.0,accept,unanimous_agreement
559191136,8242,"by the way, just being curious, isn't really there anywhere in the project where you need to close these pipes in the current redis server? it just keeps these pipes alive during the whole server runtime?",0,0,0,0.940202295780182,0.899620532989502,0.974833607673645,0.0,accept,unanimous_agreement
559193358,8242,"considering we don't expect this test to ever fail, unless some regression happens, no one will know about the existence of that file, until the ci will fail the day after the offensive pr is merged. and then we'll get the full stdout in the output.",0,0,0,0.9757888317108154,0.979909360408783,0.9830607771873474,0.0,accept,unanimous_agreement
559193629,8242,so we just comment out these code lines in the present?,0,0,0,0.9866207838058472,0.9908855557441713,0.993497371673584,0.0,accept,unanimous_agreement
559193672,8242,"afaiu what we wanted to keep for future use is the close on exec flag even for parts of redis that never do exec. (cluster and modules). specifically because it doesn't add much code (one flag in an existing call, or one new line) but i don't see a reason to keep dead code for future use (specifically because it's so easy to write). and yes, redis never closes these pipes.",0,0,0,0.963872253894806,0.9817920327186584,0.9786689281463624,0.0,accept,unanimous_agreement
559193925,8242,"maybe we have a misunderstanding.. for some reason github shows as if i commented on the entire block. i mean to just remove the last line (the one that prints the file name). the warning and `cat` should be kept, and i think that's sufficient.",0,0,0,0.9107133746147156,0.9453917741775512,0.8492090106010437,0.0,accept,unanimous_agreement
559194458,8242,i meant to only comment out the lines that prints the file path and switch it on when we need it.,0,0,0,0.9785602688789368,0.984764277935028,0.986081600189209,0.0,accept,unanimous_agreement
559194506,8242,see the latest commit.,0,0,0,0.9853835701942444,0.9860817193984984,0.995131015777588,0.0,accept,unanimous_agreement
559194910,8242,"never mind, it doesn't indeed seem to have much value, removed it.",0,0,0,0.8331918716430664,0.8241094350814819,0.7875981330871582,0.0,accept,unanimous_agreement
559195071,8242,understood.,0,0,0,0.977540135383606,0.982597291469574,0.9652015566825868,0.0,accept,unanimous_agreement
560403676,8242,"sorry. my bad for completely forgetting there are other oses. we have quite a few places that use `uname` in the tcl code to skip tests. so we can skip registering that bash script. (instead of the change in the bash file). i don't have an objection for that change in the bash script, but i rather an early exit than the indentation you added. and i don't think the `echo` is useful, i rather drop it. i'll look into the ci issue..",-1,-1,-1,0.9910981059074402,0.993767023086548,0.9899791479110718,-1.0,accept,unanimous_agreement
560566820,8242,"it did seem to make a little more sense to do this in tcl rather than bash. since this pr is already merged in, then i just open a new pr for it?",0,0,0,0.9730519652366638,0.99186772108078,0.9835975766181946,0.0,accept,unanimous_agreement
560590507,8242,done in #8364,0,0,0,0.9877911806106568,0.9913411736488342,0.9940126538276672,0.0,accept,unanimous_agreement
722187208,9601,overflow/underflow causes ub (integer overflow is undefined behavior),0,0,0,0.9841365814208984,0.9325740337371826,0.9870175719261168,0.0,accept,unanimous_agreement
722187893,9601,"if value is negative, it's ub. (negative integer shift)",0,0,0,0.9810482263565063,0.982219099998474,0.990561068058014,0.0,accept,unanimous_agreement
722188850,9601,unaligned load. bitshift version is good enough. compilers recognize pattern and generate single mov instruction(if cpu is ok with unaligned load).,0,0,0,0.8848142623901367,0.9757199883461,0.9881619811058044,0.0,accept,unanimous_agreement
722190811,9601,"left shift of unsigned char promotes variable to ""int"". variable can become negative in that case(ub), further shift is ub etc.",0,0,0,0.9860279560089112,0.9933029413223268,0.9924893379211426,0.0,accept,unanimous_agreement
722191454,9601,"left shift of unsigned char promotes variable to ""int"". variable can become negative in that case(ub), further shift is ub etc.",0,0,0,0.9860279560089112,0.9933029413223268,0.9924893379211426,0.0,accept,unanimous_agreement
722192080,9601,unaligned load is ub. bit shift version generates same instructions with gcc or clang.,0,0,0,0.9881582856178284,0.993515133857727,0.9947482943534852,0.0,accept,unanimous_agreement
722192579,9601,buf is used after it goes out of scope.,0,0,0,0.985840916633606,0.989355206489563,0.9856923818588256,0.0,accept,unanimous_agreement
722194104,9601,"unaligned load. fix is to copy variables to a temporary aligned array, execute operation and store back variables to the destination. makes code a bit uglier though.",-1,0,0,0.9219968914985656,0.9521449208259584,0.6165235638618469,0.0,accept,majority_agreement
722195241,9601,hash(signed variable) is shifted beyond its size(ub) or becomes negative and shifted again (ub),0,0,0,0.9873685240745544,0.9892663955688475,0.9928827285766602,0.0,accept,unanimous_agreement
722195769,9601,`when * 1000` and `when += basetime` can overflow (integer overflow is ub).,0,0,0,0.9875504374504088,0.9889806509017944,0.9912962913513184,0.0,accept,unanimous_agreement
722196604,9601,i'm a bit confused here. bit shift version looks same to me with pointer load or mempcy even for little endian architectures.,-1,-1,-1,0.8929415345191956,0.91997230052948,0.7226807475090027,-1.0,accept,unanimous_agreement
722197949,9601,there is memmove() call later. looks like we call this function with s=null and len=0. memmove() is not supposed to be called with a null buffer even with len=0.,0,0,0,0.988643229007721,0.9907032251358032,0.9939279556274414,0.0,accept,unanimous_agreement
722198906,9601,address sanitizer complains about leaks in sentinel. added this function to call in prepareforshutdown().,0,0,0,0.9797565340995787,0.9812992215156556,0.9946245551109314,0.0,accept,unanimous_agreement
722199525,9601,"small leak, address sanitizer complains",0,-1,0,0.9232317209243774,0.8335734605789185,0.6078963279724121,0.0,accept,majority_agreement
722200650,9601,random write is an ub.,0,0,0,0.9856995940208436,0.9722123742103576,0.9908384680747986,0.0,accept,unanimous_agreement
722217118,9601,"adding `-fno-omit-frame-pointer` normally helps to get better stack traces in the results, anything you have tried?",0,0,0,0.9868506193161012,0.9941323399543762,0.9928561449050904,0.0,accept,unanimous_agreement
722260959,9601,"you're right, the bit shift version works for any endianness. it decodes little-endian `data` to local representation. the code you deleted is some handmade optimization only for little-endian machines that reads all bits together, but the bit shift version will compile to the same assembler afaik.",0,0,0,0.9835521578788756,0.974354088306427,0.9905073642730712,0.0,accept,unanimous_agreement
722916162,9601,"actually, i get pretty accurate stacktraces but maybe that's related to compiler version/arch i tried. i added that flag anyway, it might be helpful in another setup.",0,0,0,0.961176574230194,0.9568598866462708,0.9678351879119872,0.0,accept,unanimous_agreement
722921490,9601,"yeah, bit shift version generates single mov (for x86 at least) since ~ gcc 5. [a link]",0,0,0,0.9862020611763,0.9874308109283448,0.9923100471496582,0.0,accept,unanimous_agreement
723145870,9601,"that's exactly the point i wanted to argue, we can write simpler code (or in this case actually more complex), and assume (or even verify that) a modern compiler will do the right thing, but i rather not assume these (at least not in places where it really matters, i.e. performance intense loops). i would rather keep redis efficient (and correct) even if compiled on an odd / old compiler.",0,0,0,0.9123587012290956,0.9632447957992554,0.967427670955658,0.0,accept,unanimous_agreement
723182465,9601,"i think we need to improve `dump_server_log` in `tests/support/server.tcl` to also print the `stderr` file, otherwise we won't see the reports. it's probably also a good idea to use something similar when `--dump-logs` isn't specified. i.e. where `crashlog_from_file` is used.",0,0,0,0.97896409034729,0.993556797504425,0.9726396799087524,0.0,accept,unanimous_agreement
723240017,9601,"i don't know if performance matters here but some old/odd compilers will get a hit anyway. e.g they are falling into pointer load version before the fix and they won't able to emit single load after the fix. just specific to this one, we may keep mempcy() version for little endian systems if you want. looks like it's easier to optimize for compilers compared to bit shift one. (trying it from goldbolt.org). other option, not to fix at all :)",0,1,1,0.5631675124168396,0.9782797694206238,0.9754709005355836,1.0,accept,majority_agreement
723250091,9601,"could you explain what you did here (and in the other `if` below), i'm having hard time to follow..",-1,-1,-1,0.969028651714325,0.7160829305648804,0.8514731526374817,-1.0,accept,unanimous_agreement
723258451,9601,"i think the first part of the comment you removed is still applicable (i.e. the part about fast path vs vanilla algorithm), let's revive it.",0,0,0,0.9847919940948486,0.9859201312065125,0.9860727787017822,0.0,accept,unanimous_agreement
723280535,9601,this comment is outdated: (commenting on another line due to gh limitations) [code block] it was written in d866803818fb47a851e5730ccff634f993ce6f68 before f15df8ba5d and before the `use_aligned_access` check was added. lets use this opportunity to drop it.,0,0,0,0.70455402135849,0.9939056038856506,0.9925695061683656,0.0,accept,unanimous_agreement
723284609,9601,"so salvatore wrote an optimized path and made it run only on x86, and used an unoptimal one for arm, and we're now making that optimized path a bit less optimized, but make it work for arm too.... right? salvatore bothered to make sure that code only runs on platforms in which it's safe, but the sanitizer warning is bothering us (with no real good reason)... maybe we can also just silence that warning specifically for that code block? i don't mind keeping your change either, since doesn't seem your change would hurt performance. i.e. we know most compilers will convert that memcpy to either a single load instruction on x86, or multiple ones on arm, and i suppose the later code in the loop will probably be using registers and not really accessing that temp variable... anyway, my point is that if we wanna make that change i wanna make sure we prove it doesn't hurt performance at all.. did you do that?",0,-1,0,0.5972005724906921,0.6110172271728516,0.5593578815460205,0.0,accept,majority_agreement
723305353,9601,"considering the address sanitizer is so much faster than valgrind, maybe we wanna run it in the ci workload (per pr), and hopefully stop leaks before they reach the daily workflow? wdyt?",0,0,0,0.9741420745849608,0.978201389312744,0.9866623282432556,0.0,accept,unanimous_agreement
723308358,9601,"keep the memcpy then, since it's not unaligned. if we use unaligned access, it should be only within some ifdefs for archs that support it. i see that we have a macro which forbids it for certain archs known not to support it which is a bit backwards: [code block]",0,0,0,0.9823414087295532,0.9731295108795166,0.9825175404548644,0.0,accept,unanimous_agreement
723317683,9601,"... and if we want to run santitizers in builds, we should silence the warnings where we know it's safe. is there any pragma or so to do that?",0,0,0,0.9269869327545166,0.9811024069786072,0.9883620142936708,0.0,accept,unanimous_agreement
723317877,9601,"in some way, this debug segfault is attempting to mimic a real segmentation fault, and calling `raise` may behave slightly different (e.g. signal sender is the user space program and not the kernel). would changing it to write to null (address 0 instead of -1) resolve the warning? if not, maybe we can silence this warning somehow? i'm probably just paranoid, and it's probably not a real problem to replace it with raise, but this is an example of a ub that's on purpose and we may wanna silence it instead of ""fixing it"". wdyt?",-1,0,0,0.8577919006347656,0.7818871140480042,0.549207329750061,0.0,accept,majority_agreement
723339745,9601,"just for the sake of discussion... integer overflow is ub? this is bs! can someone enlighten me on a single arch in which this would not work? afaik multiplication, accumulation, and subtraction are always compiled to the same instruction (regardless of the signness of the variable). ie. the sign only matters for comparison and division (and sign extension: r-shift, casting, etc) and the claim is that signed integer overflow is ub, while unsigned integer overflow is not ub, right?",0,0,0,0.9112010598182678,0.909306824207306,0.7598902583122253,0.0,accept,unanimous_agreement
723343246,9601,"i think the comment is still useful (explains which validation we do and which validation we can't do), let's bring it back.",0,0,0,0.9778627157211304,0.965605616569519,0.9111737608909608,0.0,accept,unanimous_agreement
723349381,9601,"again, a case were we're dismissing an optimization (which had a check to run only when it's safe) because modern compilers do that anyway, but i don't like to think redis is only targeted to these.",0,-1,0,0.5181849002838135,0.5741664171218872,0.9560815691947936,0.0,accept,majority_agreement
723379212,9601,"what a horrible bug. i see (tested) that on x86 it behaves as ""expected"". returned the correct result and even compiled to the same assembly as the fixed version (in both old and new compilers (which generated completely different assembly). it also generates the same assembly as the fixed version on arm. do we know of any system on which it really produced a bug? if it did, then this backported to older releases and mentioned in release notes (in which case we better move this fix to a separate pr)",-1,-1,-1,0.98979914188385,0.9846665859222412,0.9931575655937196,-1.0,accept,unanimous_agreement
723386797,9601,"what did it complain on? we don't bother to release memory on shutdown in redis (this slows down termination). and valgrind searches for referenced memory, not unreleased.. so i'm curious to know what was the issue (and too lazy to reproduce and check)",-1,-1,0,0.6711982488632202,0.672160267829895,0.629790723323822,-1.0,accept,majority_agreement
723388488,9601,can you please assess the effects of this bug?,0,0,0,0.9821581840515136,0.9793940782546996,0.984119474887848,0.0,accept,unanimous_agreement
723389749,9601,let's discuss this after we conclude the discussion in rdbloadintegerobject,0,0,0,0.9838606119155884,0.9870280027389526,0.9944878220558168,0.0,accept,unanimous_agreement
723391002,9601,let's discuss after we conclude the discussion in bitops.c and hll,0,0,0,0.9716729521751404,0.9874123334884644,0.9928132891654968,0.0,accept,unanimous_agreement
723397242,9601,"really? now any shift on a signed integer is ub? this is bs, left shift doesn't care of the signness of the variable, or the content of the bits. it could overflow and become positive or negative according to the contents of the bits, but what's undefined about that? anyway, considering i know how this code is compiled to assembly, i don't see how this could have caused bugs. i.e. it would move the bits to the upper part of the integer, possibly flip the bytes in be, and then copy them. let me know if you think i'm wrong.",0,-1,0,0.9527543783187866,0.6848441958427429,0.8723595142364502,0.0,accept,majority_agreement
723937672,9601,"my notes regarding ub for signed overflows: - i'd like to propose defining redis as ""only works on cpus with 2's compliment"". if i understand [a link] correctly then this assumption is valid. this means we'll pass the `-fwrapv` argument to the compiler (both clang and gcc support this) and we'll rid ourselves of this pesky issue. i think any compiler optimizations based on signed integer overflow ub (like optimizing out `if (i + 1 > i)`) are only valid in cases the code is exceptionally badly written. - there might be some cases currently detected by the sanitizer where we should have used an unsigned value. i'm not sure there are such. for example the case above we know `value` might be negative but in that case it's safe to assume its top 40 bits are 1s since it's in the 24 bit range. so left shifting by 8 doesn't change the sign and doesn't produce an overflow. passing `-fwrapv` would simply guarantee it does what we originally wanted it to do. - there are cases in our existing code (like #8910) where we avoid signed overflow ub by creating extra checks which make the code ugly and less efficient. having `-fwrapv` will avoid this, and we should fix those places in the code.",0,0,0,0.7405669689178467,0.9075124859809875,0.9647983312606812,0.0,accept,unanimous_agreement
723957806,9601,[code block] looks like gcc and clang accept attributes for functions to surpress it.,0,0,0,0.9886549711227416,0.9869332313537598,0.9910463690757751,0.0,accept,unanimous_agreement
723968410,9601,"`__attribute__((no_sanitize(""undefined"")))`",0,0,0,0.9872590899467468,0.9932844638824464,0.994426131248474,0.0,accept,unanimous_agreement
723980100,9601,"good idea -steinberg. the santitizer complains because the c standard doesn't assume anything about the representation. in ancient history, there were alternatives: ""one's complement"" and ""sign & magnitude"". in practice, it's bs though. wikipedia on two's complement:",1,1,1,0.91383957862854,0.9638231992721558,0.9726350903511048,1.0,accept,unanimous_agreement
724005075,9601,"if -fwrapv used, i think no need to say whether redis works with 2's compliment or not, compiler will generate correct code for any cpu if i'm not mistaken. afaik linux uses -fwrapv and works everywhere :)",1,1,1,0.9091061353683472,0.9823040962219238,0.9928665161132812,1.0,accept,unanimous_agreement
724006380,9601,"unlike the unaligned pointer access, the majority of the changes in this pr for integer overflows seem to me that are ok to be merged (they don't introduce any ugly code or efficiency issues), and the main point of the lengthy discussion for was to rant about it being bs (because it's fun to discuss). i do like the idea of getting rid of the ugly code in #8910 and the few other places that do that. however, i don't like to depend on specific compiler flags that may be missing in some odd/old compilers (unless we use these flags only to silence the sanitizer in it's ci build). so the question is if we drop these changes and add a compilation flag just for one compiler, if we're not taking a risk that the other compilers will decide to mess up the perfectly good code, just because in theory it relies on ub. am i right? if i am, then we can't do that.",1,1,0,0.55353182554245,0.8652225136756897,0.4930967390537262,1.0,accept,majority_agreement
724011526,9601,"nice, so we can keep using the (theoretically more efficient on some old compilers) unaligned access code on x86, and just silence the sanitizer warning. however, in bitops.c, this pr currently changes the implementation on arm to be more efficient (not fall back to the loop that processes just one byte at a time), i'd like to try to keep that.",0,0,0,0.692651629447937,0.9426913857460022,0.7046189308166504,0.0,accept,unanimous_agreement
724014592,9601,it's also possible to disable certain kinds of ub warnings by adding `-fno-sanitize=shift` after `-fsanitize=undefined` to disable this warning.,0,0,0,0.9887776970863342,0.9934908747673036,0.9943865537643432,0.0,accept,unanimous_agreement
724032575,9601,"i think you are right, but i'm still for defining redis as ""requires two's complement implementation of signess"" and therefor any compiler that doesn't assume that (and assumes ub or something else instead) is not compatible with redis. this, of course, is purely theoretical as there are no such (relevant) compilers. and if redis ever crashes or doesn't pass tests or sensitization on such a setup, we'll know why.",0,0,0,0.963806688785553,0.9368130564689636,0.9025428891181946,0.0,accept,unanimous_agreement
724051660,9601,"sanitizer will complain with attempts to write out of process' address space. so, 0, null or -1 fails as well. we can surpress with this attribute mentioned.",0,0,0,0.9746901988983154,0.6672704815864563,0.9928809404373168,0.0,accept,unanimous_agreement
724097766,9601,"i don't know if it can cause any problem for relevant systems. looks like it generates same code for all major compilers/systems. just as an example this one would be a bug, a system where int is 2 bytes, result would be wrong(even if it wraps). also, usual suspects like ardunio, avr generates different code ([a link] but they are microchips.",0,0,0,0.9560901522636414,0.7339770793914795,0.92908775806427,0.0,accept,unanimous_agreement
733168943,9601,"i added these but i have no prior tcl experience, could you review tcl file changes?",0,0,0,0.9861689805984496,0.9878936409950256,0.9906923174858092,0.0,accept,unanimous_agreement
733171584,9601,"actually, i'm confused with existing if checks. i believe conditions inside the if checks overlap with each other. so, i did it in a non-overlapping way but let's revert the change, it's hard to understand already and i don't want to cause a regression. current change, just does a uint64_t cast, this should behave same way before this pr and prevent integer overflow.",-1,-1,0,0.6517971158027649,0.5792743563652039,0.5676138401031494,-1.0,accept,majority_agreement
733174860,9601,added back,0,0,0,0.9769960045814514,0.9585580825805664,0.990625023841858,0.0,accept,unanimous_agreement
733344909,9601,"this seems weird to me. why not raise a segfault explicitly? writing to address -1 wouldn't necessarily do this, or am i wrong?",-1,-1,-1,0.9841981530189514,0.979622483253479,0.9822752475738524,-1.0,accept,unanimous_agreement
733346203,9601,see [a link],0,0,0,0.9835211038589478,0.9869033098220824,0.99574077129364,0.0,accept,unanimous_agreement
733366692,9601,"yes, i agree with you. compiler can even delete this line as this is clearly an ub (checked a few compilers and they don't do though). related discussion : [a link]",0,0,0,0.9720789790153505,0.8259502649307251,0.9668002724647522,0.0,accept,unanimous_agreement
735132322,9601,"-steinberg i was concerned that using `raise` could in some way be different than a plain access violation, and since the purpose of this sub-command is to test the crash log by simulating an access violation, i think the best thing we can do is to actually do just that. if we're absolutely sure there's no difference between the two (from the perspective of the signal handler, on any / all platforms), i don't mind switching. on the other hand, if for some reason the compiler decides to delete that code, there's no real harm to redis (and the tests will fail), so as long as we silence the warning i guess we're good.",0,0,0,0.6057358980178833,0.9057117700576782,0.8181492686271667,0.0,accept,unanimous_agreement
735133180,9601,"do these sometimes exists in stdout and other times exist in stderr? if not, i think it's a better idea to split it into two functions, i.e. `crashlog_from_file` and `sanitizer_warnings_from_file` or alike.",0,0,0,0.9856071472167968,0.9917260408401488,0.9906643629074096,0.0,accept,unanimous_agreement
735133653,9601,"maybe we need to update the comment? either just delete it, or mention the casting is needed to solve the ub?",0,0,0,0.985326647758484,0.9912320971488952,0.9877561330795288,0.0,accept,unanimous_agreement
735136049,9601,"i see you reverted this, do you have any feedback as to what was the trigger for that change?",0,0,0,0.9837304353713988,0.9844911694526672,0.9902439713478088,0.0,accept,unanimous_agreement
735149044,9601,"i ran same tests with valgrind, it was clean. also, when we clean memory on exit, sanitizer was okay, didn't show a leak. so, it proves that those memory allocations were still ""reachable"". i considered this a false positive. (address sanitizer is supposed to show ""unreachable"" memory only). i've realized that sanitizer doesn't complain about this issue with ""libc"", so i've changed sanitizer builds to use ""libc"" to avoid these kind of false positives.",0,0,0,0.9418967962265016,0.9616609811782836,0.9495710134506226,0.0,accept,unanimous_agreement
735161945,9601,the comment is still accurate. added a line for the cast.,0,0,0,0.9796546101570128,0.9864808320999146,0.9913761019706726,0.0,accept,unanimous_agreement
735162210,9601,prints to stderr only. splitted functions.,0,0,0,0.988962471485138,0.989658772945404,0.9940401911735536,0.0,accept,unanimous_agreement
735297253,9601,"i agree. if that's the purpose better do a real access violation and let our tests verify it's actually working. looking at [a link] it seems accessing address 0 might be the best option, but if we have a test for this which passes on all relevant oss/compilers with -1 then that's good too.",0,0,0,0.756920576095581,0.8364017009735107,0.8106202483177185,0.0,accept,unanimous_agreement
735370006,9601,"actually, on a second look, we don't have that test (yet). the test i remembered is one located in `tests/integration/logging.tcl`. i see it tests the watchdog-period, and an explicit sigabrt, but not debug segfault. and even that is skipped on all platforms except linux and macos. the reason is that not on all platforms we can generate a stack trace (i.e. not that not on all platforms we can generate a crash log, sometimes without a stack trace) do we wanna take this opportunity to add another test there?",0,0,0,0.967702090740204,0.9915707111358644,0.9796492457389832,0.0,accept,unanimous_agreement
735374359,9601,worth noting that at least on gcc 11.2 this also yields a warning: [code block],0,0,0,0.9852460026741028,0.9551097750663756,0.9814894795417786,0.0,accept,unanimous_agreement
735379436,9601,what do you suggest? is there a way to suppress that warning properly (on all compilers)? or do you think we should rely on `raise` (less effective for what we actually want to test)? another alternative is to write some code that will confuse the compiler so it won't really know what address we write into at compile time (and silence it in the sanitizer),0,0,0,0.9739383459091188,0.9759663939476012,0.9904237389564514,0.0,accept,unanimous_agreement
735389362,9601,"there is a way to suppress this on gcc with a `#pragma` but then clang will complain about it. i think we can just change this to a null pointer which will also suppress the warning and while technically still a ub, we could probably assume it does what is expected.",0,0,0,0.9770725965499878,0.9479187726974488,0.9867016673088074,0.0,accept,unanimous_agreement
735393892,9601,"i've seen compilers deleting writes to null addr. btw, gcc should give same warning even it's null addr?",0,0,0,0.9863768219947816,0.9773676991462708,0.9883391857147216,0.0,accept,unanimous_agreement
735395475,9601,"changed it to null, gcc 10.2 gives a warning : [code block] option 1: __builtin_trap(). looks like clang supports that as well. option 2: `*((volatile char*)-1) = 'x';`",0,0,0,0.9841791987419128,0.994343876838684,0.9937902092933656,0.0,accept,unanimous_agreement
735401855,9601,how about making it `volatile` as suggested?,0,0,0,0.9816593527793884,0.9924159049987792,0.993437111377716,0.0,accept,unanimous_agreement
735403011,9601,"i think that if we're considering `__builtin_trap` we might as well use `raise`, that'll at least generate a sigsegv and not sigill.",0,0,0,0.9884710311889648,0.9929468035697936,0.9799984097480774,0.0,accept,unanimous_agreement
735407225,9601,`*((volatile char*)-1) = 'x';` suppresses warning for gcc.,0,0,0,0.9876430034637452,0.9934192299842834,0.9943051934242249,0.0,accept,unanimous_agreement
736245000,9601,"gcc(trunk) gives another warning even for volatile solution : [a link] [code block] another option : [code block] this one follows language rules, avoids compiler warnings and behaves equivalent to `*(char*)-1) ='x'; ` hopefully :)",0,1,1,0.7497490644454956,0.9905543923377992,0.9699029326438904,1.0,accept,majority_agreement
736363959,9601,"wow.. that's a very long way to go trigger a signal 8-( for a moment i was afraid it'll cause issues for `memtest_test_linux_anonymous_maps`, but that one is checking the `rw` flags. i suppose we're looking too much into this. i see that we have no chance to suppress the warnings, so i think i'd go with the `mmap` approach for debug.c, and with the `raise` approach for redisassert.c (the mmap approach looks too complicated to be put there). but if anyone thinks otherwise, i'm also willing to stick to `raise` in both and forget about this concern.",-1,-1,-1,0.8821622729301453,0.5647377371788025,0.9895586967468262,-1.0,accept,unanimous_agreement
736590314,9601,how long does such a run takes compared to a plain execution of `./runtest`?,0,0,0,0.9863594174385072,0.9927876591682434,0.9855934977531432,0.0,accept,unanimous_agreement
736643355,9601,"as nobody else has made a comment, i've made those changes. just a single concern about mmap solution is portability. hopefully, all operating systems implement mmap and flag combination we use. (i checked popular libraries how do they use mmap and i did in a similar way to provide max portability).",0,0,0,0.960772693157196,0.8643814921379089,0.9882712960243224,0.0,accept,unanimous_agreement
736652454,9601,"seems safe to me but we can also add the test i suggested [a link] i.e. add a test that uses debug segfault, and test that we got a sigsegv crash (and either only validate the stack trace part on linux/mac or not at all)",0,0,0,0.9690971970558168,0.9846700429916382,0.9917710423469543,0.0,accept,unanimous_agreement
737467592,9601,"sorry, i missed this. no change in execution time. they can be added to pr ci as well if you want. ub sanitizer catches some of the leaks/use-after-free issues as well, so i suggest adding both.",-1,-1,-1,0.979897916316986,0.9870376586914062,0.9716364741325378,-1.0,accept,unanimous_agreement
737468195,9601,added a test for it,0,0,0,0.9860852956771852,0.9900938868522644,0.9931963682174684,0.0,accept,unanimous_agreement
737706680,9601,"ok, if there's nothing to lose, let's do that.. it'll catch leaks before they are merged, and there's a smaller chance valgrind will panic the next day",0,0,0,0.58404541015625,0.9622822403907776,0.8244057297706604,0.0,accept,unanimous_agreement
741668979,9601,"i added sanitizers to pr ci (with same configs with regular pr ci : ./runtest --verbose --tags -slow). i also realized we don't check exit code of redis when we kill it. so, we were missing some sanitizer warnings that is printed on exit. i had to fix them and added checks to search log on exit for sanitizer errors, similar to valgrind build. please take a look at last couple of commits.",0,0,0,0.9702831506729126,0.9705631136894226,0.8907902240753174,0.0,accept,unanimous_agreement
741882591,9601,"these are kinda rare, i think we can keep relying on the daily ci for them.",0,-1,0,0.6667083501815796,0.5043153166770935,0.9177918434143066,0.0,accept,majority_agreement
741883568,9601,"is there any reason to keep the other `test-ubuntu-latest` job? i was thinking we can just re-purpose the one ""per pr"" test job we have to do both testing and address (leak) sanitization. is there any downside in that?",0,0,0,0.964554727077484,0.9748597741127014,0.9890071153640748,0.0,accept,unanimous_agreement
741885408,9601,why do we need this optional? why not have that always?,0,0,0,0.9313527941703796,0.9743762612342834,0.9827157258987428,0.0,accept,unanimous_agreement
741888913,9601,why not have that by default (when the build supports it)?,0,0,0,0.9759731292724608,0.9858696460723876,0.9846699237823486,0.0,accept,unanimous_agreement
741890142,9601,"i think maybe we can just apply this change on the default execution (the last `else` in this chain), but if not, please be aware that instances.tcl (cluster and sentinel tests) spawns severs on it's own (not using this code), see `exec_instance`",0,0,0,0.9876387119293212,0.994768500328064,0.9890187978744508,0.0,accept,unanimous_agreement
741922400,9601,"it's up to you. sanitizers instrument code and may hide some bugs due to slower execution, different code generation etc. ofcourse you can rely on daily ci for that, we still have default build and tests there.",0,0,0,0.9738734364509584,0.9901070594787598,0.971544086933136,0.0,accept,unanimous_agreement
741925753,9601,"made it similar to valgrind setting, it checks logs for sanitizer errors when built with sanitizer only. otherwise, it'll search logs unnecessarily. i can make it default if you are okay with that.",0,0,0,0.9634698033332824,0.9882181286811828,0.9914507269859314,0.0,accept,unanimous_agreement
741931612,9601,"what do you mean by ""when the build supports it"". if we enable it by default, it'll search sanitizer errors in the log even redis is built without sanitizer instrumentation. i'm not sure if this is a problem though.(just searchs stderr which is often empty i believe, so i expect it just adds slight performance cost). we can make it default.",0,0,0,0.9699306488037108,0.9711029529571532,0.9878154993057252,0.0,accept,unanimous_agreement
741933227,9601,"this is only required for corrupt_dump tests, so i added here only. anyway, i'll set it by default.",0,0,0,0.9779988527297974,0.9918688535690308,0.9944637417793274,0.0,accept,unanimous_agreement
741937792,9601,"the `--valgrind` argument is mainly to control the execution (`exec valgrind`), and in some places also skip tests that are too slow. here we run a normal redis binary (which was built differently), i don't think we need that flag. the stderr file is normally empty, i think the search in it is no overhead. so i prefer to remove the flag. i may be a bit unhappy about the extra environment variable you add, but i suppose it doesn't do any harm, so all we need is a comment stating what it's for...",0,0,0,0.576887845993042,0.7564534544944763,0.6620182394981384,0.0,accept,unanimous_agreement
741938840,9601,"ok, make it by default and add a comment stating what it's for...",0,0,0,0.974120318889618,0.9859718680381776,0.9949264526367188,0.0,accept,unanimous_agreement
741940148,9601,"ok, we can keep both and maybe drop one later... i guess i'm just trying to save microsoft some cache on cpu time (or care about global warming)",0,0,0,0.5090197324752808,0.957568347454071,0.864683985710144,0.0,accept,unanimous_agreement
741955366,9601,"just to be clear, do you want `./runtest-moduleapi` here or not?",0,0,0,0.9865480065345764,0.993443489074707,0.9943732023239136,0.0,accept,unanimous_agreement
741972586,9601,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
741974132,9601,"ok, got rid of the argument and made it look for sanitizer errors by default",0,0,0,0.9845820069313048,0.9860846400260924,0.991723358631134,0.0,accept,unanimous_agreement
742042430,9601,"sorry i wasn't clear. i meant that i don't think the undefined sanitizer should be executed in the pr ci. i wanted the address sanitizer since it can find memory leaks before they cause failures in the daily ci. but i think the ub sanitizer issues are rarer and we can skip that and rely on the daily ci. regarding module tests, (in the address sanitizer) i do want them. and ideally i would have wanted cluster testss too, but they're just too slow.",-1,-1,-1,0.9859790205955504,0.983827829360962,0.9643219709396362,-1.0,accept,unanimous_agreement
742072710,9601,"okay. removed ubsan from the ci. just fyi, `runtest --tags -slow` takes ~7 minutes. cluster tests are ~13 minutes and sentinel tests are ~2 minutes : [a link] cluster tests can be added as another instance and it would extend ci time by ~6 minutes, just fyi. (don't know if worth it)",0,0,0,0.9106340408325196,0.9397491812705994,0.9558924436569214,0.0,accept,unanimous_agreement
742083226,9601,"i see [a link] that the runtest part takes 5 minutes (with and without sanitizer takes the same time and they run in parallel). if we'll add runtest-cluster and runtest-sentinel, we'll add them on the same build (sequentially), so the ci would take 20 minutes instead of 5. the problem with these cluster and sentinel tests is that they run each of the units sequentially rather than in parallel to each one.. one day someone will have the time to fix that, but for now, i rather leave the ci fast (5 minutes)",0,0,0,0.7501877546310425,0.9807626605033876,0.9167775511741638,0.0,accept,unanimous_agreement
742091710,9601,gotcha,0,0,0,0.8672440648078918,0.9491292238235474,0.749405026435852,0.0,accept,unanimous_agreement
742168628,9601,"hey , this is a potential bug when the value of sentinel_election_timeout is larger than 2147483647. mstime_t is long long [a link] when the value is sentinel_election_timeout is larger than 2147483647 election_timeout is set to sentinel_election_timeout then election_timeout value will be negative. so setting election_timeout to mstime_t makes sense to avoid the potential bug and to be consistent. but i am not sure in what case the value of sentinel_election_timeout will be set to a value larger than 2147483647.",0,0,0,0.660040020942688,0.6409627199172974,0.9595782160758972,0.0,accept,unanimous_agreement
742376966,9601,this bug will cause the failover fail and keep getting delayed indefinitely. if sentinel_election_timeout is larger than 2147483647 then election_timeout will be negative. then the following condition will be true and the failover will be aborted. [a link],0,0,0,0.9309670329093932,0.9494855403900146,0.9705934524536132,0.0,accept,unanimous_agreement
742624450,9601,"according to yossi it'll only happen when the user input is broken, and in that case it'll be immediately visible. so not something to fuss about.",0,0,0,0.8532729148864746,0.8130584955215454,0.9490864872932434,0.0,accept,unanimous_agreement
1565150106,13209,"sun: not sure if just using lpinsertinteger(.., hash_lp_no_ttl, ...) on the old lp would be faster.",0,0,0,0.9351905584335328,0.9866294860839844,0.9172382354736328,0.0,accept,unanimous_agreement
1565150478,13209,"sun: here could be a bottleneck, maybe we can add lpforeach with a callback method and use lpskip to traverse lp internally, it will be much faster than three lpnext().",0,0,0,0.98183274269104,0.9896875023841858,0.990284264087677,0.0,accept,unanimous_agreement
1565150964,13209,please take a look at these changes.,0,0,0,0.9755709767341614,0.963129997253418,0.99114990234375,0.0,accept,unanimous_agreement
1565152288,13209,github got confused and shows a huge diff for my commit here. maybe looking it on git might help. it is better there.,0,-1,-1,0.9031671285629272,0.58094722032547,0.6076554656028748,-1.0,accept,majority_agreement
1568280230,13209,forget to initialize hi->expire_time to eb_expire_time_invalid when hash is hashtable?,0,0,0,0.9378121495246888,0.9942173957824708,0.9862375259399414,0.0,accept,unanimous_agreement
1568302097,13209,ht does not use this field but probably it is better to match behaviors. maybe we should delete `expire_time` variable in the iterator and read value from `hi->tpr` in `hashtypecurrentfromlistpack()` similar to what is happening in `hashtypecurrentfromhashtable()`.,0,0,0,0.9879432320594788,0.9953067898750304,0.988395094871521,0.0,accept,unanimous_agreement
1573085106,13209,"added a comment, hope it is clear",1,0,1,0.6572636365890503,0.7445810437202454,0.815573513507843,1.0,accept,majority_agreement
1574287348,13209,i think should follow similar naming convention between `listpack` and `ht`. maybe you can use `listpcakex` instead. wdyt? we can leave this decision to the end of this pr.,0,0,0,0.985304057598114,0.9935787916183472,0.9904705286026,0.0,accept,unanimous_agreement
1574287929,13209,it is expensive. you can respect `info->maxtoexpire` and provide `nextexpiretime` in the same `while` loop. something like: [code block],0,0,0,0.7073152661323547,0.9813591837882996,0.9039345979690552,0.0,accept,unanimous_agreement
1576887274,13209,why do we need `tptr` in the iterator? i think it is confusing and not being used. `expire_time` is enough.,0,0,0,0.8622854948043823,0.9484981894493104,0.8401064872741699,0.0,accept,unanimous_agreement
1577055923,13209,"done, it is faster, for most cases",0,0,0,0.9633878469467164,0.8850529789924622,0.9870572686195374,0.0,accept,unanimous_agreement
1577536899,13209,no need to have function freehashobject(). we can call directly to hashtypefree(),0,0,0,0.98595529794693,0.9777179956436156,0.9920610189437866,0.0,accept,unanimous_agreement
1577553539,13209,note that most of this logic around upding `db->hexpires` was removed by [a link] (please review it): [code block],0,0,0,0.98826664686203,0.9924949407577516,0.9937611222267152,0.0,accept,unanimous_agreement
1577834509,13209,why not merge both cases? the block of `(o->type == obj_zset && o->encoding == obj_encoding_listpack)` is included in the block of `(o->type == obj_hash &&(o->encoding == obj_encoding_listpack || o->encoding == obj_encoding_listpack_ttl))`,0,0,0,0.9885467290878296,0.9951908588409424,0.9936920404434204,0.0,accept,unanimous_agreement
1577845649,13209,consider use tuple instead of pair.,0,0,0,0.9774322509765624,0.9903548955917358,0.990764856338501,0.0,accept,unanimous_agreement
1577855220,13209,maybe add big values no more than 2^48-1 to mimic ttl,0,0,0,0.9844312071800232,0.9913381338119508,0.9879201650619508,0.0,accept,unanimous_agreement
1578155260,13209,"`tptr` points to last element. so, on `hashtypenext()`, we do `fptr = lpnext(tptr)`. i'll check if i can make it more obvious.",0,0,0,0.9874852299690248,0.991054356098175,0.991259515285492,0.0,accept,unanimous_agreement
1578159133,13209,"just to be inline with others, i think we can keep it as it is. other types have like `freelistobject, freesetobject, freemoduleobject, freestreamobject` etc..",0,0,0,0.9852892756462096,0.9915687441825868,0.9768152236938475,0.0,accept,unanimous_agreement
1578161132,13209,sounds okay to me. are you suggesting it to both `obj_encoding_listpack_ex` and `struct listpackex` ?,0,1,0,0.8918991684913635,0.5690140724182129,0.979462206363678,0.0,accept,majority_agreement
1578168920,13209,"these apis have become a bit awkward. it is returning key, value pairs out of tuples. i feel like calling it lprandomtuple() might be more confusing as it is actually returning pairs.",-1,-1,-1,0.9575164318084716,0.9702613353729248,0.9551052451133728,-1.0,accept,unanimous_agreement
1578195221,13209,"if i recall correctly, it might be sufficient to use `tptr` only as local var.",0,0,0,0.988738179206848,0.9907271862030028,0.9918224215507508,0.0,accept,unanimous_agreement
1578196356,13209,then maybe make it static function only for object.c,0,0,0,0.9795503616333008,0.9916016459465028,0.9923243522644044,0.0,accept,unanimous_agreement
1580728051,13209,i find confusing to mix both zset and hash after introducing expiry. e.g. seeing ttl checks or `expired` variable in obj_zset's case.,0,0,0,0.7986924052238464,0.8210605382919312,0.5213561654090881,0.0,accept,unanimous_agreement
1580734143,13209,"`struct listpackttl` lives in t_hash.c (not exposed). to make `hashtypefree()` static in object.c, we have to expose `struct listpackttl`. i don't have strong opinion on anything anyway. let me know if you prefer one over other.",0,0,0,0.906410276889801,0.9659135937690736,0.9733240604400636,0.0,accept,unanimous_agreement
1582066145,13209,what about just adding new `o->type == obj_hash && o->encoding == obj_encoding_listpack_ttl` and keep the code about hash listpack with zset?,0,0,0,0.9899280667304992,0.994765281677246,0.9940919280052184,0.0,accept,unanimous_agreement
1582070074,13209,we use snake style in redis. [code block],0,0,0,0.9886015057563782,0.9937663078308104,0.9954452514648438,0.0,accept,unanimous_agreement
1582072414,13209,lgtm,0,0,0,0.9795994758605956,0.7242414951324463,0.9618706703186036,0.0,accept,unanimous_agreement
1582075939,13209,"it's better to add `b->hexpires` reference to it, otherwise when defragging the listpack, we can't know which db or db->expires the listpack is belong to.",0,0,0,0.9873456358909608,0.9918700456619264,0.992417335510254,0.0,accept,unanimous_agreement
1582362228,13209,"i copied it but it makes me doubt as well. i see there are bunch of mixed style examples in the unstable branch as well. if the most common is snake case, let's change our code for it. please ack so we can have consistent style for hfe code.",0,-1,0,0.9579042792320251,0.5641492009162903,0.7961560487747192,0.0,accept,majority_agreement
1582363645,13209,okay sure. how do you know it in case of dict?,0,0,0,0.9755799174308776,0.9470969438552856,0.9916455149650574,0.0,accept,unanimous_agreement
1582363806,13209,i'm fine with it as long as we don't mix zset and ttl. i don't have a strong opinion though.,0,0,0,0.5454925298690796,0.7308289408683777,0.8713228702545166,0.0,accept,unanimous_agreement
1582458558,13209,get it from the metadata of dict.,0,0,0,0.987285315990448,0.9909284710884094,0.994848370552063,0.0,accept,unanimous_agreement
1582630581,13209,"sorry, i misunderstood, the hfe ebuckets of the dict is for dict fields, so listpackttl doesn't need it.",-1,-1,-1,0.9827281832695008,0.9873931407928468,0.9867284893989564,-1.0,accept,unanimous_agreement
1585938026,13209,"i added obj_encoding_listpack_ttl case separately, let me know if you have some other preference.",0,0,0,0.9882832765579224,0.9929733276367188,0.992935597896576,0.0,accept,unanimous_agreement
1587056272,13209,most of the lines in this file is no more than 80 chars. please try to avoid exceeding 100 characters in length.,0,0,0,0.9825605750083924,0.9666376113891602,0.9816245436668396,0.0,accept,unanimous_agreement
1587059610,13209,line too long,0,-1,-1,0.5172257423400879,0.5564961433410645,0.5516884922981262,-1.0,accept,majority_agreement
1587104097,13209,internal hash data. i think we can hide this struct in t_hash.c.,0,0,0,0.989260196685791,0.9878876209259032,0.994117021560669,0.0,accept,unanimous_agreement
1587105727,13209,if only used in t_hash.c then let's avoid exposing them.,0,0,0,0.9725215435028076,0.9923770427703856,0.9917230010032654,0.0,accept,unanimous_agreement
1587110529,13209,we can make this function more generic `hashtypeisexpired(uint64_t expiretime)` such that if it is not 0 and not `eb_expire_time_invalid` then check the condition.,0,0,0,0.988827347755432,0.9941973686218262,0.9936413168907166,0.0,accept,unanimous_agreement
1587125914,13209,we already have `min` value in our hands in the loop. let's avoid from calling `hashtypegetnexttimetoexpire`.,0,0,0,0.9753652215003968,0.9934192299842834,0.9933218359947203,0.0,accept,unanimous_agreement
1587145720,13209,"this part is common, applied inside and outside the loop. maybe we can refactor the code such that it will be applied once at the end of the loop.",0,0,0,0.9876149892807008,0.9910473227500916,0.989763617515564,0.0,accept,unanimous_agreement
1587150753,13209,"this part is common, applied inside and outside the loop. maybe we can refactor the code such that it will be applied once at the end of the loop.",0,0,0,0.9876149892807008,0.9910473227500916,0.989763617515564,0.0,accept,unanimous_agreement
1587659370,13209,i understand that you are going to change apis. i will review it afterward.,0,0,0,0.961594820022583,0.9630199670791626,0.9782236218452454,0.0,accept,unanimous_agreement
1589929201,13209,this code was copied from function `hashtypesetexdone()`. please refactor instead and let `hashtypesetexdone()` call this function as well.,0,0,0,0.9885581731796264,0.9919241070747375,0.9944750666618348,0.0,accept,unanimous_agreement
1589933995,13209,please also add a description how expiry metadata will be attached obj_encoding_listpack_ttl.,0,0,0,0.9868446588516236,0.994650423526764,0.9949979782104492,0.0,accept,unanimous_agreement
1589961015,13209,you have function hsetfcheckttlcondition(). see if you can refactor it for this condition.,0,0,0,0.987677276134491,0.9939981698989868,0.994380533695221,0.0,accept,unanimous_agreement
1589961171,13209,make it static function and add braces for if-then-else.,0,0,0,0.9859814643859864,0.9907497763633728,0.9935179948806764,0.0,accept,unanimous_agreement
1589961415,13209,from here and below. please arrange the commands such that the static/local functions at start and the commands are grouped at the end.,0,0,0,0.987143576145172,0.9930614829063416,0.9938058853149414,0.0,accept,unanimous_agreement
1589961525,13209,please make it static.,0,0,0,0.9769480228424072,0.9905677437782288,0.9920552372932434,0.0,accept,unanimous_agreement
1589973640,13209,"is it agreed to return old value even if not override or created it? even if was requested to get new value? if that is the case, then please clarify i with a proper comment.",0,0,0,0.9846648573875428,0.9917458891868592,0.9950782060623168,0.0,accept,unanimous_agreement
1589982139,13209,please write a description to this function.,0,0,0,0.9814240336418152,0.9858396053314208,0.9942063093185424,0.0,accept,unanimous_agreement
1589982979,13209,please write a description to this function.,0,0,0,0.9814240336418152,0.9858396053314208,0.9942063093185424,0.0,accept,unanimous_agreement
1590484877,13209,what about passing ebuckets(db->hexpires) instead of `db`?,0,0,0,0.981295645236969,0.9948699474334716,0.9941766262054444,0.0,accept,unanimous_agreement
1590485675,13209,"can you move this struct into server.h in this pr, i saw that #13243 also added some interfaces for the access of this struct.",0,0,0,0.9856395721435548,0.9864290952682496,0.9955469369888306,0.0,accept,unanimous_agreement
1590554111,13209,it is already in server.h,0,0,0,0.9700492024421692,0.9894362688064576,0.9759584665298462,0.0,accept,unanimous_agreement
1590562258,13209,"sorry, i'm blind.",-1,-1,-1,0.9870399832725524,0.9912856221199036,0.9935247898101808,-1.0,accept,unanimous_agreement
1590693389,13209,"there are minor differences, maybe we should just leave as it is",0,0,0,0.9629002809524536,0.9709039330482484,0.9541200399398804,0.0,accept,unanimous_agreement
1590694360,13209,i changed it silently :roll_eyes:,-1,0,-1,0.9791784286499025,0.5734729170799255,0.9897756576538086,-1.0,accept,majority_agreement
1590820959,13209,"yes, we return whatever exists in the field even if we decide not to override. added the comment",0,0,0,0.9863414168357848,0.9910661578178406,0.9949736595153807,0.0,accept,unanimous_agreement
1590821569,13209,this is needed for defrag,0,0,0,0.9860835671424866,0.987461268901825,0.9955493211746216,0.0,accept,unanimous_agreement
1590834506,13209,i'll address this in a later pr,0,0,0,0.9812949895858764,0.9880776405334472,0.9917516112327576,0.0,accept,unanimous_agreement
1590834589,13209,i'll address this in a later pr,0,0,0,0.9812949895858764,0.9880776405334472,0.9917516112327576,0.0,accept,unanimous_agreement
1590897518,13209,"the schema is incorrect, please have a look #13238.",0,0,0,0.9604032039642334,0.974936842918396,0.9652566313743592,0.0,accept,unanimous_agreement
1590898073,13209,i saw you fixed.,0,0,0,0.966017246246338,0.961967408657074,0.9273377060890198,0.0,accept,unanimous_agreement
1590906493,13209,i'll address this later with some other perf improvements.,0,0,0,0.9856911301612854,0.9831392168998718,0.983346462249756,0.0,accept,unanimous_agreement
1590936853,13209,"i am fine (i try to align to the file i am within. if it is a new file, i prefer camel-case.)",0,0,0,0.8617522120475769,0.833278477191925,0.8677780032157898,0.0,accept,unanimous_agreement
1591729250,13209,this test failed in [a link] 1. we can't guarantee `myhash` doesn't expire between `r hpexpire myhash 200 nx 1 field1` and `r hpexpire myhash 1000 xx 1 field1`. 2. we can't guarantedd `after 15` will not pass more than 100ms.,0,0,0,0.951588213443756,0.990462839603424,0.9757846593856812,0.0,accept,unanimous_agreement
1591864282,13209,might overflow.,0,0,0,0.9278780817985536,0.7669616937637329,0.973594605922699,0.0,accept,unanimous_agreement
1591865365,13209,"please ignore, missed the range check above.",0,0,0,0.8961096405982971,0.9799304008483888,0.9862272143363952,0.0,accept,unanimous_agreement
1591867329,13209,use getrangelongfromobjectorreply()?,0,0,0,0.9883638620376588,0.9935358762741088,0.9954602122306824,0.0,accept,unanimous_agreement
1591878616,13209,maybe we can use `memmove` to move these three entries in the future improvement.,0,0,0,0.9865505695343018,0.9932057857513428,0.9832873344421388,0.0,accept,unanimous_agreement
1591904249,13209,i was thinking about lpbatchinsert() which can be used appending to the tail as well but probably moving is good enough.,0,0,0,0.9569470286369324,0.9598921537399292,0.9899757504463196,0.0,accept,unanimous_agreement
1592429786,13209,i think this comment is not very helpfull. the code speaks for itself.,-1,-1,-1,0.8096548318862915,0.6118099093437195,0.7796414494514465,-1.0,accept,unanimous_agreement
1592439506,13209,maybe when comment of a func becomes too long i think we should give general title to the function and destinct it with empty line from the rest of the description. something like: [code block],0,0,0,0.9744550585746764,0.977590262889862,0.98333078622818,0.0,accept,unanimous_agreement
1592448597,13209,", you resolved it but i think that the logic hasn't changed.",0,0,0,0.9690403342247008,0.975039839744568,0.9721267223358154,0.0,accept,unanimous_agreement
1592461257,13209,forgot that now items are ordered.,0,0,0,0.6621410250663757,0.9779818654060364,0.8500362038612366,0.0,accept,unanimous_agreement
1592487343,13209,lines are too long,-1,-1,-1,0.646780252456665,0.5274685621261597,0.7529681324958801,-1.0,accept,unanimous_agreement
1592884097,13209,"you need to add here also a case for obj_encoding_listpack_ex to release it as expected. note, in case obj_encoding_ht it handles hash-fields with optional ttl inherently by callbacks of mstrhashdicttype which knows how to release items from hash's private `ebuckets`.",0,0,0,0.9895601272583008,0.9949199557304382,0.9951359629631042,0.0,accept,unanimous_agreement
1593013086,13209,this is common code. refactor it to be before if-then-else.,0,0,0,0.9879321455955504,0.9805817008018494,0.9929798245429992,0.0,accept,unanimous_agreement
1593015190,13209,nice,1,1,1,0.8361793160438538,0.9342552423477172,0.7884483337402344,1.0,accept,unanimous_agreement
1593082011,13209,if there are short if-then-elif-else conditions and one long then better get rid of the short ones at start and apply the long one out of if block.,0,0,0,0.9843780398368835,0.98932284116745,0.9868213534355164,0.0,accept,unanimous_agreement
1593253503,13209,added,0,0,0,0.973513960838318,0.9267084002494812,0.8435775637626648,0.0,accept,unanimous_agreement
1593260862,13209,88 columns is not too long. [code block],0,0,0,0.9780557155609132,0.9883952140808104,0.9876353144645692,0.0,accept,unanimous_agreement
1593261347,13209,what about moving this into object.c?,0,0,0,0.9882445335388184,0.9919791221618652,0.9946995973587036,0.0,accept,unanimous_agreement
1593262170,13209,what about changing to assertion and move into `else`?,0,0,0,0.9808822274208068,0.9911623001098632,0.9931026697158812,0.0,accept,unanimous_agreement
1593340631,13209,"we should make sure that hsetfsetfieldandreply() takes with a reply, but not here. if it doesn't enter, i think it can be changed to the following. [code block]",0,0,0,0.9875503182411194,0.992523729801178,0.9938634634017944,0.0,accept,unanimous_agreement
1593364373,13209,"if updated is 0, we should check if hashobj is empty and delete it to avoid create a empty hash.",0,0,0,0.9867103695869446,0.991841435432434,0.9938884377479552,0.0,accept,unanimous_agreement
1593385850,13209,"what i missed here is that there are flows that might release a hash-fields with ttls not in the path of `dbgenericdelete()` and in turn an invalid item will be leftover dangling in global hfe ds. the following sequenece of commands is such example that release a hash and avoid calling `dbgenericdelete()`: * hset mykey f v * hexpire mykey 1 1 f * set mykey f i tried to avoid adding `dbid` into listpackex or dictexpiremetadata and placed a hook in `dbgenericdelete()` instead. but looks like we cannot escape it. we can fix it on a distinct ticket for hash and listpack, add `dbid` to metadata and add the logic here.",-1,0,0,0.5860314965248108,0.9921813011169434,0.9877721071243286,0.0,accept,majority_agreement
1593598176,13209,moving this above needs a new check as well. let's keep it this way. just a few lines of code duplication.,0,0,0,0.9832936525344848,0.952049732208252,0.9924873113632202,0.0,accept,unanimous_agreement
1593601982,13209,"not sure i understand. for listpack, there is no private ebuckets. is this related about deleting object without deleting it from global ebuckets?",0,0,0,0.9729450941085817,0.9407753944396972,0.8111783862113953,0.0,accept,unanimous_agreement
1593618853,13209,i know that. i just try to say that you don't see here any footprint of hfe is because it is hidden in the call dictrelease(). you do need to release object obj_encoding_listpack_ex.,0,0,0,0.9857124090194702,0.9598326086997986,0.9934440851211548,0.0,accept,unanimous_agreement
1593635833,13209,"i'll wrap it for now but i think this is something we can not / should not do in the long run. we don't have a rule, so impossible to say whether a line is too long or not.",0,0,0,0.8108472228050232,0.7265031337738037,0.5781788229942322,0.0,accept,unanimous_agreement
1593638992,13209,i try to do it that way for the new ones.,0,0,0,0.9392945766448976,0.9838221669197084,0.9832388162612916,0.0,accept,unanimous_agreement
1593641598,13209,"just a suggestion (again, try to align to the file convention...)",0,0,0,0.9833803176879884,0.9878126978874208,0.9908382296562196,0.0,accept,unanimous_agreement
1593641649,13209,"in general yes, i agree but here, i kept it similar to hashtypeconvertlistpack(). easier to compare with it.",0,0,0,0.9558345675468444,0.9797915816307068,0.9813678860664368,0.0,accept,unanimous_agreement
1593706797,13209,but hashtypefree() releases obj_encoding_listpack_ex as well.,0,0,0,0.9897304773330688,0.9933417439460754,0.9941932559013368,0.0,accept,unanimous_agreement
1593710130,13209,good catch. looks like we don't have a test case doing something similar.,1,1,1,0.974299430847168,0.9616103768348694,0.976478099822998,1.0,accept,unanimous_agreement
1593710543,13209,my mistake. i was looking on obsolete code.,-1,-1,-1,0.977801501750946,0.9609501957893372,0.9801244735717772,-1.0,accept,unanimous_agreement
1593712366,13209,as part of the fix we can add the test as well.,0,0,0,0.9891274571418762,0.9871250987052916,0.9936063289642334,0.0,accept,unanimous_agreement
1593719928,13209,"added assert to verify type. also, changed where we return. hope it is clear.",1,0,0,0.7590954899787903,0.7198529243469238,0.5384100079536438,0.0,accept,majority_agreement
1593746354,13209,"so the question is how do we handle it: - we create the object as dc (don't create) flag is not provided. - hsetf does not set any field - we delete the empty object in this case, we'll be sending notifications for empty object.",0,0,0,0.982855498790741,0.9892596006393432,0.9940261840820312,0.0,accept,unanimous_agreement
1593785412,13209,"ping , in this case, we will send two notifications(new, del), do you have any advices?",0,0,0,0.9857597947120668,0.9804375767707824,0.9940106272697448,0.0,accept,unanimous_agreement
1593829304,13209,let's handle that in a follow up pr,0,0,0,0.979684352874756,0.9893460869789124,0.9921876192092896,0.0,accept,unanimous_agreement
1593909159,13209,[code block] added this early check to avoid creation of the object. a bit ugly but no way around it.,-1,-1,-1,0.8984430432319641,0.9698299169540404,0.9720669388771056,-1.0,accept,unanimous_agreement
1593926804,13209,"i would prefer to send 2 notifications, which is pretty rare, unless someone intentionally sends error command.",0,0,0,0.921566903591156,0.9410777688026428,0.9590489864349364,0.0,accept,unanimous_agreement
1593997046,13209,"i don't have a strong opinion but pinged oran and he also asked if we can do an early check to avoid it. well, maybe this early check is not worth it. not sure.",-1,-1,-1,0.7830812335014343,0.851643979549408,0.8167673945426941,-1.0,accept,unanimous_agreement
1594056765,13209,"not sure the following sulution is avaliable, since we might need to update the fields ebuckets and db->hexpires. btw: should we update db->hexpires ebuckets after dbdelete()? [code block]",0,0,0,0.9844196438789368,0.9863741397857666,0.9594058394432068,0.0,accept,unanimous_agreement
1594088834,13209,"to do this, we also need to do `attachhfemeta()` lazily. inside of it, we use the key reference in dict. it becomes more complicated imho. also, it will be different than other commands, it feel like it might be confusing. hope i understand this question correctly, if `hashtypelength(hashobj, 0) == 0` then, object is not part of db->hexpires. so, dbdelete() should be safe.",0,0,-1,0.6487852334976196,0.9308990836143494,0.9665969610214232,0.0,accept,majority_agreement
1594150160,13209,"alternatively, we can add dcf check next to dc and return null rather than replying to all fields. [code block] edit: interpreting description again i think this is what we should do. see the last commit please. would you consider it better than the previous one?",0,0,0,0.9822683334350586,0.9841741323471068,0.9930766820907592,0.0,accept,unanimous_agreement
1594221280,13209,"yeah, i like it.",1,1,1,0.9514922499656676,0.8330575823783875,0.957651436328888,1.0,accept,unanimous_agreement
1602569422,13209,"ref [a link] this assertiong will never be triggered. you passed null to the second parameter of `lpgetvalue()`, if the field is string, it will crash in `*slen = ele_len;`. [code block] crash log: [code block] what about adding a new method like `int lpgetinteger(unsigned char *lp, long long *lval)`, return 1 if it's a integer.",0,0,0,0.9832772016525269,0.99273419380188,0.9906660914421082,0.0,accept,unanimous_agreement
1602684226,13209,"how did you trigger this crash? edit: ok, i see with corrupt restore, it is possible. `lpgetinteger()` sounds good.",1,0,0,0.7927514314651489,0.8032155632972717,0.9521495699882508,0.0,accept,majority_agreement
1602751912,13209,[a link] it's easy to reproduce the corrupt by using the patch. then run `./runtest --single integration/corrupt-dump-fuzzer --accurate`,0,0,0,0.984932005405426,0.9899654388427734,0.9940925240516664,0.0,accept,unanimous_agreement
1204213214,12209,"there's a reason all the filtering (pattern matching, expiry, etc), is done after fetching all the keys. with this change, the loop that's suppose to stop at `count` can take very long time if it doesn't find anything. it'll possibly return better results to the caller, but at a latency cost. if we wanna move the filtering to the scan callback, we must also increment some counter so that we can stop the loop after the right amount of keys found, not ones collected.",0,0,0,0.9804598689079284,0.9783740043640136,0.9812016487121582,0.0,accept,unanimous_agreement
1204220483,12209,"note that another side effect of this change is that we don't attempt to expire keys that didn't match the type (or pattern). i.e. both lookupkeyreadwithflags and expireifneeded below will do that. but we don't want to do that from within the scan callback. some people use scan in order to force expiration on keys, but i suppose they won't use any filters, so that's probably ok.",0,0,0,0.978335976600647,0.9900734424591064,0.9775617718696594,0.0,accept,unanimous_agreement
1204225164,12209,"ohh, i see you added a test (to validate that the matched ones do get expired). we'll, we'll also need to document the behaviour change about the non-matched ones, in the pr top comment, so that we mention that in the release notes.",0,0,0,0.975103199481964,0.9787719249725342,0.9889278411865234,0.0,accept,unanimous_agreement
1204230218,12209,"and if we do that, let's move the pattern matching too.",0,0,0,0.9842893481254578,0.990961253643036,0.994191348552704,0.0,accept,unanimous_agreement
1209006159,12209,"sorry, i don't get your concerns, please correct me if i'm wrong. the loop will stop at 'maxiterations' no matter the count of keys collected, so it will not hang a long time. [a link] or do you mean that as the number of filter conditions increases, the probability of reaching maxiterations will increase, resulting in a longer time-consuming execution of a single command? when scan command specify the type or match string, we can reduce the value of maxiterations, for example maxiterations = count * 5, but i doubt it's really worth it.",-1,-1,-1,0.9715803265571594,0.978753924369812,0.9818057417869568,-1.0,accept,unanimous_agreement
1209282841,12209,"yes, it will have the side effect. i think it would be better to expire the keys only when matched, whether it is match pettern or match type. and the current strategy is very confusing: if pattern not mached, the key will not attempt to expire, while when type not mached, the key still attempt to expire.",0,-1,0,0.5944374799728394,0.7127549648284912,0.8095092177391052,0.0,accept,majority_agreement
1209284545,12209,agree and i will try it.,0,0,0,0.9232560992240906,0.9770053625106812,0.975600004196167,0.0,accept,unanimous_agreement
1209323793,12209,"the `maxiteration` limit is there in case we're working on an empty dict, one with a lot of empty buckets. e.g. users sometimes use scan+del, and then when they re-start scan from 0, all the initial buckets are empty. but count currently means to stop after that number of keys have been found (not necessarily matched), and if this pr is an efficiency optimization, i don't think we should affect that (i.e. and increase the likelihood we'll hit the `maxiterations` limit. instead, i think we need to add an `unsigned long sampled` member to `scandata`, increment it inside the scan callback, and then check that the loop instead of checking `listlength(keys)`",0,0,0,0.9673648476600648,0.9836822152137756,0.990040361881256,0.0,accept,unanimous_agreement
1209327896,12209,i agree. just saying we must clearly document the behavior change in the top comment and release notes.,0,0,0,0.9495567083358764,0.7352624535560608,0.9562507271766664,0.0,accept,unanimous_agreement
1209955767,12209,"oh, forgive my stupidity, i finally got what you mean through performance testing...the slowlog shows that when all keys cannot be matched, the scan command of this pr is 5 times slower than the unstable. thank you very much for your review, which is very very useful!",1,1,1,0.9869215488433838,0.9729174375534058,0.9886904954910278,1.0,accept,unanimous_agreement
1210046909,12209,"on the ather hand, it scanned ten times the number of keys, while only taking 5 times slower, the performance has been improved by 100% :-)",1,1,1,0.8825181126594543,0.9931529760360718,0.9883081316947936,1.0,accept,unanimous_agreement
1217896633,12209,"not sure the assert is right. now it is true if one of them is not null, but as the comment, it should be `serverassert(!o || data->typename)`",0,0,0,0.9791529774665833,0.9874966144561768,0.8180931210517883,0.0,accept,unanimous_agreement
1218041864,12209,"sorry, my comment did not explain clearly what i really want to express: o and typename cannot have meaningful values at the same time",-1,-1,-1,0.989316999912262,0.9875078797340392,0.9951490759849548,-1.0,accept,unanimous_agreement
1218042675,12209,thank you,1,1,1,0.7400884628295898,0.6702879667282104,0.9420937299728394,1.0,accept,unanimous_agreement
1218795418,12209,"if so, it should be `serverassert(!(o && data->typename))`.",0,0,0,0.9876973032951356,0.9940046668052672,0.9945705533027648,0.0,accept,unanimous_agreement
1221457906,12209,"i think `!data->typename || !o` and `!(o && data->typename)` are the same statement,does i miss something?but the `!(o && data->typename)` is easier to understand, i prefer to use your sentence.",0,0,0,0.6861768364906311,0.9799055457115172,0.9862841367721558,0.0,accept,unanimous_agreement
1222398270,12209,"ohh, yes, they are the same.",0,0,0,0.8949995636940002,0.9310801029205322,0.9517636895179749,0.0,accept,unanimous_agreement
1223979632,12209,"i have copied your code, thank you",1,1,1,0.9117918610572816,0.97699773311615,0.9274933934211732,1.0,accept,unanimous_agreement
1225832099,12209,"i suppose it's much better to translate the type to an integer and then match the time, rather than do string compare per key. anything i'm missing? p.s. if that's right, let's match the time before the patter (possibly saving some effort)",0,0,0,0.9814580082893372,0.9556174874305724,0.9858960509300232,0.0,accept,unanimous_agreement
1225832961,12209,"let's change this list to contain sds, rather than robj. in the distant past (iirc before v3.2), we used to add robj to the output buffer list, so it'll reference these, but these days we just copy the bytes from the sds to the output buffer, and dispose it. i.e. there's no advantage in creating that robj, just an extra allocation.",0,0,0,0.9844698905944824,0.9911540150642396,0.9923450350761414,0.0,accept,unanimous_agreement
1226177300,12209,"agree, i will try it and retest the improvement result",0,0,0,0.9520428776741028,0.9755586981773376,0.9719977378845216,0.0,accept,unanimous_agreement
1233370729,12209,why is this one still creating a string object?,0,0,0,0.9345751404762268,0.945609211921692,0.9901167750358582,0.0,accept,unanimous_agreement
1233371609,12209,"are we sure this will never return values in the range of 0 to 7, or llong_max? that's a 54 bit number, so negating it seems safe, just making sure..",0,0,0,0.97803395986557,0.9585999846458436,0.9833516478538512,0.0,accept,unanimous_agreement
1233373496,12209,"let's add another key of a different type, so that the filtering is effective. also, please check if the type command has a test already, and if not, maybe add an assertion below.",0,0,0,0.9874876737594604,0.9934939742088318,0.9949766397476196,0.0,accept,unanimous_agreement
1233373737,12209,"any reason to handle this error separately from the one below? i see this one isn't tested or documented in the top comment, but can't we just drop it?",0,0,0,0.9799663424491882,0.977152943611145,0.9816017746925354,0.0,accept,unanimous_agreement
1233374332,12209,"is that for the expireifneeded call? if so, how about this: [code block]",0,0,0,0.98691725730896,0.9930277466773988,0.9953279495239258,0.0,accept,unanimous_agreement
1233472778,12209,"so, it means that if the key have been expired, we need copy the key string twice. but considering that the percentage of stale keys is usually small, i think this is a good compromise. thanks for your wonderful comment!",1,1,1,0.9909238219261168,0.9943814873695374,0.9961050748825072,1.0,accept,unanimous_agreement
1233481227,12209,"yes, although long long type size is platform-dependent, but guaranteed by the c standard (iso c99) to be at least 64 bits, so we don't need to worry about it",0,0,0,0.9709075093269348,0.9845436215400696,0.9899170994758606,0.0,accept,unanimous_agreement
1233491469,12209,it will return 5 if `name` is '\0' or `\0xxxx`. perhaps `obj_type_name` can be changed to [code block],0,0,0,0.9889609217643738,0.9952219128608704,0.9947667121887208,0.0,accept,unanimous_agreement
1233546039,12209,"seems that i commented on the wrong thread. this was meant for [a link] i.e. the reason we create a string object was for expiry test, so we have a better solution. while on that subject, maybe we can even avoid sdsdup? it would be harder for the other key types (hscan, sscan, zscan), but at least for normal keyspace scan we can easily avoid copying the string. it'll be a little bit ugly, but i think the performance boost is worth it, if we add a few comments to clear that up. anyway, back to the original purpose of this thread: i see this one isn't tested or documented in the top comment, but can't we just drop it?",0,0,1,0.7018237113952637,0.7706369161605835,0.6002029180526733,0.0,accept,majority_agreement
1233791202,12209,"[code block] on the other hand, `default: type = ""unknown""; break;` is dead code in the origin code, maybe we can change it to `assert` instead.",0,0,0,0.985287308692932,0.9937219023704528,0.9921332001686096,0.0,accept,unanimous_agreement
1233926920,12209,"because i use a special empty string in the `obj_type_name` array to represent the module type to prevent the wrong type from matching with the module. this is indeed a bit ugly, i will move the judgment to the getobjecttypebyname function, return the empty string as an unknown type (llong_max), wdyt",-1,-1,-1,0.8298070430755615,0.8360555768013,0.9845853447914124,-1.0,accept,unanimous_agreement
1233937694,12209,"but null pointer can not be used in strcasecmp funtion. i think your question is same with oranagra's [a link] , i prefer to compare strings ahead of time if they are empty in `getobjecttypebyname` [code block]",0,0,0,0.9843594431877136,0.9926243424415588,0.994848608970642,0.0,accept,unanimous_agreement
1233941513,12209,"agree, it does look like dead code.",0,-1,0,0.9741223454475404,0.6211612224578857,0.8943538665771484,0.0,accept,majority_agreement
1234035535,12209,sounds good. then we'll just get the plain `unknown type name` error.,1,0,0,0.8430721759796143,0.8195940852165222,0.9201565384864808,0.0,accept,majority_agreement
1234046267,12209,don't forget about the suggestion to avoid sdsdup which i mistakenly posted in the wrong thread: [a link],0,0,0,0.974067747592926,0.887039840221405,0.9839192032814026,0.0,accept,unanimous_agreement
1234058357,12209,"yes, i think hash/set type with the ht encoding also could easily avoid sdsdup easily, i'm trying",0,0,0,0.9641574025154114,0.9850024580955504,0.9920794367790222,0.0,accept,unanimous_agreement
1234801628,12209,"maybe instead of duping this one, we can have zset release only the values, and not the keys? not sure if it's worth the trouble, have a look and decide.",0,0,0,0.918945610523224,0.937976598739624,0.8609724044799805,0.0,accept,unanimous_agreement
1234830417,12209,looks like i'm blind for white space issues recently :smile:,1,1,1,0.9254170060157776,0.9863035082817078,0.9932282567024232,1.0,accept,unanimous_agreement
1235024532,12209,"`moduletypelookupmodulebyname` is using `memcmp`, so moduletype's name is case-sensitive. but currently `strcasecmp` is used for comparing typename, which may cause a breaking change. in theory, this should be considered a bugfix because different case means a different moduletype, and this situation is also very rare, so it is not a breaking change in practical.",0,0,0,0.9373024106025696,0.9892674088478088,0.9873615503311156,0.0,accept,unanimous_agreement
1235060152,12209,"good catch! considering the other type filters are case insensitive, i think we should have this one case insensitive too. for consistency. besides, it's easier for users to use (having two modules with similar names is probably just a theoretic case). and also, let's avoid a breaking change if we didn't mean for it and we can avoid it. bottom line, let's add a boolean argument for moduletypelookupmodulebyname to be case insensitive.",1,1,1,0.9700356125831604,0.9512715339660645,0.9930549263954164,1.0,accept,unanimous_agreement
1235189883,12209,"i think both of these cases are handled now since we use `strlen` (not `sdslen`), which means that even `\0xxxx` will exit this function early. do you still see a problem? p.s. maybe it's a good idea to use `null` as you suggested too, and add explicit code to avoid using it when null (before calling `strcasecmp`).",0,0,0,0.984411358833313,0.9857147336006165,0.9737333059310912,0.0,accept,unanimous_agreement
1235273896,12209,it's ok now. i prefer using null too.,0,0,0,0.9018608331680298,0.7757344841957092,0.6292132139205933,0.0,accept,unanimous_agreement
1235386263,12209,"cool! :thumbs_up: agree. it's better to be consistent for users, and having two modules with similar name is rarer than input case insensitivity when scanning module type. but this is still a breaking change for docs , that means we definitely not support case sensitive scan for module type, and the same needs to be stated in the module's documentation. should we be more careful to make decision?",1,1,1,0.985042929649353,0.993998885154724,0.9963746666908264,1.0,accept,unanimous_agreement
1235388049,12209,it's seems that my clang-format break down again :-(,-1,-1,-1,0.9915253520011902,0.988512635231018,0.9964535236358644,-1.0,accept,unanimous_agreement
1235401468,12209,"ooh, i get you point. null is indeed better than a weird empty string. i'll do it tomorrow. thank you, i like the advice, guys.",1,1,1,0.985542058944702,0.94387948513031,0.9775855541229248,1.0,accept,unanimous_agreement
1235405338,12209,i could try it out but it feels a bit hard and code might get a bit ugly.,-1,-1,-1,0.9598178267478944,0.9316874146461488,0.8055585026741028,-1.0,accept,unanimous_agreement
1235588322,12209,"not sure what you mean. do we agree that we should avoid the breaking change? and you argue that in addition to that we should document that it ignores case for modules? i'd rather not document that, and have the opportunity to break it on the next major release so it's consistent with other types.",0,0,0,0.9294310808181764,0.8144411444664001,0.6136180758476257,0.0,accept,unanimous_agreement
1236247377,12209,"your understanding is completely correct, i will follow your point.",0,0,1,0.9310778975486756,0.8988709449768066,0.9273650646209716,0.0,accept,majority_agreement
1241082846,12209,"in order to ensure that static robj is supported in lookupkey, i added the nonotify flag here to avoid modifying the notifykeyspaceevent function. i think the `keymiss` notification generated by the scan command is completely unnecessary. but i am not sure whether it will also be a breaking change.",0,0,0,0.7311996817588806,0.9865584969520568,0.9735057950019836,0.0,accept,unanimous_agreement
1241097856,12209,"i agree.. in theory this should have been a `lookup_noeffects`, or actually just a plain dictfind, but currently we do want the expiration side effect. regarding the `keymiss` notification, if scan would ever send them, that would be a bug (badly affecting whoever is using relies on this notification), and in such case i would document that in the release notes as a bug fix. but in fact, these should always be hits (never misses), so i don't think that bug exists. what you did is ok, and it's a good idea to keep nonotify just to be on the safe side.",0,1,1,0.8589117527008057,0.7200583815574646,0.9387531280517578,1.0,accept,majority_agreement
1241098787,12209,"we haven't solved the case-insensitive compare issue yet, right?",0,0,0,0.9501415491104126,0.9836265444755554,0.9800407886505128,0.0,accept,unanimous_agreement
1241099692,12209,maybe we should even clearly mark these with [code block] and [code block],0,0,0,0.9835167527198792,0.9938831329345704,0.9818461537361144,0.0,accept,unanimous_agreement
1241100614,12209,that var is no longer needed again.,0,0,0,0.9329453706741332,0.9837337136268616,0.992834210395813,0.0,accept,unanimous_agreement
1241101428,12209,"maybe we can add a `continue`, instead of `else`, so that when this code is removed we don't need to de-indent the call to `expireifneeded`",0,0,0,0.9881873726844788,0.994671642780304,0.9859187602996826,0.0,accept,unanimous_agreement
1241101892,12209,let's add a `todo: remove this in 8.0`,0,0,0,0.9870294332504272,0.9924517273902892,0.9946367144584656,0.0,accept,unanimous_agreement
1241102506,12209,let's add ```tcl # todo: uncomment in 8.0,0,0,0,0.9871010780334472,0.9908370971679688,0.9945747256278992,0.0,accept,unanimous_agreement
1241777565,12209,what about `ignore_case`?,0,0,0,0.9800570011138916,0.991462767124176,0.990653932094574,0.0,accept,unanimous_agreement
1241841875,12209,"hi, i just added a space and didn't put brace to the new line, not sure if my coding style is right.",0,0,0,0.9662312269210817,0.897831380367279,0.876599907875061,0.0,accept,unanimous_agreement
1241843667,12209,"yes, i just updated",0,0,0,0.9871852993965148,0.9615779519081116,0.9915522933006288,0.0,accept,unanimous_agreement
1241849619,12209,"because there are multiple lines in the `if`, redis style recommends to put the brace on a single line.",0,0,0,0.986928403377533,0.9933797121047974,0.9921591281890868,0.0,accept,unanimous_agreement
1241866407,12209,"i think it is still needed, because we must use it as a flag that if there is a type filter in redis7.2. and i deleted the local repeated `typename` just now, so we also no need to delete this line in redis 8.",0,0,0,0.9872695207595824,0.9892288446426392,0.9884103536605836,0.0,accept,unanimous_agreement
1241871431,12209,"thank you for your detailed answer, i will follow the style",1,1,1,0.9037436246871948,0.8731185793876648,0.9629027843475342,1.0,accept,unanimous_agreement
1241957482,12209,"i might be missing something, but i don't see this new function being used anywhere. don't you need to use it in getobjecttypebyname? or maybe better, let scangenericcommand pass an `ignore_case` argument to it, and make it more explicit. let's add a simple test for this (would have uncovered this oversight which we almost missed twice, and protect future changes from breaking it).",0,0,0,0.9762819409370422,0.9806504845619202,0.9685775637626648,0.0,accept,unanimous_agreement
1241965760,12209,can't we use `type != llong_max` like we planed to use for 8.0 (and move that var to the inner scope)?,0,0,0,0.9881568551063538,0.9957148432731628,0.9921809434890748,0.0,accept,unanimous_agreement
1242012286,12209,"please correct me if i'm wrong, if specificated type filter is unkown in redis7.2, which means `type` is equal llong_max, we still need continue to scan the full key space and execute `lookupkey` for these keys. but in redis8.0, we will will reply a error immediately for the unkown type filter, `type != llong_max` is just means there is no type filter in scan command.",0,0,0,0.9782694578170776,0.9581380486488342,0.951015293598175,0.0,accept,unanimous_agreement
1242033271,12209,"sorry, i was distracted and caused this careless question. i found it difficult to avoid string comparisons in redis7.2, using numeric comparisons still cause a breaking change. such as tow module types,""a12345678"" and ""a12345678"", in the past server would return all keys belonging both ""a12345678"" and ""a12345678"", but now if we use interger compareison, the server only return the keys belonging either ""a12345678"" or ""a12345678"".",-1,-1,-1,0.9838358163833618,0.9823067784309388,0.9855910539627076,-1.0,accept,unanimous_agreement
1242077745,12209,"ohh, right. please add a test to cover that.",0,0,0,0.9546794295310974,0.935993194580078,0.9748522043228148,0.0,accept,unanimous_agreement
1242082958,12209,"you mean if there are two modules with the same name (and only character case difference)? i think we can overlook this (i don't think there's such a case in reality). what's important imo is that if a module is named ""abcd12345"" we can find it with ""abcd12345"" and ""abcd12345"" too. so i think we can keep the integer compare, as long as we look it up with ignore_case.",0,0,0,0.9757674336433412,0.9755254983901978,0.9862666130065918,0.0,accept,unanimous_agreement
1242086643,12209,"i'm also confused by your last comment. if you wanted to cover that case that i'm willing to give up, you should have kept the string compare, but looking at the code i see you still do integer compare... so either way, let's add a test to cover this (without one module and several searches, not with two modules with similar name). side note: i'm also willing to bring back the string compare for 7.2 and replace it in 8.0, but it seems to me that with small effort we can keep the integer compare too.",-1,-1,0,0.5107483267784119,0.6949842572212219,0.6675670742988586,-1.0,accept,majority_agreement
1242113381,12209,i don't think we'll want to remove it. it breaks backwards compatibility and we don't gain anything. let's drop the comment.,0,-1,0,0.7937820553779602,0.5373576283454895,0.9102429747581482,0.0,accept,majority_agreement
1242114855,12209,and also the comments in the test.,0,0,0,0.9857710599899292,0.9866082668304444,0.9935455918312072,0.0,accept,unanimous_agreement
1242115379,12209,"i add a test case using a case insensitive scan for the module type, not sure if it is what you wanted",0,0,0,0.9773666262626648,0.9738367199897766,0.9873088002204896,0.0,accept,unanimous_agreement
1242118228,12209,"when reading this test, i don't recall the case with which the module registers the type. i originally thought that we'll search both ""test___dt"" and ""test___dt"" and match the results. but maybe using an odd ""test___dt"" will prove the point and be clearer?",0,0,0,0.9792446494102478,0.9802483916282654,0.9780224561691284,0.0,accept,unanimous_agreement
1242280811,12209,"i added a test case in `scan unknown type` for current version, and coverd the impact on expired keys",0,0,0,0.9893386363983154,0.993399143218994,0.9949625730514526,0.0,accept,unanimous_agreement
1243523115,12209,"for this remaining problem, i have a preliminary idea, hoping to add an addreplybulkdouble to directly output double‘s strings, avoiding malloc/free, and i hope the function can be used in other places, not sure if it is feasible.",0,0,0,0.959479033946991,0.9528090357780457,0.9764209389686584,0.0,accept,unanimous_agreement
1243731934,12209,"i find we have had a `addreplydouble` function in networking.c. while it maybe use the resp3 format to output, i think it can be used here.",0,0,0,0.9851210117340088,0.9933632612228394,0.9890965819358826,0.0,accept,unanimous_agreement
761911531,9890,this block is irrelevant because we never propagate anything before exec is completely done,0,0,0,0.920681357383728,0.9650469422340392,0.9768868088722228,0.0,accept,unanimous_agreement
762581587,9890,can you describe in which case we reach here with -1?,0,0,0,0.986639142036438,0.9901217818260192,0.9945909976959229,0.0,accept,unanimous_agreement
762582972,9890,"how many calls to the old `propagate` remain in the code? maybe we should rename it, so that if there's an old pr, or some fork with extra calls, it'll not compile.",0,0,0,0.983847200870514,0.9901419281959534,0.9821922183036804,0.0,accept,unanimous_agreement
762583787,9890,"we now have `aftercommand` that's called in both `call` and also (nearly) each of the above `if-else` cases. maybe the better approach is to do that there. note, that i suppose that it's logically **incorrect** to pack this whole loop in a single muli-exec, am i right? we may need to also introduce a `beforecommand`, or maybe alternatively change the default value of `server.core_propagates`, and have the module sybsystem do that hacky part of changing the state?",0,0,0,0.9543550610542296,0.956290364265442,0.9824578166007996,0.0,accept,unanimous_agreement
762584196,9890,"we're not in cron here (we may be in a timer, or inside processcommand). am i missing anything?",0,0,0,0.9482983350753784,0.98691725730896,0.986869752407074,0.0,accept,unanimous_agreement
762585230,9890,"not sure i understand that comment. ""take care of their own propagation"" is true anyway, since they don't mess with `server.dirty`. but here you're discussing the flushing of the pending commands, right? so let's rephrase. anyway, you're saying that modules will flush their own pending commands if if that's happening from a timer, even even when coming from `call`? why not let `call` do the flushing when we come from there too? seems cleaner and more intuitive. i.e. let `call` and ""execcommand"" do what they always do, and let the modules take care only of the odd cases.",0,0,0,0.8119710087776184,0.9776645302772522,0.634658694267273,0.0,accept,unanimous_agreement
762585459,9890,"if we wanna rely on this method, maybe eliminate redismodule_ctx_init, so it won't be used by mistake? also, there's performance regression in this change, maybe pass the context pointer as an argument rather than return a huge struct?",0,0,0,0.9864040613174438,0.993749499320984,0.9850173592567444,0.0,accept,unanimous_agreement
762588099,9890,"so whatever we added to the propagation queue as a master is discarded, right? do we have a test for it?",0,0,0,0.98455148935318,0.9927853345870972,0.992708146572113,0.0,accept,unanimous_agreement
762603278,9890,let's just leave an unused placeholder instead of messing the blamelog,0,0,0,0.969535231590271,0.9668788313865662,0.984924614429474,0.0,accept,unanimous_agreement
762604139,9890,"i'll hijack this block to start an unrelated discussion this pr could in theory have some performance implications. in the past, propagate would just write directly into the client output buffers, but now it is appended to a list and then copied to the output buffer. in practice, since propagate always took an argv array, and the output buffers are always (in recent years) plain byte buffers, i suppose there's no effect. i.e. either the robj items in the argv array are just a reference to the argv from networking.c, or they where created just for the call to propagate, they where copied anyway. and this doesn't really change with this pr, right?",0,0,0,0.9778175950050354,0.9874469637870787,0.9703155755996704,0.0,accept,unanimous_agreement
762604742,9890,"as i noted elsewhere, i feel there's a better way, to let modules commands that are just executed from networking to be propagated here too. maybe i'm missing something.",0,0,0,0.7175890207290649,0.9650132060050964,0.9723747372627258,0.0,accept,unanimous_agreement
762606013,9890,"maybe more important to test a timer that runs two commands, and gets wrapped in multi-exec. i.e. it's not that bad if a single command will be wrapped in mult-exec, but it is quite bad if multiple commands are not.",0,0,0,0.8734692335128784,0.7284368872642517,0.9345459938049316,0.0,accept,unanimous_agreement
762606619,9890,"i don't think we need the `wait_for_ofs_sync` here.. we're using a fake replica, that we don't check anyway.",0,0,0,0.9558904767036438,0.9619722962379456,0.9823268055915833,0.0,accept,unanimous_agreement
762606910,9890,"isn't it a bit wrong for the select to be inside the multi? that multi is probably always executed, so it may not matter much, but still feels wrong.",-1,0,-1,0.8455466032028198,0.733248770236969,0.8485056161880493,-1.0,accept,majority_agreement
762606946,9890,what are these two notifications? i expected only one.. what am i missing?,0,0,0,0.6232142448425293,0.8365827798843384,0.8506360650062561,0.0,accept,unanimous_agreement
762607216,9890,maybe the module should notice it is running in a replica and avoid that propagation?,0,0,0,0.9789156317710876,0.9906798005104064,0.9846447110176086,0.0,accept,unanimous_agreement
762607443,9890,"i think these ""known limitation"" bugs should be explicitly described in the top comment (to emphasize the effect of the change). p.s. if we don't solve the select/multi re-order it should also be clearly mentioned there.",0,0,0,0.9880216121673584,0.989213526248932,0.9794227480888368,0.0,accept,unanimous_agreement
762611403,9890,don't you need to delete that note?,0,0,0,0.9849137663841248,0.9894195795059204,0.9925597906112672,0.0,accept,unanimous_agreement
762611974,9890,here we don't validate that there no exec that messes things up maybe add another command after the multi-exec and see that it's visible after the `set foo bar`,0,0,0,0.977204203605652,0.9845671057701112,0.9885340332984924,0.0,accept,unanimous_agreement
763080657,9890,"yep, i suppose you're right.. i'll drop the `!(c->cmd->flags & cmd_module)` when `call` needs to determine if core propagates or not",0,0,0,0.9658750891685486,0.9582054615020752,0.9850324392318726,0.0,accept,unanimous_agreement
763084073,9890,we have them module propagates nested ctx case1 module propagates nested ctx case2,0,0,0,0.9867929220199584,0.9848582744598388,0.9953835606575012,0.0,accept,unanimous_agreement
763084559,9890,will do,0,0,0,0.9603245854377748,0.957181751728058,0.9619618058204652,0.0,accept,unanimous_agreement
763085709,9890,i think it's there so we don't check the replication stream prematurely...,0,0,0,0.9676860570907592,0.9701370000839232,0.9880862236022948,0.0,accept,unanimous_agreement
763090081,9890,"yes, it is a bit weird but it simplifies the code tremendously. otherwise, i would have to make propagatependingcommands take a dbid (which i don't have, except in `call`), only to pass on to execcommandpropagatemulti which anyway does not mess with keys, so why would they need to select anything?",-1,-1,-1,0.9084116220474244,0.9562235474586488,0.9006844758987427,-1.0,accept,unanimous_agreement
763091030,9890,i added a comment above this block: [code block] set with px issues two separate notifications,0,0,0,0.9888161420822144,0.9902329444885254,0.9957188963890076,0.0,accept,unanimous_agreement
763094824,9890,"the ""problem"" is that the module running on master is calling rm_replicate of incr commands, without actually performing them, which is very bad practice... tbh rm_replicate may wreak havoc in master-slave consistency if not used right... the natural way of propagating to slave should by either rm_call with `!` or rm_replicateverbatim (in which case all rm_calls should not have `!`) but it seems like rm_replicate was specifically built for causing consistency issues: it basically means the user wants the slave to run a command which the master didn't",-1,-1,-1,0.6228106617927551,0.9545321464538574,0.8808034062385559,-1.0,accept,unanimous_agreement
763102930,9890,"yep, updated the comment",0,0,0,0.9850483536720276,0.9670715928077698,0.9879062175750732,0.0,accept,unanimous_agreement
763187918,9890,don't we need an `aftercommand` also after active-expiry/eviction? they too can invalidate cache,0,0,0,0.9870486855506896,0.994521141052246,0.9930722117424012,0.0,accept,unanimous_agreement
763341262,9890,"aftercommand was born to awake blocked clients, and update command stats, so it doesn't fit these.",0,0,0,0.9411876797676086,0.9326863288879396,0.9802600741386414,0.0,accept,unanimous_agreement
763345303,9890,"it waits for the slave to read the data the master sent it. assuming we don't use deferring connection, as soon as we got the reply of the `set`, it means `beforesleep` was done, and that means the data was also written to our fake replica (unless it's huge). i don't understand why we have it.. maybe copied form somewhere which really needed it, or outdated.",0,0,0,0.8219558000564575,0.946169137954712,0.9622977375984192,0.0,accept,unanimous_agreement
763350692,9890,"maybe somehow just emit the initial select in a different way? i.e. if later someone does: [code block] i'll be willing to accept that the select went into the multi.. but the initial one just looks very odd. but anyway, aren't you injecting the multi retroactively? maybe just check that the first command is a select and swap their order? since anyway, the commands are serialized to the replication stream, which is used on the target as one client, the client state can't mix with anything so the atomicity of select doesn't matter. unless if for some reason the transaction is aborted on the dest, in which case maybe it's a little bit better to take the select out?",0,0,0,0.782572865486145,0.8363407254219055,0.69321608543396,0.0,accept,unanimous_agreement
764678323,9890,"right we didn't, i just added one",0,0,0,0.9777469038963318,0.9483470916748048,0.989551603794098,0.0,accept,unanimous_agreement
764727490,9890,1. add to afterpropagte 2. add a flag to avoid multi/exec for non-call() stuff,0,0,0,0.9874239563941956,0.992210865020752,0.9936726093292236,0.0,accept,unanimous_agreement
764729072,9890,right,0,0,0,0.9538289308547974,0.8996442556381226,0.9678029417991638,0.0,accept,unanimous_agreement
764739850,9890,"steal the dbid of multi from first command, exec from last",0,0,0,0.9584354758262634,0.9799290299415588,0.9946433305740356,0.0,accept,unanimous_agreement
764784511,9890,-1 will be illegal,-1,0,0,0.6849251389503479,0.7369505167007446,0.8907796144485474,0.0,accept,majority_agreement
764784619,9890,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
765185085,9890,maybe updatestatsonunblock should be move to be together with unblockclient and aftercommand,0,0,0,0.9886004328727722,0.9928125739097596,0.9919270277023317,0.0,accept,unanimous_agreement
765186125,9890,"i think the var name should include the word ""multi""",0,0,0,0.9865309596061708,0.9856154918670654,0.9855513572692872,0.0,accept,unanimous_agreement
765188667,9890,"doesn't this cause each of the blocked commands to avoid adding multi in case one of them propagates two commands? since now each of them flushes the queue on its own, what's the problem of not setting this flag?",0,0,0,0.952472686767578,0.9633047580718994,0.9884483218193054,0.0,accept,unanimous_agreement
765191659,9890,"maybe we can assert for that? maybe by passing the flags? i see the the caller passes null, then sets the module pointer on its own..",0,0,0,0.9850354194641112,0.9925985336303712,0.9913410544395448,0.0,accept,unanimous_agreement
765269449,9890,why did you move this?,0,0,0,0.9203510880470276,0.9491409063339232,0.9917152523994446,0.0,accept,unanimous_agreement
765296027,9890,where did this come from and why did you have to add it?,0,0,0,0.9679011702537536,0.9888548254966736,0.9948975443840028,0.0,accept,unanimous_agreement
765299341,9890,why did you turn it from an op array to an op pointer array? so that the realloc is smaller (less memcpy)?,0,0,0,0.9828667044639589,0.9920451641082764,0.9927843809127808,0.0,accept,unanimous_agreement
765470676,9890,please add a comment explaining that test (what was queued is discarded),0,0,0,0.9851967096328736,0.9912235736846924,0.9950961470603944,0.0,accept,unanimous_agreement
765473319,9890,"i just realized that this call in `aftercommand` is gonna propagate the evicted dels too, right? which will add them to a multi with the command itself, or on their own if the command was a read-only command. i think that's wrong, and that we should flush the queue after eviction. maybe, we need to skip that though, if we're in a nested call (which is only `rm_call, right?). please add tests (if possible for both cases).",0,0,0,0.926786720752716,0.9836145043373108,0.8798584342002869,0.0,accept,unanimous_agreement
765474426,9890,aren't we missing a similar call in the eviction (tenacity) timer path? i don't recall if there's a test that triggers this path in a master/replica configuration. maybe it's a good idea to add one (or extend an existing one).,0,0,0,0.9785979390144348,0.990952730178833,0.99125999212265,0.0,accept,unanimous_agreement
765494949,9890,"before this commit, we didn't have multi/exec and i was under the impression that we want to avoid unnecessary transactions. if we do want to inject a redundant multi/exec i think it should be around all the commands propagated by handleclientsblockedonkeys, i don't see any reason to group the multi/execs by type (list,zset,stream,module)",0,0,0,0.9470952153205872,0.9765541553497314,0.986742615699768,0.0,accept,unanimous_agreement
765498340,9890,"do you mean we should pass redismodule* which could be null + the creation flags (redismodule_ctx_*)? and then modulecreatecontext always assigns the module (which may be null) and, if it's not redismodule_ctx_thread_safe we bump up ctx_nesting?",0,0,0,0.9889923334121704,0.9942626357078552,0.9934139847755432,0.0,accept,unanimous_agreement
765498457,9890,see the comment above this `if`,0,0,0,0.9862457513809204,0.9906826019287108,0.9949906468391418,0.0,accept,unanimous_agreement
765499987,9890,it came from `replicationfeedslaves` and it's here (along with the aof condition above) in order to prevent pushing stuff to also_propagate in case we don't have any aspect of replication (cpu + memory optimization) do you think this condition should be in a function that replicationfeedslaves uses? imho it's basic-enough to appear in those two places,0,0,0,0.98472797870636,0.9835445284843444,0.9913415312767028,0.0,accept,unanimous_agreement
765500071,9890,yes,0,0,0,0.9564858078956604,0.9659429788589478,0.9686408638954164,0.0,accept,unanimous_agreement
765501514,9890,"aftercommand isn't called after eviction we flush the propagation queue in performevictions which is called either from the timer or process command i even assert that the queue is empty before eviction/expiry so that before eviction/expiry the queue is empty, we delete keys, and we flush the queue so now it's empty again or maybe i misunderstood your comment",0,0,0,0.9499552249908448,0.9816315770149232,0.9890087246894836,0.0,accept,unanimous_agreement
765502308,9890,we have the same call in performevictions which is called either from the timer or processcommand,0,0,0,0.9874795079231262,0.9945564270019532,0.9939445853233336,0.0,accept,unanimous_agreement
765536270,9890,"it's not by type, it'd by command. ie. blmove or some other blocked command can propagate two commands, and these should be in transaction. but the entire event of processing all unblocked clients as a transaction is wrong (they're unrelated operations)",0,0,0,0.958171546459198,0.9728454351425172,0.8933522701263428,0.0,accept,unanimous_agreement
765566287,9890,"i'm not sure it's a win (doing more calls to malloc). unless the array is expected to be huge, which i doubt. i.e. you could have added the greedy growth mechanism, and keep it a flat array.",0,0,0,0.743163526058197,0.8364652395248413,0.8047784566879272,0.0,accept,unanimous_agreement
765568020,9890,"sorry, for some reason i looked at the code and it seemed as if you didn't modify evict.c (some glitch)",-1,-1,-1,0.9862650036811828,0.9853084683418274,0.9902198910713196,-1.0,accept,unanimous_agreement
765569391,9890,sorry.. somehow i missed it. but maybe add a test for eviction and propagation anyway? (in case we don't have one)?,-1,-1,-1,0.989282488822937,0.984901249408722,0.9858561754226683,-1.0,accept,unanimous_agreement
765638437,9890,"i mean i saw the callers pass null as context, and then do `ctx->module = module` right after. so it's odd to use this argument as an indication to bump the nesting. i think we need another argument, and let the caller always pass the module as argument. we can take this opportunity to take more arguments that are commonly set to the newly created context (like flags), and then we can use the thread_safe flag for the nesting need.",0,0,0,0.932561218738556,0.9410386681556702,0.9097558856010436,0.0,accept,unanimous_agreement
766553978,9890,"when running `latency of expire events are correctly collected` with address-sanitizer it made a huge difference. this test uses a lua to add 1m elements to a set. which means the also_propagate array reaches 1m*sizeof(redisop), which is 64mb, instead of just 8mb when we store pointers. maybe the whole scenario is a bit extreme (address sanitizer + creating a 1m member set in a lua) your call",0,0,0,0.8981953859329224,0.8884744644165039,0.9547500014305116,0.0,accept,unanimous_agreement
766676129,9890,this huge difference is between the version with and without the extra pointer? or from before you added the greedy allocation? i don't understand why address sanitizer will be slow to realloc more memory. if anything the extra indirection has an extra cost.,0,0,-1,0.9310998320579528,0.6336103081703186,0.5424016118049622,0.0,accept,majority_agreement
766755175,9890,"i re-checked and you're right, the greedy allocation was the game changer... i'll keep only the greedy allocation",0,0,0,0.951832115650177,0.9329886436462402,0.9560049772262572,0.0,accept,unanimous_agreement
767286846,9890,please help me follow this. did we ever propagated config set to replicas? or is this a new concern added by this pr?,0,0,0,0.9682546854019164,0.9872626662254332,0.9929978847503662,0.0,accept,unanimous_agreement
767287568,9890,please put a third set of eyes on this to make sure we're not overlooking anything.,0,0,0,0.9198167324066162,0.9795260429382324,0.9018441438674928,0.0,accept,unanimous_agreement
767287943,9890,maybe preserve that comment in the other occurrence of this case (to be on the safe side),0,0,0,0.9840328097343444,0.9842981100082396,0.9842811822891236,0.0,accept,unanimous_agreement
767288381,9890,"why do we need a replica? `attach_to_replication_stream` will work without one. also, why `after 1000`? (did you copy it from somewhere?) p.s. don't we need to set the ping period to a very high value to make sure one won't make it's way into our stream and fail the test?",0,0,0,0.9843695163726808,0.9898982048034668,0.991709530353546,0.0,accept,unanimous_agreement
767290014,9890,"side note, i think i would be willing to leave this case as something that no sane module should be doing. i.e. calling config set maxmemory from a timer.",0,0,0,0.9791697263717652,0.9599393010139464,0.9723051190376282,0.0,accept,unanimous_agreement
767329636,9890,"yes, we did form top comment: [code block]",0,0,0,0.9880982041358948,0.9711267948150636,0.9927549958229064,0.0,accept,unanimous_agreement
767444233,9890,"ok, so that bug (propagating config set) is not new (probably exists in previous releases), but only happens when modules listen to the ""evicted"" notification, and do some rm_call or other propagation from within that callback. right? so i guess this doesn't mean we wanna backport such a fix, but we may still wanna mention it in the top comment.",0,0,0,0.9796075820922852,0.9832028150558472,0.9812752604484558,0.0,accept,unanimous_agreement
767588380,9890,"do you want me to explicitly block it? or just assume no module would even do it? if we want to block it, should it be in call() or in rm_call?",0,0,0,0.9868985414505004,0.992443025112152,0.9926722049713136,0.0,accept,unanimous_agreement
767591140,9890,right,0,0,0,0.9538289308547974,0.8996442556381226,0.9678029417991638,0.0,accept,unanimous_agreement
767593119,9890,"right about both, deleted the replica",0,0,0,0.987380862236023,0.9838391542434692,0.9884196519851683,0.0,accept,unanimous_agreement
767600181,9890,the only other occurrence is rm_getthreadsafecontext and even then sometimes we have a module and sometimes we don't.. i don't see a value of having the comment there too,0,0,0,0.960426390171051,0.8919448852539062,0.991672933101654,0.0,accept,unanimous_agreement
767714638,9890,add test: multi incr x config set maxmemory 1 incr x exec x should be 2,0,0,0,0.9833469986915588,0.9913313388824464,0.9946749210357666,0.0,accept,unanimous_agreement
767775572,9890,"for the record. we realized that it's not only modules, but also multi, and that the solution is probably to allow the config set, but skip the eviction because we can't afford to propagate.",0,0,0,0.974683403968811,0.9914996027946472,0.9888521432876588,0.0,accept,unanimous_agreement
768018994,9890,yes,0,0,0,0.9564858078956604,0.9659429788589478,0.9686408638954164,0.0,accept,unanimous_agreement
768081316,9890,good catch! i see we already had a test for that? so how come we didn't get the assertion before? p.s. another way to test it could be: multi + lpush + expire + debug sleep,1,1,1,0.9908578991889954,0.9796016216278076,0.9960397481918336,1.0,accept,unanimous_agreement
768088041,9890,"can you help me understand this change? all i see that changed in the test code itself (and the module), is not sending the config set maxmemory (which means the test name is now outdated?) but i don't understand how it impacted the verification code in such a way. p.s. is the reason you removed the config set, just because you realized that multi-exec demonstrates a similar problem, so there's no need for the module notification case?",0,0,0,0.9722276926040648,0.9891645312309264,0.978634238243103,0.0,accept,unanimous_agreement
768424493,9890,"3 commits ago i added the assertion `serverassert(server.also_propagate.numops == 0);` in `handleclientsblockedonkeys` and then the external-server tests failed on that swapdb test the reason it failed is that `swapdb` called `handleclientsblockedonkeys` which added the expire-delete to also_propagate (and never actually propagated) and then `handleclientsblockedonkeys` was called again from `beforesleep`, triggering the assertion. the reason it happened only with the external server is probably that at some point the external server loaded an rdb, causing it to create a backlog and thus `shouldpropagate` returned 1 (in non-external tests the server come up fresh, and if there's no aof or replicas, `alsopropagate` doesn't do anything)",0,0,0,0.985217034816742,0.994358241558075,0.9915750622749328,0.0,accept,unanimous_agreement
768431471,9890,"in the past it used to do call(incr) // and replicate call(config set maxmemory 1) replicate(incr) // so ti's done only on replica call(config set maxmemory 0) call(incr) //and replicate after the last commit, setting maxmemory to 1 and then 0 in the same atomic operation would not result in eviction (because numops > 0). i wanted to get some evictions, so i removed the `config set maxmemory 0` form the module code (note that it still does `config set maxmemory 1` so the test name is correct) another change is that i changed the names of the keys we incr via rm_call and made them volatile so that they can be evicted when i set the eviction to volatile-based (i don't use allkeys because we have the special key ""notifications"" that always comes back to life, and then it gets evicted a random amount of times, and i can't assert anything about the replication stream) this test is indeed similar to the one in maxmemory.tcl but i wanted to test the module case too (also, the test already existed, would be a shame to delete it).",0,0,0,0.9573285579681396,0.9889238476753236,0.992766499519348,0.0,accept,unanimous_agreement
768432520,9890,"now, we can see that keys are evicted only after the module executes and replicates everything in the callback",0,0,0,0.987109899520874,0.9921499490737916,0.9926443099975586,0.0,accept,unanimous_agreement
768536520,9890,"comment from ctx_nesting should be global, not per module imagine ""module1.foo"" calling ""module2.foo"". if the nesting level is not global module2.foo will propagate everything by itself, while module1.foo should do it (the issue here is the order of propagation)",0,0,0,0.9879716038703918,0.9936043620109558,0.9940220713615416,0.0,accept,unanimous_agreement
768540063,9890,comment from bug: calling rm_call of a native redis command with `!` inside a thread safe ctx will not propagate. redis core won't propagate because it's an rm_call + we may never free the thread-safe ctx so there's no chance to propagate. solution: in gil-lock we need to incr ctx_nesting (in order to prevent any internal rm_calls from propagating stuff on their own). assert: ctx_nesting must be 0 before the incr. in gil-unlock. assert ctx_nesting is 1. we decr it and call propagatependingcommands,0,0,0,0.9382505416870116,0.9778724908828736,0.986873209476471,0.0,accept,unanimous_agreement
768609970,9890,so maybe it's wise to use this opportunity to add an explicit test for it (multi + lpush + expire + debug sleep)?,0,0,0,0.9788764715194702,0.9919739365577698,0.990674078464508,0.0,accept,unanimous_agreement
768642766,9890,"i actually edited to original test to check the replication stream, so now even if it's not in standalone mode, the server still replicates... i checked and indeed it failed without the fix in non-standalone mode do you still want me to add the multi + lpush + expire + debug sleep case?",0,0,0,0.9847737550735474,0.9600233435630798,0.9901052117347716,0.0,accept,unanimous_agreement
768645625,9890,"this area of redis seems fragile, so i think more tests to detect future regressions are better. but if it takes too long to compose that test, i'm willing to let go.",-1,-1,0,0.6788669228553772,0.652509331703186,0.8397231101989746,-1.0,accept,majority_agreement
768649218,9890,"i'll add the test, should be easy enough",0,0,0,0.9662277698516846,0.7318518757820129,0.9886554479599,0.0,accept,unanimous_agreement
775114399,9890,[code block] the test failed once and again [code block],0,0,0,0.9769306182861328,0.9888876080513,0.9434380531311036,0.0,accept,unanimous_agreement
775353455,9890,happened again: [a link],0,0,0,0.9771610498428344,0.9882431626319884,0.99393492937088,0.0,accept,unanimous_agreement
805410083,10293,"this exact slot enumeration logic has already been used twice in cluster.c. i wonder if it helps to single source it with a callback pattern that takes two parameters: the start index and the length. more specifically, i am thinking that the code block between line 5080 and 5094, inclusive, can be moved into a callback function while the rest of the for loop can be extracted into a generic enumeration function.",0,0,0,0.9135765433311462,0.9881073832511902,0.9901590943336488,0.0,accept,unanimous_agreement
805410348,10293,i'd suggest using a non-sds version of the key_compare function to help cut down on the memory allocations. the key_compare function can even take advantage of the fact that it is dealing with a fixed length key.,0,0,0,0.9867188334465028,0.9926464557647704,0.9898701310157776,0.0,accept,unanimous_agreement
805425169,10293,i've thought about how to deduplicate this slot range enumeration logic too. my idea is create an iterator function which returns each slot range of a node: [code block] i have an implementation. i can post it tomorrow.,0,0,0,0.9728329181671144,0.9560332894325256,0.979423761367798,0.0,accept,unanimous_agreement
805430433,10293,"another idea is to just use the clusternode pointer itself as the key, which reduces the key size from 40 bytes to 8 bytes on 64bit platforms.",0,0,0,0.9860799908638,0.9938960671424866,0.9907316565513612,0.0,accept,unanimous_agreement
805445282,10293,"worth mentioning we have two types of iterations: 1. we do a straight iteration through all of the slots and group them by slot ranges (see `cluster slots`) 2. we want a result which is the ordered list of nodes and then we want to iterate through those node's slots (see `cluster nodes`. need to make sure the iterator supports both, or still makes 2 easily attainable.",0,0,0,0.9753353595733644,0.9770172834396362,0.9870952367782592,0.0,accept,unanimous_agreement
805446087,10293,"i think this documentation is all that helpful, since it's pretty easy to scan through and see this all.",0,1,1,0.6151477694511414,0.6984428763389587,0.8054510951042175,1.0,accept,majority_agreement
805446202,10293,i think we want to have tcp and tls port here if available. we need to do some computation. fyi,1,0,0,0.6075966358184814,0.685944676399231,0.983549952507019,0.0,accept,majority_agreement
805446290,10293,"i think empty string is valid for endpoint, it means ""unknown endpoint"".",0,0,0,0.9882118105888368,0.9723588824272156,0.987586498260498,0.0,accept,unanimous_agreement
805446915,10293,"hm, we may need to take a call on this. although it's used sporadically in documentation, ""primary"" is not really used as a role delimiter. we probably have to keep using master here for the time being for consistency.",0,0,0,0.9786884784698486,0.9838752746582032,0.970852553844452,0.0,accept,unanimous_agreement
805548391,10293,what's the point of unknown endpoint? shouldn't we omit it from the map in that case?,0,0,0,0.9712528586387634,0.9816075563430786,0.9901346564292908,0.0,accept,unanimous_agreement
805674414,10293,"good point. the version posted below only iterates over a single node (i.e. it covers 2 but not 1) but i guess it can be adapted, or possibly 1 is different enough to have a separate iteration function for that. int nextslotrange(clusternode *node, int *begin, int *end); [code block]",1,0,1,0.947143256664276,0.7223837971687317,0.956135630607605,1.0,accept,majority_agreement
805678079,10293,"one possibility: we don't need ""role"" if we just decide that the first node is the master and the following nodes are replicas.",0,0,0,0.9859355688095092,0.9917768239974976,0.9876920580863952,0.0,accept,unanimous_agreement
805715299,10293,"yes, i agree. probably something like this: [code block] and omitting any port if it's zero.",0,0,0,0.9825275540351868,0.9817439317703248,0.9854626655578612,0.0,accept,unanimous_agreement
805744848,10293,i used the above while writing the below code :grinning_face_with_smiling_eyes:,0,0,0,0.665705680847168,0.9887931942939758,0.5031620264053345,0.0,accept,unanimous_agreement
805944883,10293,"i have added a conditional check if the node provided is null, we move on to the next slot. wdyt ? [code block] [code block]",0,0,0,0.9883163571357728,0.9725310206413268,0.9956868290901184,0.0,accept,unanimous_agreement
805949107,10293,"i think keeping the role is safe, don't want to leave it to assumption. i'm moving it to `master` for now.",0,0,0,0.9171801209449768,0.954532027244568,0.9405690431594848,0.0,accept,unanimous_agreement
806043486,10293,"creating a temporary dict seems unnecessary. maybe we can avoid it? i think it's cheaper to iterate over the structures and add replies directly without allocating any extra structures, even if we might need to iterate over the nodes one extra time e.g. once just to count the shards to `addreplyarraylen(c, numshards);`. if we need to create a structure like this one, then perhaps it can be stored permanently or maybe we can change the existing structures to be more optimized for cluster shards (if possible).",0,0,0,0.9566459059715272,0.9923831820487976,0.9824256896972656,0.0,accept,unanimous_agreement
806115474,10293,"if n == null, the function returns a range with a single slot for no node? i think it is strange. it relies on the caller to make sure that `begin + 1` has no node. maybe you meant `*begin = *end + 1`? i think the next range starts where the previous range ends. or did you change this? anyway, this function cannot check this slot has no node, so i think it is strange. better check if n == null and find node with a slot before calling the iterator function. maybe we need another function `nextslotrangeandnode(*begin, *end, *node)` which also returns the node of the next range...? this logic is different and it is less complex to make them separate functions imo. [code block] implementation (untested): [code block] ---- one question: why do we need to return the slots in ascending order? can't we just use the order of the master nodes?",-1,0,-1,0.5245054960250854,0.5399397015571594,0.7386490702629089,-1.0,accept,majority_agreement
806394778,10293,"it means that clients should reach out to the same endpoint connected to. omitting feels weird to me, but i suppose that could be defined behavior.",-1,-1,-1,0.7073433995246887,0.9386240243911744,0.9462180137634276,-1.0,accept,unanimous_agreement
806397112,10293,i think we could re-use the iterator logic for `cluster nodes` that loops through all the slots an caches the response on each node. we can then re-iterate through the cached nodes to add the output.,0,0,0,0.9880118370056152,0.9925947785377502,0.9874788522720336,0.0,accept,unanimous_agreement
806588636,10293,"right, so empty string means use same as current. omitted could mean that there is no endpoint at all, or that it's completely unknown. the word ""unknown"" is perhaps not the best term to use here...",0,0,0,0.8216677308082581,0.950746774673462,0.9869108200073242,0.0,accept,unanimous_agreement
808358984,10293,"for now, i'm not picking this up. i have shared the code between `cluster nodes` and `cluster shards`. may be we can come back later to improve the redundancy for `cluster slots`",0,0,0,0.9650627374649048,0.9759174585342408,0.9779986143112184,0.0,accept,unanimous_agreement
808359288,10293,removed this part of code.,0,0,0,0.9606428146362304,0.985982358455658,0.991904079914093,0.0,accept,unanimous_agreement
810566529,10293,"""unknown endpoint' is what we defined here, [a link] if you have a better term we can update it, but i couldn't think of a better one.",0,0,0,0.943250834941864,0.9246481657028198,0.9875386953353882,0.0,accept,unanimous_agreement
810567930,10293,none of this seems to be used anymore,0,0,0,0.9261820912361144,0.96086323261261,0.9876880049705504,0.0,accept,unanimous_agreement
810568216,10293,tls_port ?,0,0,0,0.987703025341034,0.9439853429794312,0.9945695996284484,0.0,accept,unanimous_agreement
810568708,10293,"let's add some documentation here, and probably for the rest of the functions.",0,0,0,0.9867271780967712,0.9856098294258118,0.9919701218605042,0.0,accept,unanimous_agreement
810568759,10293,"not sure exactly why we return here, should we compute the result then?",0,0,0,0.8482108116149902,0.9243693947792052,0.94889235496521,0.0,accept,unanimous_agreement
810569303,10293,"i assume that the assumption is that when n->slot_info_pair is null, the node owns no slots? if so, let's document that. [code block]",0,0,0,0.9877008199691772,0.992379665374756,0.9931342601776124,0.0,accept,unanimous_agreement
810569451,10293,this can never be 0 right? at the very least the node passed in is serving these slots.,0,0,0,0.9854094982147216,0.974880874156952,0.986136555671692,0.0,accept,unanimous_agreement
810569992,10293,"let's just embed this all in ""create a 4 node cluster with custom slots""",0,0,0,0.986153244972229,0.991455376148224,0.9941796064376832,0.0,accept,unanimous_agreement
810570087,10293,"you should just be able to call this, the previous call was for testing hostnames.",0,0,0,0.988936483860016,0.9828500151634216,0.9949955940246582,0.0,accept,unanimous_agreement
810570107,10293,what does this mean?,0,0,0,0.9322381615638732,0.9679911136627196,0.9850018620491028,0.0,accept,unanimous_agreement
810570173,10293,"would be ideal to set this at the beginning, and use it to assign slots.",0,0,0,0.9820441007614136,0.9825074076652528,0.991576373577118,0.0,accept,unanimous_agreement
810570301,10293,let's replace this with a wait_for,0,0,0,0.9844733476638794,0.9909045100212096,0.9937460422515868,0.0,accept,unanimous_agreement
810570447,10293,why are there two writable tests?,0,0,0,0.969722330570221,0.9345280528068542,0.9858109951019288,0.0,accept,unanimous_agreement
810701929,10293,"for the invocation from `clustergennodedescription` for `cluster nodes` output, the result is computed if `slot_info_pair` is null. for safety, i added it, removing it.",0,0,0,0.9884324669837952,0.9953882694244384,0.9948251247406006,0.0,accept,unanimous_agreement
811243772,10293,"after failover, i've added this to verify if the cluster is writable. is it unnecessary ?",0,0,0,0.9862191081047058,0.9927316308021544,0.9941425919532776,0.0,accept,unanimous_agreement
811629632,10293,why wouldn't the cluster be writable? we normally don't test this after each failover,0,0,0,0.9546492695808412,0.9750390648841858,0.9873207807540894,0.0,accept,unanimous_agreement
815368229,10293,"nit: 1. lower case 'c' for cluster in ""the total number of cluster nodes"" 2. missing an ""an"" between ""get"" and ""array"" in ""get array of cluster slots to node mappings""",0,0,0,0.9882707595825196,0.9948145747184752,0.992850661277771,0.0,accept,unanimous_agreement
815368592,10293,"nit: associated ""with"" it",0,0,0,0.9808566570281982,0.966016173362732,0.992381989955902,0.0,accept,unanimous_agreement
815372394,10293,"nit: rename ""node"" to ""master"" to improve readability?",0,0,0,0.986430525779724,0.9929099678993224,0.9905804991722108,0.0,accept,unanimous_agreement
815373010,10293,would pfail be a state worth exposing?,0,0,0,0.9698651432991028,0.9818214774131776,0.9575018882751464,0.0,accept,unanimous_agreement
815373352,10293,"i think adding `addreplyarraylen(c,0)` for empty shards as well would make the parsing easier.",0,0,0,0.9879180788993835,0.9925447106361388,0.9862836599349976,0.0,accept,unanimous_agreement
815384251,10293,"i think our tenets here should be that the state is actionable for clients. so i think pfail (aka timedout) isn't that useful, since it's not committed yet.",0,0,0,0.9758973717689514,0.9817776679992676,0.983356475830078,0.0,accept,unanimous_agreement
815386541,10293,"it could be actionable i think especially in the read-replica use case. not saying i know of a client actually doing it, i can imagine though a latency-sensitive client skips pfail replicas for read traffic because otherwise there is a nontrivial amount of likelihood that a pfail replica is actually down permanently so knowing pfail would be useful if the client would like to reduce latency as much as possible, either when the cluster is in a steady state or going through some node failures. since pfail is a well-known and well-defined state and exposing it is neither complicated nor costly, i would like to err on the side of exposing it and let the client get creative. my suggestion for including epoch follows the same philosophy.",0,0,0,0.9233455061912536,0.9763330817222596,0.96939218044281,0.0,accept,unanimous_agreement
815611962,10293,"empty shards can not exist, since if they were they really empty there would be node to call addshardreplyforclustershard() on.",0,0,0,0.9840579628944396,0.993123471736908,0.9906668066978456,0.0,accept,unanimous_agreement
815613216,10293,"i don't agree we should err on the side of ""as much of possible"". i honestly think we should do the opposite, release as little as possible. my mentality is if we the maintainers of redis built our version of a perfect client, would we include this information, i would guess not. transient failures does not imply we should avoid that node, i would rather wait for the consensus of the cluster to say the node is down.",0,0,0,0.8104705214500427,0.5407118201255798,0.7628170847892761,0.0,accept,unanimous_agreement
815623483,10293,"i changed it to addshardreplyforclustershards. i'm not sure that is much better, but i didn't think addmaster really made that much sense either. thoughts?",0,0,0,0.9138931632041932,0.884605884552002,0.8999385237693787,0.0,accept,unanimous_agreement
815630350,10293,"i too believe in the [a link] principle so to clarify a bit, i am not trying to push a big and bloated command. my concern is that exposing this state would require changing the public interface in the future, which carries backcompat risk (probably more so with epoch); given that it is such a trivial thing to add it now, that is why i'd like to bring this discussion up now. from a quick search, it seems like #10195 could benefit from this information.",0,0,0,0.5171290636062622,0.8691487312316895,0.8997220396995544,0.0,accept,unanimous_agreement
815634595,10293,"this is one of the reasons we wanted to move to a dict, so that we can add more fields and clients can opt in to them. i pinged the tencent guy to weigh in. i would like to understand their use case a little bit more, but am more inclined to add it now. i'll add it to the top level comment as a consideration.",0,0,0,0.9052507281303406,0.9184389710426332,0.9288873672485352,0.0,accept,unanimous_agreement
815635023,10293,"probably fine, maybe make an issue for improvement?",0,0,0,0.972665309906006,0.9822856187820436,0.9672369360923768,0.0,accept,unanimous_agreement
815635275,10293,"strictly speaking, ""empty shards can't exist"" is not part of the contract of `addnodereplyforclustershard` but a state inferred from the only caller of `addnodereplyforclustershard` right now so if this function is ever used outside of this ""boundary"" in the future, there is a chance an empty shard could be introduced. so how about adding a serverassert on the list length of `nodes_for_slot` not being 0?",0,0,0,0.9859153032302856,0.9768902063369752,0.9903199076652528,0.0,accept,unanimous_agreement
815658291,10293,sgtm. thanks,1,1,1,0.9248377680778505,0.938027799129486,0.9790942072868348,1.0,accept,unanimous_agreement
815662203,10293,lgtm,0,0,0,0.9795994758605956,0.7242414951324463,0.9618706703186036,0.0,accept,unanimous_agreement
815686565,10293,i think a plural is good naming style for a list. [code block],1,0,1,0.7907941341400146,0.9103818535804749,0.7137792110443115,1.0,accept,majority_agreement
815723422,10293,agreed.,0,0,0,0.9702104926109314,0.9005043506622314,0.954565167427063,0.0,accept,unanimous_agreement
816445859,10293,i'm usually good with asserts :),1,1,1,0.9815099239349364,0.9911606907844543,0.8794857263565063,1.0,accept,unanimous_agreement
827669805,10293,this fails in my gh cluster test [a link] [code block],0,0,0,0.9214906692504884,0.9621005654335022,0.9912516474723816,0.0,accept,unanimous_agreement
828228419,10293,will take a look here.,0,0,0,0.9795839190483092,0.9624519348144532,0.9726574420928956,0.0,accept,unanimous_agreement
828245535,10293,"bane of my existence, for some reason this test only fails when you run the entire suite but passes individually. i'm committing to deprecating this test suite now.",-1,-1,-1,0.9668228030204772,0.8630335927009583,0.9789921641349792,-1.0,accept,unanimous_agreement
828700223,10293,"please take a look here (tls_port and the above port in tls mode) the cluster-shards test failed in tls. ([a link] with this patch, the test pass, but i'm not very familiar with tls mode [code block] in case anyone will fix it, i would like to mention: 1. since we deprecated cluster-slots, maybe we need to add a doc_flags in cluster-slots.json like others 2. i notice cluster-shards.json, it's indented by two spaces, we use four spaces elsewhere 3. and the three `wait_for_condition 50 100` in 28-cluster-shards.tcl, there may be a timing issue, at least i've encountered it locally (centos7), so maybe change it to 500 100",0,0,0,0.7809562683105469,0.9651694297790528,0.9812864661216736,0.0,accept,unanimous_agreement
828718974,10293,"for 1, we marked it as deprecated. was there something else that you meant?",0,0,0,0.983363151550293,0.9657080173492432,0.9903357028961182,0.0,accept,unanimous_agreement
828720465,10293,"i mean the doc_flags, like other commands? [code block]",0,0,0,0.988103687763214,0.9934839606285096,0.9928277134895324,0.0,accept,unanimous_agreement
828726645,10293,"oh, i guess i didn't realize that was a thing.",-1,-1,0,0.6322503685951233,0.6128665804862976,0.8321018218994141,-1.0,accept,majority_agreement
828740288,10293,do you have time to address this? otherwise i can take a look tomorrow.,0,0,0,0.9790775179862976,0.959299087524414,0.9934050440788268,0.0,accept,unanimous_agreement
828894809,10293,"-binbin regarding the `port` and `tls-port` logic: `server.tls_port` is always a tls port and `server.port` is always a plaintext (aka cleartext) port if specified. for the cluster bus, it depends on the `server.tls_cluster` variable: [code block]",0,0,0,0.9881445169448853,0.995670199394226,0.9599226713180542,0.0,accept,unanimous_agreement
865990198,10293,"the slots here is not integers, see #10680 [code block]",0,0,0,0.986234188079834,0.99472838640213,0.9941799640655518,0.0,accept,unanimous_agreement
1590318231,13243,"it shouldn't be `estimate`, maybe like `lpentrysizeinteger(long long)`.",0,0,0,0.9844905734062196,0.98969566822052,0.9925222992897034,0.0,accept,unanimous_agreement
1590329271,13243,what about using `tuple_len` like `lprandompair`.,0,0,0,0.985755205154419,0.9920172691345216,0.9912477731704712,0.0,accept,unanimous_agreement
1590333765,13243,"i don't like using hashaddctx as this way, did you just for updating the ebuckets in the hashtypesetexdone()? if so, i think we can extract these code to separate method.",-1,0,-1,0.7946043014526367,0.6132250428199768,0.6357815861701965,-1.0,accept,majority_agreement
1590482286,13243,"in fact, i've been confused about this, traditionally we return 1 for success and 0 for fail. if we want 0 to indicate success, we should have failure return a negative number instead of 1. please correct me if i'm wrong.",0,-1,-1,0.5479250550270081,0.9151820540428162,0.541770339012146,-1.0,accept,majority_agreement
1590482697,13243,uncessary change?,0,0,-1,0.9855386018753052,0.7215748429298401,0.864913284778595,0.0,accept,majority_agreement
1590503389,13243,"why create the hash object in advance? i saw that you removed `zfree(encoded);` and `o->ptr = null;`, which will cause memory leak(encoded) and crash due to ptr(obj_string) and type(obj_hash) don't correspond to.",0,0,0,0.983942449092865,0.9897140860557556,0.987973690032959,0.0,accept,unanimous_agreement
1590585815,13243,this allows listpackexexpire() to be more independent. [code block],0,0,0,0.9889336824417114,0.9946486353874208,0.9953873753547668,0.0,accept,unanimous_agreement
1590586545,13243,"since listpackex can be accessed outside server.h, i think we can discard these methods, and listpackexcreatefromlistpack() is only used in rdb.c, it's not a good deal to add a separate for it.",0,0,0,0.9701030254364014,0.981541395187378,0.98226797580719,0.0,accept,unanimous_agreement
1590631988,13243,these are the returned values. i only corrected the comment so that it'll correctly reflect what is being returned. suggestions on the values themselves should probably be addressed by .,0,0,0,0.9859873652458192,0.9860259890556335,0.9925194978713988,0.0,accept,unanimous_agreement
1590633340,13243,"reverted that, although afaik this isn't necessary. but it's probably better addressed at a different commit.",0,0,0,0.9848986268043518,0.987716019153595,0.9780600666999816,0.0,accept,unanimous_agreement
1590661195,13243,"yes, but i've seen other developers reference listpack.h/.c directly into their code.",0,0,0,0.988483726978302,0.9846197962760924,0.9932339787483216,0.0,accept,unanimous_agreement
1590813237,13243,"i agree with the comment, but just to verify: `listpackexexpire` was increasing `stat_expired_hash_fields` internally before this change. so after my fix it will not increase any stat value internally, instead its callers will increase whichever stat value is right after calling `listpackexexpire`, based on the value returned in `info.itemsexpired`. is this what you mean?",0,0,0,0.9846354722976683,0.9916383624076844,0.9848068952560424,0.0,accept,unanimous_agreement
1590822025,13243,"i agree. it should return 1 on success. -kalish , if you already touching there, maybe you can fix it. thanks.",1,1,1,0.9716943502426147,0.9879781007766724,0.9928296208381652,1.0,accept,unanimous_agreement
1590944368,13243,", sure. will do.",0,0,1,0.7693457007408142,0.962036907672882,0.5494581460952759,0.0,accept,majority_agreement
1590952443,13243,"yes, this decouples listpackexexpire() from the statistics.",0,0,0,0.9880881905555724,0.9933432340621948,0.9938954710960388,0.0,accept,unanimous_agreement
1590954195,13243,"this is the (short version) of the new api opened by in t_hash to add fields to a hash object, plus setting their expiration time. not commenting on the specific implementation, i think it is better (in terms of encapsulation, at least) to have the logic of adding / deleting / setting expiry (of) fields in t_hash.c instead of rdb.c. is there any other specific suggestion?",0,0,0,0.9830145835876464,0.9911620616912842,0.9878090620040894,0.0,accept,unanimous_agreement
1591017165,13243,"changed that to return c_ok and c_err. note that this requires including server.h, which also requires removing other include statements to avoid build errors.",0,0,0,0.988524854183197,0.99382084608078,0.9942042231559752,0.0,accept,unanimous_agreement
1591020657,13243,i really want to avoid include server.h as much as i can. the file server.h is a huge mess to include.,-1,-1,-1,0.979915201663971,0.9714519381523132,0.9942978024482728,-1.0,accept,unanimous_agreement
1591066952,13243,not sure i understand. `o` is created before this point as string (line 2493) for all the ziplist / listpack encoded types. i need to convert it here to hash_litspack / hash_listapck_ex encoding. would appreciate other suggestions. i removed the `zfree(encoded)` and `o->ptr = null` bits as memory free will happen as part of `decrefcount(o)` (at least after setting its correct type and encoding) and returning null will block any accesses to `o->ptr` as far as i can see.,0,0,0,0.9503250122070312,0.96958726644516,0.8548882603645325,0.0,accept,unanimous_agreement
1591097177,13243,"yeah, you're right.",0,0,0,0.932545840740204,0.6884310245513916,0.9575839638710022,0.0,accept,unanimous_agreement
1591122527,13243,"ok, changed it back to 0 on success and -1 on error (which are identical to c_ok and c_err, respectively)",0,0,0,0.9869760870933532,0.9935240745544434,0.9799315333366394,0.0,accept,unanimous_agreement
1591135672,13243,"i'm fine with either ways, but i hope that it's better for all ebuckets interfaces to have the same way.",0,0,1,0.8832698464393616,0.7028223872184753,0.5109737515449524,0.0,accept,majority_agreement
1591147501,13243,"ok, removed. i created these in the first place because `listpackex` (which was `listpackttl` back then) was defined in `t_hash.c` and thus not accessible from `rdb.c`",0,0,0,0.985631823539734,0.9939124584197998,0.9913970232009888,0.0,accept,unanimous_agreement
1592039147,13243,"it can be complicated, i think we can leave it as now, and improve it in the future.",0,0,0,0.9007055759429932,0.975023090839386,0.9576178789138794,0.0,accept,unanimous_agreement
1594450544,13243,no need to pass `dbid`. it can be extracted from `db` (`db->id`),0,0,0,0.9881998300552368,0.9941542744636536,0.9947697520256042,0.0,accept,unanimous_agreement
1594542286,13243,"better to align terminology with t_hash.c. maybe something like: [code block] ""ex"" can be interpret as ""expiry"" and if evolve further as ""extended"".",0,0,0,0.985310673713684,0.994862973690033,0.9927748441696168,0.0,accept,unanimous_agreement
1594980427,13243,i think we need here better clarification. we can also merge the logic below into the same line to better grasp the idea. something like: [code block],0,0,0,0.9777255058288574,0.9665659070014954,0.9838340878486632,0.0,accept,unanimous_agreement
1594986367,13243,"to simplify the code, these lines can be merged into the condition with `with_ttl` below.",0,0,0,0.9882732033729552,0.9910284876823424,0.9945675134658812,0.0,accept,unanimous_agreement
1594987501,13243,"we can merge the condition above into this line to simplify the code. something like: [code block] we save a condtion, and all the logic sits in one place.",0,0,0,0.9866967797279358,0.9863946437835692,0.9926313161849976,0.0,accept,unanimous_agreement
1595033368,13243,`ttl` is not accurate. it is absolute time. consider using `expire` or `expireat` instead .,0,0,0,0.9484165906906128,0.9856369495391846,0.9931451082229614,0.0,accept,unanimous_agreement
1595199285,13243,there is a diff in the logic vs. handling expire which also taking into account `rdbflags_aof_preamble`. please follow expire logic regarding aof preamble. might need also `!(rdbflags&rdbflags_aof_preamble) &&`,0,0,0,0.9837278127670288,0.995031476020813,0.9950578212738036,0.0,accept,unanimous_agreement
1595207993,13243,no need to check length of integer value against `hash_max_listpack_value` which aimed for strings only. simpler.,0,0,0,0.9707762598991394,0.9876788258552552,0.9927571415901184,0.0,accept,unanimous_agreement
1595225894,13243,not sure i understand your todo comment. the number of tuples of the loaded hash is bigger than initial size of and so we try to expand the table.,0,0,0,0.9582573771476746,0.95110023021698,0.8048869967460632,0.0,accept,unanimous_agreement
1595229632,13243,this assert is redundant. we don't have any break condition in the loop and stop condition is `len==0`,0,0,0,0.9643110036849976,0.9805669188499452,0.9777657389640808,0.0,accept,unanimous_agreement
1595244986,13243,use constant `eb_expire_time_invalid` instead of `uint64_max`. note that also this way it will politely ignores invalid ttls equal or bigger than it (can consider failing if value >= eb_expire_time_invalid),0,0,0,0.9847673773765564,0.9937167763710022,0.9939047694206238,0.0,accept,unanimous_agreement
1595340117,13243,"-kalish , i sent you a patch that suppose to simplify all the usage of hashtypegroupset* into one simple function without any malloc(). please review it.",0,0,0,0.939825713634491,0.9800400733947754,0.9879637956619264,0.0,accept,unanimous_agreement
1595543685,13243,"i think you forgot to init `lpt->key`. if that so, please add appropriate test. we should have a test that makes lazy/active-expiry after rdb load of dict/listpack.",0,0,0,0.987825095653534,0.9946691393852234,0.9918232560157776,0.0,accept,unanimous_agreement
1595547524,13243,no need to pass `dbid`. included in `db`,0,0,0,0.9847330451011658,0.9930427074432372,0.99516099691391,0.0,accept,unanimous_agreement
1595558529,13243,"we need a finer resolution of expiry after restart, whether the item was expired: 1. during rdb load 2. shortly after by active-expiration 3. later by lazy expiration. and apply this test for listpack and dict.",0,0,0,0.9863042235374452,0.9941179752349854,0.9935812950134276,0.0,accept,unanimous_agreement
1595570271,13243,"right, only that db might be null (in rdb verification scenario).",0,0,0,0.9876530170440674,0.990996241569519,0.9888990521430968,0.0,accept,unanimous_agreement
1595578747,13243,"this is anyway problematic considering how tests are written. when you ""hget"" or ""hgetall"", active expiry spring into action, doesn't it? so it's not really checking expiry on load... is there a way to disable it?",-1,-1,-1,0.5869492888450623,0.7450375556945801,0.7150887250900269,-1.0,accept,unanimous_agreement
1595618622,13243,"same as above, db can sometimes be null",0,0,0,0.982075810432434,0.9910399317741394,0.9918017983436584,0.0,accept,unanimous_agreement
1595640174,13243,"merged, but remove the internal condition outside (this condition is not avoided regardless of its location, but it's simpler to understand when it's not used as a function param imho). the original location was actually to allow saving the ""options"" filed (whether value and/or ttl exists) but since this was deleted, it was indeed wrongly placed.",0,0,0,0.9864553213119508,0.992409348487854,0.9855419397354126,0.0,accept,unanimous_agreement
1595668290,13243,reviewed and merged.,0,0,0,0.981487512588501,0.9898606538772584,0.9860661625862122,0.0,accept,unanimous_agreement
1595668568,13243,fixed as part of the patch,0,0,0,0.9852548837661744,0.992285966873169,0.99418842792511,0.0,accept,unanimous_agreement
1597601335,13243,"fixed by removing dbid, as it was only used for module loading and in that case, the code using it would return before using it if it was in rdb check mode. added a validation db is not null before using it. however, there was some accommodation to do in order to adjust to the option of null db when loading hfe, since db is used to connect all fields with expiry.",0,0,0,0.9886524081230164,0.994350790977478,0.992897629737854,0.0,accept,unanimous_agreement
1597614913,13243,"i fixed the key. also moved setting `o->encoding` into the if. actually current tests caught that and crashed, so it's sort of covered, but i'll add testa for actual active expiry shortly after loading for both dict and listpack, as agreed.",0,0,0,0.9882021546363832,0.9846686720848083,0.98086816072464,0.0,accept,unanimous_agreement
1597617073,13243,"my todo is about len being decreased every iteration, so the expansion is done only for the reaming size. after looking at the expansion code, i think this might be a real bug. , would appreciate your opinion about that.",1,1,1,0.7348868250846863,0.9492011666297911,0.895489513874054,1.0,accept,unanimous_agreement
1601400240,13243,let output parameter `error` at the endo of parameter list?,0,0,0,0.985983431339264,0.9946067929267884,0.9946718811988832,0.0,accept,unanimous_agreement
1601498381,13243,"if i'm not mistaken, these functions declarations are letfovers.",0,0,0,0.987163782119751,0.858441948890686,0.982638955116272,0.0,accept,unanimous_agreement
1601504981,13243,"these two are new added, i guess you keep them when deal with conflict.",0,0,0,0.9573626518249512,0.9821532368659972,0.987854540348053,0.0,accept,unanimous_agreement
1601513301,13243,probably i'm missing something but where do we call this function with keyindb = 0 ?,0,0,0,0.9294137954711914,0.9819611310958862,0.9701650738716124,0.0,accept,unanimous_agreement
1601516477,13243,"[code block]suggestion foreach {type lp_max_entries} {listpackex 512 hashtable 0} { test ""hash field expiration save and load rdb one expired field, ($type)"" { r config set hash-max-listpack-entries $lp_max_entries r flushall r hmset key a 1 b 2 c 3 d 4 r hexpireat key 2524600800 2 a b r hpexpire key 100 1 d assert_encoding $type key ```",0,0,0,0.9797213077545166,0.989039182662964,0.9942635893821716,0.0,accept,unanimous_agreement
1601516699,13243,"this is a leftover from a previous version, i'll remove it. thanks for noticing!",1,1,1,0.9763299226760864,0.9825699925422668,0.989932656288147,1.0,accept,unanimous_agreement
1601519354,13243,"yes, i had these in my pr. then, i removed them. so, leftover declarations from the previous rebase.",0,0,0,0.9868013858795166,0.9867098927497864,0.9930034279823304,0.0,accept,unanimous_agreement
1601525369,13243,i saw you as ronen. didn't you find your avatars are the same except the color.,0,0,0,0.9731336832046508,0.9483203887939452,0.979473888874054,0.0,accept,unanimous_agreement
1601543740,13243,i'd be useful to print log on error. please consider if other error paths need logging as well.,0,0,0,0.982712984085083,0.9831541180610656,0.9937927722930908,0.0,accept,unanimous_agreement
1601545065,13243,maybe we can export `listpackexaddnew()` and `listpackexcreate()` and use it in this file.,0,0,0,0.9880183935165404,0.9940855503082277,0.987435221672058,0.0,accept,unanimous_agreement
1601567353,13243,lol wish there is a way to change the avatar :d,1,1,1,0.9748867750167848,0.986598014831543,0.9934205412864684,1.0,accept,unanimous_agreement
1601571437,13243,"what about let md at the end, like `hash-hashtable-md`, if we add new ones in the future we won't continue these styles.",0,0,0,0.98539400100708,0.99072927236557,0.9918801188468932,0.0,accept,unanimous_agreement
1601585318,13243,"using `listpackexaddnew` would be, imho, not very efficient as it is assumed the hash was already sorted before saving, so each entry read will be added at the end and, so (possibly) the entire listpack has to be traversed for each item. possibly, a ""hint"" parameter can be added to it to so that it will be notified the new field should be added as the last entry, and it will only verify this. wdyt? (i'll try to use `listpackexcreate` reagrdless)",0,0,0,0.961056351661682,0.9834160804748536,0.9458408951759338,0.0,accept,unanimous_agreement
1601608194,13243,"please correct me if i'm wrong, currently we don't read fields ordered by ttl. so, even without `listpackexaddnew()`, we have to fix the current code here as we don't have items ordered? do we have any other option than calling `listpackexaddnew()`?. if field does not have ttl, it will just append the field without traversing it. otherwise, we have to walk over the list as we have to find the correct spot, no?",0,0,0,0.957172691822052,0.8617615699768066,0.8872113227844238,0.0,accept,unanimous_agreement
1601621708,13243,"i guess you're right, order is indeed not guaranteed when reading an object saved as dict, i'll use `listpackexaddnew` instead.",0,0,0,0.984438955783844,0.9797369837760924,0.9823394417762756,0.0,accept,unanimous_agreement
1601653864,13243,"btw a test case for it would be nice. e.g. add listpack 100 volatile and 100 non-volatile elements. verify volatile ones expired after some time. if items are not ordered, active expiry will fail to expire some of the volatile fields.",0,0,0,0.8233147263526917,0.9808746576309204,0.921292245388031,0.0,accept,unanimous_agreement
1601663322,13243,"indeed, `len` not truly represent number of tuples. but there is no bug, only inefficiency. should be a distinction between `ntuples` and `ntuplesleft`. please consider either having it as part of this pr if you don't see any risk. otherwise, let's have it on a distinct pr.",0,0,0,0.9826876521110536,0.9855617880821228,0.9759706258773804,0.0,accept,unanimous_agreement
1601757358,13243,"following this change, it won't convert any more to ht in case of `db` is null. instead i think we should modify `hashtypeconvert()` to accept pointer of `redisdb` instead of `ebuckets hexpires` and let it handle with null. it will simplifes conditions at rdb.c as well.",0,0,0,0.988821029663086,0.9924713373184204,0.9893242716789246,0.0,accept,unanimous_agreement
1601768547,13243,"not sure i follow - what does this change have to do with conversion to dict? any why should we care about conversion to dict when db is null? in this case, the requirement (afaik) is to check rdb validity, the resulting object should be discarded (at least in this repo). what am i missing?",0,0,0,0.9557713270187378,0.9535821676254272,0.6874930262565613,0.0,accept,unanimous_agreement
1601779529,13243,i think we should remove this debug,0,0,0,0.9860952496528624,0.9385746717453004,0.986754596233368,0.0,accept,unanimous_agreement
1601781550,13243,oops...,-1,-1,-1,0.9871377944946288,0.9654041528701782,0.94526207447052,-1.0,accept,unanimous_agreement
1601786735,13243,please write a comment that explains the diff,0,0,0,0.9853253960609436,0.9830365777015686,0.9947576522827148,0.0,accept,unanimous_agreement
1601788680,13243,please give short explanation,0,0,0,0.972317397594452,0.9701244831085204,0.9913158416748048,0.0,accept,unanimous_agreement
1601789416,13243,this comment has become a stale one right?,-1,0,0,0.8595196008682251,0.94391131401062,0.9674763083457948,0.0,accept,majority_agreement
1601792221,13243,give 101 instead of 100 to be clear.,0,0,0,0.9855955839157104,0.982326328754425,0.9857311844825744,0.0,accept,unanimous_agreement
1601795401,13243,we may add a test for dump/restore commands. (i couldn't see one but please ignore if it already exists),0,0,0,0.9640700817108154,0.9899548292160034,0.9944909811019896,0.0,accept,unanimous_agreement
1601796832,13243,"seems like you are doing this validation above, no?",0,0,0,0.9713838696479796,0.9783198833465576,0.9910625219345092,0.0,accept,unanimous_agreement
1601798184,13243,", we have a distinct task for dump restore.",0,0,0,0.985721230506897,0.990715265274048,0.9915944933891296,0.0,accept,unanimous_agreement
1601812077,13243,"right, removed",0,0,0,0.975366234779358,0.9765532612800598,0.9862462282180786,0.0,accept,unanimous_agreement
1601812531,13243,is supposed to be working on this,0,0,0,0.9843385815620422,0.9709051847457886,0.9561924934387208,0.0,accept,unanimous_agreement
1601814110,13243,"please trigger a daily build for your branch. tests that rely on timing might fail on slow environments. to wait something, better approach is using `wait_for_condition`. please consider if it is possible to use in these tests.",0,0,0,0.9841848611831664,0.988904058933258,0.9926645159721376,0.0,accept,unanimous_agreement
1601816012,13243,"you don't miss anything. just saw a change in the logic which i tend to avoid if not necessary at large changes. and in addition to the fact that passing `redisdb` to `hashtypeconvert()` it will relax the condtions at `rdb.c`, made me to write my thought.",0,0,0,0.9075499773025512,0.9633415937423706,0.9556964039802552,0.0,accept,unanimous_agreement
1601818351,13243,"not sure to which validation you are referring: to the comment in the todo, to `db != null` or to `hashtypelength(o, 0) > server.hash_max_listpack_entries`, and where exactly is this happening above?",0,0,0,0.982823610305786,0.9932922124862672,0.9690999984741212,0.0,accept,unanimous_agreement
1601822215,13243,"i was referring to todo: comment. (sorry, while reviewing, i thought comment was on another line)",-1,-1,-1,0.987418293952942,0.990611493587494,0.9698021411895752,-1.0,accept,unanimous_agreement
1601833309,13243,how do i trigger a daily build?,0,0,0,0.9691116213798524,0.9876360297203064,0.9929077625274658,0.0,accept,unanimous_agreement
1601854849,13243,"you should be able do it on your fork here: [a link] daily -> run workflow -> run workflow. (see the descriptions for `jobs to skip`, `tests to skip` sections, write sth dummy to these boxes) for your pr, i triggered one on my fork: [a link] it takes a few hours, fyi.",0,0,0,0.7988042235374451,0.7935751080513,0.990095853805542,0.0,accept,unanimous_agreement
1602506612,13243,"deep_integrity_validation is 1 means that we will not trigger any assertion after loading this datatype. so we should validate the ttl field is a valid integer, otherwise, we should trigger the assertion in listpackexexpiredryrun(). [code block] am i missing something?",0,0,0,0.9878175854682922,0.993910789489746,0.99326890707016,0.0,accept,unanimous_agreement
1602571987,13243,"restore with a corrupt data, and there is a string ttl inside it. when enabling `sanitize-dump-payload`, the restore command shouldn't success. [code block]",0,0,0,0.8953563570976257,0.993100643157959,0.9923957586288452,0.0,accept,unanimous_agreement
1603334749,13243,"after discuss with -kalish , let's deal with this together in restore/dump.",0,0,0,0.9870032668113708,0.9827856421470642,0.9941312670707704,0.0,accept,unanimous_agreement
1603408929,13243,please add a simply comment for this.,0,0,0,0.9829972982406616,0.9872570633888244,0.994743585586548,0.0,accept,unanimous_agreement
1603425721,13243,[code block] seems like you save ttl first.,0,0,0,0.9862972497940063,0.985681176185608,0.9932883381843568,0.0,accept,unanimous_agreement
1603440255,13243,"you're right, it was recently changed, i forgot to update the comment.",0,0,0,0.970306158065796,0.9774463772773744,0.9881225228309632,0.0,accept,unanimous_agreement
1603483508,13243,"maybe we can create hashtable or listpackex directly, instead of creating a listpack then converting to hashtable or listpackex. may a todo comment for future optimize.",0,0,0,0.987446427345276,0.992781698703766,0.988503396511078,0.0,accept,unanimous_agreement
1603486161,13243,"if we exit here and o->encoding is hashtable, does it mean that db->hexpires still retain the robj? but this is also has to do with a corrupt data, we can leave it to another restore/dump pr to do it.",0,0,0,0.9732436537742616,0.9932122230529784,0.9914236664772034,0.0,accept,unanimous_agreement
1603519888,13243,"presumably no, the new object is only added to `db->hexpires` in the following `if` statement, so if the function returns here it was not yet added (and therefore should not be removed, obviously)",0,0,0,0.978590965270996,0.9947763681411744,0.991140067577362,0.0,accept,unanimous_agreement
718368776,9530,what about the null terminator? consider just zstrdup().,0,0,0,0.9850507974624634,0.9913029670715332,0.99309241771698,0.0,accept,unanimous_agreement
718372811,9530,"consider hardware archs that require alignment, i think this might break.",0,0,0,0.7709141373634338,0.9380016922950744,0.9643176794052124,0.0,accept,unanimous_agreement
719075557,9530,"ack, my current plan is to make every 8 byte aligned.",0,0,0,0.9798339009284972,0.7920929193496704,0.9694187045097352,0.0,accept,unanimous_agreement
719079583,9530,"none of this code will exist in the next revision, but i do forget about zstrdup a lot.",0,0,0,0.63487309217453,0.945001780986786,0.905032515525818,0.0,accept,unanimous_agreement
723837408,9530,"after thinking about this more, i don't like it. i'll put the hostname in a separate field. it's probably good to have named values here.",-1,-1,-1,0.965571939945221,0.9663825035095216,0.9534448385238647,-1.0,accept,unanimous_agreement
723837917,9530,"i'm going to also constrain the allowed characters here, to make sure it can be correctly parsed by cluster nodes. (also noticed an extra space)",0,0,0,0.9855501651763916,0.9872711300849916,0.9926502108573914,0.0,accept,unanimous_agreement
736053569,9530,"i didn't end up implementing this because their are arbitrary number of slots, so i kept the original proposal.",0,0,0,0.9686664938926696,0.9121508598327636,0.9469029903411864,0.0,accept,unanimous_agreement
746405266,9530,"probably safer to free `n->hostname` here, the node is not guaranteed to be freshly created (not sure under what conditions though).",0,0,0,0.9852445721626282,0.9895836114883424,0.9801243543624878,0.0,accept,unanimous_agreement
746921786,9530,do we really need `cluster-prefer-hostname`? an alternative is to treat `cluster-announce-hostname` like the other `cluster-announce-` parameters and simply use the hostname instead of the ip whenever it's available. this is not mutually exclusive to the idea of extending `cluster slots` with additional meta-data.,0,0,0,0.9872164130210876,0.9944321513175964,0.994371771812439,0.0,accept,unanimous_agreement
746923794,9530,"looks like `uint16_t` is wrong here, `length` is `uint32_t`. given the flood of int overflows we've encountered i think we should try to stick to `size_t` internally.",0,0,0,0.9755143523216248,0.9821059703826904,0.9810925126075744,0.0,accept,unanimous_agreement
746927344,9530,"not thrilled about relying on `hdr->totlen` to determine that we've reached the last ping ext, it leaves very little room to future changes. maybe `clustermsgdata.ping` could explicitly state the number of extensions included, or specify a `ping_totlen` for that specific payload?",-1,-1,-1,0.6606982350349426,0.5544622540473938,0.9003190994262695,-1.0,accept,unanimous_agreement
746929297,9530,should we be more defensive and not assume the target is already zero-filled?,0,0,0,0.757794201374054,0.983061909675598,0.950520634651184,0.0,accept,unanimous_agreement
746930244,9530,potential overflow?,0,0,0,0.9665296077728271,0.9375947713851928,0.9842618703842164,0.0,accept,unanimous_agreement
746931950,9530,not sure if it's worth doing this estimate vs. always allocating a worst case: it's a short lived buffer so shouldn't impact memory but might actually help reduce fragmentation.,0,0,0,0.8942891955375671,0.9156075716018676,0.8356610536575317,0.0,accept,unanimous_agreement
746932671,9530,"[code block] currently rounding up when already aligned, i assume it's a mistake and not intentional?",0,0,0,0.9311864376068116,0.9684402346611024,0.9902896285057068,0.0,accept,unanimous_agreement
747889211,9530,"(: i did have an earlier check for the number of extensions and you asked if was needed. i can add it back, i think it was a better sanity check.",-1,0,-1,0.7979288101196289,0.957934319972992,0.9471681714057922,-1.0,accept,majority_agreement
748818280,9530,"shame on me :) on the first review, i had a misconception of the cluster bus extension mechanism when and considered it to be completely decoupled from specific message types.",-1,1,1,0.96299010515213,0.9958781003952026,0.9812088012695312,1.0,accept,majority_agreement
754744975,9530,"we do a zcalloc earlier, so i think it's safe to assume it's zero filled.",0,0,0,0.9802457690238952,0.9835608005523682,0.9917488098144532,0.0,accept,unanimous_agreement
754752625,9530,"i'm not sure it's purely analogous to to the announce ips, this is declaring an alternative way to find the node. my original thought for this argument is that in the tls case, you may still want to connect to the node's ip, and if the hostname is available you can use that for hostname validation. you may not want to take a dependency on dns or some other host discovery service.",0,0,0,0.9697373509407043,0.8959073424339294,0.9735255837440492,0.0,accept,unanimous_agreement
754755255,9530,true story.,0,0,0,0.907036066055298,0.9139534831047058,0.9460693001747132,0.0,accept,unanimous_agreement
754755748,9530,"my argument against this is that it adds another two functions which need to stay in sync. it shouldn't really affect fragmentation too much, since the hostname won't really change sizes.",0,0,0,0.6843515634536743,0.9599608182907104,0.9535769820213318,0.0,accept,unanimous_agreement
754800111,9530,"ok, back to having the total number of extensions. we still validate it based off the length as well, but we could obviously change that implementation in the future.",0,0,0,0.9869676232337952,0.9906262159347534,0.9873360991477966,0.0,accept,unanimous_agreement
755966694,9530,it just makes this code a bit more fragile in case it ends up in different code paths in the future.,0,-1,0,0.557117760181427,0.628220796585083,0.7046316266059875,0.0,accept,majority_agreement
755969726,9530,"this is a valid point, but in practice i think these two usually go hand in hand. that is, if you're providing an ip instead of a hostname, you'd probably turn off certificate validation rather than say ""hey, here's the real hostname i expect but did not use for the connect"". i'm ok either way.",0,0,0,0.9512056112289428,0.7695170640945435,0.679709792137146,0.0,accept,unanimous_agreement
762737047,9530,"i'm okay either way as well. the original thought here was that aws we've seen some annoyances with dns caching, so some users only went to have the hostname for sni but not for anything else. this flag mostly covers that case.",0,0,0,0.929282009601593,0.856683075428009,0.8931214213371277,0.0,accept,unanimous_agreement
774806825,9530,"so the 4th element ""additional networking information"" is a map with info-type as the keys? a map can't have duplicate keys, or can it? for multiple ip addresses, duplicate keys are needed.",0,0,0,0.9890796542167664,0.9932823181152344,0.9934275150299072,0.0,accept,unanimous_agreement
774807304,9530,"the type is ""ip"" for ipv4 and ipv6? i think it can be useful to distinguish them as ""ipv4"" etc.",0,0,0,0.9874345660209656,0.990742027759552,0.992684841156006,0.0,accept,unanimous_agreement
774844782,9530,"i'm still of the opinion that we don't want to support multiple endpoints of the same type, so i think a map is fine.",0,0,0,0.9567955136299132,0.9159955978393556,0.970180869102478,0.0,accept,unanimous_agreement
774845497,9530,"we don't really differentiate the different ip types today, i don't want to optimize earlier for that case. we can always extend the map to be ipv4 and ipv6 later.",0,0,0,0.9492437839508056,0.917851448059082,0.9864450097084044,0.0,accept,unanimous_agreement
775014104,9530,"we can add ""ipv4"" and ""ipv6"" later but then we'll need to keep ""ip"" too for backward compat...?",0,0,0,0.9851709008216858,0.9897773861885072,0.9865028858184814,0.0,accept,unanimous_agreement
775048553,9530,"i think having that is ""okay"". we already show just an ""ip"" in multiple places and don't try to distinguish it between versions. we just give them an ip address they can talk to.",0,0,0,0.9441874623298644,0.9422814846038818,0.8964359164237976,0.0,accept,unanimous_agreement
775252616,9530,"we do have a conflict here: * no multiple endpoints of the same type - i agree in principle, we'll just get clients confused. * no specific ipv6/ipv4 types - i agree with that as well, it's not something we currently do. but if i'm forced to choose, i'd give up the first to support ipv4 and ipv6 concurrently, simply because i don't see the real downside of the response format allowing that. not feeling too strong about it though.",-1,-1,-1,0.7735631465911865,0.8527466058731079,0.5169068574905396,-1.0,accept,unanimous_agreement
775277161,9530,"we could also re-evaluate the possibility of not tagging them with a type and let the client figure out what they are. then, we ip versions and multiple of the same type become non-issues.",0,0,0,0.9884467124938964,0.9901955723762512,0.9925621151924132,0.0,accept,unanimous_agreement
775277263,9530,"okay then, but we could also skip tagging them altogether. it's pretty easy for a client to tell a host name and an ip address apart.",0,0,0,0.977584183216095,0.974365532398224,0.9845045804977416,0.0,accept,unanimous_agreement
776000775,9530,"i don't want to push clients to know how to ""parse"" stuff, it's much easier to just do extra_networking['hostname'] as opposed to parsing all of them looking for a hostname.",0,0,0,0.8001475930213928,0.9162931442260742,0.9434911608695984,0.0,accept,unanimous_agreement
776010782,9530,"i don't think the resolution to supporting both ipv4 and ipv6 is to show both of them with the same name and have the clients check all the entries and figure out what they want to do. we only gossip a single ip address on the clusterbus today (which can be ipv6). if we want to introduce more, we would need to a way to name them/announce them, so i think however we resolve that naming would give us a new name to add to this map. i also will probably advocate that if we go down the path of supporting dual stack ipv4 + ipv6 configurations, we just determine which the cluster responds with the same way we do with tls. if a client connects over ipv4, we respond with ipv4, and the same with ipv6.",0,0,0,0.8705227375030518,0.9800437688827516,0.9656968712806702,0.0,accept,unanimous_agreement
776050011,9530,"fine, i got that. (though they may need to parse the primary endpoint which isn't tagged...) the only point i wanted to make is that clients may still need to auto-detect if an ip is ipv4 or ipv6 and now we had a change to tag that information too, but if we don't differentiate between them in other places, then it's fine here too. i don't really prefer anything, just that the available options have been considered, and now they have. i think the map for additional stuff is a very clean and nice format. it's probably future-proof too.",1,1,1,0.9308766722679138,0.911987841129303,0.9649604558944702,1.0,accept,unanimous_agreement
776052272,9530,that is a fair point. statically typed languages will have to deal with it. most dynamic languages usually just allow passing in either and it will figure it out. most of the reason we're doing the new map instead of new fixed position fields is because many clients will pickup the hostname without any changes that way.,0,0,0,0.9652540683746338,0.9346813559532166,0.874825119972229,0.0,accept,unanimous_agreement
776057617,9530,"exactly, in c for example, you use `inet_pton()` with the `af_inet` or the `af_inet6` flag. here's from redis itself: [code block]",0,0,0,0.9883601665496826,0.993674635887146,0.9946413040161132,0.0,accept,unanimous_agreement
776664306,9530,"i just want to point out that as the interface design here involves clients, it is likely to outlive many of the current server-side implementation details. you're basically saying any future extension will need its own new and unique identifier. i'm ok with that.",0,0,0,0.9724100232124328,0.8749861717224121,0.8858315944671631,0.0,accept,unanimous_agreement
794994327,9530,the math doesn't look right. notused1 should be 30 bytes long as opposed to 16 because uint16_t is 2 bytes (16 bits). this will break cluster rolling upgrades.,-1,-1,-1,0.5486628413200378,0.549762487411499,0.7165142893791199,-1.0,accept,unanimous_agreement
795034954,9530,it'd be good to have interoperability tests with different versions.,0,0,0,0.9301114082336426,0.8976442813873291,0.9860825538635254,0.0,accept,unanimous_agreement
795036962,9530,do you want to prepare a pr so we can fix it before 7.0.0-rc1?,0,0,0,0.9876357913017272,0.99458509683609,0.9952228665351868,0.0,accept,unanimous_agreement
795089778,9530,yep i will work on a fix next. i will also add static asserts to make sure that we catch issues like this at compile time in the future. a proper interop test suit would be even better but i feel that it is better dealt with separately.,0,0,0,0.6717469692230225,0.9389538168907166,0.961498498916626,0.0,accept,unanimous_agreement
795098077,9530,pr is [a link],0,0,0,0.9856773614883424,0.9897805452346802,0.9947189092636108,0.0,accept,unanimous_agreement
795141268,9530,any particular reason to not use sds for hostname? it would've eliminated the strlen calls when computing the message size.,0,0,0,0.988061785697937,0.9876869320869446,0.9897136688232422,0.0,accept,unanimous_agreement
795141592,9530,divisions and multiplications are much more expensive than bit operations. can you consider the following instead? 7 is the mask for 8 (2^3 - 1) #define eight_byte_align(size) ((((size) + 7) & (~7)),0,0,0,0.9714022278785706,0.987491011619568,0.973879337310791,0.0,accept,unanimous_agreement
795142121,9530,"if we could institute a universal requirement of 8-byte alignments for all extensions, we could use 16 bits to represent a max of 64k 8-byte blocks, which is 512kb in total size, then the clustermsgpingext could be shrunk by 4 bytes (uint16_t length and unused removed).",0,0,0,0.9878973960876464,0.995162546634674,0.993703544139862,0.0,accept,unanimous_agreement
795144548,9530,"the max hostname length is not a trivial number, i.e., 256 bytes. the non-stop broadcasting of a node's host name in a large cluster increases the overhead on both network and cpus when the cluster is in a steady state. this impact can also grow with more extensions added in the future, it will be great if a generic mechanism could be devised such that the broadcasting of these extensions can be optional and only activated when a change is detected in the cluster (for instance, hostname updates or new node arrivals).",0,0,0,0.876379668712616,0.9909000396728516,0.9442116022109984,0.0,accept,unanimous_agreement
795191130,9530,division by constant 8 is optimized into bit operations anyways so it doesn't matter here.,0,0,0,0.9772451519966124,0.9865732192993164,0.982359766960144,0.0,accept,unanimous_agreement
795191415,9530,please open a new issue or pr. comments on closed prs are not often read by people.,0,0,0,0.9478639960289,0.982245683670044,0.990362584590912,0.0,accept,unanimous_agreement
795308322,9530,you are right. thanks [code block],1,1,1,0.96321702003479,0.97056245803833,0.992923617362976,1.0,accept,unanimous_agreement
795326313,9530,"yeah, generally trust the compiler to do these types of optimizations for you. doing bit shifts is easy to get wrong.",0,0,0,0.9422102570533752,0.9118440747261048,0.9590823650360109,0.0,accept,unanimous_agreement
795326500,9530,i read them :d,1,1,1,0.9658129811286926,0.9175439476966858,0.9935706853866576,1.0,accept,unanimous_agreement
795331615,9530,seems like a reasonable change.,0,0,0,0.9510205388069152,0.9800745248794556,0.9727109670639038,0.0,accept,unanimous_agreement
795332256,9530,"the idea was that we wanted the start of the extension data to still be 8 byte aligned, which means we don't get any benefit by shrinking this since we still need to pad before the start of the data. the data needs to be 8 byte aligned since we want the start of a future extension to also be 8 byte aligned.",0,0,0,0.9810263514518738,0.9858150482177734,0.990270972251892,0.0,accept,unanimous_agreement
795335243,9530,"yeah, i apparently did the math wrong. i did check interoperability on an earlier revision, but i didn't check it after making this change. i created a separate issue to add interoperability tests, [a link]",0,0,0,0.8184254765510559,0.7379090785980225,0.9203375577926636,0.0,accept,unanimous_agreement
796360959,9530,"understand the alignment requirement. i was trying to see if we could save a few more bytes here but if the new ""hostname"" extension can be made optional then this optimization is moot. i think this is good. feel free to resolve/close this comment.",1,1,1,0.971507728099823,0.7124234437942505,0.9680517315864564,1.0,accept,unanimous_agreement
907189733,9530,"here seems `sizeof(clustermsgpingext)` is needless since `gethostnamepingextsize` has counted `sizeof(clustermsgpingext)` in, but it doesn't affect the integrity as `estlen` is just a hint for allocation, larger is fine.",0,0,0,0.963538408279419,0.9905187487602234,0.9887098670005798,0.0,accept,unanimous_agreement
907198143,9530,"are you sure? the `clustermsgpingext` struct ends with a [a link], which is not counted by sizeof. [code block]",0,0,0,0.9873724579811096,0.9952754974365234,0.9951321482658386,0.0,accept,unanimous_agreement
907258450,9530,"[code block] so the l2903 is equivalent to `estlen += sizeof(clustermsgpingext) + sizeof(clustermsgpingext) + eight_byte_align(strlen(myself->hostname) + 1)`, but actually there's only one `clustermsgpingext` header and following a `clustermsgpingexthostname` body",0,0,0,0.98684561252594,0.9943851232528688,0.9924752116203308,0.0,accept,unanimous_agreement
907272649,9530,"ah, i see, it is counted twice.",0,0,0,0.9715381264686584,0.9488841891288756,0.9829939603805542,0.0,accept,unanimous_agreement
1287105271,12453,[code block] just to conform to the style of other lines in that block.,0,0,0,0.985483944416046,0.9919906258583068,0.9904120564460754,0.0,accept,unanimous_agreement
1287106734,12453,"i wonder why this is a ""flag"" and not just a generic ""test and set"" (to work on any integer) to set it, and a plain atomicset to clear it? in which case we won't need to declare the `redisatomicflag` type.",0,0,0,0.9556024670600892,0.9926989674568176,0.9672022461891174,0.0,accept,unanimous_agreement
1287111586,12453,"__atomic_add_fetch seems to be a gcc builtin, while the other primitives we use in this group (e.g. atomic_fetch_add_explicit are c11. i suppose we must not mix them.",0,0,0,0.9858171343803406,0.9809920191764832,0.98805969953537,0.0,accept,unanimous_agreement
1287112830,12453,same goes for the use of __atomic_test_and_set and __atomic_clear below,0,0,0,0.987514317035675,0.994481921195984,0.9947592616081238,0.0,accept,unanimous_agreement
1287114991,12453,"do we really have to have this one? people can easily get that outcome by using atomicgetincr and incrementing the result. a bit convoluted to use, maybe we can do that with a wrapper instead of adding primitives?",0,-1,0,0.8746253848075867,0.6404724717140198,0.9556784629821776,0.0,accept,majority_agreement
1287119424,12453,"we cannot make intel specific assumptions here. at least not without making this code use an alternative sync primitive, or at the very least break the compilation when that's not the case.",0,0,0,0.9499810338020324,0.9788337349891664,0.97174072265625,0.0,accept,unanimous_agreement
1287120947,12453,this whole test can be replaced by simply sending using debug segfault and watching the stack trace of other threads (like bio.c),0,0,0,0.9874581694602966,0.9914727210998536,0.9936407208442688,0.0,accept,unanimous_agreement
1287124060,12453,"a ""get threads stacktrace"" feature is a nice thing to have in redis (not for testing, but for runtime troubleshooting). but, if we can, we better not have it as a command, since redis might be unresponsive, which is the reason why we want to extract a stack trace. i think we should re-use the sigalrm mechanism used by `watchdog-period`, and just enable it on startup regadless of the config. then whenever we want a stacktrace, we just send the signal from command line.",0,0,0,0.9524853229522704,0.9742427468299866,0.966793954372406,0.0,accept,unanimous_agreement
1287128397,12453,"we can't use `bool` and `false`, we need to keep being compatible with c99.",0,0,0,0.9810050129890442,0.9851548075675964,0.990744948387146,0.0,accept,unanimous_agreement
1287134215,12453,don't we need `redisatomic` prefix (for c11 `_atomic`)?,0,0,0,0.9884926676750184,0.994996190071106,0.9933941960334778,0.0,accept,unanimous_agreement
1287216980,12453,according to [a link],0,0,0,0.982950747013092,0.9882408380508424,0.9929147958755492,0.0,accept,unanimous_agreement
1287219265,12453,boolean was introduced in c99 [a link],0,0,0,0.9880268573760986,0.9889378547668456,0.9943081736564636,0.0,accept,unanimous_agreement
1287221513,12453,this is a pre-declaration for the local copy,0,0,0,0.9886464476585388,0.9922630786895752,0.995368242263794,0.0,accept,unanimous_agreement
1287230643,12453,stdatomic.h has its own api for test and set atomicset can be used to clear the flag but atomicflagclear makes the api more robust.,0,0,0,0.9868884682655334,0.989183783531189,0.9932491779327391,0.0,accept,unanimous_agreement
1287985401,12453,"i think it makes it less robust. i.e. an integer api can be used for various purposes as well as handling a boolean, and not the other way around.",0,0,0,0.9828436374664308,0.9705765843391418,0.959234654903412,0.0,accept,unanimous_agreement
1287986728,12453,added this to the following issue [a link],0,0,0,0.9886052012443542,0.9831909537315368,0.9956047534942628,0.0,accept,unanimous_agreement
1287989583,12453,"ok, maybe i misunderstood. this comment applies for the entire block that uses the `_sync` intrinsics, not just the ones you added? i.e. these intrinsics will be supported by the compiler only when using a supported platform, and if not, we'll either choose a different atomic option, or fail to build. so your comment is just meant to improve the description in the code, and it doesn't mean that the changes you made could perform wrongly when not used on intel?",0,0,0,0.8679226040840149,0.969918966293335,0.9376165866851808,0.0,accept,unanimous_agreement
1287991179,12453,"ok, so there must be another reason why we don't use `bool` in redis, but let's stay consistent with the rest of the code, and drop the use of `stdbool.h`",0,0,0,0.9814607501029968,0.9922653436660768,0.9897311329841614,0.0,accept,unanimous_agreement
1287992401,12453,"ohh, i'm sorry. i mixed it with g_thread_ids",-1,-1,-1,0.99016273021698,0.9924641847610474,0.992832899093628,-1.0,accept,unanimous_agreement
1288093740,12453,"hey :) can you please explain what's the purpose of this section and in what scenario it will be activated? according to [a link] i do see that your intention ([a link] was to support earlier versions of gcc, where `stdatomic.h` is missing, and we can't use `_atomic` types. in this case, we compile with std99 in which, as far as i understand, __atomic* functions family are also not included, so we anyway need to choose the __sync* family.",1,1,1,0.9736317992210388,0.9614150524139404,0.9951983094215392,1.0,accept,unanimous_agreement
1288132689,12453,i can replace test and set with exchange but note that atomic_flag is [a link],0,0,0,0.9887857437133788,0.9896842241287231,0.9950090646743774,0.0,accept,unanimous_agreement
1288148911,12453,"it is actually, but i added this comment since there was a misalignment between the gcc doc and the intel guide regarding the return type of `__sync_bool_compare_and_swap` (bool in gcc, int in intel) also, intel describes which types of operands the function expects (int, long, long long, unsigned int, unsigned long, unsigned long long) so yes, only to explain.",0,0,0,0.9872954487800598,0.9927712082862854,0.9943282008171082,0.0,accept,unanimous_agreement
1288150596,12453,but if deop the bool i must use exchange...,0,0,0,0.9005758166313171,0.9888193011283876,0.9912917017936708,0.0,accept,unanimous_agreement
1295579258,12453,"sorry for delayed reply afaik, before gcc11, we just use `_atomic*` functions, it works well when compiling with std99. and when we use old gcc or old redis (before 6.0), i ever found `atomicvar_api:atomic-builtin` in `info` command output. so this section makes sense",-1,-1,-1,0.9844963550567628,0.9883113503456116,0.985631823539734,-1.0,accept,unanimous_agreement
1302745918,12453,"printing stack traces is debug.c responsibility, maybe we can move it back there? (and then we don't need that other forward deceleration)",0,0,0,0.9780178666114808,0.9847179055213928,0.9901485443115234,0.0,accept,unanimous_agreement
1303840633,12453,we will still need a forward declaration to call a setup function upon the server startup (something like `setupsigalrmhandler`. but i do agree that the registration to the signal belongs to debug.c,0,0,0,0.9861226081848145,0.9934266805648804,0.9916565418243408,0.0,accept,unanimous_agreement
1304087149,12453,maybe we should call just one `setupdebugsighandlers` instead of both of these? i.e. some init function for debug.c to do whatever it needs..,0,0,0,0.9867681860923768,0.9935332536697388,0.98756742477417,0.0,accept,unanimous_agreement
1304089774,12453,"did you move this so that it's not under the `======== software watchdog =======` title? i think i'd rather avoid moving big blocks, and add forward declarations if needed. i think it's arguably still ok to b considered part of the ""software watchdog"" code, and the fact it also serves another mechanism is ok.",0,0,0,0.9756396412849426,0.97688090801239,0.974032700061798,0.0,accept,unanimous_agreement
1304116662,12453,yes and also i wanted to group all the signal setups together,0,0,0,0.9813982844352722,0.9847278594970704,0.9932435154914856,0.0,accept,unanimous_agreement
1304127220,12453,we can have `setupdebugsighandlers` that wraps `setupsigsegvhandler` and `setupsigalrmhandler` setupsigsegvhandler still has to be exposed since it is used by `updatesighandlerenabled`,0,0,0,0.9868693947792052,0.9951561689376832,0.9936738014221193,0.0,accept,unanimous_agreement
1304312135,12453,"ohh, i missed that. well, in that case, let's keep what you have now",-1,0,0,0.8938671350479126,0.7851126194000244,0.8517736792564392,0.0,accept,majority_agreement
1304312510,12453,"ohh, i see you changed it.. well, that's ok too.",0,0,0,0.5215284824371338,0.7076138854026794,0.7773477435112,0.0,accept,unanimous_agreement
1304317331,12453,i think now it's better.. also easier to see what's actually changed (the info->si_pid part),0,0,1,0.9308270812034608,0.9513826370239258,0.8779063820838928,0.0,accept,majority_agreement
1304426785,12453,i am also doing my best to write detailed commits descriptions to make the review process easier :),1,1,0,0.8418418169021606,0.9381670951843262,0.9374709129333496,1.0,accept,majority_agreement
1311199589,12453,"we usually put the doc comment next to the implementation, not the forward declaration.",0,0,0,0.9862918853759766,0.9908315539360046,0.9919208288192748,0.0,accept,unanimous_agreement
1311243400,12453,do we assume these two lines are sequential? not sure that's right..,0,0,0,0.5943039059638977,0.7782461047172546,0.8224011063575745,0.0,accept,unanimous_agreement
1314560140,12453,"it is not explicitly guaranteed in the linux documentation, but this is the example format, and in addition, they are grouped together [a link] ![a link] ![a link] anyway, it is safer to not rely on the file order. i'll change it. also i'll add a warning msg in case one of the fields is not found and the test will check that this warning doesn't appear.",0,0,0,0.9794186353683472,0.98698228597641,0.9858558773994446,0.0,accept,unanimous_agreement
1315004810,12453,"i find this logic of this function a bit odd (even though it's probably efficient). maybe it'll be nicer to extract each of these two fields into a variable, and put the logic that looks at the values of these variables after. maybe without a dedicated struct and a dedicated function. like we do argument parsing of a command, e.g. look at `geoaddcommand`. we can break out as soon as we have values for both, or even as soon as we have value for either. wdyt?",0,0,-1,0.7407286167144775,0.7421329617500305,0.8501514196395874,0.0,accept,majority_agreement
1315036839,12453,"my intention was to to discard one `strncmp` after finding one of the fields (unlike `geoaddcommand`) and to make it easier to generalize `is_thread_ready_to_signal` in the future if we decide we want to extract more fields from the file. i can do [code block] this is probably cleaner and considering the fact that sigblk and sigign are probably sequential, it won't affect the performance. but less general",0,0,0,0.9470413327217102,0.9855743646621704,0.989320993423462,0.0,accept,unanimous_agreement
1315061658,12453,"i'd rather that version, doesn't attempt to create some common infrastructure for something that's very specific",0,0,0,0.9506590962409972,0.8238614201545715,0.9595162272453308,0.0,accept,unanimous_agreement
1315417903,12453,"[code block] if `prctl(pr_get_name, trace_data->thread_name);` fail, `trace_data->thread_name` will be uninitialized.",0,0,0,0.9749035239219666,0.9946348667144777,0.9945732951164246,0.0,accept,unanimous_agreement
1315433860,12453,"possible failures of `prctl` in this case are: arg2 is an invalid address. einval the value of option is not recognized. einval arg2 is not valid value for this option. so if it fails, an uninitialized string is our last concern.",0,0,0,0.9231760501861572,0.9776816368103028,0.9877917170524596,0.0,accept,unanimous_agreement
1315460760,12453,"you have a few more of these, please go over them.",0,0,0,0.9792979955673218,0.9599561095237732,0.9574515223503112,0.0,accept,unanimous_agreement
1315462338,12453,that string feels a bit long to me. it could be just `*` or `cur`. wdyt?,0,-1,0,0.9583293199539183,0.8224522471427917,0.9640454649925232,0.0,accept,majority_agreement
1315468531,12453,"did you get to this conclusion empirically? or by some docs? i remember i made a similar assumption about sigsegv, and eventually concluded it was wrong and used `si_code`",0,0,0,0.977182924747467,0.9814265370368958,0.9814987778663636,0.0,accept,unanimous_agreement
1315470460,12453,"maybe we should have an `else` that prints some other title explaining why there's a stacktrace on the log (i.e. even some ""sigalrm received"". also, maybe print `si_code`, `si_pid` etc, like we do on sigsegv?",0,0,0,0.9885795712471008,0.9948375821113586,0.9883018136024476,0.0,accept,unanimous_agreement
1315491511,12453,"maybe we want to print something on timeout?, and maybe also list the threads that didn't respond?",0,0,0,0.9817485213279724,0.9876619577407836,0.9898971319198608,0.0,accept,unanimous_agreement
1315494394,12453,"maybe we can add some additional check to see a stack trace coming from one of the other threads? e.g. we know the bio one is for sure sleeping, right?",0,0,0,0.9808735251426696,0.9926826357841492,0.9873213768005372,0.0,accept,unanimous_agreement
1315608507,12453,a nit pick. :grinning_face: [code block],0,1,1,0.3982654511928558,0.8203135132789612,0.9784873127937316,1.0,accept,majority_agreement
1316739299,12453,"at first, i tried to use `si_code`. on macos, both cases got the same code so i **tried** using `si_pid` and got the behavior described. [a link] here it is described in what cases `si_pid` is populated. it is not explicitly guaranteed that it is not populated if the signal is sent by `setitimer()`. i'll add a test to ensure this is the behavior on all systems/if they decide to change something in the future.",0,0,0,0.9849943518638612,0.993486225605011,0.9878223538398744,0.0,accept,unanimous_agreement
1316765627,12453,"i added ""received sigalr"" to avoid using unsafe formated string functions of view of redis. signals that are going to kill the server anyway and where we need printf-alike features are served by serverlog(). */ void serverlogfromhandler(int level, const char *msg) {",0,0,0,0.9805361032485962,0.9765933752059937,0.9924445748329164,0.0,accept,unanimous_agreement
1316771711,12453,i don't think that there is a simple way to get such a list. we can print the requested tids list and if needed manually compare to the output tids.,0,0,0,0.97504061460495,0.95064115524292,0.9828116297721864,0.0,accept,unanimous_agreement
1316785855,12453,i'm not familiar wit redis bg threads jobs i can add a check that `bioprocessbackgroundjobs` is printed 3 times (is it always 3?),0,0,0,0.7872501611709595,0.9129465222358704,0.9686683416366576,0.0,accept,unanimous_agreement
1316814507,12453,"i remember that it seemed to work at first and then i started noticing in random places that it doesn't. looked like it was just left uninitialized in some cases. i don't think a test will help for ""if they decide to change something in the future"", our old versions will have bugs. we can dig into the kernel code (at least in linux), but i'd rather rely on docs and avoid that speculation. did you say that si_code worked for you too?",0,0,0,0.9359807968139648,0.8969848155975342,0.9224399328231812,0.0,accept,unanimous_agreement
1316816696,12453,so at least print that we bailed on timeout,0,0,0,0.986247718334198,0.962717831134796,0.9208971858024596,0.0,accept,unanimous_agreement
1316818710,12453,"currently we have 3 (always), i'd be ok if we check that we check that we have at least one (that way we can see that we extract a trace not only from the main thread). i guess there's no harm to match it to 3 though.. if we'll ever change the number, the test will fail and we can update it.",0,0,0,0.9532973766326904,0.9113296270370485,0.952156126499176,0.0,accept,unanimous_agreement
1316828167,12453,`*` is ok,0,0,0,0.9720792174339294,0.9759702682495116,0.8823615908622742,0.0,accept,unanimous_agreement
1316843824,12453,"maybe we can add more systems here? i see in config.h we do support more systems, specifically bsd which we have in our ci.",0,0,0,0.947903573513031,0.9927190542221068,0.9886534810066224,0.0,accept,unanimous_agreement
1316857772,12453,"on macos i got the same `si_code` for both sending `kill sigalrm` and timer expiration. btw,: [a link] the si_code generated using the recommended function ([a link] is well-defined",0,0,0,0.9868687987327576,0.9880496859550476,0.990456759929657,0.0,accept,unanimous_agreement
1317122194,12453,"so you're saying that in current code that uses `settimer()` we can't rely on si_code (empirically, it doesn't work), and `si_pid` does seem to work. but by shifting to posix.1-2001, we can resolve that and we can rely on si_code that's explicitly documented. is that right? wdyt?",0,0,0,0.982073187828064,0.9003640413284302,0.9911251664161682,0.0,accept,unanimous_agreement
1317161282,12453,correct,0,0,0,0.9691285490989684,0.8340582847595215,0.98023784160614,0.0,accept,unanimous_agreement
1317197921,12453,all the threads manager logic is protected by a `#ifdef __linux__` macro,0,0,0,0.9881069660186768,0.9949309229850768,0.9938068985939026,0.0,accept,unanimous_agreement
1317227226,12453,"yes, the multi-thread stack trace will only be on linux, but the single thread stack trace can be tested on more platforms (reassure us that we didn't break anything)",0,0,0,0.9770007729530334,0.9915704727172852,0.9902980923652648,0.0,accept,unanimous_agreement
1317415781,12453,aren't all these lines done too early? shouldn't they be run after the `wait_for_log_messages`?,0,0,0,0.9764203429222108,0.9947420358657836,0.9899991154670716,0.0,accept,unanimous_agreement
1317427441,12453,"after the `r debug sleep 1` returns, we know we have a log file, no?",0,0,0,0.98734712600708,0.9882948398590088,0.9937061667442322,0.0,accept,unanimous_agreement
1317489535,12453,"no.. maybe the system is super slow, and redis is starved of cpu time. the code below uses wait_for to wait for the watchdog to kick in and print. so all the other validations should be after",0,-1,0,0.6174579858779907,0.6086621284484863,0.889060914516449,0.0,accept,majority_agreement
1318177480,12453,"ok, but if we get one of these error messages, we will fail to find the stacktraces and not for having the errors, and the test doesn't indicate the actual problem. i changed the test to get a full report by failing the server and after we checked we got to the end of the log report, we can start checking that the backtraces prints succeeded. [code block] i could replace `assert_equal [count_log_message 0 ""failed to open /proc/""] 0` with `catch {wait_for_log_messages 0 {""failed to open /proc/""} 0 100 100}` but in the typical case, where we fail and retry to find a line that doesn't exist because there was no error, the test is very slow.",0,0,0,0.9771767258644104,0.9828587174415588,0.952983856201172,0.0,accept,unanimous_agreement
1335159585,12453,how can we make sure it's safe to allocate memory in a signal handler on all platforms? see the `signal-safety(7)` man page. i think this is also true specifically for jemalloc.,0,0,0,0.9821871519088744,0.9933949112892152,0.99378502368927,0.0,accept,unanimous_agreement
1335159599,12453,why not call `gettid` directly?,0,0,0,0.9782307147979736,0.991293728351593,0.9887077808380128,0.0,accept,unanimous_agreement
1335159815,12453,same comment as above.,0,0,0,0.985135853290558,0.9899691939353944,0.9935632944107056,0.0,accept,unanimous_agreement
1335160215,12453,"also `snprintf()` is not thread safe, which is why `serverlogfromhandler()` avoids using it.",0,0,0,0.9559489488601683,0.9840996265411376,0.991643726825714,0.0,accept,unanimous_agreement
1335160477,12453,probably better to use `path_max` here.,0,0,0,0.9861815571784972,0.9928145408630372,0.9863834381103516,0.0,accept,unanimous_agreement
1335160598,12453,also `fopen()` and the other bufferred i/o functions are not signal safe.,0,0,0,0.9457730650901794,0.982868194580078,0.988498032093048,0.0,accept,unanimous_agreement
1335160845,12453,"the documentation indicates that while `sem_post` is async thread safe, `sem_init` and `sem_destroy` aren't.",0,0,0,0.9867759346961976,0.9941184520721436,0.9933993816375732,0.0,accept,unanimous_agreement
1335227684,12453,`gettid` is not signal safe btw :upside_down_face:,-1,0,-1,0.8532146215438843,0.9827624559402466,0.9657009840011596,-1.0,accept,majority_agreement
1335227776,12453,"opendir, readdir and closedir are not signal safe as well.",0,0,0,0.6992189288139343,0.9786419868469238,0.9736570119857788,0.0,accept,unanimous_agreement
1338201865,12453,seems like a good change - remove an obsolete call and get better/predictable results that are aligned with the documentation.,0,0,1,0.7804844379425049,0.8523390293121338,0.8063027858734131,0.0,accept,majority_agreement
1338444409,12453,"i just wonder if posix.1-2001 is old enough to rely on, or if we already depend on it. i don't want to introduce compatibility issues with exotic or old systems.",-1,-1,0,0.7005543112754822,0.499796599149704,0.9160672426223756,-1.0,accept,majority_agreement
1338461223,12453,i think it's reasonable to rely on it.,0,0,0,0.949005961418152,0.9472357630729676,0.9771919846534728,0.0,accept,unanimous_agreement
1351712161,12453,from the pr description: the threads mngr api is only supported in linux. we use syscall(sys_gettid) and syscall(sys_tgkill...) because their dedicated alternatives (gettid() and tgkill) were added in glibc 2.3.,0,0,0,0.9875217080116272,0.9952772855758668,0.992919385433197,0.0,accept,unanimous_agreement
1382888773,12453,"update on this one: it works fine on linux but for some reason, and although it is supposed to conform to posix std, posix timers api is not supported on mac (i tried it on my local machine) see so thread here [a link] i guess we'll stay with the original timer",0,0,0,0.9011558890342712,0.9802298545837402,0.957954466342926,0.0,accept,unanimous_agreement
1383317041,12453,"i'm ok with keeping the current code (since empirically, it works). or we can (if the code looks clean enough) use timer_create on linux, and fall back to setitimer on other platforms (or only on macos)",0,0,0,0.9808298349380492,0.9654616713523864,0.9533699750900269,0.0,accept,unanimous_agreement
1383374721,12453,"you can take a look here at the linux implementation: [a link] as it includes initialization of a global timer and a different timer struct type, it requires checking the platforms in several locations in the code. not very clean imo also, as the documentation is misleading, i don't really know on which platforms other than linux it is supported",0,-1,-1,0.8470137119293213,0.6091760993003845,0.5093386769294739,-1.0,accept,majority_agreement
1383938813,12453,"ok, indeed it looks like it'll cause too much mess to support both. if we did, i din't mind explicitly using linux for one, or explicitly excluding macos from the other. but since the current one seems working, let's drop it for now. we can always pick it up again in the future",0,0,0,0.5479109287261963,0.6694827675819397,0.5790439248085022,0.0,accept,unanimous_agreement
978296386,11290,what about `createlistpacksetobject` or `createsetlistpackobject`?,0,0,0,0.9871261715888976,0.9949925541877748,0.994543433189392,0.0,accept,unanimous_agreement
978437394,11290,"i don't think we should remove this assertion, maybe we should change it to `(setobj->encoding == obj_encoding_intset || setobj->encoding == obj_encoding_listpack) && setobj->encoding ! = enc`",0,0,0,0.9851014614105223,0.9921277761459352,0.9876205325126648,0.0,accept,unanimous_agreement
978453978,11290,"is it necessary to extract this code, because line 716 has the same code. btw, i found that the lookup operation in `settyperemove` is actually wasteful, because `settyperandomelement` actually already knows the position of the lookedup element, but it looks it up again, maybe in the future we can get the iterator based on the index, and then delete by this iteraotr, so as to avoid these lookups.",0,0,0,0.9229057431221008,0.9853567481040956,0.989837884902954,0.0,accept,unanimous_agreement
978542592,11290,"you're right, that's more in line with the other function names.",0,0,0,0.9794620871543884,0.9499546885490416,0.9846941828727722,0.0,accept,unanimous_agreement
978548248,11290,"since the code in this function now doesn't depend on setobj->encoding anymore, i.e. it uses only generic settype functions, i don't think it makes sense to assert on encoding. it just adds unnecessary logic. perhaps we can assert `(enc != setobj->encoding)`?",0,0,0,0.9651222229003906,0.9836302399635316,0.981116533279419,0.0,accept,unanimous_agreement
978550221,11290,"`createstringobjectfromlonglong` returns a obj_encoding_int with `shared.integers[llele]`, which is what caused some problems in the fuzz testing you helped me resolve. :-)",1,1,1,0.9525033831596376,0.970221757888794,0.967965304851532,1.0,accept,unanimous_agreement
978620081,11290,"yes, possibly. something like `void settypeemitandremove(set, str, len, llele)`? that would be good. perhaps it's material for another pr though?",0,0,0,0.8957498073577881,0.9860808849334716,0.9644104242324828,0.0,accept,unanimous_agreement
979532027,11290,`(enc != setobj->encoding)` sounds good.,1,0,0,0.8756943345069885,0.9834657907485962,0.947376012802124,0.0,accept,majority_agreement
984599365,11290,"before we introduce this. i wonder if we should have the conversation if these are a) tuned anywhere near correctly and b) should we introduce some type of more ""generic"" nob for this that is abstracted from the underlying implementation. we did something similar for expiration, having expiration tenacity instead of low level values.",0,0,0,0.9237104654312134,0.9430514574050904,0.9715036749839784,0.0,accept,unanimous_agreement
993613511,11290,"maybe we can re-use `_lppairsentryvalidation` and `lppairsvalidateintegrityanddups` by passing an argument. i.e. rename, move the `pairs` part to an argument that skips the `((data->count) & 1` check.",0,0,0,0.9886088371276855,0.9959216117858888,0.98665452003479,0.0,accept,unanimous_agreement
993619737,11290,"the null part here might not be right. we're about to convert the whole existing set, not just add a new entry. we can sum the size of all the elements we push to `intsetadd` so we have something close enough. it doesn't have to be 100% accurate since listpack_max_safety_size is set to 2^30 and not 2^31. probably not a realistic concern, but i think it's better to address it. come to think of it, we may be violating set_max_listpack_value too. not with it's default value of 64, but imagine a case where it's set to `3`. so we need to keep track of both max and sum in the loop, so we can use them here.",0,0,0,0.9300605058670044,0.9559569358825684,0.961618959903717,0.0,accept,unanimous_agreement
993622907,11290,"personally, i think this word wrap that took two extra lines is uncalled for. i don't really mind, but just curious: do you really have a monitor that's that narrow, or is your editor misleading you?",0,-1,1,0.8545592427253723,0.8845510482788086,0.8220428824424744,,review,no_majority_disagreement
993624526,11290,need to bump the rdb version,0,0,0,0.9766232967376708,0.990403413772583,0.9916459918022156,0.0,accept,unanimous_agreement
993643256,11290,"considering that `hash-max-listpack-entries` is `512` doesn't the default of `set-max-listpack-entries` needs to be 1024? i.e. in hash it matches the field count (list pack length / 2), but in sets we don't have values, so maybe we can afford a longer linear search? why did you set it to 128?",0,0,0,0.9856303334236144,0.9933515191078186,0.9923886656761168,0.0,accept,unanimous_agreement
993810232,11290,"another case where null is not right, but i'm not sure how to solve that one. maybe some estimation based on the size of the intset and it's maximal value? i.e. we can match the top value in the intset (the number of digits it has) to set_max_listpack_value, and also multiply that with the number of entries, to get some idea of the possible size of the resulting listpack (pass that to lpsafetoadd) again, probably not a realistic concern, especially considering that lpsafetoadd is set on 2^30 not 2^31, but still nicer to handle it correctly.",0,0,0,0.9120284914970398,0.9339900016784668,0.877432644367218,0.0,accept,unanimous_agreement
994152448,11290,"this is a little wasteful. i.e. we already found an item in the set, and we search for it again in order to delete it. i know it was already like that, but arguably searching for an item in a sorted intset, or in a dict is faster than searching in an unsorted listpack. let's try to consider changing that and actually pop items, or somehow keep track of their index for later deletion. [this comment is also applicable for case 3 of spopwithcountcommand, which doesn't use settypeemitremoveandreturnobject, but does settyperemove on the result of settyperandomelement]",-1,0,-1,0.9535172581672668,0.8153866529464722,0.8058499097824097,-1.0,accept,majority_agreement
994172405,11290,"calling settyperandomelement repeatedly when it is listpack encoded is very inefficient. it means that we're iterating to each of the positions in the listpack from scratch, every time. in other types we use lprandompairs which returns a list of random picks, but iterates on the listpack only once. i think we must create a similar mechanism for spopwithcountcommand and srandmemberwithcountcommand",-1,0,0,0.6489343047142029,0.7109843492507935,0.8181167244911194,0.0,accept,majority_agreement
994180872,11290,"maybe we can improve. in case the other set is listpack, there shouldn't be a problem searching with char* and size_t. that part seems easy to improve here. in case the other set is a dict, in theory maybe we can create a dict type that supports non-sds lookup. i'm not sure that part is worth it, but i do hate to see sds creation just for dictfind. let's think about it.",-1,-1,-1,0.8298628330230713,0.9704437255859376,0.9048012495040894,-1.0,accept,unanimous_agreement
994184942,11290,"let's consider improving the insertion efficiency by improving the above call to createintsetobject. we know the cardinality of the dest set in this case. we can do dictexpand on dict encoded sets, and even keep a track of the total size of elements for pre-setting the capacity of lpnew.",0,0,0,0.9847412705421448,0.9911746978759766,0.9896016716957092,0.0,accept,unanimous_agreement
994185087,11290,maybe we can avoid the extra copy and free if we add a settypeadd variant that takes char* and size_t. i.e. specifically for listpack insertion it's a waste.,0,0,0,0.7579606175422668,0.989329159259796,0.9698310494422911,0.0,accept,unanimous_agreement
994211154,11290,"i'll unwrap this. because you're asking: yes, i use large font and a half-laptop wide editor and in other projects i like to keep the limit at 80. ![a link]",1,0,1,0.6897773742675781,0.4932943284511566,0.8012250065803528,1.0,accept,majority_agreement
994264006,11290,"i picked the same value as for `zset-max-listpack-entries`. didn't really analyze it but you're right, we should at least double that. i'll make it 1024 if you think it's the best value. what speaks for a lower value is efficiency, unless those points are solved.",0,0,0,0.9682790637016296,0.9765008687973022,0.97678804397583,0.0,accept,unanimous_agreement
994341386,11290,"interesting, it's odd that hash max entries is 4 times bigger than zset. maybe it's because the zset's listpacks are sorted, unlike the hash ones? i would argue that here was can use double of that, but then question is double of what? double of zset or double of hash? for now, let's take the middle ground, and use 512 (double of zset and same as hash). any further decision will probably need to be based on the typical type of operations done on sets, and some benchmarks.",0,0,0,0.951543629169464,0.7656070590019226,0.8433484435081482,0.0,accept,unanimous_agreement
996425086,11290,good idea. i'll use this upper bound and write the condition something like this: [code block],1,1,1,0.9263334274291992,0.9273566603660583,0.9749720692634584,1.0,accept,unanimous_agreement
996428917,11290,"good idea. i'll unify the callback function and also the validation functions for pairs and non-pairs, i.e. change `lppairsvalidateintegrityanddups` to [code block]",1,1,1,0.9431486129760742,0.8936247825622559,0.9669445753097534,1.0,accept,unanimous_agreement
996428961,11290,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
996656049,11290,maybe we can add a assert `intsetlen(subject->ptr) != 0`?,0,0,0,0.9875547289848328,0.9952164888381958,0.9933502078056335,0.0,accept,unanimous_agreement
996763214,11290,"yes, i believe this is where the [a link] build failed. if there can be an empty intset here, i think we need maxelelen = 0 instead of an assert.",0,0,0,0.9774128794670104,0.987114191055298,0.9917349815368652,0.0,accept,unanimous_agreement
999514232,11290,"done, and a variant for adding ints. variants of `settypeismember()` and `settyperemove()` would also allow skipping some temporary sds values (but i'll handle the other cr comments first).",0,0,0,0.9889393448829652,0.9949918389320374,0.9947052597999572,0.0,accept,unanimous_agreement
999529436,11290,how do you mean? we don't know the cardinality of dstset until we have computed the intersection. what am i missing?,0,0,0,0.931635081768036,0.7322695255279541,0.9911899566650392,0.0,accept,unanimous_agreement
999704185,11290,"don't recall, maybe i was wrong. maybe we can benefit from setting it to be initially large (according to the size of the first set (which is the smallest), and then scale it down at the end? i.e. trade repeated rehashing and realloc for one?",0,0,0,0.9633181095123292,0.9859452843666076,0.93552964925766,0.0,accept,unanimous_agreement
999796399,11290,"theoretically subelelen should go instead of null, and maxelelen as the second argument, but that's not possible (the function takes a listpack pointer. however, since lpsafetoadd only cares about the sum, that doesn't make any difference maybe we should put a comment to avoid any future confusion?",0,0,0,0.9819167256355286,0.9923961758613586,0.9820187091827391,0.0,accept,unanimous_agreement
999799003,11290,lets add a comment that we're estimating a worse cause (overshoot),0,0,0,0.7986440658569336,0.8857361078262329,0.9855977892875672,0.0,accept,unanimous_agreement
999814200,11290,maybe use long_str_size from util.h?,0,0,0,0.9868710041046144,0.9945271611213684,0.9921938180923462,0.0,accept,unanimous_agreement
1001975753,11290,i'm replacing this function with a function `settypepop` with a specialized case for listpacks. it's a much better abstraction. thx,0,0,1,0.922333836555481,0.6588915586471558,0.9548548460006714,0.0,accept,majority_agreement
1001978975,11290,"i'm replacing all usages of repeated `settyperandomelement()` for listpacks with new listpack functions `lpnextrandom()` (for unique sampling as a kind of iteration, a refactoring of lprandompairsunique) or `lprandomelements()` (non-unique sampling) that i've added in the last commits.",0,0,0,0.9874514937400818,0.9921912550926208,0.9934232234954834,0.0,accept,unanimous_agreement
1002668572,11290,"let's use lp_malloc, lp_free (things changed recently on unstable)",0,0,0,0.9890848994255066,0.9909834861755372,0.9938408136367798,0.0,accept,unanimous_agreement
1002669658,11290,maybe it'll be nicer for the interface to return listpackentry like the other similar methods?,0,0,0,0.9840095043182372,0.9937434792518616,0.9853111505508424,0.0,accept,unanimous_agreement
1002670459,11290,"now the comment above about ""the probability we pick it is the quotient of the count"" isn't needed here. imho",0,0,0,0.9832016825675964,0.9879953265190125,0.989900529384613,0.0,accept,unanimous_agreement
1002670787,11290,"let's drop ""dict""?",0,0,0,0.9820795059204102,0.9898057579994202,0.9925124645233154,0.0,accept,unanimous_agreement
1002676292,11290,maybe `settypepoprandom` or `settyperandompop` is slightly better name?,0,0,0,0.9873344898223876,0.9926241636276244,0.9892821311950684,0.0,accept,unanimous_agreement
1002677065,11290,"in some cases, these deletions can cause repeated re-allocation and memmove. maybe we can some day make it more efficient some day, by marking tomstones, and them do one set of memmoves to the final positions at the end of all deletions. let's leave if for last, or some future pr...",0,0,0,0.9231446385383606,0.9814441204071044,0.9821324348449708,0.0,accept,unanimous_agreement
1002677983,11290,maybe use `settypeaddint` instead of creating an sds here?,0,0,0,0.9879915118217468,0.9949471354484558,0.9924119114875792,0.0,accept,unanimous_agreement
1002679056,11290,"let's make sure that the tests we have for randomness, cover all encodings.",0,0,0,0.9835912585258484,0.988933801651001,0.9892627596855164,0.0,accept,unanimous_agreement
1002765889,11290,"yes, i'm not done with this refactoring. i want to replace settypeaddint and settypeaddbuf with a settypeaddaux(set, str, len, llval, str_is_sds) which better matches the interface of settypenext where str == null means use llval instead. and similar for is-member and remove. it'll be simpler and nicer, i promise.",0,1,1,0.8241786956787109,0.6128114461898804,0.7821813821792603,1.0,accept,majority_agreement
1002766467,11290,"yes but a listpackentry is three words instead of one, so i thought it's wasteful. perhaps refactor the listpackentry functions towards element pointer instead?",-1,0,0,0.5323622822761536,0.8983120918273926,0.9553757309913636,0.0,accept,majority_agreement
1002895756,11290,"the difference is that it saves you the effort to later call lpget. are you worried from memory efficiency? listpacks are meant to be small, i don't think this matters. what could matter is if in some cases you either in some cases you don't need to decode all entries you got (just some of them), so the lpget is excessive, or if you need the actual pointer in order to delete records and such.",0,0,0,0.9212098717689514,0.9263753890991212,0.9811115860939026,0.0,accept,unanimous_agreement
1002971028,11290,"fine, i'll use listpackentry for this.",0,0,0,0.9813499450683594,0.9707182049751282,0.9729328155517578,0.0,accept,unanimous_agreement
1003972098,11290,"when remaining > lplength(lp), p will be null. perhaps we should add `if (!p) break;` or assert? and add some unittest for this in redis_test. i see that some places have assert, but others don't. is it missing?",0,0,0,0.9846845269203186,0.9924210906028748,0.9918093085289,0.0,accept,unanimous_agreement
1004076557,11290,i omitted error handling in the loop to make the example simpler. i can add `assert(remaining <= lplength(lp))` in the beginning of the example as a precondition. it will prevent all of these problems. i should probably add a redis_test for this too. good idea.,1,1,1,0.95626300573349,0.8495757579803467,0.9643315076828004,1.0,accept,unanimous_agreement
1004077206,11290,"btw, if you think i should add more asserts in the implementation, please mark them. i didn't think very much about this.",-1,0,0,0.5312919616699219,0.9159690141677856,0.9715025424957277,0.0,accept,majority_agreement
1004080779,11290,like here,0,0,0,0.9794307351112366,0.9507298469543456,0.9712543487548828,0.0,accept,unanimous_agreement
1004084139,11290,"does it also need to be like other places `serverassert(p = lpnextrandom(lp, p, &index, count--, 0))`?",0,0,0,0.9887701272964478,0.9919543862342834,0.9948571920394896,0.0,accept,unanimous_agreement
1004134498,11290,"we already know that count < size and count > 0 here, so it can't return null here. perhaps `assert(count < size)` before the loop? assert after every call to listpack functions seems excessive. the we should also assert p != null after lpdelete, lpnext, etc. there are already some asserts inside lpnext, etc.",0,0,0,0.9789026975631714,0.992106556892395,0.9849020838737488,0.0,accept,unanimous_agreement
1004372207,11290,listpack can hold native integers as well (without converting them to string),0,0,0,0.9881492853164672,0.9934127926826476,0.994307577610016,0.0,accept,unanimous_agreement
1004380237,11290,"tombstones in listpack would be a different pr. :-) we can use some of the unused bit patterns: 1111|0101 to 1111|1110 are currently not used. we can fill the unused space with one of these bytes repeated. another option is to create a tombstone element which can be skipped by it's size, e.g. <11111101, tombstone-size, unused-space, element-total-length>",1,1,1,0.964727520942688,0.9784145951271056,0.9764594435691832,1.0,accept,unanimous_agreement
1004416424,11290,"another alternative is that we can save the offset of p(p - lp) that needs to be deleted, and then eventually delete them from right to left, which also avoids having to traverse the listpack again when cleaning up.",0,0,0,0.9852924942970276,0.992694616317749,0.9911044836044312,0.0,accept,unanimous_agreement
1004465741,11290,"in theory, lpfind can be adjusted to search by integer, and then we can avoid converting the integer here to string, and then back to integer inside lpfind. let's leave that idea out for now, and consider it last. same applies for settypeismemberaux",0,0,0,0.9836336970329284,0.9935061931610109,0.9910008311271667,0.0,accept,unanimous_agreement
1004467755,11290,"missing a top comment. also, the new ""aux"" functions you added don't document the return value.",0,0,0,0.9661144018173218,0.983024001121521,0.9625503420829772,0.0,accept,unanimous_agreement
1004764676,11290,"right, there is already `lpappendinteger`. i'll use it.",0,0,0,0.9856364727020264,0.9900766015052797,0.993104875087738,0.0,accept,unanimous_agreement
1004766445,11290,"there are already lpappendinteger, lpprependinteger, lpinsertinteger, lpreplaceinteger. following this convention, i guess it makes sense to create the functions lpfindinteger and lpdeleteinteger.",0,0,0,0.9877580404281616,0.98957496881485,0.9925094842910768,0.0,accept,unanimous_agreement
1004820498,11290,we need lpfindinteger before using lpappendinteger. i'll leave this out for now.,0,0,0,0.9825605750083924,0.9909111857414246,0.9951252341270448,0.0,accept,unanimous_agreement
1004850100,11290,"i did a ""minioptimization"", using lpappendinteger instead of lpappend if str == tmpbuf (which means we had an integer originally but converted it to string for lpfind).",0,0,0,0.9889771342277528,0.991868257522583,0.9927485585212708,0.0,accept,unanimous_agreement
1005620508,11290,this can be done in the other `lpappend` above too.,0,0,0,0.9891645312309264,0.9942627549171448,0.9958016276359558,0.0,accept,unanimous_agreement
1005627267,11290,"lpdelete takes `p`, so as soon as we have `lpfindinteger` that's enough. then we can use it in settyperemoveaux, settypeismemberaux, and improve the partial optimization in settypeaddaux. again, we can leave this for last or future effort.",0,0,0,0.987093985080719,0.9886210560798644,0.992355465888977,0.0,accept,unanimous_agreement
1005814511,11290,"ah, right",0,0,0,0.919791579246521,0.6934537291526794,0.9854475855827332,0.0,accept,unanimous_agreement
1006697366,11290,missing tests for 'hashtable' added in the last commit.,0,0,0,0.9465535879135132,0.9924817085266112,0.9885000586509703,0.0,accept,unanimous_agreement
1012903843,11290,"i'm dismissing the comment for now (the part about creating a dict type in which we can search with char* and size_t). we have others like this in redis, if we some day pick this up we'll be able to find that one too. ok?",0,0,0,0.8444052338600159,0.983216106891632,0.8709093928337097,0.0,accept,unanimous_agreement
1012908756,11290,"yes, i didn't mean adding tombstones feature to listpack, just that we somehow keep track of what we want to delete, and then delete it in one go. i.e. add an lpbatchdelete that takes an array, and avoid unnecessary memmove (avoid moving the same byte several times), and does only one realloc.",0,0,0,0.9814395308494568,0.9869085550308228,0.9925310015678406,0.0,accept,unanimous_agreement
1013114272,11290,"you mean we leave it for later? then i agree. there are plenty of places where an sds string is created just for a dict lookup. it deserves a pr of its own, perhaps in combination with other changes to dict which are discussed in various places.",0,0,0,0.9564654231071472,0.9503238201141356,0.9881524443626404,0.0,accept,unanimous_agreement
1013154354,11290,"ok, i get it. there will be only one realloc but we need an allocation for the temporary array of elements that we need to pass to lpbatchdelete. this is about spopwithcountcommand where lpdelete is called in a loop in two places. i can attempt this now if you want...",0,0,0,0.9649718999862672,0.9742364883422852,0.9490572810173036,0.0,accept,unanimous_agreement
1013219808,11290,"yeah, please give it a try..",0,0,0,0.8788756728172302,0.8421812057495117,0.50531005859375,0.0,accept,unanimous_agreement
1013422695,11290,"the dstkey set is created as an intset because if the intersection contains only integers (even if the source sets don't), intset the right encoding for dstkey. we don't have any code for converting to intset from the other encodings. if we create a listpack of the same capacity as the first set (if the first set is a listpack), then we will not be able to convert it down to intset later (unless we add code for converting listpack to intset).",0,0,0,0.9870471954345704,0.991898775100708,0.993044912815094,0.0,accept,unanimous_agreement
1013987446,11290,"forgot to free `ps` (also in ""case 3)",0,0,0,0.9413965940475464,0.9922975897789,0.932673990726471,0.0,accept,unanimous_agreement
1014009761,11290,"i'll try this and add code for converting to intset. if the first set is a listpack, it means it has some non-integer member and it probably means the result is not only integers either, in most cases, so it can be a good heuristic.",0,0,0,0.8716641068458557,0.9785960912704468,0.9885059595108032,0.0,accept,unanimous_agreement
1014019297,11290,"we need to keep in mind that insertion into intset can be expensive if done out of order (since its sorted it means insert rather than append), it would end up being beneficial if it remains an intset, but a waste if it is later converted. on the other hand, if we start with a listpack, we can append out of order, and sort into an intset only if needed. i'm starting to think that in order to make this efficient, we need quite a lot of heuristics, and code to handle it differently depending on the input sets sizes and encoding. (so maybe it's better to give it up)",0,0,0,0.8168841600418091,0.919944703578949,0.942678451538086,0.0,accept,unanimous_agreement
1014491048,11290,"thx, yeah i found out from the failed ci.",0,0,0,0.9446593523025512,0.9728782773017884,0.9903263449668884,0.0,accept,unanimous_agreement
1014492452,11290,i've pushed a commit attempting some heuristic on this. please have a look.,0,0,0,0.9472143650054932,0.8654375076293945,0.988178551197052,0.0,accept,unanimous_agreement
1017545315,11290,"we discussed this in a core-team meeting. we decided that since we don't know how the existing defaults were tuned, and we don't know what to set for the new defaults, we'll take a conservative approach of using 128, so that the performance impact compared to the previous releases is lower (and also the memory benefits). we decided that even if we some day want to add more ""generic"" controls on all of these, it should be in a separate pr were we handle all these tunables, so we leave it out for now.",0,0,0,0.9435122609138488,0.9916197061538696,0.9753163456916808,0.0,accept,unanimous_agreement
1018617352,11290,"fyi. the two below tests both missing lpfree, fix it in #11492",0,0,0,0.985571265220642,0.979074001312256,0.9898327589035034,0.0,accept,unanimous_agreement
1018785674,11290,:facepalm: thanks for fixing it!,1,1,1,0.9762840867042542,0.9784041047096252,0.9884810447692872,1.0,accept,unanimous_agreement
768574744,9938,"i think the more commonly used pattern is nicer and will also result in less changed lines. i.e. all the code keeps using the stack based var, and we have an `if (rdbver_ptr) *rdbver_ptr = rdbver;` in one place.",0,0,0,0.9802657961845398,0.9781278371810912,0.966670036315918,0.0,accept,unanimous_agreement
768577251,9938,"i now realize that since functions are saved to the rdb, we need to do `server.dirty++` (to trigger a periodic save later). so this comes in place of `forcecommandpropagation`, and probably applies in the other function sub-commands. i guess it doesn't come instead of `may-replicate`, since we may not want to mark this as a `write` command.",0,0,0,0.9242749810218812,0.9923612475395204,0.9869763255119324,0.0,accept,unanimous_agreement
768581975,9938,"maybe there's a use case for merging functions from two sources, or failing when a function already exists? in which case we need a `replace` argument, and to return an error when there's a name collision (of a function name or library name)?",0,0,0,0.983732044696808,0.9935874938964844,0.983961820602417,0.0,accept,unanimous_agreement
768586487,9938,"can you review this code, and also maybe advice how to test it? seems that the cluster tests don't use `redis-cli --cluster add-node`.",0,0,0,0.9878972768783568,0.993804693222046,0.992957592010498,0.0,accept,unanimous_agreement
769362805,9938,"if returns `c_err`, `dictreleaseiterator` will not be called.",0,0,0,0.9812158942222596,0.9911523461341858,0.9944459199905396,0.0,accept,unanimous_agreement
769829378,9938,maybe we should always do merge (and raise error on collision) and if the user wan replace he can do `function flush` before sending the `function restore`?,0,0,0,0.9880738854408264,0.9944306015968324,0.9888572096824646,0.0,accept,unanimous_agreement
769846321,9938,"replace (overriding some functions), is not the same as flush + restore. i.e. since restore carries multiple functions",0,0,0,0.98481547832489,0.9863662719726562,0.9892873764038086,0.0,accept,unanimous_agreement
769849911,9938,"ok so you want the user to use `function flush` anyway in case he wants a full replacement of the functions set. and also allow the user to specify replace argument to replace collides functions, so: `function restore [replace] `? looks good?",0,0,0,0.898926317691803,0.9448575377464294,0.6429752707481384,0.0,accept,unanimous_agreement
770027474,9938,"yes, i suppose we don't need a merge argument, since the user can use flush in multi? still maybe it's more convenient to have some atomic option for merge or flush",0,0,0,0.981021523475647,0.9840213656425476,0.9899817109107972,0.0,accept,unanimous_agreement
770216581,9938,also missing the helpful documentation right above the function that indicates arguments :),0,1,0,0.7799752950668335,0.9872344136238098,0.8413720726966858,0.0,accept,majority_agreement
770217426,9938,we are just checking the version here right?,0,0,0,0.9873973727226256,0.9901789426803588,0.9927767515182496,0.0,accept,unanimous_agreement
770218161,9938,these need to be updated too.,0,0,0,0.978394091129303,0.985657513141632,0.9936671853065492,0.0,accept,unanimous_agreement
770219493,9938,"we should probably check that there are no existing functions, like we do with data in clustermanagernodeisempty, or multi-exec the a flush along with this.",0,0,0,0.9881979823112488,0.9930452704429626,0.993152379989624,0.0,accept,unanimous_agreement
770220499,9938,"yeah, since all of the cluster tests rely a fixed 20 nodes, it's not surprising that it wasn't tested. it's probably easier to create a test in the old framework that starts up a small cluster, and adds in a new node.",0,0,0,0.9524735808372498,0.9809118509292604,0.9765341281890868,0.0,accept,unanimous_agreement
770275074,9938,it should also verify the checksum.,0,0,0,0.9868567585945128,0.9933850169181824,0.995049774646759,0.0,accept,unanimous_agreement
770276933,9938,"since this dump contains multiple functions (or soon to be libraries), i wanna extend function restore with some argument like: flush - completely replace all existing functions append - add non-existing ones, and fail if there are conflicts replace - add non-existing ones, and override existing ones. in this case, add-node can use flush wdyt?",0,0,0,0.9882665276527404,0.9779728651046752,0.9848291277885436,0.0,accept,unanimous_agreement
770277565,9938,"by ""old"" you mean `tests/unit/cluster.tcl` that i recently created? or `tests/cluster/tests`?",0,0,0,0.984309196472168,0.993783712387085,0.9915617108345032,0.0,accept,unanimous_agreement
770476487,9938,i think it makes sense.,0,0,0,0.9574840664863586,0.8977321982383728,0.8290268778800964,0.0,accept,unanimous_agreement
771930520,9938,version + checksum,0,0,0,0.9877127408981324,0.9837583899497986,0.9938992261886596,0.0,accept,unanimous_agreement
771968894,9938,fixed accordingly and updated top comment.,0,0,0,0.9843085408210754,0.990956962108612,0.9918888211250304,0.0,accept,unanimous_agreement
771968909,9938,"done, thanks.",1,1,1,0.727206826210022,0.6998467445373535,0.5576635599136353,1.0,accept,unanimous_agreement
771968948,9938,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
771969096,9938,"let's add a comment saying that when it fails, error output is mandatory, and that releasing it is the responsibility of the caller. another possibility is to avoid dynamic string, and just return static ones.",0,0,0,0.9828197360038756,0.9923365712165833,0.9947847723960876,0.0,accept,unanimous_agreement
771969215,9938,why aren't we setting the error in this case?,0,0,0,0.9382123351097108,0.9506489634513856,0.9786229133605956,0.0,accept,unanimous_agreement
771969495,9938,"fixed, not resolving so you can review the documentation.",0,0,0,0.9854254722595216,0.9886528849601746,0.9855249524116516,0.0,accept,unanimous_agreement
771969511,9938,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
771969524,9938,"fixed, thanks.",1,1,1,0.7894600033760071,0.8161105513572693,0.623163640499115,1.0,accept,unanimous_agreement
771969544,9938,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
771969591,9938,"fixed, not resolving so you can review the changes.",0,0,0,0.9851978421211244,0.9855452179908752,0.9846943020820618,0.0,accept,unanimous_agreement
771969635,9938,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
771969662,9938,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
771969857,9938,"added flush, append, and replace options according to this comment [a link]",0,0,0,0.9886519312858582,0.9898871779441832,0.9955235719680786,0.0,accept,unanimous_agreement
771969882,9938,maybe make sure to nullify `err` on success? maybe make `err` an optional argument?,0,0,0,0.984876275062561,0.9932873845100404,0.9932069182395936,0.0,accept,unanimous_agreement
771970125,9938,"i don't like the fact that we rely on `err` to be set in order to know we failed. it would be ok if it's all local to this function, but then we need to make sure to set it manually, if `rdbfunctionload` fails and doesn't set it.",-1,-1,-1,0.976296067237854,0.8944173455238342,0.9767054915428162,-1.0,accept,unanimous_agreement
771970354,9938,"not sure how to proceed here, should i add tests for adding node to the cluster? maybe it should be a separate pr?",0,0,0,0.9064125418663024,0.975377917289734,0.8181241154670715,0.0,accept,unanimous_agreement
771970643,9938,"is the append/flush/replace an optional or mandatory arg? if it's optional, it must be last, if it's mandatory, then just put 4 here",0,0,0,0.9886884093284608,0.9936686158180236,0.9946817755699158,0.0,accept,unanimous_agreement
771971883,9938,"i saw that on redis-cli line comments are used all around, should i still change it?",0,0,0,0.9884400367736816,0.9914203882217408,0.9935657382011414,0.0,accept,unanimous_agreement
771972095,9938,"its optional, but i prefer not to put it last so the blob could be used with `-x` argument on `redis-cli`. we have this pattern on `function create` where `replace` is optional and comes before the code. if you do not like it here maybe you do not like it there either?",0,0,0,0.7548068165779114,0.9528949856758118,0.9899060130119324,0.0,accept,unanimous_agreement
771972361,9938,it is set by `functionscreatewithfunctionctx`,0,0,0,0.9859420657157898,0.994489312171936,0.9951629638671876,0.0,accept,unanimous_agreement
771972559,9938,"it can not be a static string because it might be set by the engine itself (telling the user where the code failed compilation for example), will document it.",0,0,0,0.9882460236549376,0.9888867735862732,0.990114688873291,0.0,accept,unanimous_agreement
771972869,9938,thought to spare the extra argument but i can add another argument that indicate failure.,0,0,0,0.9771958589553832,0.9770085215568542,0.9899583458900452,0.0,accept,unanimous_agreement
771973370,9938,"i suppose it has some line comments by mistake (too many different hands worked on it, and some maybe without aggressive review) [code block]",0,0,0,0.9782924056053162,0.9337518215179444,0.9539687633514404,0.0,accept,unanimous_agreement
771973443,9938,will make sure to set an error message in case its not set.,0,0,0,0.9843712449073792,0.9874881505966188,0.9908698201179504,0.0,accept,unanimous_agreement
771973557,9938,"ok, will make it optional.",0,0,0,0.9852676391601562,0.9874854683876038,0.994986057281494,0.0,accept,unanimous_agreement
771973790,9938,"or make sure that when rdbfunctionload returns an error without setting `err`, you're setting it yourself. (better not trust the implementation of another function)",0,0,0,0.9096096158027648,0.9908192753791808,0.9912692308425904,0.0,accept,unanimous_agreement
771974598,9938,"ohh, i see the code now. so we're reserving the last argument to the code payload, and any extra arguments in between restore and the payload could be modifiers (more can be added in the future). kinda like [a link] (last argument is always timeout, and any args in between are keys). i think it's a bit awkward. also, in normal restore the payload is not necessarily the last argument. maybe we don't absolutely have to have it last? i.e. you wanted the user to be able to put the function code in a file and use `-x`, but maybe we're willing to waive that?",0,-1,-1,0.5195755362510681,0.9280277490615844,0.956518054008484,-1.0,accept,majority_agreement
771975557,9938,"i thought it make sense to build the commands such that we can use the `-x`, i believe `restore` should have also built this way. another option is to extend `redis-cli` with `--restore-functions` option (like we have for --eval).",0,0,0,0.9860159754753112,0.9885587692260742,0.9907163977622986,0.0,accept,unanimous_agreement
771975736,9938,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
771975780,9938,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
771976155,9938,"well, you know what.. i agree with you. commands with huge binary payloads should be designed so that they have that as a last argument... or maybe another alternative is to enhance the `-x` feature. it could be `-x1` and `-x-1` (i.e. to denote injecting the argument at a certain offset from the start or the end). or it could be `-x ` like `redis-cli -xpayload function restore payload << payload.dump`",0,0,0,0.9602335691452026,0.7806565761566162,0.9267622828483582,0.0,accept,unanimous_agreement
771976402,9938,"did you mean to test and set `err`? or pass `error` to `functionscreatewithfunctionctx`? something here seems odd, maybe we don't want to have both variables, or just one internally for the function, and handle the output arg only at the end.",0,0,0,0.8640047907829285,0.9731342792510986,0.8550418615341187,0.0,accept,unanimous_agreement
771976956,9938,"thinking about this more, if it was possible to change restore in a way that the payload is always the last argument, i'd go for it. but since it's not possible, and actually that -x feature is just an odd feature of redis-cli, maybe we should indeed improve redis-cli to be able to inject stdin at any position like my placeholder idea above, and not worry about the position of that argument in the comment (we don't need to design command according to limitations of redis-cli)",0,0,0,0.9650286436080932,0.9658817052841188,0.9658809900283812,0.0,accept,unanimous_agreement
771976965,9938,"this is how it is done, `error` is the local variable that used everywhere and `err` is the output parameter that is set at the end with the value of `error` (if given). did i missed something?",0,0,0,0.9850913882255554,0.994900405406952,0.994493007659912,0.0,accept,unanimous_agreement
771977160,9938,we're good.. it's just that i looked at an intermediate commit.,1,0,1,0.956806182861328,0.5645102858543396,0.5420363545417786,1.0,accept,majority_agreement
771977167,9938,"convinced, will change flush|append|replace to be last argument.",0,0,0,0.9852349758148192,0.9929613471031188,0.994005799293518,0.0,accept,unanimous_agreement
771978459,9938,fixed and updated top comment.,0,0,0,0.984725296497345,0.989083468914032,0.9892082810401917,0.0,accept,unanimous_agreement
771988449,9938,"are you sure flush should be the default? maybe append is the safest. that's the only one that doesn't delete old data (it errors instead).. either way, let's document that in the top comment and maybe help message",0,0,0,0.977792263031006,0.986075222492218,0.9868836998939514,0.0,accept,unanimous_agreement
771988539,9938,"i think ""old"" and ""new"" are mixed",0,0,0,0.9813979864120485,0.9699259400367736,0.9657281041145324,0.0,accept,unanimous_agreement
771989186,9938,the append/replace/flush argument is missing,0,0,0,0.9853142499923706,0.990413248538971,0.9954043626785278,0.0,accept,unanimous_agreement
771992855,9938,changed default to append.,0,0,0,0.9770928621292114,0.988642394542694,0.9929186701774596,0.0,accept,unanimous_agreement
771992874,9938,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
771992895,9938,"thanks, added.",1,1,1,0.5709743499755859,0.794124960899353,0.6461454033851624,1.0,accept,unanimous_agreement
772661245,9938,consider describing how we construct the binary blob and why it requires an explicit crc64 appended to it.,0,0,0,0.9807685017585754,0.9911802411079408,0.9896981120109558,0.0,accept,unanimous_agreement
772662033,9938,wouldn't it make more sense to have the blob as the last argument? that will work better with `redis-cli -x` and may also be useful if we'll handle streaming of arguments in the future. it should not be hard to disambiguate any of these keywords from an actual blob.,0,0,0,0.9806641340255736,0.993588089942932,0.9931432008743286,0.0,accept,unanimous_agreement
772662667,9938,i think it's a bit awkward to define a preprocessor macro in what *appears* to be a function context. suggest to just define an enum.,-1,-1,-1,0.7735075950622559,0.9423977136611938,0.9515374898910522,-1.0,accept,unanimous_agreement
772675267,9938,"having the blob as last argument means that either the modifier args are non-optional, or they're optional, and we know they're not the blob just because the blob is mandatory and there are more args. kinda reminds me of blpop where the timeout is the last arg, and anything before it is keys. i think it's bad. not sure we should define our commands by the limitations of redis-cli, which are in any case also limiting restore (if the replace argument is provided). instead, we should improve redis-cli (will also help eval, restore, etc) btw, in restore it's called `serialized-value` in the docs, and `payload` in the code, maybe we should fallback to the same terminology.",-1,-1,-1,0.9556277990341188,0.976624310016632,0.9763240218162536,-1.0,accept,unanimous_agreement
772933170,9938,"will change the terminology. regarding the payload as last argument, i agree `redis-cli -x` should not come as a consideration but maybe streaming (in the future) should?",0,0,0,0.9840214848518372,0.9908889532089232,0.9931451082229614,0.0,accept,unanimous_agreement
773048874,9938,"even in streaming, i. e. handling that payload via some background operation without blocking the entire server, we need to apply thee change to redis only when the streaming ends. i. e. we can't flush the existing functions right away,, we must flush them only when we're done parsing the new ones, and we apply that command atomically. so i don't see any argument about that with regards to argument order.",0,0,0,0.974518656730652,0.9729825258255004,0.9847987294197084,0.0,accept,unanimous_agreement
773103690,9938,"we discussed this in the core-team meeting, and concluded that we'd like it tested as part of `tests/unit/cluster.tcl`",0,0,0,0.9698902368545532,0.9849523901939392,0.9919235110282898,0.0,accept,unanimous_agreement
773143071,9938,"i agree with the final point. i don't think `redis-cli` should be a consideration either, so i'm ok with the current command structure.",0,0,0,0.9796239733695984,0.947540819644928,0.7996089458465576,0.0,accept,unanimous_agreement
773433113,9938,"thanks , updated the documentation.",1,0,1,0.7294067144393921,0.5110270977020264,0.8257858157157898,1.0,accept,majority_agreement
773433415,9938,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
773433556,9938,"thanks, fixed.",1,1,1,0.6975147128105164,0.8492836356163025,0.8536084890365601,1.0,accept,unanimous_agreement
773900190,9938,"added a test, let me know what you think.",0,0,0,0.9822532534599304,0.9651565551757812,0.9437308311462402,0.0,accept,unanimous_agreement
774314000,9938,"what's the logic to use `append` here, the current node would then be inconsistent with the remaining nodes in the cluster. i would've expected `flush`.",0,0,0,0.9859495759010316,0.98812335729599,0.9924103021621704,0.0,accept,unanimous_agreement
774314984,9938,can't this just be a regular client?,0,0,0,0.9745200276374816,0.9866515398025512,0.9791065454483032,0.0,accept,unanimous_agreement
774315707,9938,none of these are used.,0,0,0,0.9740744233131408,0.9745930433273317,0.9874025583267212,0.0,accept,unanimous_agreement
774316937,9938,"this is very limited testing of this functionality, so it would probably be good to clarify this test is just verifying the function transfer behavior.",0,0,0,0.9809508323669434,0.9728751182556152,0.9832944869995116,0.0,accept,unanimous_agreement
774349005,9938,so you suggest to use `flush` and check before that there is not existing functions?,0,0,0,0.988197147846222,0.9942806959152222,0.9954400062561036,0.0,accept,unanimous_agreement
774351186,9938,actually it will be enough to just verify that there is no functions in the new node...,0,0,0,0.9822231531143188,0.989512860774994,0.9944685697555542,0.0,accept,unanimous_agreement
774356722,9938,fixed and update top comment.,0,0,0,0.9866740703582764,0.9899173378944396,0.9934983253479004,0.0,accept,unanimous_agreement
774356799,9938,"thanks , fixed.",1,1,1,0.6975147128105164,0.8802324533462524,0.9227998852729796,1.0,accept,unanimous_agreement
774356857,9938,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
774356912,9938,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
774424332,9938,"i think adding another round trip to check if the node has functions may be excessive and more complicated. but one thing's for sure, we do wanna either override the conflicting ones, or fail the add-node (which i think is better). so the disadvantage here (when using append, and failing if there are conflicts) is that there's a chance the new node will have some additional functions that don't exist in the other nodes. but there's actually no guarantee that other nodes don't have such mismatches (if the user uploaded different functions to each). so maybe the question is where this new node come from, and if it was wiped clean, and re-configured before being added. is there some mechanism for that? or common practice? if not, then maybe we do need flush",0,0,0,0.8908894658088684,0.9380294680595398,0.940418779850006,0.0,accept,unanimous_agreement
774425950,9938,"ohh, i see it was already implemented, and looks like not a lot of code. so the only possible concern is that maybe we're overriding some data that the user didn't realize that he's gonna lose. but that's also true about data in the keyspace, right? something in that process is calling flushall?",0,0,0,0.8513736724853516,0.9143980145454408,0.8575055599212646,0.0,accept,unanimous_agreement
774453849,9938,"why we overriding data? if there is any function on the new node we failed the process, otherwise we add the node and the functions (we are not overriding because we know there are no functions on the new node).",0,0,0,0.9707196950912476,0.9912557601928712,0.988118588924408,0.0,accept,unanimous_agreement
774463893,9938,right. sorry.. i guess i mixing the case using flush without a check in my head.,-1,-1,-1,0.9896371960639954,0.9921405911445618,0.9825189113616944,-1.0,accept,unanimous_agreement
775050275,9938,maybe we should be specific and advise a function flush?,0,0,0,0.9866691827774048,0.9929976463317872,0.9860477447509766,0.0,accept,unanimous_agreement
775050282,9938,"this will now fail if any function already exists on the dest, right? even if there are no overlapping or an identical set of functions. maybe we should modify the test. p.s. maybe redis-cli needs to have some `--force` option to skip that check?",0,0,0,0.9841014742851256,0.9888694286346436,0.9905250668525696,0.0,accept,unanimous_agreement
776568500,9938,"sorry for being slow, doing the check outlined here seems like the safest approach, so lgtm.",-1,-1,-1,0.9879056215286256,0.9918551445007324,0.9929641485214232,-1.0,accept,unanimous_agreement
551881422,8288,maybe some clarification: ..this is where the assigned id is `returned.`,0,0,0,0.984031081199646,0.994123876094818,0.9907624125480652,0.0,accept,unanimous_agreement
551887199,8288,a comment depending on how much validations normally is done at this level: validating that argv contains an even amount of elements? (and possibly >= numfields*2 elems) probably good since it seems that `streamappenditem()` expects values to exist: `value = argv[i*2+1]->ptr`,0,0,0,0.9644446969032288,0.9876238107681274,0.9800024032592772,0.0,accept,unanimous_agreement
551887521,8288,currently unused unused,0,0,0,0.9439116716384888,0.9056840538978576,0.986547589302063,0.0,accept,unanimous_agreement
551930404,8288,what do you mean? it's not possible to check the number of elements in argv.,0,0,0,0.9716360569000244,0.8616690039634705,0.991227090358734,0.0,accept,unanimous_agreement
551976473,8288,"never mind, i see now that we only have pointers to work with and no container. it needs to be correct from caller and your updated function description is perfect.",1,0,1,0.6874631643295288,0.7269704341888428,0.8933249711990356,1.0,accept,majority_agreement
552031460,8288,"technically, i think it's ok.. they're identical and will never change. but i can't see any preexisting practice like that, and since it's just to field, copying them one by one is easy and clean (which is what you did), so i guess that's a better choice.",0,0,1,0.844278872013092,0.7387326955795288,0.5743514895439148,0.0,accept,majority_agreement
552032116,8288,"we might want to give the user some visibility on the error types. rm_call does it with `errno`, i'm not sure if we wanna keep that practice. need to think this through",0,0,0,0.8752497434616089,0.9265405535697936,0.9380677342414856,0.0,accept,unanimous_agreement
552034724,8288,"i think your decisions of not doing signalkeyasready, signalkeyasready, etc implicitly are right. module should do these manually when done amending the stream. maybe it should be clearly stated in the documentation of the add api though.",0,0,0,0.985879361629486,0.9915593266487122,0.8798341751098633,0.0,accept,unanimous_agreement
552036112,8288,"these are not yet documented (documentation is generated from the comments in the c file. i guess you're not using them, and just added them as a preparation for your next pr (in which case let's trim them from here), or are you planning to extend this pr with more stream apis?",0,0,0,0.9856967926025392,0.9903399348258972,0.9932368397712708,0.0,accept,unanimous_agreement
552037149,8288,"styling: i see that (maybe wrongly) none of the other apis are broken to multiple lines in this file (although some are 300 chars long). for now i think we should be consistent with that. p.s. i doubt we really want `int64_t` for numfields, `long` would be better (for 32 bit builds)",0,0,0,0.9463651180267334,0.960574746131897,0.9793205261230468,0.0,accept,unanimous_agreement
552229422,8288,"ok, good. however, `redismodule_signalkeyasready() calls the signalkeyasready() with obj_module as the 3rd arg. i'm not sure it works or if needs to be obj_stream.",1,0,0,0.9253211617469788,0.9325448274612428,0.8303641080856323,0.0,accept,majority_agreement
552230177,8288,"that's right, they're not used yet. i can remove them and add them again in another pr where they're used. i think it's good to divide the stream api into multiple prs. are the docs generated from the comments? i assumed they're just manually copied into the redis-docs repo. please clarify so i can do it properly.",0,0,0,0.9484823942184448,0.9177232384681702,0.9704354405403136,0.0,accept,unanimous_agreement
552232390,8288,"sure, i'll use `long`. (maybe `size_t` would be semantically correct but it doesn't seem to be used much in redis.) i took `int64_t` from the numfields arg in `streamappenditem` (t_stream.c)",0,0,0,0.9840456247329712,0.9951229691505432,0.9917490482330322,0.0,accept,unanimous_agreement
552714588,8288,"good catch. that seems like a flaw in the api. it should have taken a `redismodulekey` argument rather than key name. not sure what we can do now, other than add a new api and deprecate the old one. wdyt?",1,0,1,0.7179151773452759,0.6006923913955688,0.8883545994758606,1.0,accept,majority_agreement
552717610,8288,the docs are generated by `src/modules/gendoc.rb` (parsing module.c and looking for comments above rm_ apis).,0,0,0,0.9888598918914796,0.9945118427276612,0.9954255223274232,0.0,accept,unanimous_agreement
552718735,8288,"the code inside redis is more flexible to change. the api needs to be abi compatible, so what we set now is there forever. i think `long` is the right one here.",0,0,0,0.9717538952827454,0.9745396375656128,0.9763075113296508,0.0,accept,unanimous_agreement
555902372,8288,"another idea is define more non-zero return values to use only in new api functions, e.g. `redismodule_err_badarg`, `redismodule_err_badtype`, etc. we can't add them to old functions though since users may have assumed that `result != redismodule_err` means success. but, given that it's is possible to prevent all the errors by properly opening the key for writing and checking the type of the key before calling streamadd with the right args, i think just returning err is ok. if we return `redismodule_err` for now, we can add errno later if you decide upon that?",0,0,0,0.9676517844200134,0.9924389123916626,0.9765941500663756,0.0,accept,unanimous_agreement
556571551,8288,maybe rm_createstringfromstreamid?,0,0,0,0.9884213209152222,0.9939961433410645,0.9926203489303588,0.0,accept,unanimous_agreement
556575659,8288,i vote for defining more non-zero errors afaic i don't mind having specific errors for specific apis as long as it's documented otherwise maybe we can find some general errors that are not api-specific,0,0,0,0.7470033764839172,0.8883116245269775,0.9345375299453736,0.0,accept,unanimous_agreement
556577633,8288,maybe call them `start` and `end`? it's a bit weird that in case of redismodule_stream_reverse minid > maxid also to avoid confusion with xtrim minid,-1,-1,-1,0.9638565182685852,0.9048445224761964,0.9455057382583618,-1.0,accept,unanimous_agreement
556584557,8288,"good idea. i wanted to start them all with `rm_stream`, but this one is actually just like `redismodule_createstringfrom(longlong|double|...type...)` so i like it. should i put it together with the other `createstringfrom*` functions so they show up together in the ref docs?",1,1,1,0.9818140268325806,0.960741639137268,0.9883202314376832,1.0,accept,unanimous_agreement
556585043,8288,"if reverse is specified, maxid is actually the start and minid is the end, so i thought minid and maxid are more clear than startid and endid. maybe rename to upper and lower? or i can change the semantics and require startid >= endid if reverse is specified. or maybe just do reverse implicitly if startid > endid and we don't need a reverse flag...? [edit] i assume you mean we want startid >= endid when reverse is specified, so the order of args will be like xrevrange.",0,0,0,0.9812313914299012,0.9831263422966005,0.9845176339149476,0.0,accept,unanimous_agreement
556594512,8288,i think it's best to stick with the standard set by `streamiteratorstart` and use `start` and `end` (and then reverse goes from `end` to `start` which kind makes sense..?),0,0,0,0.9836874008178712,0.9875530004501344,0.9816923141479492,0.0,accept,unanimous_agreement
556594756,8288,yes please,0,0,0,0.9602795839309692,0.9627472162246704,0.8169810771942139,0.0,accept,unanimous_agreement
556603995,8288,"one more thing: if startid and endid are **not** pointers, redismodule_stream_min and redismodule_stream_max can be used directly. ok?",0,0,0,0.9872554540634156,0.9920768737792968,0.991569459438324,0.0,accept,unanimous_agreement
556610448,8288,"why do you want to pass them by value? i think it's more intuitive to pass null the means ""i want the edge""",0,0,0,0.9757401943206788,0.9539310336112976,0.9881207942962646,0.0,accept,unanimous_agreement
556611559,8288,also please you called them redismodule_streamid_min and not redismodule_stream_min (maybe update comment),0,0,0,0.9809364080429076,0.9924726486206056,0.992752194404602,0.0,accept,unanimous_agreement
556612176,8288,perhaps you want to use the min/max constants here,0,0,0,0.9877678751945496,0.9930971264839172,0.9917230010032654,0.0,accept,unanimous_agreement
556616014,8288,"yes, the user can use it like [code block] ... but since they are pointers, they can also be null. with null we also use min and max. in the other comment, i suggested we don't let it be pointers. then they can't be null and we don't need this logic.",0,0,0,0.9740648865699768,0.9897832274436952,0.9920197129249572,0.0,accept,unanimous_agreement
556618686,8288,generally speaking we prefer to pass structs by ref and not by value.. i think it's ok as-is,0,0,0,0.9556491374969482,0.820610761642456,0.904125452041626,0.0,accept,unanimous_agreement
556629210,8288,"also renaming the parse function to `rm_stringtostreamid` (matching `stringtolonglong` and others), ok?",0,0,0,0.9893117547035216,0.994677186012268,0.9953246116638184,0.0,accept,unanimous_agreement
556630900,8288,yes please,0,0,0,0.9602795839309692,0.9627472162246704,0.8169810771942139,0.0,accept,unanimous_agreement
556661907,8288,"ok, so let's use pointers and null for the edges. then, we don't really need min and max, so i'll delete them. better just have one way of specifying it, right? (i do think start and end are ambiguous. start and end could mean (1) where you start and end the iteration vs (2) the start and end of the interval. but i'll stick with the start-end terminology and make it clear in the docs.)",0,0,0,0.9672649502754213,0.9784395098686218,0.9837788939476012,0.0,accept,unanimous_agreement
556941909,8288,"trying to come up with generic `redismodule_err_*` usable also for future apis, here are some far-from-perfect ideas. i think errno is not very well suited in some cases, but i've tried to map them too. **[edit] `errno` column updated to match the current implemention in this pr.** | scenario | functions | errno | return macro idea | |-|-|-|-| | invalid flags | all which have flags | einval | `redismodule_err_inval` | | mandatory pointer arg is null | all | einval | `redismodule_err_inval` | | key is empty (type empty => wrong type) | iterator*, delete, trim* | enotsup | `redismodule_err_notexist` | | key not a stream (wrong type) | add, iterator*, trim* | enotsup | `redismodule_err_wrongtype` | | key not open for writing | add, delete, iteratordelete, trim* | ebadf | `redismodule_err_readonly` | | iterator not started | iterator* (except iteratorstart) | ebadf | `redismodule_err_notstarted` | | requested id is 0-0 | add | edom | `redismodule_err_toosmall` | | requested id not greater than last stream id | add | edom | `redismodule_err_toosmall` | | stream id reached the last possible | add | efbig | `redismodule_err_full` | | iterator reached end | iteratornext* | enoent | `redismodule_eof` (not an error) | | id not found | delete | enoent | | | string not a stream id | stringtostreamid | (edom) | `redismodule_err` (aligned with existing string functions) | most of the errors are programming errors. maybe it could be possible to enable debug logging instead and get a readable error message printed somewhere, such as by putting a log function pointer in the context or so? the only errors which aren't possible to detect in other ways are ""iterator reaches end of range"" (not an error) and ""stream id not available for add"" (can be indicated by setting `id` to the next available id while returning an error). maybe we can have special return values for only these (and maybe a few more) and generic err for the rest?",0,0,0,0.9014480710029602,0.9900904893875122,0.8273069858551025,0.0,accept,unanimous_agreement
557732528,8288,"indeed we can't change existing apis, since some module can explicitly check for err return. and introducing new error types just for these apis is bad for consistency. so i tends to lean towards using `errno`. i'd like to hear what thinks.",-1,0,0,0.9323009252548218,0.6284942030906677,0.9260908961296082,0.0,accept,majority_agreement
557978920,8288,"`signalkeyasready()` is called by `dbadd()` (db.c) so it's done implicitly by `rm_listpush()` and `rm_zsetadd()` (via `modulecreateemptykey()`). these types (blpop, etc.) can only block if the key doesn't exists, because popping the last element deletes the key. `signalkeyasready()` is also done implicitly when adding to a non-existing stream, also via `modulecreateemptykey()`. thus i think it should be done implicitly also when adding to an existing stream. stream is the only type where readers can be blocked even if the key exists (e.g. using xread with id `$`). makes sense?",0,0,0,0.9855493903160096,0.9951959252357484,0.9905597567558287,0.0,accept,unanimous_agreement
559197097,8288,"do we really need that `redismodule_stream_nomkstream`? it's a bit hard to resist, but i think we should try hard to escape from the desire to map the commands ""as is"" into functions. and instead come up with a useful api. in this case i think the module can check the type of the key it opened, and we don't want that flag. i.e. the flag exists for a command for atomicity.",0,0,0,0.9454006552696228,0.9353694915771484,0.94680917263031,0.0,accept,unanimous_agreement
559198928,8288,"maybe a better api is to let the user interrogate the item at the iterator cursor rather than return it (or a portion of it) in the `next` call? i.e. `rm_streamiteratornext` will return count, or just an ok / error, and you'll have another function to query the individual fields and values? this way there's no need for a pre-allocated array, and the user can run on the result until he finds the records he's interested in (in case it's a specific one).",0,0,0,0.9852691292762756,0.992194890975952,0.9858863353729248,0.0,accept,unanimous_agreement
559199334,8288,i feel it's a bit odd that we're mixing flags of different functions together (most will never be used in combination with each other). maybe of these can maybe just be turned into a boolean argument (although that means that we can't extend it in the future),-1,-1,-1,0.923263430595398,0.6421952843666077,0.8959255218505859,-1.0,accept,unanimous_agreement
559199612,8288,"maybe instead of the `exclusive` flag we better just expose streamincrid and streamdecrid as apis? it would be a bit harder to use, but can be more powerful. i'm not sure. ?",0,0,0,0.91454017162323,0.6882878541946411,0.9363105893135072,0.0,accept,unanimous_agreement
559201797,8288,"as much as i really don't like the `errno` abuse, i think at this point in the api's life cycle we should probably stick to it rather than create a new error coding system. i think the cognitive load of remembering when to extended `redismodule_err_*` and when to use `errno` will inevitably lead to unnecessary bugs.",-1,-1,-1,0.9401023983955384,0.5642890334129333,0.5942811965942383,-1.0,accept,unanimous_agreement
559442089,8288,good point!,1,1,1,0.9838534593582152,0.9942666888237,0.9930058121681212,1.0,accept,unanimous_agreement
559445727,8288,just like the internal streamiterator then. i like it. so how about: [code block],1,1,1,0.8898073434829712,0.9721974730491638,0.9279200434684752,1.0,accept,unanimous_agreement
559448367,8288,"just in case we want to allow some functions to share some flags, i made them use distinct bits. you use the macros anyway, right?",0,0,0,0.9870927333831788,0.989515781402588,0.9923946857452391,0.0,accept,unanimous_agreement
559450844,8288,give me a use case for incr and decr and i will be convinced. :-),1,1,1,0.978491187095642,0.9941617846488952,0.983132541179657,1.0,accept,unanimous_agreement
559453786,8288,"regarding boolean arguments vs flags: when reading code, which of the below is easier to understand? [code block] [code block]",0,0,0,0.98203045129776,0.9941001534461976,0.9926003813743592,0.0,accept,unanimous_agreement
559459676,8288,"i agree it's makes it easier to read the code, and also opens the possibility for adding more flags in the future without modifying the api. but it's a bit odd that they share the same ""bit"" space. i suppose i can live with it.",0,1,0,0.8362451195716858,0.5307683944702148,0.7525720000267029,0.0,accept,majority_agreement
559810557,8288,related: #8356,0,0,0,0.9788928031921388,0.984010636806488,0.9882206916809082,0.0,accept,unanimous_agreement
560825568,8288,"i don't mind having a different bit space for each api function if you prefer that. then maybe the name prefixes should reflect that too, e.g. `redismodule_stream_iterator_reverse`, etc. currently, each command has a check that only supported stream flags are used, exploiting the fact that all flags are distinct. if we make e.g. reverse = autoid, it's not possible for a check to forbid iteration with the autoid flag.",0,0,0,0.9550853371620178,0.9839710593223572,0.9755834341049194,0.0,accept,unanimous_agreement
560996001,8288,"yeah, if each of these flags applies only for one function, let's name them appropriately.",0,0,0,0.9838573932647704,0.9863784313201904,0.9838142395019532,0.0,accept,unanimous_agreement
561055623,8288,i didn't read the entire correspondence - what's the decision here?,0,0,0,0.6942490339279175,0.8998496532440186,0.8793067932128906,0.0,accept,unanimous_agreement
561103762,8288,i think we decided to go with `errno`. yossi's last post sums it up nicely,0,0,0,0.9604153633117676,0.9885486364364624,0.9535975456237792,0.0,accept,unanimous_agreement
561268690,8288,"i still don't think we should implicitly call signalkeyasready in rm_streamadd. i think the module should do it explicitly when done adding. for lists that may be ok to count on dbadd (executed once per command), but streams you can add to an existing stream (many times inside one call), and also, the client can be blocked on a key that exists (unlike list that blocks on a key that's missing) wdyt? p.s. is the fact that redismodule_signalkeyasready still calls signalkeyasready() with obj_module not causing any harm now? seems to me that it does and the only reason the test in #8356 passes is because it relies the automatic one in dbadd. i think we need to modify redismodule_signalkeyasready and signalkeyasready, so that when it is called it skips that new check.",0,0,0,0.9800671935081482,0.9899783134460448,0.9867076873779296,0.0,accept,unanimous_agreement
561710770,8288,"i think it's inconsistent if streamadd (and listpush and zsetadd) to an empty key signals implicitly, but adding to an existing stream doesn't. if the worries are about performance, we can set a flag in the key struct and signal when the key is closed. how about that? for comparison: signal to watched keys (`signalmodifiedkey()`) is done implicitly when a key opened for writing is closed. any ideas? that's right. the test case relies on it being done implicitly, for the correct type.",0,0,0,0.976138472557068,0.9647533893585204,0.972401797771454,0.0,accept,unanimous_agreement
561715618,8288,i suppose your suggestion about caching a flag in the key and doing it implicitly in close is ok. can you also make a pr to solve the problem with redismodule_signalkeyasready?,0,0,0,0.9872995018959044,0.989153265953064,0.9905685782432556,0.0,accept,unanimous_agreement
561735985,8288,"ok good. :smiling_face_with_smiling_eyes: what's the problem in `redismodule_signalkeyasready()`? if all normal types are signaled implicitly, the only point of `redismodule_signalkeyasready()` is to signal for user-defined types... [edit] but documentation could be updated.",1,1,1,0.9558749794960022,0.8183733224868774,0.9896113872528076,1.0,accept,unanimous_agreement
561737843,8288,"i've discussed it with guy, at first we concluded that the code in `redismodule_signalkeyasready` is ok (no need to fix it). since any modification on other types (list / streams) will always trigger an implicit signalkeyasready, so the only reason to use that api is for a module that wants to release another client blocked on a module data type (which doesn't have an implicit signalkeyasready). but then we thought of another case, let's say there's a module that implements an lpop, but one that's similarly to an xread can wait for new data even on a non-empty list (e.g. when a list has at least 5 elements). this means that there's no implicit signalkeyasready since a push to a non-empty list won't trigger it. but on the other hand, if the only blocked client that's waiting for this case is a module, then calling rm_signalkeyasready will release it (in that case, the argument to signalkeyasready is not about the type of the blocked key, but rather the identity of the entity that's blocked). maybe it would be nice to add a test like that a command like module.lpop 5 (that will unblock only when there are 5 elements to pop, and will block even if the list is not empty).",0,0,0,0.9463440179824828,0.9844581484794616,0.9432966709136964,0.0,accept,unanimous_agreement
561741610,8288,"i'll go with `errno`. i think it's quite fine in all cases except when an iterator comes to its end. eof is not an error. i've considered enoent for ""no more entries"" but you shouldn't need to check errno in a successful iteration, right? how about returning ok (0), err (1) or eof (-1) for iteratornext?",0,0,0,0.8952023386955261,0.9785918593406676,0.5663625001907349,0.0,accept,unanimous_agreement
561750865,8288,"i don't like the -1 that much. considering the user wants to abort the iterations on eof, i guess it's not too bad to return err, with errno set to enoent",-1,-1,-1,0.9752368330955504,0.9660196304321288,0.9710512757301332,-1.0,accept,unanimous_agreement
561767306,8288,"ok , i don't like either of the two solutions actually. :-) i'd like to think about it a bit more to see if there are any other options. any ideas are welcome. i pushed two commits just now. if we decide to go with enoent, i'll revert the last one.",1,1,1,0.9667885899543762,0.9951960444450378,0.9917689561843872,1.0,accept,unanimous_agreement
561772233,8288,"`blpopn key 5` – it's so nice it deserves to be an official command :d jokes aside, that was a good discussion. thanks for sharing. adding a test case sounds like a good idea.",1,1,1,0.9905722737312316,0.9949471354484558,0.9968401193618774,1.0,accept,unanimous_agreement
561807028,8288,"what do you think? when an iterator is spent, return a redismodule_err and errno=enoent, or add another redismodule_eof?",0,0,0,0.9893923997879028,0.9844968318939208,0.9888504147529602,0.0,accept,unanimous_agreement
561808232,8288,"fyi, in the commit that added the errno, you documented the enoent, but didn't actually use it. so if you revert the last commit, you'll need to fix this.",0,0,0,0.9787623286247252,0.9721804857254028,0.9903087019920348,0.0,accept,unanimous_agreement
561814394,8288,"i'm not comfortable with this undefined behavior. i think we should check `si->lp_ele` (maybe add an `streamiteratorisvalidfield`, or modify `streamiteratorgetfield` to return an error), and handle that too (possibly setting errno to enoent).",-1,-1,-1,0.9309839010238647,0.6099744439125061,0.8329674005508423,-1.0,accept,unanimous_agreement
561827885,8288,"i'll try this. i was planning to store a field counter of the current entry in the key struct and use it to return an error in nextfield(), but if it can be done in streamiterator itself, it's better of course.",0,0,0,0.9821750521659852,0.9854094982147216,0.9817335605621338,0.0,accept,unanimous_agreement
562006063,8288,solved. i followed my original idea and stored a counter in the key struct.,0,0,0,0.982258677482605,0.9384555220603944,0.9800072312355042,0.0,accept,unanimous_agreement
562085633,8288,"i'm curious, did you try the `si->lp_ele` idea and found some problem with it, or just didn't want to do any changes in t_stream.c ?",0,0,0,0.9485357999801636,0.971959352493286,0.9332371950149536,0.0,accept,unanimous_agreement
562167500,8288,don't you mean `|=`?,0,0,0,0.932595193386078,0.9913672804832458,0.9937832355499268,0.0,accept,unanimous_agreement
562170088,8288,"commenting that now one ""next"" api returns eof value, and the other does `errno = enoent` just so we don't forget this.",0,0,0,0.9836560487747192,0.9926758408546448,0.9939677715301514,0.0,accept,unanimous_agreement
562232928,8288,"the latter. i haven't spent enough time to understand the internals of t_stream.c and with the union in the key struct, it doesn't really cost anything extra to put it there... do you prefer the `si->lp_ele` solution?",0,0,0,0.962097704410553,0.9476895928382874,0.985706090927124,0.0,accept,unanimous_agreement
562233701,8288,right... but not even that. the stream can also be empty and when adding one it will have length == 1. i'll have to rework this a little.,0,0,0,0.9287363886833192,0.5622740983963013,0.9775471687316896,0.0,accept,unanimous_agreement
562234437,8288,good. yes i know... i thought we're leaning towards enoent for both of them now...,1,1,1,0.9548968076705932,0.9451240301132202,0.9796836376190186,1.0,accept,unanimous_agreement
562237521,8288,there's a slight diffrerence though. for nextfield() you can know the number of fields in advance and thus it can be considered an error to call it for more times than that number. for nextid() you don't know the number in advance.,0,0,0,0.9690134525299072,0.968223512172699,0.9851828217506408,0.0,accept,unanimous_agreement
562555977,8288,"i've been thinking about err vs eof for the iteratornext() functions a bit more and i think you're right, err is cleaner for the user. motivation: if streamiteratorstart(key, ...) was successful, iteratornextid(key, ...) can't fail if it's called with the same key, so in practice, users don't need to check errno for iteratornextid(). i'll revert to err and add a note about this. if or anyone else has other ideas, i'll be happy to change it again.",0,1,1,0.717771589756012,0.9625386595726012,0.9347193837165833,1.0,accept,majority_agreement
562584385,8288,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
562584759,8288,changed to `if (!created) key->u.stream.signalready = 1;`,0,0,0,0.9852484464645386,0.993267297744751,0.9942850470542908,0.0,accept,unanimous_agreement
562644112,8288,here's the test discussed: #8382. a module blocks until a list has 5 elements.,0,0,0,0.9874171018600464,0.9892386198043824,0.9938016533851624,0.0,accept,unanimous_agreement
563249899,8288,"i think it's a good idea to also zero the output arguments, not just rely on the return value.",0,0,0,0.782804548740387,0.943224310874939,0.7308865785598755,0.0,accept,unanimous_agreement
563252313,8288,"i prefer it since it seems safer (won't cause npd in case of a mismatch between the count and what's actually in the listpack, see #7807). i suppose such a change would also have such a side effect benefit for other pieces of in stream that use this function (even if they do run a loop that exit only on field count), but i suppose for modules this safety is of higher concern. from a quick look i took now, in order to make it safe, `streamiteratorgetfield` should exit when `si->lp_ele` is null. maybe for extra safety, it would also be a nice idea to nullify it in two places in `streamiteratorgetid` when it returns 0 due to running out of range.",0,0,0,0.9022141695022584,0.9508969187736512,0.8064975142478943,0.0,accept,unanimous_agreement
563264365,8288,"i agree with you, i think it's not perfect but it's more consistent. in addition to the usage you describe, i think introducing `redismodule_eof` globally and using it only here would be confusing.",0,0,0,0.912159264087677,0.936461627483368,0.8936284184455872,0.0,accept,unanimous_agreement
563363878,8288,"ok, i'll put this back again, tomorrow. (for reference: first i added this but then i removed it again because i thought it would be unexpected to touch the output args when err is returned.) [edit] i think it can be useful *not to zero* them actually. let's say a module iterates over the stream, saves the last id and later continues iterating from there, like in this pseudo-code: [code block] in a way it's similar to `for (i = 0; i < n; i++) { ... }` -- you'd expect `i == n` afterwards and some code even relies on it. anyway, if we zero the args, i think it should at least be documented to avoid any confusion if anyone tries to do like in `consume_stream()` above.",0,0,0,0.968696355819702,0.9786033034324646,0.9760857820510864,0.0,accept,unanimous_agreement
565103053,8288,i'm looking at this. * `streamiteratorgetfield` returns `void`. it would need to return `int` to indicate if there was a field or not. * i can't see the two places where you want to nullify `si->lp_ele`. lpnext() and lpprev() already return null when running out of range. maybe you can enlighten me? i suppose this can also be changed as a separate improvement after merging this pr. i don't feel very confident about the listpack and rax structure.,0,0,-1,0.7043752074241638,0.9098026752471924,0.6868324279785156,0.0,accept,majority_agreement
565206151,8288,"would the issue in `streamiteratorgetfield()` be that if the first `lpnext()` returns null since it is running out of range, the second `lpnext()` will get null in its listpack pointer, which triggers an assert in `lpnext()`. i guess `streamiteratorgetfield()` needs to bail out after attempting to get the missing fieldptr, and then it might need to nullify the returned field and value ptrs before returning. this can later be checked in `rm_streamiteratornextfield()` to make sure that more fields existed.",0,0,0,0.9853948354721068,0.9933053851127625,0.9883408546447754,0.0,accept,unanimous_agreement
565263090,8288,"the two places i meant that i think `streamiteratorgetid` should nullify `si->lp_ele` are: [a link] [a link] i think that if we do that, and change `streamiteratorgetfield` to return an error when `si->lp_ele` is null on entry, should make all of this safe. i'm ok leaving this issue for some future day, and also ok to change the pr to use that instead of counting the fields. up to you if you wanna try it.",0,0,0,0.9376445412635804,0.9469243884086608,0.9538132548332214,0.0,accept,unanimous_agreement
565319416,8288,"ok, thanks. i tried it, but getfield() doens't reach `si->lp_ele == null` after the last field in an entry, so it just continues returning fields from the next stream entry. my guess that we need a numfieldsleft counter for this, either in the streamiterator or in the api... btw, this pr reached :100: comments. :)",1,1,1,0.9862019419670104,0.9954930543899536,0.9960325360298156,1.0,accept,unanimous_agreement
565321080,8288,"ohh, right. for some reason i thought the next entry is in the next rax node. sorry.",-1,-1,-1,0.9903941750526428,0.9920415282249452,0.9920437932014464,-1.0,accept,unanimous_agreement
1384820874,12658,"why change this one? it is only used from within a fatal crash. also, i suppose the extra linefeed is to add an empty line after that header, why did you remove it?",0,0,0,0.9740570783615112,0.96675705909729,0.984201729297638,0.0,accept,unanimous_agreement
1384824258,12658,don't we need to cast size_t to a long here?,0,0,0,0.9860481023788452,0.9922751784324646,0.9909713268280028,0.0,accept,unanimous_agreement
1384824924,12658,"again, is this change necessary according to our guidelines? same for bugreportend..",0,0,0,0.9750381112098694,0.9896076321601868,0.9933719635009766,0.0,accept,unanimous_agreement
1384829531,12658,let's fix the indentation,0,0,0,0.983770489692688,0.9735623002052308,0.9936362504959106,0.0,accept,unanimous_agreement
1384831072,12658,i think this one and others should be put in util.c,0,0,0,0.9542676210403442,0.9886338710784912,0.9800399541854858,0.0,accept,unanimous_agreement
1384847720,12658,let's comment that we do it this way because of signal safety,0,0,0,0.9791616201400756,0.9822522401809692,0.992190420627594,0.0,accept,unanimous_agreement
1384851789,12658,"maybe it could be called serverlograwfromhandler (like serverlograw), and be made non-static? i.e. they both take a pre-formatted message",0,0,0,0.98740953207016,0.995732605457306,0.9859635233879088,0.0,accept,unanimous_agreement
1384854374,12658,maybe part of the comment should be copied from the other function,0,0,0,0.9865533709526062,0.9926161766052246,0.9821609258651732,0.0,accept,unanimous_agreement
1384863802,12658,"this lock was there to avoid writing to an already destroyed data structure. now that we don't destroy it, that's not a concern, but if we repeatedly invoke this mechanism, then a thread that's late for the previous invocation, and corrupt the next one. is that right?",0,0,0,0.9769417643547058,0.9583134055137634,0.9756240844726562,0.0,accept,unanimous_agreement
1384864354,12658,please ack that this is right,0,0,0,0.9710273146629332,0.9541633129119872,0.7586092948913574,0.0,accept,unanimous_agreement
1384872266,12658,"what does the ""safe"" prefix here stands for? why does `fgets_async_signal_safe` state that and this one doesn't? at the very least these should have a comment explaining them and when they should be used.",0,0,0,0.978579878807068,0.9932315349578856,0.9870790243148804,0.0,accept,unanimous_agreement
1384873266,12658,"`_` prefix usually denotes private / static. if these are exposed, let's drop the prefix",0,0,0,0.987728238105774,0.994418740272522,0.9924396276474,0.0,accept,unanimous_agreement
1386020714,12658,`serverlograw` and `serverlogfromhandler` with `ll_raw` flag just print the text with no preceding header. `serverlogfromhandler` adds a newline so we are keeping the current behavior but using a safe version,0,0,0,0.9862877130508424,0.9939858913421632,0.9939992427825928,0.0,accept,unanimous_agreement
1386025388,12658,we also said we rather use safe functions in new contexts,0,0,0,0.9825035929679872,0.9913232326507568,0.992747962474823,0.0,accept,unanimous_agreement
1386121168,12658,"just a note, using `path_max` for a buffer implies that you are going to write a file path into it. if you are not using the buffer for this purpose, i would avoid doing that.",0,0,0,0.8754720091819763,0.9898924827575684,0.9921894073486328,0.0,accept,unanimous_agreement
1386124150,12658,[code block] leftover? seems not necessary anymore as it will be overridden on the next line,0,0,0,0.9705392122268676,0.9932141304016112,0.9947634935379028,0.0,accept,unanimous_agreement
1386126331,12658,you can also check if read() returns negative.,0,0,0,0.9837125539779664,0.9861857891082764,0.9943296909332277,0.0,accept,unanimous_agreement
1386141741,12658,"i forgot to mention, that it's probably a good idea to add a `format printf` attribute to _safe_snprintf, see addreplyerrorformat and others.",0,0,0,0.9711437821388244,0.9886839985847472,0.983754336833954,0.0,accept,unanimous_agreement
1386218270,12658,"one thing i'm not sure is if this struct definition is portable. same link i pointed before: [a link], it defines `struct linux_dirent64` itself. also, there are some bits in **notes** section that implies we are supposed to define ourselves: [a link] probaby, our best bet is defining `struct linux_dirent64` ourselves as in the above link. btw, did you run daily for this branch? i assume our alpine build uses musl libc, it may not provide `struct dirent64`.",0,0,0,0.9180559515953064,0.9631311893463136,0.9574177265167236,0.0,accept,unanimous_agreement
1386226571,12658,"ok, i thought safe version isn't needed (this flow uses unsafe logging anyway)",0,0,0,0.9863098859786988,0.9739935398101808,0.9834169149398804,0.0,accept,unanimous_agreement
1386557625,12658,"the fact that we define the struct won't protect us if `syscall(sys_getdents64)` expects to fill another struct. note that although the man page implies that, the struct mentioned is incorrect. (d_name comes before d_type) this is why i feel more comfortable using something defined in a standard header. and yes [a link]",0,0,0,0.9583324790000916,0.9139231443405152,0.9900510907173156,0.0,accept,unanimous_agreement
1386575175,12658,"but if we can use it it won't hurt, right?",0,0,0,0.9573745727539062,0.6394957304000854,0.948700487613678,0.0,accept,unanimous_agreement
1386588639,12658,"actually, i copied it as is from twitter, but you are right and that it will be better to align all the new safe functions' names. i'd go with _async_signal_safe",0,0,0,0.9453619718551636,0.962806522846222,0.9869231581687928,0.0,accept,unanimous_agreement
1386687442,12658,"beware, there are two structs: `struct linux_dirent` and `struct linux_dirent64`. variable order is slightly different in these two (yes, it is confusing!). we are using `struct linux_dirent64` with `syscall(sys_getdents64)` the above [a link] mentiones that this struct definition cannot change without breaking the linux api. so, that's why they defined themselves. otherwise, we have to assume libc will provide it and libc provided struct will always match the required struct by this syscall. i'm not sure this assumption is better. considering defining it in the code has worked for these guys, i'd do the same.",0,-1,0,0.8862546682357788,0.907404601573944,0.7775489687919617,0.0,accept,majority_agreement
1387512682,12658,to avoid copying the message if there is no format? my intention was not to change all the existing calls to `serverlogfromhandler`,0,0,0,0.9789035320281982,0.9842785000801086,0.9920542240142822,0.0,accept,unanimous_agreement
1387517859,12658,right. i increased the timeout to 10 s.,0,0,0,0.971157968044281,0.9891000390052797,0.992881178855896,0.0,accept,unanimous_agreement
1387520331,12658,please suggest an alternative macro,0,0,0,0.984664261341095,0.9815496802330016,0.995057225227356,0.0,accept,unanimous_agreement
1387582094,12658,"they won't, but it could be confusing if some prints in this flow (or function) use one way, and others use the other way.",0,0,0,0.976813554763794,0.8055290579795837,0.95695161819458,0.0,accept,unanimous_agreement
1387586110,12658,"and completely remove the one that takes `fmt, ...` and uses `_safe_vsnprintf`? that may be ok, but i think we may want to use it some day, so having the two apis in both modes, and naming them consistently seems better.",0,0,0,0.9796922206878662,0.9923396110534668,0.9894752502441406,0.0,accept,unanimous_agreement
1387586396,12658,"if we keep it, let's add printf attribute here too",0,0,0,0.9874845147132874,0.9906340837478638,0.9943365454673768,0.0,accept,unanimous_agreement
1387597891,12658,"if i'm building a path string, i use path_max but otherwise, if i'm building log lines as in here, i generally just use big enough one like `char buf[1024]` (ofcourse you can define something like max_buff_length if you want) also, for snprintf, i generally pass local buffer size with sizeof() (whether buf size is a macro or not). the reasoning is that if i change buffer size later, no need to change in every snprintf invocation in the function. [code block] these are generally quite personal. so, please ignore if you disagree :)",0,1,1,0.981117308139801,0.931566059589386,0.9569640159606934,1.0,accept,majority_agreement
1387601436,12658,"i don't think that's a valid solution, first, that long timeout can cause issues when one thread hangs, but secondly, it doesn't really solve the problem. let's see what's the worse that can happen. in the past it could have cause memory corruption, and now it'll just mess up the next trace (only in case two are executed in close proximity). is that right? maybe we can attempt to reproduce that and see if there aren't other issues? i.e. reduce the timeout, slow down the threads, and trigger many traces repeatedly.",0,0,0,0.6238409876823425,0.6695550680160522,0.7067081928253174,0.0,accept,unanimous_agreement
1387771646,12658,"the original version of `serverlogfromhandler` did not take `fmt, ...`, the varidaic args were added by me. what i'm saying is that i didn't want to replace all the existing calls with `_serverlogfromhandler` (or whatever new name we'll choose), and since `...` also works for passing only a string literal, i moved the implementation to the static `_serverlogfromhandler`, and used `serverlogfromhandler` as a wrapper.",0,0,0,0.9781039953231812,0.981242060661316,0.9921815395355223,0.0,accept,unanimous_agreement
1387807408,12658,"there are some scenarios if some thread is hanging: 1. main thread reached timeout, nullified the callback pointer one of the threads is **trying to invoke `g_callback()`, that's a segfault** (we can avoid nullifying the callback) 2. main thread reached timeout, we set all the threadsmanager globals to 0 and returned from threadsmanager_runonthreads, we are done printing the stacktrace and returned from `writestacktraces` one of the threads has managed to call the callback, but then hanged for some reason, now it is writing the stacktrace to the an **array that doesn't exist anymore** (it was on `writestacktraces` stack). also, it will increase`g_num_threads_done` in the threads mngr, and the next call will start from 1 (this is easy to fix by setting this variable to 0 at the beginning as well) 3. main thread reached timeout, and we now print a stacktrace while a thread writes to this exact location in the array (not very likely but can happen). **we will get some corrupted print of this thread's** stack trace, or of the thread's name, depending on where `collect_stacktrace_data` and `writestacktraces` were at this point. all scenarios are very unlikely. why would a thread hang and then come back to life? and i think the only way to avoid them is to lock critical code sections unless you have a better idea.",0,0,0,0.971771776676178,0.9648087620735168,0.9908353090286256,0.0,accept,unanimous_agreement
1387829806,12658,"i know they are not the same (btw sys_getdents didn't work at all). and that's another thing to consider. i didn't find any documentation that explicitly defines the struct for `sys_getdents64`. what i did find was glibc docs on [a link]. however `getdents64` function has been supported since glibc 2.2, and some tests failed trying to use it (see [a link] i believe that an official documentation of glibc is more reliable.",0,0,0,0.9219029545783995,0.98643559217453,0.9876844882965088,0.0,accept,unanimous_agreement
1387847985,12658,"having said that a warning is raised if we define the printf attribute + call it with a buffer (and not a string literal), for example: `serverlogfromhandler(ll_warning, msg);` yields server.c: in function ‘sigshutdownhandler’: server.c:6399:5: warning: format not a string literal and no format arguments [-wformat-security] 6399 | serverlogfromhandler(ll_warning, msg); so i'll take your suggestion and expose `serverlograwfromhandler`. please don't complain there are too many diffs :grinning_face_with_smiling_eyes:",0,0,1,0.9800515174865724,0.8156780004501343,0.9034718871116638,0.0,accept,majority_agreement
1387886348,12658,"1. let's keep nullifying the callback, and change the code to print some log warning and exit if it's null. 2. setting it to 0 on startup seems good. i suppose it can still fire after we set it to 0, but the only damage is that one one thread will be printed twice, or that another one would be missing. i think that's ok. 3. i suppose such corruption will only result in a messed up stack trace, but nothing fatal. these are all unlikely, so i don't care much about the outcome, as long as it doesn't cause any crashes or memory corruptions.",0,0,1,0.5388882756233215,0.784534752368927,0.7282624244689941,0.0,accept,majority_agreement
1387933173,12658,"1. one problem is that checking and invoking is not one atomic operation 2. we have two counters to consider: one is in the threads mngr, which counts how many threads are done with invoking the callback. if a thread returns from the callback after a timeout and increases this counter, nothing will happen in the next call to the thread manager (if we fix setting this counter to 0). but in what scenario do we want to print the stacktrace that often? the second counter is in debug.c and we use it to take a memory pool from the array allocated in `writestacktraces` before calling the threads_mngr. if we already returned from `writestacktraces` and the thread trying to get this memory or already holds one, it will access a memory that doesn't exist anymore. but again, why would a thread invoke the callback successfully and then get stuck for a long time and then suddenly continue? 3. yes",0,0,0,0.9667901396751404,0.9881932139396667,0.9031765460968018,0.0,accept,unanimous_agreement
1387940634,12658,regarding 2- writing to a stack memory that doesn't exist anymore will not cause a crash it won't affect the next calls to `writestacktraces` (unless we call it again and the thread is still working on invoking the callback),0,0,0,0.9876149892807008,0.9855700135231018,0.9920143485069276,0.0,accept,unanimous_agreement
1388538394,12658,"this snipped is from [a link], see the notes section. [code block] looks like they added getdents64() in a later version but we can't use it as you showed it already fails on some environments. back to original question, can we rely on existence of `struct dirent64` from libc? i just don't see any guarantees for it. in all example codes ([a link], it defines the struct before caling `syscall()`. just to be on the safe side, i'd declare it like [a link].",0,0,0,0.9681481719017028,0.98312646150589,0.99126535654068,0.0,accept,unanimous_agreement
1388539383,12658,"just realized now, should we close() directory fd before returning here?",0,0,0,0.9882832169532776,0.9930019974708556,0.9927957653999328,0.0,accept,unanimous_agreement
1390336183,12658,yes,0,0,0,0.9564858078956604,0.9659429788589478,0.9686408638954164,0.0,accept,unanimous_agreement
1390338071,12658,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
1390354613,12658,"1. we can fetch the pointer to the stack (most likely the compiler will store it in the register anyway), and then test it before calling. 2. why is not an interesting question, i don't want a long timeout (specifically when this doesn't come from a fatal crash), ideally it should all be very quick (<10ms), and i certainly don't wanna hold the process for more than a second when some thread misbehaves. now considering a short timeout, even if the threads don't misbehave, there could always be timing issues, and any scenario that's theoretically possible, will happen at some point, and we should at least make sure we don't crash or corrupt heap. if we can't handle the above cases. another way out could be to just prevent the next stack trace collection, if the previous one didn't complete. this means that if one thread blocks forever, we'll only get one partial trace, and next ones will be skipped. if a thread is just late, then it'll be excluded from the trace, but won't block the next trace. wdyt?",0,0,0,0.8021957874298096,0.8865182399749756,0.941770076751709,0.0,accept,unanimous_agreement
1390376021,12658,1. ok 2. currently it's 10 to be on the safe side with valgrind. regarding you suggestion - how do you differentiate between a stuck thread and a late one?,0,0,0,0.9675690531730652,0.9342958331108092,0.9447345733642578,0.0,accept,unanimous_agreement
1390376437,12658,"and we can't corrupt the heap cause we don't use any malloc's all of the scenarios i mentioned above can lead to weird stacktrace prints, but not to a crash",-1,0,0,0.5133233666419983,0.9536907076835632,0.9548761248588562,0.0,accept,majority_agreement
1390392821,12658,let's expose the raw one too. like we do for the other raw,0,0,0,0.9770362973213196,0.9888463616371156,0.9926747679710388,0.0,accept,unanimous_agreement
1390392933,12658,the one in the `#else` block isn't needed.,0,0,0,0.9857853055000304,0.9892102479934692,0.9873206615447998,0.0,accept,unanimous_agreement
1390399782,12658,this is the raw one the one that takes format is 2 functions above,0,0,0,0.986825168132782,0.9876441359519958,0.9939367175102234,0.0,accept,unanimous_agreement
1390400000,12658,why?,0,0,0,0.6633803844451904,0.8699262738227844,0.9622438549995422,0.0,accept,unanimous_agreement
1390400778,12658,"i didn't suggest to differentiate between a stack thread and a late one, i just said these are two cases we need to handle. stack corruption can lead to heap corruption and vice versa.. anyway, so you say that the one leading to a segfault is now handled, and the other ones will just lead to bad stack trace in the log, but no effects on the other mechanisms in redis. if that's the case then i'm fine with it. but if we're afraid of unexpected issues, i'm also ok in preventing any stack trace collection until the previous one ended (if the hangs indefinitely, then the whole thing will get disabled till redis is restarted).",0,0,0,0.882373571395874,0.8670033812522888,0.7960398197174072,0.0,accept,unanimous_agreement
1390442896,12658,"following the discussion with and ### **background:** `writestacktraces` allocates a buffer on **its stack** of size **sizeof(stacktrace_data) * len_tids**, where stacktrace_data =~ **800 b** and len_tids is the current number of threads willing to receive sigusr2 signal. it saves the pointer in a global variable. then it calls the thread_mngr that sends sigusr2 to all `len_tids` threads, and each one invokes `collect_stacktrace_data`. in this callback, each thread gets its unique spot in the array allocated by `writestacktraces` and writes its stacktrace into it. when all the threads are done, or we reach timeout we return from thread mngr, print the stacktraces we were able to collect and the stack allocation is no longer available. ### **the problem**: one or more of the threads are late, we reach timeout, return from the thread mangr, exit `writestacktraces`, and then the thread wakes up and starts writing to this address and corrupts other thread's stack. ### **suggested solutions** 1. **one solution** that was suggested was to pre-allocate a global / static stacktrace_data array and save it to a global pointer that will live as long as the server is up. the of such array with our current limits (maximal threads number = 50 and max address per thread = 100) is ~40kb. today an empty instance of redis is ~800kb, and 40kb is pretty big (empty redis takes some 800kb). we can shrink it if we decide to allow a smaller backtrace depth. 2. **changing this allocation size dynamically** before the signal handler requires syncing and making sure there are no threads currently writing to it, and we don't need any additional struggles with sync mechanisms... 3. **writing directly to the log file** from each thread's signal handler (composing a buffer with all the data, and issue a single `write` call). this is problematic since backtrace_symbols (returns a malloc'd array of translated stacktrace address as strings) is obviously not async-signal-safe. we could use `backtrace_symbols_fd` but we're unsure if it's safe, and we'll also have issues with the other per thread info we wanna print.. 4. **dynamic allocation with mmap**, replace the current stack allocation (allocate exactly what we need, when we need it) with an mmap (since malloc is disallowed from a signal). we may need to use the system call directly (the libc one isn't specified as signal safe)",0,0,0,0.9791311025619508,0.9907346963882446,0.9845340251922609,0.0,accept,unanimous_agreement
1390653801,12658,"unless i'm missing something (again), this is just a forward declaration, but we already have a forward declaration below. one of them can be removed.",0,0,0,0.9837835431098938,0.9852955341339112,0.9811579585075378,0.0,accept,unanimous_agreement
1390656177,12658,the one above is with the printf attribute i've just put `serverlogfromhandler` under the same if/else with the existing one of _serverlog,0,0,0,0.9881755113601683,0.9931204319000244,0.9954792261123656,0.0,accept,unanimous_agreement
1390661050,12658,please have a look :point_up:,0,0,1,0.9804521203041076,0.8844124674797058,0.978825867176056,0.0,accept,majority_agreement
1390911417,12658,"i like option-3. currently, we already call `backtrace()` which is listed as not async-safe (if this function call triggers loading libbacktrace.so to memory). we are already taking this risk. we can also call `backtrace_symbols_fd()` in threads. it's listed as ""as-safe"" here: [a link] what are these issues? maybe we can find a workaround for it? wdyt? --- passing fd to threads to make them print their own stacktraces makes sense to me. though, i assume this scenario can occur: 1- main thread opens log fd. 2- one thread is late but main thread moves on, prints stacktraces to the log file and close fd. 3- later, same fd number is assigned to something else in the process. 4- slow thread writes to this fd. we need some sort of synchronization around fd. maybe you can think of something better but first thing that comes to my mind, we can create a pipe() on process startup and let threads write to it. then, main thread copies pipe content to the actual log file: [code block]",1,0,0,0.8006585240364075,0.6000986695289612,0.7334944009780884,0.0,accept,majority_agreement
1391102859,12658,my bad,-1,-1,-1,0.98702734708786,0.9903985261917114,0.9953005313873292,-1.0,accept,unanimous_agreement
1391117954,12658,the issue is that the other info we print could easily get out of order when many threads do several writes each to the same log file.,0,0,0,0.9785991907119752,0.9621777534484864,0.923117697238922,0.0,accept,unanimous_agreement
1391327639,12658,"oh, right... :fearful: maybe threads can fill `struct stacktrace_data` and write it to the pipe fd. main thread will read structs from the pipe and print it to the log file. read/write smaller than `pipe_buf` is atomic. so, i assume we won't see partial struct in the pipe.",-1,-1,-1,0.9246599078178406,0.9667831063270568,0.9940400123596193,-1.0,accept,unanimous_agreement
1392247172,12658,"write() fails when trying to write to a closed fd, so no need to sync.",0,0,0,0.9806710481643676,0.9508723020553588,0.9940265417099,0.0,accept,unanimous_agreement
1392403462,12658,"i mean same fd number can be assigned to some other file or socket after closing the log file. then, write() will not fail. say fd=15 was log file, we close it and move on. later, main thread opens another file/socket for some other purpose. os can assign 15 to this fd (because 15 is available after close()). then, late thread wakes up and write() to fd=15 successfully. (it will write to a socket or a file mistakenly). i assume this is a possible scenario.",0,0,0,0.9838345050811768,0.9817299842834472,0.9890149235725404,0.0,accept,unanimous_agreement
1392792143,12658,"ok, so we'll only call `backtrace` (not `backtrace_symbols*`) from the thread, but instead of filling a global data structure, we'll pass the data to the caller via pipe, and rely on `write` being atomic? sounds like a good idea. then the caller can keep using a stack allocation, not a heap one. in order to avoid that problem with a closed fd, we can keep that pipe forever instead of re-creating it each time. wdyt?",0,0,0,0.8027217984199524,0.89934903383255,0.86800616979599,0.0,accept,unanimous_agreement
1392901904,12658,let me make sure i understood correctly: with server startup: create a global pipe [code block],0,0,0,0.959725260734558,0.9731630682945251,0.9929948449134828,0.0,accept,unanimous_agreement
1392976067,12658,", yes, exactly like that. then, caller can even read one by one: [code block] this way we avoid any memory synchronization issues (hope we don't miss anything else). downside is we have to keep a pipe open forever.",0,0,0,0.8817907571792603,0.9700731635093688,0.6396876573562622,0.0,accept,unanimous_agreement
1393014460,12658,"just out of curiosity, what are the consequences other than 2 occupied fds? does it have any impact on the memory consumption ?",0,0,0,0.772320568561554,0.9496506452560424,0.9817852973937988,0.0,accept,unanimous_agreement
1393061201,12658,"the overheads are negligible. we have other piles, both for the entire duration of the execution, and temporary ones for a certain purpose.",0,0,0,0.9480327367782592,0.8046380281448364,0.9535727500915528,0.0,accept,unanimous_agreement
1393139901,12658,"pipe has a buffer for unread data internally, typically 64 kb. os can do some optimizations though: allocate it on the first use or free it when all data read etc.",0,0,0,0.9860563278198242,0.9931735396385192,0.9900115132331848,0.0,accept,unanimous_agreement
1395190257,12658,"[code block] regarding the flags you suggested **`o_cloexec`** - what does it do? if i understood correctly, the pipe will be closes automatically **for the child process** upon `execve()` ? i agree we need **`o_nonblock`** - don't block (fail) if we: 1. read and the pipe is empty 2. we try to write and there is no space available i suggest we use also **`o_direct`** (since linux 3.4): each write to the pipe is dealt with as a separate packet, and reads from the pipe will read one packet at a time.",0,0,0,0.9672980308532716,0.9933578372001648,0.9905601143836976,0.0,accept,unanimous_agreement
1395251772,12658,"`o_cloexec`: yes, it will automatically close `fds` after exec.. calls. afaik, it is a good practice to open with this flag by default, otherwise, after an execve() call, fds will be a leak for the new process (because signal handler won't be usable after an execve() call anyway). `o_nonblock`: yes, we can use it just to prevent blocking threads `o_direct`: as far as i understand, `o_direct` is useful if you are writing variable length messages to the pipe. as we write and read same struct from the pipe, it shouldn't change anything for us. pipe() guarantees atomicity, so we should never see partial struct bytes in the pipe. write() calls should write struct fully or fail without writing a single byte if remaining space in pipe buffer is smaller than sizeof(stacktrace). if this is not going to change anything for us, i think we should not use it so, our code can stay compatible with older linux distributions. do you see any other issue? maybe i miss something.",0,0,0,0.929104208946228,0.9923241138458252,0.9703137874603271,0.0,accept,unanimous_agreement
1398358470,12658,"no,i thought o_direct guarantees atomicity, thanks for the clarification. the pipe was a great idea imo. well done i've implemented it, please review daily tests: [a link]",1,1,1,0.9477513432502748,0.9929667711257936,0.9947013854980468,1.0,accept,unanimous_agreement
1398364372,12658,"i think this needs an update. if `read` failed, then we'll still have the last record in the buffer.",0,0,0,0.9862639904022216,0.9881975054740906,0.985329568386078,0.0,accept,unanimous_agreement
1398364864,12658,"can't we put this inside setupdebugsighandlers? it's part of the signal handler system (although it also serves assertions). p.s. maybe we should copy some of the checks we do for watchdog (i.e. matching `bioprocessbackgroundjobs` part of the stack trace), into the assertion test?",0,0,0,0.9885603785514832,0.9951093792915344,0.9942307472229004,0.0,accept,unanimous_agreement
1398365483,12658,already fixed :smile:,1,1,1,0.7716354131698608,0.9893559813499452,0.9960655570030212,1.0,accept,unanimous_agreement
1398373912,12658,can we reuse `anetpipe()` here same as other pipes? seems like it has some portability fixes in it: [a link],0,0,0,0.986999809741974,0.9893370866775512,0.99489164352417,0.0,accept,unanimous_agreement
1399350907,12658,we don't need the pipe on other systems than linux.,0,0,0,0.9679581522941588,0.979953408241272,0.9900510907173156,0.0,accept,unanimous_agreement
1399476542,12658,yes we can and should,0,0,0,0.9777435064315796,0.9758541584014891,0.9798359870910645,0.0,accept,unanimous_agreement
1399514676,12658,ping,0,0,0,0.9714881777763368,0.9308286309242249,0.4991936683654785,0.0,accept,unanimous_agreement
1399554019,12658,"regardless of portability, we have a convenience wrapper, let's use it.",0,0,0,0.9852809309959412,0.9880585074424744,0.9904274940490724,0.0,accept,unanimous_agreement
1399630257,12658,maybe we should add a short sleep / yield here? just so that it's not an intense busy loop?,0,0,0,0.948181450366974,0.97541081905365,0.9814453721046448,0.0,accept,unanimous_agreement
1400049942,12658,but why initialize the pipe for systems where it will never be used?,0,0,0,0.969602346420288,0.9818472266197203,0.9767390489578248,0.0,accept,unanimous_agreement
1400059762,12658,i think that in most cases it will just increase this loop duration. i experimented with different timeouts and noticed that i need a super low timeout (in ns) to get even one of the threads to be late.,0,0,0,0.9684154987335204,0.9625767469406128,0.9761441349983216,0.0,accept,unanimous_agreement
1400340533,12658,"still, on an overloaded system, not sure if the false system call (vdso) will induce a context switch, rather than just eat cpu. i'd rather add a `usleep(10)`, or even 1, or alike.",0,0,-1,0.9725977778434752,0.8963131308555603,0.6854766607284546,0.0,accept,majority_agreement
1400352459,12658,"i meant portability between linux versions. it tries pipe2() first then fallback to pipe(). also, in future, if we want to introduce a fix to pipe2(), then we can do it in a single place if all places call a single wrapper function.",0,0,0,0.9827333688735962,0.992172122001648,0.9900444746017456,0.0,accept,unanimous_agreement
1401242288,12658,i hate to say it but `usleep()` is not listed among signal-safe functions. maybe we can use `select()`: [code block],-1,-1,-1,0.9161264300346376,0.9919215440750122,0.8997749090194702,-1.0,accept,unanimous_agreement
1401958079,12658,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
1402503712,12658,"the header is: [code block] so it makes sense that the footer will have a similar format. i.e. `-` instead of `=`, upper case. maybe [code block]",0,0,0,0.9862003326416016,0.994318425655365,0.993871808052063,0.0,accept,unanimous_agreement
1402947666,12658,"it doesn't do that. it's just that when it does create a pipe, it does it with our wrapper, same one we use everywhere else..",0,0,0,0.6683510541915894,0.9705058336257936,0.9914302229881288,0.0,accept,unanimous_agreement
762518839,9812,why did you delete this part?,0,0,0,0.9371044635772704,0.9875844120979308,0.9861327409744264,0.0,accept,unanimous_agreement
762519297,9812,i think you can just delete that test. same probably applies for others that are no longer relevant. like ones that where created to test the script cache and it's invalidation.,0,0,0,0.9802138209342957,0.9908515810966492,0.9865322709083556,0.0,accept,unanimous_agreement
762519415,9812,"i suppose it's possible that two calls to random will return the same value in rare cases. i think we can just delete that test, or keep something basic (no assert?) just for coverage.",0,0,0,0.9860228300094604,0.9726898074150084,0.9845906496047974,0.0,accept,unanimous_agreement
762519528,9812,i think we should keep that test since old aof files can still have eval in them. we need to convert that test to use a hand crafted aof file (see how `append_to_aof` is used in `integration/aof.tcl`),0,0,0,0.9863574504852296,0.9934775829315186,0.9894373416900636,0.0,accept,unanimous_agreement
762519700,9812,maybe it would be easier to review and better for the blame log if you keep the old indentation..,0,0,0,0.9695353507995604,0.9891347885131836,0.9724978804588318,0.0,accept,unanimous_agreement
762539625,9812,"i guess we need to add a ""dead"" options table to clean up this code.",0,0,0,0.958033323287964,0.8874510526657104,0.9745035171508788,0.0,accept,unanimous_agreement
762539962,9812,"do we need to continue to support this as a ""dead"" option? i think it's not documented and only used in tests. i suggest just removing this.",0,0,0,0.97657972574234,0.9376591444015504,0.986840844154358,0.0,accept,unanimous_agreement
762541110,9812,for the sake of the blame log we can avoid re-numbering the consts and just add an empty marker or comment where we have the whole.,0,0,0,0.9680830240249634,0.990257978439331,0.988028049468994,0.0,accept,unanimous_agreement
762548083,9812,do we also need to get rid of the `to-sort` flag and all related code? if we don't check `cmd_sort_for_script` anymore then we can delete it too and there's no need to have any commands marked with it.,0,0,0,0.9882935285568236,0.995096743106842,0.9928116202354432,0.0,accept,unanimous_agreement
762548978,9812,"alternatively you can change it to a `wait_for_condition` with a 0 timeout and, lets say, 10k tries where you repeat the `eval` and wait for them to be not equal.",0,0,0,0.9779231548309326,0.9913578033447266,0.9908344745635986,0.0,accept,unanimous_agreement
762555836,9812,"i thought i saw it get deleted, didn't look closely enough... we do not need to maintain backwards compatibility for debug sub-commands at all. we can simply drop it.",0,0,0,0.916378140449524,0.9228625893592834,0.9417142868041992,0.0,accept,unanimous_agreement
762608709,9812,why removing this? you still need to check that you are getting an argument no?,0,0,0,0.803368091583252,0.9775665402412416,0.9841212034225464,0.0,accept,unanimous_agreement
762665342,9812,mistake fixed,-1,0,0,0.574524998664856,0.8154381513595581,0.934861660003662,0.0,accept,majority_agreement
764608137,9812,mistake fixed:,-1,0,0,0.6883106827735901,0.6770238280296326,0.9430458545684814,0.0,accept,majority_agreement
764673964,9812,"this is good, but i wonder if we really need to store the argc info for deprecated configs. it might be enough just to know the deprecated config's name in order to ignore it since we don't really care what args are passed to it.",0,0,0,0.8691172003746033,0.9354732036590576,0.6315661668777466,0.0,accept,unanimous_agreement
764698465,9812,is there any better way create a delay in the script than a 1.5 million iteration loop? if we want to check a script timeout then perhaps create an infinite loop?,0,0,0,0.9798914790153505,0.9811788201332092,0.9913528561592102,0.0,accept,unanimous_agreement
764700351,9812,shouldn't we check that the read reply indicates a times out script?,0,0,0,0.9812684655189514,0.9934159517288208,0.9935025572776794,0.0,accept,unanimous_agreement
764701003,9812,"if the script is timed out then i'd expect an error not ""y""",0,0,0,0.9775089025497437,0.9677753448486328,0.987656831741333,0.0,accept,unanimous_agreement
764711908,9812,"infinite loop: maybe no, for we expect the script **finishes** but its running time greater than `lua-time-limit`? this case is modified from a test here [a link] mentioned",0,0,0,0.9812418222427368,0.9837575554847716,0.9888249039649964,0.0,accept,unanimous_agreement
764718733,9812,"`$rd read` is synchronous and would read an 'ok' returned by script, if i get its meaning correctly.",0,0,0,0.9892663955688475,0.9894413948059082,0.9932357668876648,0.0,accept,unanimous_agreement
764719117,9812,"'timeout' isn't equal to script kill. after `$rd read`, the script has finished its operations successfully.",0,0,0,0.9837924242019652,0.9925357103347778,0.9857190251350404,0.0,accept,unanimous_agreement
764821576,9812,"i had some chats about this topic with and realized that i think it's better to keep these flags for the sake of #9359 / #9876. i.e. we wanna provide clients and anyone else, all there is to know about redis commands, and one of the things to know is when a command has a non-deterministic reply (random content or random order). this also means two additional changes: * rm_createcommand should be able to set that flag (same as it sets the `no-monitor` flag and others) * maybe we wanna give a better name for that flag in command command (i.e. instead of `sort_for_script`), and maybe even move it to another flags field? * hgetall should be set with that flag (today it has the `random` flag because the lua code was limited and wasn't able to sort it's output. fyi / please comment. i suppose some of that work can be done in another pr, but we need this one to at least avoid deleting the flag.",0,0,0,0.958884596824646,0.9749566316604614,0.9547491073608398,0.0,accept,unanimous_agreement
764835290,9812,"i didn't read the full pr, please remind me why did we need to sort in the past, and now we don't anymore? the comment says: [code block] but why does it matter if we're in a script or not? i would expect sunion to behave the same as a script running sunion and replying with its reply. anyway, my observations: 1. script_random_dirty is no longer needed 2. ""to-sort"" flag is no longer needed (we will use ""random"" instead) 3. ""random"" should be a doc-flag rather than a command flag",0,0,0,0.8529497981071472,0.9881690740585328,0.9575391411781312,0.0,accept,unanimous_agreement
764909200,9812,"i think this test is ok (timeout means redis responds to command during the script, it didn't fail). specifically, it's the same test we had before, but because of our change the old test needed adjustments, to still cover cases of loading old aof files. the test itself may not be perfect, and although we can work on it to improve it, maybe we can also leave it imperfect.",0,0,1,0.9749221205711364,0.9835149049758912,0.6916691660881042,0.0,accept,majority_agreement
764910862,9812,"i feel we're devoting too much code to this ""mechanism"", personally i'm also ok with the previous approach (as long as we don't have too many dead configs, e.g. more than 8)",-1,0,-1,0.8863819241523743,0.9269906282424928,0.676459550857544,-1.0,accept,majority_agreement
764917507,9812,"it was needed since eval was propagated to the replica as is, and redis needed to make sure it'll behave there exactly the same. (e.g. if you do hvals and only use the first 2). it also used to forbid writes after using an random command (like randomkey). so now that redis doesn't need that anymore, we can delete it, but i think that instead of deleting it, it should be a client hint (#9876) however, a few observations: 1. i think there's still a difference between an random command (like randomkey), and one that may just return the same results at a different order (hvals). 2. hgetall was incorrectly flagged because of limitations of the sorting mechanism. 3. spop was flagged as raondom, but i suppose it's too late (it's a write command of it's own). 4. the `sort_for_script` flag was already documented, but maybe we can ""break"" things and move + rename it. bottom line, i want this pr to just delete all the logic about sorting and such, but keep the command flags, and i want #9876 to take these flags to the right place.",0,0,0,0.9696733355522156,0.9906983971595764,0.987351894378662,0.0,accept,unanimous_agreement
765066795,9812,"yes i agree... both ""random"" and ""sort_for_script"" (maybe ""random-order""..?) should be command hints, not flags can't we drop ""random"" for hgatll, spop, and possibly other discriminated commands? we remove it from flags, so we kinda break the output anyway...",0,0,0,0.9596771597862244,0.856804609298706,0.9679154753684998,0.0,accept,unanimous_agreement
765609720,9812,"observation: `$ grep -rn ""cmd_random"" .` `./src/server.h:193:#define cmd_random (1ull<<7) /* ""random"" flag */` `./src/server.c:4533: c->flags |= cmd_random;` `./src/server.c:5781: flagcount += addreplycommandflag(c,cmd->flags,cmd_random, ""random"");` `./src/module.c:797: else if (!strcasecmp(t,""random"")) flags |= cmd_random;` i think we can re-define them: ""to-sort""(renaming it as ""random-order"" or ""random-output"") commands would produce random outputs, while ""random""(needs renaming too, maybe ""random-update""?) commands would lead to random operations to db. in that ways these two flags are untied and can both exist on a single command. i did an redo commit [a link] these flags have been re-added to codebase, maybe you missed the commit out? anyway, these are little relevant to this pr and may be discussed in another issue/pr separately.",0,0,0,0.9809529185295104,0.9877606630325316,0.9933250546455384,0.0,accept,unanimous_agreement
765664100,9812,"i didn't miss that commit.. just wanted to state i wanna keep it that way (since the previous instruction was to re-do that after guy's pr is merged). p.s. i think the `random` flag doesn't mean it makes random changes in the data set (e.g. randomkey), it means the reply is random (not just an ordering issue). spop is a special case of a command that's both `random` and `write`.",0,0,0,0.8401254415512085,0.9554497599601746,0.98043030500412,0.0,accept,unanimous_agreement
766138298,9812,"if `match` is 1 we skip this code, maybe we can add a `goto` to deal match.",0,0,0,0.9881373047828674,0.9947383999824524,0.991625726222992,0.0,accept,unanimous_agreement
767272115,9812,"one of the very few consistent styling guides in redis, is that it avoids using line comments. [code block]",0,0,0,0.978074312210083,0.9921701550483704,0.9837886095046996,0.0,accept,unanimous_agreement
767504190,9812,"re p.s.: what i meant is not their definitions now, but that we can distinguish these commands with ""random-order""/""random-update""/... further, even if we are making some small changes on them i think. and that's the meaning of **re-define**.",0,0,0,0.971547782421112,0.9833342432975768,0.9898722171783448,0.0,accept,unanimous_agreement
768592154,9812,why do we need preventcommandpropagation? i think it's just enough to remove the call to forcecommandpropagation,0,0,0,0.9832725524902344,0.9845160245895386,0.9886217713356018,0.0,accept,unanimous_agreement
768592579,9812,"also, we need to remove the `may-replicate` flag.",0,0,0,0.98740816116333,0.9944974780082704,0.994187831878662,0.0,accept,unanimous_agreement
768597464,9812,"i don't think we wanna mention `debug loadaof` in the test. the test comes to test aof loading on a replica, instead of doing it properly, it used the debug command (as a way to achieve something similar), but that's not the purpose of the test. actually, now that we generate the aof on our own, we can just let the server start from it, and there's no need for debug loadaof at all. i also don't understand why you negated the name of the test (adding ""can't"") and why the assert is for """" and not ""102""? maybe there's a bug to fix? [code block]",0,0,0,0.8994183540344238,0.9732410311698914,0.8634957075119019,0.0,accept,unanimous_agreement
768599340,9812,"this assert may not get to fulfill its purpose. let's add one additional command either inside the multi, or after it, and validate that (i.e that there's no script load before it.",0,0,0,0.9714977145195008,0.9906567335128784,0.9852139353752136,0.0,accept,unanimous_agreement
768603171,9812,"ohh, i now see your other post, i suppose this is a bug we need to fix. but either way, this test should now use plain aof loading (start a server to be configured as a read-only replica, and set it to load an aof file on startup)",0,0,0,0.967371106147766,0.9057427644729614,0.9828029870986938,0.0,accept,unanimous_agreement
769202085,9812,should we remove the propagation of `script flush` and its `may-replicate` flag too? i think we should.,0,0,0,0.9884263277053832,0.9948413968086244,0.9920297861099244,0.0,accept,unanimous_agreement
769325745,9812,"yes, i agree. this means the existence of the script (effects of eval, script load, script flush), are always local, and never propagate to replicas / aof.",0,0,0,0.9859555959701538,0.9852479696273804,0.985363781452179,0.0,accept,unanimous_agreement
769450953,9812,"i don't how (of if), this test passed, but the whole point of it was to make sure we can load old aof files that contains eval with write commands, even in read-only replicas. so if it fails with my suggestions, we must debug it and see what's wrong. if you can't figure it out, let me know, i'll clone this pr an help. [code block]",0,0,0,0.733930230140686,0.785123884677887,0.9429025650024414,0.0,accept,unanimous_agreement
769452826,9812,not sure if we really need the multi in this test.. enough to just show that flush isn't propagated. or did i forget part of our discussion?,0,0,0,0.8809126615524292,0.8127660751342773,0.6294717192649841,0.0,accept,unanimous_agreement
769460311,9812,i would like to add a check to confirm that it propagates the right commands. i.e. using `attach_to_replication_stream` and `assert_replication_stream`. i think that's the purpose of this test. and let's also add expire to that list of command (propagates as expireat),0,0,0,0.9821425080299376,0.9854872226715088,0.9892147183418274,0.0,accept,unanimous_agreement
769501088,9812,"i was setting it as """" instead of 102 to check if all tests run successfully to make sure that this is the only problem i'm going to deal with(and it fails with your suggestions, while passes with current commit). currently i'm going to debug it to see what's going on on it.",0,0,0,0.9573634266853333,0.9766448736190796,0.97658771276474,0.0,accept,unanimous_agreement
769503859,9812,"we didn't mention `script flush` command (or i forgot about it), so i added this test. sure that we can drop the 'multi/exec' part and only test about `script flush`, but it does no harm adding the 'multi/exec', which can cover more cases, doesn't it?",0,0,0,0.9785624146461488,0.9873122572898864,0.9902445077896118,0.0,accept,unanimous_agreement
769505596,9812,"oops, looks like i forgot to clean the messes up",-1,-1,-1,0.9777082800865172,0.9603204131126404,0.9597815871238708,-1.0,accept,unanimous_agreement
769510627,9812,agree,0,0,0,0.9757640957832336,0.9753760099411012,0.8991182446479797,0.0,accept,unanimous_agreement
769530473,9812,why delete `aof-use-rdb-preamble no`? default it is `yes`.,0,0,0,0.982115626335144,0.9951069355010986,0.9927858114242554,0.0,accept,unanimous_agreement
769561986,9812,"now that it's a trivial command (no propagation), in theory there's no need to test it neither here no there (with / without multi). back when script load had special (non trivial) handling for propagation, it made sense to test it both ways. i don't mind keeping the multi (it just looks odd since i didn't understand why should we), but i also don't mind dropping this test completely, or just keep it simpler and remove the multi.",0,0,0,0.5473709106445312,0.9567265510559082,0.8095982074737549,0.0,accept,unanimous_agreement
769562979,9812,"the config was only needed because we used bgrewriteaof to generate an aof (after running eval commands). but now that we generate the config manually, this config is meaningless (doesn't affect the test).",0,0,0,0.9792501330375672,0.987896203994751,0.9889784455299376,0.0,accept,unanimous_agreement
769585814,9812,"closing this thread, moved the conclusions to #9876",0,0,0,0.9878215193748474,0.9915282726287842,0.9942598342895508,0.0,accept,unanimous_agreement
769705387,9812,:scream: i wonder how why the tests didn't catch it when we broke it. do you happen to know?,-1,-1,-1,0.9763005971908568,0.7423936128616333,0.8901065587997437,-1.0,accept,unanimous_agreement
770256553,9812,"no, maybe it just wasn't covered by the test `eval processes writes from aof in read-only slaves` (it should be). i think maybe this test case was missed for changing when effects replication was introduced?",0,0,0,0.985153079032898,0.9934948086738586,0.989237904548645,0.0,accept,unanimous_agreement
770262397,9812,"actually if we decide not to change the behaviour of `script flush` any more, we could just drop this case. otherwise we'd better keep this case? maybe it looks weird but it's for robustness i think?",0,0,-1,0.8748155236244202,0.7966428995132446,0.7112306356430054,0.0,accept,majority_agreement
770278991,9812,fine. let's keep it.,0,0,0,0.8947346806526184,0.5806180238723755,0.7719569802284241,0.0,accept,unanimous_agreement
770289532,9812,one question: is there any special case when mget would get rewritten now? if no i'll drop it. didn't find it anyway.,0,0,0,0.935866117477417,0.9784510135650636,0.9719898700714112,0.0,accept,unanimous_agreement
770395315,9812,"looks like it was covered by that test, and and indeed it disabled preamble-rdb, and, used debug loadaof that empties the old db, **but it looks like the test forgot to disable `lua-replicate-commands`**, so since that feature was made the default, this test was ineffective. luckily, now that we decided to completely drop support for disabling lua-replicate-commands, we realized that this test can no longer work by letting the eval commands generate the aof, and we moved to generate it on our own, and found that bug. and we're also lucky that the bug that checked the wrong variable is not yet released.",0,0,0,0.8423165082931519,0.9730479121208192,0.97323077917099,0.0,accept,unanimous_agreement
770434506,9812,"please add another set or incr command at the end, so we can be sure that it's not just timing that caused that mget not to be replicated",0,0,0,0.9877055287361144,0.99075186252594,0.9939361214637756,0.0,accept,unanimous_agreement
770436244,9812,"let's add another command here as well (after the last spop), this empty multi-exec is gonna be gone soon (see #9890), so in order to be sure the spop is not propagated, we need some incr here.",0,0,0,0.9835758805274964,0.9921684861183168,0.989812672138214,0.0,accept,unanimous_agreement
770437794,9812,"mget was never re-written, i think this test is just to make sure read commands are not propagated. for all i care you can unify these 3 tests back to one. or if you keep them separated, you can rename this test.",0,0,0,0.7767581939697266,0.9796406626701356,0.9722075462341307,0.0,accept,unanimous_agreement
770445724,9812,"i think it's clearer separating them into different tests, or there would be too many operations in one test, which is complex and may no so easy to read.",0,0,0,0.935477077960968,0.9743525981903076,0.973097801208496,0.0,accept,unanimous_agreement
770446151,9812,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1496859167,12826,"i see in the code, we allow n to be negitive (memkeys-samples is the same)?",0,0,0,0.9887386560440063,0.9917568564414978,0.9939809441566468,0.0,accept,unanimous_agreement
1496859511,12826,i'm wondering if we need this check. i see that other hdr_record_value calls actually don't check the return value.,0,0,0,0.9584969282150269,0.7853214144706726,0.9629309773445128,0.0,accept,unanimous_agreement
1496860254,12826,"sdscatrepr will append a `""""`, so i removed the '' [code block]",0,0,0,0.9885693192481996,0.9944737553596495,0.9950868487358092,0.0,accept,unanimous_agreement
1496931970,12826,"good point. even if `--memkeys_samples` could be -1 (not to use `samples`), the value entered by the user should not be negative. i changed `unsigned memkeys_samples;` to be an `int` to solve [a link] we could add something like for `--cursor` or `--top`: [code block] and do the same for `--memkeys-samples`.",1,0,1,0.957100749015808,0.927473485469818,0.9509015083312988,1.0,accept,majority_agreement
1500242248,12826,"the fact `--memkeys-samples` is using `atoi()` made me use an `int`. if we want to be accurate, we should use a `long long`, like it is done in `memorycommand()`, and check the value to be [0, llong_max].",0,0,0,0.9888933300971984,0.994322657585144,0.9925053119659424,0.0,accept,unanimous_agreement
1519158977,12826,`memkeys_samples` was changed to `long long` and the argument value in `--memkeys-samples` and `--keystats-samples` is being checked. we now check for `strtoull()` parsing issues (`--cursor` and `--top`) and did the same for `strtoll()` (`--keystats-samples` and `--memkeys-samples`). i did not check for `erange` as i thought it was overkill.,0,0,0,0.9839841723442078,0.9942640662193298,0.9933092594146729,0.0,accept,unanimous_agreement
1553304606,12826,"fefresh too fast looks a little flashy, refresh every 100 looks good.",1,1,1,0.9191790223121644,0.4278157949447632,0.9508812427520752,1.0,accept,unanimous_agreement
1553476824,12826,`1ull` and uint64_c are the same. [code block],0,0,0,0.9881777167320251,0.9927805066108704,0.9949350953102112,0.0,accept,unanimous_agreement
1553657136,12826,check reaching the end in advance? [code block],0,0,0,0.9886298179626464,0.9909833669662476,0.995740532875061,0.0,accept,unanimous_agreement
1553710215,12826,what about make the progress to 100% if it is 0(the scan was completed). [code block],0,0,0,0.9877678751945496,0.9903796911239624,0.9949750900268556,0.0,accept,unanimous_agreement
1554519124,12826,"true, we could check we reached the end first. though, we need `int j;` outside the `for` as is it used to add to the count on the next line: `dist->size_dist[j].count++;`.",0,0,0,0.9856522083282472,0.99443781375885,0.9918471574783324,0.0,accept,unanimous_agreement
1554519704,12826,thanks for finding the mix of spaces and tab in the indentation. i will have to double check my ide to make sure all tabulations are converted automatically to spaces.,1,1,1,0.9090448021888732,0.5606173872947693,0.9470615386962892,1.0,accept,unanimous_agreement
1554520849,12826,is it much better? this make distribution more readable and there is no need to check `dist->size_dist[j].size`. [code block],0,0,0,0.9777069091796876,0.9895853400230408,0.9860900640487672,0.0,accept,unanimous_agreement
1554521061,12826,"we could finish the scan with less than 100% if we use `--cursor` (we get the cursor position when we interrupt the scan with ctrl-c). when we start the scan at a specific cursor, it might be better to show the user that the information is not on 100% of the keys.",0,0,0,0.987803041934967,0.9925191402435304,0.990204930305481,0.0,accept,unanimous_agreement
1554522224,12826,i'm okay with both.,0,0,0,0.9278429746627808,0.6846001744270325,0.9313865303993224,0.0,accept,unanimous_agreement
1554522448,12826,"oh, indeed, more readable. and i missed listnodevalue(). thanks! i think i did the same for loop mistake in displaykeystatstopsizes(). i will change it there too.",1,1,1,0.9641631245613098,0.9869999289512634,0.9912499189376832,1.0,accept,unanimous_agreement
1554523489,12826,"you are right about the ""flickering"". i agree that 10 is a bit too low. 100 is looking good on a local database, but when i tested over the network, i remember i waited a while before seeing the first progress information. i thought about a spinning cursor, or anything that gave a visual feedback to show the user we are not frozen. let me do more test and see if 100 is ok most of the times.",0,0,0,0.8385958671569824,0.6721275448799133,0.8133625388145447,0.0,accept,unanimous_agreement
1554527341,12826,"that might work. we need to change the comment above `sizedistinit()` to replace {0, 0}. in addition, we need to change `displaykeystatslengthdist()` to use uint64_max as `for (int i=0; dist->size_dist[i].size; i++)` does not work in that case. let me test it.",0,0,0,0.9814903736114502,0.9935054779052734,0.9925285577774048,0.0,accept,unanimous_agreement
1554728675,12826,"i created a database in the cloud to test how long it will take to see the first refresh. with 10, the first data is showing around 6 seconds. with 100, it took around 90 seconds (i was expecting 60 seconds...). even with 10 it is a long time. would it be acceptable to introduce a refresh display based on time and not scan_loops? for instance every 300ms? if so, i can give it a try.",0,0,0,0.959923267364502,0.9643712043762208,0.8997741341590881,0.0,accept,unanimous_agreement
1554793780,12826,"yeah, it is reasonable.",0,0,0,0.9531205296516418,0.894524872303009,0.9747494459152222,0.0,accept,unanimous_agreement
1555120406,12826,the latest commit is using uint64_max.,0,0,0,0.9889461398124696,0.9916091561317444,0.9950188398361206,0.0,accept,unanimous_agreement
1555121167,12826,"the refresh is now every 300ms (`findbigkeys()`, `keystats()`, and `findhotkeys()`).",0,0,0,0.989026129245758,0.9921786785125732,0.9949295520782472,0.0,accept,unanimous_agreement
1555307629,12826,"whether i is out of bounds? i will be greater than the length of size_dist, and theoretically the loop could infinite, size will always be less than uint64_max. it seems that we still need to put a {0,0} at the end of the `distribution`, `otherwise we won't know its size.",0,0,0,0.9766985774040222,0.9681670665740968,0.990328848361969,0.0,accept,unanimous_agreement
1556833713,12826,same as above.,0,0,0,0.9746477603912354,0.9857698678970336,0.9922299981117249,0.0,accept,unanimous_agreement
1556834296,12826,"the original version was 0 terminated, i think your suggestion to terminate with uint64_max works too. we just have to make sure we enter the last element with uint64_max or 0, depending of what we want to test for. `size_dist_entry distribution[] = { {32, 0}, {256, 0}, {uint64_max, 0} };` or `size_dist_entry distribution[] = { {32, 0}, {256, 0}, {0, 0} };` when we add a value, we stop when the value is less or equal to the current element, it works because we cannot go above uint64_max. when we read the count per value, we stop when we reach uint64_max. we read the entire array. we could write the for loop this way too: `for (int i=0; dist->size_dist[i].size != uint64_max; i++)` maybe we could test with `dist->max_size` to stop earlier, but i am not sure it is going to make the code simpler. we can pick 0 terminated or uint64_max terminated, i think both can work. we should just pick what makes it easier to read. let me know if i missed something that will make the loop to go out of bound.",0,0,0,0.9816126227378844,0.9911144971847534,0.9879330992698668,0.0,accept,unanimous_agreement
1556854086,12826,"thanks, i will correct the same mistake i did in updatetopsizes(), keystats(), and findhotkeys().",1,0,1,0.5956238508224487,0.5090796947479248,0.842949628829956,1.0,accept,majority_agreement
1556877953,12826,"that is soloestoy code, but looks like it went under my name when zuiderkwast asked me to add the progress bar to memkeys, bigkeys, and hotkeys. though, i think your suggestion is good.",0,1,1,0.5064852833747864,0.7796502113342285,0.9875249862670898,1.0,accept,majority_agreement
1558870223,12826,i tested and it crashed. the reason is that `k` is an `unsigned int`. it works if `k` is an `int`. let me do more test with `k` as an `int` and i will push a commit later this week.,0,0,0,0.9776453971862792,0.9615326523780824,0.9774870276451112,0.0,accept,unanimous_agreement
1560467247,12826,last commit has the new `for` loop with `k` as an `int` to make it work.,0,0,0,0.987874448299408,0.9919077157974244,0.9944592714309692,0.0,accept,unanimous_agreement
1560467753,12826,last commit is back to 0 terminated distribution.,0,0,0,0.9851074814796448,0.9740807414054872,0.9905347228050232,0.0,accept,unanimous_agreement
1560477161,12826,done as well.,0,0,0,0.9804908633232116,0.9867402911186218,0.9896328449249268,0.0,accept,unanimous_agreement
1561964784,12826,what about adding a macro like is_tty_or_faketty() to avoid repeated so many times.,0,0,0,0.9522690773010254,0.9736720323562622,0.9877079129219056,0.0,accept,unanimous_agreement
1561969070,12826,"you are right, even if it will not reduce the number of lines, it will probably help the readability. let me give it a try.",0,0,1,0.6839949488639832,0.5523607730865479,0.6017343401908875,0.0,accept,majority_agreement
1561992398,12826,"done. actually, as the macro is shorter, it reduced some `if` statements from 2 lines to 1 line.",0,0,0,0.9882488250732422,0.9892305731773376,0.9919394850730896,0.0,accept,unanimous_agreement
1596706675,12826,what about eliminating `cleanprintln()` which is only used by `cleanprintfln()`. [code block],0,0,0,0.9875515103340148,0.9931218028068542,0.994767427444458,0.0,accept,unanimous_agreement
1597318180,12826,looks better and easier to read! without the recursion we can merge both functions.,1,1,1,0.9753106832504272,0.9159085750579834,0.9725762009620668,1.0,accept,unanimous_agreement
1597406836,12826,why make effort to touch these? just to fill the floating part? doesn't feel very necessary.,-1,0,0,0.728325366973877,0.8029260635375977,0.6556559801101685,0.0,accept,majority_agreement
1597407239,12826,"on the other hand, i'm a fan of this implement that returns the original s. although it makes cleanprintfln save two lines, it still seems werid.",-1,-1,1,0.5363016724586487,0.737387478351593,0.8285749554634094,-1.0,accept,majority_agreement
1597434293,12826,why not showing this in the tty?,0,0,0,0.9500547051429749,0.9603842496871948,0.9855905771255492,0.0,accept,unanimous_agreement
1597504590,12826,i used the return value of `bytestohuman()` 7 times when calling `cleanprintfln()`. i thought it will be convenient to return a `char*`. we have the choice to use the return value or not. let me know if you prefer to have: [code block] instead of: [code block] i am ok with both.,0,0,0,0.9651079177856444,0.9153355360031128,0.8019916415214539,0.0,accept,unanimous_agreement
1597505357,12826,in that case it's better update the comment as well.,0,0,0,0.985435664653778,0.9905391931533812,0.9923261404037476,0.0,accept,unanimous_agreement
1597505961,12826,"as i added terabyte (t) in `bytestohuman()`, i wanted to show in the comment every possibilities. moreover from the original comment we might think that we only convert to integer numbers, when in fact, even with the original version, we will display 100.00m.",0,0,0,0.9841489195823668,0.9909075498580932,0.9910620450973512,0.0,accept,unanimous_agreement
1597506047,12826,"good point, i will add in the comment that the return value is the original *s pointer.",1,1,1,0.9047353863716124,0.592058002948761,0.9283167719841005,1.0,accept,unanimous_agreement
1597507578,12826,"in the tty, it is already displayed as part of the progress bar: [code block] we preserved the old output when redirected to a file in case someone did an automation around that.",0,0,0,0.989674985408783,0.9887190461158752,0.9944549202919006,0.0,accept,unanimous_agreement
1612992983,12826,what about adding some comments for these parameter?,0,0,0,0.9829058647155762,0.9885404706001282,0.9946964979171752,0.0,accept,unanimous_agreement
1613108915,12826,is this comment outdated? or can be removed?,0,0,0,0.9514949917793274,0.9844902157783508,0.9914225935935974,0.0,accept,unanimous_agreement
1613112327,12826,please check if this todo is done.,0,0,0,0.984075963497162,0.9890080690383912,0.993708610534668,0.0,accept,unanimous_agreement
1614196693,12826,"after checking, we cannot implement this todo because we changed the output in `findbigkeys()`. i will remove the comment.",0,0,0,0.9834928512573242,0.984186828136444,0.9942718744277954,0.0,accept,unanimous_agreement
1614197997,12826,"the comment is not outdated, there are two ways to check if we interrupted the loop. as we are giving the cursor to the user, i think we should keep the test on `it`. i will remove the comment.",0,0,0,0.9850034117698668,0.971369743347168,0.9936338663101196,0.0,accept,unanimous_agreement
1614198774,12826,we have to keep `int j` outside the loop as we are using it after.,0,0,0,0.9809515476226808,0.9889206290245056,0.9919220209121704,0.0,accept,unanimous_agreement
1614219527,12826,done in the latest commit.,0,0,0,0.9857707023620604,0.9885199666023254,0.994671642780304,0.0,accept,unanimous_agreement
637365526,8974,"you need to align the pointer upwards (find set of complete pages inside this allocation). this is probably what corrupted your tests [code block] you need to align the pointer upwards, to find a complete set of pages that fall inside the allocation (p. s. comment needed). this is what probably corrupted your tests..",0,0,0,0.868496298789978,0.974417805671692,0.9795156121253968,0.0,accept,unanimous_agreement
637513191,8974,"truly thanks i suddenly notice i should align the pointer upwards instead of downwards, because the memory address is increased upwards",1,1,1,0.9816272854804992,0.9867609739303588,0.946833610534668,1.0,accept,unanimous_agreement
669867850,8974,"we do have have_malloc_size on glibc malloc too. [code block] btw, i think it's odd this method is placed in server.c, maybe we should move it to zmalloc.c (and find a way to init the page_size global just once)",0,0,0,0.955883800983429,0.9912410378456116,0.9758936166763306,0.0,accept,unanimous_agreement
669868676,8974,we now have `server.in_fork_child` that can be used instead of these.,0,0,0,0.9884218573570251,0.9921938180923462,0.995058298110962,0.0,accept,unanimous_agreement
669871156,8974,"we realized that although peak is important, average and current are also important. if we're gonna stick to using static variables in that function (not a temp code), let's print them too.. and also since by default only the final print is displayed in the log, the average sample count would be nice to have too (since this function can throttle itself)",0,0,0,0.9129045009613036,0.9489060044288636,0.97469824552536,0.0,accept,unanimous_agreement
669874574,8974,"this function is called by the parent, you can't use a static var here. i agree that now that the final cow and the peak cow are different, we want these stat fields to show the peak, but in order to do that we need to zero some initial server metric when we fork, and then update it here. additionally if we have that variable, maybe we should also have an info field that reflects the peak (i.e. `current_cow_peak` in addition to `current_cow_size`)?",0,0,0,0.9831039905548096,0.9908522963523864,0.992764174938202,0.0,accept,unanimous_agreement
669877060,8974,"i think the term ""unused"" isn't good here. maybe some adverb like ""dismiss"" or ""dispose""? or maybe ""dontneed"" to refer to our system level hack? also, we need some big comment explaining this here, specifically why we don't bother to do that on some object types (small strings, etc)",0,0,0,0.9213947057724,0.9619773626327516,0.9621090888977052,0.0,accept,unanimous_agreement
669879431,8974,"the members in a set (and fields in hash, or list) can be big (in some cases). did we decide we're not gonna handle them? if we're afraid of the extra iteration, maybe we wanna integrate that freeing logic into the saving code, i.e. release list nodes and hash fields one by one when iterating on them for saving. considering today we have preamble aof, and it's by default, i'm even willing to overlook the old aofrw code and only do that for rdb saving.",0,0,0,0.9550104141235352,0.9774608612060548,0.9786829948425292,0.0,accept,unanimous_agreement
669881198,8974,"my benchmarks showed that if there's no write traffic on the parent, the extra calls for madvise don't slow down the saving. but this loop might. sometimes the server may have many thousands of clients. we need to re-think this.",0,0,0,0.9732694029808044,0.9430667757987976,0.9849039316177368,0.0,accept,unanimous_agreement
672165143,8974,"yes, i am afraid of the extra iteration, i am not sure it is right way to integrate that freeing logic into the saving code, that may make code coupled. i think it is usual that aof only stores redis command, so i did that.",-1,-1,-1,0.9671661257743835,0.883727490901947,0.9051518440246582,-1.0,accept,unanimous_agreement
672165192,8974,"yes, we should avoid too much loop, i am not sure, but clients' memory will be changed if there is much write traffic.",0,0,0,0.9460535049438475,0.6393693685531616,0.9843512773513794,0.0,accept,unanimous_agreement
674460403,8974,[code block] `thp` may be disabled.,0,0,0,0.9820095896720886,0.9938144683837892,0.995294153690338,0.0,accept,unanimous_agreement
674460671,8974,[code block] i still remember that it was you who reminded me.,0,0,0,0.963754653930664,0.9858500361442566,0.9853975772857666,0.0,accept,unanimous_agreement
674466027,8974,i remembered i said i prefer to keep them in one line if the length is short,0,0,0,0.9624578952789308,0.9827812314033508,0.9811522960662842,0.0,accept,unanimous_agreement
674466604,8974,"before this line, if server.disable_thp, we will try to disable thp (and we may fail to do that), so here we only check again i think",0,0,0,0.982671558856964,0.9797440767288208,0.989164650440216,0.0,accept,unanimous_agreement
674469032,8974,"t_t, i may have misremembered.",0,0,0,0.756361722946167,0.8845341801643372,0.7346497178077698,0.0,accept,unanimous_agreement
674472649,8974,"actually, in redis, this style is not clear, i just make typesetting tidy. if it is not long, i prefer one line, otherwise, i prefer to use {}, of course, sometimes, i follow old style around modified code block.",0,0,0,0.9764658212661744,0.9672226309776306,0.9855822920799256,0.0,accept,unanimous_agreement
674481370,8974,"i have tested, if `thpisenabled()` is true, even if `prctl(pr_set_thp_disable, 1, 0, 0, 0)` is successful, `thpisenabled()` is still true. maybe this line can be moved to `linuxmemorywarnings`.",0,0,0,0.98473060131073,0.9938596487045288,0.9917810559272766,0.0,accept,unanimous_agreement
674481570,8974,i've gotten used to single lines without `{`.,0,0,0,0.9751810431480408,0.8756410479545593,0.9739689826965332,0.0,accept,unanimous_agreement
674512962,8974,"some styles should have specification. i always curious about how to use. * `if` one line or two lines, with or without `{ }`; * spaces between operators or not; * spaces between function call params or not.",0,0,0,0.934845209121704,0.8034138679504395,0.9799627065658568,0.0,accept,unanimous_agreement
674514453,8974,"like said, i also follow old style around modified code block.",0,0,0,0.9869648218154908,0.9901857376098632,0.9909732937812804,0.0,accept,unanimous_agreement
674516166,8974,this is only way we can follow.,0,0,0,0.9505860209465028,0.9730949401855468,0.9864280819892884,0.0,accept,unanimous_agreement
674532036,8974,"thanks , i had second look, i find `prctl` only take effect on calling thread instead of entire os, so the result of `thpisenabled` still is not changed. and i find let me fix, thanks",1,1,1,0.9765852093696594,0.9841282963752748,0.9900118708610536,1.0,accept,unanimous_agreement
674619326,8974,"my preference is for less lines, especially around trivial things or error handling, don't like to hide the important things by wasting a lot of lines on nonsense. as you said, there are many styles in redis, so imho this specific topic isn't strict.",0,-1,0,0.5247048735618591,0.835926353931427,0.8995852470397949,0.0,accept,majority_agreement
674621874,8974,"why did you remove that? iirc at some point i said that i'm ok to ignore aofrw, if we wanna integrate the advises into the rdb serialization code of each type (so we don't need the dismiss function and the iterations and switch-cases it has). but since we decided to keep it (second iteration after serialization), why not have it in aofrw too? is that because of the dump_size guess work? i suppose we use that for aof too",0,0,0,0.9757171273231506,0.9844722151756288,0.9830637574195862,0.0,accept,unanimous_agreement
674622126,8974,i think we wanna report average too,0,0,0,0.9703673124313354,0.937137484550476,0.9855495095252992,0.0,accept,unanimous_agreement
674626229,8974,"what about streams? since they're listpack encoded, dismissing them could be similar to quicklist. i.e. iterate on the rax, and release whole listpacks. and do that only if the average element size of the rax is big.",0,0,0,0.987425684928894,0.98802649974823,0.991504728794098,0.0,accept,unanimous_agreement
674648645,8974,"i misunderstood, let me add. dump_size just is approximate, even the size in aof may be more accurate",0,-1,0,0.538061797618866,0.7623034715652466,0.950492024421692,0.0,accept,majority_agreement
674648780,8974,"ok, let me do that",0,0,0,0.9802556037902832,0.9691758751869202,0.9670725464820862,0.0,accept,unanimous_agreement
674715460,8974,"i only used rax tree, but not familiar with it, at first glance, i find rax iterator is not safe, we may still use listpacks data when iterating rax. i may have a look at `raxrecursivefree`, any advise?",0,0,0,0.973884642124176,0.9323052167892456,0.9496363401412964,0.0,accept,unanimous_agreement
674786054,8974,you just need to use raxiterator.. have a look at `defragradixtree`,0,0,0,0.9874808192253112,0.991853415966034,0.9956066012382508,0.0,accept,unanimous_agreement
674787913,8974,actually that function has some complications that can mislead you. basically something like that: [code block] and the judgement about iterating or not should use `raxsize`,0,0,0,0.8956775665283203,0.7801113128662109,0.9634214639663696,0.0,accept,unanimous_agreement
674833969,8974,"i am afraid we can't, we may access `ri.data` when calling `raxnext`",-1,-1,-1,0.9653992652893066,0.9474680423736572,0.9188252687454224,-1.0,accept,unanimous_agreement
674881138,8974,"are you saying that from code review, or did you test it and it crashed? are you sure you're not confusing it with `it->node->data`? each node has an encoded payload with pointers to the children and the fragments of the keys, as well as the pointer to the actual data of the leaf, but that's different than `it->data`, which is the pointer to the listpack. there's absolutely no reason for the rax iterator to access the listpack itself.",0,0,0,0.9745008945465088,0.9826556444168092,0.9848222732543944,0.0,accept,unanimous_agreement
675277136,8974,"sorry, i misunderstood, `it->data` is the pointer to the listpack instead of `it->node->data`, please forgive me :winking_face_with_tongue:",-1,-1,-1,0.9902375340461732,0.9922488927841188,0.97091406583786,-1.0,accept,unanimous_agreement
675397175,8974,"we actually know the size of the bulk (example code below). but maybe we don't wanna bother since it's usually big. howeer, we can skip the loop if `c->reply_bytes` is small (in some cases there may be many nodes but all of them are small). also, let's dismiss `c->querybuf` and `c->argv[]` if `argv_len_sum` is big. [code block]",0,0,0,0.977310299873352,0.9900778532028198,0.9913041591644288,0.0,accept,unanimous_agreement
675397521,8974,we also know the size of the backlog.. but it is almost certainly huge..,0,0,0,0.8982168436050415,0.8837335109710693,0.9779882431030272,0.0,accept,unanimous_agreement
675403790,8974,maybe that's better? [code block],0,0,0,0.9822466969490052,0.9913074374198914,0.9863670468330384,0.0,accept,unanimous_agreement
675410135,8974,"cool, thanks",1,1,1,0.9845861196517944,0.9636846780776978,0.9889790415763856,1.0,accept,unanimous_agreement
675416617,8974,"yes, it is almost certainly huge, so i didn't, but to make unified, let me add",0,0,0,0.8844970464706421,0.8724726438522339,0.9858736991882324,0.0,accept,unanimous_agreement
675513667,8974,"you mean there may be some small nodes after `trimreplyunusedtailspace`, so it is necessary to specify size in `dismissmemory`.",0,0,0,0.986979365348816,0.9935865998268129,0.9920684099197388,0.0,accept,unanimous_agreement
675516474,8974,"hi for the log, i think maybe users collect cow info by this log, i break old format, wdyt? and currently i am not satisfied with current description, do you have advise?",-1,0,0,0.6780387163162231,0.635933518409729,0.5402776002883911,0.0,accept,majority_agreement
675791512,8974,"there may be small nodes due to deferred replies, or even null nodes. i don't mind passing 0, or the size (as shown in my diff), the nodes are usually big, so we only rarely have an excessive call to malloc_size. but more important is the bottom of my comment above, about the possibility to skip the loop, and feeling other client buffers.",0,0,0,0.9604431986808776,0.908039391040802,0.9708005785942078,0.0,accept,unanimous_agreement
676107378,8974,you must dismiss the argv itself after freeing the items in the array 8-),0,1,0,0.6249634623527527,0.5737211108207703,0.9910539984703064,0.0,accept,majority_agreement
676108416,8974,"i don't think we need to retain backward compatibility with log messages. maybe ins some special cases like redis fails to start up due to bind address being used and such, in case someone (like our tests) attempts to resolve that and retry. but breaking this log message won't result in any actual problem, just missing metrics, and the right way to extract these metrics is from info (always has been)",0,0,0,0.969149112701416,0.9182305335998536,0.9731078147888184,0.0,accept,unanimous_agreement
676149590,8974,"oh, ashamed. thanks",-1,-1,-1,0.9877395033836364,0.9927737712860109,0.9934229254722596,-1.0,accept,unanimous_agreement
676297196,8974,:scream:,-1,0,-1,0.9807952046394348,0.928717851638794,0.5615465044975281,-1.0,accept,majority_agreement
676297495,8974,i think the common style in redis is with spaces. not very consistent though..,0,0,0,0.5106503367424011,0.5171135067939758,0.9723570346832277,0.0,accept,unanimous_agreement
676302098,8974,"we need `external:skip` due to aofrw and debug digest. i'd also suggest to move this to a file of it's own in the `integration` folder. i regret not creating a specific file for defrag back then when i introduced it. [code block] also, please use gcov to improve this test till you see all the optimization `if`s we added are tested (e.g. add client output buffers, argv, etc) big output buffers can be achieved by using a differing client that asks for something big, and doesn't read the response. big argv array can be achieved by writing resp directly to the socket and not providing the last argument. e.g. [code block]",0,0,-1,0.8538656830787659,0.9854944944381714,0.8776332139968872,0.0,accept,majority_agreement
676310777,8974,"fyi (not sure if you know), you can do `make gconv` and then follow similar steps to the `lcov` target.",0,0,0,0.9887152314186096,0.9911220073699952,0.9899725914001464,0.0,accept,unanimous_agreement
676640104,8974,:grinning_face:,0,0,1,0.4436031877994537,0.9864159822463988,0.9670160412788392,0.0,accept,majority_agreement
677170513,8974,"i know, make sure to cover all new coed",0,0,0,0.8503167033195496,0.947138011455536,0.99052095413208,0.0,accept,unanimous_agreement
677170614,8974,"actually, i am a bit tangled, in this case, `&&` is the top operator, i prefer to not use spaces in sub judgement",-1,-1,0,0.9393250942230223,0.908775806427002,0.6438191533088684,-1.0,accept,majority_agreement
680679690,8974,maybe also skip this entirely if `thp_enabled` is true?,0,0,0,0.9875277876853944,0.9933690428733826,0.9936165809631348,0.0,accept,unanimous_agreement
680680488,8974,"is there a particular reason for moving these private headers first? over time it tends to be trouble, so if it must be done i think we should have a single designated `config.h` for that.",0,0,0,0.9729267954826356,0.9793943762779236,0.9907203912734984,0.0,accept,unanimous_agreement
680709980,8974,"yeah, good idea, let's skip it in both entry points to this mechanism (`dismissmemoryinchild` and `dismissobject`). if we do that, maybe we can choose to remove the check from `dismissmemory`",1,0,0,0.6491666436195374,0.7399240732192993,0.7881909012794495,0.0,accept,majority_agreement
680711991,8974,"we copied that block from `server.h` since we needed this part of `fmacros.h` [code block] without it `madvise` didn't wanna play ball... in server.h this pile of compatibility headers are included first, so we thought we can copy that entire block here too. what do you suggest? moving `fmacros.h` and `solarisfixes.h` to be part of `config.h`?",0,0,0,0.9629075527191162,0.989663541316986,0.9916303753852844,0.0,accept,unanimous_agreement
680932504,8974,"ok, let me do that",0,0,0,0.9802556037902832,0.9691758751869202,0.9670725464820862,0.0,accept,unanimous_agreement
681329679,8974,structure*,0,0,0,0.9752212166786194,0.9797351360321044,0.9914142489433287,0.0,accept,unanimous_agreement
681387360,8974,"fixed, thanks",1,1,1,0.882018506526947,0.8305290937423706,0.9271016120910645,1.0,accept,unanimous_agreement
754822885,9780,you have a tab here.,0,0,0,0.9857571721076964,0.9707555174827576,0.9952651262283324,0.0,accept,unanimous_agreement
754823193,9780,"we have a known issue where a script can execute a delete first, and then continue to use memory and grow. it seems like we should fix that initially here.",0,0,0,0.986017405986786,0.960690140724182,0.9914920926094056,0.0,accept,unanimous_agreement
754824714,9780,"it looks like we do this today, but just because a command is a write, doesn't mean it dirties the dataset. i suppose this means we might send a multi-exec filled with commands that don't execute. not a correctness problem i presume, just weird.",-1,-1,-1,0.978029727935791,0.9516366124153136,0.9763017296791076,-1.0,accept,unanimous_agreement
754825055,9780,"can we call r_ctx, ""run_ctx"", while reading this i keep thinking it must be a ""redis context"".",0,0,0,0.9784107208251952,0.9853199124336244,0.9898070693016052,0.0,accept,unanimous_agreement
754825312,9780,you need to make up your mind about where the pointer *s go :),1,1,0,0.9588547348976136,0.835061252117157,0.9915823340415956,1.0,accept,majority_agreement
754827001,9780,should this be moved into script.(c|h)? perhaps a better time for a little more modularity. we can pull the stuff out of server.h as well.,0,0,0,0.9772328734397888,0.993281364440918,0.9910518527030944,0.0,accept,unanimous_agreement
754829222,9780,i generally dislike ambiguous acronyms (like desc) can we just put description ?,-1,-1,0,0.9422709941864014,0.9637096524238586,0.5429120659828186,-1.0,accept,majority_agreement
754832556,9780,"we could also tell the user what script is being run because these have names, that seems useful?",0,0,0,0.9808777570724488,0.991582691669464,0.9922824501991272,0.0,accept,unanimous_agreement
754833230,9780,"based on terminology, it's non-obvious why script kill wouldn't also apply to functions. you said a script is either an eval or function.",0,0,0,0.979369342327118,0.9127835035324096,0.9814631938934326,0.0,accept,unanimous_agreement
754834095,9780,kill?,0,0,-1,0.631093442440033,0.8905609846115112,0.8367312550544739,0.0,accept,majority_agreement
754834540,9780,why aren't we also printing back the raw function code? do we think it's too much memory to store?,0,0,0,0.8985264897346497,0.9363553524017334,0.9846597909927368,0.0,accept,unanimous_agreement
754835702,9780,"why is cluster needed here? i didn't see anything cluster specific in this file, and conceptually it doesn't make sense to me.",0,0,0,0.7221955060958862,0.7186583280563354,0.892916738986969,0.0,accept,unanimous_agreement
754842418,9780,more tabs.,0,0,0,0.9799323678016664,0.9315015077590942,0.9865777492523192,0.0,accept,unanimous_agreement
755822090,9780,yes we actually have an idea to handle this issue and will share on following pr's/issues. for this pr i wanted to keep the behaviour untouched.,0,0,0,0.9214804768562316,0.9659338593482972,0.98884916305542,0.0,accept,unanimous_agreement
755832097,9780,"at first i did everything like this one (pointer close to the type). but then i saw that the conversion in redis is that the pointer is next to the variable name and i changed. must a missed some. will fix and re-scan the code, thanks.",1,1,1,0.9436774253845216,0.6144000291824341,0.9587063789367676,1.0,accept,unanimous_agreement
755833645,9780,"good point, will move it.",1,1,1,0.911242425441742,0.8061710596084595,0.9732733368873596,1.0,accept,unanimous_agreement
755835247,9780,"actually, re-looking at this, it is looking at the server struct so maybe we should keep it here?",0,0,0,0.9829769134521484,0.9900400042533876,0.9904876351356506,0.0,accept,unanimous_agreement
755844376,9780,"also had this discussion with , the reason is that it might confuse the user because `script load` for example is not apply to function.",0,0,0,0.9804359674453736,0.9697868824005128,0.9881614446640016,0.0,accept,unanimous_agreement
755848177,9780,"we actually do store the raw function code to be able to save it to rdb. i thought that returning it on info might be to much and also not sure we want to commit to always be able to return the raw function code (it also might be meaningless on other engines in the future, like web-assembly for example). wdyt?",0,0,0,0.9813005924224854,0.91937518119812,0.970472514629364,0.0,accept,unanimous_agreement
755851812,9780,"mistake, thanks.",-1,-1,1,0.8495707511901855,0.5855199098587036,0.7128480672836304,-1.0,accept,majority_agreement
755852204,9780,replace all tabs with spaces,0,0,0,0.9820667505264282,0.9735630750656128,0.9915693402290344,0.0,accept,unanimous_agreement
755861987,9780,"currently the run_ctx is shared between eval and functions and it is not aware about the functions which is currently running (his purpose is to interact with redis from within a script). i can add optional metadata that can be added there and we can put the running function in this metadata. then we will be able to reply with the function name, wdyt?",0,0,0,0.9859750866889954,0.9757703542709352,0.9915629625320436,0.0,accept,unanimous_agreement
756183874,9780,"yes, i also gave that comment, and after some discussions retracted it. the old terminology was mixing [lua, eval, script], in some cases it suites us, in orders we had to rename or break. in this one, we can choose to support script kill, and then drop the function kill command. and then we can also use just one error message rather than two, or accept the current code which regards the script command as an eval manager. maybe another new idea to solve this is merge the entire function command into the script command. so instead of function create, we'll have script fcreate (similar to the fcall). then when the entire script command is about both functions and eval, the terminology problem is solved. i.e. obviously some of the sub-commands will be only applicable to some cases, but it might not be that bad. p.s. i'm not sure i like the idea i just suggested. maybe the current code is better.",0,0,0,0.9556657075881958,0.981015682220459,0.9750969409942628,0.0,accept,unanimous_agreement
756187946,9780,"maybe we want to add another sub-command for that, better leave it outside of info, to make it short. i.e we can add function get and function all and alike. i don't think it'll be a problem for wasm, we'll just spit back the code we got from the user. either way we'll need to persist them, so even if we only store it in the engine, we have to have a way to get it back.",0,0,0,0.9626281261444092,0.9760887026786804,0.9787116646766664,0.0,accept,unanimous_agreement
756190856,9780,"we only recently added something like that for eval, we print the name to the log. either way, i don't think it should be part of the error message. maybe a different introspection command that is allowed to run during a busy script?",0,0,0,0.9603773355484008,0.9755786061286926,0.9839141368865968,0.0,accept,unanimous_agreement
756239232,9780,"i think it will be irrelevant with wasm because the ""code"" we will get is a binary blob, nothing readable or meaningful.",0,0,0,0.8515896201133728,0.9505079388618468,0.8877383470535278,0.0,accept,unanimous_agreement
756688398,9780,"first, everything can be desassembled 8-) but also, people can get it in order to load it into another redis (or another system). i think it is ok if we spit out what we got as input.",1,1,0,0.5345251560211182,0.6607407927513123,0.9795388579368592,1.0,accept,majority_agreement
756707016,9780,its actually on the following pr list: so i will come with a proposal and implementation.,0,0,0,0.97802472114563,0.9294994473457336,0.995418906211853,0.0,accept,unanimous_agreement
757688276,9780,maybe it shouldn't be in server struct at all then?,0,0,0,0.9758813977241516,0.9918758869171144,0.9733282327651978,0.0,accept,unanimous_agreement
757688511,9780,"i'm fine either way, i just think the user should have a way to know what ""function"" is running.",0,0,0,0.874530017375946,0.8602334856987,0.8870823979377747,0.0,accept,unanimous_agreement
757688638,9780,"sounds good, we should just make sure it's fixed before 7, since it seems like we'll need some type of breaking change.",0,0,0,0.5847435593605042,0.8420129418373108,0.634303629398346,0.0,accept,unanimous_agreement
757689633,9780,i think having a separate subcommand with more info sounds like the right approach.,0,0,0,0.9712550044059752,0.9612147808074952,0.9575438499450684,0.0,accept,unanimous_agreement
757862791,9780,"i agree, added another pr and moved the entire timeout handling into `script.c`",0,0,0,0.9236311316490172,0.918670892715454,0.991397738456726,0.0,accept,unanimous_agreement
757862962,9780,"i am not sure what you mean here, do you refer to this issue: [a link]",-1,-1,0,0.8034574389457703,0.605901837348938,0.8375015258789062,-1.0,accept,majority_agreement
757863797,9780,"we discussed it on the issue ([a link] mentioned that its not enough to know the function that is running because it might be change by the time we will send the `function kill`. even if we will allow to kill only if the function name is equal to a given parameter, it still might have finished and restarted by the time we will send the command. regardless, we can add `function running` that will return the current running function (as mentioned on the pr message), i am just not sure it will help the user kill the ""right"" function. let me know what you think.",0,0,0,0.5789462327957153,0.9633954763412476,0.9428712725639344,0.0,accept,unanimous_agreement
757863965,9780,should we do it on this pr or open an issue with api definition and then handle it on following pr?,0,0,0,0.9867098927497864,0.9944626688957214,0.9938637018203736,0.0,accept,unanimous_agreement
758128751,9780,"imho if you have time to kill, and it doesn't add another major approval barrier to this pr, you can go ahead and add it.",0,0,0,0.9748203754425048,0.9733827710151672,0.9012500047683716,0.0,accept,unanimous_agreement
758132540,9780,"i agree, it should be some sort of introspection command, (not part of the error) maybe instead of function running, we can add some function status or stats that will print some general info on all engines (unlike function info which is on one function, right?). i.e. something similar to memory stats and info. there was can put all soft of general details, including the currently running function, it's args, and execution duration.",0,0,0,0.9719685912132264,0.983697474002838,0.9782084822654724,0.0,accept,unanimous_agreement
758165502,9780,should free `fi` after `engine->create` successfully?,0,0,0,0.9879350662231444,0.9944532513618468,0.9955551028251648,0.0,accept,unanimous_agreement
758167590,9780,"no, we should only free it if it already exists and we replacing it.",0,0,0,0.97319757938385,0.9900244474411012,0.9861065149307252,0.0,accept,unanimous_agreement
758173354,9780,"i mean that when we create a function that fails, we shouldn't delete the old one. [code block] expectation [code block]",0,0,0,0.9836559295654296,0.9937976002693176,0.989165723323822,0.0,accept,unanimous_agreement
758174134,9780,"ohh, nice catch, thank you.",1,1,1,0.9770948886871338,0.990622103214264,0.9886541366577148,1.0,accept,unanimous_agreement
758198887,9780,added a commit that fixes it.,0,0,0,0.9862698912620544,0.9889764189720154,0.9931917786598206,0.0,accept,unanimous_agreement
758199002,9780,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
758201787,9780,incorrect tab indent.,0,-1,-1,0.6833807826042175,0.7286726236343384,0.8281334042549133,-1.0,accept,majority_agreement
758202415,9780,another tab indent.,0,0,0,0.9214991927146912,0.9636132717132568,0.9826977849006652,0.0,accept,unanimous_agreement
758204823,9780,"yeah, just saw it, thanks.",1,1,1,0.8521999716758728,0.7750300765037537,0.8222365975379944,1.0,accept,unanimous_agreement
758205059,9780,:+1:,0,0,0,0.7570654153823853,0.9166757464408876,0.9328674077987672,0.0,accept,unanimous_agreement
758273766,9780,"although `functionscreatewithfunctionctx` has already deleted the key, i think it's safer to add an assertion. [code block]",0,0,0,0.9856254458427428,0.9922519326210022,0.99307382106781,0.0,accept,unanimous_agreement
758276040,9780,"i do not like putting code that should run inside an assert (in case we want to run without asserts someday), will save the return value and assert it.",-1,-1,-1,0.9659277200698853,0.8516096472740173,0.8053557276725769,-1.0,accept,unanimous_agreement
758287522,9780,"yes, it saves a line of code when writing in assert if we don't need the return value.",0,0,0,0.987250030040741,0.991000473499298,0.9907082319259644,0.0,accept,unanimous_agreement
758289322,9780,"i mean that i want to save the return value in a variable and then assert, this way if someone compiles without asserts it will still work: [code block]",0,0,0,0.982545018196106,0.9893596172332764,0.9921759963035583,0.0,accept,unanimous_agreement
758292684,9780,"it seems that it could go here, which would eliminate the need to call it when deleted. [code block]",0,0,0,0.987302541732788,0.9937300682067872,0.9928581714630128,0.0,accept,unanimous_agreement
758465090,9780,"added function stats command, update the top comment with the relevant info.",0,0,0,0.9850617051124572,0.9921711683273317,0.9952961802482604,0.0,accept,unanimous_agreement
758465909,9780,added the option to specify function name on function info command that also return the raw code. updated the top comment accordingly.,0,0,0,0.9866245985031128,0.9913979768753052,0.9910624027252196,0.0,accept,unanimous_agreement
758466656,9780,please let me know if you agree with the fix and if i can resolve this.,0,0,0,0.9617706537246704,0.9622626900672911,0.9873056411743164,0.0,accept,unanimous_agreement
758875807,9780,would it be better to keep the original style? [code block],0,0,0,0.9876603484153748,0.994089901447296,0.9927831888198853,0.0,accept,unanimous_agreement
758902986,9780,one extra blank line.,0,0,0,0.9738208651542664,0.9682443737983704,0.9728474617004396,0.0,accept,unanimous_agreement
759213147,9780,maybe you can settle this?,0,0,0,0.9767358303070068,0.9909186363220216,0.9891589283943176,0.0,accept,unanimous_agreement
759241151,9780,"does that mean that `function info`, and `function info ` return completely different result? if it does, i don't like that.",-1,-1,-1,0.9534525275230408,0.8808717727661133,0.9604985117912292,-1.0,accept,unanimous_agreement
759269348,9780,so you suggest a new sub-command? function code?,0,0,0,0.9883068203926086,0.9927685260772704,0.9948569536209106,0.0,accept,unanimous_agreement
759295897,9780,"i think we should have * `function stats` - general info on the engine and some counters (no per function details) * `function list` - listing all function and some metadata on each (excluding the function code) * `function info [withcode]` - detailed info on the function, optionally including it's code.",0,0,0,0.984644055366516,0.9888359904289246,0.9902239441871644,0.0,accept,unanimous_agreement
759335761,9780,"i also don't like the last idea. generally i don't think scripts and functions should be confused, but `-busy` does imply a more general state, so it's a bit weird to require the user to determine what keeps redis busy and then decide if `script kill` or `function kill` should be executed. maybe support both and let users use them interchangeably?",-1,-1,-1,0.9825778603553772,0.9782490730285645,0.9810957312583924,-1.0,accept,unanimous_agreement
759352894,9780,"so what you mean is that you don't like to introduce the function management commands as sub-commands of script? and you're ok with letting script remain dedicated for the eval scripts (despite the fancy terminology we creates which states that a ""script"" can refer to both functions and eval)? and you're suggesting to just tackle the kill problem as a special case, in which we don't wanna force the user to be able to recognize them apart (it's the same error code), and instead we'll just have two kill sub-commands, interchangeable (either one can kill both functions and eval)? did i get your thought correctly?",0,0,0,0.9503141045570374,0.7473928332328796,0.960756242275238,0.0,accept,unanimous_agreement
759574180,9780,"no, if we send a write command we mark the script as dirty. we don't need to though, we only need to care if the write command actually does something to the dataset. i'll open an separate issue for this, it's not related but something i noticed.",-1,0,0,0.8127845525741577,0.9710003733634948,0.9844087958335876,0.0,accept,majority_agreement
759796986,9780,it's ok.,0,0,1,0.9350651502609252,0.7333295345306396,0.651191234588623,0.0,accept,majority_agreement
759962383,9780,"updated the code accordingly, also updated top comment.",0,0,0,0.9835494756698608,0.9914355874061584,0.9950262904167176,0.0,accept,unanimous_agreement
759962722,9780,"i see, so i guess i can resolve this one?",0,0,0,0.9803192019462584,0.9764187932014464,0.9837194085121156,0.0,accept,unanimous_agreement
759964170,9780,should it be `function doesn't exist`?,0,0,0,0.9808834195137024,0.9908151626586914,0.9854063987731934,0.0,accept,unanimous_agreement
760608079,9780,after discussion with and the decision is to keep the api separate.,0,0,0,0.9839259386062622,0.9900287985801696,0.9925810098648072,0.0,accept,unanimous_agreement
760879436,9780,"some more details about our discussion. first, about considering moving the function command logic to script (since our new terminology dictates that both ""eval"" and ""functions"" are ""scripts), we concluded that in this case it'll cause too much confusion (e.g. script load will obviously remain as is), and it's ok to leave the administrative parts of eval in script, and the ones of fcall in function. secondly, regarding kill, and busy: we concluded that the busy response is more about telling the client that the server is busy and the command should be retried later, than about a way to kill the blocker. i even remember a discussion with salvatore about exec returning busy without resetting the multi state so that it can be retried later (we abandoned that since it's dangerous, and it always fails with execabort). moreover, we have a plan to soon let modules play that busy game too (see #9655), and they're obviously not gonna get killed by script kill. p.s script kill is in many time a dead end anyway (responds with unkillable)",0,0,0,0.9540244340896606,0.9881163835525512,0.9450893998146056,0.0,accept,unanimous_agreement
760882512,9780,"yes, this is not related to here, let's add it to #8478",0,0,0,0.9841541051864624,0.9892576336860656,0.9937997460365297,0.0,accept,unanimous_agreement
681924408,9309,"do you need to have such low level access to determine what the user does and does not have access to. i would expect it to be easier to maintain to just have an aclcheckclientpermission(client, command arguments), so that it emulates the normal permission check that we do.",0,0,0,0.9817521572113036,0.9917308688163756,0.986068606376648,0.0,accept,unanimous_agreement
682070913,9309,"a module may want to check permission to a key before doing rm_openkey (so the low level checkkey api is needed). in other cases before executing a sequence of rm_calls, the module will want to first make sure they're all allowed. i haven't yet looked at the code, but while responding to this message i see the signature of the checkcommand interface, and i think it's insufficient, we want to pass the full argv array, so keys will get checked too (in some cases the module may be a ""script engine"" and it's doesn't really understand what command it executes and which arguments refer to key names).",0,0,0,0.9689616560935974,0.9837064743041992,0.9892923831939696,0.0,accept,unanimous_agreement
682082573,9309,"maybe my questions are dumb and this is obvious to you module developers, but i don't follow why having three individual commands is useful. i don't understand this use case, in what context would this be used instead of having the module declare what keys are needed by the command? a lot of code in redis (cluster mode and server-side key tracking) assume this. it seems weird to have a separate backchannel for defining if the user has access. it also seems weird that this won't be published to the acl log. not sure i understand why you would want three separate api calls here instead of just one that answers the question, ""can this user execute this command"". it's fragile to future changes where we add more acl changes.",-1,-1,-1,0.9627823233604432,0.9873573780059814,0.9847820401191713,-1.0,accept,unanimous_agreement
682091593,9309,"as we know, by design, modules are exempt from acl validations on the actions they do. i.e. antirez said that since they can write to arbitrary memory and execute arbitrary syscalls, when a user allowed a certain module command to run, it can do whatever it wants with no limitations from redis, and this includes doing any rm_call they like. so the first obvious thing is to add the flag to rm_call that enables full checks inside it. but as i stated, in some cases the module wants to verify that a sequence of commands can succeed before issuing the first one, so that's why we need the first new api. as for the other ones, some modules access keys that are not explicitly referred to in the argument list. i can provide few trivial cases: 1. a module that implements a domain specific query language that has some operators before each argument or isn't at all separated by spaces or distinct arguments 2. a module that for some reason adds prefixes to keys names it got from arguments, or some other funny shit (think of sort by). 3. a module that implements a scripting language, for instance one that exposes similar interface to what eval has today, so the user passes a script, and maybe also a list of key names to be verified before the module command is executed, but there's no guarantee that the script doesn't access other keys. needless to say, some of the examples above are not compatible with cluster mode. so i'm aiming to do two things: 1. provide something that's easy to use and hard to mis-use. 2. provide low level tools for advanced modules. please chime in. please update rm_aclcheckcommandperm to take a full argv list and validate all that's validated by processcommand",0,0,0,0.9810522794723512,0.9837294220924376,0.9801470637321472,0.0,accept,unanimous_agreement
682113721,9309,1. i suppose we should add a low level cluster mode command to check for cross slots then as well. 2. i think what you were expecting with rm_aclcheckcommandperm was the alternative i was asking about originally. having a module check that does the exact permission check that redis normally does seems easier to use and maintain. i'm fine to also have other apis for power users to do shenanigans with.,0,0,0,0.8612756729125977,0.894381582736969,0.8882747292518616,0.0,accept,unanimous_agreement
683185655,9309,"i'm not certain what are the side effects of this. maybe instead we should keep `c->user` set to null, and use a more explicit code below to call `aclcheckallusercommandperm` instead of `aclcheckallperm` can you think of any undesired or desired side effects?",0,0,0,0.9226661920547484,0.9364805817604064,0.9061425924301147,0.0,accept,unanimous_agreement
683187127,9309,"we need to document `eacces` at the top, or even provide detailed specific errors for the various acl errors (i think i rather not) alternatively, maybe we wanna return an error reply? (i don't think so). ?",0,0,0,0.9770298004150392,0.990954339504242,0.9751296043395996,0.0,accept,unanimous_agreement
683188044,9309,we need to document the various errno in the top comment. and maybe we need detailed errors for the various acl errors.,0,0,0,0.973260462284088,0.9880508184432985,0.9920089244842528,0.0,accept,unanimous_agreement
683188390,9309,i think the input here should be a redismodulestring,0,0,0,0.9849231243133544,0.9799348711967468,0.9860379099845886,0.0,accept,unanimous_agreement
683188926,9309,"i think the input should be a redismodulestring, and we also need to document the `literal` flag.",0,0,0,0.987873077392578,0.9877120852470398,0.9904664754867554,0.0,accept,unanimous_agreement
683190214,9309,"i'm not sure i like the ""perm"" shorthand, since the prefix already has ""acl"", and ""check"", maybe we can drop it? what do you think of these changes? [code block]",-1,0,0,0.8026295900344849,0.8249916434288025,0.799595057964325,0.0,accept,majority_agreement
683192342,9309,let's add here also a case of a successful call to rm_call.aclcheck.,0,0,0,0.9889286160469056,0.9901004433631896,0.9953741431236268,0.0,accept,unanimous_agreement
683192588,9309,lets add here also a case of a successful call to rm_call.aclcheck.cmd,0,0,0,0.9851439595222472,0.9886136054992676,0.9951332211494446,0.0,accept,unanimous_agreement
683267960,9309,did you consider `const user *`? (applies below as well),0,0,0,0.9886150360107422,0.9934881925582886,0.9959052801132202,0.0,accept,unanimous_agreement
683270832,9309,"i agree, even if there are no desired side effects now i can see how they pop up in the future.",0,0,0,0.9516132473945618,0.9583600759506226,0.9639992713928224,0.0,accept,unanimous_agreement
683272047,9309,"another point is what we do if the context has no associated user. if we want to be more secure by default, i'd say we may need to fail the operation.",0,0,0,0.968765377998352,0.947540044784546,0.9881076216697692,0.0,accept,unanimous_agreement
683274624,9309,"redis module api tends to use longer names and avoid shorthand, consider `rm_aclcheckcommandpermissions`. also, i am not sure about the coupling with `redismodulectx` here. doesn't it make more sense to take a `redismoduleuser` here, and have a separate function that can extract `redismoduleuser` from the context?",0,0,0,0.9152808785438538,0.9895719289779664,0.9853081107139589,0.0,accept,unanimous_agreement
684727255,9309,"what if it is used from a threadsafectx that does not attach to any block client? will it crash here? also, what will happen if it's a threadsafectx that was attached to this user but until it was created by the background thread the user was already dropped?",0,0,0,0.9747250080108644,0.9580734968185424,0.987687885761261,0.0,accept,unanimous_agreement
684727385,9309,i guess this question is relevant also to the rest of this api,0,0,0,0.9855778813362122,0.879382848739624,0.985726237297058,0.0,accept,unanimous_agreement
684728637,9309,"maybe we need to add a variant of the api that takes a user name as input rather than rely on the connection, and obviously and api to get the current user. if the user is already disconnected or modified by the time the module tries to use it, i guess the module should fail (get denied)",0,0,0,0.956350564956665,0.9632662534713744,0.9838693737983704,0.0,accept,unanimous_agreement
684729169,9309,i was thinking maybe it might be a good idea to introduce a credentials object. all those new functions can get a credentials object (instead of redismodulectx*) and we can also add an api to get credentials object from redismodulectx. the credentials object can leave even after the user has changed/deleted and can be used safely on another thread.,0,0,0,0.9748193621635436,0.9812020063400269,0.9688777923583984,0.0,accept,unanimous_agreement
684731274,9309,"i'm not sure this is the desired path (at least at this point in time). seems simpler and more in-line with other things to let the module pass the user name around, and if it was modified or deleted, the validation should just get denied. wdyt?",0,0,0,0.9119309782981871,0.7952016592025757,0.8389977216720581,0.0,accept,unanimous_agreement
684732951,9309,"i agree with you, passing the user name is better, this way if the user permission change it will still work correctly.",0,0,0,0.9445918202400208,0.8810182213783264,0.9454962015151978,0.0,accept,unanimous_agreement
684739898,9309,"iiuc this is what already mentioned, no? ""also, i am not sure about the coupling with redismodulectx here. doesn't it make more sense to take a redismoduleuser here, and have a separate function that can extract redismoduleuser from the context?""",0,0,0,0.9817573428153992,0.9277305006980896,0.981847643852234,0.0,accept,unanimous_agreement
684740985,9309,yep missed that ... but i do believe the username suggested by is a good idea...,1,0,1,0.9524472951889038,0.4161593019962311,0.9646786451339722,1.0,accept,majority_agreement
684753100,9309,why pass usernames around when we can use `redismoduleuser`?,0,0,0,0.977144420146942,0.9930879473686218,0.9591151475906372,0.0,accept,unanimous_agreement
684754190,9309,"from my perspective the user name is an opaque struct that represents the user, so i think it's fine if it's `redismoduleuser` as long as we handle permission changes/deletion and we make sure `redismoduleuser` can continue living even after the actual user got deleted.",0,0,0,0.9810304641723632,0.9815152287483216,0.9842775464057922,0.0,accept,unanimous_agreement
684754690,9309,"and of course, if the user was deleted and the module continues using its `redismoduleuser` then we get permission deny on everything as mentioned.",0,0,0,0.9889505505561828,0.9770525693893432,0.9940345883369446,0.0,accept,unanimous_agreement
684758596,9309,"what's worse, if the module keeps a `redismoduleuser` for later use, and the user is deleted, then the `->user` member here points to released memory!",-1,0,-1,0.7214663624763489,0.5536345839500427,0.7913680076599121,-1.0,accept,majority_agreement
684759782,9309,"this makes sense, i'd still feel more comfortable having some opaque `redismoduleuserid` and not commit to the fact that it's a string / the username.",0,0,0,0.9763752222061156,0.8661806583404541,0.9841673970222472,0.0,accept,unanimous_agreement
685957018,9309,"i don't think we wanna mess with errno in most apis, just when we have multiple failure reasons. [code block]",0,0,0,0.8799927234649658,0.9336925148963928,0.9149518609046936,0.0,accept,unanimous_agreement
685958824,9309,"we need to decide if we wanna reflect the various acl errors, or just one error for all. wdyt?",0,0,0,0.9800608158111572,0.8712573051452637,0.982824683189392,0.0,accept,unanimous_agreement
685960945,9309,outdated comment?,0,0,0,0.5176096558570862,0.9534004330635072,0.9614076018333436,0.0,accept,unanimous_agreement
685962888,9309,when did we delete the user? did you intend to run some rm_call to delete it here?,0,0,0,0.9814806580543518,0.9938920736312866,0.9943590760231018,0.0,accept,unanimous_agreement
686101599,9309,redismodule_freemoduleuser,0,0,0,0.9866029024124146,0.9686218500137328,0.9883323311805724,0.0,accept,unanimous_agreement
686130149,9309,"ohh, very confusing api name, looks as if it frees a resource of the current module, but in fat it deletes the user in redis. i.e. equivalent to acl deluser.",-1,-1,-1,0.7191827297210693,0.9818989038467408,0.9389488101005554,-1.0,accept,unanimous_agreement
686215863,9309,"i agree that `rm_getcurrentuserid` is a better name, but using the ""create"" word implies that it is not just a reference for exiting object, but we created it, and the user should be responsible for freeing it, wdyt?",0,0,0,0.9771990776062012,0.9894918203353882,0.9868353605270386,0.0,accept,unanimous_agreement
687521566,9309,"c being a rather low level language, i think it's reasonable to assume you need to release something you've received as a result of a `get`. some examples: * `getaddrinfo()` -> `freeaddrinfo()` * `getipnodebyname()` -> `freehostent()` also, the redis module api already has similar use cases - just to name a few: * `rm_getclientusernamebyid` * `rm_serverinfogetfield`",0,0,0,0.9656304121017456,0.9864482283592224,0.9766244292259216,0.0,accept,unanimous_agreement
687524757,9309,i think we can use `eacces` for every acl related failure.,0,0,0,0.98792564868927,0.9850570559501648,0.974736511707306,0.0,accept,unanimous_agreement
693859539,9309,"let's rearrange this comment even further, have one line or a block per argument each specifying what it does, when it is used. personally, i think this api is a mess, and don't like the fact that it decides what to take from c->argv on it's own rather than be fed the right object, but looking at how it's used, it seems it's hard to change that. so i suppose what should be documented is that `object` (better put as last argument) is a manual override to be used instead of any of the automatic ones which depend on the `reason` arg) same as `user` is now (after your change) a manual override for the automatic one (seems better than the previous logic)",-1,-1,-1,0.9763258099555968,0.9687087535858154,0.9185035228729248,-1.0,accept,unanimous_agreement
694095982,9309,are the two tests added for acl log testing both of these? (cmd name and key name)?,0,0,0,0.9886930584907532,0.9941146969795228,0.9953674077987672,0.0,accept,unanimous_agreement
694102328,9309,"we need to document what's `object`. i see the acl log doesn't really define that [a link] so maybe it's just sufficient to give a reference to there? i see that there's also a `context` field that can be set to `toplevel`, `multi`, or `lua`, i suppose that in this case we either use a hard coded `module`, use the module name, or expose that as an argument in this function? whatever we decide, this also applies for the logging we added in rm_call. i vote for a hard coded `module` ?",0,0,0,0.9530227184295654,0.9900628924369812,0.9898680448532104,0.0,accept,unanimous_agreement
694103584,9309,i see this api isn't covered by the test.,0,0,0,0.9857892394065856,0.85834139585495,0.9899771213531494,0.0,accept,unanimous_agreement
694226529,9309,"currently, we are taking the context based on the flags of the ctx->client, so if a client is running some module command inside multi or lua script (if it's valid) you will see these contexts. if it doesn't gain anything i agree that we can use the 'module name' or just ""module"" context. the api is covered in ""test module check acl for command perm"" (rm_call_aclcheck_cmd)",0,0,0,0.9854793548583984,0.9941129088401794,0.9899429082870485,0.0,accept,unanimous_agreement
694226823,9309,"only one of them, i will add the other one as well",0,0,0,0.9780144691467284,0.9837469458580016,0.9929319620132446,0.0,accept,unanimous_agreement
694284743,9309,"i think seeing a module context is more valuable than seeing multi or lua, but maybe we wanna change the context thing to flags rather than enum and show both.",0,0,0,0.9440158605575562,0.9756195545196532,0.9748297333717346,0.0,accept,unanimous_agreement
703100440,9309,"the context is an enum value, can we just use a defined value instead of passing in -1, which is so cryptic? also, i'm not clear why we don't just pass the context in, since i assume we know it better from the calling site. this seems like an unnecessary level of abstraction.",-1,0,-1,0.7487338185310364,0.5006365180015564,0.5438894629478455,-1.0,accept,majority_agreement
703101183,9309,there is a random space here btw. [code block],0,0,0,0.9880908727645874,0.99179345369339,0.98807692527771,0.0,accept,unanimous_agreement
703101434,9309,"i'm going to assume there is some long conversation about this somewhere, but why are we introducing a new resource called a userid. in the other module api we just pass in the real username?",0,0,0,0.9777617454528807,0.9210147857666016,0.981330931186676,0.0,accept,unanimous_agreement
703101732,9309,"module created users will fail here, since they are created outside of the regular acl system. i believe you can still pull it out of the user successfully though, since the code in `rm_getcurrentuserid` just grabs the name of the currently attached user. it doesn't look like there is any test validating this behavior.",0,0,0,0.8147168159484863,0.9898631572723388,0.983500838279724,0.0,accept,unanimous_agreement
703101829,9309,would be nice to document why this can error.,0,0,0,0.8993537425994873,0.8598389625549316,0.9852853417396544,0.0,accept,unanimous_agreement
703155897,9309,is forget to add this test to `runtest-moduleapi`?,0,0,0,0.9762489795684814,0.99480801820755,0.9949097037315368,0.0,accept,unanimous_agreement
703165881,9309,[code block] released too early.,0,0,0,0.9589729309082032,0.9840351939201356,0.7494885325431824,0.0,accept,unanimous_agreement
703433198,9309,"we actually don't know the context in the caller (can't be hard coded there), and salvatore designed all of these to be automatically populated by the server struct state. maybe we can somehow do that for modules too?",0,0,0,0.9805742502212524,0.9909679293632508,0.9893789887428284,0.0,accept,unanimous_agreement
703435877,9309,there was some discussion here: [a link] i don't remember why it was decided to make an opaque type rather than use a string. ?,0,0,0,0.93014258146286,0.9499029517173768,0.9901152849197388,0.0,accept,unanimous_agreement
706791948,9309,"we actually can, we call it from processcommand (top_context), execcommand (multi_context) and luaredisgenericcommand (lua_context)",0,0,0,0.9877012372016908,0.9926475286483764,0.9951907396316528,0.0,accept,unanimous_agreement
706819599,9309,i think it makes sense to take it out of `addacllogentry`. btw i find the context pretty confusing - what should i expect if i have an `eval` calling a module command all wrapped in `multi/exec`?,-1,0,0,0.5863577723503113,0.7546521425247192,0.908521294593811,0.0,accept,majority_agreement
706820320,9309,"first version was passing clients around, we wanted to decouple that but did not want to hold references to redismoduleuser. passing a string was an option but an opaque type seemed like a cleaner api that is less prone to abuse and more future proof.",0,0,0,0.9741141200065612,0.9848832488059998,0.9893080592155457,0.0,accept,unanimous_agreement
707826933,9309,"so, my understanding is that this should apply to both redismoduleuser (which are not owned by the acl system) and users owned by the acl system. i think the new resource makes sense if we encapsulate both of those two types of redis acls. is there also an intention that modules can hold onto this new redismoduleuserid resource and then pass it to a background thread for async processing? i assume that is why it's not actually holding on to the user, but that doesn't seem correct implementation wise. so i guess i'm not really clear why we don't just use the context.",0,0,0,0.9252200126647948,0.9513225555419922,0.9732375741004944,0.0,accept,unanimous_agreement
711743383,9309,thanks added,1,1,0,0.5284340977668762,0.7709925770759583,0.7172717452049255,1.0,accept,majority_agreement
711744146,9309,let's be sure to use uppercase acl,0,0,0,0.985292375087738,0.9839136600494384,0.9943596720695496,0.0,accept,unanimous_agreement
711747230,9309,the convention is that the module name comes first. i think these should be `aclcheck.xxxxx`,0,0,0,0.985246241092682,0.9917731881141664,0.9931894540786744,0.0,accept,unanimous_agreement
711807610,9309,redismoduleuserid dropped,0,0,0,0.9847442507743835,0.9894000887870787,0.9475150108337402,0.0,accept,unanimous_agreement
768423473,9940,what else should we clear here? i assumed these clients are used for accumulating replies so clearing replies only. is there any other use case for these temp clients?,0,0,0,0.986864984035492,0.9871721863746644,0.9949681162834167,0.0,accept,unanimous_agreement
768633722,9940,maybe we need to extract some code from `resetcommand` and re-use it here? maybe `modulefreecontextreusedclient` should also use it?,0,0,0,0.988331139087677,0.9957699179649352,0.9914827346801758,0.0,accept,unanimous_agreement
768634038,9940,styling. [code block],0,0,0,0.9876807928085328,0.9917085766792296,0.9946789741516112,0.0,accept,unanimous_agreement
768635845,9940,"i'm curious, was it necessary to change this code? maybe i'm missing something.",-1,0,0,0.6199793219566345,0.88898104429245,0.8812412619590759,0.0,accept,majority_agreement
768656859,9940,maybe i am missing something but wouldn't this will prevent you from reading from the pipe which will eventually cause the pipe to be full?,0,0,0,0.8038291335105896,0.9640763998031616,0.9588937759399414,0.0,accept,unanimous_agreement
768663229,9940,"not necessary, just an optimization. we can skip unnecessary `read()` call if `moduleunblockedclients` does not contain a client. we write byte to pipe when we are adding client to `moduleunblockedclients`. if list is empty, pipe is empty. i can revert it if this is confusing, not that critical. added this check just to skip one more syscall in the critical path.",0,0,0,0.969271957874298,0.988797962665558,0.9848085641860962,0.0,accept,unanimous_agreement
768668895,9940,"if there is data in pipe, `listlength(moduleunblockedclients)` should be greater than zero. i added if check here to just skip unnecessary `read()` call. if list is empty, pipe should be empty.",0,0,0,0.9886123538017272,0.9942848086357116,0.9943298101425172,0.0,accept,unanimous_agreement
768669513,9940,"ohh sorry, you are reading if there is something in the list, so i believe you are good... :+1:",-1,-1,-1,0.9751588702201844,0.9392266273498536,0.5149499773979187,-1.0,accept,unanimous_agreement
768674622,9940,"i'm more concerned with `write()` calls actually, i can revert the change here for `read()` if this is confusing. just added this check to skip one syscall in the critical path.",0,0,0,0.8540207147598267,0.951834201812744,0.9659159183502196,0.0,accept,unanimous_agreement
772089713,9940,"is it possible to define 1024 as a constant, so that there is no need to calculate its size in `modulereleasetempclient`?",0,0,0,0.987523913383484,0.9953044652938844,0.9943095445632936,0.0,accept,unanimous_agreement
772115572,9940,"sure, i'll do. actually, compilers calculate it on compile time as it's all about compile time constants. i relied on this but maybe it's better to be explicit.",0,0,0,0.9777812361717224,0.9800761342048644,0.9705004692077636,0.0,accept,unanimous_agreement
772570598,9940,"looking at `freeclient`, it may involve quite a few different flows and may even give control back to modules. i think it should only be called with the mutex unlocked.",0,0,0,0.9856970310211182,0.988636076450348,0.988450288772583,0.0,accept,unanimous_agreement
772899442,9940,"looks like clearclient() may also call back to modules. createclient() doesn't but it may in future. changed code a bit, holding the lock just to add/remove to/from array.",0,0,0,0.987491488456726,0.9897026419639589,0.9900988936424256,0.0,accept,unanimous_agreement
772904231,9940,it seems that `clearclient` only needs when !full.,0,0,0,0.9693204760551452,0.9868488311767578,0.9934409260749816,0.0,accept,unanimous_agreement
772964133,9940,"yes but we don't want to call clearclient/freeclient while holding the lock.(please see yossi's [a link]. so, to detect if it's `full`, we have to acquire the lock. then, we need to release the lock before calling `clearclient()`. after calling `clearclient()`, we need to acquire the lock again and place the client object into the cache if it has not become full while we are running `clearclient()`. so, it's a bit ugly but here we are being optimistic and calling `clearclient()` beforehand hoping the cache is not full. in this case, we lock once. if cache is full (unlikely), yes, we are calling clearclient() unnecessarily.",-1,0,0,0.9274006485939026,0.5463181138038635,0.6151114106178284,0.0,accept,majority_agreement
772965436,9940,we can move it to the end of the method(`else`).,0,0,0,0.9885780811309814,0.988714039325714,0.9949813485145568,0.0,accept,unanimous_agreement
772969168,9940,"ohh, i missed something, you are right.",1,0,0,0.8207024335861206,0.6947082877159119,0.8943641185760498,0.0,accept,majority_agreement
772970969,9940,"could you please suggest as change? if you are suggesting this : [code block] at this point, we've already placed client into the cache and unlocked the mutex. some other thread can acquire the lock and pull the client before we call `clearclient()`.",0,0,0,0.9897013902664183,0.9926373958587646,0.9953623414039612,0.0,accept,unanimous_agreement
772976358,9940,"yeah, i see it, thx.",0,0,0,0.7361828088760376,0.9038380980491638,0.9802257418632508,0.0,accept,unanimous_agreement
774370904,9940,why not continue using `server.module_client` here instead of using the cache (which require mutex locking)?,0,0,0,0.9829058647155762,0.9946635961532592,0.9931384921073914,0.0,accept,unanimous_agreement
774386096,9940,"it's just to handle temporary clients from a single place and clear code a bit. `modulefreecontextreusedclient` change is same as well. yes, there might be performance hit with these changes. even without using cache here, clearclient() is doing more compared the previous partial clear operation. i'm not sure how sensitive modules are to these changes. just to avoid the risk, i can revert these two back to using the same client instance at least. what do you think?",0,0,0,0.9078554511070251,0.9189679622650146,0.9618728160858154,0.0,accept,unanimous_agreement
775248512,9940,"maybe add a comment here, explaining why for blocked clients we use `bc->thread_safe_ctx_client` (refer to the code below), and for other thread safe clients, we think we can afford to take the slow path.",0,0,0,0.9850906133651732,0.992385983467102,0.9917131662368774,0.0,accept,unanimous_agreement
775248554,9940,maybe refer to the comment we're adding in rm_getthreadsafecontext,0,0,0,0.9871246814727784,0.9949605464935304,0.9927928447723388,0.0,accept,unanimous_agreement
775248772,9940,"maybe 1024 is too high? (clients consume a lot of memory, and in this case after reaching the peak they'll never be released). maybe 32 is a better constant?",0,0,0,0.9669277667999268,0.9785152673721312,0.9643352031707764,0.0,accept,unanimous_agreement
775249438,9940,"maybe it's a good idea to keep this function here (empty) for future use? so that if it's needed later, someone doesn't introduce the call in the wrong place (like it did in the past)",0,0,0,0.962313711643219,0.9925605654716492,0.9804213643074036,0.0,accept,unanimous_agreement
775250007,9940,"maybe i don't understand the responsibility of initclientvariables, but i think it should probably not reset `conn` and `id`",0,0,0,0.9662674069404602,0.9654163718223572,0.9282543659210204,0.0,accept,unanimous_agreement
775250434,9940,this method is quite heavy. ideally we could put all these fields together and reset them with a memset. i can't think of a good way to do that though.,0,-1,0,0.6619552969932556,0.8097379207611084,0.5241919159889221,0.0,accept,majority_agreement
775251828,9940,"i'm not certain where we plan on using this method in the future. currently it's only used in module.c where `conn` is null, so i'm not sure if this belongs here or not.",0,0,0,0.8264617323875427,0.7360225319862366,0.860304057598114,0.0,accept,unanimous_agreement
775252207,9940,"same here. not sure if this belongs here or not. we need to define the role of this function better. i.e. we never add clients with no `conn` to the client list, so no need to remove them from there, or unregister their event handlers.",0,0,0,0.9737626910209656,0.9725402593612672,0.9373421669006348,0.0,accept,unanimous_agreement
775265061,9940,"looking at this struct now, i wonder if we can just use the `reply_client`? not sure though ...",-1,0,0,0.5483619570732117,0.951974093914032,0.9401094317436218,0.0,accept,majority_agreement
775265291,9940,i guess we can remove this variable from the server struct?,0,0,0,0.9880311489105223,0.9858006834983826,0.9904719591140748,0.0,accept,unanimous_agreement
775265655,9940,shouldn't this be initialise anyway (even if bc is null)?,0,0,0,0.9752938747406006,0.9888395667076112,0.9893497824668884,0.0,accept,unanimous_agreement
775266030,9940,[code block] ?,0,0,0,0.988338053226471,0.9873912930488586,0.9939754605293274,0.0,accept,unanimous_agreement
775266219,9940,isn't those two are `not` of each other?,0,0,0,0.946057140827179,0.9857743978500366,0.9826748967170716,0.0,accept,unanimous_agreement
775266661,9940,"never mind, i see it uses the redismodule_ctx_new_client flag",0,0,0,0.972669243812561,0.9552952647209167,0.9772626757621764,0.0,accept,unanimous_agreement
775267146,9940,i see you removed it,0,0,0,0.980502188205719,0.9736740589141846,0.9848749041557312,0.0,accept,unanimous_agreement
775281379,9940,"no (i was wondering that myself), each of them states how a client should be freed when the context is destroyed. when neither is set, the client shouldn't be automatically freed. maybe a comment is due",0,0,0,0.9798728227615356,0.9493460655212402,0.9858415722846984,0.0,accept,unanimous_agreement
775382159,9940,"i'm not sure either. it looks okay to use `reply_client` if user doesn't do something surprising. it works for my case and tests pass as well but i'm not sure so i didn't reuse it here. i'd love to use it as it means one less `client` struct to clear, leads to better performance. i think question is, for a thread safe context, can someone call functions other than `rm_reply**` functions? if no, we can use `reply_client` here i believe.",0,1,1,0.4876205325126648,0.5330430865287781,0.9602809548377992,1.0,accept,majority_agreement
775385460,9940,"`client` struct is around 17 kb, so 1024 of them will consume around 17 mb. we use 2 `client` objects per blocked client. so, i assumed that we can have ~ 512 blocked clients at a time. 32 is too few, how about 256(4 mb) or 512(8 mb) ?",0,0,0,0.9800314903259276,0.9818676710128784,0.9843847751617432,0.0,accept,unanimous_agreement
775388855,9940,"where did you get the ~512 number from? since the code will keep working even if we exceed the limit, the compromise we need to make is about 1. efficiency - if we take a number that's too low the optimization will not be sufficient 2. memory - if there's a burst of clients we have no mechanism to later reclaim that memory i'm not comfortable with very high numbers even as high as 256. if we wanna go that high, i think we need: 1. some introspection about this memory consumption in info and memory commands. 2. maybe a ""cron"" mechanism to release them after some idle period. wdyt?",0,0,0,0.6906780004501343,0.843109667301178,0.8663992881774902,0.0,accept,unanimous_agreement
775394962,9940,"i just tried to create a generic function to clear clients. clients can be with or without `conn`. so, i thought we want a single function to `clear()` client objects which can be real clients or fake clients.",0,0,0,0.9836878776550292,0.9897987842559814,0.9803449511528016,0.0,accept,unanimous_agreement
775395351,9940,i just copied this from `freeclient()`. just tried to create a generic `clearclient()` function to be used for all kind of clients either with `conn` or without.,0,0,0,0.9883687496185304,0.993253529071808,0.9940423369407654,0.0,accept,unanimous_agreement
775396807,9940,"`initclientvariables()` is called just after `malloc(sizeof(client)` or when we want to reuse client object, it that case, we clear it as if it is a brand new allocation. maybe change `clearclient()` name, my intention was `clearclient()` will destroy and create new `client` object without deallocating its memory. after `clearclient()` is called on a client object, it's a brand new client object.",0,0,0,0.9847763776779176,0.9913749098777772,0.9930395483970642,0.0,accept,unanimous_agreement
775397536,9940,"i'll take a look. probably, compiler is doing the same as most variables are initialized to zero. i expect it use vectorized instructions here.",0,0,0,0.9836192727088928,0.9807536005973816,0.987382709980011,0.0,accept,unanimous_agreement
775400612,9940,"but what would we use such a function for? resetcommand can't obviously use it (doesn't want to disconnect the client or remove it from the client list). maybe if we wanted to recycle the client structs for normal clients (i.e. when they disconnect add them to a pool). i'm actually not sure it'll be a big performance win, not sure why client struct creation takes so long, maybe it's registration part (in the different lists) is even heavier.",0,0,0,0.7612693309783936,0.8588091135025024,0.8925872445106506,0.0,accept,unanimous_agreement
775400940,9940,"512 is just an assumption mostly considering redisraft use case. i agree there is trade-off, can consume some memory after reaching the peak. also, there is an opportunity to cut the number half, could you take look at here : [a link]",0,0,0,0.9822722673416138,0.9787418842315674,0.9782016277313232,0.0,accept,unanimous_agreement
775403092,9940,"ok, so it assumes nothing there is being used (i.e. clientunlink was called). maybe rename to `initclientstruct`? please try to define / describe / document these functions and their roles, maybe then it'll make more sense to me.",0,0,0,0.9843543767929076,0.9934857487678528,0.9929198622703552,0.0,accept,unanimous_agreement
775403604,9940,"p.s. when we first suggested that module.c and resetcommand can share code, i imagined a much smaller change. i.e. extracting some code from resetcommand into a function to be used by both. maybe we got carried away?",0,0,0,0.9826175570487976,0.9903451800346376,0.9467260241508484,0.0,accept,unanimous_agreement
775404978,9940,"yes, there is no use case for real clients for now. you asked for a single function to clear clients previously in the comments, so i created one `clear` function that can clear all kind of clients. looks like i misunderstood, you were talking about fake clients only? client create/free involves 8 malloc/free pairs including client's own malloc. that takes quite time. so, i tried to avoid freeing memory in clearclient() as much as possible.",0,0,0,0.7999757528305054,0.9006823897361755,0.9625654816627502,0.0,accept,unanimous_agreement
775405777,9940,"after discussion with , i tried to create a generic function to clear clients no matter what kind of clients they are, maybe i misunderstood. so, it could be used different places later if needed etc.",0,0,0,0.9710295796394348,0.9840245842933656,0.9586324095726012,0.0,accept,unanimous_agreement
775421432,9940,i don't know enough about this.. so i'm paranoid.,-1,-1,-1,0.9733157157897948,0.9465894103050232,0.9907482266426086,-1.0,accept,unanimous_agreement
775422002,9940,i think my comment about a single clear function was to share code with resetcommand.,0,0,0,0.9873346090316772,0.9821754097938538,0.9854934811592102,0.0,accept,unanimous_agreement
775440773,9940,added a comment,0,0,0,0.9853251576423644,0.9825007319450378,0.985995590686798,0.0,accept,unanimous_agreement
775440864,9940,ok put it back,0,0,0,0.9795637726783752,0.9701990485191344,0.9874922037124634,0.0,accept,unanimous_agreement
775440909,9940,added a comment,0,0,0,0.9853251576423644,0.9825007319450378,0.985995590686798,0.0,accept,unanimous_agreement
775440966,9940,added a comment,0,0,0,0.9853251576423644,0.9825007319450378,0.985995590686798,0.0,accept,unanimous_agreement
775842893,9940,"i think not, it's deliberately a different client: [a link]",0,0,0,0.9406256675720216,0.9322776198387146,0.985188603401184,0.0,accept,unanimous_agreement
779422339,9940,"please add some comment here to describe that cache, it's purpose and behavior (shrinking). maybe define the `32` minimum in some `#define` constant? please also mention limit and cron mechanism in the top comment of the pr. (to be used as commit comment)",0,0,0,0.9885021448135376,0.9929457306861876,0.9947620034217834,0.0,accept,unanimous_agreement
779423413,9940,"you have a comment specifying the throttling, but i feel you're missing a line that specifies what that does (puts the throttling comment in some context)",0,0,0,0.7808599472045898,0.959671676158905,0.9872794151306152,0.0,accept,unanimous_agreement
779423931,9940,"this is a very minor leak, but still for completion, i think we should mention it in the pr top comment.",0,0,0,0.975688099861145,0.7875900268554688,0.9826394319534302,0.0,accept,unanimous_agreement
781927076,9940,"this is not a leak actually. it was using `modulefreecontextreusedclient` previously. so, no need to call modulefreecontext() previously. now we allocate a temp client object from pool and return it to the pool. to do that, need to call modulefreecontext().",0,0,0,0.9882142543792723,0.9918872714042664,0.9922735095024108,0.0,accept,unanimous_agreement
782047132,9940,"personal opinion, i think this code is not easy to understand. after `modulecron` use `moduletempclientmincount` to record the count after the last shrink, during the next 100ms, if `moduletempclientcount` is reduced to smaller than `moduletempclientmincount`, then use the reduced count to scale in the next `modulescron`, is this correct?",0,0,0,0.9064710140228271,0.9529377222061156,0.8109117746353149,0.0,accept,unanimous_agreement
782068270,9940,we may also want to realloc the `moduletempclients` array. afaict currently it only grows and grows.,0,0,0,0.989544689655304,0.9933238625526428,0.9914891719818116,0.0,accept,unanimous_agreement
782072317,9940,"the new mechanism of only releasing clients that where not used since the recent cron seems ok to me. it's a little hard to follow, but i suppose ok. p.s. why did you change the `iteration` limit from 10 to 500? original one seemed too low, and this one seems too high. i did suggest it could be proportional to the number of recently allocated or release clients, but that may be an overkill.. so just asking how you got to that number? p.p.s. 16, 8, or 4 for `min_client` all seem fine to me.. maybe with a slight preference to the lower ones, so we could settle on 8.",0,0,0,0.896548330783844,0.7413412928581238,0.528472900390625,0.0,accept,unanimous_agreement
782123473,9940,yes. that's correct.,0,0,0,0.9753570556640624,0.8731471300125122,0.9755628108978271,0.0,accept,unanimous_agreement
782123613,9940,fixed.,0,0,0,0.9810503125190736,0.979083240032196,0.9905837774276732,0.0,accept,unanimous_agreement
782124282,9940,added code to shrink it in cron,0,0,0,0.988586962223053,0.993267059326172,0.9951432943344116,0.0,accept,unanimous_agreement
782148500,9940,"sorry, confused by numbers, 500 is a lot. checking it again, on my local i see freeclient() takes around 800-900 nanoseconds. so, we need upper limit here. changed it to 50, which will introduce 50 microseconds latency on this case. should we go higher or lower? can you suggest one? ps. set `min_client` to 8.",-1,-1,-1,0.9868494272232056,0.9861823320388794,0.9833225607872008,-1.0,accept,unanimous_agreement
782190133,9940,seems fine :shrug:,0,-1,-1,0.832030177116394,0.4503968060016632,0.7669844031333923,-1.0,accept,majority_agreement
782194738,9940,"i think this can have a resonance effect. you multiply by 2, and then shrink to half. maybe the shrinking should be only when there's 4 times waste?",0,0,0,0.9670454859733582,0.92234867811203,0.977070689201355,0.0,accept,unanimous_agreement
782247191,9940,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
970241347,11248,"we really don't want to `invalidate` page cache, we want to `reclaim` page cache here, so i think `reclaimfilepagecache` seems better here.",0,0,0,0.9773027896881104,0.9740679860115052,0.9896059036254884,0.0,accept,unanimous_agreement
970242160,11248,"what abouht `return posix_fadvise(fd, offset, length, posix_fadv_dontneed);`?",0,0,0,0.9872034192085266,0.9888219833374025,0.9948655962944032,0.0,accept,unanimous_agreement
970325660,11248,"yes, the reason i wrap the ret is i want to normalize the ret to -1 or 0 just as other utility functions, from man page `posix_fadvise` returns the error number. or maybe whether -1 is return is not critical.",0,0,0,0.9853999018669128,0.9768026471138,0.9912147521972656,0.0,accept,unanimous_agreement
1048541056,11248,"we probably wanna do the same when we save in `finishshutdown`, since we're likely to be restarted from that rdb file soon.",0,0,0,0.9874065518379213,0.9930316209793092,0.9913449287414552,0.0,accept,unanimous_agreement
1048580950,11248,isn't it far better to call this incrementally while writing? like we do with sync_file_range?,0,0,0,0.97181636095047,0.9931649565696716,0.9921644926071168,0.0,accept,unanimous_agreement
1048585547,11248,"neat! but again, maybe we can incrementally release the pages? i guess that in this case it doesn't matter much since we had to accumulate the whole rdb file in the page cache anyway (unlike a persistence save, in which we can avoid that buildup), so it might not matter if we release it incrementally or in one go?",1,0,-1,0.9180645942687988,0.7425472140312195,0.9475615620613098,,review,no_majority_disagreement
1048587484,11248,"in theory we can maybe also incrementally release when parsing the rdb, but that's probably more complicated and we better skip that.",0,0,0,0.975952923297882,0.9856343865394592,0.9775224328041076,0.0,accept,unanimous_agreement
1051580705,11248,"i don't like the fact that we're riding on this ""info"" struct. and also, this change caused quite a lot of cascading changes. i think that instead we only need to add an argument to rdbsave and rdbsavebackground and we're done. it will touch some 9 places that call them, but it'll still be a smaller diff than what you did. maybe instead of a boolean argument it can be a flags argument, so in the future we can add more flags (will also make it slightly more readable than a boolean)",-1,-1,-1,0.9774238467216492,0.7753370404243469,0.9648392796516418,-1.0,accept,unanimous_agreement
1051582819,11248,"maybe it's better to use the same ranges we use in sync_file_range? do we have something to benefit from that? the only reason we also have a fallback for redis_fsync is because sync_file_range isn't standard. i think that the statement about posix_fadv_dontneed not affecting dirty pages is irrelevant. the advise is a generic one, and each implementation can decide how to act on it. it can even change in some future kernel. on the other hand, the advantage of using sync_file_range is not because it is range specific, but rather because we can start a sync on one range and wait on another. so considering that the advise (regardless of being immediate action as it is now, or something else in the future), is applicable on the whole range that was written so far, maybe we don't have to use ranges?",0,0,0,0.8873404860496521,0.9894728064537048,0.9627723097801208,0.0,accept,unanimous_agreement
1051589528,11248,"posix_fadvise is posix, why do we need that `#ifdef`? some platforms may not support it by ignoring it, or do different interpretations of the hint, but why shouldn't we give it?",0,0,0,0.9724285006523132,0.9779592752456664,0.990850865840912,0.0,accept,unanimous_agreement
1051591001,11248,"it can also be used to disable, maybe this is slightly better. wdyt? [code block]",0,0,0,0.9775413870811462,0.9535790085792542,0.9930188059806824,0.0,accept,unanimous_agreement
1051591265,11248,"i think we better explicitly set it to 0 in rioinitwithfile, otherwise, i'm not sure we can be certain what't the value.",0,0,0,0.9302143454551696,0.8068369626998901,0.98031085729599,0.0,accept,unanimous_agreement
1051592615,11248,"our variables are snake_case (for the most part). but also, iirc we now call it ""reclaim"", not ""invalidate"". how about just calling it `int reclaim`?",0,0,0,0.9883421063423156,0.9928761720657348,0.994326651096344,0.0,accept,unanimous_agreement
1051593242,11248,i think that's an ll_warning,0,0,0,0.9851810932159424,0.8532451391220093,0.9336426258087158,0.0,accept,unanimous_agreement
1051593824,11248,"maybe considering my other advise of using it on all oses, not just linux, we wanna silently ignore the error?",0,0,0,0.9750643372535706,0.9778674840927124,0.9876685738563538,0.0,accept,unanimous_agreement
1051593950,11248,"if we wanna silently ignore the error, we should drop that `goto`",0,0,0,0.9845012426376344,0.983337938785553,0.9909691214561462,0.0,accept,unanimous_agreement
1052231134,11248,"yes i didn't notice the other rdb functions has a rdbflags parameter, and i misunderstood the rdbsaveinfo plays the role of flags. i move the keep_cache to the rdbflags parameter.",0,0,0,0.9839704632759094,0.9561284184455872,0.9794412851333618,0.0,accept,unanimous_agreement
1052243397,11248,"according to [a link] posix_fadvise may not be supported in many platform :( , at least not supported on my macbook. to suppress the compilation error and for simplicity, i think regard it as a linux-specific feature is fine at the moment. on the other hand, the direct reclaim and cache issue is also linux-specific :)",-1,-1,-1,0.9013918042182922,0.5573090314865112,0.9691298604011536,-1.0,accept,unanimous_agreement
1052246584,11248,"sure, i'm always not good at naming things... i also expected this function could both turn on and turn off the option.",-1,-1,0,0.9582723379135132,0.5103842616081238,0.5127605199813843,-1.0,accept,majority_agreement
1052252530,11248,"as it's a mirror error information(as you clarify below, the error can be ignored safely), i think ll_notice maybe is sufficient to let user know what happens without scare.",0,0,0,0.983410656452179,0.9910354614257812,0.9841359853744508,0.0,accept,unanimous_agreement
1052269158,11248,"my consideration is `sync_file_range` just issue a writeback request to os, but when posix_fadvise is called, the dirty page is still in flushing, so the posix_fadvise almost has no effect. without the range the writeback-ed pages has another chances to be reclaimed. what about add a statement that it's a linux behave? though we're not supporting it at other os now...",0,0,0,0.9360513687133788,0.5855399966239929,0.9869602918624878,0.0,accept,unanimous_agreement
1052377800,11248,"now that we pass the same rdbflags (`rdbflags_` prefix) to rdbsave, we should probably pass it forward to rdbsaverio rather than use rdbflags_none",0,0,0,0.9882597923278807,0.9953860640525818,0.9924262762069702,0.0,accept,unanimous_agreement
1052386329,11248,"ok, i agree about reclaiming the whole range (the alternative would be to only reclaim what we know we're done flushing (fsynced offset), and didn't yet reclaim, but i guess we don't need that complication. we can mention (maybe here?) why we reclaim the whole range, and the fact that fadv_dontneed on linux only acts on clean pages, but i don't think we should explicitly support that only on linux. i think we should use the generic posix advise and maybe explicitly disable on systems where we see it causes damage.",0,0,0,0.9425331354141236,0.9711658358573914,0.9693126678466796,0.0,accept,unanimous_agreement
1052389324,11248,"ohh, i imagined that not being supported means that you can call it and it does nothing. iirc (from many years ago) even linux doesn't implement all the advises, or that for some the implementation was really naive, and not taking the full power of what it can do with the advise. if it fails to compile, maybe there's a better way to detect where it's present, rather than explicitly rely on `__linux__`?",0,-1,0,0.6661589741706848,0.7193190455436707,0.8127761483192444,0.0,accept,majority_agreement
1053390921,11248,"yes, i try to leverage the compile-time detection just like what `c11_atomic` dose, but i find a problem that i don't know how to express multi-line shell script embedded in makefile, something like: [code block] i know a workaround that put the contents into an individual shell script and let makefile execute the shell script, but if i do this should i also move the `c11_atomic` detection out? can you give me some suggestions oran",0,0,0,0.9582040905952454,0.9505120515823364,0.99076908826828,0.0,accept,unanimous_agreement
1053525199,11248,patl,0,0,0,0.8746429681777954,0.9351621270179749,0.886904776096344,0.0,accept,unanimous_agreement
1068319081,11248,"i found a less intrusive way to achieve this, and i found it works well in my mac and linux vm. i think it's ready to get reviewed.",0,0,1,0.6776761412620544,0.5234593749046326,0.7841088175773621,0.0,accept,majority_agreement
1068959923,11248,"maybe we'd better move the cache reclaim to `rdbload` just like what `rdbsave` does, but `rdbload` operate with `file` while `biocreateclosejob` operate with fd, i don't like open and close a file twice, maybe we could refactor `file` to fd and maintain the file buffer ourself in the future.",0,0,0,0.8807750344276428,0.9785553216934204,0.9664207100868224,0.0,accept,unanimous_agreement
1083411412,11248,"you could use `fileno` to get the fd of that file, but i'm not certain we want to move it to rdbload. readsyncbulkpayload is the one that writes that file, and also calls rdbload to read it, so at least the writing concern belongs here (also it's the one that orchestrates the load). maybe the question should be if we want to reclaim the cache after loading an rdb file on startup. remember we did rdbflags_keep_cache in finishshutdown. since unlike other cases, in both of these cases we don't incrementally reclaim, and instead we can allow the entire file to get cached, it could be that none of this really helps reducing the damage. also, if we reclaim after loading at startup, we should make sure to do it only on successful load, since it could be that loading fails due to some bad configuration, and it's gonna be re-attempted. imho we can keep it as it is now.",0,0,0,0.9804078936576844,0.9920388460159302,0.9887996912002563,0.0,accept,unanimous_agreement
1083632693,11248,"in the bio we would fadvise and close the fd, outside the bio(i.e. in rdbload) we close the file, as there may have race condition in two different thread, so we'd better do all the file operations in bio, but i guess close fd is not equal to close a file(at least the memory refered by file pointer is not released), so passing the fileno of file to biocreateclosejob is not enough. specifically in our use case, a high-capacity host carrying tens or hundreds of redis instances, as page cache in each redis instance grows, it assembles substantial page cache in the host(usually more than 50gb), and finally triggers direct reclaim. as the number of pages to be scanned and reclaimed is quite a lot, the stall time is not ignorable. to solve this specific case finally reclaiming the cache after load is ok. in low-capacity machine the os needn't do many works to relcaim cache as the total pages is less, so this won't be a issue.",0,0,0,0.9448605179786682,0.9699309468269348,0.9891762137413024,0.0,accept,unanimous_agreement
1084838899,11248,"this more strict, autoconf-like approach to detect fadvise is good but less consistent with how redis *generally* does it (with few exceptions). do you see a problem just having a few `#ifdefs` based on platform to set `have_fadvise` in `config.h`?",0,0,0,0.9839826822280884,0.9837448596954346,0.9830591678619384,0.0,accept,unanimous_agreement
1084843354,11248,"the reason to avoid logging here is to refrain from spamming the log with redundant messages, which could happen regardless of os. we could add a counter instead, but given that it's very unlikely to hit an error here, a counter is probably not worth it.",0,0,0,0.922997236251831,0.9639858603477478,0.9837512373924256,0.0,accept,unanimous_agreement
1085571465,11248,"see the discussion [a link] at first i also detect it by platform, but remind me that the support may not only depend on platform but also the kernel version, so i deside to seek for compile-time detection. i think this also helps on some novel syscall, e.g. iouring and so on.",0,0,0,0.9687905311584472,0.9760838150978088,0.9720044136047364,0.0,accept,unanimous_agreement
1085592170,11248,"normally reclaimfilepagecache won't throw a error, but i worry some odd kernel or fs may hit an error, and personally in my practice i prefer more observability in case some odd bug occurs. as the code here is only used on some file load operation, which is not much high frequent, i suppose it wouldn't produce many noise.",0,0,0,0.941724419593811,0.7184537053108215,0.8545839190483093,0.0,accept,unanimous_agreement
1086261514,11248,"i'm not certain i understand yossi's original intent, but still i have a few comments about this: 1. we don't need a special job (or two) for this. it would be enough to add a step to an existing job (one on freebsd and one on linux). 2. maybe we don't need the freebsd one, and it's enough to know that on linux we detect it correctly, and see that other platforms don't fail to build/run. 3. maybe grepping the source code is not the right approach, and instead we can add a tcl test (that runs only on linux) which sets up some extreme scenario and then somehow measures the amount of page cache used by the process? i.e. validates that it achieves its purpose rather than just the fact we call fadvise.",0,0,0,0.7309439182281494,0.9792795181274414,0.8624672293663025,0.0,accept,unanimous_agreement
1089706513,11248,"sadly there're no metrics about page cache used by the process, `/proc/meminfo` counts the total cache size, but this cannot be used directly in tcl test, since the test environment is not isolated, other test case or processes may also increase the cache. the tool `vmtouch` can observe the cache size of file, but it need another dependency installation, so i won't try it. the syscall `mincore` can also observe the cache backed by a file, but i don't know how to use it in tcl... so i only add unittest for it now, it would be nice if you have other ideas about how to measure the cache in integration test.",-1,-1,-1,0.7561568021774292,0.9726698398590088,0.9545019865036012,-1.0,accept,unanimous_agreement
1089893214,11248,maybe we should drop the have_fadvise condition? this will server as an assertion that on linux we did detect that fadvise is supported.,0,0,0,0.9892032742500304,0.9949113726615906,0.986506164073944,0.0,accept,unanimous_agreement
1089894486,11248,"ok, considering it's only when closing a file (not a high rate operation), i guess we can keep it.",0,0,0,0.9848885536193848,0.976152777671814,0.9824846386909484,0.0,accept,unanimous_agreement
1089895941,11248,you're right. so you wanna add a reclaim on startup when an rdb was successfully loaded?,0,0,0,0.9790873527526855,0.9214887619018556,0.9905948638916016,0.0,accept,unanimous_agreement
1089896305,11248,"so can we keep the current code? i do wanna support any os that has it, not just linux. or maybe you argue that we should empirically find the oses we support that have it and use it only on these (leaving others out of scope)?",0,0,0,0.9671015739440918,0.9760419130325316,0.9891034364700316,0.0,accept,unanimous_agreement
1089897072,11248,"ok, so in the current approach we don't have any tcl tests that test our usage of fadvise (make sure we have no bugs). but we do have a test (specific for linxu) that checks our detection and the fact fadvise works. i agree we probably can't write a tcl test that verifies these, since we have no clue how these run and in parallel to what. but maybe we can add a check in one of the gh action workflows? i.e. in that case we do know we run on an isolated host. e.g. spin up a job on linux, measure `/proc/meminfo` run `--single integration/replication` or alike, and re-measure meminfo?",0,0,0,0.9575533866882324,0.9848443865776062,0.9657557010650636,0.0,accept,unanimous_agreement
1089910278,11248,make sense,0,0,0,0.9631345272064208,0.9401010274887084,0.9741621613502502,0.0,accept,unanimous_agreement
1089916494,11248,"yes, i think this would be more consistent with quit while keeping the rdb cache, though i don't know how to do it elegantly now(i.e. without extra open and close file operations).",0,0,0,0.9779899716377258,0.9800617098808287,0.9890916347503662,0.0,accept,unanimous_agreement
1089951259,11248,"i added a github action but i'm not sure it works as expected. there're some other variables, like saving rdb while quitting, or log, that may increase the cache, so i doubt the limit 10kb is enough, and i don't know how to trigger a github action to verify it. i'll tune it according to the result.",0,0,0,0.8155333399772644,0.5064935088157654,0.892480194568634,0.0,accept,unanimous_agreement
1093008072,11248,i don't think an extra open (at startup) is an issue.,0,0,0,0.9033403396606444,0.9406954050064088,0.9666154384613036,0.0,accept,unanimous_agreement
1098684543,11248,"maybe do that only if loading succeeded? if it didn't (e.g. failed on oom issue), maybe it is likely to be retried?",0,0,0,0.9810196757316588,0.993427276611328,0.990839421749115,0.0,accept,unanimous_agreement
1098698245,11248,"if we do that, we should add a `reclaimcache` part to the `skipjobs` defaults at the top of the file. but maybe we should make it more generic so that other similar tests can be added in the future. we could make it more generic by naming it `specific`, so we can choose to skip or not to skip all specific tests (i.e. ones that don't just re-run the whole test suite on various combinations). another alternative is to move it to a separate (new) yaml file (with a daily cron trigger), but then we won't be able to trigger it with our workflow dispatch on random branches and prs. i'm leaning towards just renaming it.",0,0,0,0.9827706813812256,0.9946580529212952,0.988500714302063,0.0,accept,unanimous_agreement
1098878802,11248,"i think it's right, on failure the user would retry or remove/rewrite the corrupt rdb finally",0,0,0,0.9809414148330688,0.9823641777038574,0.9607252478599548,0.0,accept,unanimous_agreement
1100073725,11248,"yes, i think we can white list the specific platforms on which we assume it exists and ignore it elsewhere. it's more aligned with how most other capabilities are handled.",0,0,0,0.9846405982971193,0.9795758724212646,0.9884767532348632,0.0,accept,unanimous_agreement
1100196054,11248,"i think other things that we handle that way are non-standard (like `sync_file_range`), but `posix_fadvise` is standard (like `_atomic`. so using it on just a few platforms (e.g. just linux and mac), could theoretically be a wasteful miss on solaris (just random examples, i didn't bother to check which one supports it). on the other hand, we can say that since this is just an advise, and we're not sure what's the implementation behind each os, we don't wanna use it on ones on which we didn't test it.. although, we are never gonna test it on these, so if we'll enable it, we can get some report of issues from the community, but if we're wasteful on some of these oses because we didn't bother to enable it, no one will report that. did i convince you? or do you insist on explicitly enabling it on specific list of oses?",0,0,0,0.8654731512069702,0.8664597868919373,0.9649510383605956,0.0,accept,unanimous_agreement
1100428435,11248,"personally i perfer autoconf-like detection since it's more robust and portable, and doesn't depend on the programer's good understanding to the environment as well as its history. i refer to some `make` project, like nginx, rocksdb, they detect the symbols with shell script, while other `cmake` project utilize the cmake mechanisms like `check_symbol_exists` and `check_cxx_source_compiles`. in redis's tradition these detection were done with macros, so it involves some break...",0,0,0,0.9619076251983644,0.9555984139442444,0.9435409307479858,0.0,accept,unanimous_agreement
1101317247,11248,"i discussed this with yossi and decided to drop it in favor of ifdefs in config.h. personally i'm not very happy about it, but willing to let go. the arguments were that we don't do such a thing for many other system calls, and we don't want to transition into adding more of these in the current way. arguing that the _atomic thing was an exception because the problem was rather widespread. putting this in config.h we have two alternatives: 1. by default try to use it, and just add an explicit set of exception oses on which it's missing. 2. by default don't use it, and add exceptions only for the oses on which we know it exists and works as expected. the disadvantage of [1] would be that compilation would break on some system, and then we'll get a pr to add an exception. the disadvantage of [2] is that on some system were we could have performed better, we won't and it's likely no one will notice. we decided to take option [2]. i know you've invested quite a lot of time on this mechanism, i apologize for pushing in that direction and wasting your time.",-1,-1,-1,0.4761923849582672,0.6665911674499512,0.7562496066093445,-1.0,accept,unanimous_agreement
1101784784,11248,"it's just a process of exploration, so no need for the apologize, and i think i learned a lot from the discussion : ) i'll update this part tomorrow. i also spent sometime updating the top comment, but since i'm a native speaker, i'm sure if i describe correctly. if there're some faults or other points i missed, plz help me refine it thanks!",1,1,1,0.9908636212348938,0.99038964509964,0.9957948923110962,1.0,accept,unanimous_agreement
1103779268,11248,"i now notice that we create a job that does the reclaim, but doesn't do an fsync, so doesn't that mean that the fadvise may be ineffective. we do that here (rdbload, and also in closerepldbfd)",0,0,0,0.9852026104927064,0.9914445281028748,0.990817666053772,0.0,accept,unanimous_agreement
1103779537,11248,"i realize that we're doing a reclaim on the aof (only when closing a file, or doing a rewrite), but we didn't do any reclaim in the incremental fsync (biocreatefsyncjob). it feels a bit odd, maybe we should be more decisive and either leave the aof file out of this campaign, or fully include it. wdyt?",-1,-1,-1,0.6027286648750305,0.8882718086242676,0.8106229305267334,-1.0,accept,unanimous_agreement
1103820535,11248,"i think we'd better address aof the same as rdb, since this pr just intend to solve a specific problem we encountered when we do massive upgrade to our cluster initially, so it only reclaim the cache of rdb. i'll submit another pr for it.",0,0,0,0.9834840893745422,0.9842337965965272,0.9871395230293274,0.0,accept,unanimous_agreement
1103821349,11248,"fsync should coordinate with write to guarantee the safety of file, rdbload just read the file, i think it's based on a assumption that the file has been fsynced at the time write is performed.",0,0,0,0.9849287867546082,0.9941330552101136,0.9891408681869508,0.0,accept,unanimous_agreement
1103823500,11248,"ok, indeed both rdbsave and readsyncbulkpayload do an fsync before leaving, so we're safe there. but on the other hand, it means that adding another fsync would be harmless, so it may be ""safer"" or cleaner to always make sure we couple an fadvise with an fsync just before it. we can do that by passing `1` as the need_fsync, or by modifying bio.c to always force an fsync before calling fadvise, even if need_sync is 0. what do you think?",0,0,0,0.9609131813049316,0.9762492179870604,0.9642194509506226,0.0,accept,unanimous_agreement
1103932680,11248,"i still don't think it's a good idea. fsync belongs to the scope of write, but we do something related to write while reading a file, the couple of read and write looks a little odd. another problem is, while fadvise has no side effect to write, but fsync do. while a page is marked as writeback, the page can not be written util the writeback ends(more precisely the write would block util writeback is done), so fsync here may interfere a write at other place, which is unexpected.",-1,-1,-1,0.528473973274231,0.8078004717826843,0.8855873942375183,-1.0,accept,unanimous_agreement
1104028243,11248,"ok, let's leave it as is then.",0,0,0,0.979541003704071,0.9869242906570436,0.9843660593032836,0.0,accept,unanimous_agreement
1105230661,11248,"there is a failure in the daily, can you take a look? [a link]",0,0,0,0.915989875793457,0.9818149209022522,0.9836693406105042,0.0,accept,unanimous_agreement
1105231425,11248,"there is also an error here, which can be reproduced on my local valgrind env [a link] [code block]",0,0,0,0.9819505214691162,0.992450475692749,0.9945989847183228,0.0,accept,unanimous_agreement
1105391083,11248,"i can also reproduce (linux), it passes when running without valgrind, but fails when running with valgrind. not sure how we can detect it and skip the test (never done that). i see there's a running_on_valgrind macro that requires valgrind.h. i suppose that this being part of the unit test and not redis itself (something only developers use), it might be a valid solution. maybe someone knows a better one?",0,0,0,0.9635136723518372,0.9583310484886168,0.9666338562965392,0.0,accept,unanimous_agreement
1105939629,11248,"1375580160 - 1375014912 = 565,248 byte, it's a litter over the limit 500kb i set. to track accurately where the small cache is from is a little hard, i'll follow up",0,-1,0,0.9749904274940492,0.908341109752655,0.929008424282074,0.0,accept,majority_agreement
1105960014,11248,"i suspect valgrind would do some black magic like mock the mmap syscall to track the memory allocation(as far as i know some allocator claim large trunk of memory form os with `mmap`), though i'm not an expert on valgrind.",0,0,0,0.5801820755004883,0.9323288202285768,0.9437209367752076,0.0,accept,unanimous_agreement
1106079820,11248,let's just skip it with the ugly ifdef,-1,-1,-1,0.7174831628799438,0.8914494514465332,0.8667725920677185,-1.0,accept,unanimous_agreement
1106696590,11248,"to stop the ci failures, i made a pr for this change [a link] please handle the other issues (test thresholds, and aof).",0,0,0,0.9861409664154052,0.9862723350524902,0.9941815733909608,0.0,accept,unanimous_agreement
572462635,8474,"since we are no longer doing any introspection on cmds here, i think we can safely remove this from the function signature.",0,0,0,0.9861704111099244,0.9861046671867372,0.9920386075973512,0.0,accept,unanimous_agreement
572463531,8474,pxat*,0,0,0,0.9494314193725586,0.9811903238296508,0.9829551577568054,0.0,accept,unanimous_agreement
572463807,8474,"spacing, two other offenders below. [code block]",0,0,0,0.9816082119941713,0.9754058122634888,0.9849898815155028,0.0,accept,unanimous_agreement
572465308,8474,also slightly off spacing.,0,0,0,0.9745780825614928,0.9632658362388612,0.9804163575172424,0.0,accept,unanimous_agreement
572468611,8474,i think there was some discussion that expire could overflow during this multiplication. might want to check it's still positive at the end.,0,0,0,0.9845332503318788,0.9767524600028992,0.9878569841384888,0.0,accept,unanimous_agreement
572469705,8474,"shared.px should be unused now, we could probably drop it from the shared table.",0,0,0,0.9873371720314026,0.9953475594520568,0.9917348623275756,0.0,accept,unanimous_agreement
572472018,8474,since we're deleting all of the validation that the two values are the same (just that we're replicating it as a pexireat or set pxat). can we also test that on the primary and replica executing ttl gives the same value?,0,0,0,0.9888482093811036,0.9942116141319276,0.9933034777641296,0.0,accept,unanimous_agreement
572488776,8474,"done. i'm still keep the `cmd` argument in the upper layer `propagate()` signature, even though it is not used there anymore either: 1. too many invocations of `propagate()` to change/squeeze in this pr. 2. might be useful later when we want to do things based on `cmd` that apply to both aof and replication.",0,0,0,0.981376051902771,0.990454375743866,0.9863985180854796,0.0,accept,unanimous_agreement
572489836,8474,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
572490333,8474,fixed.,0,0,0,0.9810503125190736,0.979083240032196,0.9905837774276732,0.0,accept,unanimous_agreement
572501578,8474,good point. done.,1,1,1,0.9373816847801208,0.9410116672515868,0.9740297198295592,1.0,accept,unanimous_agreement
572501796,8474,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
572503457,8474,hmm something wrong with my formatter...fixed.,-1,-1,-1,0.8014248609542847,0.8909249305725098,0.7515236735343933,-1.0,accept,unanimous_agreement
572574240,8474,i agree,0,0,0,0.934429407119751,0.8392824530601501,0.9744842648506165,0.0,accept,unanimous_agreement
573260156,8474,makes sense to not reduce the test coverage. done. had to introduce a new `[absolute]` optional argument to `ttl` and `pttl` commands to return absolute expiration timestamps of keys.,0,0,0,0.9867984652519226,0.989464521408081,0.9903665781021118,0.0,accept,unanimous_agreement
573371094,8474,you really like your tabs.,1,1,1,0.943912386894226,0.8254771828651428,0.9645144939422609,1.0,accept,unanimous_agreement
573372473,8474,what's this cool flag do?,1,1,1,0.6528623700141907,0.7664358615875244,0.9587220549583436,1.0,accept,unanimous_agreement
573373177,8474,"this is a syntax error, not a subcommand syntax error. [code block]",0,0,0,0.9674330353736876,0.9842739701271056,0.9589918851852416,0.0,accept,unanimous_agreement
573374364,8474,lol this cool flag changed the meaning of the command so is cold-bloodedly discarded now. removed.,1,1,1,0.9071735739707948,0.993928074836731,0.9752824306488036,1.0,accept,unanimous_agreement
573374560,8474,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
573374627,8474,lol my bad. fixed,-1,-1,-1,0.987860381603241,0.9908910393714904,0.993097722530365,-1.0,accept,unanimous_agreement
580568035,8474,i ended up introducing a new `expiretime` command to query absolute timestamps of ttls.,0,0,0,0.9878041744232178,0.9753918647766112,0.988739252090454,0.0,accept,unanimous_agreement
593502348,8474,"i prefer to keep `ttl` in the name as `milliseconds` is too generic and doesn't indicate this is the time to live. if you want to make it clear that the ttl is in terms of milliseconds, you can rename it to be something like `ttl_millis`.",0,0,0,0.9680817127227784,0.9902267456054688,0.9893456101417542,0.0,accept,unanimous_agreement
593509195,8474,`ttl_milliseconds`?,0,0,0,0.988415002822876,0.9921494722366332,0.9939956068992616,0.0,accept,unanimous_agreement
593509855,8474,`millisecond_obj` for a more consistent naming schemes for local variables.,0,0,0,0.9872947335243224,0.9888972640037536,0.9899135828018188,0.0,accept,unanimous_agreement
593513680,8474,nitpick: don't need to move this method call down from where it was for better code locality :),1,1,0,0.9286959767341614,0.8905465006828308,0.7573571801185608,1.0,accept,majority_agreement
593519865,8474,"not sure if it is a good idea to expose this command as a new redis command. i think most redis users would prefer to see expire time as a relative value instead of the absolute epoch time value. if this command is used for testing purposes only, can you make it into a sub-command for `debug` command?",0,0,0,0.9738560318946838,0.9844634532928468,0.7247423529624939,0.0,accept,unanimous_agreement
594499335,8474,i dont feel strongly but existing code uses `milliseconds` already: [a link],-1,0,0,0.6290498971939087,0.894172728061676,0.7819051742553711,0.0,accept,majority_agreement
594513886,8474,"i'm introducing it for testing purposes. but i do think it has use cases outside testing. it allows users to understand the relative distance between the expiration deadlines of different keys. e.g. if two keys would be expired together. today there is no way to do that. i think this family of use cases deserve a top level command, assuming we don't only introduce top level commands for super popular use cases. i preferred introducing `expiretime` over a `debug` sub-command also because i wanted to colocate the implementation of `expiretimecommand` in `expire.c` next to `ttlcommand` so i can easily re-use `ttlgenericcommand`.",0,0,0,0.7543057203292847,0.9773320555686952,0.8126873970031738,0.0,accept,unanimous_agreement
594516152,8474,"all other `notifykeyspaceevent(notify_generic,""expire""` invocations in other command processing funtions happen after command rewriting. i was trying to unify that. examples: 1. [a link] 2. [a link]",0,0,0,0.9792228937149048,0.994449257850647,0.995310127735138,0.0,accept,unanimous_agreement
594519435,8474,setting expiry with absolute timestamp is not a new feature. people can already do that today. i am not sure if this change justifies adding a new user facing command. i still prefer us to handle the expiry replication as an internal mechanism inside redis that is done transparently from the redis user,0,0,0,0.8049097657203674,0.9589725136756896,0.9484578371047974,0.0,accept,unanimous_agreement
594524557,8474,a downside to changing it is it confuses the git history. i don't really care.,-1,-1,-1,0.9819985628128052,0.7257664799690247,0.7999640703201294,-1.0,accept,unanimous_agreement
594549648,8474,change to replicaof,0,0,0,0.9877076745033264,0.9866807460784912,0.9929794669151306,0.0,accept,unanimous_agreement
594570650,8474,yes people can set expiry with absolute timestamps today. but they can't query them. do you agree that it can be useful to query absolute timestamps outside of testing?,0,0,0,0.9832192063331604,0.9876832365989684,0.9920090436935424,0.0,accept,unanimous_agreement
595537064,8474,this transformation is only needed if `!absttl`,0,0,0,0.9578261375427246,0.9938560128211976,0.995607316493988,0.0,accept,unanimous_agreement
595842428,8474,"i'd vote to keep `ttl`. another possibility is to read it into an `ll` var, and then copy it into an `mstime_t ttl`, but it later changes from relative to absolute. i suppose we can reduce the git diff and make it easier on the git log, since this rename doesn't really improves this function (the ttl is always in milliseconds in this command)",0,0,0,0.980299711227417,0.9863353967666626,0.987835705280304,0.0,accept,unanimous_agreement
595848426,8474,"i agree, it'll be easier to read if we move the `!absttl` condition we have below to wrap this whole block and avoid messing with the propagation if `absttl` is true.",0,0,0,0.98401939868927,0.930075228214264,0.9754539132118224,0.0,accept,unanimous_agreement
595862726,8474,"i think this rename is unnecessary too (we should keep `when`), and note that there's possibility a duration where the variable holds seconds.",0,0,0,0.945999801158905,0.9881576895713806,0.9764525294303894,0.0,accept,unanimous_agreement
595875472,8474,"i don't think we need the time/ptime variants.. i think this command can always just return milliseconds. note that if we remove them, then like ttl and pttl this command may some day become variadic. we can always later add pexpiretime (more consistent with ttl, pttl, expireat, pexpireat)",0,0,0,0.9801258444786072,0.9877244234085084,0.9792367219924928,0.0,accept,unanimous_agreement
595884424,8474,"technically, expireat doesn't block negative expire times (times before 1/1/1970), so i don't think expiretime should do that either. this could mean that the check for `output_abs` should be moved to be with `expire != -1`, so that we skip the truncation of negative values below. however, then we have a problem with the semantics of the command, returning -2 on non-existing keys and -1 on non-volatile keys. maybe wanna give this new command different semantics, like returning an error in those cases, and a raw unixtime on success which could in theory be negative? p.s. in theory negative values are non-observable since lookupkey will return null, in theory there could be a case where a propagated script that is received from the master, is executed on the replica and lookupkey returns an expired key, but even that can't happen since this command is marked with the `random` flag. i'm not entirely sure what's the right thing to do here yet... waiting to hear other opinions and suggestions.",0,0,0,0.9722176790237428,0.9524254202842712,0.9832184910774232,0.0,accept,unanimous_agreement
595955320,8474,"i'm in favor of adding that command (not as debug command). someone wanting to use dump and restore, may want to use it instead of pttl (to provide absttl to restore)",0,0,0,0.9776238203048706,0.9916770458221436,0.9801913499832152,0.0,accept,unanimous_agreement
595961879,8474,can you explain why you did that change?,0,0,0,0.9759481549263,0.9880449175834656,0.9927313923835754,0.0,accept,unanimous_agreement
595962744,8474,i think these are more suitable to util.tcl rather than test_helper.tcl (one of the benefits is that they can be used in the cluster tests one day),0,0,0,0.9530810713768004,0.9565700888633728,0.9051759839057922,0.0,accept,unanimous_agreement
595969248,8474,"this sleep was in order to let the time pass (not in order to flush the aof file). in fact, as soon as you got the reply for the last command you executed, this contents is already in the aof file (`appendfsync always` isn't needed, it's about power-loss and kernel panics) i suggest to drop the comment, and move that sleep to be just before that `debug loadaof` below.",0,0,0,0.9837666749954224,0.9938158988952636,0.9940791130065918,0.0,accept,unanimous_agreement
595970915,8474,there's some indentation issue.,0,0,0,0.9737609624862672,0.7408466935157776,0.9287959337234496,0.0,accept,unanimous_agreement
595972742,8474,"let's use `assert_equal` rather than `assert`. the benefit is that when the assertion fails, the message contains the values. also, let's convert this big block to a loop using keys, rather than a line per key.",0,0,0,0.9858089089393616,0.9894232153892516,0.9913483262062072,0.0,accept,unanimous_agreement
595980885,8474,"please use `assert_euqal` here and below instead of `assert`. the benefit is that when it fails, we can see the values.",0,0,0,0.9866757988929749,0.9937159419059752,0.993144989013672,0.0,accept,unanimous_agreement
596416627,8474,i didn't take git history into account. i can revert my ttl variable naming changes in this pr. i still think it's worthwhile to unify how ttl variables are named across different places. if we think `ttl` is better/sufficient. should we want to change places like this too? [a link],0,0,0,0.9177863001823424,0.936545729637146,0.980741560459137,0.0,accept,unanimous_agreement
596421092,8474,reverted,0,0,0,0.9771652221679688,0.9411051869392396,0.976313292980194,0.0,accept,unanimous_agreement
596421540,8474,"done. to clarify, i copy-pasted this variable name from: [a link] i'm changing there too.",0,0,0,0.9869710206985474,0.981752634048462,0.9901756644248962,0.0,accept,unanimous_agreement
596422094,8474,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
596428409,8474,"i'm not entirely understanding the problem here. my assumption is that redis never stores a negative absolute timestamp into the expire dictionary. if `expireat/pexpireat` is executed with a negative unix timestamp, it will [a link], therefore not stored into the expire dictionary. and since `expiretime` just simply returns what is stored in the expire dictionary, there is no legitimate case where it would return a negative value. therefore it's safe to reserve `-1` and `-2` for error responses. what am i missing?",0,0,0,0.8850212693214417,0.7447813749313354,0.6205399036407471,0.0,accept,unanimous_agreement
596430435,8474,"i see. i was under the impression that oss redis prefers to limit the number of new commands, meaning if two commands essentially perform the same functionality, then we prefer to combine them. `expiretime` and `pexpiretime` are two commands that would be performing very similar functionalities. are we sure we want to have two separate commands? btw, i think you meant to say `expiretime` should just always return seconds, since that is the unit `ttl` and `expireat` deal with. i don't feel strongly either way. if we decide to implement two separate commands. i don't see why not implement both now.",-1,0,0,0.5528445839881897,0.7164276242256165,0.8742499351501465,0.0,accept,majority_agreement
596437591,8474,"with this change, `expireat` should never appear in aof files. so i think we should adapt this test to test what's possible.",0,0,0,0.9859058856964112,0.9822115302085876,0.9914946556091307,0.0,accept,unanimous_agreement
596443221,8474,i put them here because their replication stream counterpart `read_from_replication_stream` and `assert_replication_stream` are in this file. moved.,0,0,0,0.989424467086792,0.9946563243865968,0.9944674968719482,0.0,accept,unanimous_agreement
596447092,8474,"thanks for the info. i didn't realize that. changed. i added a comment to say this sleep is to ""let time pass"", to warn other uninformed people like me.",1,1,1,0.524114191532135,0.9066898226737976,0.9761903882026672,1.0,accept,unanimous_agreement
596448272,8474,thanks for the info. i didn't know the difference. done.,1,1,1,0.7758449912071228,0.8992884755134583,0.968665897846222,1.0,accept,unanimous_agreement
596450834,8474,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
596452811,8474,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
596769610,8474,"yes. we do wanna keep the number of commands low, and have commands that do similar things unified into one. the main reason for that is that if we have two variants with some boolean flag difference between them (e.g. set and setnx), when we add another mutation (setget) we can end up with 4 commands, and if we add another one (setkeepttl) we have 8. so in that spirit, maybe one option is to deprecate `pttl`, and change `ttl` to have `abs` and `ms` arguments. that would mean that ttl can never be made variadic. for some reason i think that in this case i rather add `pexpiretime` (and possibly `expiretime`, not a must) which will take no arguments and can later be made variadic. i'm still not certain what's best here. wdyt?",0,0,0,0.9736925959587096,0.985116183757782,0.9805475473403932,0.0,accept,unanimous_agreement
596771333,8474,"i guess it's just me.. being obsessed with the fact that negative unix times are valid values. in redis, we don't store arbitrary dates in the past, just the future, so a valid negative timestamp would only happen if the machine's wall-clock is set to before 1/1/1970, in which case the key won't deleted on the spot by `checkalreadyexpired`. i guess this is not a valid use case for redis. till now in the api (commands) we mainly abused the values -1 and -2 for relative times, so that's ok either way (even if your clock is before 1970). we do have that issue in `getexpire` too, work works with absolute times, but this is internal and can in theory be fixed one day. so we need to realize that the semantics of this new command carves that in stone (api). wdyt?",-1,-1,0,0.8647845387458801,0.9226931929588318,0.5221490263938904,-1.0,accept,majority_agreement
596772194,8474,"ohh, that's a good reason. maybe one day we should move read_from_replication_stream too. for now, i guess that we can keep the old one misplaced and the new one in the right place.",1,0,0,0.6530241966247559,0.8967112302780151,0.7594853043556213,0.0,accept,majority_agreement
597046502,8474,"my first choice was to extend ttl to have [code block] and [code block] arguments, and deprecate the pttl command. they all logically fit together, and i do think they are more of debugging commands and less for production workloads. i don't think there is much value in making the ttl command variadic, i can't think of a very compelling case for it. this issue of variadic commands keeps coming up though, so we probably want to figure out the best syntax for having flags + multiple key names. my second choice was the current implementation, expiretime time|ptime. i really think similar commands should be logically grouped together.",0,0,0,0.8455660343170166,0.9686816930770874,0.9003475904464722,0.0,accept,unanimous_agreement
597064319,8474,"i'm okay with blocking negative expires in redis, i can't see a world where we would want to store them and return them.",0,0,0,0.9717437624931335,0.8797805309295654,0.9277659058570862,0.0,accept,unanimous_agreement
597073382,8474,"i will defer to you folks making this decision. but i will leave my 2 cents here: `ttl abs` is a bad choice. it's contradictory within itself. `ttl` means time-to-live. it's inherently a relative-time-based concept. the first sentence of its [a link] says: [code block] adding a `abs` option simply invalidates that sentence, and complicates the core purpose of this api.",-1,-1,-1,0.912519633769989,0.7898753881454468,0.8292858600616455,-1.0,accept,unanimous_agreement
597075069,8474,+1 for disallowing setting negative unix timestamps with `expire/expireat/pexpire/pexpireat` altogether.,0,0,1,0.9542578458786012,0.9926313161849976,0.9060559272766112,0.0,accept,majority_agreement
597102197,8474,you're right. in theory we can resolve that by making the new all purpose command named expiretime (will take abs/ttl/ms arguments). but maybe the most straight forward thing to do is add just a pexpiretime command with no arguments and skip expiretime.,0,0,0,0.9202908873558044,0.9857128858566284,0.9802087545394896,0.0,accept,unanimous_agreement
597163097,8474,"i agree `ttl abs` is confusing. i think having both `pexpiretime` and `expiretime` makes sense: * it's only a single extra command, not a matrix like in other cases * more consistent with existing expiration family of commands * can be variadic (although i agree the value is not terribly high)",0,0,0,0.8271799683570862,0.9154731631278992,0.9133434295654296,0.0,accept,unanimous_agreement
597848893,8474,"i don't think we wanna change the behavior of existing commands in that case (return an error), but as we concluded above, we can assume negative values will never find their way into the expires dict. so i think the current code in this pr is fine in that regard.",0,0,0,0.9801784157752992,0.976350486278534,0.9424009919166564,0.0,accept,unanimous_agreement
597985821,8474,implemented `pexpiretime` and `expiretime`,0,0,0,0.9882825016975404,0.9942196607589722,0.995306432247162,0.0,accept,unanimous_agreement
598925483,8474,waiting for `1000` makes this test sometimes flaky on my slower local machine. change it to without a timeout to de-flake it.,0,0,0,0.5802860260009766,0.7127060890197754,0.9057525992393494,0.0,accept,unanimous_agreement
611164370,8474,"in general, we don't want to change small things like these, except if it really improves the code. if there is no risk of confusion (or only a very small risk), i suggest keeping the old variable names.",0,0,0,0.9810523986816406,0.9528492093086244,0.9875584840774536,0.0,accept,unanimous_agreement
546545119,8217,why isn't `auth` (the first error) prefixed with `-`? [code block],0,0,0,0.9781578183174132,0.994617521762848,0.9922925233840942,0.0,accept,unanimous_agreement
546546320,8217,"i would like to try to find a way to avoid there changes (gonna cause conflicts for other prs). one way is to group `microseconds`, `calls`, `failed_calls`, and `id` into a separate struct for runtime info. then we can init that entire struct with one `{}`, and we don't need to edit the declarative statement whenever a runtime variable is added. but the above idea still means we need to edit it once (today), let's try to think of a way..",0,0,0,0.945592999458313,0.9831421375274658,0.954346776008606,0.0,accept,unanimous_agreement
546549080,8217,"i don't see why we need this static struct and a fancy dict population function. at the end of which, we have the error name in both the dict key, and again embedded inside it's value. one other way is to drop this static table, and just have a 3 line population function that adds the 3 errors (3 calls to dictadd), later using dictgetunsignedintegerval to increment. or is we need a struct with more than one integer, we can calloc it when calling dictadd. the way i see it, the justification for the command table population way, is when you have a lot of metadata to add to each item on creation, and you want it shown in the code in a ""declarative"" form. but in this case we don't have a metadata (it's initialized with 0) another alternative is to not use dict at all, just an array with some enum as index to it. the fact is, that currently, you're not looking up for an error that was given to you by the caller (which justifies a runtime lookup), you're only actually looking up an error which you know (at compile time) which one it is, so you can just use an enum as an index to the array. this will not hold if we'll try to detect other types of errors in the future, in which case we'll need `lookuperror` to only match the error prefix, and not the entire string.",0,0,0,0.9377710819244384,0.9442129731178284,0.9064792394638062,0.0,accept,unanimous_agreement
546550813,8217,"in the current form, these are not needed, the lookup dict (if at all we keep it), can use a char* search rather than an sds search, and the char* can be a static string, not a heap allocation.",0,0,0,0.987589716911316,0.993907392024994,0.992922306060791,0.0,accept,unanimous_agreement
546942834,8217,"can we also just move the pointer one character in, we know the first character must be ""-""",0,0,0,0.628540575504303,0.98967182636261,0.9928210377693176,0.0,accept,unanimous_agreement
546943744,8217,can this function just increment the error? not sure why we need to fetch it then increment it.,0,0,0,0.9682613611221312,0.9002330303192139,0.9537693858146667,0.0,accept,unanimous_agreement
546998812,8217,"also, isn't this duplicative of the acl log?",0,0,0,0.9795942902565002,0.9908219575881958,0.9942182302474976,0.0,accept,unanimous_agreement
547035499,8217,fixed in last commit,0,0,0,0.9878752827644348,0.9843711256980896,0.993574559688568,0.0,accept,unanimous_agreement
547035649,8217,agree . changed in the latest commit,0,0,0,0.981603503227234,0.9918747544288636,0.987757921218872,0.0,accept,unanimous_agreement
547038515,8217,"due to ""auth"" error string not starting with `-`. the `-` is added afterwards but non included in the error string, within addreplyerrorlength() line `if (!len || s[0] != '-') addreplyproto(c,""-err "",5);` . noneteless if we follow the new approach this is accounted for...",0,0,0,0.9754441380500792,0.9880651831626892,0.9938606023788452,0.0,accept,unanimous_agreement
547038644,8217,followed your advice and using a rax with a much simpler and future proof aproach. can you check it?,0,0,0,0.978539228439331,0.895362377166748,0.9042626023292542,0.0,accept,unanimous_agreement
547205411,8217,agree :) will do that change - since yesterday we already had two conflicts =) ),1,1,1,0.9854742288589478,0.9955546259880066,0.9965912103652954,1.0,accept,unanimous_agreement
547340987,8217,"ok, this means that the text ""auth"" which we matched against, is not the error code, it's just a part of the error text which happens to be uppercase. i think it means we need to move `aftererrorreply` to be called in the different place, since it takes an error message, but it's no the final error message.",0,0,0,0.9822618961334229,0.9880560636520386,0.987687051296234,0.0,accept,unanimous_agreement
547341834,8217,"we have a plan for the future, but i'm also hoping to find a plan for now (would very much like to avoid these modifications)",0,0,0,0.9031928777694702,0.915427029132843,0.8624954223632812,0.0,accept,unanimous_agreement
547368301,8217,"we do not want to **optionally** remove the spurious dash, this is in fact an indication that this method (`aftererrorreply`) is called in the wrong place, and given the wrong input (incomplete error message). if we do that, the dash will always be present (and we can remove it, and even assert that it's there).",0,0,0,0.9589911103248596,0.990207850933075,0.9846359491348268,0.0,accept,unanimous_agreement
547372445,8217,i think you just need to discard the rax and create a fresh one. this way the info response won't even show 0 values for errors that no longer happen.,0,0,0,0.9756189584732056,0.9806499481201172,0.983806610107422,0.0,accept,unanimous_agreement
547373788,8217,"you don't need to store the name inside the rax ""value"". when iterating on the rax you get the key from the iterator. considering my previous comments, the error code will always be uppercase. no need to mess with the character casing.",0,0,0,0.9798018932342528,0.9902209043502808,0.9919189810752868,0.0,accept,unanimous_agreement
547379048,8217,"i think we can just omit that change for now, and it'll all pass. it means that the last `0` which was the command `id` will now be stored into the new `failed_calls` and the last member (the `id`) will be implicitly initialized to 0 (which is ok). i remember in the past that some compiler generated a warning on structs that were partially initialized but not fully initialized, but i see in the ci for `#8210` passes and we do use `-werror`. ideally that means we can trim the last 3 `0`, and not just avoid adding a 4th, but i don't wanna do that. i'm planning another huge pr soon which will completely rewrite that whole command table array, so that's when i'll trim these.",0,0,0,0.9498449563980104,0.9925925135612488,0.9645780324935912,0.0,accept,unanimous_agreement
547512213,8217,given that we check on the `info errorstats` string building if the error is 0 and don't print it (`if(e->count)`) shouldn't we keep the rax to avoid uncessary destroy and construction? sample output validating the above: [code block],0,0,0,0.9894619584083556,0.9944748282432556,0.9946712851524352,0.0,accept,unanimous_agreement
547532859,8217,"yeah, you're right about the output. sorry, well, many places in redis just discard the rax or dict and create an empty one in similar situation, i suppose it avoids keeping a lot of elements that are relics past traffic (in this case errors might no longer be seen again). but i suppose there are not that may error types, so i guess we can go either way.",-1,-1,-1,0.7780516147613525,0.9500072002410888,0.7126264572143555,-1.0,accept,unanimous_agreement
547542445,8217,followed the suggestion and removed this changes ( it makes the pr a lot cleaner ),0,0,0,0.9678313136100768,0.9675469398498536,0.9852344393730164,0.0,accept,unanimous_agreement
547554598,8217,fixed in the last commit and squash,0,0,0,0.9869906306266784,0.9906152486801147,0.9943931102752686,0.0,accept,unanimous_agreement
547556109,8217,agree. fixed in the latest commit and squash. please see my latest comment,0,0,0,0.9485697150230408,0.8887070417404175,0.9768386483192444,0.0,accept,unanimous_agreement
547715559,8217,"as much as i hate wasting lines on braces, this seems to be the style in redis [code block]",-1,-1,-1,0.960909366607666,0.9031026363372804,0.8686005473136902,-1.0,accept,unanimous_agreement
547716932,8217,"we need to limit this search to `len`, but maybe also lower? like `min(len,32)`?",0,0,0,0.9868475794792176,0.9941868782043456,0.9923579096794128,0.0,accept,unanimous_agreement
547717910,8217,"i suppose we need to have an `else`, either an assertion, or falling back to add `err` type error. i think i would have been ok with an assertion, but then if i think of modules, maybe that's not wise.",0,0,0,0.9385684728622437,0.9685344696044922,0.9765962362289428,0.0,accept,unanimous_agreement
547718834,8217,"i think we never expect this to be null, let i rather drop the `if` and let it crash if we're wrong. [code block]",0,0,0,0.9566709995269777,0.9305120706558228,0.9825467467308044,0.0,accept,unanimous_agreement
547720275,8217,just noting that this section is not included by default. i guess that's good.,1,1,0,0.7031084895133972,0.7038511633872986,0.5900480151176453,1.0,accept,majority_agreement
547724747,8217,"let's replace that with `if (!c->count) continue;` so that we don't have the extra indentation. styling: both the `if` and `while` above are missing a space (please search the rest of your (new) code and fix these (maybe grepping the diff file). other personal taste styling: * i don't like a multi-line action in an `if` without braces. * i don't like statements that change execution flow (break, continue, return, goto) being in the same line together with the `if`. unless this is an error handling code that is heavily repeated, in which case i rather not waste too many lines on it, reducing the amount of the related code that fits in the screen.",-1,0,0,0.960479736328125,0.5833039879798889,0.9857378005981444,0.0,accept,majority_agreement
547726099,8217,these are not needed / used [code block],0,0,0,0.9878565073013306,0.9929511547088624,0.9938881993293762,0.0,accept,unanimous_agreement
547730533,8217,"let's add a test that checks `-nogroup` and `-wrongtype`, and an invalid command like `catch {r asdfasdf}`. both are different classes of errors than the ones you tested. i.e. one will have both `calls` and `failed_calls` showing `1`. and the other will show an error with nothing in the command table. this attempt will immediately expose two facts: 1. some commands fail with an error without being executed, and others fail inside the command. maybe we want to distinguish between `failed_calls` and `rejected_calls` in the command stats? (we can do that in `call()`) 2. the problem which was discussed before, which is that many commands use a plain `addreply` to reply with an error, and we can't log these today. the only way out that i can think of is to grep for `addreply(*,shared.*err);` and modify each of these to use a new `adderrorreply` or `addreplyerrobject`. and even that's not enough since i see some places do funny things like: [code block] if we do this, let's do that in a separate commit, so a reviewer (now or in the future) on your new code won't have to scan changes in all other files. (i.e. we won't squash-merge it)",0,0,0,0.9432798027992249,0.9764097929000854,0.9797973036766052,0.0,accept,unanimous_agreement
548026042,8217,fixed in the last commit. thank you for the explanation oran.,1,1,1,0.901175856590271,0.8663919568061829,0.7505398988723755,1.0,accept,unanimous_agreement
548026317,8217,"given this is so ""cheap"" to compute and potentially a very usefull info i've added it as default. wdyt?",0,0,0,0.8192686438560486,0.6537359952926636,0.9249739050865172,0.0,accept,unanimous_agreement
548026453,8217,agree. fixed in the last commit,0,0,0,0.9792044758796692,0.9921420812606812,0.984644651412964,0.0,accept,unanimous_agreement
548026679,8217,fixed in the last commit ( added description to ensure who's reading the code know the max error prefix length used is 32,0,0,0,0.9858657121658324,0.993720531463623,0.9928435683250428,0.0,accept,unanimous_agreement
548030302,8217,"with regards to the tests i've added the requested ones and now we have: the added tests are divided as follow: - **failed** call authentication error - **failed** call nogroup error - **rejected** call due to wrong arity - **rejected** call by oom error - **rejected** call by authorization error with regards to 1) accounting for rejected vs failure i've added a new flag to the command when we call `rejectcommand` or `rejectcommandformat`, meaning if we reject a command it wont increment the failed counter. with regards to 2) i believe has already kicked off that effort on [a link] so we should push 2) there correct? i believe all comments have been addressed. can you check if the added changes make sense? thank you both for reviewing this and pushing this feature forward.",0,0,0,0.9679123759269714,0.9892539978027344,0.9855212569236756,0.0,accept,unanimous_agreement
548054303,8217,"this is slightly weird user behavior, since reset doesn't actually reset the table back to what it looked like at the start. i would free the table and create a new one, and set the explicit expectation that if an element is missing, it's never been seen.",-1,-1,-1,0.971744418144226,0.9658113718032836,0.966289758682251,-1.0,accept,unanimous_agreement
548054998,8217,do we intend to extend this? otherwise it would be easier to just store the count in the rax.,0,0,0,0.9872722029685974,0.9929490089416504,0.9934414625167848,0.0,accept,unanimous_agreement
548055633,8217,where does cmd_err_rejected get reset?,0,0,0,0.9715785384178162,0.9904444813728333,0.9927176237106324,0.0,accept,unanimous_agreement
548085765,8217,you're totally right . i've fixed it and added a test to confirm it's working as expected,1,1,1,0.9337425827980042,0.7696917057037354,0.9774872660636902,1.0,accept,unanimous_agreement
548092339,8217,i thought of it as wrapper struct for future requirements.,0,0,0,0.985251784324646,0.9844834208488464,0.9832133054733276,0.0,accept,unanimous_agreement
548307148,8217,"i see the only section that's currently not part of the default is the commandstats, i don't suppose it's a matter of being cheap to generate (other parts are possibly more demanding), i think it's also about the verbosity and usefulness. i suppose that in practice we'll never see here more than some 4 errors, but i'm not sure i'd say it's more useful than the commands stats. let's leave this question open for later discussion.",0,0,0,0.9341802597045898,0.9356964826583862,0.9437541961669922,0.0,accept,unanimous_agreement
548314906,8217,"sorry, i'm not able to catch up on my notifications lately, so i wasn't aware of that other pr. i didn't review all your changes yet, but i do wee you addressed this comment. the only things in this comment that are not addressed are: * wrongtype, which you can't address yet, until the other pr is merged, but also that's the reason i suggested the nogroup error, since it's already in the state today that the wrongtype will be after the other pr is merged. so i guess we can skip that (or after the other pr is merged, replace the uncommon nogroup test with a simpler common wrongtype test) * the unknown (asdf) command (which will leave a trace in the error stats, and not in the command stats). i think we should add it.",-1,-1,-1,0.9829407334327698,0.9869658946990968,0.9702104926109314,-1.0,accept,unanimous_agreement
548320526,8217,"i think this function should only update the error stats, and not the command stats. in theory a single command can reply with an array of errors (more than one error per call). i think the right place to update the command stats, is at the end of `call()` and in `rejectcommand()`, both are nontenured to be executed only once per command execution. this means that the new `cmd_err_rejected` flag you added isn't needed. and instead you do need to be able to tell in `call()` that the command failed. the way to do that can be to try to match a global error counter (much like it looks at changes in `server.dirty`). this new global error counter can also be useful as a general metric (put next to `stat_unexpected_error_replies`) the only problem with this is nested command (lua, multi-exec, and modules). we can probably solve it by adding (yet another server struct global) which we reset to the last global error counter, every time we ""log"" the error into some command.",0,0,0,0.976549506187439,0.9909521341323853,0.966767430305481,0.0,accept,unanimous_agreement
548321118,8217,"okay, as long as that is intended, it's okay.",0,0,0,0.9593036770820618,0.8270103931427002,0.956041693687439,0.0,accept,unanimous_agreement
548324331,8217,with regards to the unknown command test just added it in the latest commit.,0,0,0,0.9874323606491088,0.9921271800994872,0.9951252341270448,0.0,accept,unanimous_agreement
548331177,8217,let's add it to the info stats section,0,0,0,0.9743230938911438,0.9827262163162231,0.9937514662742616,0.0,accept,unanimous_agreement
548331823,8217,i've followed the review suggestion and removed the added flag cmd_err_rejected and moved all command error log to processcommand+rejectcommand. oran i'm checking within processcommand and not call so that we can check the initial error count and then after call or queing the command we can see if any error reply occurred. given that rejectcommand/rejectcommandformat return prior than call this will simplifies stuff and allows to differentiate rejected from failed. what do you guys think of this approach?,0,0,0,0.9423442482948304,0.978174328804016,0.7781931757926941,0.0,accept,unanimous_agreement
548332156,8217,"this may need to be in `call()` not `processcommand()`. let's try to think this though together. when someone does: [code block] do we want the failure to be logged in lpush, exec, or both? i think we only want it in lpush, so i think we need to move this block to `call`, but also add another global variable that will ""consume"" this diff in some way, so that exec will not show that error. similar thing will happen for lua and modules doing rm_call.",0,0,0,0.984943389892578,0.9886351823806764,0.9908892512321472,0.0,accept,unanimous_agreement
548642839,8217,added in the last commit,0,0,0,0.9873855113983154,0.97890704870224,0.9951190948486328,0.0,accept,unanimous_agreement
548645611,8217,"i've added two tests for multi and lua to showcase that with the latest push we're properly setting the error on the right command and not having it shown on exec/eval,etc... tests: [a link] i'm basically checking if we're within a multi context or lua or module client and if so i'm restoring the error back to the original previous value given the failed counter it has already been updated on the real command as follow: [code block] what do you guys think?",0,0,0,0.9698071479797364,0.9692944884300232,0.8717325925827026,0.0,accept,unanimous_agreement
548665539,8217,"i had something else in mind. note that the way you implemented it, the errors inside the multi will not be shown in the global error counter. what i thought of doing is store another global variable (possibly a static inside the function), which recalls the last value of the global error counter which was used to increment the command error counter, so that one increment of the global error counter can't increment a command counter of more than once.. maybe it's even enough to make the stack variable you added in `call` a static one. then, we update it in the entrance to `call`, and check again it at exit (before we update it again). this way we never set back the global error counter, but we also never log the same error twice in nested commands.",0,0,0,0.9225467443466188,0.9723747372627258,0.9622312784194946,0.0,accept,unanimous_agreement
549044042,8217,i've followed you recommendation with regards to the static variable within `call` and added an extra test (rejected call within multi/exec). apart from that also checking the server stat total_error_replies value. can you check it?,0,0,0,0.9856525659561156,0.993237316608429,0.9938629865646362,0.0,accept,unanimous_agreement
549073099,8217,there's a method called `s` which does this: [code block],0,0,0,0.9876640439033508,0.9914599657058716,0.99534273147583,0.0,accept,unanimous_agreement
549073206,8217,i think we better add a comment somewhere explaining the use of the static variable. i.e. that it is used so that nested calls to `call` don't log the same error twice. here is probably a good place.,1,0,0,0.5015023946762085,0.9443559050559998,0.9722079634666444,0.0,accept,majority_agreement
549151150,8217,"thank you , addressed in the last commit",1,1,1,0.5399324893951416,0.8954498171806335,0.762093186378479,1.0,accept,unanimous_agreement
549152286,8217,added the details on why we're required the static variable. please revise,0,0,0,0.9872222542762756,0.9898515939712524,0.9948824644088744,0.0,accept,unanimous_agreement
549544207,8217,style: space between && and !c->rejected_calls,0,0,0,0.9792739152908324,0.9917815327644348,0.993627667427063,0.0,accept,unanimous_agreement
549544221,8217,"when can error ever be null? i don't see how it's possible, and it would be nice if we could remove it.",0,0,0,0.9772834181785583,0.9255985617637634,0.9842087626457214,0.0,accept,unanimous_agreement
549544438,8217,style: space around '>',0,0,0,0.9626411199569702,0.9909413456916808,0.9408265352249146,0.0,accept,unanimous_agreement
549544691,8217,style: * typically sticks with the variable name in redis.,0,0,0,0.9834625720977784,0.9914359450340272,0.9931799173355104,0.0,accept,unanimous_agreement
549546077,8217,"e->count is always at least 1 if it's present, so this check should be unnecessary.",0,0,0,0.9748193621635436,0.9887697696685792,0.9929647445678712,0.0,accept,unanimous_agreement
549781482,8217,renamed to `incrementerrorcount`,0,0,0,0.9859272241592408,0.9929375052452089,0.9940760135650636,0.0,accept,unanimous_agreement
549798340,8217,now fixed :),1,1,0,0.958651602268219,0.9892567992210388,0.9139775037765504,1.0,accept,majority_agreement
551302461,8217,"i have a question, why reset prev_err_count here.",0,0,0,0.9741992950439452,0.9690526127815248,0.791353166103363,0.0,accept,unanimous_agreement
551319931,8217,this is why this variable exists: [code block] maybe it would have been nicer to move that reset line to right next to the place it is used (incrementing `failed_calls`),0,0,0,0.9856034517288208,0.9941741824150084,0.993645429611206,0.0,accept,unanimous_agreement
780951809,10061,some formatting issues: 1. the use of `\` to break lines in the code leads to extra spaces in the output. 2. no point in specifying the executable path here (`./`) this is probably wrong anyway. 3. specify `yes` is a configuration value by quoting it. here's what i suggest (also for next change below): [code block],0,0,0,0.9365537762641908,0.9934521913528442,0.9676514267921448,0.0,accept,unanimous_agreement
780957950,10061,what if this is the last line and has no trailing `\n`? do we handle this?,0,0,0,0.985556185245514,0.9916933178901672,0.990739107131958,0.0,accept,unanimous_agreement
780958620,10061,do we support lines with leading spaces before the `#`? do we support lines with a `#` at their end?,0,0,0,0.9860535264015198,0.9942787885665894,0.99382084608078,0.0,accept,unanimous_agreement
780961330,10061,consider using `strtoll` instead of `atoll` to gain error checking.,0,0,0,0.9820333123207092,0.99199378490448,0.9885363578796388,0.0,accept,unanimous_agreement
780961977,10061,is a zero `ai->file_seq` not valid?,0,0,0,0.9680930972099304,0.9928170442581176,0.9952961802482604,0.0,accept,unanimous_agreement
780964511,10061,seems like in some cases we don't free `ai`. but in general i think we can assume `exit(1)` cleans up open files and allocations before terminating the process and avoid all these cleanups.,0,0,0,0.9829276204109192,0.9882984161376952,0.98384827375412,0.0,accept,unanimous_agreement
780965379,10061,can't we assume the sequence always grows by 1? [code block],0,0,0,0.9877821803092957,0.991293728351593,0.9940007328987122,0.0,accept,unanimous_agreement
780969010,10061,maybe add `strtol` error handling (via `endptr`)?,0,0,0,0.9883179068565368,0.99468731880188,0.991248369216919,0.0,accept,unanimous_agreement
780974635,10061,"no need for all these `fclose()` cleanups since we're `exit()`ing right after. i'm not strictly against this, but then i suggest we'll be consistent and clean up all allocations too.",0,0,0,0.9813582301139832,0.9666256904602052,0.9809162020683287,0.0,accept,unanimous_agreement
780982944,10061,"why `""r+""`? don't we just want to read the file: `""r""`.",0,0,0,0.9798963069915771,0.984631359577179,0.990403413772583,0.0,accept,unanimous_agreement
780985470,10061,error checking for `strtol`.,0,0,0,0.943310022354126,0.989390194416046,0.953015923500061,0.0,accept,unanimous_agreement
781010119,10061,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
781014274,10061,"each line of the manifest is generated by `redis`, and `redis` guarantees that each line ends with `\n`, so i think that no matter which line (including the last line) does not end with `\n` is a format error.",0,0,0,0.9863133430480956,0.9900630116462708,0.9853244423866272,0.0,accept,unanimous_agreement
781015260,10061,we only support like this: [code block],0,0,0,0.9830607771873474,0.98708575963974,0.9935169219970704,0.0,accept,unanimous_agreement
781018847,10061,i'm not totally convinced. users may create/edit the manifest files manually and miss the last line feed. wdyt?,0,-1,0,0.7270789742469788,0.8860421776771545,0.744896411895752,0.0,accept,majority_agreement
781019188,10061,"yes, `file_seq` start with 1",0,0,0,0.9865113496780396,0.9909389019012452,0.9945186972618104,0.0,accept,unanimous_agreement
781020614,10061,"first, in the context of manifest files (not aof files) these are more ""comments"" and not ""annotations"", right? also i guess for now this is ok, perhaps we'd like to improve this in the future, but i guess as long an we'll be backwards compatible it'll be ok. again, wdyt?",0,0,0,0.9763330817222596,0.9089674353599548,0.9363782405853271,0.0,accept,unanimous_agreement
781023848,10061,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
781025216,10061,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
781029377,10061,"yes, i think we need to leave room for manifest to expand, i think allowing `# `to appear is a method similar to using annotation in aof. btw it would be fine if we used it as a comment, like explaining the meaning of the file below, although we don't currently do that.",0,0,0,0.9815669059753418,0.9898567199707032,0.9886820316314696,0.0,accept,unanimous_agreement
781030460,10061,"this log is currently consistent with that in `aof.c`. i think that if we want to change it, we also need to modify` aof.c`. are you sure we need to do this?",0,0,0,0.9875364899635316,0.993490993976593,0.9932172894477844,0.0,accept,unanimous_agreement
781039856,10061,"i think this worry is superfluous. if we can't guarantee and establish an inherent file format, then i think a lot of our code needs to deal with this kind of case heavily, such as the user deletes the `\n` in a line in the middle. i think our current code is able to detect and handle this error.",-1,0,0,0.776489794254303,0.5614768862724304,0.9385892748832704,0.0,accept,majority_agreement
781183313,10061,"i see what you mean, we do need to do this technically. however, what i want to say is that aof, including manifest, is generated by `redis` (such as the timestamp here), and we don't want anyone to change these contents, otherwise he should be responsible for this behavior. i tried looking for `strtol` usage in existing `redis` code and i found almost no error checking anywhere, i don't know if this is intentional or not. anyway, i added error checking here.",0,0,0,0.9538180232048036,0.9379938840866088,0.975814402103424,0.0,accept,unanimous_agreement
781187996,10061,"agree, but what i say is that i wanna say this code has been around for a long time.",0,0,0,0.97749000787735,0.502478837966919,0.9582145810127258,0.0,accept,unanimous_agreement
781189413,10061,i add `zfree(ai)` here to suppression sanitizer false positive. (tested in aof.c),0,0,0,0.9893506169319152,0.9935312867164612,0.9947761297225952,0.0,accept,unanimous_agreement
781190162,10061,all these logs are new to the multi-part-aof feature. it's just that the english isn't correct and sounds a bit weird. i'm for fixing it in all places. ?,-1,-1,-1,0.9767738580703736,0.9800731539726256,0.8430689573287964,-1.0,accept,unanimous_agreement
781191833,10061,removed fclose(fp);,0,0,0,0.9705538153648376,0.983032763004303,0.9954060316085817,0.0,accept,unanimous_agreement
781192506,10061,in _config.c_ we do such error checking. in other places we use `string2ll()` which has its own error checking. i suggest you look in _config.c_.,0,0,0,0.9852782487869264,0.9938805103302002,0.992932677268982,0.0,accept,unanimous_agreement
781198435,10061,"ok, thanks.",1,1,0,0.5829715132713318,0.7235771417617798,0.6576256155967712,1.0,accept,majority_agreement
781224160,10061,"in theory you are right, but i don't want to add such a strong limit here, because we just load the corresponding files in order according to the instructions of the manifest, and the increasing order is guaranteed to ensure that we can get a maximum value. too restrictive means less scalability later.",0,0,0,0.9575145840644836,0.9694101214408876,0.9743608832359314,0.0,accept,unanimous_agreement
781663263,10061,modified.,0,0,0,0.979846715927124,0.977075219154358,0.9878163933753968,0.0,accept,unanimous_agreement
781801479,10061,what about checking endptr?,0,0,0,0.98660546541214,0.984033703804016,0.99367094039917,0.0,accept,unanimous_agreement
781812895,10061,"since the buf here is not a c string terminated with `'\0'`, i am not sure if we are going to use `*endptr != '\r' `to judge.",0,0,0,0.9095725417137146,0.9473523497581482,0.9581006169319152,0.0,accept,unanimous_agreement
781814594,10061,added,0,0,0,0.973513960838318,0.9267084002494812,0.8435775637626648,0.0,accept,unanimous_agreement
789100806,10061,"why do we need the 30 constant? we're matching the string `file`, let's just make sure that we can read as much.. maybe better add a space, i.e. make sure the file has at least 5 chars, read them and make sure they match `file `",0,0,0,0.9826152324676514,0.9895752668380736,0.9886705875396729,0.0,accept,unanimous_agreement
789102415,10061,just want to ask and make sure this was tested? i.e. single file with rdb header and aof tail.,0,0,0,0.9884580969810486,0.9932117462158204,0.9944827556610109,0.0,accept,unanimous_agreement
789104583,10061,"there could be a case of a multi-part (manifest) aof, in which the base file is an old (after upgrade) file, with rdb header and aof tail. looks like you're not handling the aof tail here. please also make sure to test it.",0,0,0,0.9852941036224364,0.9923896193504332,0.99366956949234,0.0,accept,unanimous_agreement
789111562,10061,"let's denote that `multi` is an out variable. either name `out_multi`, or add some top comment about the args and return value. p.s. overall this file is / was in a bad shape, please add some comments on function and big code blocks explaining what they do",-1,0,-1,0.788181722164154,0.9567552208900452,0.6542850136756897,-1.0,accept,majority_agreement
789112326,10061,"btw, why did you have to refactor this function (and deal with the complexity of an output var for the `multi`? isn't it easier to leave it as it was?",0,0,0,0.9761735796928406,0.9906170964241028,0.9811416268348694,0.0,accept,unanimous_agreement
789114397,10061,please add a top comment explaining what it does. what the return value means and in which cases it exists rather than return. please do a similar thing to other functions,0,0,0,0.9867604970932008,0.9758244752883912,0.9933949112892152,0.0,accept,unanimous_agreement
789117156,10061,why did you have to copy all that parsing logic here? let's find a way to re-use the one in aof.c it would be wrong for us to have two copies of this code. e.g. a bug is fixed in one and left in the other. we do already have such cases with redis-check-rdb and redis-check-aof.. let's at least avoid adding more of them.,0,0,0,0.9592085480690002,0.979152500629425,0.938974678516388,0.0,accept,unanimous_agreement
789119546,10061,"unrelated to this line. let's be sure to extend the tests to test all the aof variations that we could be facing. i.e. just test the happy path of: 1. single preamble aof with rdb head and aof resp tail 2. single old style resp aof (no rdb header) 3. manifest file with resp aof base 4. manifest file with rdb aof base 5. manifest file after upgrade, with base that's an rdb with aof tail",0,0,0,0.7613847255706787,0.9908181428909302,0.9629762172698976,0.0,accept,unanimous_agreement
789123050,10061,"not sure i care much, and in any way i commented that i wanna see that entire function gone from here. generally i'd agree with yoav, if the file is a plain text file, we better assume people may edit it and correctly handle these edits (even if they are bad ones). iirc yossi thought so too, when we changed the parsing logic to be a loop that can handle the `file`, `seq`, etc argument at any order, and not just at the order in which we emit them.",0,0,-1,0.5275885462760925,0.7993524670600891,0.5572788119316101,0.0,accept,majority_agreement
807567642,10061,"ok,maybe i'm being too cautious",-1,-1,0,0.9330446720123292,0.8265720009803772,0.7411100268363953,-1.0,accept,majority_agreement
807581180,10061,"yes, tested. [code block]",0,0,0,0.9874180555343628,0.964383065700531,0.9835912585258484,0.0,accept,unanimous_agreement
807585788,10061,"yes, you are right.",0,0,0,0.9410759806632996,0.7251467108726501,0.9548653960227966,0.0,accept,unanimous_agreement
807595099,10061,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
807601602,10061,"ok,i will add this tests.",0,0,0,0.98428475856781,0.9695224761962892,0.9930403232574464,0.0,accept,unanimous_agreement
807606828,10061,"indeed, i am also struggling with this issue. in `aof.c`, the `aofloadmanifestfromdisk` function has no parameters, and it will automatically construct the real path of the manifest according to `server.aof_dirname `and `server.aof_filename`. then, in `redis-check-aof`, we will directly specify the path of the manifest file, which prevents me from directly reusing the `aofloadmanifestfromdisk` code. two options: 1.parse the incoming manifest path, and set the path part and the file name part to `server.aof_dirname` and `server.aof_filename`, which may be a pity, but i think it's a bit complicated. 2.refactor the `loadmanifestfromfile` function in `aof.c` , split it into two functions `aofloadmanifest(void)` and `aofloadmanifestfromfile(char *filename)`, `aofloadmanifest` internally constructs the path based on `server.aof_dirname` and `server.aof_filename` and passes it to `aofloadmanifestfromfile`, so that the `aofloadmanifestfromfile` function can also be directly reused in `aof-check-aof.c`. i prefer 2, wdyt?",-1,0,-1,0.926705837249756,0.9068209528923036,0.7288733720779419,-1.0,accept,majority_agreement
807608012,10061,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
807650148,10061,already updated pr as per 2,0,0,0,0.9809920191764832,0.9895055890083312,0.992026150226593,0.0,accept,unanimous_agreement
807658838,10061,"i think the previous implementation is unreasonable. what i can remember is that in the original code, the `readannotations` function will use the while loop to read the annotations continuously until it finds that the following is not an annotation, and then uses `fseek` to go back to the previous position. a more reasonable approach is that the outer caller is responsible for judging the type of the aof line and calling the corresponding processing function according to the type. if the line starts with `*`, use `processresp`, if it starts with `#`, call `readannotations`. maybe in the future we will have other annotation types so it will be very easy for us to add a `readxxxannotations`. there are other reasons, i can't remember exactly, probably some kind of hurdle in supporting the truncation of multi part aof files.",0,0,0,0.8666093945503235,0.9144399762153624,0.8926140069961548,0.0,accept,unanimous_agreement
808205946,10061,i'd rather these have a uniform prefix [code block],0,0,0,0.9733537435531616,0.9914056062698364,0.9830977320671082,0.0,accept,unanimous_agreement
808207896,10061,the part about multi causing increment is repeated twice.,0,0,0,0.9825974106788636,0.8649889826774597,0.9889545440673828,0.0,accept,unanimous_agreement
808581870,10061,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
808582276,10061,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
786280331,10127,i think a better api would be: [code block],0,0,0,0.9705041646957396,0.9833672046661376,0.983481228351593,0.0,accept,unanimous_agreement
786280524,10127,this is unused,0,0,0,0.9750969409942628,0.9184365272521972,0.9928995370864868,0.0,accept,unanimous_agreement
786280885,10127,"i think we should have a function that just returns `sdscatfmt(sdsempty(), ""%s|%s"", parent_name, sub_name)`",0,0,0,0.9875763654708862,0.9891196489334106,0.9866302013397216,0.0,accept,unanimous_agreement
786281158,10127,"we can create the fullname and then give it to this function, instead of freeing the non-fullname later",0,0,0,0.9885472059249878,0.9902613759040833,0.9919314980506896,0.0,accept,unanimous_agreement
786391095,10127,"all done, the second commit: - change function `modulecreatecommandproxy` take `sds fullname` - add `catsubcommandfullname` function do the `sdscatfmt(sdsempty(), ""%s|%s"", parent_name, sub_name)` thing - some typos, `setimplictaclcategories` -> `setimplicitaclcategories`, `stracture` -> `structure` - add `lookupsubcommandbyfullname` / `lookupsubcommand` functions - remove `getfullcommandname` dead function and `populatesinglecommand` dead code",0,0,0,0.9798247814178468,0.9927175045013428,0.99294114112854,0.0,accept,unanimous_agreement
786623299,10127,maybe add a comment that this function takes ownership on `fullname`,0,0,0,0.9883556365966796,0.9925132393836976,0.9933526515960692,0.0,accept,unanimous_agreement
786627896,10127,"we have an odd situation where non-subcommand have `const char *` and subcommand have `sds` i suggest changing `fullname` to be `sds` (and call `sdsnew` in `populatecommandstructure`) this will also help in removing some of the implicit casting done (mostly in module.c) also, we can change some `sdsnew` to `sdsdup`",0,0,0,0.9816939234733582,0.9918245673179626,0.9929805994033812,0.0,accept,unanimous_agreement
787406040,10127,why not use `addreplybulkcbuffer`?,0,0,0,0.982132077217102,0.9928526282310486,0.9914929270744324,0.0,accept,unanimous_agreement
787409430,10127,"ohh.. right i forget this one, yes i can use it",0,0,0,0.4266349077224731,0.9281732439994812,0.923949420452118,0.0,accept,unanimous_agreement
787765011,10127,why not addreplybulksdsnofree?,0,0,0,0.9766826629638672,0.9920766353607178,0.994102656841278,0.0,accept,unanimous_agreement
787765605,10127,"generally speaking, i think i prefer if all places that iterate commands would use a recursive function instead of copying the logic... wdyt?",0,0,0,0.9786515831947328,0.7460362315177917,0.9618449807167052,0.0,accept,unanimous_agreement
787765874,10127,also here,0,0,0,0.984005570411682,0.983235239982605,0.9536449313163756,0.0,accept,unanimous_agreement
787776154,10127,"i think that if i'ts just a matter of calling one or two functions or some simple `if`, then there's no problem copying it. if there's a lot of logic, then we should avoid repeating it, and instead add a function to do that, or use a recursion. bottom line, each case for itself imho.",0,0,0,0.9779560565948486,0.965398907661438,0.9395988583564758,0.0,accept,unanimous_agreement
787784837,10127,"not sure it's worth making a copy of the same code for nofree sds, addreplybulkcbuffer has been used extensively elsewhere in the code to avoid sds being freed.",0,0,0,0.9690192937850952,0.9737412929534912,0.8192979097366333,0.0,accept,unanimous_agreement
787859197,10127,"1. maybe rename to `modulefreecommand` 2. i think a nicer api would it look something like: [code block] and the caller, which iterates` server.commands` will be in charge of deleting all the non-subcommand from `server.command` and orig_commands",0,0,0,0.9245401620864868,0.9920475482940674,0.9887977242469788,0.0,accept,unanimous_agreement
787867340,10127,i think we should have a `const char *declared_name` in the declarative part of `struct rediscommand` which comes from the structs in command.c and `sds fullname` in the run-time filled part it's a bit dangerous that there's some amount of time when `fullname` is actually a `const char*`,0,-1,0,0.794218897819519,0.6990320086479187,0.5263195037841797,0.0,accept,majority_agreement
787871136,10127,"in order to save the redundant `sdsnew` and `sdsfree` maybe we should initialize the fullname outside of `populatecommandstructure`..? not sure about this, leaving it for you to decide",0,0,0,0.9618500471115112,0.9570431113243104,0.9710615277290344,0.0,accept,unanimous_agreement
787872470,10127,`fullname` here should be an `sds`,0,0,0,0.987190842628479,0.9935629367828368,0.9952408075332642,0.0,accept,unanimous_agreement
787873240,10127,good catch,1,1,1,0.9703027606010436,0.981269359588623,0.9915775060653688,1.0,accept,unanimous_agreement
788071171,10127,"ohh, now i see what you mean, it's not about extracting the code that handles one command, but rather extracting the loop that runs on a dict, and thus the dict iteration code can be shared. well, i agree it'll make the code a bit cleaner (and mess up the blame log a bit). i guess it's worthwhile.",0,1,1,0.7648066878318787,0.6347761154174805,0.5832096934318542,1.0,accept,majority_agreement
788080819,10127,"i think it should be nice that we have a `declared_name`, so if we need just the sub-command name, we can get it without starting to split strings.",0,0,0,0.9355564713478088,0.9596136808395386,0.9511857628822328,0.0,accept,unanimous_agreement
788086208,10127,"we now have some inherent waste here (both in memory, and speed). i.e. we're hashing and matching the parent command name twice, once for the outer dict and once for the inner one. maybe we rather go back on that?",0,0,0,0.9204469323158264,0.8141548037528992,0.9611414670944214,0.0,accept,unanimous_agreement
788088966,10127,i'd rather just match a few of these than the entire list. don't wanna update it every time a new command is added to the category.,0,0,0,0.9517644047737122,0.8416868448257446,0.8073297142982483,0.0,accept,unanimous_agreement
788092009,10127,"not that it matters a lot, but it'll maybe be stronger to make sure we don't match zacl|helper. i see in some cases we wrap the command name with `'`' and in others we don't (so ` `), so if we wanna do that, we need to either make them uniform, or match each error to the right form. [code block]",0,0,0,0.974376618862152,0.984082579612732,0.9675887227058412,0.0,accept,unanimous_agreement
788092646,10127,"again, let's match a few. i don't wanna update the test every time a new one is added.",0,0,0,0.9744728207588196,0.8120919466018677,0.9800223112106324,0.0,accept,unanimous_agreement
788093836,10127,this one could also easily break when we add some new command that start with `cl` and has a help,0,0,0,0.9819419384002686,0.9941891431808472,0.9886954426765442,0.0,accept,unanimous_agreement
788096275,10127,i don't recall the details here. did you figure it out?,0,0,0,0.8992781639099121,0.8223787546157837,0.950145959854126,0.0,accept,unanimous_agreement
788096889,10127,very good you did that. did valgrind pass?,1,1,1,0.9544143080711364,0.9621830582618712,0.9904078841209412,1.0,accept,unanimous_agreement
788541745,10127,"yes, so wanted to go back? that is, the **key** is the subcommand **declared_name** i think now we can go back it with the new `declared_name` field and `fullname` field`. please ack [code block]",0,0,0,0.9826624393463136,0.9649568200111388,0.9902549386024476,0.0,accept,unanimous_agreement
788550873,10127,"i'm continuing the guy's style... in other thought, when a new command add, we can know that this part will fail, and can fix it, then prove that the test is working... [code block] yes, i can change them both to do the partial matches",0,0,0,0.9161556363105774,0.8751013875007629,0.9694975018501282,0.0,accept,unanimous_agreement
788552190,10127,"yes, it passed. i also wanted to do that in every module test. wdyt?",0,0,0,0.9775697588920592,0.8448277115821838,0.8678719997406006,0.0,accept,unanimous_agreement
788570343,10127,"it's less likely that new commands starting with `pf` will be added, so i'm fine with that one.",0,0,0,0.9775260090827942,0.9658113121986388,0.9727545380592346,0.0,accept,unanimous_agreement
788571325,10127,"i guess it can't harm, if you have the energy..",0,0,0,0.9341914057731628,0.5242990851402283,0.9367841482162476,0.0,accept,unanimous_agreement
788572974,10127,"i want to unify them, which one would you prefer, with or without `'` forgive it. i see many places may need to be changed, i choose `right form` way.",0,0,0,0.8088506460189819,0.975527048110962,0.957123041152954,0.0,accept,unanimous_agreement
788577612,10127,i guess all these places are already modified once we changed `name` to `fullname`... i guess the one with `'` is preferred,0,0,0,0.987076699733734,0.9831008911132812,0.986987829208374,0.0,accept,unanimous_agreement
788768056,10127,"ack (let's have decalred_name which comes from commands.c. it will not be used, except to build `fullname`)",0,0,0,0.9784002304077148,0.9899712800979614,0.9928478002548218,0.0,accept,unanimous_agreement
788923213,10127,"it sometimes fails on my machine, sometimes it doesn't i haven't had time to take a look yet, can remove it later",0,0,0,0.9109147787094116,0.7965633869171143,0.955817699432373,0.0,accept,unanimous_agreement
788925250,10127,"i tried it, it seems like a lot of leak in sanitizer.... i can check it out tomorrow (no rush)",0,0,0,0.5289667248725891,0.7898118495941162,0.8806653022766113,0.0,accept,unanimous_agreement
788938882,10127,debug print,0,0,0,0.9889692068099976,0.9562515020370485,0.9887174367904664,0.0,accept,unanimous_agreement
788945164,10127,i think that module commands should have declared_name = null. modulecreatecommandproxy should take only `fullname`,0,0,0,0.989737331867218,0.9915940761566162,0.988541066646576,0.0,accept,unanimous_agreement
788946275,10127,"the subcommand dict should have the fullanme as keys, not the sub_name (there's used to be `looksubcommandbyfullanme` - where is it?)",0,0,0,0.98934143781662,0.9951985478401184,0.9943997263908386,0.0,accept,unanimous_agreement
788947451,10127,"lookupsubcommand can take a `const char *` (because it calls dictsdskeycasecompare which uses `strcasecmp`. is that on purpose or something we want to fix. on the one hand, it means we can lookup using a `char*` ut on the other hand the compare functions calculate the length at o(n)) so no need to create `sds sub_name`",0,0,0,0.9877911806106568,0.9943880438804626,0.991142988204956,0.0,accept,unanimous_agreement
788950175,10127,"for example, here you use the fullname... lets' assert that dictdelete returns dict_ok also in `moduleunregistercommands`",0,0,0,0.9881902933120728,0.994127869606018,0.995622456073761,0.0,accept,unanimous_agreement
788952115,10127,"generally speaking, and maybe i'm wrong, but i think `declared_name` should be used only in `populatecommandtable` and `populatecommandtable`",0,0,0,0.9369683265686036,0.9447464942932128,0.9738754630088806,0.0,accept,unanimous_agreement
788955387,10127,also this function can be a one-liner: [code block] but maybe it shouldn't even be a function? when we bring back `looksubcommandbyfullanme` the only place we need to search by sub_name is in `lookupcommandlogic` and then we don't even need a function...,0,0,0,0.9809277653694152,0.9933807849884032,0.9882567524909972,0.0,accept,unanimous_agreement
788958717,10127,maybe it's time to have [code block],0,0,0,0.9632988572120668,0.993626356124878,0.9799240827560424,0.0,accept,unanimous_agreement
788972907,10127,why? in the past we testes that command list returned exactly those 3 commands,0,0,0,0.9868441820144652,0.9657526016235352,0.9877525568008424,0.0,accept,unanimous_agreement
789553041,10127,"i thought in here, we agree to use the `declared_name` as the subcommand dict key? [a link]",0,0,0,0.9860857725143432,0.9927518367767334,0.9949435591697692,0.0,accept,unanimous_agreement
789719764,10127,this function should take `const char *sub_name` and not rely on `subcommand->declared_name`,0,0,0,0.9874984622001648,0.9948373436927797,0.9951550960540771,0.0,accept,unanimous_agreement
789720938,10127,please go over all references to subcommands_dict and see that we always use sub_name,0,0,0,0.9872481226921082,0.9913429021835328,0.9934865236282348,0.0,accept,unanimous_agreement
789721726,10127,"yes, i'm sorry, i misunderstood. i've deleted/updated some of my comments",-1,-1,-1,0.9876794815063475,0.9907853603363036,0.9835900664329528,-1.0,accept,unanimous_agreement
789802355,10127,the hash function `dictsdscasehash` use the `sdslen`. maybe we still need the `sds sub_name`? [code block],0,0,0,0.9884327054023744,0.9954923391342164,0.994955837726593,0.0,accept,unanimous_agreement
789811813,10127,"what do you think if we have `declared_name` that store the `sds sub_command` in module command. which mean `modulecreatecommandproxy` will take another `sds sub_name` then in `dictdelete(cmd->subcommands_dict, sub_name);`, we can use it. otherwise we need to split the fullname",0,0,0,0.9848365187644958,0.9947903156280518,0.991418957710266,0.0,accept,unanimous_agreement
789813611,10127,"yes, you're right so you can ignore this comment",0,0,0,0.9556504487991332,0.8530962467193604,0.9795005321502686,0.0,accept,unanimous_agreement
789819654,10127,good idea! so: 1.`sds fullanme` is always and sds and it contains the fullname 2. `const char *declared_name` is a `const char *` for native commands and `sds` for module commands. it contains the sub_name (which is just the full name for non-subcommands) and the signature is: [code block] right?,1,1,1,0.9885450005531312,0.9837117791175842,0.9941653609275818,1.0,accept,unanimous_agreement
789822560,10127,yes. i have a local version that is written like this,0,0,0,0.9781478643417358,0.9592634439468384,0.9863173365592957,0.0,accept,unanimous_agreement
789856323,10127,reverted it...,0,0,0,0.7444391250610352,0.9085034132003784,0.9906534552574158,0.0,accept,unanimous_agreement
789859807,10127,"please check my last five commit.. hope there will be no other problems this time :) btw, thanks for your patience and the all explanation and the reviews",1,1,1,0.993175208568573,0.9956135749816896,0.9968095421791076,1.0,accept,unanimous_agreement
789860626,10127,i handle it in [a link] and [a link],0,0,0,0.9881338477134703,0.9865233302116394,0.9954370856285096,0.0,accept,unanimous_agreement
790136831,10127,"seeing 55 changed files in this pr makes me think maybe we went too far (specifically with uniform error message campaign, which isn't a real issue, so it may be an unnecessary blame log destruction). in any case, first, let's revert this unnecessary newline change.",0,0,0,0.8216729760169983,0.9140357375144958,0.7394697666168213,0.0,accept,unanimous_agreement
790138141,10127,i see we sometimes iterate on the subcommands_dict and other times we iterate on `subcommand` until we see a null `fullname`. i suppose the later is wrong (will probably be incompatible with modules).,0,0,0,0.965861678123474,0.9757305383682252,0.9834896326065063,0.0,accept,unanimous_agreement
790138590,10127,"fyi, there's no need for a markdown compatible doc comment in this one since it's not an api, so not exported to the docs..",0,0,0,0.9651231169700624,0.7898806929588318,0.9935085773468018,0.0,accept,unanimous_agreement
790139281,10127,"it's not only the top/bottom and file that changed, it's also no loner hard coded. how about: [code block]",0,0,0,0.9837434887886048,0.9867346286773682,0.994204580783844,0.0,accept,unanimous_agreement
790140421,10127,why did you add that? isn't it implicit? same comment about few lines below..,0,0,0,0.9191876649856568,0.9884876608848572,0.993273377418518,0.0,accept,unanimous_agreement
790140574,10127,"rather than string matching, i rather convert it to a list, and look up an element.",0,0,0,0.9844675660133362,0.9870902895927428,0.9935168027877808,0.0,accept,unanimous_agreement
790140755,10127,"same here. let's convert to a list, and then look into it. also, let's add one negative check to make sure it doesn't actually return all commands.",0,0,0,0.98697692155838,0.9831312894821168,0.9932996034622192,0.0,accept,unanimous_agreement
790140809,10127,"why do we need this test? isn't the test below sufficient? i.e. we're testing the infrastructure, not all possible commands and categories.",0,0,0,0.9732204079627992,0.9896711707115172,0.98241925239563,0.0,accept,unanimous_agreement
790141100,10127,let's add one negative check (for a command that should not be here),0,0,0,0.9813849925994872,0.9849753975868224,0.9859609603881836,0.0,accept,unanimous_agreement
790141131,10127,let's add one negative check,0,0,0,0.9776586294174194,0.9815186262130736,0.9559859037399292,0.0,accept,unanimous_agreement
790141242,10127,"if we would have emitted only the second one, the first one would still be hit. let's convert this to a list and do a lookup into it.",0,0,0,0.9859477281570436,0.9885032773017884,0.9911649823188782,0.0,accept,unanimous_agreement
790141530,10127,"same comments as elsewhere, let's use a list and a negative check",0,0,0,0.9832583665847778,0.985457479953766,0.991303563117981,0.0,accept,unanimous_agreement
790162683,10127,"yes... i watch it get bigger day by day, mix too much cleanup.. reverted it",-1,-1,0,0.5562317967414856,0.9303086400032043,0.5998255610466003,-1.0,accept,majority_agreement
790162875,10127,"yes, i noticed it too, but didn't think much about it, it's been updated.",0,0,0,0.9600300192832948,0.9410380721092224,0.979236364364624,0.0,accept,unanimous_agreement
790162995,10127,i thought module documentation needed to be written like this... already simplified it..,0,0,0,0.9202510118484496,0.9771341681480408,0.9858734607696532,0.0,accept,unanimous_agreement
790163064,10127,took it!,1,1,1,0.7922898530960083,0.7729146480560303,0.8505181074142456,1.0,accept,unanimous_agreement
790163301,10127,"i reverted it.. yes, it is implicit (embarrassing cleanup)",-1,0,-1,0.9833129048347472,0.8075950741767883,0.9925064444541932,-1.0,accept,majority_agreement
790163337,10127,using lsearch,0,0,0,0.9877392649650574,0.9791470170021056,0.993273377418518,0.0,accept,unanimous_agreement
790166220,10127,there's a file in `src/modules/gendoc.rb` that generates [a link] it takes the comments above rm_xxxx functions,0,0,0,0.988343060016632,0.9940398931503296,0.995550274848938,0.0,accept,unanimous_agreement
790170141,10127,"why do we need the `split`? it returns an array, which tcl converts to a list. i see that in other tests below you didn't use it... why here?",0,0,0,0.9677822589874268,0.9352606534957886,0.9883410334587096,0.0,accept,unanimous_agreement
790217797,10127,"weird, last night, before the `split` or the `trim`, the `lsearch` can not lookup the element. so i thought it is some kind of tcl things...(like that one i want to store the result in a var) now it is ok. i must be not very awake before going to bed and do something wrong.",-1,-1,-1,0.9746277332305908,0.9332504868507384,0.9616756439208984,-1.0,accept,unanimous_agreement
686960409,9356,"it would be nice if created a little bit more structure for this data: [code block] then when referencing it, `(((dictentry **)dictmetadata(de))[0])` becomes `((clusterentrymetadata *) dictmetadata(de))->prev`",0,0,0,0.9265970587730408,0.9858733415603638,0.9832148551940918,0.0,accept,unanimous_agreement
686972382,9356,all of these function names are now a bit wrong since you are passing in a dictentry and not a key (which is kind of key). i wonder if maybe we should make an alias like `keyhandle` that we can use instead of dictentry to improve clarity?,0,0,0,0.6937459111213684,0.861355721950531,0.9387006163597108,0.0,accept,unanimous_agreement
686978289,9356,"lazyfreefreeslotsmap(it's up at the top of this file) is dead code now, so please clean it up",0,0,0,0.9616615176200868,0.9439157843589784,0.7979279160499573,0.0,accept,unanimous_agreement
686993166,9356,"the original declaration was `char metadata[]` which signifies an arbitrary number of bytes. the new declaration is essentially the same, except that it indicates an arbitrary number of pointers. for this feature, you are using pointers, but in the general case, this metadata is arbitrary, and not necessarily pointers. pointers on a 64-bit machine are 8 bytes each, yet the metadata size is specified in bytes. (however, we know that the heap allocator will round up the allocation to a multiple of 8 bytes.) i think that maybe you were getting compiler errors which would be better resolved by changing the macro for accessing the metadata. like this: [code block] i think this is a better solution as `char metadata[]` better describes something that is counted in bytes. yet `dictmetadata` should be returning a pointer to some unknown data (not `char*`).",0,0,0,0.9752758741378784,0.9864454865455629,0.983733892440796,0.0,accept,unanimous_agreement
687005461,9356,"this should be refactored into 2 separate functions. indications: * almost the entire code is different, based on a boolean flag. * in every place where this is called, the boolean flag is hard-coded.",0,0,0,0.9774388670921326,0.990845024585724,0.984352171421051,0.0,accept,unanimous_agreement
687006434,9356,"makes sense, they do have less in common then they used to.",0,0,0,0.96095472574234,0.9862697720527648,0.9550905227661132,0.0,accept,unanimous_agreement
687007680,9356,"also, given that this is called from 1-line routines which are already separate, we already have the routines to refactor into. this function should be removed, and code simply added to `slottokeyadd` and `slottokeydel`.",0,0,0,0.9883986115455629,0.9951401948928832,0.9934144020080566,0.0,accept,unanimous_agreement
687015526,9356,"yes, and i'd prefer to keep the char array, and the new version is what you had in the original dictmetadata macro. the only reason i changed from `char metadata[]` to `void *metadata[]` is that i got a warning/error ""dereferencing type-punned pointer will break strict-aliasing rules"" on build-ubuntu-old (and another build, which i think is using some old gcc version) when casting the `char metadata[]` as `(dictentry**)(void*)entry->metadata`. i get the same warning with and without the middle `void*` cast, so changing the macro from old to new doesn't make any difference here. the gcc version seems to dislike casting char array to void pointer, but it seems any pointer can be cast to char array without problems (as we do when we call memset on the metadata after allocation). if you have another solution to this, i'm happy to change back to char array. note: even if it's now a `void* metadata[]`, it's still possible to use it as an arbitrary number of bytes and cast it to `char*` when using it (even though it seems wrong).",0,0,0,0.9788354635238647,0.9689314365386964,0.9880489706993104,0.0,accept,unanimous_agreement
687016379,9356,"will do. it's only called in slottokeyadd and slottokeydel, so i'll put the implementation in each of these. edit: there's some lag before i see your messages, apparently. :-)",1,1,1,0.9421172142028807,0.9925716519355774,0.987789511680603,1.0,accept,unanimous_agreement
687020310,9356,good point. aliasing the dictentry as keyhandle (typedef?) can be confusing though. maybe we can rename the function to slottoentryadd?,1,1,1,0.5613401532173157,0.5992405414581299,0.8072302937507629,1.0,accept,unanimous_agreement
687022000,9356,will do.,0,0,0,0.9548023343086244,0.9864637851715088,0.9465230703353882,0.0,accept,unanimous_agreement
687506493,9356,i have `char metadata[]` in another branch (one commit added: [a link] so you can see what fails in this build: [a link],0,0,0,0.9853176474571228,0.9893847107887268,0.9949625730514526,0.0,accept,unanimous_agreement
687946228,9356,"i think the compiler is warning that `char[]` is not inherently aligned (it's aligned to a multiple of 1). when we cast to a pointer (even when trying to misdirect the compiler with `void*`) it knows that the `char[]` is not 8-byte aligned. in our case, we know that it's aligned because the data is placed immediately after another pointer. so the code should work safely, though the compiler warning is certainly annoying. i've seen some suggestions to create a union. the union would server to force alignment with the unioned type. but i agree that this looks messy. the cleanest option might be the one you proposed `void *metadata[]`. by making it an array of pointers, the compiler knows that the array is aligned. if this is the case, i think it deserves a comment. something like: [code block] one thing that i'm not sure about is if this warning would get generated for other types given an array of pointers. for instance, if we define: [code block] does this now generate an error when we try to access `intval`?",-1,-1,-1,0.6501761674880981,0.9417858719825744,0.9627960324287416,-1.0,accept,unanimous_agreement
688104111,9356,thanks for digging into this . it make sense that it's an alignment related problem and that newer gcc versions correctly finds that it's already pointer aligned. another possibly is that type-punning is simply allowed on a `void*` by c99 so the compiler just has to accept it. i tried to add an int32_t member as you said and there's no build warning. here's the branch: [a link] [edit] ... and i'll add the comment on `void *metadata[]`,1,1,1,0.943398416042328,0.7767950296401978,0.975849151611328,1.0,accept,unanimous_agreement
688145341,9356,i'm ok with the change then. a comment should clarify what's going on. your proposal seems like the simplest solution.,0,0,0,0.9631140828132628,0.6078455448150635,0.6300896406173706,0.0,accept,unanimous_agreement
688232781,9356,we can probably just get rid of async to this function since it doesn't matter.,0,0,0,0.9806253910064696,0.9901354908943176,0.9865208864212036,0.0,accept,unanimous_agreement
688292763,9356,good. i tried `union { char bytes[]; void *pointers[] } metadata;` too but it's not allowed to have arrays without size in a union.,1,0,1,0.912243902683258,0.548660397529602,0.8465097546577454,1.0,accept,majority_agreement
688428527,9356,"i'd expect somewhere to describe this (a bit hackish) solution in detail, but at the very least, let's add a comment here. i.e. something like ""the head of a linked list dictentries (of keys) in each hash slot"".",0,0,0,0.7858309745788574,0.959025740623474,0.6947042942047119,0.0,accept,unanimous_agreement
688432427,9356,"i think we should eliminate this function entirely, and just add the loop in the one place that calls it. the current implementation is very wasteful since it copies the string to an `robj` and then copies it again to the output buffers (lost of excess malloc and memcpy calls). note that in the distinct past the reply buffers where robj, so there was no excess memcpy, but iirc starting with redis 4.0 (or maybe 3.2) we initially changed that to sds, and later to plain buffers.",0,0,0,0.785760223865509,0.9677169322967528,0.9624940156936646,0.0,accept,unanimous_agreement
688434424,9356,maybe we could have used stack based string object (wrapping the existing sds)? i suppose it can cause issues for modules that will get a notification with that stack based object (unless they already use the new rm_holdstring) wdty?,0,0,0,0.9877992868423462,0.9948746562004088,0.9897541403770448,0.0,accept,unanimous_agreement
688435806,9356,maybe a reference to to `clusterdictentrymetadata` will help?,0,0,0,0.9876263737678528,0.9946086406707764,0.9921459555625916,0.0,accept,unanimous_agreement
688436413,9356,"i see it is described in `dictentrymetadatasize`, maybe a reference here to `clusterdictentrymetadata` will help?",0,0,0,0.988347589969635,0.9942790269851683,0.9928870797157288,0.0,accept,unanimous_agreement
688444519,9356,"maybe, but it seems to be some work to investigate it. i'll have a quick look. the old code also created an robj from an sds key, so this would be an orthogonal change, i.e. probably leave it for another pr.",0,0,0,0.9712244272232056,0.9781073927879332,0.9691821932792664,0.0,accept,unanimous_agreement
688472067,9356,"yeah i noticed that was already the case, and as i noted, the change carries some implications. i suppose we better leave that for another pr anyway (because of the implications).",0,0,0,0.9625142216682434,0.9824408888816832,0.977486789226532,0.0,accept,unanimous_agreement
688474571,9356,"i think the ""slot to key api"" section in db.c would be a good place to document it in detail. how about moving this section (including the function slottoentryadd, etc.) to cluster.c and the struct clusterdictentrymetadata to cluster.h?",0,0,0,0.9668822884559632,0.9866478443145752,0.9770396947860718,0.0,accept,unanimous_agreement
688480494,9356,"i'm ok with moving them.. we need to decide if that part is more about the database or about the cluster. but note that `dbbackup` also has a similar reference. maybe we can extract some interface and remove that coupling. maybe we wanna try to remove the `include ""cluster.h"" in db.c and see where it takes us... i'm not sure..",0,0,0,0.8319209814071655,0.9165781140327454,0.8520381450653076,0.0,accept,unanimous_agreement
688498753,9356,"if i move these functions to cluster.c, we definitely need cluster.h in db.c...",0,0,0,0.944792866706848,0.9940045475959778,0.9883512854576112,0.0,accept,unanimous_agreement
689908096,9356,"i've moved the slot-to-key api to cluster.c and the dict metadata struct to cluster.h. in db.c, only calls the slot-to-key api are used. the dbbackup struct now contains a `clusterslotstokeysdata` which is a struct defined in cluster.h, to decouple it a bit more.",0,0,0,0.988965392112732,0.993643879890442,0.9898216724395752,0.0,accept,unanimous_agreement
689910937,9356,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
956203745,11193,"i presume the main functionality of this call is to unpause the clients if there is no traffic, but the comment indicates the opposite.",0,0,0,0.983029007911682,0.9869754314422609,0.9836114048957824,0.0,accept,unanimous_agreement
956210414,11193,"my understanding is we want to avoid evictions if we have a background jobs running. if we are over max-memory here, we are still going to evict on `performevictions()`. i was almost expecting this call to be in `performevictions` so we could set the pause and bail.",0,0,0,0.9556013345718384,0.9741403460502625,0.9791868925094604,0.0,accept,unanimous_agreement
956623778,11193,the main functionality of this function is to throttle (pause-unpause) clients-write operation during oom. maybe it should be named `throttleclientwritepauseduringoom`. maybe you have a better name?,0,0,0,0.984188973903656,0.9944795370101928,0.9939175844192504,0.0,accept,unanimous_agreement
956623811,11193,"function `clientwritepauseduringoom()` calls to `pauseclients()` which already take care to the low level details of pausing evictions properly. that is, later on the flow, function `performevictions()` calls at start to `issafetoperformevictions()` which calls to `checkclientpausetimeoutandreturnifpaused()` which returns 0 because earlier `pauseclients()` was called, that is not safe to perform evictions, and flow of function `performevictions()` ends without doing any evictions.",0,0,0,0.9794289469718932,0.9928537011146544,0.9922161102294922,0.0,accept,unanimous_agreement
959332472,11193,"pausing them in servercron is probably insufficient. beforesleep may be better (sooner), but might not be sufficient either. if we want to avoid excessive eviction or oom errors, the pausing needs to be done per command, which i see you do handle, so i suppose this is just needed for unpause. still maybe we need to do it in both beforesleep (sooner) and servercron (in case there's no traffic) or maybe we need to revive the condition we just deleted from lazyfree.c and let it trigger the unpausing?",0,0,0,0.95977520942688,0.9913086891174316,0.9812865853309632,0.0,accept,unanimous_agreement
959340212,11193,"ok, it's a little odd since it **is** safe to perform evictions. i.e. the **safe** part is about not emitting anything to the replication stream. but wording aside, i guess the outcome would be the correct one. i.e. the eviction will get skipped, and this command (if it's a write command) will get paused instead of processed (handled later in processcommand).",0,0,0,0.8247278332710266,0.926312267780304,0.935045599937439,0.0,accept,unanimous_agreement
959342242,11193,i'm not certain we want a config for that (even if enabled by default). why would anyone ever want to turn it off?,0,0,0,0.7156167030334473,0.7381275296211243,0.6309814453125,0.0,accept,unanimous_agreement
959347138,11193,"i don't think we wanna use redis-benchmark to populate the database for tests (unless we test redis-benchmark). we have the tcl based `populate` function, and we can improve that if needed.",0,0,0,0.9868215918540956,0.9879229664802552,0.9818732738494872,0.0,accept,unanimous_agreement
959361037,11193,i'm paranoid about these tests being flaky. maybe we can write a specific test using two clients and one command in each in some way? e.g.using (`kill -stop`) and some other tricks..,-1,-1,-1,0.9794397950172424,0.9754900932312012,0.9871588945388794,-1.0,accept,unanimous_agreement
959425295,11193,doing pause-unpause per command will block main thread to serve other clients. maybe have it called from beforesleep and servercron?,0,0,0,0.9815083146095276,0.9854034781455994,0.9905579090118408,0.0,accept,unanimous_agreement
959430887,11193,maybe i change the function name to `isperformevictions()`,0,0,0,0.987275004386902,0.9929481744766236,0.9911521077156068,0.0,accept,unanimous_agreement
959431972,11193,because of a bug? maybe hide it from the user?,0,0,0,0.814555287361145,0.9494314789772034,0.9736366271972656,0.0,accept,unanimous_agreement
959436208,11193,i think the missing features and performance between redis-benchamark and populate is too big.,-1,0,0,0.4981617331504822,0.6039037704467773,0.6317052245140076,0.0,accept,majority_agreement
959439567,11193,i let it run on two platforms for 1000 iterations. let's give it a try and see if it holds.,0,0,0,0.97806054353714,0.9675723910331726,0.9793046116828918,0.0,accept,unanimous_agreement
960437650,11193,"i'm still afraid. when that test runs in parallel to other tests, it could happen that the one that was supposed to produce a lot of evictions didn't produce many, and the other one wasn't affected, but still had a race and produced a few, and the factor is less than 4x.",-1,-1,-1,0.9809637069702148,0.9673804044723512,0.9863052368164062,-1.0,accept,unanimous_agreement
960581184,11193,added to beforesleep(),0,0,0,0.9863585829734802,0.9902573823928832,0.992733359336853,0.0,accept,unanimous_agreement
960581557,11193,removed client-pause-write-during-oom,0,0,0,0.9862513542175292,0.9904770851135254,0.9941086769104004,0.0,accept,unanimous_agreement
960582095,11193,simplified test. please review again test.,0,0,0,0.9855340719223022,0.9761531352996826,0.989486575126648,0.0,accept,unanimous_agreement
1003248668,11193,getmaxmemorystate needs to be checked against c_ok / c_err (don't rely on the fact c_ok is 0),0,0,0,0.9894249439239502,0.9882394075393676,0.9951985478401184,0.0,accept,unanimous_agreement
1003251724,11193,"come to think of it, we can remove the servercron one, since after a cron timer wakeup, we go through beforesleep anyway.",0,0,0,0.987186312675476,0.9826579689979552,0.9808578491210938,0.0,accept,unanimous_agreement
1003257925,11193,"i rather revert that rename (the name you suggested seems like it has grammar problems). but let's add a comment here that mentions: 1. if we initiated a pause then issafetoperformevictions will prevent the eviction in the later call 2. if we initiated a pause, and this is a write command, it'll get postponed later in processcommand.",0,0,0,0.9596801400184632,0.9937092065811156,0.985068380832672,0.0,accept,unanimous_agreement
1003261024,11193,"i think it should be renamed to `pause_oom_throttle` 1. we can't say we throttle without mentioning what's the throttle. e.g. imagine in the future we'll have multiple throttles, each one needs to controlled separately. 2. the fact we throttle writes is a different argument to the pause function (we have a purpose and an action)",0,0,0,0.9763250350952148,0.9932924509048462,0.9793933629989624,0.0,accept,unanimous_agreement
1003272117,11193,"i think it's better to populate the db before setting the memory limit, then measure how much we consumed, and then set the memory limit accordingly. this way, if redis some day becomes more (or less) memory efficient, it won't cause issues for this test.",0,0,0,0.9783105850219728,0.9868730902671814,0.9783607721328736,0.0,accept,unanimous_agreement
1003273893,11193,let's also look at `[s errorstat_oom]` counter.,0,0,0,0.9893207550048828,0.9934865236282348,0.9944487810134888,0.0,accept,unanimous_agreement
1003275504,11193,"can you maybe record (in the pr top comment?), the metrics (evicted, oom, and benchmark throughput) of this test with and without the feature?",0,0,0,0.9878789782524108,0.9938873648643494,0.9944369792938232,0.0,accept,unanimous_agreement
1016698915,11193,please add the `needs:config-maxmemory` and fix indentation to 4,0,0,0,0.9876691699028016,0.9938631057739258,0.995827615261078,0.0,accept,unanimous_agreement
1017412414,11193,should be uncommented?,0,0,0,0.9176745414733888,0.986586332321167,0.9929950833320618,0.0,accept,unanimous_agreement
1017413607,11193,isn't the one in processcommand enough? why do we need one in beforesleep?,0,0,0,0.9709620475769044,0.985837996006012,0.9564541578292848,0.0,accept,unanimous_agreement
1017488757,11193,the commit-suggestion is identical. what do i miss?,0,0,0,0.9550625085830688,0.7832054495811462,0.9938141107559204,0.0,accept,unanimous_agreement
1017491585,11193,please read the comment:,0,0,0,0.980086088180542,0.9644088745117188,0.9937844276428224,0.0,accept,unanimous_agreement
1017501069,11193,this logic is also related to `performevictions()` logic. we want to have rather updated state before reaching eviction phase. i could have remove it but i preferred to be on the safe side and add another checkpoint.,0,0,0,0.9751183986663818,0.990714430809021,0.9931190013885498,0.0,accept,unanimous_agreement
1017556702,11193,lower case `c` in front.,0,0,0,0.9867079257965088,0.9899842739105223,0.99088317155838,0.0,accept,unanimous_agreement
1017557990,11193,it took me a whole minute to spot it too... we're both blind to that nuance 8-),1,1,1,0.8829525113105774,0.8981912732124329,0.983574628829956,1.0,accept,unanimous_agreement
1020883346,11193,"if someone calls config resetstat during the time this is active, it can cause this block to re-enter, but i think this would be still safe.",0,0,0,0.978343665599823,0.9847002029418944,0.9875842928886414,0.0,accept,unanimous_agreement
1020889972,11193,i don't think i understand this extra `if` you added. is it an optimization to avoid calling ispausedactions multiple times later? please explain and maybe add a comment. p.s. i think the core in relation to `is_may_replicate_command` is wrong. the `is_may_replicate_command` should limit the `write`. and `is_denyoom_command` should limit the denyoom one.,0,0,0,0.7625634074211121,0.9764819741249084,0.905401885509491,0.0,accept,unanimous_agreement
1020890115,11193,i think we wanna add the `current` variant too (not only the `total` one),0,0,0,0.988115668296814,0.9881220459938048,0.9895032644271852,0.0,accept,unanimous_agreement
1020890503,11193,"let's make it `static inline`. or maybe even move it back to the c file, we don't have any inline functions in server.h at the moment.",0,0,0,0.98739492893219,0.9944781064987184,0.9915871620178224,0.0,accept,unanimous_agreement
1020919358,11193,optimized common case. added comment. thanks.,1,1,1,0.9642204642295836,0.9576623439788818,0.954312801361084,1.0,accept,unanimous_agreement
1020919528,11193,fixed `is_denyoom_command` condition. now it is checked without may_replicate.,0,0,0,0.9893527030944824,0.9952502250671388,0.9934149980545044,0.0,accept,unanimous_agreement
1020919575,11193,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
1020919755,11193,"returned it back as regular function to networking.c, next to related functions.",0,0,0,0.9880563020706176,0.9931269884109496,0.9942668080329896,0.0,accept,unanimous_agreement
1020926949,11193,let's make the order consistent across lines. [code block],0,0,0,0.987272083759308,0.987025022506714,0.9950270056724548,0.0,accept,unanimous_agreement
1022389004,11193,"i'm not a fan of the new `init_flow`, and even if we proceed with it, i suppose we need to patch a few other stat variables. correct me if i'm wrong, but it seems to me that this resetstat didn't have a real negative impact on your code. i.e. it would zero current_client_paused_oom_time, causing us to start a new measurement next time we get here, so it doesn't have any negative impact on the stats. the unexpected impact is that we'll call `pauseactions` again (even though we're already paused), but that also doesn't have any negative impact, right? ohh, the risk is that if right after resetstat we realize we need to drop the pause, we won't call unpauseactions. maybe the right solution is to separate between the decision on when we should call pauseactions and unpauseactions from any code related to the metrics?",-1,-1,-1,0.9184663891792296,0.6003463268280029,0.7992846369743347,-1.0,accept,unanimous_agreement
1022448643,11193,"imo, just because resetstat can be risky and can be called from two, very different flows, i feel it is the right thing to reflect it in its function declaration with `init_flow` flag rather than hide it and have ""clean and optimistic picture"" of it. adding another argument might complicate a rather simple logic.",0,0,0,0.8543367981910706,0.8847745060920715,0.9707585573196412,0.0,accept,unanimous_agreement
1022748323,11193,"i think resetserverstats is doing exactly what it should do (clear a bunch of variable). i might not mind the extra argument, but i don't like the complicated logic inside that function. the problem here is that we bind other logic (calling `unpauseactions`) to a stat variable. i think that's the root of this issue.",-1,0,0,0.6838788390159607,0.8587808012962341,0.8353835940361023,0.0,accept,majority_agreement
1023942452,11193,"i'm sorry for trolling you, but i now realize that resetting stat_current_client_paused_oom_time in resetstat would cause stat_total_client_paused_oom_time to later jump to a huge number. i suppose these metrics need to be completely decoupled from the `if` that decides if we want to pause, and instead depend on the eventual state (like we do in evict.c and defrag.c). p.s. we previously didn't have the is_pause_write_clients_oom variable, and relied on the quick exit in pauseactions / unpauseactions when the state doesn't change, maybe we can keep doing that?",-1,-1,-1,0.9893031120300292,0.9853588342666626,0.9833776950836182,-1.0,accept,unanimous_agreement
1024949596,11193,don't be sorry. you are doing holy job. i simplified evaluation stat_total_client_paused_oom_time. lmk if you still have any issues. thanks.,1,1,1,0.8989536762237549,0.964767038822174,0.9644766449928284,1.0,accept,unanimous_agreement
1029125821,11193,did we switch from monotonic clock to wall clock?,0,0,0,0.981439769268036,0.9930025935173036,0.988284945487976,0.0,accept,unanimous_agreement
1029128297,11193,"i don't think it's a good idea to sum milliseconds rather than microseconds. it's ok to report in msec, but the summing should be in usec so we don't lose precision",0,0,0,0.9675123691558838,0.9440396428108216,0.8186254501342773,0.0,accept,unanimous_agreement
1030275361,11193,"since this value is being used only for statistics, i prefered inaccuracy and save execution time. i feel uncomfortable to ""pollute"" top level of `struct redisserver`. i think we should think how to break it down. i will rollback my commit. i assume when you say ""separating the if that decides which action to take, from the if..."" you mean follow the pattern identify the state and ""goto update_metrics;""",-1,-1,-1,0.860238254070282,0.9778498411178588,0.9437167048454284,-1.0,accept,unanimous_agreement
1030280197,11193,in my mind was the issue that it is only being used for statistics at most. i will change it.,0,0,0,0.9228872060775756,0.9618326425552368,0.9531736969947816,0.0,accept,unanimous_agreement
1030522464,11193,"yes, let's first decide on the action to take (start or stop pause). and then, separately update the statistics, this is what we do in the other similar stats, and afaict it doesn't break on resetstat.",0,0,0,0.9867115020751952,0.9910200238227844,0.9932758808135986,0.0,accept,unanimous_agreement
1030627985,11193,"do we really need all that fancy enum and goto? can't we just add something defrag.c does the bottom (instead of return): [code block] i think it's simpler since that piece of code is independent and doesn't rely on any hints from above. i don't see any major issues with resetstat (unlike your code, after reset, if pause is in effect, it'll start measuring immediately and not on next pause). and the bonus is that it's similar to the other mechanisms, so it's behavior is less likely to surprise anyone.",0,0,0,0.9011642336845398,0.9297894835472108,0.943850576877594,0.0,accept,unanimous_agreement
1031135680,11193,cool. please note that your code avoid early return in favor of updating statistics soon after resetstat.,1,1,1,0.952051877975464,0.975892961025238,0.9857227206230164,1.0,accept,unanimous_agreement
1036303980,11193,"this text is a bit complicated and has some grammar issues.. i can try to simplify later, adding a note so that we don't forget. p.s. let's mention why we don't remove the read handler right away (syscall overhead)",0,0,0,0.5944153666496277,0.9482356309890748,0.5824910998344421,0.0,accept,unanimous_agreement
1036304340,11193,"styling, single line `if` has the `{` on the same line.",0,0,0,0.9892163276672364,0.9905515909194946,0.9935546517372132,0.0,accept,unanimous_agreement
1036358838,11193,"doesn't that limit all clients, not just ones that have been paused? i.e. we don't throttle read commands, so we shouldn't block them or remove their read handler. the only clients which we want to remove read handler for are ones that we decided not to process.",0,0,0,0.9692960381507874,0.9686830043792723,0.9923266172409058,0.0,accept,unanimous_agreement
1036361444,11193,"not sure what are the test suite changes that came with the last commit. seems like wip. but i guess that eventually, we want to add a test that challenges that (and explodes if we didn't remove the read handler)",0,0,0,0.6870718598365784,0.7882696986198425,0.902077317237854,0.0,accept,unanimous_agreement
1036486182,11193,i will try to rephrase it,0,0,0,0.9440905451774596,0.9838115572929382,0.9844956398010254,0.0,accept,unanimous_agreement
1036492943,11193,"you are right... i wanted to talk with you about this change. in case there is query_buf that grows behind some threshold i think it is safer to block it early on, even before processing a complete command (read or write). the alternative of letting query_buf grow without any limit (during oom) might be too risky. note that before this pr, in case of flushall sync, during oom or not, no client could have write to the server.",0,0,0,0.9139485359191896,0.9283690452575684,0.8797879815101624,0.0,accept,unanimous_agreement
1036883751,11193,please review new commit. the explanation there might reflect my thought.,0,0,0,0.9800729155540466,0.9826512932777404,0.993016242980957,0.0,accept,unanimous_agreement
1037516035,11193,"please be aware of #11012, fyi.",0,0,0,0.9797154664993286,0.9635950922966005,0.9876532554626464,0.0,accept,unanimous_agreement
1037530290,11193,"reading your updated comment, still wonder. so you say you remove the read handler for the `!blocked`, because you wanna affect the ones that are gonna get blocked, earlier, before they manage to consume a big qbuf, but by that, you also affect reads, and publish, etc. secondly iirc, the reason why we wanted to remove the read handler was because we were afraid that in some cases the write command throttling can actually cause damage, e.g. a case where a pipeline of small sets overwriting the same key again and again (not really consuming memory), will get blocked, and then the query buffer will grow (because of the combination of pipeline and our blocking). i.e. we wanted that qbuf protection so that our throttling won't backfire on us. lastly, iirc you argued that in previously (before this pr), flushall would be completely blocking anyway, so this mechanism of throttling some reads, can't be considered a regression, i suppose that's right, but also it may not provide the full potential of this improvement. maybe we should focus on publish, since it's more likely to have a large query buffer than reads. on the other hand, the real memory impact of publish, is actually not the query buffer, it's the output buffers it creates (which is amplified by the number of subscribers).",-1,0,0,0.5126240253448486,0.6316811442375183,0.7398869395256042,0.0,accept,majority_agreement
771954261,9963,please add a documentation comment above the api. maybe rename it to `rm_slowcontextheartbeat` (i.e. like the existing `rm_sendchildheartbeat`)? i.e. something more abstract. wdyt?,0,0,0,0.9880964756011964,0.9931492209434508,0.9943219423294068,0.0,accept,unanimous_agreement
771954331,9963,let's add some comment about these fields (what they are used for),0,0,0,0.9865642786026,0.9839481711387634,0.9947640895843506,0.0,accept,unanimous_agreement
771954500,9963,"would be better to init this when the context is created rather than the first call. let's merge it after #9890, it'll be easier. i think we'll be able to do with just one variable (`next_event`), which will be set to `script_time_limit` when the context is created.",0,0,0,0.9782375693321228,0.9829293489456176,0.9892762899398804,0.0,accept,unanimous_agreement
771954748,9963,`blockingoperationstarts` should only be called once (on the first time we get here. and then `blockingoperationends` should be called when the context is destroyed.,0,0,0,0.9824618697166444,0.9918183088302612,0.9932428002357484,0.0,accept,unanimous_agreement
771954997,9963,"please get the latest from unstable, and add these flags to the json files instead.",0,0,0,0.9886271357536316,0.9921006560325624,0.9951130747795104,0.0,accept,unanimous_agreement
771955186,9963,"i think you should revert these changes, and add a 3rd error message that's specific to modules.",0,0,0,0.9871843457221984,0.9882934093475342,0.9790440201759338,0.0,accept,unanimous_agreement
771956499,9963,"first, this is very wrong (modifying the command flags, permanently), as soon as it is called with some argument. but anyway, you'll soon be able to revert this change, since this is handled properly in #9872 (i.e. it allows the entire shutdown command, and the command itself does the rest of the filtering)",0,0,0,0.8288675546646118,0.9780592918395996,0.8264194130897522,0.0,accept,unanimous_agreement
771956725,9963,"since this is now specific to modules, let's call it `busy_module` (should be set as soon at the timeout is reached, and remain set until the context is destroyed)",0,0,0,0.989024579524994,0.994529664516449,0.99419903755188,0.0,accept,unanimous_agreement
771957198,9963,"it's a little bit odd to see it in the ""list"" test module. maybe putting it in the timer module is less awkward?",-1,-1,-1,0.8860106468200684,0.9489380717277528,0.939783811569214,-1.0,accept,unanimous_agreement
771957414,9963,"let's set `script-time-limit` to a low number, so that this test will not take long",0,0,0,0.9824320673942566,0.9888951778411864,0.9932863116264344,0.0,accept,unanimous_agreement
771957600,9963,"maybe we can add some timing, to see that we didn't get here too soon?",0,0,0,0.9720367193222046,0.9854654669761658,0.9859657287597656,0.0,accept,unanimous_agreement
771957711,9963,i'd rather have a wait_for_condition to wait for a pong rather than a constant sleep (which can also cause failure in case of timing issues).,0,0,0,0.9721625447273254,0.9889860153198242,0.9088008403778076,0.0,accept,unanimous_agreement
774014660,9963,blockingoperationends should happen in modulefreecontext ?,0,0,0,0.985929310321808,0.9928966164588928,0.9901094436645508,0.0,accept,unanimous_agreement
774018844,9963,"i think so.. but maybe it's more complicated than that when there are nested contexts? i.e. the two typical cases i was thinking of are simple commands called by redismodulecommanddispatcher (will respond with -busy), and about contexts during the `rdb_load` callback (should respond with -loading. but maybe there are also cases to think about with regards to other more complex scenarios. i think you can use modulefreecontext for now, and let's ask and to have a look.",0,0,0,0.9693659543991088,0.9838489294052124,0.9570746421813964,0.0,accept,unanimous_agreement
774056695,9963,"i'm not sure i understand, we want to see the busy error... what do you mean by timing ?",-1,-1,-1,0.8241468071937561,0.9059110879898072,0.6046810150146484,-1.0,accept,unanimous_agreement
774157606,9963,"something like this, to measure time, and see that it's bigger than the script-time-limit we've set [code block]",0,0,0,0.9794939160346984,0.9899573922157288,0.9930881857872008,0.0,accept,unanimous_agreement
774195935,9963,"we need to remember that this function can be reentrant: a module command module.foo calls this api, while another module command module.bar is allow-busy and is waiting to be processed when it is finally processed here, it also calls this module api",0,0,0,0.985243797302246,0.9837456941604614,0.9914119243621826,0.0,accept,unanimous_agreement
775874174,9963,", wdyt ?",0,0,0,0.9778684377670288,0.9773939847946168,0.9860239028930664,0.0,accept,unanimous_agreement
775954388,9963,i guess we should do the unblocking when in `modulefreecontext` when `server.module_ctx_nesting` goes back to 0. p.s. maybe we should forbid calling these apis from threads (`redismodule_ctx_thread_safe`)? or maybe there's actually an advantage to let modules handle events in long blocking gil locks from threads? (i feel sick by just raising that idea). ?,-1,-1,-1,0.9750438928604126,0.7671709656715393,0.9935835003852844,-1.0,accept,unanimous_agreement
776028076,9963,i think there is a bug advantage of allowing it from a `threadsafectx` maybe on `threadsafectx` we can call `blockingoperationstarts` and `blockingoperationend` from the lock and unlock functions? also notice that `blockingoperationstarts` and `blockingoperationend` already handled nesting so maybe there is no need to check `server.module_ctx_nesting`,0,0,0,0.9863722920417786,0.9945912957191468,0.9872201681137084,0.0,accept,unanimous_agreement
776030898,9963,"lol ""bug advantage"". exactly my thoughts. anyway, just calling the starts / stops methods isn't gonna do anything. and we certainly don't wanna call the new (processevents) api automatically (it'll start rejecting commands). and we can allow calling the new api in thread safe contexts, and after a while it'll start processing events.",1,1,1,0.6564130783081055,0.9925459027290344,0.8885229229927063,1.0,accept,unanimous_agreement
780930635,9963,"""another module command""",0,0,0,0.9875844120979308,0.9915538430213928,0.9954211115837096,0.0,accept,unanimous_agreement
780931168,9963,please move to the end or beginning of the function (currently it's in the middle of lines that are logically related),0,0,0,0.9862447381019592,0.991564393043518,0.9924170970916748,0.0,accept,unanimous_agreement
780931372,9963,"technically, it'll also permit these module commands to run while there's a blocked script. am i wrong?",0,0,0,0.6231145262718201,0.7675361037254333,0.9496204257011414,0.0,accept,unanimous_agreement
780931533,9963,"""another module command or a script""",0,0,0,0.9880948662757874,0.9898229837417604,0.9949365854263306,0.0,accept,unanimous_agreement
780931916,9963,use underscores,0,0,0,0.9881715178489684,0.9693013429641724,0.9903524518013,0.0,accept,unanimous_agreement
780932247,9963,maybe add a comment explaining this behavior,0,0,0,0.9841080904006958,0.987019181251526,0.9914496541023254,0.0,accept,unanimous_agreement
780932616,9963,please use one external `if (--server.module_ctx_nesting == 0)` and two internal `if`s,0,0,0,0.9880891442298888,0.9950974583625792,0.995352268218994,0.0,accept,unanimous_agreement
780933778,9963,"let's go with ""permit the command while the server is blocked either by a script or by a slow module command"" i feel it's important to document the scenarios in which this flags matters",0,0,0,0.9239164590835572,0.955324411392212,0.9924960136413574,0.0,accept,unanimous_agreement
781103136,9963,"modules are not always user-controlled, unlike scripts, so i think it may not always make sense to the user to get this error message. instead, i think it might be useful for a module to control the reply in this case.",0,0,0,0.9721346497535706,0.984177589416504,0.9872304797172546,0.0,accept,unanimous_agreement
781108621,9963,i think some of the terms here are confusing - i propose to name this `rm_yield`. what exactly is a `slowcontext`? we didn't define this anywhere. and `heartbeat` is usually used to describe a process where one tells another it's still alive - but this is not the case here (it's not *required* to call this function).,0,0,0,0.8508648872375488,0.8223615884780884,0.8512231111526489,0.0,accept,unanimous_agreement
781121426,9963,"ok, so it should be an argument to the rm_yield api? should it also control the error code? or just the textual message? (note that currently the error code could be either loading or busy depending on the server state)",0,0,0,0.9885050654411316,0.9947249293327332,0.9929593801498412,0.0,accept,unanimous_agreement
781783218,9963,i also like the name rm_yield(),1,0,0,0.7809739112854004,0.7561181783676147,0.8413777947425842,0.0,accept,majority_agreement
781783466,9963,"i don't understand the coupling with `script-time-limit`, can't the module decide how it's yielding to the main thread. it seems like there is a couple of different types, so maybe we can add some type of flags to the rm_yield call.",0,0,0,0.9475248456001282,0.8526360988616943,0.9693538546562196,0.0,accept,unanimous_agreement
781784026,9963,"i might be missing something, but this only ever seems to be set, but never used.",0,0,0,0.8757200241088867,0.9444947838783264,0.8465604186058044,0.0,accept,unanimous_agreement
784883754,9963,it is used in rm_yield in order to decide when is the next time to call processeventswhileblocked,0,0,0,0.9883620142936708,0.990474283695221,0.9949074387550354,0.0,accept,unanimous_agreement
784886043,9963,"i rather not let the module decide that. and indeed the name of the config is a problem. maybe we can add an alias for it. or actually, it already has an alias (was `lua-time-limit` in the past, and now it's `script-time-limit`). maybe we can find a better name that can cover both modules and scripts? how about `busy_operation_threshold`?",0,0,0,0.9321730732917786,0.9862610697746276,0.9450656771659852,0.0,accept,unanimous_agreement
785947268,9963,it makes sense. maybe `busy-reply-threshold`?,0,0,0,0.9854361414909364,0.993544578552246,0.9876355528831482,0.0,accept,unanimous_agreement
785950550,9963,"i don't like the fact that passing a null `busy_reply` will *sometimes* assert (only if we hit the code path to actually produce that reply). i suggest to either use a default, assert here instead, or maybe just have `rm_yield` return an error.",-1,-1,-1,0.9684499502182008,0.8381383419036865,0.8894986510276794,-1.0,accept,unanimous_agreement
785963513,9963,this can be removed now i guess.,0,0,0,0.987252116203308,0.9798564910888672,0.9909708499908448,0.0,accept,unanimous_agreement
786129964,9963,"i'll use it as a default.. i was actually paranoid about somehow reaching that code that uses it when in_busy_module is still true, and somehow already out of the scope of rm_yield.",-1,0,-1,0.9680510759353638,0.6804636716842651,0.799801766872406,-1.0,accept,majority_agreement
786153734,9963,"i don't like it that much, but i think i like the alternatives even less. updating the pr with a rename",-1,1,-1,0.9678696990013124,0.4454908072948456,0.8918718695640564,-1.0,accept,majority_agreement
786459432,9963,"i don't like the title, too many commands can block redis for a long time like `keys` `flushall` event `del` `hgetall` on a big key. but the threshold only works for function(lua script) and modules.",-1,-1,-1,0.959674596786499,0.979012966156006,0.9224227070808412,-1.0,accept,unanimous_agreement
786481911,9963,non-deterministic blocking commands?,0,0,0,0.9668102860450744,0.8782177567481995,0.9877771139144896,0.0,accept,unanimous_agreement
786491790,9963,"maybe adding new special configs is better, avoid breaking change since most users are using the old config `lua-time-limit`.",0,0,0,0.9792277216911316,0.9921199083328248,0.9832841157913208,0.0,accept,unanimous_agreement
786516466,9963,"it's not a breaking change, since there's an alias. but maybe in this case we want to still mention the old config in the documentation (so whoever sees it in some code can find it's docs). i'll do that.",0,0,0,0.9853715300559998,0.9880752563476562,0.987930417060852,0.0,accept,unanimous_agreement
787054908,9963,"does this imply we're ok with this being called from another thread? sounds like a lot of potential trouble, now or in the future.",-1,0,-1,0.7558853626251221,0.7832849621772766,0.8785948157310486,-1.0,accept,majority_agreement
787138908,9963,"yes, we intend for this to also be called from a slow background operation that blocks the gil for long. there's even a test for it (not that it increases the confidence that it won't be abused or trigger problematic edge cases)",0,0,0,0.978612780570984,0.9550451040267944,0.9883059859275818,0.0,accept,unanimous_agreement
787301391,9963,"i agree about renaming this blocked_postpone. there are several places that explicitly make reference to the fact this is only called in a paused context, included the documentation for it. i don't see any specific issues as long as we believe calling the yield is an infrequent event.",0,0,0,0.9730446338653564,0.9729084968566896,0.9687318205833436,0.0,accept,unanimous_agreement
787391405,9963,"calling the yield is not infrequent, but i do ""un pause"" them only when the outer most module context is done. so the other thing we can do is we throttle (delay) the initial yielding. assuming the module calls us very frequently, currently there are 3 modes of operation: 1. during loading, in which case we start processing events right away (in hz intervals, so the first one is after some 100ms of blockage). in this mode we always process all clients (return -loading), so it won't postpone any 2. during other blocked contexts, when the user used yield_clients, we start processing event only after 5 seconds of blockage, and also we don't postpone any (return -busy to all). 3. during other blocked contexts, when the user used yield_events. discuss this below. in this mode we could have ignored the `busy_reply_threshold` config, and start yielding right away (after 100ms hz delay), in which case we could do many blocking and unblocking of clients. i didn't do that (we do wait the 5 seconds) because i was afraid of side effects such as this one on short blocking operations. in theory, even if the user used yield_clients where we start yielding to clients only after the 5 seconds threshold, we could have stated yielding to other events sooner (i.e. right away after the hz delay). again, decided not to do that since it seemed risky. the meaning of that is that if there are any bugs, we're unlikely to see them. i.e they'll surface only when the module blocks for more than 5 seconds.. if we used the shorter throttling, maybe it would have exposed bugs sooner (during release candidate testing). wdyt?",0,0,0,0.97297340631485,0.9710841178894044,0.9879756569862366,0.0,accept,unanimous_agreement
787400255,9963,"added a commit with a comment to explain that, so we won't overlook this in the future.",0,0,0,0.9719125032424928,0.9879391193389891,0.9875164031982422,0.0,accept,unanimous_agreement
788050883,9963,"i'm really not sure about suddenly having significant ""main thread"" code flow running from another thread. even if things don't break, we'll still be running into weird jemalloc thread-local issues, and may regret that with any future work around threading. update: taking this back, most of that is already possible with `rm_call()` on a thread safe context so at least from the pov of this pr there's no real difference.",-1,-1,-1,0.9357228875160216,0.615387499332428,0.9247910976409912,-1.0,accept,unanimous_agreement
788324334,9963,i think the tradeoffs made are ok.,0,0,1,0.9789990186691284,0.9464421272277832,0.6976987719535828,0.0,accept,majority_agreement
788329642,9963,"when redis isn't in loading, why don't need to rely on `busy_reply_threshold` to calculate `next_yield_time`?",0,0,0,0.9864405989646912,0.9885099530220032,0.9921795129776,0.0,accept,unanimous_agreement
788360250,9963,"i don't understand the question. the initial delay is set in modulecreatecontext (different for loading and non-loading). after that, they both depend on hz. am i missing anything?",0,0,0,0.8695934414863586,0.5592770576477051,0.8924380540847778,0.0,accept,unanimous_agreement
788364243,9963,"if so, that's fine, but i don't understand why it's designed that way, it's not reflected in the comments.",0,0,0,0.9193716645240784,0.950373113155365,0.8904979228973389,0.0,accept,unanimous_agreement
788378002,9963,"isn't it logical? it's similar to what happens in scripts and in loading (when modules don't block). i.e. loading processes events every 2mb. and scripts start process events after 5 seconds. and in either case, we wanna throttle the module yield calls since they may come in a rate that's too high. am i missing anything? can you suggest where you think a comment is missing?",0,0,0,0.950108766555786,0.891769289970398,0.9830998182296752,0.0,accept,unanimous_agreement
788404548,9963,"silly me. i took `busy_reply_threshold` to be the fixed frequency of yield, as you have explained in your comment above. [code block]",-1,-1,-1,0.98747581243515,0.9826428890228271,0.9757109880447388,-1.0,accept,unanimous_agreement
1408705167,12817,start version: 7.0.0 introduced: #9963 reason: main thread reads this without getting the gil. [code block],0,0,0,0.9854505062103271,0.9939403533935548,0.9947994947433472,0.0,accept,unanimous_agreement
1408706695,12817,start version: 6.2.0 introduced: #8141 reason: release client argv outside of gil [code block],0,0,0,0.9859077334403992,0.9946345090866088,0.99487042427063,0.0,accept,unanimous_agreement
1408707239,12817,start version: 7.2.0 introduced: #12326 reason: `rm_reply*` is not thread-safe [code block],0,0,0,0.9851484298706056,0.9946622252464294,0.9952276945114136,0.0,accept,unanimous_agreement
1408708472,12817,start version: 7.0.0 introduced: #8687 reason: touch `server.stat_clients_type_memory` without gil [code block],0,0,0,0.9799797534942628,0.9947698712348938,0.995268166065216,0.0,accept,unanimous_agreement
1414373952,12817,"is the problem with the call to unblockclient , or also with the replywith? afaik it's ok to reply to the blocked clients without locking anything.",0,0,0,0.9762290120124816,0.9898468852043152,0.990805447101593,0.0,accept,unanimous_agreement
1414378465,12817,is it because of auto-memory? the stack trace here seems unrelated to the release of the argv array.,0,0,0,0.9784643650054932,0.987302541732788,0.9837744235992432,0.0,accept,unanimous_agreement
1414390068,12817,"regarding the updatestatsonunblock problem, i suppose that's a bug we introduced in #7491 (redis 6.2). we should solve it rather than add an api restriction. wdyt?",0,0,0,0.9876735806465148,0.9884489178657532,0.9862202405929564,0.0,accept,unanimous_agreement
1415416599,12817,i update the stack trace.,0,0,0,0.986681580543518,0.9763224124908448,0.9932137727737428,0.0,accept,unanimous_agreement
1415449745,12817,"[a link] i've made the `moduleblockedclienttimedout()` distinguish between the main thread andmodule threads. since we have no way of knowing if `rm_unblockclient()` was called in the thread, we have to make it always asynchronous to handle unblock status updates. and we need to make the ctx with redismodule_ctx_thread_safe flag, otherwise replying error in the `timeout_callback()` will not be thread-safe.",0,0,0,0.977540910243988,0.9940209984779358,0.9940603375434875,0.0,accept,unanimous_agreement
1418467835,12817,another more serious race condition. start version: 7.0.0 introduced: [a link] main thread (a): module thread (b): (a)beforesleep(release gil) -> (a)aeapipoll -> (b)acquire gil -> (b)rm_yield() -> (b)processeventswhileblocked() -> (b)aeapipoll [code block],0,0,0,0.9613508582115172,0.9895427227020264,0.9155062437057496,0.0,accept,unanimous_agreement
1418910794,12817,"according to the spec, i don't think we can rely on 0 not being the real id of some thread. in practice, i suppose it's not a real concern.",0,0,0,0.8985643982887268,0.9353939294815063,0.9657074213027954,0.0,accept,unanimous_agreement
1418925907,12817,"i think calling `modulecount()` may be unsafe. it currently resorts in the total size of two hash tables. if they're in the process of re-hashing, it could in theory lie.",0,0,0,0.9306948781013488,0.9259937405586244,0.9529565572738647,0.0,accept,unanimous_agreement
1418954302,12817,"so what do we conclude here? that if a module retains the argv strings, it must release them before unblocking the client, or alternatively with the gil locked? ptal",0,0,0,0.9872986674308776,0.9725258350372314,0.9932897686958312,0.0,accept,unanimous_agreement
1418958202,12817,"actually the order doesn't matter, if they both decr at the same time it can mess up the refcount. i suppose we must clone the stings before branching?",0,0,0,0.9719185829162598,0.940378487110138,0.9861429333686828,0.0,accept,unanimous_agreement
1418969583,12817,"like [a link] this is not about the use of rm_addreply, it's about using the argv strings (changing their refcount). p.s. how did you conclude it's related to the above mentioned pr?",0,0,0,0.9848006963729858,0.9921814203262328,0.9941685199737548,0.0,accept,unanimous_agreement
1418970686,12817,"this one is resolved by modifying the freeclient code, right?",0,0,0,0.9861184358596802,0.9939329028129578,0.9937572479248048,0.0,accept,unanimous_agreement
1418988306,12817,"looking at your changes in moduleblockedclienttimedout, i'm not sure i understand why we don't need to call updatestatsonunblock when the code comes from rm_unblockclient.",0,0,0,0.7648959159851074,0.820140540599823,0.9656265377998352,0.0,accept,unanimous_agreement
1419874603,12817,"i think it would make more sense to free it with gil, since it was no longer in use before unblockclient, and i can't think of a benefit to clone it.",0,0,0,0.942572832107544,0.9798023104667664,0.9813397526741028,0.0,accept,unanimous_agreement
1419878175,12817,"yes, and make `updateclientmemoryusage()` and `clientevictionallowed()` no longer keep track of non-conn user memory and whether eviction. however, this has the side effect that `server.stat_clients_type_memory[client_type_normal]` will be lower than it was before this fix was made.",0,0,0,0.9750663638114928,0.9937379360198976,0.9928061366081238,0.0,accept,unanimous_agreement
1419882170,12817,"they're not related. this is because main thread many modify `server.current_client` when module thread read it. however, `c->flags & client_pushing` is always false for module threads, so this is harmless.",0,0,0,0.9358007907867432,0.9524925947189332,0.9889919757843018,0.0,accept,unanimous_agreement
1419883004,12817,following [a link] we call `updatestatsonunblock()` here when from rm_unblockclient().,0,0,0,0.9885519742965698,0.9939602613449096,0.9946263432502748,0.0,accept,unanimous_agreement
1419883147,12817,please see [a link],0,0,0,0.9759726524353028,0.9765523076057434,0.995389461517334,0.0,accept,unanimous_agreement
1421746714,12817,"does it mean that before this pr it was called twice? maybe we should add a comment in moduleblockedclienttimedout, explaining the `if` statement by referring to this call.",0,0,0,0.9868043661117554,0.9914631247520448,0.9926949739456176,0.0,accept,unanimous_agreement
1421747175,12817,"i suppose we better document this. i.e. that anything we do with the retained arguments refcount) from a thread (using them for a reply, re-retaining, or freeing them) needs to be done with the gil locked. wdyt?",0,0,0,0.9886005520820618,0.9883404970169068,0.9886521697044371,0.0,accept,unanimous_agreement
1421747655,12817,"we can't / shouldn't evict them anyway. if we tracked them, it was wrong to do that. we can list this as a fix (not about thread race) in the top comment.",0,0,0,0.8938415050506592,0.9598629474639891,0.974200427532196,0.0,accept,unanimous_agreement
1421749431,12817,"technically we can document that, but does that make sense in terms of api usability?",0,0,0,0.9841629266738892,0.9873391389846802,0.9894415140151978,0.0,accept,unanimous_agreement
1421802052,12817,what other options do we have? introduce a new api that deep copies the string to be used when retaining it for a thread? use atomic operations on all refcounts? the only relief here is that modules that use threads to process argv are probably not too common.,0,0,0,0.9788145422935486,0.9765764474868774,0.9545404314994812,0.0,accept,unanimous_agreement
1422074571,12817,i think its ok to say that release a redismodulestring can only be done when holding the gil unless you know for sure that you are the only owner of the redismodulestring.,0,0,0,0.9854007363319396,0.9712775945663452,0.9795323014259338,0.0,accept,unanimous_agreement
1422569270,12817,"before this pr, `modulehandleblockedclients()` ignored updating the block status when the client was blocked on keys. origin code: [code block]",0,0,0,0.9885022640228271,0.9949493408203124,0.9953998923301696,0.0,accept,unanimous_agreement
1422595505,12817,"i've never been able to remember how i reproduced it. i remember using rm_call to reproduce it, but i forget which command, not the following `client no-evict` command. config: [code block] command: [code block] patch: [code block] `serverassert(c->conn);` will be triggered.",0,0,0,0.9660397171974182,0.9824911952018738,0.9733538627624512,0.0,accept,unanimous_agreement
1423907802,12817,please als have a look at [a link] and top comment(7).,0,0,0,0.9867522716522216,0.95802241563797,0.9920417666435242,0.0,accept,unanimous_agreement
1423913130,12817,"i don't think using rm_call to call the client command is valid. specifically the ones manipulating the current client, like enabling tracking, and so on. the user may be wanting to operate on the calling client, not the fake client, but that's not currently supported, and i think we should just disallow or disregard this case.",0,0,0,0.9499449133872986,0.9237295389175416,0.9663710594177246,0.0,accept,unanimous_agreement
1423927362,12817,"this is another place to record the memory usage of fake clients. when unblocking a fake client that blocks on keys, it triggers. [code block] failed test: [code block]",0,0,0,0.944229781627655,0.9914044141769408,0.991634964942932,0.0,accept,unanimous_agreement
1423957264,12817,"i think that's a bug, they're not ""evictable"", and the user (application) doesn't control them (and their amount). we don't show them in client list, and i think we should not count their memory in that mechanism (maybe we should count them elsewhere)",0,0,0,0.6428176164627075,0.823947012424469,0.9457615613937378,0.0,accept,unanimous_agreement
1429096255,12817,let's add a comment as to why we need this variable and we're not using dictsize directly,0,0,0,0.9829419255256652,0.9884629845619202,0.9933940768241882,0.0,accept,unanimous_agreement
1429097491,12817,i suppose we need to update that text.,0,0,0,0.9837250113487244,0.9716611504554749,0.9856666922569276,0.0,accept,unanimous_agreement
1429103466,12817,"\i think that `lock_pool` and `el_poll_mutex` should be renamed. at this level (server.c), we don't know if it's `poll` or `select`, so we're just protecting `ae`.",0,0,0,0.9864118099212646,0.9897632598876952,0.9891613125801086,0.0,accept,unanimous_agreement
1429106120,12817,"so we have one mutex protecting the times in which we do actual work (our gil), and another mutex for protecting times when we go to sleep (not to use epoll in 2 threads at the same time)? if we documented that using the rm_yield api from a thread has to be done while locked, and it also attempts to lock the ae mutex, then it can only actually run in a very narrow time window. i wonder if that's the right approach. maybe instead we can block the module thread, and wait for the main tread to perform an ae cycle? i wonder why at all we allowed it to be run from a thread. i don't remember the use case. maybe you remember something?",0,0,0,0.7396907806396484,0.8353956341743469,0.91886305809021,0.0,accept,unanimous_agreement
1430940105,12817,changed to `el_mutex` and `lock_el`.,0,0,0,0.9882705211639404,0.9941792488098145,0.9927635788917542,0.0,accept,unanimous_agreement
1430941067,12817,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1430941097,12817,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1433048835,12817,"i see we updated the tests, but we also need to document that. question is where? should that be done in rm_retainstring, rm_blockclient, rm_threadsafecontextlock? do you have a better idea?",0,0,0,0.9820360541343688,0.9776594042778016,0.9903745651245116,0.0,accept,unanimous_agreement
1436084241,12817,i'm trying to figure out this change. in the top comment i see this change (an addition of redismodule_ctx_thread_safe) is listed together with the fact we don't call updatestatsonunblock (which is a different change in this function). 1. can you please help me understand why it was needed. 2. what are the other side effects of this change,0,0,0,0.9335249662399292,0.9769470691680908,0.9355695843696594,0.0,accept,unanimous_agreement
1436325659,12817,"i think we should mention it on `rm_freestring`, `rm_retainstring`, and `rm_holdstring`. we should mentioned that those function are not thread safe and should only be called when the gil is held. we should decide if we want to document the exception about the `rm_freestring` in case you know you are the only owner.",0,0,0,0.9878103733062744,0.9927166104316713,0.9846845865249634,0.0,accept,unanimous_agreement
1436337636,12817,"p.s. for some reason i thought that rm_replywithstring will also be an issue, but now i see it doesn't touch the refcount. (at least not in the current implementation)",0,0,0,0.9762840270996094,0.9897434115409852,0.9791672229766846,0.0,accept,unanimous_agreement
1436412422,12817,"this one is linked to number 4 at the top, which says: trigger assertion first of all, an assertion isn't ""none"" it terminates the process and can cause data loss. maybe change it to ""low""? secondly this can also mess up the refcount, or cause double free and other issues that can lead to memory corruption. am i missing anything?",0,0,0,0.9027637243270874,0.983134388923645,0.9914199113845824,0.0,accept,unanimous_agreement
1436412887,12817,"this one at the top comment (number 2), says: but if that's just an access to a variable and then ignoring what we read from it, isn't that ""harm level: none""?",0,0,0,0.9397178888320924,0.9833182096481324,0.9799882173538208,0.0,accept,unanimous_agreement
1436427232,12817,"i discussed this with meir. context: calling rm_yield from a thread is meant to be done in case you locked the gil for a long period of time, and don't intend to release it, and meanwhile, want to reply with -busy. in this case, it is likely that that the main thread is already blocked trying to lock the gil. however, if server.hz is really low, and there are no clients with pending commands, we can imagine that the main thread's event loop is never gonna wake up, in which case rm_yield will hang (despite wishing to use ae_dont_wait). the alternative solution we wanna propose is that instead of adding the new mutex to guard the ae mechanism, we'll change the code so that we process these events from the main thread, instead of the module thread. 1. the module sets server.busy_module_yield_flags and server.busy_module_yield_reply. 2. the module sends a character on the pipe to cause the main thread's event loop to wake up. 3. the module unlocks the gil, waits for redis to reach the event loop once, and then re-locks the gil. p.s. if we agree on the direction, maybe we should extract this topic to another pr?",0,0,0,0.8966996073722839,0.878162682056427,0.9793293476104736,0.0,accept,unanimous_agreement
1436433581,12817,"you are right, it should be `none`.",0,0,0,0.9772742986679076,0.9902543425559998,0.987385630607605,0.0,accept,unanimous_agreement
1436441575,12817,"this is because both of them are fixed to ensure that `moduleblockedclienttimedout()` is thread-safe. the reason is: [code block] if the ctx is not to be `redismodule_ctx_thread_safe`, `aftererrorreply()` will be triggered if replying an error. if `redismodule_ctx_thread_safe` is used, all replies will be deferred. [a link]",0,0,0,0.9850770831108092,0.9953296184539796,0.9940856695175172,0.0,accept,unanimous_agreement
1436443612,12817,"my intention was that it was only caused by the module's use of api, not by the internal implement, so i chose `none`. let's change it to `low`.",0,0,0,0.984706461429596,0.9895548820495604,0.9929248094558716,0.0,accept,unanimous_agreement
1436473693,12817,"ohh, ok, maybe in addition to the ""harm level"", we can add some explicit ""trigger"", to specify that it depends on some rare case, and people can easily rule it out and know they're safe. or we can leave it as is, the scenario is there, it's just a little bit hard to understand if you're not keen on the details.",0,0,0,0.7508363723754883,0.8009024858474731,0.9501166939735411,0.0,accept,unanimous_agreement
1436801600,12817,"it seems to be working, i'll give it a shot.",0,0,1,0.8863970041275024,0.8642985820770264,0.5839805006980896,0.0,accept,majority_agreement
1438180926,12817,"we're missing the fact that `rm_yield()` can be called in the main thread, and if we want to proceed in that direction, we'll need to use old behavior in the main thread, and new direction in the module thread.",0,0,0,0.9783024787902832,0.9912173748016356,0.9815308451652528,0.0,accept,unanimous_agreement
1438835975,12817,"ok, let's do that. this brings back the detection of which thread we're running from, which is something we weren't happy with, but still i guess that's the right way forward.",0,0,0,0.9430839419364928,0.9505277276039124,0.9053756594657898,0.0,accept,unanimous_agreement
1448379648,12817,"now timeout and reply are all controlled by the thread, so we don't need these two callbacks and timeout.",0,0,0,0.9873570203781128,0.9914565682411194,0.9917988777160645,0.0,accept,unanimous_agreement
1448546966,12817,i think the point of that test was to interact with redis's timeout mechanism.,0,0,0,0.986052393913269,0.9832282066345216,0.9797472953796388,0.0,accept,unanimous_agreement
1448555258,12817,"yes, that's exactly what i was trying to say, the main thread wants to reply to the user in the middle of sleep of module thread. if we want to avoid the main thread triggering a timeout and let the module thread handle the time measure itself, we have to drop the timeout callback. that's what i'm struggling with.",-1,-1,0,0.8352287411689758,0.6500426530838013,0.6111738681793213,-1.0,accept,majority_agreement
1450460276,12817,"to ensure the point of that test, i think we need to add lock to protect it. first, we should clarify that rm_blockedclientmeasuretime*() api are not thread-safe. since module developers know they will use these apis in multiple threads, they should ensure these apis are safe to use. frequently locking and unlocking the gil is a bad idea, but using a local lock owned by the module might not be a bad idea.",0,0,0,0.8281468749046326,0.9750133156776428,0.9840019941329956,0.0,accept,unanimous_agreement
1451694283,12817,"this is repeated 3 times, let's add a method",0,0,0,0.980091631412506,0.9784266948699952,0.993536651134491,0.0,accept,unanimous_agreement
1451694379,12817,"ok, i'm fine with that. please add the comment in the api docs",0,0,0,0.963758945465088,0.8691936731338501,0.9226605296134948,0.0,accept,unanimous_agreement
1451730736,12817,done with [a link],0,0,0,0.9886857271194458,0.9809236526489258,0.9957758784294128,0.0,accept,unanimous_agreement
1451731117,12817,done with [a link],0,0,0,0.9886857271194458,0.9809236526489258,0.9957758784294128,0.0,accept,unanimous_agreement
1457563935,12817,"[code block] if you agree, mirror to the other apis with that comment.",0,0,0,0.9885608553886414,0.9884300231933594,0.9947465062141418,0.0,accept,unanimous_agreement
1671639900,12817,why did you remove `&& !bc->blocked_on_keys`?,0,0,0,0.9812058210372924,0.9944664835929872,0.9946349859237672,0.0,accept,unanimous_agreement
1671644342,12817,"ok i see you referred to my question in the previous post the thing is that, if the client is blocked on keys, `moduleunblockclientonkey` is called, which calls `updatestatsonunblock` so currently, `updatestatsonunblock` is called twice",0,0,0,0.9760225415229796,0.9932181239128112,0.9916792511940002,0.0,accept,unanimous_agreement
750250139,9748,how come these changes are here? and also not causing conflicts?,0,0,0,0.9731605648994446,0.9851884841918944,0.9755329489707948,0.0,accept,unanimous_agreement
750260362,9748,"so this function is no longer responsible of backing up the old configuration and restoring it. instead it relies on the caller to do that, by calling this function again. and it is no longer responsible of copying the new config to the server struct variables. instead it relies on the caller to do that before callng. so why does it clear the server struct config on failure? i think that should not be part of it's responsibility...",0,0,0,0.8464106917381287,0.9717147946357728,0.9313743114471436,0.0,accept,unanimous_agreement
750261558,9748,i'd like you to have a look at the changes in this function in the context of the recovery flow.,0,0,0,0.9780147075653076,0.977211594581604,0.9896327257156372,0.0,accept,unanimous_agreement
750263273,9748,is this change here to fix a bug?,0,0,0,0.9493417739868164,0.9872606992721558,0.9860671162605286,0.0,accept,unanimous_agreement
750271393,9748,"maybe we should add another test that tests a config with an apply function, and in some way actually test the restore worked? e.g. an `oom-score-adj-values` (test `/proc`, only on linux)?",0,0,0,0.9882726073265076,0.9955980181694032,0.989560604095459,0.0,accept,unanimous_agreement
750280754,9748,"wouldn't it be easier to have a value of 2 represent no changes done? (i.e. non-zero representing a different kind of success) in that case 0 would still indicate failure, and i suspect quite a few of your changes can be reverted.",0,0,0,0.9593365788459778,0.990602731704712,0.9451845288276672,0.0,accept,unanimous_agreement
750285969,9748,"not sure we want to reply the string back to the caller. i think some static form of invalid argument is enough. can be server.syntaxerr, a static more specific reply, or if you insist, reply the argc back the at caller.",0,0,0,0.9791380763053894,0.9224326610565186,0.9620569944381714,0.0,accept,unanimous_agreement
750287476,9748,afaik we never have non-sds encoded objects coming from networking.c,0,0,0,0.986578643321991,0.9818475246429444,0.9901134967803956,0.0,accept,unanimous_agreement
750289059,9748,"maybe in this one we do want to respond with a more specific error, if we can. maybe even a more explicit one for non-mutable configs. in which case, maybe we wanna `break` too?",0,0,0,0.9764987826347352,0.9880273342132568,0.9776650667190552,0.0,accept,unanimous_agreement
750291225,9748,we may wanna break from the two outer loops too (maybe check the `invalid_args` var in the loop exit condition?,0,0,0,0.9820123910903932,0.9917929768562316,0.9930490255355836,0.0,accept,unanimous_agreement
750293729,9748,let's have the test check that the correct error returns (the one from the setter or apply function),0,0,0,0.9872736930847168,0.99174702167511,0.9927270412445068,0.0,accept,unanimous_agreement
750300453,9748,"is it an ""invalid argument""? it could be any other type of (apply) failure?",0,0,0,0.9568086862564088,0.982815682888031,0.986791491508484,0.0,accept,unanimous_agreement
750310201,9748,are we sure it's completely valid for the new approach that the update function modifies the server struct value?,0,0,0,0.9873961806297302,0.9926122426986694,0.9929641485214232,0.0,accept,unanimous_agreement
750326299,9748,do we know why the old code used to refuse a request to shrink the config? (save memory),0,0,0,0.9846551418304444,0.9804562330245972,0.993341624736786,0.0,accept,unanimous_agreement
750329365,9748,actually i see we're still refusing to reduce the size of ae (silently ignoring the config),0,0,0,0.8292329907417297,0.858586847782135,0.971555233001709,0.0,accept,unanimous_agreement
750335017,9748,i see the old code didn't call tlsconfigure if it was already called in the past and the port is changed. please look at the downside of removing that condition.,0,0,0,0.9841808080673218,0.9689133763313292,0.9918057918548584,0.0,accept,unanimous_agreement
750350410,9748,"i'd rather avoid these renames. changes in this block have a high potential to cause unnecessary merge conflicts since each of these configs is just one line, so if an adjacent line is also changed it causes a useless conflict. also, even if in some pr / branch / release / fork, there are some other change to this line (like flags or alias), there's no need to cause cause a conflict. i think we can keep the terms ""update"" and ""apply"" mixed. p.s. i'm ok to change the tls block (no need to create / define apply aliases), i presume this block won't cause much conflicts",0,0,0,0.930213212966919,0.7067365646362305,0.9339094161987304,0.0,accept,unanimous_agreement
750961496,9748,i think i did this here originally in order to understand something and then cherry picked to a separate pr. there's no conflict because the change is identical. what do you suggest i do?,0,0,0,0.9765849709510804,0.9555522799491882,0.9825007319450378,0.0,accept,unanimous_agreement
750974839,9748,"looking at the branch of this pr, i see this block only once, and since there's no conflict, i suppose that we might get this block twice when we merge it. anyway, you have two options: 1. delete this code from your branch 2. rebase (merge unstable into your branch), and make sure the block only appears twice. either way, just make sure the diff between your branch and the `git merge-base` sha, shows no changes to this file (you can use the diff tool to revert them).",0,0,0,0.98237943649292,0.98051917552948,0.9880467653274536,0.0,accept,unanimous_agreement
750983944,9748,just copied the original logic: [a link] i'll gladly remove this as i'm not sure why it's there. the original assertion here was added more than 11 years ago (a375b077cc1da6afee6497749e4e3512caa757c7).,0,0,0,0.973345160484314,0.8340721130371094,0.9834632277488708,0.0,accept,unanimous_agreement
750987743,9748,"we **don't** want to break out of the loops, there's a comment above explaining why. if i'm missing something (or if you have a cleaner implementation than the ugly flag i put here) let me know.",-1,-1,0,0.7359324097633362,0.7198333740234375,0.5831223726272583,-1.0,accept,majority_agreement
750990786,9748,no break here on purpose. see: [code block],0,0,0,0.9877084493637084,0.9875176548957824,0.9882683157920836,0.0,accept,unanimous_agreement
750994566,9748,"it's tricky having a mutable error message since we're returning a static string pointer. it's possible doing this with a static (global) buffer. i saw we do this in at least once other similar case. but i don't like that idea that much. i think ""unrecognized parameter"" is pretty informative. i'll consider adding another message for the immutable config case.",-1,-1,-1,0.9262707233428956,0.935238242149353,0.5381690859794617,-1.0,accept,unanimous_agreement
751010089,9748,what do you mean?,0,0,0,0.9683603048324584,0.9843899607658386,0.9906946420669556,0.0,accept,unanimous_agreement
751013519,9748,the assumption is that if we failed it's because the input arguments to `config set` were bad. so it's always a bad argument issue and there's the extra `errstr` to help here. for example if you try to `config set dir /some_dir_that_doesnt_exist` then i can claim the path argument was invalid and i get this: `err invalid arguments - no such file or directory`. if you really think this is wrong i'll change it to something like `config set failed - %s`. let me know.,0,0,0,0.910304307937622,0.9818325042724608,0.9815371632575988,0.0,accept,unanimous_agreement
751016598,9748,good question but as far as i can think of it's a valid approach. this is the only way to cap the value implicitly and not return an out of range error.,1,1,1,0.7031540274620056,0.6384432911872864,0.9378362894058228,1.0,accept,unanimous_agreement
751017770,9748,"yes, i know it's old and outdated, i think we should use this opportunity to clean it up.",0,0,0,0.7016507983207703,0.9541842937469482,0.7147921919822693,0.0,accept,unanimous_agreement
751019823,9748,see comment below.,0,0,0,0.9795164465904236,0.9845473170280457,0.99399995803833,0.0,accept,unanimous_agreement
751020472,9748,i think this check is enough and the original approach of ignoring the new value is the same as ignoring the currently applied set size.,0,0,0,0.9801784157752992,0.9838159680366516,0.9810201525688172,0.0,accept,unanimous_agreement
751021123,9748,"ok, missed that comment. in theory, maybe we don't have to redact configs in invalid commands. i.e. what if someone messes the order of `field / value` and puts the password as the config name, and the `masterauth` string as the value? we can't / won't handle that. but i suppose minimal effort on valid syntax and common mistakes is ok. so let's keep your code.",0,0,0,0.9271773099899292,0.8917056918144226,0.8952516317367554,0.0,accept,unanimous_agreement
751023296,9748,"i suppose the easy way out is: 1. only report the right error message on the first error you encounter (but still have a specific error message for that issue). 2. keep running the loop just for the sake of redaction, but don't override the error message if already set. in any case, i do think we wanna have specific error message, to let user figure out the problem faster.",0,0,0,0.974538803100586,0.9647802710533142,0.976909637451172,0.0,accept,unanimous_agreement
751023833,9748,"i thought about it, the down side is that we don't waste time re-configuring tls (and loading cert files etc) when changing a port. this makes sense because a port change isn't really related to tls configuration. but now we have a mechanism in the `.set` interface to return 2 when there's no change. so if there's no port change we won't call the apply function anyway. the idea was that for any place we use to have a quick exit in the update function because of no change we now have a generic mechanism to handle this and there's no need for the `prev` val in the apply function (for this use case) anymore.",0,0,0,0.9217036366462708,0.987986981868744,0.8641288876533508,0.0,accept,unanimous_agreement
751026470,9748,"i mean that i'm worried that in some way, the speific error message from either the set function or the apply function will get somehow lost in the recovery code. so i wanna add a test that verifies we got the right error message. i.d like to have two tests, one in which there's a failure in the set function and one in which there's a failure in the apply function, and in both it'll be nice if it's the second config out of a set of 3 (so the recovery will have some loops).",-1,0,0,0.7130329012870789,0.6817684173583984,0.7204506993293762,0.0,accept,majority_agreement
751027928,9748,"i think `config set failed - %s` is better, since i think some failures are due to runtime problem (port already in use or such), so it's not really an invalid config, it's just that it failed.",0,0,0,0.9747673273086548,0.9884499311447144,0.9810999035835266,0.0,accept,unanimous_agreement
751029941,9748,"for the record, i do have a plan to clamp many configs to more appropriate ranges, but i don't wanna introduce a breaking change (don't wanna error in case someone currently passes an insane value). so some day soon, i'd like to introduce some automatic clamping flag to config.c. till then, i just wanted to be sure these two lines don't violate anything of the new approach.",0,0,0,0.825196385383606,0.7407569885253906,0.9709487557411194,0.0,accept,unanimous_agreement
751032422,9748,"ok, i still wonder why we do that, but since we didn't change the logic much, we can dismiss that concern for another day.. so the old code used to completely ignore an ask to reduce the size (both the ae array and the fd limit). and the new code just limits the ae array shrinkage?",0,0,0,0.7458544373512268,0.9135951399803162,0.6972990036010742,0.0,accept,unanimous_agreement
751034520,9748,"ok, but when changing the port we still do an unnecessary re-init of tls, maybe this function should do some optimization on that? maybe not by checking the port, but by checking if we're already initialized?",0,0,0,0.985903024673462,0.9848257899284364,0.9884748458862304,0.0,accept,unanimous_agreement
751036163,9748,"yes. i think i needed to make sure that even if the port change fails on `listentoport` or `createsocketaccepthandler` or something else we still end up with the old socket closed. this way the automatic restore mechanism on failure can simply restore the previous port. the old implementation left the old port open on failure which might have been ok, but the new code can't assume that and has it's own restore mechanism that needs to assume the old port isn't open.",0,0,0,0.9755913019180298,0.9883776307106018,0.9860969185829164,0.0,accept,unanimous_agreement
751037799,9748,"fyi, you have `assert_error`",0,0,0,0.9779276847839355,0.9268420338630676,0.9937000274658204,0.0,accept,unanimous_agreement
751047511,9748,":+1: i'll remind you that i had a specific talk with you about whether or not we should redact on invalid configs and we even checked to see in monitor what would be the effect of this. i also gave the example of cases where redact won't work, like switching the order of confg-value pairs. finally you said, lets be on the safe side and keep the original logic.",0,0,0,0.6351447105407715,0.8936148285865784,0.7543047070503235,0.0,accept,unanimous_agreement
752016837,9748,"in order to test the restore woks for failed applies we need somehow to provide a config value that will consistently pass the set() function and will fail the apply() function. this is, by definition, an unexpected scenario. for `oom-score-adj-values` the range and validity is checked in the set() function so i can't see how i'll get the apply to fail. i'll try to do something for `port` which might be easier and portable to get to fail.",0,0,0,0.930616855621338,0.982397437095642,0.94155615568161,0.0,accept,unanimous_agreement
752042800,9748,added another test for apply errors using `port` please re-review.,0,0,0,0.9855058193206788,0.9917512536048888,0.9950384497642516,0.0,accept,unanimous_agreement
752049805,9748,"i'd like to add another config before the port (like you did with maxmemory above), so we can test the first one was reverted too. ideally, it would be one with an apply function, which we can test too (like oom-score-adj, but preferably not one that's platform specific)",0,0,0,0.9767343997955322,0.9926584362983704,0.99208003282547,0.0,accept,unanimous_agreement
752050542,9748,not sure the current connection has chance to get interrupted. maybe open a new one for the check?,0,0,0,0.7877913117408752,0.9431993961334229,0.957361340522766,0.0,accept,unanimous_agreement
752082124,9748,fixed. please re-review.,0,0,0,0.9789143800735474,0.97300785779953,0.9910253286361694,0.0,accept,unanimous_agreement
752113484,9748,":+1: done, please re-review.",0,0,0,0.7397423982620239,0.7108584642410278,0.8907920122146606,0.0,accept,unanimous_agreement
752256998,9748,"even if we add some auto clamping mechanism it'll just make this redundant, no need to worry about it now.",0,0,0,0.7850707173347473,0.97686505317688,0.9633387327194214,0.0,accept,unanimous_agreement
752263286,9748,"i couldn't find any other good apply function other than port (except tls, but then the test becomes tls specific). i did however add more configs before/after `port` so i think we can resolve this.",0,0,0,0.9803869128227234,0.9796624779701232,0.99029541015625,0.0,accept,unanimous_agreement
752266128,9748,i think it must have been disconnected since we close the listening socking in the server and re-open it in the restore phase. i think test suit's auto-reconnect kicked in. but just in case i'll change to an explicit new connection.,0,0,0,0.9820445775985718,0.9789565205574036,0.990264892578125,0.0,accept,unanimous_agreement
752304541,9748,yes.,0,0,0,0.969875693321228,0.98186594247818,0.9851860404014589,0.0,accept,unanimous_agreement
752389715,9748,i'm not sure it's a big deal to re-init here but it definitely seems redundant in case we changed the port but tls was already configured. i can easily fix this by adding a `int tlsisconfigured()` function in _tls.c_ and do: [code block] it seems that any other way will require accessing internal _tls.c_ stuff (or passing the `prev` argument). this seems nicer to me than assuming tls is configured based on the old port setting. does this make sense? can i add this new api to _tls.c_?,0,0,0,0.6353766322135925,0.9329236745834352,0.9431952834129332,0.0,accept,unanimous_agreement
753806022,9748,ok - fixed.,0,0,0,0.9783158898353576,0.9759753942489624,0.9834203720092772,0.0,accept,unanimous_agreement
753851760,9748,"what about `oom-score-adj-values`? in order to properly validate that, the tcl code will need to have some linux specific portion, but maybe it's not that bad.",0,0,0,0.9334962368011476,0.9521560668945312,0.9821471571922302,0.0,accept,unanimous_agreement
753985100,9748,"i can do this, but then the test will run only on linux and i don't like it that much. if you're sure it's better to have the linux specific test here than what's currently there then let me know. my default is not to change it.",-1,-1,0,0.9247982501983644,0.9040658473968506,0.56654953956604,-1.0,accept,majority_agreement
754017083,9748,"i didn't mean that the test will run only on linux, just that the part of verifying the rollback was done correctly (looking into `/proc` will be linux specific. p.s. i don't mind such a test being linux specific since: 1. linux is our main target platform. 2. if we test that logic on linux, there's no reason to assume it'll somehow get broken on another platform. anyway, if you don't think it worth the effort you can drop it. it's just that this rollback mechanism is complicated, and has multiple steps, so i feel it should be tested heavily.",0,0,0,0.5568968653678894,0.8117164969444275,0.8029292225837708,0.0,accept,unanimous_agreement
754533698,9748,nit: use explicit function type to be consistent with the rest of the fields.,0,0,0,0.9869728684425354,0.9911647439002992,0.992175281047821,0.0,accept,unanimous_agreement
754538323,9748,"not sure about panicing here. this should of course never happen, and if it does - it's either * a bug * some external state. for example, you overwrite a tls cert file and use `config set` to force a reload. file is corrupt so the reload fails, but so will the revert. in both cases, terminating without providing any option to remediate seems a bit harsh and potentially very risky.",-1,-1,-1,0.9083576202392578,0.7083662748336792,0.8269257545471191,-1.0,accept,unanimous_agreement
754540685,9748,"not sure if it's still relevant, but is having a static non-mutable string here so important? saves some boilerplate code, but returning an allocated string might give us more flexibility.",0,0,0,0.9835408329963684,0.9613392949104308,0.9046765565872192,0.0,accept,unanimous_agreement
754546399,9748,-steinberg it makes sense. although i'm not sure we won't run into the need to supply `apply` with the `prev` config elsewhere.,0,0,0,0.9743767380714417,0.9836596250534058,0.9439916610717772,0.0,accept,unanimous_agreement
754548908,9748,"lgtm, unless i'm missing something here - it's basically the same revert logic that gets applied globally now.",0,0,0,0.9813398718833924,0.991004467010498,0.9860796332359314,0.0,accept,unanimous_agreement
754948702,9748,should be `c->argc % 2` ?,0,0,0,0.9886749982833862,0.9938306212425232,0.993084192276001,0.0,accept,unanimous_agreement
755043875,9748,did it and it indeed found some bugs. fixed them. please review.,0,0,0,0.9343446493148804,0.9612841606140136,0.7399032115936279,0.0,accept,unanimous_agreement
755054084,9748,the basic design is that during the _set_ phase you can check the _prev_ value. the _apply_ phase is there just to apply the current setting. this simplifies the implementation but brings a bit less flexibility - like forcing the apply functions to be idempotent but i feel this is actually a simplification which is worth it. anyway added `tlsisconfigured`.,0,0,0,0.7611070871353149,0.889987587928772,0.7230371236801147,0.0,accept,unanimous_agreement
755055189,9748,"i agree, but somehow i didn't change it during development and now i think it's not that relevant. perhaps the next time we need some fancy error string we'll change this entire mechanism and add the extra flexibility.",0,0,0,0.9603330492973328,0.9219634532928468,0.951081156730652,0.0,accept,unanimous_agreement
755065823,9748,oops :person_facepalming:. thanks. fixed.,1,1,-1,0.9737238883972168,0.9937041401863098,0.9555111527442932,1.0,accept,majority_agreement
755069125,9748,"i agree. i wasn't sure about this either. my approach was to avoid staying in an undefined state, which seems to me the only sane way to handle this other than panicking. so the other option would be to report an error and just ignore the failure. wdyt?",0,0,0,0.8701881766319275,0.6428934335708618,0.7444697618484497,0.0,accept,unanimous_agreement
755071914,9748,it's just that i use this type for an array of (unique) function pointers to be applied after _set_ or during restore after failure. i wanted to avoid the risk of someone changing the function type in one place and not the other.,0,0,0,0.961462140083313,0.9883670210838318,0.9902655482292176,0.0,accept,unanimous_agreement
755438545,9748,i think this would be better.,0,0,0,0.9071467518806458,0.9535861611366272,0.946835160255432,0.0,accept,unanimous_agreement
755533475,9748,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
760180949,9748,it looks like this will cause ci to fail (in my daily ci) mac: [a link] freebsd: [a link] [code block] maybe we should readd `if (server.oom_score_adj == oom_score_adj_no) return c_ok;` ?,0,0,0,0.9820997714996338,0.9915191531181335,0.9932162165641784,0.0,accept,unanimous_agreement
760216884,9748,"thanks for reporting. the reason we removed it so that when this config is disabled (after being enabled), it'll remove the previously set adjustment. i.e. [code block] i.e. the last line will undo the changes as if it was never enabled. what i don't yet understand is why the `config sanity` fails on that. iirc what that test does it config get, and then config set with the value it got from get. and iirc the config infra is suppose to catch these no-op things today and avoid calling the apply function. can you please look into that? regardless, i see another issue with that change. let's say the user never enabled `oom-score-adj`, but as soon as he's setting `oom-score-adj-values` to a new value, we'll get here and try to apply the startup adjust (`oom_score_adj_base`).",1,1,1,0.6025451421737671,0.8107614517211914,0.9580783247947692,1.0,accept,unanimous_agreement
760352406,9748,"[code block] it looks like this failed, `createspecialconfig` does not catch no-op things, those `special` commands are not checked that part",0,0,0,0.8776232004165649,0.984939992427826,0.99228173494339,0.0,accept,unanimous_agreement
760371559,9748,"ohh, right. special configs don't do that. ok, the easy way out is to add these oom-score* configs to the `skip_configs` list. the only reason this test used to pass so far is because it feeds back to redis the same value it got from config get, and thus the oom-score-adj was always disabled, so even when it ""modified"" oom-score-adj-values, it didn't do anything. can you please make a pr right away, so the daily ci doesn't fail? the next thing would be to add explicit tests around these two configs: 1. to make sure that when disabling oom-score-adj, it reverts what it did when it was enabled. 2. make sure that setting either of these two configs when oom-score-adj is disabled, it will not try to modify `/proc` and fail on non-linux systems. 3. consider improving the ""special"" oom-score-adj-values config to detect no-op changes and skip them. we can leave that task of 3 tests and config improvement for -steinberg to handle when he's back. in theory, if we did all 3 of the above (or even somehow just do 2, without breaking 1), there was no need to add them to the `skip_configs` list, but if we'll add specific sanity tests for them anyway, i think it's safe to skip them. p.s. that whole `config sanity` is kinda useless now that everything in the config goes from a config framework... in the past each config had special hand written code, and this test (which is also relatively new) exposed some inconsistencies.",0,0,0,0.8689712882041931,0.941477119922638,0.9215802550315856,0.0,accept,unanimous_agreement
760381899,9748,"so what i need to do now is to add `oom-score-adj` and `oom-score-adj-values` to skip_list? i try it on my mac, the test also fails on `config set rollback on apply error` ... i am working on it",0,0,0,0.9526797533035278,0.9611391425132751,0.9897010326385498,0.0,accept,unanimous_agreement
760829480,9748,"a quick fix, handled in #9881",0,0,0,0.9852327704429626,0.9806185364723206,0.9553955793380736,0.0,accept,unanimous_agreement
760923087,9748,so i'll find a solution for 2 above where the user can manipulated `/proc` on their own and even if we write to `oom-score-adj-values` they don't need to worry redis will overwrite `/proc` as long as `oom-score-adj` is `no`.,0,0,0,0.9858436584472656,0.9916048049926758,0.9923123717308044,0.0,accept,unanimous_agreement
775282049,10004,aren't you leaking the library (dict value) this way?,0,0,0,0.97359961271286,0.9834223985671996,0.9939245581626892,0.0,accept,unanimous_agreement
775282114,10004,"if you'll move the memory accounting to the ""constructor"" and ""destructor"", you'll be able to replace all of that with dictclear or alike",0,0,0,0.9884610176086426,0.993918776512146,0.9925509691238404,0.0,accept,unanimous_agreement
775282342,10004,"would be nice to nullify the `iter` here (and test for null at the botto), so in case we have other (later) `goto done`, they won't break.",0,0,0,0.9360921382904052,0.99227374792099,0.986977517604828,0.0,accept,unanimous_agreement
775282530,10004,let's nullify `iter` here and in the other two places,0,0,0,0.9866591691970824,0.9937645196914672,0.9932589530944824,0.0,accept,unanimous_agreement
775283071,10004,"this is a little bit inefficient (each linking searches for dup functions, and if later reverted will search for dups again) maybe we can pass a flag to avoid that (since in these case we know there are no collisions)? or maybe instead of making a ""backup"" library, we'll just make a backup list? (will avoid the excessive collision search on one way). i.e. we mostly care for an optimized happy path.",0,0,0,0.5360991358757019,0.9239862561225892,0.9149086475372314,0.0,accept,unanimous_agreement
775283316,10004,"in case we just passed through the `!replace` flow, then this loop is excessive (it won't find anything). so we can make it an ""else if"" for the `!replace` loop. or we can unify both loops into one, and just have a branch when there's a hit.",0,0,0,0.9706892371177672,0.9881721138954164,0.9918699264526368,0.0,accept,unanimous_agreement
775283457,10004,why bother nullify `entry` before these dict iterations?,0,0,0,0.9359169602394104,0.9827552437782288,0.9706763029098512,0.0,accept,unanimous_agreement
775284128,10004,i think it should be [code block],0,0,0,0.984362244606018,0.9864540696144104,0.9851314425468444,0.0,accept,unanimous_agreement
775284248,10004,"maybe we should note that even in replace, there could still be collision in function names. actually that's not that important here, but we need to remember that detail for the actual documentation.",0,0,0,0.9838371872901917,0.9772806763648988,0.9830152988433838,0.0,accept,unanimous_agreement
775284551,10004,"if we do add a flag to skip the collision check, here's another place to use it.",0,0,0,0.9862772822380066,0.9925328493118286,0.9927794337272644,0.0,accept,unanimous_agreement
775284583,10004,let's give it an better name. `oldlib`?,0,0,0,0.9820589423179626,0.9915613532066344,0.9908742904663086,0.0,accept,unanimous_agreement
775284715,10004,let's add a comment saying what's it for and what it does.,0,0,0,0.9765263199806212,0.9774611592292786,0.994375467300415,0.0,accept,unanimous_agreement
775284819,10004,still missing the arguments description,0,0,0,0.9651336669921876,0.9837480783462524,0.975600242614746,0.0,accept,unanimous_agreement
775284902,10004,"deferring length comes with a price (system calls and packets). maybe we can use it only in case a pattern is provided, and use pre-determined length when we can.",0,0,0,0.9882556200027466,0.9918050765991212,0.9902127385139464,0.0,accept,unanimous_agreement
775285532,10004,who knows if we'll add more args in the future.. [code block],0,0,0,0.9831416606903076,0.9834094047546388,0.9699454307556152,0.0,accept,unanimous_agreement
775286852,10004,"this code is not specific to functions, right? so maybe in eval this `if` is not reachable, but it still looks a bit odd to refer to ""functions"" here.",-1,0,-1,0.5454866886138916,0.6768372654914856,0.7637542486190796,-1.0,accept,majority_agreement
775287023,10004,"maybe it would be more readable to have two calls for `lua_pcall`, each with a different set of arguments.",0,0,0,0.984978973865509,0.9940162897109984,0.96735817193985,0.0,accept,unanimous_agreement
775288156,10004,make sure to list that interface change,0,0,0,0.9782735705375672,0.9649004340171814,0.9950815439224244,0.0,accept,unanimous_agreement
775760804,10004,"no, unlink does not free the libraryinfo, it just remove it from librariesctx",0,0,0,0.9790761470794678,0.9832845330238342,0.9925813674926758,0.0,accept,unanimous_agreement
775761442,10004,its not related to the distributor of libraryinfo. the libraryinfo has no knowledge about which librariesctx it is located in.,0,0,0,0.9490355849266052,0.8716052770614624,0.989467203617096,0.0,accept,unanimous_agreement
775765180,10004,listed on the top comment.,0,0,0,0.9808523058891296,0.9867026209831238,0.991771638393402,0.0,accept,unanimous_agreement
775798184,10004,changed to backup list,0,0,0,0.983403980731964,0.9923911690711976,0.9911128878593444,0.0,accept,unanimous_agreement
775801310,10004,do you think its that critical? it should not happened a lot and it can actually help spot bugs (the return value is asserted).,0,0,0,0.9855603575706482,0.9721688628196716,0.9823678731918336,0.0,accept,unanimous_agreement
775814500,10004,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
775814601,10004,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
775819773,10004,unified to a single loop,0,0,0,0.9861543774604796,0.966198980808258,0.9882310032844543,0.0,accept,unanimous_agreement
775819872,10004,"no reason, removed.",0,0,0,0.806434690952301,0.972270369529724,0.9756168127059937,0.0,accept,unanimous_agreement
775820074,10004,"added here also, will also make sure to mentioned it on documentation.",0,0,0,0.978857398033142,0.9906816482543944,0.9934220910072328,0.0,accept,unanimous_agreement
775820182,10004,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
775820264,10004,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
775820309,10004,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
775820355,10004,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
775820423,10004,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
775820505,10004,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
775923808,10004,i see you have a few more of these redundant lines.,0,0,0,0.9822418689727784,0.632813572883606,0.9800216555595398,0.0,accept,unanimous_agreement
775924909,10004,the var name is wrong (not a ctx),0,0,0,0.8460528254508972,0.8971980810165405,0.6808400750160217,0.0,accept,unanimous_agreement
775926587,10004,let's add a comment explaining the difference between the two,0,0,0,0.98040109872818,0.9862339496612548,0.9949766993522644,0.0,accept,unanimous_agreement
775927821,10004,"now it only happens in the non-happy path, but still there could be many (hundreds of) functions. so librarylink has two loops on that entire list (one for re-insertion, which we can't avoid), and the other one for collision check. i think that adding an argument and a single line `if` is a very low price to pay to avoid an excessive loop which could maybe be big.",0,0,0,0.9402450919151306,0.7073491215705872,0.9662550687789916,0.0,accept,unanimous_agreement
775981767,10004,"this is the variable definition, you want to not initialised it either?",0,0,0,0.9784584641456604,0.989782989025116,0.9948607087135316,0.0,accept,unanimous_agreement
775982352,10004,"ohh, sorry, i missed the fact it creates the variable here. ignore me.",-1,-1,-1,0.987813115119934,0.9918519854545592,0.9867106080055236,-1.0,accept,unanimous_agreement
775995571,10004,"because there was only one place that was actually needed this verification, i moved it outside of the `librarylink` function. let me know what you think.",0,0,0,0.987070083618164,0.9835184812545776,0.9878697991371156,0.0,accept,unanimous_agreement
776023641,10004,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
776023702,10004,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
776029111,10004,lgtm,0,0,0,0.9795994758605956,0.7242414951324463,0.9618706703186036,0.0,accept,unanimous_agreement
777650254,10004,extra line,0,0,0,0.9743177890777588,0.971166491508484,0.994001805782318,0.0,accept,unanimous_agreement
777650391,10004,please add comments that are a lot more verbose,0,0,0,0.9627060890197754,0.5094058513641357,0.9862008690834044,0.0,accept,unanimous_agreement
777651521,10004,"let's extract this to a function, and improve the doc comments",0,0,0,0.9859840273857116,0.9872495532035828,0.9934282898902892,0.0,accept,unanimous_agreement
777654382,10004,"maybe we should re-consider the api name. it can still be a different object at each time, but it can have the same name so that the user won't know he's working on a different api object. do you think the new name serves us to avoid exposing the wrong apis, or also serves the user to understand he's working with a different set of apis?",0,0,0,0.9743717312812804,0.984878957271576,0.9835467338562012,0.0,accept,unanimous_agreement
777654798,10004,add a comment why we do that,0,0,0,0.9733880758285522,0.9749290943145752,0.9936633110046388,0.0,accept,unanimous_agreement
777922865,10004,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
777923246,10004,added explanations and links for further reading.,0,0,0,0.976842999458313,0.9838702082633972,0.8411140441894531,0.0,accept,unanimous_agreement
777923321,10004,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
777923415,10004,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
778091184,10004,"maybe also refer to `luaenableglobalsprotection` and explain the differences? in which case, maybe it should be below it?",0,0,0,0.9864068627357484,0.9951855540275574,0.9943695664405824,0.0,accept,unanimous_agreement
779471630,10004,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
959454858,11199,"i don't like that user config. maybe it could be the module that sets it? maybe it can be hard coded? or maybe no config is needed at all, and a misbehaving module / combination would cause an infinite loop?",-1,-1,-1,0.9818693995475768,0.9479507803916932,0.9558942914009094,-1.0,accept,unanimous_agreement
959462416,11199,maybe this should become optional (free_pd can be null),0,0,0,0.988091230392456,0.9899681806564332,0.9871800541877748,0.0,accept,unanimous_agreement
959463604,11199,"if we end up dropping the config, we need to drop this text.",0,0,0,0.9780201315879822,0.9853363633155824,0.9910520911216736,0.0,accept,unanimous_agreement
959485239,11199,"maybe it'll be a good idea to document what this module logically does, so it'll be easier to read its code. maybe instead of the big copyright and liability statement 8-)",1,1,1,0.8531697988510132,0.7553162574768066,0.7730078101158142,1.0,accept,unanimous_agreement
963593878,11199,"not only a module that misbehaving can cause an infinite loop, it might be a combination of two modules that running alone will behave just right but together will cause an infinite loop. this is why i thought to protect it on the redis level and print a warning. if we allow module to set it then what happened if multiple modules set it? we will take the highest value?",0,0,0,0.9344560503959656,0.7370411157608032,0.9245651364326476,0.0,accept,unanimous_agreement
963620962,11199,"yes, we can take the higher value, or the sum... not sure about the details, but i'm pretty sure it shouldn't be a user config.",0,0,0,0.9412364363670348,0.8679901361465454,0.9832528829574584,0.0,accept,unanimous_agreement
973934117,11199,i removed the configuration value and created a module api to set it. default is 1000. i also updated the top comment.,0,0,0,0.9878596663475036,0.9926921725273132,0.9947682619094848,0.0,accept,unanimous_agreement
973974911,11199,add afterdatasetchange,0,0,0,0.9884222149848938,0.9898574352264404,0.9938350915908812,0.0,accept,unanimous_agreement
973975664,11199,add some tests with two modules,0,0,0,0.9859522581100464,0.9875816106796264,0.9941510558128356,0.0,accept,unanimous_agreement
973976013,11199,redundant,0,-1,0,0.9539549946784972,0.8220753073692322,0.8288995623588562,0.0,accept,majority_agreement
973980061,11199,check replication order of lazy-expire inside postjob,0,0,0,0.985909938812256,0.9882035851478576,0.9877787232398988,0.0,accept,unanimous_agreement
973986835,11199,delete empty line,0,0,0,0.9684393405914308,0.9395154118537904,0.9901198148727416,0.0,accept,unanimous_agreement
977316642,11199,"it is delete, do you mean to return it?",0,0,0,0.9827476143836976,0.9901911020278932,0.9928717017173768,0.0,accept,unanimous_agreement
977368796,11199,test was added,0,0,0,0.9839593768119812,0.9888808727264404,0.9944243431091307,0.0,accept,unanimous_agreement
977387060,11199,test was added.,0,0,0,0.983665943145752,0.9892733693122864,0.9939583539962769,0.0,accept,unanimous_agreement
977863570,11199,perhaps we can get rid of core_propagates and use `if (server.in_nested_call == 0)` here and `if (server.module_ctx_nesting == 0)` in the other places it's used i think it will achieve the same goal (prevent afterdatasetchange from doing stuff while not at the top-most level of command execution),0,0,0,0.9870607852935792,0.9923866987228394,0.9849038124084472,0.0,accept,unanimous_agreement
977863787,11199,remove,0,0,0,0.9725990891456604,0.947705328464508,0.9896913170814514,0.0,accept,unanimous_agreement
977895438,11199,please document this bugfix in the top comment,0,0,0,0.934401512145996,0.9904208183288574,0.992954432964325,0.0,accept,unanimous_agreement
977898582,11199,please add a warning about the infinite recursion that could occur,0,0,0,0.983977735042572,0.9365140199661256,0.993540346622467,0.0,accept,unanimous_agreement
977899108,11199,please update,0,0,0,0.9838215112686156,0.9846460223197936,0.99217426776886,0.0,accept,unanimous_agreement
977912090,11199,lets do it on another pr? i want to keep this pr easy to cherrypick.,0,0,0,0.967185080051422,0.985603928565979,0.9896706938743592,0.0,accept,unanimous_agreement
977921620,11199,so in that case let's drop afterdatasetchange and call firepostkeyspacejobs from propagatependingcommands,0,0,0,0.9879388809204102,0.9932335019111632,0.994024693965912,0.0,accept,unanimous_agreement
977922023,11199,yes,0,0,0,0.9564858078956604,0.9659429788589478,0.9686408638954164,0.0,accept,unanimous_agreement
979378474,11199,"considering the rename, and also considering #9406 and #11310, i think we should drop the `if (server.also_propagate.numops > 0)`, we can move it inside the function if needed.",0,0,0,0.9881476759910583,0.993751347064972,0.9897790551185608,0.0,accept,unanimous_agreement
979379251,11199,"i agree, i think we need to modify these `if`s to look at nesting level and other variables, and not on anything specific to propagation. is your comment about cherry picking because this code is already different in 7.0? or because you want the change to be conservative (not have any side effects if the feature isn't used)? let's put the time to map the side effects of such a change so that we feel comfortable with it.",0,0,0,0.9741814136505128,0.9679131507873536,0.9686322212219238,0.0,accept,unanimous_agreement
979379434,11199,this should be done with backticks [code block],0,0,0,0.9879262447357178,0.9941349625587464,0.9958629608154296,0.0,accept,unanimous_agreement
979379652,11199,"considering #9406, #11310, and maybe other campaigns, maybe we should rename this api to be more purpose generic (not only about keyspace notifications)",0,0,0,0.984126091003418,0.9928094148635864,0.9891349077224731,0.0,accept,unanimous_agreement
979380208,11199,"i think part of this warning is already covered in rm_subscribetokeyspaceevents. i don't think we should repeat ourselves, and also i wanna make this api more ""general-purpose"". let's make sure all the ksn specific concerns are placed in rm_subscribetokeyspaceevents, and make this one more generic",0,0,0,0.9764085412025452,0.9555520415306092,0.9624709486961364,0.0,accept,unanimous_agreement
979380487,11199,need to document that new option in rm_setmoduleoptions,0,0,0,0.9854233264923096,0.9940104484558104,0.9953479170799256,0.0,accept,unanimous_agreement
979380712,11199,"the warning needs to be in rm_setmoduleoptions. the text here can also include some hint about the warning, but should probably be kept lean.",0,0,0,0.988709270954132,0.9937798380851746,0.9922530055046082,0.0,accept,unanimous_agreement
979380993,11199,another case where i think it's wrong to condition afterdatasetchange on a propagation related variable. maybe it can be moved to inside afterdatasetchange if needed.,0,0,0,0.8997465372085571,0.9833637475967408,0.9781162738800048,0.0,accept,unanimous_agreement
979381473,11199,"maybe do some strncmp or alike, and add a comment that it's just to smoke out issues.?",0,0,0,0.9432972073554992,0.9798761606216432,0.988288640975952,0.0,accept,unanimous_agreement
979387724,11199,"i want it to be conservative so we will not be afraid to cherrypick it, i can apply all your suggestions to unstable on another pr.",0,0,0,0.8682402968406677,0.605426549911499,0.9890040755271912,0.0,accept,unanimous_agreement
979389759,11199,"i see that on #9406 we chose to go with server event and not key space notification. do you want this mechanism to be used there as well? i am not sure its right, for key space notifications we can generally instruct not to perform any writes inside them, but for server events we will need distnguish between events and state which events are safe to write and which require this new api? i wonder if we made the right move, maybe unlink should have been a key space notification?",0,0,0,0.965205192565918,0.903335452079773,0.9470616579055786,0.0,accept,unanimous_agreement
979391064,11199,i prefer to do those changes on a follow up pr so this pr will be safer for cherrypick.,0,0,0,0.9555220007896424,0.979434847831726,0.9852643609046936,0.0,accept,unanimous_agreement
979391374,11199,"removed and add reference to `rm_subscribetokeyspaceevents`. regarding generalise the api, other then unlink (which i wrote [a link] i believe we should reconsider the chose we made), what other places do you think this api can be used?",0,0,0,0.987802803516388,0.9906783103942872,0.9946768283843994,0.0,accept,unanimous_agreement
979391466,11199,as i wrote here: [a link] i prefer to do it on separate pr if you agree.,0,0,0,0.97073632478714,0.9684820771217346,0.9951735138893129,0.0,accept,unanimous_agreement
979391533,11199,as discussed with i will remove this fix from here and will do it on separate pr.,0,0,0,0.9875154495239258,0.9900784492492676,0.9950986504554749,0.0,accept,unanimous_agreement
982255550,11199,i'm not 100% certain if unlink should be a ksn or a server event. it could go either way. but i think it doesn't matter for the purpose of this pr. it should be ok to say that in some server events you are allowed to do modifications and in others you're not allowed. and i think the api name in this pr should be generic enough so that people can use it in various places.,0,0,0,0.9141271710395812,0.9760043621063232,0.921280801296234,0.0,accept,unanimous_agreement
982260366,11199,"i'm ok being conservative for a while and do some cleanup later, but for this to be effective, we need to open a big time gap between the merging of the first pr and the second. in any case, even if we want to be conservative (i.e. avoid risk of any bugs from this change when the new api isn't used), i think we still need the code to make sense. and it's odd to see a call to `afterdatasetchange` that's inside a condition on `core_propagates`. so maybe the middle ground is to call `afterdatasetchange` unconditionally, but pass a boolean argument specifying whether or not it should call `propagatependingcommands`",0,0,0,0.5428829789161682,0.7579795122146606,0.8998810052871704,0.0,accept,unanimous_agreement
990744372,11199,"ok, i will generalise it.",0,0,0,0.9813515543937684,0.9834770560264589,0.992544412612915,0.0,accept,unanimous_agreement
990770677,11199,"as discussed, api will be generalised but currently will be documented that it can be used on key space notifications.",0,0,0,0.9889971017837524,0.9928382039070128,0.993854820728302,0.0,accept,unanimous_agreement
992337093,11199,returned `afterdatasetchange` and called it `postunitoperations`. rearrange `server.core_propagates` conditions will be done on a followup pr to unstable only (as discussed).,0,0,0,0.9888591766357422,0.9953533411026,0.9952431321144104,0.0,accept,unanimous_agreement
992337783,11199,dropped,0,0,0,0.9455007910728456,0.9561327695846558,0.969372570514679,0.0,accept,unanimous_agreement
992338178,11199,api was generalised,0,0,0,0.9873036742210388,0.9788578152656556,0.992237150669098,0.0,accept,unanimous_agreement
993218619,11199,"some comments before the call, look like they're outdated, i.e. the comment in this one speaks about lazy expiry. maybe if the call is renamed from ""unit"" to ""modification"" or ""action"" it can still make sense, but if we stay with ""unit"" i feel we need to improve some of the comments. (even if just saying ""the following call handles that"").",0,0,0,0.8724309802055359,0.9722872972488404,0.9472983479499816,0.0,accept,unanimous_agreement
993224355,11199,"not happy with this name. we're adding a `job` that's a `post `, but it doesn't say post of what. maybe it should also be a ""post action job"" or ""post modification job"", or a ""post execution unit job"". maybe you have an advise",-1,-1,-1,0.7235643267631531,0.8988632559776306,0.9640900492668152,-1.0,accept,unanimous_agreement
993231766,11199,"ohh, now i see where ""unit"" comes from. if we're coining the term ""execution unit"" for this thing, i think we may need to mention it in a few other places, not sure where. but at the very least, let's rename the `postunitoperations` to `postexecutionunitoperations`. the term ""unit"" can be applied to so many other things, and i think ""exec"" as short hand for ""execution"" isn't good since we have a command named exec.",0,0,0,0.8945508599281311,0.9576904773712158,0.8764336109161377,0.0,accept,unanimous_agreement
994382973,11199,so i guess we should also rename `addpostjob` to `addpostexecutionunitjob`,0,0,0,0.986446976661682,0.9904035329818726,0.9928715825080872,0.0,accept,unanimous_agreement
994414404,11199,"updated, let me know if it makes more sense now.",0,0,0,0.9836879968643188,0.9825484752655028,0.9755287766456604,0.0,accept,unanimous_agreement
997586963,11199,[code block] for consistency with other apis.,0,0,0,0.9874966144561768,0.9916179776191713,0.9950920343399048,0.0,accept,unanimous_agreement
997591871,11199,"are logical units = execution units? it seems like this paragraph is describing one thing, so maybe just be consistent. either that, or i'm not sure what the difference is.",0,0,0,0.904801070690155,0.9272719025611876,0.8646273016929626,0.0,accept,unanimous_agreement
997592051,11199,is there a corresponding issue for refactoring all of the variables? i would rather have it there then buried into the code some place.,0,0,0,0.9843616485595704,0.9409840106964112,0.9878427982330322,0.0,accept,unanimous_agreement
1009438817,11199,"not directly related to this pr, but i think we're missing a way for a module to determine if this option is supported or not, like `rm_get**flagsall.`",0,0,0,0.955245852470398,0.9908620119094848,0.9738362431526184,0.0,accept,unanimous_agreement
1009444233,11199,"i think the terminology is confusing here - both api and implementation wise. it appears as if `execunitjob` is something generic, but what it really is a `deferredksncallback` (or something similar, that is more self explanatory). my suggestion: * agree on the right term for this mechanism and stick to it. * add a return code to this function and return `redismodule_err` if not called from within a ksn callback.",0,0,0,0.9022060632705688,0.7947628498077393,0.7674612402915955,0.0,accept,unanimous_agreement
1009451521,11199,[code block] fixed a typo and went on a bit...,0,0,0,0.9754413366317748,0.8904848098754883,0.9848805665969848,0.0,accept,unanimous_agreement
1009568184,11199,"we realized we're gonna use this mechanism for more than just ksn, and we ended up coining a new term (for redis, not just modules), called ""execution unit"". does that solves the terminology comment? do you have a better idea?",0,0,0,0.9734877347946168,0.9885314702987672,0.9915307760238647,0.0,accept,unanimous_agreement
1015635716,11199,"my comment is about the api design, not implementation (whose details should ideally not leak through the api), so i think it's still valid. what are we going to use this mechanism for beyond ksn? do we think we'll expose it through module api for other use cases? are they well covered in the api as it's defined now? my suggestion is to keep the api narrow and well-defined. even if we implement it using the more generic mechanism we're creating, we should still consider the immediate use case and design the api for it.",0,0,0,0.966917097568512,0.9685145616531372,0.9258853197097778,0.0,accept,unanimous_agreement
1015778998,11199,one example could be the unlink event we're adding in #9406,0,0,0,0.987761378288269,0.9950632452964784,0.9923302531242372,0.0,accept,unanimous_agreement
1017596946,11199,"we discussed this in a core-team meeting. i'm not 100 on board with that, but the decision was to narrow the scope of this api (be only about ksn), so that maybe we can extend it int he future, rather than make it wide now (a generic ""execution unit""), and later regret it. this applies just to the api. we can keep the internal concept of execution units, where we're free to keep adjusting it, just not expose it to users via api.",0,0,0,0.9147828221321106,0.9239141345024108,0.876413106918335,0.0,accept,unanimous_agreement
1031162741,11199,i have updated the pr and the top comment accordingly. external api specify only key space notifications.,0,0,0,0.9879214763641356,0.9843894839286804,0.995801031589508,0.0,accept,unanimous_agreement
1031169944,11199,created one: [a link],0,0,0,0.987434983253479,0.9865556955337524,0.9955735206604004,0.0,accept,unanimous_agreement
1031170418,11199,fixed to execution unit,0,0,0,0.986236810684204,0.9883516430854796,0.9938576817512512,0.0,accept,unanimous_agreement
1031323430,11199,"i'd argue that it is related to this pr since it adds a new option and a a compatibility issue. it's real quick to add it, i don't see a need for another pr or issue.",0,0,0,0.8776615858078003,0.8060410618782043,0.9592134952545166,0.0,accept,unanimous_agreement
1031524409,11199,added to this pr and updated the top comment.,0,0,0,0.983043372631073,0.9892238974571228,0.9943934679031372,0.0,accept,unanimous_agreement
1031668524,11199,"the api is `rm_setmoduleoptions`, so this one should be `rm_getmoduleoptionsall` imho",0,0,0,0.9867114424705504,0.993425726890564,0.9925298094749452,0.0,accept,unanimous_agreement
1031690308,11199,"ok, will change it.",0,0,0,0.9812626242637634,0.9870935082435608,0.9924370646476746,0.0,accept,unanimous_agreement
1032794748,11199,isn't redundant?,0,0,0,0.9754654765129088,0.8682928681373596,0.9793586134910583,0.0,accept,unanimous_agreement
1032807676,11199,"yes, certainly redundant, i wonder how it slipped in.... admittedly, i only did incremental reviews, and didn't do a top to bottom one before merging. please make a pr to fix.",-1,-1,-1,0.786302924156189,0.9618195295333862,0.7885500192642212,-1.0,accept,unanimous_agreement
1032875979,11199,"yes, totally redudent, bad merge from unstable on my side (funny, i believe i also did the pr that caused the conflict and i still missed it) will make a pr to remove it.",-1,-1,-1,0.960680365562439,0.9662862420082092,0.9860088229179382,-1.0,accept,unanimous_agreement
1032876291,11199,i see sundb already made the pr: #11547,0,0,0,0.9526111483573914,0.9681692719459534,0.9886381030082704,0.0,accept,unanimous_agreement
1032876511,11199,"ohh right, greate, thanks.",1,1,1,0.9810020923614502,0.9737253785133362,0.9235568642616272,1.0,accept,unanimous_agreement
556123809,8315,"can we squash these two blocks together, so we don't double up on the replication cron. [code block]",0,0,0,0.988544762134552,0.9913609623908995,0.9923930168151855,0.0,accept,unanimous_agreement
556126377,8315,shouldn't this be server.master instead of cached_master? we only want to accept a failover request if we are currently connected to the master.,0,0,0,0.9824886322021484,0.9929913282394408,0.9905347228050232,0.0,accept,unanimous_agreement
556134744,8315,"it would be nice to have an explicit check here about the status, so we aren't running through this code. i don't think it's possible to find a replica.",0,0,0,0.94966322183609,0.95123690366745,0.9834719896316528,0.0,accept,unanimous_agreement
556135161,8315,"a nitpick, i think a clearer implementation would be to identify the replica in the conditional block, and consolidate the replicationsetmastercode + comment after. i think we also need to break here, the current code will setmaster if multiple replicas are caught up.",0,0,0,0.9859473705291748,0.9857364296913148,0.9525007009506226,0.0,accept,unanimous_agreement
556152546,8315,i don't 100% recall the reason for this. i think that the the issue is the initial primary disconnects all replicas before issuing a psync command to the targeted replica. if the replica processes the primary disconnection before it receives the psync command then server.master will be null and failover will fail. server.cached_master will still be valid in this case and allow the failover to complete.,0,0,0,0.976556658744812,0.9601803421974182,0.966324508190155,0.0,accept,unanimous_agreement
556156362,8315,added a check for this,0,0,0,0.9874417781829834,0.9881523251533508,0.9938486218452454,0.0,accept,unanimous_agreement
556156473,8315,"added a break, but the consolidation was a little tricky so i did not do that",0,0,0,0.6281120181083679,0.6147629022598267,0.9751095175743104,0.0,accept,unanimous_agreement
556553460,8315,i think we should have 2 replicas connected in all tests (and use one of them for replica_host etc.),0,0,0,0.9854522347450256,0.9834975004196168,0.985834777355194,0.0,accept,unanimous_agreement
556560246,8315,"i think the ""extra time"" should be configurable",0,0,0,0.9844297170639038,0.9843973517417908,0.9848529100418092,0.0,accept,unanimous_agreement
559225227,8315,why repl_state_transfer and not repl_state_connected? do we expect this will ever be possible to lead to full sync?,0,0,0,0.9822469353675842,0.993097722530365,0.9885149598121644,0.0,accept,unanimous_agreement
559378723,8315,"the `server.mstime` cached time is updated, no reason not to use it",0,0,0,0.9839300513267516,0.98430734872818,0.9935844540596008,0.0,accept,unanimous_agreement
559391008,8315,"or maybe we don't have to have that extra time at all? i.e. user provided a timeout, we can just respect that timeout, and use that timeout as a total timeout for the whole operation. and if we sense we're already too close to the timeout (less than a second remained?), abort instead of extending the timeout and proceeding.",0,0,0,0.9801751971244812,0.9820414781570436,0.9863436222076416,0.0,accept,unanimous_agreement
559405303,8315,"maybe to reduce delays, we can move the trigger to that to the actual replconfcommand? i.e. not wait for the next cron",0,0,0,0.9846333861351012,0.9948775172233582,0.982308030128479,0.0,accept,unanimous_agreement
559407636,8315,"nitpick, something feels wrong about the indentation of `if`s you're breking to multiple lines. this one stands out more than others. in many of them i think we can avoid it and keep them in one one. or if we do break them to multiple lines, i think the way other parts in redis indent the other lines to the opening `(` of the `if`, and then put the `{` in a line of it's own.",-1,-1,0,0.768424391746521,0.8641788363456726,0.7502629160881042,-1.0,accept,majority_agreement
559411289,8315,i suppose you meant to delete the other call above to [code block],0,0,0,0.9884385466575624,0.9919140338897704,0.9903708100318908,0.0,accept,unanimous_agreement
559413683,8315,"considering the default hz (when there are not many clients) is 10, (a cron tick per 100ms), this `20` may be misleading, it'll not actually run that many times normally. i would feel more comfortable seeing 100 here, and if we conclude that's not enough maybe we need to find another solution. (like immediate triggers, tapping into specific commands / replies and beforesleep) as i stated, some parts of that failvercron function can be immediately triggered when replconf ack is received.",0,0,0,0.9647002816200256,0.9695504903793336,0.9802738428115844,0.0,accept,unanimous_agreement
559416709,8315,i think it would make more sense to call this command `failover`. failoverto suggests that we already have a failover command and this one is a variant of it. how about: [code block] then we don't have to have the special `any one` thing. p.s. the force argument wasn't documented here.,0,0,0,0.985995352268219,0.9845204949378968,0.9849741458892822,0.0,accept,unanimous_agreement
559425705,8315,"considering that the failover has several states (as evident by the code in `failovercron`), i think it would be nice to show the current state here, maybe similarly to how `master_link_status` is shown. unless after reviewing my other comments we eliminate these stages, and have just one (waiting for the offsets to match)",0,0,0,0.980949342250824,0.988289475440979,0.9869996905326844,0.0,accept,unanimous_agreement
559429029,8315,do we have test coverage for this case?,0,0,0,0.985292375087738,0.9903051853179932,0.9946802258491516,0.0,accept,unanimous_agreement
559440657,8315,"calling `replicationsetmaster` at this point is equivalent to getting a replicaof command. why do we need to keep tracking the failover and extending the timeout? at this point can't we just terminate the whole operation? i.e. from this point forwards we're a replica, and we don't need the client pause anymore. the bonus is that we get rid of the extra failoverto_timeout. if we don't do that, then maybe we should remember the original timeout and use it, rather than the fixed 5 seconds here.",0,0,0,0.9788033366203308,0.9891030788421632,0.9842065572738647,0.0,accept,unanimous_agreement
559441017,8315,is this case covered by the test?,0,0,0,0.9843621253967284,0.9912336468696594,0.9925339221954346,0.0,accept,unanimous_agreement
559492970,8315,i was gonna comment that it would be a nice idea to have background traffic. reading this comment and the client pause i wonder if i'm missing anything?,0,-1,0,0.9227179884910583,0.4029234051704407,0.8640754818916321,0.0,accept,majority_agreement
559497129,8315,"fyi, you have `wait_for_ofs_sync` in util.tcl",0,0,0,0.9847676157951356,0.9829301238059998,0.9945698380470276,0.0,accept,unanimous_agreement
559497932,8315,this will really slow down the tests by 5 seconds (think we wanna try hard to avoid such a thing). making that timeout configurable in some way would speed up the tests.,0,0,0,0.94633150100708,0.7043069005012512,0.5416085124015808,0.0,accept,unanimous_agreement
559509018,8315,"i think many of these tests can be improved to add some additional assertions. like looking at the `sync_full`, `sync_partial_ok` counters. or maybe also using `verify_log_message` to make sure the intended flow really executed.",0,0,0,0.9779707789421082,0.99275803565979,0.9746431112289428,0.0,accept,unanimous_agreement
559527202,8315,i think we need to cover a case were the replica doesn't support the new failover argument for psync. i think it would be good enough to just block the psync command entirely with acl (it would be similar to getting an arity error.,0,0,0,0.9732913374900818,0.984100341796875,0.987193763256073,0.0,accept,unanimous_agreement
559538568,8315,i suppose we do. in which case i think we need to add a test to cover it.,0,0,0,0.9812731742858888,0.9778687357902528,0.98915696144104,0.0,accept,unanimous_agreement
559904183,8315,if you want to force it yeah. test can be added.,0,0,0,0.9845561981201172,0.9764426350593568,0.9927224516868592,0.0,accept,unanimous_agreement
559955557,8315,nice,1,1,1,0.8361793160438538,0.9342552423477172,0.7884483337402344,1.0,accept,unanimous_agreement
560546505,8315,"will remove second part of timeout, so this test is out.",0,0,0,0.988048493862152,0.9916457533836364,0.9931694269180298,0.0,accept,unanimous_agreement
560547757,8315,"this is the regular failover timeout, so there is a test for this.",0,0,0,0.9843846559524536,0.9935043454170228,0.9934946894645692,0.0,accept,unanimous_agreement
560548199,8315,i think this is addressed.,0,0,0,0.980703830718994,0.8891593813896179,0.9538474082946776,0.0,accept,unanimous_agreement
560548429,8315,"yeah, this is the case where the second half of the handshake (waiting to move to state transfer) times out. since this is getting dropped, this code should be clearer.",0,0,0,0.9856509566307068,0.9741962552070618,0.9877787232398988,0.0,accept,unanimous_agreement
560674914,8315,"i'll add the partial syncs. i generally dislike checking log messages, it feels too much like whitebox testing, would rather test to behavior is correct then the right logs showed up.",-1,-1,-1,0.9714481234550476,0.9685859084129332,0.7120538353919983,-1.0,accept,unanimous_agreement
560675115,8315,i'll add a test for background traffic.,0,0,0,0.9871046543121338,0.982519268989563,0.9921575784683228,0.0,accept,unanimous_agreement
560675312,8315,i think the better fix is just to trigger the failovercron (or replicationcron generally) from replconf. will look into it.,0,0,0,0.9841140508651732,0.9825432300567628,0.9810888767242432,0.0,accept,unanimous_agreement
560675391,8315,"there is 3 states, so updated to show those 3 states.",0,0,0,0.9847491383552552,0.9880563020706176,0.9948306679725648,0.0,accept,unanimous_agreement
560675849,8315,"this code has been removed, since the failover doesn't rollback here.",0,0,0,0.9869263172149658,0.9931013584136964,0.9934415817260742,0.0,accept,unanimous_agreement
561709320,8315,"maybe we wanna error here rather than proceed ignoring the ""failover"" argument?",0,0,0,0.9599429965019226,0.9873124957084656,0.9728904962539672,0.0,accept,unanimous_agreement
561762382,8315,"i think the to argument can be optional, this way we don't need the any one trick. [code block]",0,0,0,0.9857766032218932,0.9881860017776488,0.9847952723503112,0.0,accept,unanimous_agreement
561769852,8315,"if we change to to be optional, the arity needs to change",0,0,0,0.9844204783439636,0.9896866679191588,0.9888309836387634,0.0,accept,unanimous_agreement
561773479,8315,let's match debug digest here. probably wise to do this on all tests below.,0,0,0,0.9435692429542542,0.9817566871643066,0.9926998019218444,0.0,accept,unanimous_agreement
561774927,8315,any specific reason you're using redis-benchmark and not the tcl `start_write_load` ?,0,0,0,0.9866209030151368,0.9948760867118835,0.9940049052238464,0.0,accept,unanimous_agreement
561778608,8315,"did you mean to do this sigcont later? seems like the forceful failover isn't taking place here (a normal failover happens). or am i missing anything? let's use `verify_log_message` to make sure a forceful failover happened. and let's validate the old master managed to do a `sync_full` i guess we can also test debug digest here (after the old master performs full sync). but if not, let's at least validate neither of them go empty (dbsize)",0,0,0,0.9746422171592712,0.9930729269981384,0.989314079284668,0.0,accept,unanimous_agreement
562064189,8315,i was trying to document it like it was one command with two subcommands. otherwise it would look like this: [code block] which i find much harder to follow.,0,0,0,0.5670216679573059,0.8968294262886047,0.8068103194236755,0.0,accept,unanimous_agreement
562064719,8315,"sure, easy to do.",0,0,0,0.829712986946106,0.9502092599868774,0.8048853874206543,0.0,accept,unanimous_agreement
562068657,8315,"there is still failover abort, which is just 2 arguments.",0,0,0,0.9784144163131714,0.972219467163086,0.9877893924713136,0.0,accept,unanimous_agreement
562087860,8315,"ok. got it.. but if it's a sub-command, i'm still not sure the `to` is a good sub-command. maybe the sub-command should be something like `start`, and `[to ]` would still be an optional argument.",0,0,0,0.9497660398483276,0.934107542037964,0.8464714884757996,0.0,accept,unanimous_agreement
562088568,8315,"i meant that if to is optional, then the arity would be `-1`",0,0,0,0.9820505380630492,0.9936193823814392,0.9897345304489136,0.0,accept,unanimous_agreement
562166153,8315,"sorry, i now understand what you are getting at, ""failover"" by itself would pick a replica and failover. i still like the current wording, i'll address all the other comments and then ping the group about what the command will be named like.",-1,-1,-1,0.9890201687812804,0.988191545009613,0.9671425819396972,-1.0,accept,unanimous_agreement
562171605,8315,"yes.. the main ""advantage"" is that to becomes optional and we don't need to use the ""any one"" trick",0,0,0,0.9544686079025269,0.9581339359283448,0.9642602205276488,0.0,accept,unanimous_agreement
562412676,8315,"yeah, this test can work as expected, but it's purely contingent on the fact the cron doesn't run that often. made this test much more robust and added the additional needed tests.",0,0,0,0.9587334394454956,0.9714571237564088,0.987434983253479,0.0,accept,unanimous_agreement
562412781,8315,"i did not know about start_write_load :) (if you haven't noticed, we don't use tcl at aws)",1,1,1,0.6173356175422668,0.9881595373153688,0.9941790103912354,1.0,accept,unanimous_agreement
565380752,8315,maybe expose the rest of the failover state? attaching to an instance stuck in failover that can be valuable debugging info i believe.,0,0,0,0.9796246290206908,0.9871448874473572,0.9907931685447692,0.0,accept,unanimous_agreement
565385720,8315,not in use anymore.,0,0,0,0.5090686082839966,0.9678099751472472,0.9685711860656738,0.0,accept,unanimous_agreement
565391911,8315,"one issue here is `replicationsetmaster()` terminates all replicas (and blocked clients etc.) before establishing the connection to the master and beginning `psync`. i think it's a good start but maybe we should be leaving a message to our future self here to address that in future refactoring. ideally, we could first set up the connection and do initial `psync` negotiation, and only then drop everything.",0,0,0,0.952592134475708,0.9896609783172609,0.6772724986076355,0.0,accept,unanimous_agreement
565402104,8315,consider defining `node_n_pid` to make it more readable.,0,0,0,0.9850715398788452,0.9921525120735168,0.9925147891044616,0.0,accept,unanimous_agreement
565414138,8315,"i'd consider another test case - `psync` initiated but not completed, thus we remain in failover/paused state to avoid two masters.",0,0,0,0.9868974685668944,0.988054096698761,0.9908285140991212,0.0,accept,unanimous_agreement
565610419,8315,"i agree, there is more optimizations to be done here. would we prefer this being an issue or a comment in the code?",0,0,0,0.9742912650108336,0.9766627550125122,0.9732828140258788,0.0,accept,unanimous_agreement
565611996,8315,"port is currently read in as a long, i think this is just to be parity with replicaof which does the same validation.",0,0,0,0.9879111051559448,0.9896773099899292,0.9929487705230712,0.0,accept,unanimous_agreement
565614321,8315,"since the force test already simulates this case, i added asserts there to make sure `failover-in-progress` state puts everyone to slaves.",0,0,0,0.9862923622131348,0.9930651187896729,0.991371750831604,0.0,accept,unanimous_agreement
565618862,8315,i'm going to put a note at the top of the function about the side effects.,0,0,0,0.97714501619339,0.9689843654632568,0.9846136569976808,0.0,accept,unanimous_agreement
565623580,8315,"i thought about this, so when we are in the failover state, our master/host values will be set and timeout isn't valid. that should be enough to debug what is going on. if we are in the sync state, the data is available through our offset and the slaves section, and i'm not sure if adding timeout is that useful. we can add more data here, but i think there is enough to investigate right now.",0,0,0,0.961180865764618,0.970225989818573,0.9366594552993774,0.0,accept,unanimous_agreement
565625303,8315,i think at this point it's more likely to be noted as a comment,0,0,0,0.9754732847213744,0.9768162965774536,0.9628980755805968,0.0,accept,unanimous_agreement
565626542,8315,but `target_replica_port` is an int...,0,0,0,0.9872875213623048,0.9866064786911012,0.9942441582679749,0.0,accept,unanimous_agreement
665854625,8315,"i feel there is a missing return here? i happen to use `psync runid offset failover` in redis-cli, the interactive behavior is a bit strange oh.. maybe i am missing something. don't bother...",-1,-1,-1,0.9488376379013062,0.9810173511505128,0.5003620982170105,-1.0,accept,unanimous_agreement
665895021,8315,"-binbin i don't think there's a return missing, but feel free to show me where i'm wrong (i didn't debug it). keep in mind two things: 1. psync is not intended to be used from redis-cli, it's a command one redis server sends to another, not a user command. 2. psync failover is a command sent by a master to one of its replicas, it does two things - promote the replica to be a master (few lines above this comment). - the old master (the one sent the psync command) attempts to psync from that replica (which is why we need to keep running the bottom part of this function (the return will break it)",0,0,0,0.9064912796020508,0.9621732234954834,0.8973726630210876,0.0,accept,unanimous_agreement
543401685,8170,"i'm concerned about this loop (server with an immense number of client can choke on it). i actually imagined we'll have a list of clients that got blocked, there's a chance that many didn't get blocked either because they're inactive, or because they didn't issue write commands. if we have a list, we can fuse it into the other list without even iterating, and take care of the flags in processunblockedclients. while on that subject (of looping though clients), maybe we need to somehow throttle the unblocking in processunblockedclients, in case many clients got unblocked at the same time, maybe we should defrost them gradually.",-1,-1,-1,0.9647196531295776,0.5058385133743286,0.9044694900512696,-1.0,accept,unanimous_agreement
543423369,8170,"if we keep this var, i rather it'll move to the top (can be used for other checks some day)",0,0,0,0.9883689880371094,0.9905285239219666,0.9914950132369996,0.0,accept,unanimous_agreement
543432778,8170,"i don't think we wanna check for `cmd_readonly`, i think we should check for `!cmd_write`. seems to me that we do wanna allow non-keyspace commands like ping, info, client, shutdown, config etc. and even basically any command that's not writing to the keyspace, like dbsize. other examples off the to of my head (not already mentioned above): acl, debug, reset, watch, discard, select, sync, subscribe and multi / exec (both already handled in your code explicitly). i suppose publish is ok too (doesn't propagate to replicas, so it's ok, right?) the tricky part is eval (which we don't know it's content, and pfcount (which is a ready-only, which **does** increment server.dirty). i suppose we can explicitly block eval for now, and either add some code to pfcount that will avoid the conversion and propagation, or block it too. modules already have the `rm_avoidreplicatraffic` (which i think you should fix to only look at the ro pause flag)",0,0,0,0.9600537419319152,0.9735976457595824,0.9766044020652772,0.0,accept,unanimous_agreement
543926422,8170,ack,0,0,0,0.9720376133918762,0.8596508502960205,0.9149930477142334,0.0,accept,unanimous_agreement
543927637,8170,"yeah, i was hoping this might save some effort, but while talking it through internally !write is probably the way to go.",0,0,0,0.7784891128540039,0.825833797454834,0.5445892810821533,0.0,accept,unanimous_agreement
543952895,8170,"ack about the second list, that's a reasonable optimization. i think we should probably serve the clients that have been blocked immediately? it doesn't seem right to slowly unblock them.",0,0,0,0.8591052889823914,0.7286189794540405,0.9451056122779846,0.0,accept,unanimous_agreement
546961452,8170,looks like this further relates to the pr you just put up as well.,0,0,0,0.9826794862747192,0.9837647080421448,0.9867119789123536,0.0,accept,unanimous_agreement
547151871,8170,lol. this is the flag i was trying to avoid adding in #8216 (and eventually found a better way without it). i suppose we do need to add that flag (the alternative being to explicitly check a specific list of commands). do we want to expose it to clients in command command?,1,1,1,0.9173117876052856,0.8906962871551514,0.9601645469665528,1.0,accept,unanimous_agreement
547152839,8170,i wish we could make this an `enum`.,0,0,0,0.9627240896224976,0.9854045510292052,0.9784610867500304,0.0,accept,unanimous_agreement
547154422,8170,maybe you better nullify paused_list_node after doing that.,0,0,0,0.985782265663147,0.9916635751724244,0.986077070236206,0.0,accept,unanimous_agreement
547157461,8170,"we don't want to consider any exec a write command, only ones that contains a write command. [code block]",0,0,0,0.98445463180542,0.9806705713272096,0.9939537644386292,0.0,accept,unanimous_agreement
547176474,8170,"i guess that script load, and publish commands needs that too. basically any command that calls forcecommandpropagation. maybe we even want to add an assertion on c->cmd in forcecommandpropagation?",0,0,0,0.9857935309410096,0.991034209728241,0.9864219427108764,0.0,accept,unanimous_agreement
547553205,8170,"nice, i really think pfcount should not modify the underlying structure, so this flag is really just for scripts and modules that execute scripts they can't pre-validate.i'll update the command command.",1,1,1,0.7200149297714233,0.7582343220710754,0.6314230561256409,1.0,accept,unanimous_agreement
547555263,8170,"we could use a macro like getflag(cmd_module_getkeys), where cmd_module_getkeys is just a regular enum. the macro would do the bit shifting, since it'll still all be known at compilation time, it should optimize it the same way. it doesn't seem overly worth it to me.",0,0,0,0.9269791841506958,0.959709107875824,0.9762549996376038,0.0,accept,unanimous_agreement
547556114,8170,good point.,1,1,1,0.9406068921089172,0.9406900405883788,0.914055109024048,1.0,accept,unanimous_agreement
547559066,8170,"so, the reason i originally didn't add this is you can multi-exec a client pause with a write, which is probably stupid. i added a log in propagate to identify that something bad happened.",-1,-1,-1,0.967276394367218,0.9620988368988036,0.9619065523147584,-1.0,accept,unanimous_agreement
547571780,8170,can you explain the point of the assertion in forcecommandpropagation that you proposed?,0,0,0,0.9867572784423828,0.9881272912025452,0.994099736213684,0.0,accept,unanimous_agreement
547579474,8170,"later comment showed there were some other commands as well, so i guess this makes sense.",0,0,0,0.9843020439147948,0.9831105470657348,0.991024136543274,0.0,accept,unanimous_agreement
547988635,8170,to make sure that we don't add a some future command that uses forcecommandpropagation and isn't marked with either `write` or `can-replicate`. maybe we should also have such assertion in the call to `propagate()` in `call()`.,0,0,0,0.9882252216339112,0.9948390126228333,0.9934531450271606,0.0,accept,unanimous_agreement
547989980,8170,"so you mean you're gonna apply my suggestion, right?",0,0,0,0.9776791334152222,0.9742451310157776,0.9849409461021424,0.0,accept,unanimous_agreement
548047994,8170,"oh, that assert seems reasonable. i thought about adding one in the propagate path, but there are ways you can get there like multi-exec'ing a client pause + a write. i throw a warning there now, which isn't great.",-1,0,-1,0.5076868534088135,0.7437418699264526,0.6133545637130737,-1.0,accept,majority_agreement
551900761,8170,"this one is missing a comma, right? [code block]",0,0,0,0.985253632068634,0.9920462369918824,0.9932055473327636,0.0,accept,unanimous_agreement
551906495,8170,"i think the name `unpauseclients` is a bit misleading, can be improved. i.e. it doesn't always unpause. maybe `unpauseclientsiftimeout`? not not.. if you agree try to find a better name, if not, leave it as is.",0,0,0,0.9433122277259828,0.8721948862075806,0.8638124465942383,0.0,accept,unanimous_agreement
551907178,8170,"the name of this function was always bad (misleading, hides it's side-effects).. i see it is used in only 10 places, maybe we want to consider renaming it.",-1,-1,-1,0.8466308116912842,0.7869284152984619,0.9286508560180664,-1.0,accept,unanimous_agreement
551908893,8170,"maybe add an uppercase ""warning"" to that message? would increase chance of it being noticed. or maybe we want an assert here?",0,0,0,0.9829623103141784,0.9920271039009094,0.988323450088501,0.0,accept,unanimous_agreement
551912468,8170,can't we use a wait_for_condition here? we do want to fail if timeout was reached,0,0,0,0.9451050758361816,0.9888562560081482,0.9898853302001952,0.0,accept,unanimous_agreement
551915003,8170,"i don't particularly like the 1 second delay we're adding to the tests here. we send the getack request in every cron, so normally it would unblock after 100ms. maybe we want to reduce the timeout? or find another way? for instance, we can use `attach_to_replication_stream` to see what's exactly going into the replication stream.",-1,0,-1,0.9209796786308287,0.5711209177970886,0.772456169128418,-1.0,accept,majority_agreement
551919597,8170,"it just occurred to me that maybe it would be nice to also have a read pause feature. i.e. one that will still allow ping, info, client, shutdown, but will refuse get, dbsize and any access to the keyspace. what do you think? (should be very easy to implement now)",0,0,0,0.9383269548416138,0.9497029185295104,0.841792106628418,0.0,accept,unanimous_agreement
552115585,8170,"a really awkward line and difficult to read. * `clientsarepaused` seems like a boolean function. * it's actually used as a boolean function in this update (`db.c`). * however, here it's being compared against an enumerated/defined value which blows my expectations. * the double-negative is hard to read. ""off"" is negative and the `!` is negative. * so i'm left wondering, why was this line changed? is this actually a boolean routine? or does it return some type of enumerated value? if it does return an enumerated value, is the change in `db.c` correct (where this is being used as a boolean function)?",-1,-1,-1,0.942468762397766,0.9511761665344238,0.9924532771110536,-1.0,accept,unanimous_agreement
552123304,8170,"i also commented on this above. the function used to be boolean, but now that's no longer the case. looking at how it's used, i suggest that you retain the original boolean behavior `return (server.client_pause_flags != client_pause_off);` there's no reason to complicate the usage by returning the specific flags. if a caller is interested in the actual flags, they can always be retrieved globally.",0,0,0,0.9817460775375366,0.9910982251167296,0.988439440727234,0.0,accept,unanimous_agreement
552127828,8170,would it be better to use the monotonic clock for these times?,0,0,0,0.9812015295028688,0.993504524230957,0.9860432147979736,0.0,accept,unanimous_agreement
552138618,8170,"2 things: * maybe use ""may-replicate"" or ""might-replicate"" - because ""may"" conveys that there is a *possibility* that the command might generate replication. ""can"" doesn't generally imply ""possibility"". (it implies permission or ability.) * i don't like having the comment say ""only used for client pause"". these flags provide information about the command. we should be thinking about the meaning of the flag in relation to the command, not in relation to how we think that flag would be used. so, instead say something like: `might-replicate: command is not formally a ""write"" command, but may still produce replication. this applies to non-keyspace commands like publish and also commands like eval which are not formally ""write"" commands, but may generate replicated writes.`",-1,0,0,0.4977150559425354,0.9483045339584352,0.9154475331306458,0.0,accept,majority_agreement
552145101,8170,"(i can't leave the comment on the unmodified line above.) shouldn't exec be marked as ""can-replicate""? it seems like maybe you've worked around this elsewhere in the code, but i think that exec should be marked. i know that for your use case, you are using the accumulated flags from the commands in the exec. you have logic something like: `if can_replicate || (exec and m.flags==can_replicate)` you could do: `if can_replicate && !(exec && n.flags != can_replicate)` i agree that this logic is more complicated to read, but it creates a more solid definition around the meaning/use of the new flag.",0,0,0,0.9475007653236388,0.9823423027992249,0.9849536418914796,0.0,accept,unanimous_agreement
552149774,8170,"from the logic above, it seems that it's possible to have both client_pause_write and client_pause_all active at the same time. if so, and one of the pauses completes, all clients will be unblocked even though some might still need to be blocked. for example, if client_pause_write completes, but client_pause_all is still active, all clients will be unblocked (incorrectly). is this intentional, with the expectation that they will be reblocked when processed? it seems that we should check each client before unblocking.",0,0,0,0.9749357104301452,0.981966495513916,0.9876582026481628,0.0,accept,unanimous_agreement
552157166,8170,"this is small, but i think it might be useful to break this code out into a separate function - and maybe this new function would fit better in `networking.c`. i think this might be a common action whenever a client (with command) is taken out of the normal processing path and later re-activated. also, is there a reason why an unblocked client might not have client_pending_command?",0,0,0,0.9757518768310548,0.994030773639679,0.9826027154922484,0.0,accept,unanimous_agreement
552161771,8170,"after a client is unblocked (put into the unblocked list), how can a client get reblocked before leaving the unblock queue? i'm thinking that this flag should always be clear here. maybe add an assertion to ensure/document? i'm thinking that once a client is unblocked, we would call `processcommandandresetclient()` (always) and then check client_blocked before calling `processinputbuffer()`. (but as mentioned in the comment, `processinputbuffer` must check that anyway, so the additional check is not needed here.) if this code is extracted and moved to `networking.c` it would reduce the logic bleed between modules.",0,0,0,0.9791577458381652,0.9927090406417848,0.9917176961898804,0.0,accept,unanimous_agreement
552176858,8170,"yup, c just happily concatenated them :)",1,1,1,0.9881114959716796,0.995952010154724,0.7315419316291809,1.0,accept,unanimous_agreement
552186327,8170,"i think the problem is that it has the side effect of unpausing clients. i tried decomposing it a little bit. it's a little more verbose, but hopefully more readable.",0,0,0,0.8732267022132874,0.8640522360801697,0.8621993064880371,0.0,accept,unanimous_agreement
552186593,8170,see previous comment.,0,0,0,0.980539083480835,0.9873520135879515,0.9940604567527772,0.0,accept,unanimous_agreement
552195230,8170,"yes, it was worse before (looking as a gettter or checker function and now it's better) since it's clear it takes action, but it doesn't always take action, and that's still a bit misleading",-1,0,-1,0.9053688049316406,0.7834677696228027,0.6407297253608704,-1.0,accept,majority_agreement
552198488,8170,"i wanted to comment about it too, but decided to skip it. the `!(a==b) ` is odd. i do think the function can keep returning a bit flag, but the check here should be `!=off` (or a simple `!!` we wanna count on off being 0, and need to convert it to true boolean (less clean)",0,-1,0,0.6572678685188293,0.6283524036407471,0.6731659770011902,0.0,accept,majority_agreement
552200747,8170,"i can do that. i was torn about asserting specifically because people are using this to failover, it's probably one of the worst times to crash.",-1,-1,-1,0.9808694124221802,0.940338134765625,0.9157570004463196,-1.0,accept,unanimous_agreement
552200829,8170,yup,0,0,0,0.7866461277008057,0.6203734278678894,0.8985633254051208,0.0,accept,unanimous_agreement
552207401,8170,"in theory, you're right. since the flag is named ""might"", we can set it to exec and then write code to ignore it. but that logic can be applied to any other flag (if we try to put aside the ""might"" part). i. e. we can set the oom flag and others. i'd like to offer a different way of thinking about exec: it's not a command, it's part of the redis client protocol. it would be wrong for anyone to look at its flags. instead one must always looks the the flags of the commands inside it. maybe it would have been better if it wasn't in the command table, but rather implemented like quit is. anyway, i vote to keep the code s it is.",0,0,0,0.9298911690711976,0.977332353591919,0.899647057056427,0.0,accept,unanimous_agreement
552211067,8170,wait_for_condition is much better,0,0,0,0.97487610578537,0.9818726181983948,0.9090632796287536,0.0,accept,unanimous_agreement
552212776,8170,"we use server.mstime, so it's effectively free. we also don't need monotimes high precision.",0,0,0,0.9786059260368348,0.9839476346969604,0.9841416478157043,0.0,accept,unanimous_agreement
552214229,8170,"i want some way to catch this in the test suite. we can maybe add some keyword that there tests search for in the logs. on the other hand, out philosophy so far was to crash when something unexpected happens.. we may cause someone some damage, but at least we'll learn about the problem, and fix it asap instead of keeping buggy code that can cause data corruption or inconsistencies. i'm not certain if this one falls under this philosophy, or we wanna be more careful here. but at the very least the warning should be bolder.",0,0,0,0.8784255981445312,0.7961230874061584,0.7278618812561035,0.0,accept,unanimous_agreement
552215860,8170,"it behaves as you suggested, it just reprocesses everything.",0,0,0,0.8770806193351746,0.9815067052841188,0.9920192360877992,0.0,accept,unanimous_agreement
552216281,8170,io threads can queue up clients with fully formed commands and uses this flag. i like the suggestion for the function.,1,1,0,0.8878637552261353,0.9377027153968812,0.5912195444107056,1.0,accept,majority_agreement
552216733,8170,i don't really follow this comment.,-1,-1,0,0.8933183550834656,0.8343443274497986,0.6441807746887207,-1.0,accept,majority_agreement
552223208,8170,"i'm pretty sure the meaning of can/may has degraded in the us language, but i like the sound of may more anyways. might is also the future tense, so that doesn't feel right. i'm going to intentionally not conflate it with write commands, since this is any commands that replicate data over the replication stream. we've talked about pulling out a separate channel for non-writes, and at that time we might revisit this.",0,0,0,0.666624128818512,0.8279178738594055,0.8973827362060547,0.0,accept,unanimous_agreement
552223513,8170,"the original documentation of clientsarepaused, is just that it returns non-zero, so it's checking against zero. it seems like the wrong choice to keep that, so now it behaves like a bool as expected.",-1,0,0,0.5384531617164612,0.9121460914611816,0.8851099014282227,0.0,accept,majority_agreement
552224087,8170,"i'm not convinced it's useful. if there is a usecase you think makes sense, i agree it'll be straightforward to implement.",0,0,-1,0.933329701423645,0.6936578154563904,0.7902169227600098,0.0,accept,majority_agreement
552224530,8170,"i was copying the pattern from above, mind if this get's punted to a separate pr? the wait tests currently take like 10 seconds.",0,0,0,0.974038541316986,0.905215620994568,0.982287347316742,0.0,accept,unanimous_agreement
552252042,8170,i agree with oran.,0,0,0,0.9548770189285278,0.9340445399284364,0.9617374539375304,0.0,accept,unanimous_agreement
552252304,8170,"i changed my mind, this code is complex, and just having one type will simplify everything.",0,0,0,0.7580292820930481,0.6295186877250671,0.7748386859893799,0.0,accept,unanimous_agreement
552256780,8170,"i'll update to add an assert. this will break backwards compatibility in one way, you will no longer be able to do: [code block] since that would violate this constraint.",0,0,0,0.9502442479133606,0.9647996425628662,0.9947364926338196,0.0,accept,unanimous_agreement
552307965,8170,"the client was blocked. it was then unblocked and put onto the unblocked list. now we are processing that list... at this point, how can client_blocked be set? if it's set, we shouldn't have moved it to the unblocked list, right? i agree that the client can be re-blocked after calling `processcommandandresetclient`, but i'm not sure how the client can be blocked at this line.",0,0,0,0.9481846690177916,0.9668651223182678,0.9224568605422974,0.0,accept,unanimous_agreement
552316998,8170,"oh, i think the comment ""the code is conceptually more correct this way"" is the only reason this is there.",0,0,0,0.9395565390586852,0.951168954372406,0.9870861768722534,0.0,accept,unanimous_agreement
552317472,8170,i found a semi-ok work around.,0,0,0,0.9808459877967834,0.9466387629508972,0.966460108757019,0.0,accept,unanimous_agreement
552393415,8170,"one usecase would have been during loading, and busy scripts. instead of responding with error to all requests, we can just postpone them. this can make the life of users much easier (kinda like the annoying eagain retry that's needed just because the process got and handled a signal). but i agree we can leave this for a later stage.",0,0,0,0.926354706287384,0.9326459169387816,0.968697428703308,0.0,accept,unanimous_agreement
552393948,8170,"ok, we'll handle it some other day.",0,0,0,0.9718068838119508,0.9881682991981506,0.9772807955741882,0.0,accept,unanimous_agreement
552398270,8170,"i'm not certain we have to support that. why would someone do that? why wouldn't they do [code block] seems more straight forward. is there are real use case for that, or are we just concerned not to break something that users may already be using?",0,0,0,0.7046416401863098,0.657987654209137,0.7969701886177063,0.0,accept,unanimous_agreement
552401269,8170,this is a bit odd. either re-instate the comment saying: [code block] or just check that both come back empty? `[r get foo] == {} && [r get bar] == {}`,-1,-1,-1,0.9345942735671996,0.8691686391830444,0.7570878863334656,-1.0,accept,unanimous_agreement
552402035,8170,let's add `$rd close` at the end,0,0,0,0.9878166317939758,0.9913852214813232,0.9947022795677184,0.0,accept,unanimous_agreement
552404290,8170,"doing the set before the client pause is more sensible, but it will still trigger the assert as long as client pause is sent in a multi-block that propagates something. since it's within a multi-block, the final exec will always propagate at the end of the block. since client pause will now be active, that will trigger a crash. i don't think it's a likely case, but it seems possible someone might trigger it. i think the assert is really useful as you mentioned, to make sure we're being correct here.",0,0,0,0.9468559622764589,0.9041213393211364,0.8370151519775391,0.0,accept,unanimous_agreement
552405923,8170,"we normally don't add an explicit option which is the same as the default. i.e. `client pause` and `client pause all` are the same. i admit it has its pros, but i still wonder why you did that?",0,0,0,0.7885971069335938,0.6667187809944153,0.6954435110092163,0.0,accept,unanimous_agreement
552408450,8170,"this was based on your comment we might add more types. they will all be mutually exclusive, so it's more that this an enum type.",0,0,0,0.9842299818992616,0.9917844533920288,0.9938522577285768,0.0,accept,unanimous_agreement
777429914,10043,`utils/generate-command-help.rb` can be deleted. and maybe update a comment in `tests/support/util.tcl` that refers to `help.h`,0,0,0,0.9807337522506714,0.9956563711166382,0.9937983155250548,0.0,accept,unanimous_agreement
777430497,10043,"i know redis-cli is a bit less consistent about that than redis, but i think we should avoid introducing new code with line comments.",0,0,0,0.963326096534729,0.9067803025245668,0.9791629910469056,0.0,accept,unanimous_agreement
777549561,10043,note to self. check if everything works with both resp3 and resp2,0,0,0,0.9764565229415894,0.9845008850097656,0.979438304901123,0.0,accept,unanimous_agreement
777550414,10043,"note to self, test how this works with old redis versions.",0,0,0,0.9860153198242188,0.9885537624359132,0.9922307133674622,0.0,accept,unanimous_agreement
777550755,10043,fyi #10028,0,0,0,0.9620736837387084,0.9843115210533142,0.9895557761192322,0.0,accept,unanimous_agreement
777552432,10043,"styling in redis is usually that on multi-line `if` the opening bracket is on the next line, but on `if-else` it's on the same line. e.g. [code block]",0,0,0,0.9882858395576476,0.993805766105652,0.9941381216049194,0.0,accept,unanimous_agreement
777555381,10043,"what are these checks? please add a comment, but also, i couldn't find that we used these, and maybe we should check others?",0,0,0,0.9805557131767272,0.9890045523643494,0.9923256635665894,0.0,accept,unanimous_agreement
777683268,10043,oops - i haven't written much c lately. (i assume you're referring to the double-slash.),-1,-1,-1,0.9411394000053406,0.9658428430557252,0.8112221360206604,-1.0,accept,unanimous_agreement
777683690,10043,is there any kind of style guide?,0,0,0,0.982649564743042,0.990542471408844,0.9911960363388062,0.0,accept,unanimous_agreement
777684095,10043,these checks were in the original code. apparently they're some kind of sanity check on the output of command? it's not clear to me why these specific checks appeared but not others.,0,0,0,0.9435663819313048,0.951971173286438,0.9784762263298036,0.0,accept,unanimous_agreement
777700359,10043,"no.. just looking at the code around you and try to mimic it's style. but sadly, redis-cli is not very consistent with the rest of redis (which isn't very consistent with itself)",-1,-1,-1,0.8294551968574524,0.5240757465362549,0.6474945545196533,-1.0,accept,unanimous_agreement
777700783,10043,"since we're revamping this area, i think we should take this opportunity to change this, or document what exactly it's for..",0,0,0,0.9581171870231628,0.9826799631118774,0.9791359305381776,0.0,accept,unanimous_agreement
781360612,10043,so i'll put this on hold until that pr is finalised.,0,0,0,0.9853160977363586,0.9917815327644348,0.989327311515808,0.0,accept,unanimous_agreement
781370777,10043,"okay, these checks were added in b6ab4d0: ""fix redis-cli rare crash. this happens if the server (mysteriously) returns an unexpected response to the command command."" basically, the code checks that each of the fields it intends to read from the command reply array actually exists and has the correct expected type. if not, it returns early with no error message. if we want to maintain the equivalent behaviour, these checks should be removed (except for `element[0]`), since the new code doesn't read the same fields, and the command parsing code in `cliinitcommandhelpentry()` should check the validity of each field before reading it.",0,0,0,0.9685003757476808,0.990345537662506,0.9848699569702148,0.0,accept,unanimous_agreement
784436618,10043,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
784437060,10043,"no longer relevant - the code now only retrieves command docs, which doesn't exist on old versions.",0,0,0,0.9819886088371276,0.96769517660141,0.9845991134643556,0.0,accept,unanimous_agreement
784437233,10043,"i've replaced these checks with type assertions throughout the code, which also seems more consistent with the rest of the file.",0,0,0,0.9882135391235352,0.982083797454834,0.9897631406784058,0.0,accept,unanimous_agreement
784762883,10043,still need to test how it works on old versions (should at the very lest not explode). is there absolutely no benefit of using the old command command?,0,0,0,0.9555449485778807,0.9744437336921692,0.9720675945281982,0.0,accept,unanimous_agreement
785541313,10043,"now that you mention it... the old (i.e., current) implementation uses the output of command to generate stub help entries for commands not in the help.h file, with parameters named ""key"" and ""arg"". i presume this was used for dynamically-loaded commands such as modules. if we want, we can use this as a fallback mechanism in case command docs is unavailable, presumably when connecting to a previous version of the server. if we want to do that, we could call command info if command docs doesn't exist.",0,0,0,0.9883408546447754,0.9938622713088988,0.9850159883499146,0.0,accept,unanimous_agreement
785769108,10043,"the value of doing that seems low (showing ""arg"" and ""key""), so we can choose to do that only if the effort is low too. but what about showing a list of commands or auto-complete / suggest command names?",0,0,0,0.9780110120773317,0.985599160194397,0.9885697960853576,0.0,accept,unanimous_agreement
785817624,10043,"command docs contains all the command and subcommand names, so that should already be covered.",0,0,0,0.9892218112945556,0.9931657910346984,0.9929471015930176,0.0,accept,unanimous_agreement
785819923,10043,i meant that this part of the cli help can keep working on old redis versions if we fallback to command command.,0,0,0,0.9799414873123168,0.9879667162895204,0.9815775752067566,0.0,accept,unanimous_agreement
785825923,10043,"oh, right. yes, that's an option. ultimately, this is a product decision: what level of help support do we want to maintain for old server versions? and how much code is worth maintaining for that purpose?",0,0,0,0.9568110108375548,0.9577769637107848,0.90980327129364,0.0,accept,unanimous_agreement
785827224,10043,"as i said, i don't see much value in the ""arg"" and ""key"" tips. listing the commands is nice, but that's also low value, so only if the cost is low.",0,0,0,0.9721137881278992,0.9076759815216064,0.8185930252075195,0.0,accept,unanimous_agreement
786143636,10043,"okay, i added the command names from command as a fallback. i don't think it's too much code to support, but it also gives only limited benefit. it doesn't even have subcommand names.",0,0,0,0.9661273956298828,0.9728071093559264,0.9629872441291808,0.0,accept,unanimous_agreement
792197891,10043,"fyi: under resp3, the ""arguments"" field appears to be returned as a set. this seems odd, as command arguments are ordered.",0,0,0,0.9209079146385192,0.8393681049346924,0.9314129948616028,0.0,accept,unanimous_agreement
792386036,10043,can you please make a pr to fix this?,0,0,0,0.981886625289917,0.9927789568901062,0.9938346147537231,0.0,accept,unanimous_agreement
792657830,10043,redis usually uses this style [code block],0,0,0,0.9890517592430116,0.9932656288146972,0.994899570941925,0.0,accept,unanimous_agreement
792724588,10043,"do we really need these asserts? what if the config.resp3 is outdated (we meant to use resp3, but fails, and didn't update the config). i think we can just handle both types, no need for these asserts.",0,0,0,0.9844373464584352,0.9842188954353333,0.9846952557563782,0.0,accept,unanimous_agreement
792749423,10043,"we're using this just to show the `since` when user types ""help"", right? maybe we should do the same with the `history` entry? or maybe drop both? i.e. it was useful in the past in case you used a new redis-cli with an old redis-server (so you get indication of things you might not be able to use). but now when you get the hints that are relevant for the same version you're using, why do we need it?",0,0,0,0.9803617000579834,0.988934338092804,0.982593834400177,0.0,accept,unanimous_agreement
792761323,10043,"ohh, does this mean that the other assertions down the line are not reachable? still i think we shouldn't look at `config.resp3`, and instead just be able to handle both types silently.",0,0,0,0.9445403218269348,0.9253411293029784,0.9702871441841124,0.0,accept,unanimous_agreement
792777598,10043,"would you get rid of all the asserts? i just put them in for consistency. there are element type assertions elsewhere in the file. or i could change this assert to accept either type. the actual handling code is the same either way. if the reply data is wrong for some reason, the code will crash somewhere. if it doesn't crash on an assertion it will crash somewhere else. i don't have a strong attachment to the asserts, though. whatever makes sense to you.",0,0,0,0.9325489401817322,0.90844464302063,0.952025294303894,0.0,accept,unanimous_agreement
792779145,10043,"makes sense. so just drop ""since"" from the help output? they can always look it up online if they're just curious about the history.",0,0,0,0.9803941249847412,0.9869056344032288,0.9840394854545592,0.0,accept,unanimous_agreement
792781940,10043,"basically, the effect of this `return` is that if the reply from `command docs` is insanely wrong, it will skip initializing the help data and run without help or hints. if it gets past this, then any failed assertion will crash the cli.",0,0,0,0.7056212425231934,0.8346732258796692,0.9195581674575806,0.0,accept,unanimous_agreement
792782804,10043,maybe all the asserts in the help initialization should just silently abort loading the help data and return control to the command line?,0,0,0,0.9851064682006836,0.988063395023346,0.9871056079864502,0.0,accept,unanimous_agreement
792810857,10043,"i'm ok with the assert, i just don't think we should depend on `config.resp3` (in asserts or `if`s`, but rather just handle what we can, and fail on what we can't handle)",0,0,0,0.9741964936256408,0.934601366519928,0.8652614951133728,0.0,accept,unanimous_agreement
792811209,10043,this pattern exists in several other functions you added.,0,0,0,0.988139271736145,0.9892701506614684,0.9941866397857666,0.0,accept,unanimous_agreement
792812593,10043,"i'm ok with both the asserts and `return`, just don't think we need to use `config.resp3`.",0,0,0,0.9875898361206056,0.951981008052826,0.9671229720115662,0.0,accept,unanimous_agreement
792828853,10043,fixed.,0,0,0,0.9810503125190736,0.979083240032196,0.9905837774276732,0.0,accept,unanimous_agreement
792829042,10043,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
792864592,10043,"this one is merged, so you can merge from unstable and fix the parsing code if needed.",0,0,0,0.9887409806251526,0.9907310605049132,0.9947746396064758,0.0,accept,unanimous_agreement
792866068,10043,missed a few.. [code block],0,0,0,0.808699369430542,0.967467725276947,0.8970983624458313,0.0,accept,unanimous_agreement
793573943,10043,"that dictadd will usually fail, right? in which case we leak memory",0,0,0,0.9736218452453612,0.9406068921089172,0.9811530113220216,0.0,accept,unanimous_agreement
799338104,10043,we now wanna keep this file,0,0,0,0.9806479811668396,0.9224801063537598,0.9941148161888124,0.0,accept,unanimous_agreement
799342847,10043,?,0,0,0,0.9320514798164368,0.9557723999023438,0.9296892285346984,0.0,accept,unanimous_agreement
799393224,10043,"oh, i thought the plan was to keep `help.h` constant. will fix.",0,0,0,0.949249804019928,0.9675213098526,0.9741895794868468,0.0,accept,unanimous_agreement
799403909,10043,oops - fixed.,0,-1,-1,0.9797250628471376,0.797854483127594,0.947247326374054,-1.0,accept,majority_agreement
559096268,8324,"i think we need to improve the doc comment here and explain what's a ""range"". maybe refer to the command command docs.",0,0,0,0.9851073622703552,0.9850096106529236,0.980701208114624,0.0,accept,unanimous_agreement
559097744,8324,looks like you added this line (redismodule_ismodulenamebusy) by mistake?,0,0,0,0.988362729549408,0.9808827042579652,0.9885026216506958,0.0,accept,unanimous_agreement
559099712,8324,can't we know the count in advance? i.e. there's no need for a deferred reply here.,0,0,0,0.983786642551422,0.9841480255126952,0.992003619670868,0.0,accept,unanimous_agreement
559159701,8324,"we need to let modules add arbitrary flags that will be visible to the clients. let's save the original string in the spec, and reflect that string in the output of command command. (and also document it in the module api) it would also be nice to do that for the command flags somehow, but maybe as a separate pr.",0,0,0,0.9771174192428588,0.9912583231925964,0.9913881421089172,0.0,accept,unanimous_agreement
559332112,8324,[code block] would this be more safe.,0,0,0,0.9849278926849364,0.9885263442993164,0.9879557490348816,0.0,accept,unanimous_agreement
559426693,8324,"like the modulecommand command, which is not initialized with keys_specs_static, could it cause unforeseen problems?",0,0,0,0.9619340300559998,0.9909720420837402,0.9882590770721436,0.0,accept,unanimous_agreement
559478538,8324,"is it `continue`? the current command definition will not have problems with break, but if there are other definitions before the kspec_range definition, it may cause the legacy_range_key_spec data to be inconsistent with the old version. like this: [code block] i wrote a test, if i change the code above. output: [code block] the correct output should be: [code block]",0,0,0,0.9868480563163756,0.9925082325935364,0.9909173846244812,0.0,accept,unanimous_agreement
560808243,8324,"not sure i understand, modulecommand is also handles in this function",0,0,0,0.9809561371803284,0.965435028076172,0.9070011377334596,0.0,accept,unanimous_agreement
560878861,8324,"sorry, i feel that my understanding is wrong.",-1,-1,-1,0.9850858449935912,0.990327775478363,0.9924174547195436,-1.0,accept,unanimous_agreement
561065084,8324,"`cmdhasmovablekeys` gets called quite often, i think it will be a good idea to precompute this as a command flag.",0,0,0,0.5984766483306885,0.9775789380073548,0.9569585919380188,0.0,accept,unanimous_agreement
561066852,8324,nit: add a default case with assertion.,0,0,0,0.9873449206352234,0.9902951717376708,0.993809163570404,0.0,accept,unanimous_agreement
561072014,8324,is there a particular reason we keep using the custom getkeys_proc callbacks when keyspecs are available?,0,0,0,0.9788955450057985,0.9930049777030944,0.9943630695343018,0.0,accept,unanimous_agreement
561080001,8324,"i guess they won't be totally arbitrary, still validated against a set of known flags right?",0,0,0,0.974969446659088,0.8726840019226074,0.9741804003715516,0.0,accept,unanimous_agreement
561082157,8324,"don't like this, would be much happier with `rm_createcommandex` or something but i acknowledge that modules will probably end up using both anyway which is ugly as well. can't think of anything better, but please comment if you do!",-1,-1,-1,0.9764800667762756,0.9564729332923888,0.99472177028656,-1.0,accept,unanimous_agreement
561097730,8324,"we plan to do it at some point, but we think the complexity of getting key indices in a generic way is complicated both to code and both in cpu also there the ambiguity problem, for example if a user has a keyname called ""streams"" in xread",0,0,0,0.9487136602401732,0.9786232709884644,0.9837427139282228,0.0,accept,unanimous_agreement
561107665,8324,"`rm_createcommandex` would mean it needs to get a pointer to an array of structs, and we'll have to declare an abi stable strut. but the bigger problem is that modules that want to work with both redis versions (old and new) need to call the old rm_createcommand, and then call the new rm_addcommandkeyspec variants optionally (only if they exist). i.e. if we have a new rm_createcommandex, modules will need to have an if-else and bother to call both.",0,0,0,0.9459084868431092,0.9921101927757264,0.9856945872306824,0.0,accept,unanimous_agreement
561162244,8324,isn't this specific issue a limitation we should try to address with the keyspec?,0,0,0,0.982333242893219,0.98993182182312,0.9881965517997742,0.0,accept,unanimous_agreement
561236050,8324,"it would be nice, but i don't have an idea. the only way i can think of is to add a full argument spec for the command (like the one in commands.json in redis.io), but that would be complicated for client libraries to work with. this simple approach is easy to use and will almost always work. additionally we aim to gradually depreciate all these keyword argument commands. meanwhile, since redis already has these getkeys procs, i think is should keep using them",0,0,1,0.7782718539237976,0.8663738965988159,0.5626704096794128,0.0,accept,majority_agreement
561239941,8324,"yes, that's why i mentioned it's not necessarily better.",0,0,0,0.7877576947212219,0.8980131149291992,0.9840409755706788,0.0,accept,unanimous_agreement
561241828,8324,i'm ok with leaving the redis implementation as is but i have a concern about the keyspec. basically this means we should not use `keyword` for `xread` because clients implementing it may parse the command the wrong way.,0,0,0,0.5835222005844116,0.9601046442985536,0.8891287446022034,0.0,accept,unanimous_agreement
561244462,8324,"but what else can we do at this point in time? georadius* xread* sort*, stralgo, migrate and memory are terrible in that manner (hard to find the key names).",-1,-1,-1,0.972123682498932,0.8888294696807861,0.9868770837783812,-1.0,accept,unanimous_agreement
563176410,8324,"i actually meant totally arbitrary, but that's actually wasn't meant for the key-spec flags, but rather the command flags. i wanted for modules to add flags such as ""all-shards"" and such (hinting proxies and clients with some things). but later realized two things: 1. it has nothing to do with this pr (since it's related to the command flags) 2. these flags must be documented in redis.io and in that case they can indeed by validated by redis. i asked and to open another issue to discuss that",0,0,0,0.962601602077484,0.9186831712722778,0.9746382236480712,0.0,accept,unanimous_agreement
563176983,8324,"i guess you forgot about this one. let's just mention in the comment something like: `(to be used for command command output)` this way people can go look the meaning of these flags in the docs. the alternative is to document the meaning of `step`, `startfrom` etc, including the negative notations. maybe it's not a bad idea. (i.e. do both, mention command command output, and the meaning of each arg).",0,0,0,0.9213244915008544,0.9602593779563904,0.8451565504074097,0.0,accept,unanimous_agreement
564964597,8324,this makes more sense as an enum.,0,0,0,0.9800578355789183,0.9868393540382384,0.9886128902435304,0.0,accept,unanimous_agreement
564973468,8324,"sometimes you use ""keys specs"" and sometimes its ""key specs"". it would be nice if they were all consistent, unless there is some meaning to differentiate the two.",0,0,0,0.9821661114692688,0.9916821718215942,0.9780516028404236,0.0,accept,unanimous_agreement
564985559,8324,"so if something doesn't work with this ""best effort"" algorithm, do we need to handle it specially when constructing the keyspec in the main server table? otherwise i'm not clear what the implication is here.",0,0,0,0.9492471218109132,0.6520673632621765,0.9659390449523926,0.0,accept,unanimous_agreement
564988741,8324,"this function can return a value, but value error is never checked, should be asserting instead?",0,0,0,0.9889577627182008,0.9855359196662904,0.9884109497070312,0.0,accept,unanimous_agreement
564990220,8324,"i think this structure should be documented explaining what the different keyspecs are. i didn't see a clear definition anywhere else, and it's probably useful to have somewhere. although some of these are self explanatory, some are less clear. for example, i'm not sure what ""keycount"" is. is it the number of keywords we expect, the position of the key from the keyword, the number of keys after the keyword.",0,0,0,0.956353724002838,0.9464171528816224,0.7357645630836487,0.0,accept,unanimous_agreement
565066657,8324,"the best effort here is to come up with a legacy range that is as broad as possible. the only use for that legacy range is the backwards compatible response of the command command. i.e. clients that look only at indexes 4,5,6 need to still be able to find there what they're looking for. so instead of maintaining these legacy ranges in the command table, we generate them at runtime by looking for consecutive ranges. that comment was meant to tell that story, so if it wasn't clear enough, maybe you can suggest a phrase that will fill in the gap that caused the confusion?",0,0,0,0.9714097380638124,0.9818430542945862,0.987033486366272,0.0,accept,unanimous_agreement
696046288,8324,"iirc following this discussion we came up with the `limit` option for the search (although i don't see it in the pr top comment). and we also came up with some definition for guarantees, which are that some specs can be marked as ""incomplete"", which means they may not find all keys, but the ones they do, are always right (assuming the command's syntax is correct). i think the pr top comment is missing these, and also an example",0,0,0,0.9731439352035522,0.9684947729110718,0.98007994890213,0.0,accept,unanimous_agreement
696049874,8324,a comment explaining what it does is needed.,0,0,0,0.970605194568634,0.9787265062332152,0.9913772344589232,0.0,accept,unanimous_agreement
696053036,8324,would be nice to add a comment of what bs and fk mean,0,0,0,0.8985697031021118,0.979706346988678,0.9545835256576538,0.0,accept,unanimous_agreement
696060986,8324,"the documentation is lacking. obviously it should refer to somewhere that describes keyspaces and the various types there are (we don't have that yet). but some other aspects of this api must be documented: - the `spec_id` concept - when it should be called (after command registration) - what happens to the first,last,step that were added during command registration. i also have some issue with the naming of these. the ones that are about ""beginsearch"" can be named ""add"", but the other two should be named ""set""? maybe it's a better interface to have just one ""add"" api, that returns an index. and the other 4 methods, both for setting the beginsearch and the findkeys should be prefixed by ""set"" rather than ""add""",0,0,-1,0.8538216352462769,0.9861418604850768,0.5222916007041931,0.0,accept,majority_agreement
696065554,8324,why the `read` flag?,0,0,0,0.9719469547271729,0.9895381927490234,0.9887831807136536,0.0,accept,unanimous_agreement
696067570,8324,"ohh, because of the get option. we may wanna add a comment (it's confusing)",-1,-1,-1,0.9154176115989684,0.8035416603088379,0.6794931888580322,-1.0,accept,unanimous_agreement
696069779,8324,"maybe we better give both `read` and `write` flags because we don't know? i.e. for some client logic it might be better to have both set, rather than none?",0,0,0,0.9821457266807556,0.9937509894371032,0.984870195388794,0.0,accept,unanimous_agreement
696315712,8324,"we can't use assert since this function fails a lot. what matters is the action it takes the bottom (storing the lagacy spec), so the caller doesn't really care about the return value. we can change it to void, or keep ignoring it. p.s. i do see that some of the early exists are c_ok (even ones that don't store a legacy spec), and others are c_err.",0,0,0,0.9517062306404114,0.9795123934745787,0.9827064275741576,0.0,accept,unanimous_agreement
699931605,8324,"i did mention `limit` and `incomplete` specs in the top comment, but i did miss the fact that some `incomplete` specs can be completely empty (i.e. unknown begin_search) which should tell the client that command getkeys must be used",0,0,0,0.9513108730316162,0.9934241771697998,0.9857103228569032,0.0,accept,unanimous_agreement
699994268,8324,"i meant a limit for the keyword search, not for the range spec",0,0,0,0.9784660935401917,0.9870327711105348,0.9872660636901855,0.0,accept,unanimous_agreement
700046076,8324,"i'm ok with this function returning `void` (because of what oran said) but the assertions are necessary imho: they make sure the function works properly (i.e. if we have a bug and for some reason lastkey==0 we would like to know about it asap rather then fail silently) for the record: c_ok means that the legacy range was populated correctly (also if we didn't do anything, if there aren't any specs at all)",0,0,0,0.9823023676872252,0.9625834822654724,0.8621759414672852,0.0,accept,unanimous_agreement
700051087,8324,"also, it can help a module writer catch bugs just on startup... for example, the module writer provided ""index"" bs of 0 (which is the command name). we would like to catch that asap",0,0,0,0.9714407920837402,0.9932138919830322,0.9868873953819276,0.0,accept,unanimous_agreement
700053180,8324,is that a bug then?,0,0,0,0.8407147526741028,0.9614834189414978,0.9561294913291932,0.0,accept,unanimous_agreement
700096614,8324,"no, that's how the function was supposed to behave anyway, it's going to return `void` so it doesn't matter what do you think about these assertions? if you're against i could make it return error if the user input doesn't make sense and c_ok otherwise. then the caller needs to fail onload or something like that instead of crashing the server",0,0,0,0.9127566814422609,0.9222657084465028,0.9720962047576904,0.0,accept,unanimous_agreement
700104283,8324,"for redis, i suppose an assertion is ok. for a module, i think i'd rather return an error, unless we think it is likely that the module will not check for that error, and the whole thing can go overlooked, in which case i'm ok with an assert (since this is a new api, we'll fail modules during development). maybe instead of an assertion we can disable module commands that failed that, so the module author will not be able to overlook it, but then it'll be hard for them to figure out why the command got disabled, so i guess an assertion is better.",0,0,0,0.9634616374969482,0.9747894406318665,0.89915931224823,0.0,accept,unanimous_agreement
700468959,8324,"considering modules (even new ones) may still wanna be compatible with old versions of redis, maybe we wanna encourage people to keep using these for simple ranges? we did make the code handle this case properly, right? a case where the first range is added in the command registration and the others added later?",0,0,0,0.9818347692489624,0.9915001392364502,0.9867357611656188,0.0,accept,unanimous_agreement
700476181,8324,maybe if we name the command `kspec.smove` it'll be clearer? i.e. give an example of a module that mimics a built in command with multiple specs..,0,0,0,0.9883501529693604,0.9953827261924744,0.9860942363739014,0.0,accept,unanimous_agreement
700510543,8324,i suppose we need to refer to command command here? or cluster aware clients?,0,0,0,0.9871702790260316,0.9930021166801452,0.9926969408988952,0.0,accept,unanimous_agreement
700514483,8324,"all the nuances of the various arguments in these functions (negative values etc) are not documented in rm_addcommandkeyspec, so they should either be documented here, or maybe have a reference to command command where they'll be documented soon.",0,0,0,0.9878387451171876,0.99460768699646,0.9914630055427552,0.0,accept,unanimous_agreement
700885530,8324,"just summarizing, for the record: xread is actually not an issue: assuming the syntax is correct, there are no arbitrary strings in argv up until streams (only command name, optional tokens, and numbers), so it's safe to use ""keyword"" the command we have issues with are migrate, stralgo, and sort for migrate, because the token keys, if exist, must be the last token, we can search in reverse. it one of the keys is actually the string ""keys"" will return just a subset of the keys (hence, it's ""incomplete"") for sort and stralgo we can use this heuristic (the keys can be anywhere in the command) and therefore we added a key spec that is both ""incomplete"" and of ""unknown type"" if a client encounters an ""incomplete"" spec it means that it must find a different way (either command getkeys or have its own parser) to retrieve the keys. please note that all commands, apart from the three mentioned above, have ""complete"" key specs",0,0,0,0.9633889198303224,0.9839431047439576,0.9751283526420592,0.0,accept,unanimous_agreement
700914570,8324,"this is a good description, maybe it should be copied to the top comment, or to a redis-doc pr. for now i was thinking of not suggesting to make a redis-doc pr since we currently added this data to the command command, but we plan on moving it out of it soon and into the commands command.",0,0,0,0.9374237656593324,0.9827468395233154,0.6761386394500732,0.0,accept,unanimous_agreement
701043303,8324,yes i modified the test to cover that scenario (next commit),0,0,0,0.9874317646026612,0.9894455075263976,0.9936206936836244,0.0,accept,unanimous_agreement
701145677,8324,"let's format this as a markdown list, see `rm_streamtrimbylength` as an example",0,0,0,0.9873145818710328,0.992850661277771,0.9949769377708436,0.0,accept,unanimous_agreement
701147640,8324,actually in smove the first key is also write. [code block],0,0,0,0.9894992113113404,0.9936436414718628,0.994601845741272,0.0,accept,unanimous_agreement
701312704,8324,don't we also wanna avoid the deprecation notice and explain that these serve a limited purpose and the more advance ones can be used if you have a complicated spec?,0,0,0,0.9762176275253296,0.9613996744155884,0.9923498034477234,0.0,accept,unanimous_agreement
701673907,8324,"yes, next commit",0,0,0,0.9863835573196412,0.9748929738998412,0.9816323518753052,0.0,accept,unanimous_agreement
1465002211,12913,"i think that intead of `mem_db_bucket_overhead_ht0` and `mem_db_bucket_overhead_ht1`, which are low level details. we should have `mem_db_hashtable_overhead_total` and `mem_db_hashtable_overhead_rehashing` i.e. the `total` should be ht0+ht1, and the `rehashing` is just ht1.",0,0,0,0.9869385957717896,0.9927073121070862,0.9878870248794556,0.0,accept,unanimous_agreement
1465005376,12913,"actually, looking at my [a link] the `rehashing` metric is not `ht1`, it's `ht0` of dicts that also have `ht1` allocated (dicts that are undergoing rehashing). so the raw counters should be different than what you implemented.",0,0,0,0.9869834184646606,0.9882502555847168,0.9916609525680542,0.0,accept,unanimous_agreement
1465106935,12913,"i see ... so once `ht1` is allocated, it is considered as the ""main"" hash table, and `ht0` becomes rehashing overhead.",0,0,0,0.986929416656494,0.9912273287773132,0.9899890422821044,0.0,accept,unanimous_agreement
1465768010,12913,"i can understand that the term ""hashtable"" refers to the array of `dictentry` pointers stored in the dict, and its overhead refers to the size of this pointer array. however, it's a bit unfortunate that the memory stats also include an item with ""hashtable"" and ""overhead"" in its name: `overhead.hashtable.main`. this item not only calculates the size of the pointer array but also includes the size of all `dictentry`, `robj`, and metadata. do we need to consider renaming it to differentiate it more clearly? for example, `mem_db_dict_ht_total`, but it might seem too low-level.",-1,0,-1,0.628607451915741,0.915855884552002,0.8776739835739136,-1.0,accept,majority_agreement
1465942650,12913,"that's unfortunate, but i don't like to rename existing metrics. and at the same time i don't like to mention `ht0` and `ht1`. so let's keep `overhead.hashtable.main`, `overhead.hashtable.expiers`, and maybe call the new ones `overhead.hashtable.lut` and `overhead.hashtable.lut.rehashing`. i think we should add them to both `memory stats`, and `info memory` p.s. i'm willing to drop `overhead.hashtable.lut`, and only add `overhead.hashtable.rehashing`",-1,-1,-1,0.9721198678016664,0.9884114265441896,0.9469210505485536,-1.0,accept,unanimous_agreement
1465996713,12913,"i wasn't suggesting renaming existing metrics `overhead.hashtable.main` or `overhead.hashtable.expires`. i mean we can give the newly added metric in this pr a more appropriate name to differentiate it from the existing metrics. btw, i'm thinking if we can modify the semantics of `overhead.hashtable.main` to only represent the size of the dictentry pointer array. then, we can add a new metric like `overhead.database.main` to represent the overall overhead size including the size of all dictentry, robj, and metadata. then the meaning of the new metric and the existing metric will be consistent. wdyt?",0,0,0,0.9664484262466432,0.98638516664505,0.978126347064972,0.0,accept,unanimous_agreement
1466089752,12913,"i think that in some sense, reducing the scope of the existing metric from counting a total to counting just a portion, and adding a new one for the total, would be a breaking change. let's just keep it intact and add 2 new metrics (to both memory stats and info memory). we just need to choose a suitable name. so it can be `overhead.hashtable.lut`, add `overhead.hashtable.rehashing` or maybe someone can suggest something better?",0,0,0,0.9714088439941406,0.986611008644104,0.9699923396110536,0.0,accept,unanimous_agreement
1466181649,12913,"i'm fine with `overhead.hashtable.lut` and `overhead.hashtable.rehashing`, let's just go on with this.",0,0,0,0.9815338253974916,0.9738422632217408,0.954566240310669,0.0,accept,unanimous_agreement
1466260689,12913,"don't we also need to zero these when a dict is deleted or detached? i.e. `emptydbstructure()`, which will take care of flushdb sync/async, and repl_diskless_load_swapdb or maybe it's a better idea to just call the `rehashingcompleted` callback from `_dictclear()`? i.e. we're already have some leaks in the bucket counters? ptal.",0,0,0,0.9880147576332092,0.992956042289734,0.9919974207878112,0.0,accept,unanimous_agreement
1466282638,12913,"yes we need, and i do want to zero them in `_dictclear()`. it just took me some time to make sure all cases are covered.",0,0,0,0.9825411438941956,0.9856824278831482,0.9914215207099916,0.0,accept,unanimous_agreement
1466293928,12913,"or, we may have a new callback in dicttype that is called when dict is cleared/released?",0,0,0,0.9889658093452454,0.994687795639038,0.9936410784721376,0.0,accept,unanimous_agreement
1466347550,12913,"maybe we can just call the existing callbacks. i.e. if we're in the middle of rehashing, trigger `rehashingcompleted`. and after that, call rehashingstarted and rehashingcompleted with destination size of 0?",0,0,0,0.9869449734687804,0.99519145488739,0.9851526021957396,0.0,accept,unanimous_agreement
1467309252,12913,"i edit the metrics in `emptydbstructure()` bacause `_dictclear()` may involve too many other structures. is there any other code clearing dict in dbs? i hope i didn't miss them. and i prefer to modify the metric derectly instead of calling `rehashingstarted` and `rehashingcompleted`, because most of their job is already done in `emptydbstructure()`.",0,0,0,0.937273383140564,0.9856759309768676,0.9297432899475098,0.0,accept,unanimous_agreement
1468365034,12913,"i see we already handle `server.rehashing` and `bucket_count` in emptydbstructure, so i guess we're good to go. in theory there's some room for messing up things when we deal with server struct globals, because in repl_diskless_load_swapdb there are several dictionaries being handled, but it look like the code handles them correctly (by removing what's in the dict being released, rather than zeroing variables)",0,0,0,0.7520293593406677,0.9742782711982728,0.7596875429153442,0.0,accept,unanimous_agreement
1468366387,12913,don't we need to deduct `exp[0]` from `_lut` too? i.e. the `lut` metric counts both tables.,0,0,0,0.9878720045089722,0.9946576952934264,0.991716206073761,0.0,accept,unanimous_agreement
1469247889,12913,"we can move this out of the `if`, and eliminate the `else`",0,0,0,0.9872987866401672,0.9937012195587158,0.9927982091903688,0.0,accept,unanimous_agreement
1471460919,12913,"i would prefer just to keep this one. this one seems very actionable to me, since it indicates the temporary overhead for me. the other two seem more tightly coupled to the current implementation, and they are much harder to explain to a typical user why they are important.",0,0,0,0.8966891765594482,0.7611963152885437,0.9340956807136536,0.0,accept,unanimous_agreement
1471549541,12913,"`mem_overhead_hashtable_lut` is an important part of memory usage, we may regard rehashing overhead as ""dynamic"" overhead, and this as the sum of both ""static"" and ""dynamic"" overhead. we may display them as two aspects of lut's overhead. when the overhead of rehashing grows large, `databases_rehashing_dict_count` can tell us the keys increasing happens in a few slots or many slots, which helps monitoring data flow. these two may be not so intuitive but displaying them gives a more complete description of db's hash tables.",0,0,0,0.9698730111122132,0.9889973402023317,0.9753503799438475,0.0,accept,unanimous_agreement
1471749110,12913,"so you consider dictentry part of the key in that respect? or is it also part of the ""static"" overhead?",0,0,0,0.9853140115737916,0.9944732785224916,0.9920997023582458,0.0,accept,unanimous_agreement
1471894162,12913,i don't mean any of these. i am just saying that both aspect of look up table's overhead should be displayed together.,0,0,0,0.8518974781036377,0.9324922561645508,0.9308107495307922,0.0,accept,unanimous_agreement
1474004604,12913,"i tend to keep both. the overhead mainly consists of two parts: 1. the metadata of each key, which includes `dictentry` and `robj`. the size of these metadata items is directly proportional to the number of keys, and they do not cause memory spikes due to rehashing. 2. the other part is the hash table or lookup table, which is related to the number of buckets. however, the number of buckets does not have a one-to-one relationship with the number of keys, and rehashing can cause memory spikes. therefore, it is difficult to infer the actual size. hence, keeping both can better assist users in observing the memory usage related to the second point.",0,0,0,0.9486519694328308,0.9746128916740416,0.9783247113227844,0.0,accept,unanimous_agreement
1474216237,12913,"i personally don't mind keeping both, we have other low level metrics already anyway. p.s. till recently we had a `overhead.hashtable.slot-to-keys` in memory stats, which we now dropped. we could have kept it and measure the memory wasted by 16k * sizeof(dict).",-1,0,0,0.5320902466773987,0.9505255818367004,0.7223399877548218,0.0,accept,majority_agreement
1487099042,12913,"a lot of my perspective comes from the idea that i don't like showing information to users unless it's clear what it's useful for. i think we as engineers come from a world where more data is better, but most people are not as technically sophisticated as us and we are asking them to parse more information. i want to keep redis simple. i don't want end users to have a complete description, i want them to have a useful description. if you have a reason this information is useful, i am all for adding it. we could have kept it and measure the memory wasted by 16k * sizeof(dict). that's probably true, would make it ""less"" of a breaking change i suppose. i'm not sure that really matters though.",-1,-1,0,0.4333285391330719,0.7365630269050598,0.6031091809272766,-1.0,accept,majority_agreement
1487106598,12913,i suppose i'll also clarify i'm ok with `memory stats` having more detailed breakdown as well. we don't need all the information posted everywhere all the time.,0,0,0,0.981027126312256,0.9316218495368958,0.9868263006210328,0.0,accept,unanimous_agreement
1490576907,12913,"i don't like memory stats (i regret having it). many monitoring frameworks only collect data from info, so if a field is there, it can be easily collected, and if it's missing from info, it's not collected. in my experience, that makes memory stats useful only for manual investigation with redis-cli. p.s. we have another option (which i don't support) which is exposing it in info debug (not officially part of the interface).",-1,-1,-1,0.9796925783157348,0.8652981519699097,0.9771883487701416,-1.0,accept,unanimous_agreement
1490577922,12913,"i think that if we can't agree on everything, let's reduce the scope and merge the part we agree on.",0,0,0,0.9778439998626708,0.9465166330337524,0.9728410243988036,0.0,accept,unanimous_agreement
1491826684,12913,"my understanding is that the two more detailed fields are basically **only** useful during manual investigations? from a monitoring perspective, you really just care that extra memory was being used during the rehashing.",0,0,0,0.9247695803642272,0.9691886901855468,0.9810236692428588,0.0,accept,unanimous_agreement
1492319911,12913,"so `mem_overhead_hashtable_rehashing` for info, and the other two only in memory? let's do that.",0,0,0,0.987564980983734,0.993783712387085,0.9925905466079712,0.0,accept,unanimous_agreement
1493516373,12913,"let's do that. i am ok with this, since we can't agree on everything.",0,0,0,0.8874979019165039,0.8183951377868652,0.7227170467376709,0.0,accept,unanimous_agreement
1495185179,12913,we do not need this now?,0,0,0,0.9652337431907654,0.9676177501678468,0.9828793406486512,0.0,accept,unanimous_agreement
1495188191,12913,i suggest directly multiplying by sizeof(dictentry *) to calculate the memory here.,0,0,0,0.9857515692710876,0.9890672564506532,0.992643177509308,0.0,accept,unanimous_agreement
1495190294,12913,it's better to also calculate the `overhead_hashtable_rehashing` and display it in the stats results.,0,0,0,0.98690664768219,0.9937435984611512,0.9934515953063964,0.0,accept,unanimous_agreement
1495195925,12913,"i think it seems that each db should also have its own information about `overhead_ht_lut`, `overhead_ht_rehashing`, and `dict_rehashing_count`. wdyt?",0,0,0,0.9873654842376708,0.9887285232543944,0.984310507774353,0.0,accept,unanimous_agreement
1495198272,12913,"[code block] i think we should remove line 1250, even if `keyscount` is zero, overhead still exists, as we have discussed previously in the context of scan+del.",0,0,0,0.9890339374542236,0.9943814873695374,0.9919304251670836,0.0,accept,unanimous_agreement
1495302082,12913,or do the calculation inside `kvstoreoverheadhashtablelut` and `kvstoreoverheadhashtablerehashing`? seems more reasonable that these two functions return memory value.,0,0,0,0.9874932765960692,0.9936216473579408,0.9927672147750854,0.0,accept,unanimous_agreement
1495306054,12913,"so `overhead_hashtable_rehashing` in both `info memory` and `memory stats`, and the other two only in `memory stats`? perhaps we need to convince about this ...",0,0,0,0.9770137667655944,0.9891489148139954,0.9923479557037354,0.0,accept,unanimous_agreement
1496774907,12913,we can directly use `mh->db_overhead_hashtable_rehashing` right?,0,0,0,0.9889642000198364,0.9948425889015198,0.9939263463020324,0.0,accept,unanimous_agreement
1497490903,12913,"i think i'd rather drop that early return entirely. afaik it's here just because in non-cluster mode we don't need to maintain the bucket_count, but: 1. it looks odd, and can maybe lead to a bug someday if someone relies on that variable unconditionally. 2. before this change it'll at least also save the call to dictrehashinginfo, but now it no longer does.",0,0,-1,0.6273967027664185,0.9598937034606934,0.8683658838272095,0.0,accept,majority_agreement
1497502352,12913,i think we can use `dict get` instead of this proc. grep the tests to see how it's used elsewhere.,0,0,0,0.9867685437202454,0.9888584613800048,0.9875280261039734,0.0,accept,unanimous_agreement
1497504550,12913,this seem fragile i'd rather use assert_range,0,-1,0,0.8506091833114624,0.8357921838760376,0.5935931205749512,0.0,accept,majority_agreement
1497504988,12913,i'm not certain this is needed.,-1,-1,0,0.5685674548149109,0.5368972420692444,0.7182268500328064,-1.0,accept,majority_agreement
1497508897,12913,"i'm not sure it's a wise idea to test it this way, it could someday break. we already have other tests that test rehashing, i think it's better to just hog one of these by adding some 3 lines that test these fields (i don't even think we have to test all of them.",-1,0,-1,0.6763472557067871,0.6804840564727783,0.6262663006782532,-1.0,accept,majority_agreement
1497511294,12913,"this is fragile. i.e. coupled with the current code. i suggest matching what we know should be zero to zero, and relax the other tests with assert_range to about twice of what we measured.",-1,-1,0,0.5246384739875793,0.8953829407691956,0.9069165587425232,-1.0,accept,majority_agreement
1497513990,12913,"i think this could be going too far. i think it's enough we know to attribute part of `used_memory` to these overheads, i don't think we need to tell the user in which db they are. considering that most users use one db, it'll really be excessive (we'll see them twice)",0,0,0,0.6360202431678772,0.861894965171814,0.8994354605674744,0.0,accept,unanimous_agreement
1498502479,12913,"it is better to verify all the metrics added, right?",0,0,0,0.981899619102478,0.991214632987976,0.9916762113571168,0.0,accept,unanimous_agreement
1498513739,12913,"i think to test the overhead, it is better to do it in a clean and undisturbed server so we can have more precise results. so i wrote the test this way: an independent test, and using transaction to make sure overhead is not changed by active rehashing.",0,0,0,0.9748753905296326,0.9843495488166808,0.9835742712020874,0.0,accept,unanimous_agreement
1498842324,12913,"i have a feeling that we have too many ways to try to prevent resizing in tests, in most places we use a fork child, but recently we added a debug command (#13043). now we use multi. considering that for testing these metrics, all you need is a test that can reliably run commands when a dict is in a rehashing state, then since we already have such a test, i thought it makes more sense to add some lines to validate the metrics to an existing test rather than create a new one. you're argue that in your case it may be easier to predict the exact value of the metrics. it may be right, although i don't want to match their exact value anyway, only make sure they get back to zero when they should (no leak). anyway, this test isn't too long, we can keep it, and if we have problems with it in the future, we can re-consider the other approach.",-1,0,0,0.8327682614326477,0.9455716013908386,0.9534338116645812,0.0,accept,majority_agreement
1500330180,12913,"adding a db prefix might be better, like `db.dict.rehashing.count`, to avoid any confusion among users that it represents all the dicts currently are rehashing.",0,0,0,0.9867239594459534,0.9926742911338806,0.986244022846222,0.0,accept,unanimous_agreement
1500339586,12913,to `db.dict.rehashing.count`,0,0,0,0.9762853384017944,0.9931946992874146,0.9944489002227784,0.0,accept,unanimous_agreement
1500391221,12913,"we currently count and display all databases, but if a user has configured a large number of databases, like 1024, then even if only one db is in use, it would output 1024 results, which is overwhelming and not conducive to observation. i think we should use a different condition to avoid displaying empty databases, such as skipping them if both the keys and expires have a `kvstorememusage` of zero (also, `kvstorememusage` should no longer include the `sizeof(*kvs)`, as this part is actually already accounted for in `server.initial_memory_usage`).",0,0,0,0.9642990231513976,0.9817673563957214,0.9725021123886108,0.0,accept,unanimous_agreement
1500408558,12913,"it use to have a ""db"" prefix. see [a link] and since other metrics here don't have ""db"" prefix, i just dropped it.",0,0,0,0.986764669418335,0.9937133193016052,0.9909907579421996,0.0,accept,unanimous_agreement
1500421341,12913,or `database.dict.rehashing.count`?,0,0,0,0.984417200088501,0.9944756627082824,0.9943374991416932,0.0,accept,unanimous_agreement
1500435881,12913,"i think db is ok, since we already have the db.x section for the details of each database.",0,0,0,0.9789460301399232,0.8968669176101685,0.8739766478538513,0.0,accept,unanimous_agreement
1500457796,12913,"it turns out that ""db"" triggers the linter (see the link above), this is why i dropped it. i have no idea why this exists. [code block]",0,0,0,0.9057388305664062,0.9452212452888488,0.9828814268112184,0.0,accept,unanimous_agreement
1501797123,12913,"that change seems wrong: [code block] i think we should revert it and the `continue` in `getmemoryoverheaddata` should check how many dicts (or better yet, how many hash slots) we have in the kvstore to skip it. i.e. `if (!kvstorebuckets(db->keys)) continue;`",0,0,0,0.9306880831718444,0.9916499853134156,0.9589738249778748,0.0,accept,unanimous_agreement
1503747971,12913,should reset `overhead_hashtable_lut` and `overhead_hashtable_rehashing` to 0 in `kvstoreempty()`,0,0,0,0.9884890913963318,0.9950793981552124,0.9943931102752686,0.0,accept,unanimous_agreement
1503759378,12913,"i'm feeling a bit conflicted now. based on the current method of calculating `kvstorememusage`, even if the dict is empty (`kvstorebuckets` is 0), the memory occupied by `kvstore` itself would still be considered part of the overhead. therefore, we should return the overhead details for all databases, which means there would be no need for a continue condition. it seems this would be more reasonable?",-1,-1,-1,0.954210877418518,0.5567635893821716,0.7843986749649048,-1.0,accept,unanimous_agreement
1505497492,12913,"i think it's pointless to list the overhead for all empty databases (ones with no dict buckets at all). i'd argue that i still rather count that memory in the global overhead metric, but listing these databases is plain noise imho.",-1,-1,-1,0.6071363687515259,0.629549503326416,0.5912441611289978,-1.0,accept,unanimous_agreement
1507087258,12913,"i don't want to list all databases neither, as too many empty dbs would be meaningless. but currently, we create kvstores with `kvstore_allocate_dicts_on_demand`, but without `kvstore_free_empty_dicts`. therefore, after deleting all data (with scan+del or flushdb sync), even if the bucket count is zero, the dict data structure still exists and occupies memory. this means that a kvstore that has once had data inserted and then cleared will use more memory than a kvstore that has never been used, precisely sizeof(dict)*allocated_dicts more. i think it would be more reasonable to use `allocated_dicts` as a condition here.",0,0,0,0.9534876346588136,0.9044199585914612,0.986092746257782,0.0,accept,unanimous_agreement
1507106633,12913,"so listing all the options from low to high: 1. list dbs only if they have actual keys in them 2. list dbs only if they have allocated lut buckets (what we have now) 3. list dbs only if they have dicts that are non-null 4. list dbs only if they use memory, basically listing all ~~i'm ok with 3. you prefer 4, i'm good with that too.~~ edit: i'm ok with 2. you prefer 3, i'm good with that too.",0,1,1,0.8911457657814026,0.971459686756134,0.8406738042831421,1.0,accept,majority_agreement
1507127376,12913,"no no, i also prefer 3, just like that: [code block]",0,0,0,0.9490737915039062,0.934096097946167,0.968142569065094,0.0,accept,unanimous_agreement
1507147961,12913,"sorry, i messed up the counting. i meant to say that i prefer 2 but i'm ok with 3. anyway, please make that change and let's move on.",-1,-1,-1,0.988810420036316,0.9897580146789552,0.9862289428710938,-1.0,accept,unanimous_agreement
1069673073,11708,made the necessary changes.,0,0,0,0.9721912741661072,0.982890784740448,0.9945231676101683,0.0,accept,unanimous_agreement
1069673353,11708,made the necessary changes.,0,0,0,0.9721912741661072,0.982890784740448,0.9945231676101683,0.0,accept,unanimous_agreement
1081176611,11708,why not just remove that line? the code below will behave correctly when cmd->acl_categories is 0,0,0,0,0.9876569509506226,0.993114173412323,0.9911879301071168,0.0,accept,unanimous_agreement
1081224717,11708,let's add a comment for this block saying that it's done to clean the slate. (assuming i'm right),0,0,0,0.9566298723220824,0.97161465883255,0.9939299821853638,0.0,accept,unanimous_agreement
1081227653,11708,"btw, why not use `selector->flags & selector_flag_allcommands` instead of aclselectorcanexecutefuturecommands? or am i missing something?",0,0,0,0.9834678173065186,0.9810028076171876,0.9877088069915771,0.0,accept,unanimous_agreement
1081235316,11708,"why do we need / want that log? maybe the log level should be reduced, or if we really want to have some warning present when modules use this feature, maybe a more official introspection feature is needed (in info or module command)",0,0,0,0.9846357107162476,0.9793973565101624,0.9883604049682616,0.0,accept,unanimous_agreement
1081237213,11708,maybe resetting `acl_categories` to 0 should be the responsibility of this function and not the caller (being an output parameter).,0,0,0,0.983424961566925,0.9921162724494934,0.9801803827285768,0.0,accept,unanimous_agreement
1081249765,11708,"maybe doing this per registered command is a bit harsh. i.e. module that registers 10 commands, will re-run though all users for each command. considering a module is only supposed to register commands when loaded, maybe we can raise some flag, and do this when the loading completed and all commands were registered.",-1,-1,0,0.9008498191833496,0.814430832862854,0.8785800933837891,-1.0,accept,majority_agreement
1081284334,11708,"maybe add a test that verifies that when loading module after user was created, it doesn't accidentally grant the user access that it shouldn't have had.",0,0,0,0.9839746356010436,0.9911757707595824,0.9866859912872314,0.0,accept,unanimous_agreement
1081454240,11708,"they do the same thing. i assume part of this is parity with acldescribeselectorcommandrules which does the same thing as part of the ""sanity"" check code. we could probably simplify the code.",0,0,0,0.9865152835845948,0.9888259172439576,0.9917375445365906,0.0,accept,unanimous_agreement
1081974950,11708,"yes, that sounds good!",1,1,1,0.9784443974494934,0.9898819327354432,0.9808686971664428,1.0,accept,unanimous_agreement
1081980073,11708,"do you mean, similar to the test next to this one, but where users are already present and modules are loaded later. will do that",0,0,0,0.9869326949119568,0.9921327233314514,0.989825427532196,0.0,accept,unanimous_agreement
1081983026,11708,yes! i will look into it!,1,1,1,0.7769254446029663,0.5843402743339539,0.9720226526260376,1.0,accept,unanimous_agreement
1082392452,11708,exactly,0,0,0,0.9761611819267272,0.9651470184326172,0.9872385263442992,0.0,accept,unanimous_agreement
1083404479,11708,"i suppose that technically, till now, we allowed modules to register commands even after the onload. am i right? do you see any reason to keep this possibility?",0,0,0,0.9720344543457032,0.96652489900589,0.9908118844032288,0.0,accept,unanimous_agreement
1083404662,11708,"this seems overly complicated (the check for `!module_contains_aclcategories_flag`), also, maybe it's nicer to do `++` instead of `= 1`",0,0,0,0.8462965488433838,0.9599860906600952,0.8654674291610718,0.0,accept,unanimous_agreement
1083404808,11708,i think it's nicer to unconditionally set it to 0 at the beginning of this function rather than re-set it to 0 when modified.,0,0,0,0.9539588093757628,0.9815585017204284,0.9725472331047058,0.0,accept,unanimous_agreement
1083692875,11708,i do not see why we should keep (none of our modules does it).,0,0,0,0.7789248824119568,0.8212373852729797,0.9376463294029236,0.0,accept,unanimous_agreement
1083908382,11708,"`matchaclcategoriesflags` returns redismodule_ok/redismodule_err so `!` should not be used here (the reason it worked is that ok is 0 and err isn't) regardless, i find this code structure a bit confusing, why not: [code block]",-1,0,0,0.5210483074188232,0.92799574136734,0.8032741546630859,0.0,accept,majority_agreement
1083910520,11708,"i think this should be inside `struct redismodule` and represent the number of [sub]commands that have acl categories (i.e. also rename it to ""num_commands_with_acl_categories""",0,0,0,0.9884787201881408,0.9947011470794678,0.9897767305374146,0.0,accept,unanimous_agreement
1084282317,11708,i'm also fine dropping that.,0,0,0,0.8644149899482727,0.9390323758125304,0.9655835032463074,0.0,accept,unanimous_agreement
1084945928,11708,"so shall we add some check in rm_createcommand and maybe also rm_createdatatype and rm_register*config, rm_loadconfigs that verifies we're inside the onload?",0,0,0,0.9897772669792176,0.9953363537788392,0.995152473449707,0.0,accept,unanimous_agreement
1087422823,11708,"those makes sense. the only other one i would consider is redismodule_registercommandfilter, which i assume shouldn't really be messed with at runtime either but maybe there are some use cases. also presumably rm_createsubcommand.",0,0,0,0.985255002975464,0.9870211482048036,0.9879360198974608,0.0,accept,unanimous_agreement
1087531512,11708,"for sure sub-commands goes together with commands. i'm not sure about the filter, we don't really care do we?",-1,-1,0,0.7598773241043091,0.6964617967605591,0.9757224917411804,-1.0,accept,majority_agreement
1090116291,11708,"i'm fine with the new structure, but i don't really think matchaclcategoriesflags should return redismodule_err or redismodule_ok now that i think about it, since those are more typically used to module error codes. since this is an internal function, it should probably directly return 1 and 0.",0,0,0,0.9831597208976746,0.9651139378547668,0.6772672533988953,0.0,accept,unanimous_agreement
1135115465,11708,maybe it'll be nicer to set `onload` in `moduleload` rather than here?,0,0,0,0.9856062531471252,0.9948145747184752,0.9882062077522278,0.0,accept,unanimous_agreement
1135176611,11708,"i suppose we want to fail if either of them succeeds. if i read the code correctly, the ""noperm"" which we expect, will happen if at least one of them fails. p.s. i'm not sure we should go to that level of detail in the testing, i would be willing to test just one of them, or none (not all 8 apis)",0,0,0,0.8957016468048096,0.9351941347122192,0.910599648952484,0.0,accept,unanimous_agreement
1135178870,11708,"same issue here. we probably want to count successes, not errors.",0,0,0,0.9763420820236206,0.9851722717285156,0.963109850883484,0.0,accept,unanimous_agreement
1135630494,11708,please describe this change (blocked apis after init) in the pr top comment. as well as anything else worth noting for whoever won't read the code.,0,0,0,0.9852842688560486,0.9840519428253174,0.9941710829734802,0.0,accept,unanimous_agreement
1142601592,11708,"here we set the `onload` flag in `rm_init()` from `(*onload)(void *, void **, int)` in `moduleload` function, as far as i know the module apis are called from this `onlaod` function.",0,0,0,0.9883304834365844,0.9944815635681152,0.9933140873908995,0.0,accept,unanimous_agreement
1142707762,11708,"just going to say this is not a high priority, let's consider refactoring this later.",0,0,0,0.968325972557068,0.919602632522583,0.9627735018730164,0.0,accept,unanimous_agreement
1142959976,11708,"it looks a bit suspicious that we return ""ok"" when things failed. maybe a comment saying that it validates that it's not possible to register these after loading, thus return an error if they succeed.",-1,-1,-1,0.6939646601676941,0.797458291053772,0.6714223623275757,-1.0,accept,unanimous_agreement
1142962800,11708,"or we can flip it and return back to using `assert_error {noperm}`. i.e. my complaint was that the `|=` tested that at least one failed, rather than at least one succeeded.",0,0,0,0.9263383746147156,0.9900807738304138,0.983900547027588,0.0,accept,unanimous_agreement
1142970377,11708,"i'm not sure about the name, i think it's missing a reference to the term ""acl"" arguably `redismodule_setcommandaclcategories` isn't that much longer...",-1,-1,0,0.7530645728111267,0.5513877272605896,0.9247763156890868,-1.0,accept,majority_agreement
1142972901,11708,"aren't we missing a check that validates this api can't be used after loading? after all, that was the main reason to add all these checks.",0,0,0,0.9844672679901124,0.993370532989502,0.9796572327613832,0.0,accept,unanimous_agreement
1142973777,11708,we're missing a similar comment in the new api.,0,0,0,0.952938199043274,0.9821595549583436,0.982801616191864,0.0,accept,unanimous_agreement
1143630867,11708,"yeah, i will add a test to check this as well.",0,0,0,0.9834854006767272,0.9843003153800964,0.991123914718628,0.0,accept,unanimous_agreement
1143632105,11708,"sure, however i made it redismodule_setcommandaclcategories to make it consistent casing with other places we use acl in module names.",0,0,0,0.9899071455001832,0.9918197393417358,0.992982029914856,0.0,accept,unanimous_agreement
1143637729,11708,"yeah that makes sense, will change the name to `redismodule_setcommandaclcategories`",0,0,0,0.9855496287345886,0.9881645441055298,0.9817334413528442,0.0,accept,unanimous_agreement
1143701266,11708,"yes, i will add a comment mentioning that and changing the error from `noperm` to `unexpectedok` so it will make it more clear.",0,0,0,0.9875707030296326,0.9910712242126464,0.9933412671089172,0.0,accept,unanimous_agreement
1198817653,12192,"is `replica-redirect` enough? it can be implicitly understood that it is only for read and write commands, just like for cluster redirects.",0,0,0,0.9875419735908508,0.9935346841812134,0.9944022297859192,0.0,accept,unanimous_agreement
1199135404,12192,"presumably we need to also cover the ""announced"" port for k8s type distributions, where this port is not the same port the end user would see. i guess announced ip/hostnames are also problems. edit: to add some more context here. we've seen a number of users try to use the masterhost and masterport info field for topology discovery, which doesn't work correctly.",0,0,0,0.9370130896568298,0.9666387438774108,0.9861704111099244,0.0,accept,unanimous_agreement
1199142650,12192,"i actually am not sure it's clear enough! we've had folks ask if they could disable redirects for cluster mode (for mostly bad reasons), so they might think they could turn this off for cluster mode.",-1,-1,-1,0.9688930511474608,0.9247658848762512,0.9711291790008544,-1.0,accept,unanimous_agreement
1199243258,12192,so you want to add something like 'standalone' to the name to make it clear it's not a cluster config?,0,0,0,0.9870469570159912,0.994415283203125,0.992282211780548,0.0,accept,unanimous_agreement
1199494108,12192,"i guess in my ideal world this config would also apply on cluster mode enabled as well, and it would be a cluster agnostic config. at that point maybe your naming would be sufficient, `replica-enable-redirects` maybe?",0,0,0,0.9768126010894777,0.9842122197151184,0.9788836240768432,0.0,accept,unanimous_agreement
1199636796,12192,"this is already the behaviour in cluster mode. would the config have different defaults in cluster vs standalone mode. btw disabling it in cluster mode is ""for mostly bad reasons"" you said above so i thought you don't want to allow that...",-1,-1,0,0.938904106616974,0.6623218059539795,0.6303133964538574,-1.0,accept,majority_agreement
1199774648,12192,"i agree it would be nice to have it cluster agnostic, and that then we have a problem with default. unless we wanna make it default to `yes` in standalone too. another bad option is to make it an enum config with [yes,no,cluster-only], the last one being the default.",0,0,-1,0.8490880727767944,0.9393309950828552,0.8382940292358398,0.0,accept,majority_agreement
1199777572,12192,"good point. but for that we need a new config, right?",1,1,1,0.8623360991477966,0.5987132787704468,0.810845136642456,1.0,accept,unanimous_agreement
1199984809,12192,you mean `master-announce-ip` and `master-announce-port`?,0,0,0,0.9881333708763124,0.993723690509796,0.994966685771942,0.0,accept,unanimous_agreement
1199986108,12192,"if we want this, i prefer split into two configs, like `replica-enable-redirect` by default `no` and `cluster-replica-enable-redirect` by default `yes`.",0,0,0,0.9873027801513672,0.9923215508461,0.9939852356910706,0.0,accept,unanimous_agreement
1201098695,12192,"yeah, something like that. not sure how i feel about adding two new configurations that i would like to deprecate though. ideally we would re-use the `cluster-announce-*` type configs. this relates to how i want to make sure we are aligned long term.",0,-1,0,0.7092575430870056,0.531441330909729,0.909168303012848,0.0,accept,majority_agreement
1201208545,12192,"for tls, we'd need `master-announce-tls-port` too then. many new configs. or maybe only these two: `redirect host:port` and `redirect-tls host:port`, i.e. redirect to any node, regardless of whether it's our master or not. too flexible?",0,0,0,0.980818808078766,0.911342442035675,0.9845706820487976,0.0,accept,unanimous_agreement
1201488694,12192,"i prefer 's idea, the `redirect` and `redirect-tls` has a clear scope, only affect redirect. if we support `master-announce-*`, seems we need apply the announce ip:port to `info` `role` and other commands' reply. but this could cause some internal management services to become unavailable, since the internal services and user businesses possibly belong to different network, and the management may rely on the real ip:port not the announced ip:port in `info` and `role` etc.",0,0,0,0.9822532534599304,0.9903748631477356,0.9783435463905334,0.0,accept,unanimous_agreement
1236454067,12192,"[code block] i'll start a separate thread on terminology. i've seen the discussion above suggesting that every collection of redis instances (master + set of replicas) is called a cluster, and i'm against that, but i'm also against using the term ""standalone"". the best thing i can think of is ""cluster mode enabled"" / ""redis cluster"" (or in short ""cluster"" or cme"" which i think are already heavily used) vs ""cluster mode disabled"", or ""non-cluster"" (i'm not a fun of ""cluster mode disabled"", and certainly not ""cmd"")",0,0,0,0.8800236582756042,0.9236157536506652,0.916987419128418,0.0,accept,unanimous_agreement
1236688030,12192,"why not ""standalone mode""? it's used in `info` (`redis_mode:standalone` since 8246e58abe, 2012), `hello` (`""mode"" => ""standalone""`) and the splash screen. the modes are ""sentinel"", ""cluster"" and ""standalone"". afaict that's the original terminology. ![a link] (the splash screen was added in 996d503d1aab68bf0220951ab71a1ef9b8678b4a (2011) originally with the spelling ""stand alone"".)",0,0,0,0.9807308912277222,0.9611126780509948,0.9821544885635376,0.0,accept,unanimous_agreement
1236703042,12192,"ok, good point. i don't like it, but let's stick with it.",1,1,0,0.7585397362709045,0.7697746157646179,0.4578268826007843,1.0,accept,majority_agreement
1239127113,12192,"i don't think we are beholden to a decision made 10 years ago by someone who no longer works on the project. the terminology is barely used in the codebase, and really doesn't make much sense. i'm going to continue to non-cluster mode or cluster mode disabled.",-1,-1,-1,0.849196195602417,0.7169089317321777,0.6710593104362488,-1.0,accept,unanimous_agreement
1239548417,12192,"these words make me feel uncomfortable. you didn't give enough respect to antirez. as the creator of redis, his contributions cannot be ignored. moreover, in the future, each of us may leave this project, but the code and spirit will remain. ""standalone"" is a conceptual description. the reason why it has not been applied to redis code and client code is that redis has been in standalone mode since its inception. the cluster mode was invented later and needed to be explicitly written in the code. this is not a difference between backwardness and advancement, but simply a difference in time. because cluster mode appeared later, the word ""cluster"" needs to be used in redis and clients code to indicate its difference from standalone mode.",-1,-1,-1,0.9766266942024232,0.9364972114562988,0.9698621034622192,-1.0,accept,unanimous_agreement
1239596121,12192,"it's not about respect, a decision that was made long ago, and possibly without investing much thought into it, could have become outdated over time. the fact is that both myself and madelyn weren't even aware of the few places where ""standalone"" was mentioned (even though washing our eyes on these prints, and even source code lines many many times). imho, the history of how we got here is irrelevant, what's relevant is that this term isn't very intuitive (vs ""non-cluster""), and although it is admittedly used in several places, it's not really widely used, so if we have a better one, we can afford to break it. i'll give another example: till redis 7.0, the words ""script"", ""lua"", and ""eval"" were all used interchangeably (for instance in info and config). now hat we had several different ""scripting"" commands, and even for the same command, we have several different programming languages, we had to clean this up. the point is, that with time we sometime have to re-think past decisions and terminology, in some even if it causes interface changes, and it has nothing to do with respecting the history.",-1,0,0,0.5332129597663879,0.7875820994377136,0.516476035118103,0.0,accept,majority_agreement
1239960309,12192,"this does get at why i like calling it ""non-cluster"". originally there was no need to describe it since there was no distinction. salvatore invented the terminology when he needed to contrast it with cluster mode. if you gloss through most of the documentation, ""standalone"" is probably the most common way to identify the original redis, but in many more cases it's just simply not described, instead making the difference when appropriate for cluster mode. we can also respect the history while choosing to do something else. not every decision made by salvatore was correct.",0,0,0,0.8826740980148315,0.969132661819458,0.8049126267433167,0.0,accept,unanimous_agreement
1240037904,12192,"i don't object to the terminology ""non-cluster"". what i want to emphasize is that standalone(non-cluster) and cluster are two very different modes. they are very different for redis itself, its client, and especially for user business. when using cluster, users must plan their keyname settings so that multi-key operations can be performed, such as using hashtags. therefore, for now, i don't want to mix standalone(non-cluster) and cluster, because we haven't solved many issues such as cross-slot, maintenance operations such as failover and building replication, and data storage.",0,0,0,0.7311511039733887,0.9192839860916138,0.8957703709602356,0.0,accept,unanimous_agreement
1240470274,12192,"are we all not directionally aligned we want to do this though? i'm under the impression we want to move all configurations to a mode where the clusterbus (or cluster v2) is running and it supports operations like `cluster failover`. i don't think this needs to necessarily solve the sharding problem, since you could have an unsharded database that still supports the cluster communication.",0,0,0,0.9005436301231384,0.9332196712493896,0.9833508133888244,0.0,accept,unanimous_agreement
1240571567,12192,"i think you misunderstood me. as of now, i am not inclined towards an unsharded-cluster. in my previous response, i was only pointing out its issues, not indicating that i support implementation it now.",-1,-1,0,0.837990939617157,0.8597875833511353,0.7037269473075867,-1.0,accept,majority_agreement
1240586005,12192,"i understand you aren't for it right now. i'm asking if you are inclined towards an unsharded-cluster eventually. my thinking was that we were going to target a lot of cluster improvements for redis 8, including supporting unsharded-clusters. (i think you indicated some doubt in another comment, and that's probably warranted at this point. we haven't made much progress there).",0,0,0,0.8246719241142273,0.9494149684906006,0.9044079184532166,0.0,accept,unanimous_agreement
556972356,8327,this should be addreplyerrorobject().,0,0,0,0.988381803035736,0.9930338859558104,0.9948023557662964,0.0,accept,unanimous_agreement
556983795,8327,thanks! fixed.,1,1,1,0.9519985914230348,0.9913148283958436,0.9897935390472412,1.0,accept,unanimous_agreement
559755630,8327,"the expire and expireat commands don't have `use-memory` and that's the only effect of this command that can cause slight memory utilization. it can be considered a `fast` command since even when it deletes a key, it can only be a string type [code block]",0,0,0,0.9838340878486632,0.993727207183838,0.993499755859375,0.0,accept,unanimous_agreement
559762624,8327,"the difference between this approach and the one deleted from feedappendonlyfile is that this one will also affect replicas (not only aof). that's actually undesirable, see [a link] so i don't mind rewriting as one command rather than two, and using the new arguments, but we should not change relative ttl to absolute ttl when propagating to replicas (only when propagating to aof)",0,0,0,0.8997571468353271,0.9532300233840942,0.9633471369743348,0.0,accept,unanimous_agreement
559762902,8327,please add a top comment that explains the inputs and outputs.,0,0,0,0.984946608543396,0.9787110686302184,0.9936501383781432,0.0,accept,unanimous_agreement
559767268,8327,"i think it would be good idea to add a test for that, maybe as part of this pr. iirc there's already a test that checks that expire is turned into expireat in the aof, but apparently there's no test that verifies that's not happening in the replication, and i can see that this mistake is gonna be repeated in the future. so even if we're gonna revert this decision some day, it should not be by mistake. such a test can either use the `cmdrstat`, or `attach_to_replication_stream` methods.",0,0,0,0.8991655111312866,0.9824198484420776,0.8958178162574768,0.0,accept,unanimous_agreement
559768271,8327,let's make this one a multi-line (as much as i hate lines) [code block],0,-1,-1,0.8314727544784546,0.97607159614563,0.6446326971054077,-1.0,accept,majority_agreement
559769744,8327,"why do we want that option? i think seeing that that option exists is just confusing. on a set command, where the default is to override the key, creating new one that's non-volatile, it makes sense. here, i suppose that we still want a getex with no options to behave the same as get, but we don't need an explicit argument that does nothing.",-1,0,0,0.571196973323822,0.5512468814849854,0.9108922481536864,0.0,accept,majority_agreement
559771197,8327,"i personally don't think that we need to share code between the normal `get` (which is also used by `getset` and `get set` with `getex`. the first 3 mention above are so simple and straight forward (easy to read the code and quickly understand what it does), and the last one is complicated, possibly propagating effects and notifications. please rename this one to be `getexgenericcommand` (or just put it into getexcommand), and restore the old simple getgenericcommand.",0,0,0,0.7613430023193359,0.9746599793434144,0.9780177474021912,0.0,accept,unanimous_agreement
559773377,8327,"fyi, there's an advantage of using `assert_equal` and `assert_range`, in that when the assertion fails, you always get the offensive value (i.e. seeing `expected '$value' to be between to '$min' and '$max'`) if you do that, you don't need to store the value into an argument. so it'll look like `assert_range [r ttl foo] 5 10`",0,0,0,0.9622635841369628,0.9823236465454102,0.9875820875167848,0.0,accept,unanimous_agreement
559773862,8327,"i thought the docs next to the command said keepttl is the default (which i think it should be, i.e. making it behave like get by default). i think the arity of the command should be changed and this test altered.",0,0,0,0.9865555763244628,0.990954339504242,0.985615849494934,0.0,accept,unanimous_agreement
559782110,8327,"thanks for the feedback. does the recommendation also apply if we get `pxat/exat`, do we want to convert absolute ttl to relative in this case?",1,1,1,0.871861457824707,0.8612784147262573,0.9374681115150452,1.0,accept,unanimous_agreement
559783111,8327,"no, if we're asked for absolute time, we forward that intent to the replica as is. afaik that's what the code does, and afair from that conversation with salvatore, that's what he intended.",0,0,0,0.9770039916038512,0.9863195419311525,0.9801571369171144,0.0,accept,unanimous_agreement
559786210,8327,thank you! for the review. i will handle this and rest of the comments soon.,1,1,1,0.9884554147720336,0.9864681959152222,0.9930641055107116,1.0,accept,unanimous_agreement
559788299,8327,"i'm trying to add a test for that for the existing commands (with a reference to the justification), so you can skip that for now, and just work on fixing the changes in this pr.",0,0,0,0.9796923398971558,0.989188551902771,0.9935824275016784,0.0,accept,unanimous_agreement
559789727,8327,ack thanks!,1,1,1,0.9529715180397034,0.9553535580635072,0.9031223058700562,1.0,accept,unanimous_agreement
559847904,8327,"can we re-open that conversation? it seems wrong to have behavior that might change dramatically on failovers if the nodes have different clocks. i don't really buy salvatore's argument we should only care about the typical case. large replication lag, full syncs, psyncs can all introduce a lot of lag between when an expire is set and when it's propagated to a replica. clock skew is usually on the matter of seconds, but these modes could introduce error on the order of minutes/hours. i see shootit commented on your test pr as well.",0,0,0,0.7503123879432678,0.6788330078125,0.6342467069625854,0.0,accept,unanimous_agreement
559946318,8327,"agreed removed this option, default behavior is now same as `get`",0,0,0,0.986064076423645,0.9937908053398132,0.9944836497306824,0.0,accept,unanimous_agreement
559946674,8327,updated and added old `getgenericcommand` back and renamed new method to `getexgenericcommand`,0,0,0,0.987111747264862,0.994525909423828,0.9940570592880248,0.0,accept,unanimous_agreement
559946934,8327,thank you! this was helpful updated it in all of the test.,1,1,1,0.985270082950592,0.9948729872703552,0.9933446645736694,1.0,accept,unanimous_agreement
559947069,8327,fixed and changed arity.,0,0,0,0.984918475151062,0.986725687980652,0.990845501422882,0.0,accept,unanimous_agreement
560059672,8327,"sure we can open that for conversation, i just want it to be intentional rather than overlooked. i suggest to have that conversation separate from this pr. it can be in my pr (before or after merging it), or in another issue.",0,0,0,0.952025830745697,0.9771440625190736,0.9748275876045228,0.0,accept,unanimous_agreement
560136033,8327,any reason you indented these by another 4 spaces?,0,0,0,0.9672448635101318,0.9743524193763732,0.9917734265327454,0.0,accept,unanimous_agreement
560139431,8327,"just to be sure, we no longer need this block now since setgenericcommand will anyway call rewriteclientcommandvector in that case, so this will fall to the next block in this function, right? let's rebase this pr after i merge #8357, and extend the two tests there to check these too: `setex`, `psetex`, and `set exat`, `set pxat`",0,0,0,0.9819489121437072,0.9889995455741882,0.9934430122375488,0.0,accept,unanimous_agreement
560143322,8327,"ohh, i now realize that this function already had a top comment, it's just not glued to the top of the function. the comment seems to be glued to the bottom of the previous function (missing blank line) rather than the next function. i think it should be moved to after the defines below.",0,0,0,0.9271808862686156,0.9688503742218018,0.961378276348114,0.0,accept,unanimous_agreement
560145956,8327,"why did you do that change? this block only removes the `get` argument if present. if it conflicts with the command vector rewrite inside setgenericcommand, i suppose we need to move this code to inside setgenericcommand and have it handle both concerns",0,0,0,0.9848341941833496,0.9921773076057434,0.993619978427887,0.0,accept,unanimous_agreement
560159345,8327,"let's include the words ""absolute"" and ""relative"" in this comment in some way, i think it'll make it more clear (rather than ""px"" and ""pxat"". also, i think this comment must mention that the command already re-written itself to always use milliseconds, so we don't need to worry about units here.",0,0,0,0.9425570368766784,0.984555184841156,0.9805997014045716,0.0,accept,unanimous_agreement
560160842,8327,"this `if` heavily relies on the fact the order is known since the command vector is re-written in the command, and we know the index of `px`. i think that's bad. if we keep it this way, i think a comment is needed here to explain that, and also comment in setgenericcommand next to the argument rewriting, to mention that we have code here that relies on the order.",-1,-1,-1,0.960788071155548,0.6944944262504578,0.939797818660736,-1.0,accept,unanimous_agreement
560326320,8327,"i extended that pr to test setex and psetex, and merged it. so after rebase you can extend these tests to test `set exat` and `set pxat`. or cover these in the area were you're gonna cover the getex propagation.",0,0,0,0.98628830909729,0.9918538331985474,0.9939236044883728,0.0,accept,unanimous_agreement
560771731,8327,thank you this was helpful.,1,1,1,0.8460572957992554,0.9815468788146972,0.9522597789764404,1.0,accept,unanimous_agreement
560776661,8327,"i added comment about the index, i tried to add the `for` loop but it had some issues when comparing the `millisecond` object with `strcasecmp`",0,0,0,0.9819206595420836,0.9899189472198486,0.9946148991584778,0.0,accept,unanimous_agreement
560933624,8327,"[code block] i improved this test to cover del which wasn't covered by other tests, and to test no propagation, maybe now the test you added in aof.tcl isn't needed anymore.",0,0,0,0.986498475074768,0.991118848323822,0.9932911396026612,0.0,accept,unanimous_agreement
561131931,8327,great catch i missed the `del` case thank you. i still retained the `aof.tcl` test as it validates there is no change in the file size.,1,1,1,0.9847443699836732,0.9912812113761902,0.9953881502151488,1.0,accept,unanimous_agreement
561144234,8327,nit: why is this split on two lines? it's less than 80 characters on one line.,0,0,-1,0.9335156679153442,0.7435648441314697,0.8232402801513672,0.0,accept,majority_agreement
561147498,8327,do we this abstraction? seems unnecessary since there will probably only be one getex command.,0,0,0,0.9245036840438844,0.8638758063316345,0.8730683326721191,0.0,accept,unanimous_agreement
561158650,8327,removed it,0,0,0,0.9677612781524658,0.9675471782684326,0.977264404296875,0.0,accept,unanimous_agreement
561158745,8327,fixed.,0,0,0,0.9810503125190736,0.979083240032196,0.9905837774276732,0.0,accept,unanimous_agreement
561639641,8327,i'll re-open an issue.,0,0,0,0.9842172861099244,0.9690180420875548,0.9872655868530272,0.0,accept,unanimous_agreement
564176687,8327,this maybe should be server.lazyfree_lazy_expire now? i have no idea if people ever set those differently.,0,0,0,0.722503662109375,0.972017228603363,0.9597803354263306,0.0,accept,unanimous_agreement
564178188,8327,"this can never fail right? we just got the item successfully, so we must be able to delete it then. i think a server assert on the delete and remove the if is cleaner.",0,0,0,0.9844471216201782,0.9759753942489624,0.9903591275215148,0.0,accept,unanimous_agreement
564179599,8327,"shouldn't this be an assert? i'm also not entirely sure this test is necessary, and the 2 second wait is not great.",-1,-1,-1,0.9525811672210692,0.9131413698196412,0.8232570290565491,-1.0,accept,unanimous_agreement
564220517,8327,"i guess if we rewrite expire to unlink, we should also rewrite this to unlink?",0,0,0,0.9863969683647156,0.9926806092262268,0.985870897769928,0.0,accept,unanimous_agreement
1042864993,11595,why is it no longer being deleted?,0,0,0,0.9185128808021544,0.9792501330375672,0.9838377833366394,0.0,accept,unanimous_agreement
1043120027,11595,"it is deleted in the lines below this using dictunlink, sdsfree, dictfreeunlinkedentry. (this dict's type has no key destructor.) i tried things back and forth, but there's actually no change here. i'll delete this commented line.",0,0,0,0.9826995134353638,0.9914074540138244,0.9932228326797484,0.0,accept,unanimous_agreement
1043631868,11595,"it looked weird from the diff i had open, but just looking at it now yeah it seems like a random line. i would vote to remove it yeah.",-1,-1,-1,0.909514844417572,0.9821934700012208,0.9450071454048156,-1.0,accept,unanimous_agreement
1059858571,11595,"[code block] it's a defrag fn, not an alloc fn. also more consistent with the other two.",0,0,0,0.9873194694519044,0.991028368473053,0.9933003187179564,0.0,accept,unanimous_agreement
1068121570,11595,let's list this change in the top comment. i.e. it's implications on 32 bit systems that don't have malloc_size (and also why we did it),0,0,0,0.9840844869613647,0.9927369952201844,0.9940186738967896,0.0,accept,unanimous_agreement
1068123543,11595,remember to remove that one.,0,0,0,0.976625919342041,0.9867292642593384,0.9886337518692015,0.0,accept,unanimous_agreement
1068133288,11595,"this looks too low level.. all we want is to add an element to the set, and we're forced to do hashing and insertion on our own. i understand the reason is that we want to avoid excessive sdsdup and sdsfree if the element is already there, right? and that in the past we were able to set the key of a dictentry after the fact, and now it's no longer the case because there might not be any dictentry... maybe we need some new interface, like a dictentryref struct or dictindex struct, which can hold both a dict entry and an index. or maybe it's enough to return a a `dictentry*` and if we see the lsb set, we realize that it's actually the hash table itself (and then dictsetkey can still update it)? either way, i'd like to avoid doing dicthashkey and dictinsertatindex etc here, considering that we may need to do it in other places in the future...",-1,0,-1,0.856113612651825,0.8621944785118103,0.9306007027626038,-1.0,accept,majority_agreement
1068177531,11595,"is this comment outdated? (as well as the one above it). i.e. it refers to the case that keys are always with lsb set, but we now have a way to control it to be the other way around. i didn't read the rest of the code yet, but at least this part is wrong, right?:",0,0,0,0.8449856638908386,0.9165193438529968,0.9730195999145508,0.0,accept,unanimous_agreement
1068217679,11595,"ohh, reading the rest of the code i see that when `keys_are_odd` is off you just disable the optimization. instead we can flip it: either set the lsb of the key on in put and clear it on output, or instead use lsb of 1 to know that it's a dictentry. maybe we don't wanna do all that investment when we don't have a use case for it yet though? (in which case we can we can add a todo comment, but that argument is also valid for the whole `keys_are_odd` feature, i.e. we can drop it and add a todo comment).",0,0,0,0.9103003740310668,0.9614369869232178,0.9144389033317566,0.0,accept,unanimous_agreement
1068236669,11595,"i think it's odd that we expose these interfaces. we bothered to make dictentry opaque so that we don't leak the dict internals to the caller, but exposing the index is similar. let's consider removing these after trying to solve the settypeaddaux case differently (see my comment there)",0,-1,-1,0.670549213886261,0.7507390379905701,0.631576418876648,-1.0,accept,majority_agreement
1068237082,11595,"moving this has an implication that dictaddraw that results in a nop doesn't do incremental rehashing. considering that dictfind does, i think it's odd. let's consider reverting that after we decide what to do with the dictinsertatindex public interface.",-1,0,-1,0.5298509001731873,0.7644083499908447,0.7412075996398926,-1.0,accept,majority_agreement
1068350927,11595,"exactly. sure, we can add a todo comment. what do you mean? shall we drop the whole keys_are_odd feature? before i added this dicttype field, there was a heuristic per key. in a dict with mixed odd and even keys, it was practically impossible to estimate the memory usage. now at least we can assert that all added keys are odd if the key_are_odd flag is set.",0,0,0,0.9788116812705994,0.9853988885879515,0.982539176940918,0.0,accept,unanimous_agreement
1068371603,11595,"exactly. a kind of ""two-phase add""... are you proposing we can essentially keep this dictkeyindex + dictinsertatindex if we just hide hash (easy, just add a wrapper to dictkeyindex that computes the hash internally) and hide that we're working with an index directly into the table? for example make the index an opaque type or returning a `dictentry**` bucket-pointer instead of an index? if we return a dictentry-pointer which is a key, there is no way to replace it other than to hash the key again to find the bucket. that's why dictsetkey doesn't work well in this case.",0,0,0,0.9800614714622498,0.9897040724754332,0.9850207567214966,0.0,accept,unanimous_agreement
1069266678,11595,"in the second option, i guess i meant a `dictentry**` so that dictsetkey (or a variant of it), can just update either the dictentry or if it's a pointer to a key (ref), it can update it.. for the first option, the `dictentryref` would be an opaque struct containing a hash, index, and whatever we need to replace the key. so that the caller isn't aware of any hash or index",0,0,0,0.9805635213851928,0.9925878643989564,0.9885339140892028,0.0,accept,unanimous_agreement
1069270765,11595,"we can document that if we use the no_value feature, keys must be odd, and a todo to fully implement the key_are_odd feature when that needs to change. again, by fully implement i mean that for dicts with key_are_odd=0 we turn things around so that they're optimal as well.",0,0,0,0.9834264516830444,0.985199809074402,0.992900848388672,0.0,accept,unanimous_agreement
1069504003,11595,"the todo i'd like to add is to also add a `keys_are_even` to enable key-as-entry for dicts where all keys are even. but what about dicts where keys can be a mix of odd and even? (string literals or other unaligned strings, or numeric keys.) to disable key-as-entry but still use dictentry_no_value for these is a reasonable compromise imho.",0,0,0,0.9764817357063292,0.9858925938606262,0.9723650813102722,0.0,accept,unanimous_agreement
1069511415,11595,"i've added a dictrehashstep call in dictkeyindex to preserve this behaviour, so this isn't affected. (i'll rename dictkeyindex to dictfindbucketforinsert to not expose the index.)",0,0,0,0.9860279560089112,0.9943494200706482,0.9943000078201294,0.0,accept,unanimous_agreement
1070069734,11595,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
1070080813,11595,"i chose to use a bucket pointer (`dictentry **`) instead of index. i replaced the functions with `dictfindbucketforinsert` and `dictinsertintobucket`. the key hashing and the index is hidden within the functions. (i didn't use an opaque struct `dictentryref` for the intermediate values, because the user can't allocate an opaque value on the stack, so it'd have to be allocated.)",0,0,0,0.9830763339996338,0.9950594902038574,0.9920421242713928,0.0,accept,unanimous_agreement
1070084704,11595,done as described. please check if it's acceptable.,0,0,0,0.9755286574363708,0.970219612121582,0.9252851009368896,0.0,accept,unanimous_agreement
1070243187,11595,"i'm not sure we'll ever need to support a case of a dict where keys are neither always odd or always even. which is why i thought that this single `key_are_odd` decides between always odd and always even. instead i now realize it decides between always odd and mixed, and we don't support the always even mode. in my previous post i supported either fully implement all of this and support both (or all 3) modes, or just dropping all the complications and supporting just the one we use. but anyway, i'm also ok with supporting the two modes you chose to support, as long it's properly documented what it does, and what's left as todo to reach the end goal.",0,0,0,0.898442268371582,0.8702444434165955,0.7941609621047974,0.0,accept,unanimous_agreement
1070243588,11595,"do we ever expect the caller of `dictfindbucketforinsert` to call any `dictentry*` function on the return value (i.e. passing `*bucket` to some api). if not, maybe it should be a `void*`? maybe the term ""bucket"" is wrong. maybe ""spot"" or another term is better (more abstract)?",0,0,0,0.9531405568122864,0.994809627532959,0.9871219992637634,0.0,accept,unanimous_agreement
1070287771,11595,what about `dictnovalueentry` or `dictentrynovalue` ? snake case and camel case mix look odd.,0,0,0,0.5148435831069946,0.8760215640068054,0.55094975233078,0.0,accept,unanimous_agreement
1070447808,11595,"you're right, it is very odd. :-) i'll change to camel case.",1,1,1,0.9759758114814758,0.989259958267212,0.9943601489067078,1.0,accept,unanimous_agreement
1070448303,11595,you're right. it should be better abstracted.,0,0,0,0.9480738043785096,0.7762810587882996,0.950419306755066,0.0,accept,unanimous_agreement
1073780417,11595,"i changed it to `void*` and renamed it to ""position"". * dictfindpositionforinsert * dictinsertatposition",0,0,0,0.9875127673149108,0.9945914149284364,0.9948503375053406,0.0,accept,unanimous_agreement
20630692,2143,"the compiler warns that this variable may be used unintialized. of course it isn't, as `target` will always be either a or b, but we could surpress this warning by just initalizing `where` anyway.",0,0,0,0.9871777296066284,0.985398769378662,0.9900155663490297,0.0,accept,unanimous_agreement
20630710,2143,"i don't know how critical this call is. we have `sdsll2str` in the code base, which should do effectively the same thing. would be interesting to see if it has an impact to use it here instead.",0,0,0,0.9304561018943788,0.9126177430152892,0.9452573657035828,0.0,accept,unanimous_agreement
20630787,2143,"i think the comment here is not totally correct (the code is though). isn't it: negative -> backward, non-negative -> forward?",0,0,0,0.9094562530517578,0.9362879395484924,0.9486134052276612,0.0,accept,unanimous_agreement
20630832,2143,why negate here? for consistency (as i think it's easier to read and done further down anyway) i would swap the if/else conditions. [code block],0,0,0,0.9844368696212769,0.985325038433075,0.9907078742980956,0.0,accept,unanimous_agreement
20630858,2143,"when compiled with `d` enabled, the compiler warns that `n` has the wrong type. for cosmetic reasons we could cast it to ""void*"" here.",0,0,0,0.9618244767189026,0.9827311635017396,0.9904898405075072,0.0,accept,unanimous_agreement
20630865,2143,same as above. `(void*)`,0,0,0,0.9830943942070008,0.9933915138244628,0.9949591159820556,0.0,accept,unanimous_agreement
20630897,2143,another smallish cosmetic thing here: inserting a newline after `void *value` will keep the line under 80 chars just as the function above.,0,0,0,0.9807892441749572,0.9739198088645936,0.988735020160675,0.0,accept,unanimous_agreement
20660386,2143,"which compiler/version? it didn't complain under my menagerie of compilers yet. maybe i don't know how to use github, but i see a 26 line diff attached to this comment (and all the comments actually), so it's difficult to tell what ""this variable"" is. :-\ (obviously next i see you mean `where`, but the github code reply doesn't make it clear. boo github. though, on second look, it seems the _last_ line in the diff is the comment target? i'll assume that going forward. still, boo github.) good point! i'll add it.",-1,-1,-1,0.9905042052268982,0.98014235496521,0.9940326809883118,-1.0,accept,unanimous_agreement
20660500,2143,"good catch. that has been on my list of things to replace, but i kept forgetting when sitting in front of a keyboard. i'll get it added.",1,1,1,0.973025679588318,0.9727472066879272,0.9921512603759766,1.0,accept,unanimous_agreement
20661067,2143,"i think it was inspired by [a link] for readability, showing the first special case of ""negate index, subtract one"" helps the reader more quickly see something strange is happening since it's the first case.",0,0,0,0.9426494240760804,0.9191531538963318,0.9593202471733092,0.0,accept,unanimous_agreement
20661116,2143,crazy gcc. will fix.,-1,-1,-1,0.972423017024994,0.9916549921035768,0.9938016533851624,-1.0,accept,unanimous_agreement
20661232,2143,"it's actually _exactly_ 80 characters, so it's still okay. the quicklist.{c,h} was was formatted with `clang-format -style=""{basedonstyle: llvm, indentwidth: 4}""` which gives reasonable output except for a few small cases here and there (small functions end up on a single line, and in-place struct initializers get too many spaces added around them).",0,0,0,0.9555782675743104,0.7753177881240845,0.9158964157104492,0.0,accept,unanimous_agreement
20661337,2143,i see. i just rechecked my config and it turns out for some reason it complained on column 79 instead of 80 -_-,0,1,-1,0.9398954510688782,0.7509169578552246,0.994648277759552,,review,no_majority_disagreement
20661482,2143,ah yes. comments are always made below the line i meant. github could really show this better.,0,0,0,0.9388248920440674,0.8065521121025085,0.9885334372520448,0.0,accept,unanimous_agreement
20661513,2143,[~]% gcc --version gcc (gcc) 4.9.2,0,0,0,0.9755115509033204,0.9916208982467652,0.9895764589309692,0.0,accept,unanimous_agreement
20661603,2143,"ah, that's the difference. my linux testing box was 4.9.0. i've got a 4.9.2 on os x and i see your extra warnings now. fixing.",0,-1,0,0.9498420357704164,0.5408636927604675,0.9435203075408936,0.0,accept,majority_agreement
20714633,2143,i tried to create the new operation with __ziplistcascadeupdate(). it may be useful to rewrite this part. :) [a link],1,1,1,0.9590067863464355,0.9938004612922668,0.9940688610076904,1.0,accept,unanimous_agreement
20757598,2143,"if center and center->prev doesn't merge, center and center->next will definitely not merge?",0,0,0,0.980465531349182,0.9777040481567384,0.9796579480171204,0.0,accept,unanimous_agreement
20757776,2143,"let's draw it! the numbers at the top boxes are the `count` for that node. [code block] so, the case you noted is: that's a good point since _target_ is only created if prev is merged. we need to set `target = center` _if_ the `(center+center->prev)` doesn't happen. i'll add it. thanks!",1,1,1,0.9752393364906312,0.9926689863204956,0.9941389560699464,1.0,accept,unanimous_agreement
20761484,2143,forget to free new_node :),-1,1,0,0.4174856543540954,0.9702298045158386,0.5179758667945862,,review,no_majority_disagreement
20761614,2143,"as _quicklistsplitnode puts it this way, ###### if after==1, then the returned node has elements [offset, end]. ###### otherwise if after==0, then the new node has [0, offset) suppose the former quicklistnode is [0, 1, 2, 3, 4, 5] & entry->offset is 3. and it will split into two quicklistnode [0, 1, 2] [3, 4, 5] ###### if after==1, then the new_node is [3, 4, 5] ###### otherwise if after==0, then the new_node is [0, 1, 2] then, ###### if after==1, we push the value at head and the new_node is [value, 3, 4, 5] ###### otherwise if after==0, we push the value at tail and the new_node is [0, 1, 2, value] what's more it forget to deal with the null result _quicklistsplitnode returns.",0,0,0,0.9806256294250488,0.9879911541938782,0.993273138999939,0.0,accept,unanimous_agreement
20761635,2143,"is it okay that we just judge `else if (full && (at_tail || at_head))`? this will involve some cases next `else if` owns, and make the cases more clear. :)",1,1,1,0.8183591961860657,0.9659398198127748,0.9759935736656188,1.0,accept,unanimous_agreement
20761677,2143,"i saw your trick to deal with this, `int orig_start = after ? offset + 1 : 0;` `int orig_extent = after ? -1 : offset;` `int new_start = after ? 0 : offset;` `int new_extent = after ? offset + 1 : -1;` with offset + 1 :) but in that way, the comment of _quicklistsplitnode is not accurate any more. :)",1,1,1,0.9803259372711182,0.9947113990783693,0.9949641227722168,1.0,accept,unanimous_agreement
20761843,2143,"more drawings! let's say maximum fill is 6. nodes here can't have more than 6 entries. if we want to insert when two neighboring nodes are full, we have: [code block] actually, as you (i think) noted, the next ""splitting node"" case _can_ match for this case too, _but_ splitting requires extra copies and math. right here we _know_ we can create an entirely new node, so it's quicker/easier/cleaner to just do it directly. also, seeing as we are already tracking the combinational state of like 25 things in that if/else tree, more explicit details everywhere make it more clear about what is happening and why (plus optional verbose debugging and comments).",0,0,0,0.7427536845207214,0.8526549935340881,0.8357717990875244,0.0,accept,unanimous_agreement
20761928,2143,"dealing with dead memory allocations here is tricky. the redis allocator actually just kills the entire process on oom, so we don't _need_ extensive malloc checking (and there isn't anything sensible we can do if allocating a new node fails anyway). oh, good point. i'll update it and note the changes below. the comment does have a reinforcing statement of `the input node keeps all elements not taken by the returned node` just in case any of the examples given were actually wrong. :)",1,1,1,0.717179000377655,0.9865362048149108,0.9818170070648192,1.0,accept,unanimous_agreement
20762397,2143,"yap, you make it more clear about what is happening and why. the case you gave above matches `else if (full && (at_tail || at_head))` with above 4 conditions. i just think a special case (nodea [1, 2, 3, 4, 5, 6]) -> null we append an element to nodea, and it will split into two nodes(nodea and an empty node). of course i didn't find any bug here, i just thought the special case should be operated by the 5th branch. and the suggestion make no progress and mass up existing code. my bad. :)",0,0,0,0.9067380428314208,0.9085129499435424,0.9689523577690125,0.0,accept,unanimous_agreement
20771521,2143,without `fill` limitation?,0,0,0,0.971518099308014,0.9916988611221312,0.992906928062439,0.0,accept,unanimous_agreement
20771574,2143,we can just skip to the head to avoid tail recursion. :),1,1,1,0.9668712615966796,0.9579472541809082,0.9804290533065796,1.0,accept,unanimous_agreement
20772539,2143,how? why would we want to avoid?,0,0,0,0.8272914886474609,0.85097736120224,0.8577617406845093,0.0,accept,unanimous_agreement
20772688,2143,"that's a great observation! we need to rename `quicklistpushtailziplist(quicklist, ziplist)` to something like `quicklistappendvaluesfromziplist(quicklist, fill, ziplist)`. then we just: - iterate over the existing ziplist - insert each element from the ziplist into tail of the quicklist (`quicklistpushtail()`) - then free the original ziplist adding each value from the old ziplist individually will create nodes with the proper fill for this instance. (this is only used when users restore an old rdb with a native ziplist encoding. it'll help them rebuild their single (maybe large 512+) entry ziplist into a quicklist with a smaller fill factor.) i'll add it to the todo list.",1,1,1,0.9890426993370056,0.9920222759246826,0.995261549949646,1.0,accept,unanimous_agreement
20772988,2143,"we should remove this, and correct the comment above. ##### \- iter->zi = entry->zi; ##### \- iter->offset++; because it may skip the next entry. --- ## test code [code block] quicklistreleaseiterator(iter); --- ## result without deletation abc foo bar foobar foobared zap bar bar test foo abc foo foobar foobared zap bar test foo --- ## result with deletation abc foo bar foobar foobared zap bar bar test foo abc foo foobar foobared zap test foo",0,0,0,0.9647462964057922,0.993312418460846,0.9952033758163452,0.0,accept,unanimous_agreement
20773139,2143,"add goto statement to the start of this quicklistnext function. it is just a little trick, decrease the depth of system stack, save the time system pushes parameters on stack and allocate stack space to run this function again. this function can at most be called one more again, this little trick doesn't save much space & time. of course at the same time goto is harmful. i didn't think this special situation over. my bad. :)",-1,1,1,0.9512099027633668,0.9820338487625122,0.6509225368499756,1.0,accept,majority_agreement
20788337,2143,"we should limit extent within the rest of list. and the 2nd if branch (line 601) `else if (entry.offset >= 0 && extent > node->count)` should add '=' to match all the cases such as, `entry.offset == 2 ; extent == node->count` should also run this branch. see [a link] :)",0,1,1,0.923053741455078,0.9868991374969482,0.957568883895874,1.0,accept,majority_agreement
20789472,2143,longval -_-,0,-1,-1,0.97303706407547,0.6093572378158569,0.9956362843513488,-1.0,accept,majority_agreement
20789898,2143,"we should reset p. think about the special situation, first & last entry are in the same node and the node's size is less than fill. then the operation on line 899 will reset the zl and p will be a wild pointer. :) ## test code [code block] --- ## result without reset segmentation fault (core dumped) --- ## result with reset 123 321 ok",1,1,1,0.8430130481719971,0.9620909690856934,0.9927345514297484,1.0,accept,unanimous_agreement
20790376,2143,the `!value` case is never triggered by the below test cases. maybe a test covering this should be added.,0,0,0,0.988473117351532,0.9938390851020812,0.991960346698761,0.0,accept,unanimous_agreement
20811484,2143,oops. good catch. added to the next fixes.,1,1,1,0.9835820198059082,0.9851269125938416,0.9801759123802184,1.0,accept,unanimous_agreement
20812342,2143,"great point! added to next update with: [code block] also improved tests so they catch these edge cases (the new tests segfault _without_ these fixes, but pass _with_ these fixes).",1,1,1,0.990388572216034,0.9875729084014891,0.9954007267951964,1.0,accept,unanimous_agreement
20864426,2143,maybe the trick _quicklistsplitnode uses can make an improvement. :),1,1,1,0.9710321426391602,0.991218626499176,0.9766390919685364,1.0,accept,unanimous_agreement
1265256278,12416,why not just rely on rm_valuelength?,0,0,0,0.9783920049667358,0.985414743423462,0.9894657135009766,0.0,accept,unanimous_agreement
1265273654,12416,"maybe instead we should encourage using rm_scankey? even if you iterate though all of them in one go, it could in theory be more efficient. it is less convenient for the caller, but maybe that forces them to write better code (in terms of scalability).",0,0,0,0.9758532047271729,0.9903807044029236,0.9819447994232178,0.0,accept,unanimous_agreement
1265280183,12416,"i wonder if we should use a similar interface as rm_hashset, e.g. one that's able to take c-strings too? i'm not particularly fond of that api, but we should also take consistency into considerations.",0,0,0,0.7823196649551392,0.863226056098938,0.5187728404998779,0.0,accept,unanimous_agreement
1266074012,12416,you are right. the idea was to map set command one by one. but since there is common api to get the same functionality. this function could be removed. i'll remove it.,0,0,0,0.9222023487091064,0.9571312069892884,0.967947006225586,0.0,accept,unanimous_agreement
1266080061,12416,good idea. let me figure out how to realize it like rm_hashset way.,1,1,1,0.9376869201660156,0.9522705078125,0.9837055206298828,1.0,accept,unanimous_agreement
1266083399,12416,ok. i got the point.,0,0,0,0.9569706916809082,0.8621535897254944,0.976731300354004,0.0,accept,unanimous_agreement
1267440299,12416,"now, i changed using fmt (""vslc"") method.",0,0,0,0.9884955883026124,0.9904604554176332,0.993816375732422,0.0,accept,unanimous_agreement
1267469327,12416,"not sure i'm right, we shouldn't change the usage of `modulecreateargvfromuserformat` which is just used for module apis related to command argv(cmdname + argv).",0,0,0,0.9639942049980164,0.957792580127716,0.9134963750839232,0.0,accept,unanimous_agreement
1267546621,12416,"yes. i expended modulecreateargvfromuserformat usage since reusing the fmt(""vslc"") to avoid code duplication. let me think it over how to optimize it.",0,0,0,0.9865672588348388,0.9822710156440736,0.9920807480812072,0.0,accept,unanimous_agreement
1267551496,12416,"agree with you, this change is better than duplication.",0,0,0,0.9537875056266784,0.9456586837768556,0.7862968444824219,0.0,accept,unanimous_agreement
1267580592,12416,"i changed modulecreateargvfromuserformat to modulecreateargvfromuserformataux. then `robj **modulecreateargvfromuserformat(const char *cmdname, const char *fmt, int *argcp, int *flags, va_list ap)` is used by rm_call(), rm_replicate()... which return flags while `robj **modulecreatesetargvfromuserformat(const char *fmt, int *argcp, va_list ap)` is used by rm_setadd(), rm_setrem()... which doesn't return flags. both modulecreateargvfromuserformat() and modulecreatesetargvfromuserformat() invokes modulecreateargvfromuserformataux() maybe it is better now.",0,0,0,0.9825635552406312,0.9896250367164612,0.993181049823761,0.0,accept,unanimous_agreement
1267584848,12416,make sense to me.,0,0,0,0.9579914212226868,0.9806976318359376,0.9761042594909668,0.0,accept,unanimous_agreement
1267629058,12416,"i think the comment that describes the flags belongs where it was, i.e. next to the code the handles them (now in the renamed modulecreateargvfromuserformataux). this will also mean less changes to the diff",0,0,0,0.9865582585334778,0.9894058108329772,0.9856806993484496,0.0,accept,unanimous_agreement
1267637553,12416,"i'd rather not name it as specific for `set`. it's just a generic one that handles an array, in contrast to the other one that takes a command name. ideally we would have renamed the other one to have `cmd` in the function name. another alternative (if we can't find a good name for this one) is to call modulecreateargvfromuserformataux directly (passing null). not sure which one is better.",0,0,0,0.7981716990470886,0.9883918166160583,0.84602952003479,0.0,accept,unanimous_agreement
1267645953,12416,"i had two arguments in the past. 1. that maybe we want to let the caller pass plain c strings and so on. 2. that maybe we want to be consistent with the hash api. if i'm not missing anything, this solves the first issue, but instead of being consistent with the hash api (e.g. `redismodule_hash_cfields`), it is consistent with `rm_replicate`. maybe you have a suggestion?",0,0,0,0.9838169813156128,0.987637996673584,0.9845778346061708,0.0,accept,unanimous_agreement
1267646913,12416,"i suppose that if we let people avoid creating a redismodulestring for adding and removing, we should support that for query was well.",0,0,0,0.9822616577148438,0.9824399948120116,0.9869693517684937,0.0,accept,unanimous_agreement
1267705159,12416,the idea for the redismodule_setadd and redismodule_setrem apis are to write data locally. replication could be done via redismodule_replicate() while implementing extend redis command which accessing set data by invoking redismodule_setadd or redismodule_setrem,0,0,0,0.9864142537117004,0.995787799358368,0.992263913154602,0.0,accept,unanimous_agreement
1267709741,12416,"you mean to use ""fmt"" method like rm_setadd does, right?",0,0,0,0.9865771532058716,0.9934505224227904,0.9934815168380736,0.0,accept,unanimous_agreement
1267711288,12416,had same concern indeed. i'll change the name.,0,0,0,0.9604681730270386,0.9736098647117616,0.9051020741462708,0.0,accept,unanimous_agreement
1267723566,12416,ok. i got your point. will change.,0,0,0,0.9272737503051758,0.6514785289764404,0.9576970338821412,0.0,accept,unanimous_agreement
1267736582,12416,"my argument wasn't that we need to replicate any of these actions from inside the api. it was about the interface, if it takes format flags like rm_replicate, or flags like rm_hashset. i think it makes more sense that this api will be consistent with rm_hashset. btw, while on that subject, for hash we have just one api for both hset and hdel, maybe for sets we can do the same, and also have it cover the get (ismember case). i.e. takes a flag that tells it if it's a query, removal or addition. all 3 apis take the same set of arguments. i admit it's a bit ugly though.",0,0,0,0.9440667629241944,0.9581443071365356,0.9802466630935668,0.0,accept,unanimous_agreement
1267788375,12416,what about `modulecreateargvfromuserformat` ?,0,0,0,0.9885371923446656,0.9943566918373108,0.9952911138534546,0.0,accept,unanimous_agreement
1267790612,12416,ok. let me try to optimize it.,0,0,0,0.9816633462905884,0.97076416015625,0.9915027618408204,0.0,accept,unanimous_agreement
1268037846,12416,a blank line added by mistake? [code block],0,0,0,0.9646629691123962,0.9902039766311646,0.9815484881401062,0.0,accept,unanimous_agreement
1268039552,12416,"the drawback of having this comment before an internal function like modulecreateargvfromuserformat is that it is not visible in the generated documentation. i think it's better to put this in the documentation of rm_call() and refer to rm_call() in other commands that use it, such as rm_replicate()'s documentation.",0,0,0,0.9757180213928224,0.9907765984535216,0.9692241549491882,0.0,accept,unanimous_agreement
1268046742,12416,"for rm_hashset, it is different because there you set the field's *value* to the special `redismodule_hash_delete` to delete the field. we can't do the same with a set since an element is not a field-value pair. i like the three functions rm_setadd and rm_setrem rm_setismember. regarding format flags, i think it's better to use an `int flags` (like rm_hashset) because the string flags for rm_call() are for multiple arguments. in rm_call(), each argument has its own format specifier (like printf) but for these set api functions, all elements are of the same type and we only want one type.",0,0,0,0.900700569152832,0.9840017557144164,0.8961924910545349,0.0,accept,unanimous_agreement
1268832212,12416,mistake. will fix it.,-1,-1,-1,0.932795226573944,0.9840287566184998,0.9541595578193665,-1.0,accept,unanimous_agreement
1268838386,12416,"so there will be three functions rm_setadd, rm_setrem and rm_setismember instead combined one. and `int flags` to determine the left arguments are redismodulestring or plain c strings. is it ok to you?",0,0,0,0.9886399507522584,0.99428129196167,0.9952034950256348,0.0,accept,unanimous_agreement
1268975930,12416,"i realized i have no idea while writing the simulator to invoke the rm_setadd after changing the rm_setadd as rm_setadd(redismodulekey *key, int flags, ...) because the elements number to be added is variable. e.g. int set_add(redismodulectx *ctx, redismodulestring **argv, int argc) { if (argc < 3) return redismodule_wrongarity(ctx); redismodule_automemory(ctx); int keymode = redismodule_read | redismodule_write; redismodulekey *key = redismodule_openkey(ctx, argv[1], keymode); redismodule_replywithlonglong(ctx, redismodule_setadd(key, redismodule_set_none, **_?_**); redismodule_closekey(key); return redismodule_ok; } but with fmt. it is easy to call. e.g. int set_add(redismodulectx *ctx, redismodulestring **argv, int argc) { if (argc < 3) return redismodule_wrongarity(ctx); redismodule_automemory(ctx); int keymode = redismodule_read | redismodule_write; redismodulekey *key = redismodule_openkey(ctx, argv[1], keymode); redismodule_replywithlonglong(ctx, redismodule_setadd(key, ""v"", &argv[2], argc-2)); redismodule_closekey(key); return redismodule_ok; }",0,0,0,0.9687869548797609,0.9835342764854432,0.9857170581817628,0.0,accept,unanimous_agreement
1269168149,12416,"have you seen how it is done in [a link]? the argument list is null terminated. for format string, if you add multiple elements, would you repeat the format for each element? like `redismodule_setadd(key, ""ssss"", s1, s2, s3, s4)`?",0,0,0,0.988439679145813,0.9945893287658693,0.9935263395309448,0.0,accept,unanimous_agreement
1270148661,12416,"the problem is not at function implementation. it is at the caller which invokes the function. to be honest, rm_hashset has limitation for caller with the number of arguments must be known while invoking the function if you look at the simulator. [a link] if (argc < 5 || argc % 2 == 0 || argc > 11) return redismodule_wrongarity(ctx); if (argc == 5) { result = redismodule_hashset(key, flags, argv[3], value_or_delete(argv[4]), null); } else if (argc == 7) { result = redismodule_hashset(key, flags, argv[3], value_or_delete(argv[4]), argv[5], value_or_delete(argv[6]), null); } else if (argc == 9) { result = redismodule_hashset(key, flags, argv[3], value_or_delete(argv[4]), argv[5], value_or_delete(argv[6]), argv[7], value_or_delete(argv[8]), null); } else if (argc == 11) { result = redismodule_hashset(key, flags, argv[3], value_or_delete(argv[4]), argv[5], value_or_delete(argv[6]), argv[7], value_or_delete(argv[8]), argv[9], value_or_delete(argv[10]), null); } else { return redismodule_replywitherror(ctx, ""err too many fields""); } it is not friendly. the number of elements to be added/removed to set at key shall not be limited if referring to sadd/srem command. for example the scenario while implementing one redis extend command: 1. set multiple(unknown number) pairs of string type key/value data. 2. add the keys to one set at key for sake of finding keys performance from the set at key instead of from whole redis. you'd better not limit the number of pairs key/value from the extend command.. the benefit with fmt is the ""v"" can tell the the function next argument is redismodulestring type vector with number of elements is in next argument following.",0,0,0,0.9661865830421448,0.9888710379600524,0.9777913689613342,0.0,accept,unanimous_agreement
1270151077,12416,cmd(with command) vs gen(generic without command). both call modulecreateargvfromuserformataux().,0,0,0,0.9888834357261658,0.9941429495811462,0.9927018880844116,0.0,accept,unanimous_agreement
1270529640,12416,"you are right, `rm_hashset` is not perfect. :-) i was just saying what we need to do if we want the syntax to match `rm_hashset`. personally, i think these functions don't need to be variadic at all. if we wouldn't already have variadic hashset, i would prefer a simple api `rm_hashset(key, flags, field, value)` and let the module loop over its data and call this functions many times. but now we already have a variadict hashset so maybe we should have setadd variadic too. but we can allow a in flag corresponding to ""v"" as well, so it is possible to do something like [code block] or possibly, if we want to allow a variadic number of vectors too, expect a null-terminated list of argv-argc pairs [code block] but maybe this would make the api too complex; too hard to understand for users. it is really just as efficient to call it many times and easy to understand and write code like this: [code block] that's some possibilities. i think it's up to the core team () to make the final decisions.",1,1,1,0.9836862683296204,0.9921141862869264,0.993966817855835,1.0,accept,unanimous_agreement
1270539204,12416,ignore my previous comment.,-1,0,0,0.5424593687057495,0.8430389165878296,0.974418580532074,0.0,accept,majority_agreement
1284162819,12416,"this `else if` is always entered when op is `redismodule_set_rem` or `redismodule_set_ismember`, so why they appear in the second and thrid `else if`, and similary, `redismodule_set_add` shouldn't appear if the third `else if`.",0,0,0,0.9879001379013062,0.9933375120162964,0.9927207231521606,0.0,accept,unanimous_agreement
1285307052,12416,this `else if (op == redismodule_set_rem || op == redismodule_set_ismember)` is used to check the key shall not be empty for remove and ismember operation. add operation can be empty for creating new key. this `else if (op == redismodule_set_rem || op == redismodule_set_add)` is used to check the key mode must be write mode.,0,0,0,0.9885191321372986,0.9938788414001464,0.994579553604126,0.0,accept,unanimous_agreement
1285307464,12416,fixed in new commitment.,0,0,0,0.9804484248161316,0.9877341389656068,0.9939178228378296,0.0,accept,unanimous_agreement
1285307508,12416,fixed in new commitment,0,0,0,0.9828222393989564,0.9883117079734802,0.9935622215270996,0.0,accept,unanimous_agreement
1285307564,12416,fixed in new commitment,0,0,0,0.9828222393989564,0.9883117079734802,0.9935622215270996,0.0,accept,unanimous_agreement
1285308064,12416,we should call `moduledelkeyifempty()` to avoid creating an empty set.,0,0,0,0.9854456186294556,0.9941474199295044,0.99382883310318,0.0,accept,unanimous_agreement
1285309783,12416,is it better to move it up after the datatype block? .e.g `redismodule_get_api(streamtrimbyid);`,0,0,0,0.9878662824630736,0.9956484436988832,0.995201587677002,0.0,accept,unanimous_agreement
1285327193,12416,this null check is unnecessary as it is handled by `zmalloc_default_oom`.,0,0,0,0.9627129435539246,0.9928503036499025,0.9951074123382568,0.0,accept,unanimous_agreement
1285588095,12416,"i think setoperate with an extra parameter to select the operation, and that the return value depends on the operation, is a weird api. i prefer rm_setadd, etc. it's possible to use setoperate as a helper if it simplifies the implementation. the implementation in general looks good to me. this is just my opinion. better wait for 's comment before you change it again. he is probably busy with the release of redis 7.2 now. this pr will be in redis 8 so there is no hurry.",-1,1,1,0.7757465839385986,0.9748486876487732,0.7530331015586853,1.0,accept,majority_agreement
1286845373,12416,"i agree it looks odd (was my suggestion), i think the reason i suggested it was that for hash, we also have one api that performs two different operations, and that when the api becomes complicated (the flags), and the complication applies to all 3 operations, it means the code, but also the documentation is shared. i don't have a strong opinion, so i'd like to get views from a few others on that subject. ? do you prefer one rm_setoperation that takes the type of operation as input (add, rem, get), or 3 separate apis? considering that we have var-args and a flags input to choose between rm string and c string, sharing code and docs, vs duplicating them...",0,0,-1,0.717275857925415,0.8205681443214417,0.6654322147369385,0.0,accept,majority_agreement
1289535839,12416,"if we were starting from scratch, i don't know i would have a strong opinion about the api. but we already have explicit apis (hashget and hashset for e.g.) for all of the other types, so it would be weird that this one api have a different format (setoperation). so i guess that leads me to have a slight preference for having 3 different apis with common code underneath, even though the vargs makes it verbose (but you can have the helper take in vargs). also coming at it from someone that writes a lot of rust (which, maybe ignore), i prefer explicit signatures and documentation for functions. i don't think i mind duplicating the flags, especially since there is just one. ebadf also only makes sense for sadd and srem, so can be cleaned up. if you were writing code in something like rust which requires complete error handling, you wouldn't need to handle ebadf for ismember operation, which leads me to think rust binds for these apis would want distinct functions with custom return codes for each type (or at least the read and write split), which leads me to believe we probably should have separate functions.",-1,-1,0,0.8370185494422913,0.743208646774292,0.5443246364593506,-1.0,accept,majority_agreement
1289536419,12416,why can't we return -1 on error? enoent is a weird error code for me.,-1,-1,-1,0.9867780208587646,0.9637954831123352,0.9794691801071168,-1.0,accept,unanimous_agreement
1363020180,12416,please also test deleting from an empty key.,0,0,0,0.9869531393051147,0.992100179195404,0.99353289604187,0.0,accept,unanimous_agreement
1363044257,12416,"other apis use enotsup if the key doesn't exist or is of wrong type. (enoent is sometimes used if an *element or entry within a key* does not exist.) some apis return -1 and set errno to enotsup, for example [a link].",0,0,0,0.9868851900100708,0.9856186509132384,0.992451012134552,0.0,accept,unanimous_agreement
1366807610,12416,"what about setting errno in these is-member cases? i suggest returning -1 on errors here, so users cab distinguish between zero (not a member) and error. !key->value is not an error, but !key and wrong type are errors.",0,0,0,0.8882580995559692,0.9844754338264464,0.993402659893036,0.0,accept,unanimous_agreement
1368223280,12416,ok. changed as !key for empty key if open key with reading mode. !key-value for empty key if open key with writing mode.,0,0,0,0.9717512726783752,0.9904272556304932,0.992455005645752,0.0,accept,unanimous_agreement
1368268789,12416,"yes, looks good now. :+1:",1,1,1,0.9839025139808656,0.9919448494911194,0.9964385032653807,1.0,accept,unanimous_agreement
1399960191,12416,"this comment isn't correct, if all the elements already exist in the set, `numadded` will be 0.",0,0,0,0.966532289981842,0.9898202419281006,0.9866018891334534,0.0,accept,unanimous_agreement
1399963889,12416,there is a strong desire for me to move the implementation of this whole piece after `redismodule_streamtrimbyid`. :beaming_face_with_smiling_eyes:,1,0,1,0.9199407696723938,0.9504312872886658,0.9376190900802612,1.0,accept,majority_agreement
1400201923,12416,thank you :-),1,1,1,0.983310043811798,0.9512805938720704,0.8494778275489807,1.0,accept,unanimous_agreement
1400249816,12416,"a bit difficult to describe it more accurate. so changed it to ""_returns redismodule_ok if elements have been added successfully._"". meaning no failure happened though zero element was added.",0,0,0,0.9432140588760376,0.9870404601097108,0.8802529573440552,0.0,accept,unanimous_agreement
710740349,9511,"these are added syscalls for non-linux if o_cloexec is not set. to avoid doing extra syscalls, do this only if the flag is set in read_flags and write_flags.",0,0,0,0.989164412021637,0.9936502575874328,0.9949328303337096,0.0,accept,unanimous_agreement
710741000,9511,we always set this for linux because it does no harm and it's no extra cost? maybe explain this in a comment.,0,0,0,0.9733778238296508,0.9854238629341124,0.992608368396759,0.0,accept,unanimous_agreement
710742169,9511,better be explicit and write o_cloexec|o_nonblock everywhere. it makes the code more clear imo.,0,0,0,0.977784276008606,0.9863714575767516,0.9819607734680176,0.0,accept,unanimous_agreement
710745968,9511,better spell out the actual flags here. the code can say what the comment above says. it's more clear imo.,0,0,0,0.967864990234375,0.8965914249420166,0.9782520532608032,0.0,accept,unanimous_agreement
710755931,9511,"yes, it is like a convention without extra side effects, i'll add a comment fot it.",0,0,0,0.9805573225021362,0.9628177881240844,0.9864878058433532,0.0,accept,unanimous_agreement
710757922,9511,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
710757939,9511,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
710760953,9511,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
710775786,9511,"i'm not sure if util.c is the best file to put `createpipe()`. maybe `anet.c` is a better place. so far, util is mostly string manipulation functions. the commet in anet.c says ""basic tcp socket stuff made a bit less boring"", but some functions like `anetnonblock()` is for any file descriptor, also pipes, so i think createpipe() can also be in anet. i will leave it for other reviewers to think about.",0,0,0,0.4916707575321197,0.907742202281952,0.9306374788284302,0.0,accept,unanimous_agreement
710777575,9511,i've thought about putting `createpipe()` into `anet.c` and then ceased for the same reason of you. any suggestions?,0,0,0,0.9845660328865052,0.955522358417511,0.990412175655365,0.0,accept,unanimous_agreement
710781018,9511,"if we want to keep anet for only tcp, we can avoid using `anetnonblock()` in `createpipe()`. it's actually nothing else than `fcntl(fd, f_setfl, o_nonblock)` so i think we can just call fcntl directly here and not include anet.h.",0,0,0,0.9857419729232788,0.9923862218856812,0.9903241395950316,0.0,accept,unanimous_agreement
710784019,9511,"actually `anetnonblock()` is also called on pipes way before this pr, so i don't think `createpipe()` using `anetnonblock()` is our main problem here.",0,0,0,0.9814199805259703,0.9886714220046996,0.988646388053894,0.0,accept,unanimous_agreement
710794678,9511,"no, the problem is that util now depends on anet. it is better if they are independent. i just realized anetnonblock does one fcntl to read the flags and then another to set the flags. anetcloexec also does two. if we set both flags (non-linux non-freebsd) we do 4 syscalls instead of 1 (fcntl with all flags combined) for one fd. actually, i think createpipe() can be much simpler if it's actually setting all flags directly (error handling omitted): [code block]",0,0,0,0.962885558605194,0.9792441725730896,0.9862509965896606,0.0,accept,unanimous_agreement
710811576,9511,"`createpipe()` would be concise if we just call `fcntl()` directly instead of `anetnonblock()` and `anetcloexec()` like you said, what do you think about that?",0,0,0,0.9872522354125975,0.9942018389701844,0.9897462129592896,0.0,accept,unanimous_agreement
711254717,9511,i just recall that we can't simply refine the `createpipe()` like that cuz we have to differentiate between `f_getfl/f_setfl` and `f_getfd/f_setfd`,0,0,0,0.9870222210884094,0.9885866045951844,0.9914888143539428,0.0,accept,unanimous_agreement
711559026,9511,"oh, good point. they're called ""file descriptor flags"" (fd) and ""file status flags"" (fl) in the fcntl map page. i still think we should use fcntl directly instead of the anet functions. why? * we avoid the extra syscalls with f_getfl and f_getfd. * anetnonblock and anetcloexec are not abstracting anything anyway because we know we're working with file descriptors since we call pipe() and pipe2() and we use the constants defined in fcntl.h (o_cloexec and o_nonblock). it's a useless abstraction which only hides what's happening.",1,0,1,0.7581368088722229,0.501423180103302,0.8144358396530151,1.0,accept,majority_agreement
711639657,9511,this fallback code for linux and freebsd is identical to the `#else` code (non-linux non-freebsd) below. we can avoid code duplication using goto.,0,0,0,0.9878772497177124,0.9936641454696656,0.994847297668457,0.0,accept,unanimous_agreement
711639822,9511,"this shouldn't be done here if pipe2() has already set o_nonblock. it's extra syscalls which you wanted to avoid using pipe2, right? an idea how to combine/simplify the common code for pipe() and pipe2() is to set flags = 0 in the pipe() case. then, here in the code which is common for both pipe() and pipe2(), if `flags & o_nonblock` is true it means that the flag it has already been set in pipe2 above. it's probably even more clear to rename `flags` to `pipe_flags` too. example: [code block] ... and we can easily allow any other flags as well (all except cloexec can be set using f_setfl) just by changing the last part like this: [code block]",0,0,0,0.9790687561035156,0.9939568042755128,0.9897063970565796,0.0,accept,unanimous_agreement
711643056,9511,this include isn't needed in util.h now.,0,0,0,0.9857264757156372,0.9899281859397888,0.9940225481987,0.0,accept,unanimous_agreement
711672426,9511,i think you missed the above code: [code block],0,0,0,0.946735978126526,0.9790465831756592,0.9890058040618896,0.0,accept,unanimous_agreement
711672719,9511,"this is for macos build, `o_cloexec` and `o_nonblock` will be not defined without this include.",0,0,0,0.9894853234291076,0.993511974811554,0.9951183795928956,0.0,accept,unanimous_agreement
711673339,9511,but i can try to simplify the code further.,0,0,0,0.9843589067459106,0.9771335124969482,0.9904378056526184,0.0,accept,unanimous_agreement
711675549,9511,"i don't think this is necessary, we should only focus on `o_nonblock` and `o_cloexec` which are currently used.",0,0,0,0.9808768630027772,0.98331880569458,0.983565390110016,0.0,accept,unanimous_agreement
711677821,9511,"![a link] we need to resolve the compilation error of ""unused labels"" in redis ci on mac.",0,0,0,0.9845520853996276,0.9757227897644044,0.9759817719459534,0.0,accept,unanimous_agreement
711712046,9511,these macros are not used in this file. the include is needed in util.c though.,0,0,0,0.9877369403839112,0.9928964972496032,0.9940648674964904,0.0,accept,unanimous_agreement
711712270,9511,"oh, just put the pipe label before `#endif`",0,0,0,0.985672116279602,0.9750975370407104,0.994429647922516,0.0,accept,unanimous_agreement
711712684,9511,for 'common' i think it's not to hard to solve...,0,0,0,0.8511563539505005,0.8982685208320618,0.9400728940963744,0.0,accept,unanimous_agreement
711713052,9511,"what about label ""common""?",0,0,0,0.9807342290878296,0.9893388152122498,0.9888259172439576,0.0,accept,unanimous_agreement
711713189,9511,"it seems to me that the label ""common"" will fail the build on mac anyway.",0,0,0,0.8015454411506653,0.8370391726493835,0.933971107006073,0.0,accept,unanimous_agreement
711716432,9511,i was talking about [a link],0,0,0,0.9302076697349548,0.9792166352272034,0.9895581603050232,0.0,accept,unanimous_agreement
711721259,9511,"i'm sorry, i'm not following this discussion closely (busy elsewhere). regarding this specific thread (haven't read all of it), here's my view. i think anet.c isn't currently specifically related to tcp, it's a file that contains some platform abstraction utilities (mainly revolved around sockets, and file descriptors), so this pipe related wrapper seems to be a good candidate to be placed there. on the other hand, util.c is not about platform abstraction, but rather just some pure c code utilities for small chores.",-1,-1,-1,0.9854642748832704,0.9877262711524964,0.975692868232727,-1.0,accept,unanimous_agreement
711722010,9511,"ok, i'm moving the `createpipe()` from `util.c` to `anet.c`.",0,0,0,0.9884767532348632,0.991933047771454,0.9942892789840698,0.0,accept,unanimous_agreement
711812221,9511,this is slightly hard to understand. just an idea. after successful pipe2() do this: [code block] then the code setting flags is more simple: [code block],0,0,0,0.9349846839904784,0.7926289439201355,0.9282848834991456,0.0,accept,unanimous_agreement
711845859,9511,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
723051144,9511,"for a moment i thought that maybe we wanna backup and restore `errno` here. but i guess there's no need (successful close will not not change it, and if for some reason `close` fails, i'm not sure we care too much which error was it). let me know if you think otherwise.",0,0,0,0.8615099787712097,0.9197585582733154,0.9060214757919312,0.0,accept,unanimous_agreement
723068214,9511,"i don't think there is anything we can do when the `close(fd)` fails, and also, there is no need to worry too much about it cuz when this extremely unlikely failure happens to `close`, it could be a kernel defect which is not something redis can handle.",0,0,0,0.9597534537315368,0.9363993406295776,0.9645549654960632,0.0,accept,unanimous_agreement
723068910,9511,so we should just follow the current strategy like: [a link],0,0,0,0.9756718277931212,0.9904606938362122,0.993645429611206,0.0,accept,unanimous_agreement
723077851,9511,"actually also ""defined"". it's from the `fcntl` manpage: ![a link]",-1,0,0,0.6581146121025085,0.96283221244812,0.9850908517837524,0.0,accept,majority_agreement
723120545,9511,"thing brings me to another thought. are we sure we can mix these two flags in the same variable? is there any guarantee that they don't collide? (considering they where intended to be used by different ""functions"")",0,0,0,0.9558972120285034,0.9457272291183472,0.9768056869506836,0.0,accept,unanimous_agreement
723121359,9511,"i wasn't concerned about exec failing, but rather about preserving the value of the original `errno`. but i don't think that's a real concern..",-1,0,0,0.5471929311752319,0.6211446523666382,0.8598071932792664,0.0,accept,majority_agreement
723125421,9511,they don't collide. pipe2 takes them in the same variable.,0,0,0,0.9823523163795472,0.9741514325141908,0.9865593910217284,0.0,accept,unanimous_agreement
723126684,9511,"yes, there is such a guarantee because the only file descriptor flag: `fd_cloexec/o_cloexec` is now treated specially in the current `anetpipe()`, which makes sure this flag won't interfere with other file status flags like `o_nonblock`.",0,0,0,0.9883050918579102,0.9934529066085817,0.993165910243988,0.0,accept,unanimous_agreement
723130059,9511,the argument about pipe2 taking them in the same variable applies only to linux.. maybe in another system they can be overlapping?,0,0,0,0.9801181554794312,0.9874951243400574,0.992496371269226,0.0,accept,unanimous_agreement
723131938,9511,"ok, they're both used in `open` syscall in the same argument too.",0,0,0,0.988235354423523,0.9929959177970886,0.9932950139045716,0.0,accept,unanimous_agreement
723132640,9511,actually `pipe2()` works the same way on freebsd as it does on linux: [a link],0,0,0,0.9862931966781616,0.9900229573249816,0.9952243566513062,0.0,accept,unanimous_agreement
723159593,9511,"that's a valid point. the constants are in the same ""namespace"" though, as their names all start with same prefix, so it's hard to imagine that they will collide in any system. [edit] ahh, there are `o_cloexec` and `fd_cloexec`.....",0,0,0,0.9764278531074524,0.9266629219055176,0.9649537205696106,0.0,accept,unanimous_agreement
723163239,9511,"i guess we need to use `fd_cloexec` when it's set with fcntl, e.g. [code block]",0,0,0,0.9869437217712402,0.994282364845276,0.9880867004394532,0.0,accept,unanimous_agreement
723167402,9511,"at least we can confirm that `o_cloexec` and `fd_cloexec` have the same value on linux and freebsd, and i believe that's all we need to know here, so i don't think this is a concern in this pr.",0,0,0,0.8734901547431946,0.9782938957214355,0.8613077998161316,0.0,accept,unanimous_agreement
723170512,9511,"no, this code is used also in systems without pipe2.",0,0,0,0.9851731061935424,0.9916583895683287,0.9923916459083556,0.0,accept,unanimous_agreement
723172777,9511,good catch!. i had an itch but couldn't scratch it.. this is probably a bug that could have go unnoticed. let's also make sure to clearly define which flags should be used (the `o_xxx` ones) in the top comment of this function.,1,1,1,0.9899573922157288,0.9835689663887024,0.9941864013671876,1.0,accept,unanimous_agreement
723174462,9511,"theoretically, `o_cloexec` (used by pipe2 and open) doesn't have to be equal to `fd_cloexec` (used by fcntl), so i think we need this change. in the manpage of `open` (man 2 open): by default, the new file descriptor is set to remain open across an ex‐ ecve(2) (i.e., the fd_cloexec file descriptor flag described in fc‐ ntl(2) is initially disabled); the o_cloexec flag, described below, can be used to change this default. the file offset is set to the begin‐ ning of the file (see lseek(2)). [code block] i do think it's safe to assume that `o_cloexec` macro does not collide with other `o_` macros though.",0,0,0,0.9792596101760864,0.9915305376052856,0.9917480945587158,0.0,accept,unanimous_agreement
723176862,9511,resolved.,0,0,0,0.9765522480010986,0.9865591526031494,0.9832034111022948,0.0,accept,unanimous_agreement
723177446,9511,"yeah, we can the `o_` macros are not colliding (not just because of the common prefix, but also because they can be used in `open`). but since there are two flags with similar purpose, we must make it clear in a top comment above the function which ones should be used.",0,0,0,0.9865174889564514,0.991628885269165,0.9904248118400574,0.0,accept,unanimous_agreement
723185941,9511,i think that `anetpipe()` supports file descriptor flag `o_cloexec` and all other file status flags in theory.,0,0,0,0.989054799079895,0.9914056062698364,0.9885196089744568,0.0,accept,unanimous_agreement
723191856,9511,"there are some flags in `open` that make no sense for pipes, such as `o_directory`. the ones supported by pipe2 are probably the only ones that make sense for pipes. we can add `o_direct`.",0,0,0,0.9878465533256532,0.9950902462005616,0.99191552400589,0.0,accept,unanimous_agreement
723198544,9511,"we can say that it supports the flags supported by `pipe2()` and `fcntl(f_setfl)`, and also explicitly give `o_cloexec` and `o_nonblock` as examples, this way we're covered by both telling the truth about the capabilities of this function, and also making sure users don't use `fd_cloexec` by mistake.",0,0,0,0.9881673455238342,0.991576373577118,0.991205394268036,0.0,accept,unanimous_agreement
723201962,9511,"yes, some file status flags might not be passed into `anetpipe()`, but the current comment is kind of misleading that `anetpipe()` only supports these flags function functionally while it actually supports all file status flags in theory, even though lots of flags is needless, how about change the comment to ""the supported flags are o_cloexec and all other file status flags in theory, but o_cloexec and o_nonblock are adequate.""",0,0,0,0.9583548903465272,0.809647262096405,0.8920572996139526,0.0,accept,unanimous_agreement
723205525,9511,"i think ""status flags"" is a bit vague, i rather refer to `fcntl(f_setfl)` like i did in my previous comment. in any case, i want to give explicit examples `o_cloexec` and `o_nonblock`, the other details are concerning me less.",0,0,0,0.928429126739502,0.9608810544013976,0.9774240255355836,0.0,accept,unanimous_agreement
1336789539,12611,[code block] `__mac_10_6` didn't exist before 10.6.,0,0,0,0.9881300926208496,0.9951342940330504,0.9939146637916564,0.0,accept,unanimous_agreement
1336969649,12611,thank you for your review. this is just too foolish.,-1,-1,-1,0.9835718870162964,0.9896562099456788,0.9910845756530762,-1.0,accept,unanimous_agreement
1337078524,12611,seem to me that these indentations are unnecessary.,0,0,0,0.5645369291305542,0.9625969529151917,0.965775728225708,0.0,accept,unanimous_agreement
1337097889,12611,"i don't like the pinning here for a specific version (which i assume is newer than macos-latest). i suggest instead of keep using macos-latest here in daily.yaml. and add a quick (maybe just compilation ci step, like we do in ci.yml) on both newer (13) and older (10?) macos. wdyt?",-1,0,0,0.9597508311271667,0.5131934881210327,0.8274989128112793,0.0,accept,majority_agreement
1337105062,12611,can you do me a favor and also explain the difference between these macros in the pr top comment and how it affects this check.,0,0,0,0.9749464392662048,0.8650659918785095,0.986071527004242,0.0,accept,unanimous_agreement
1337106999,12611,maybe we can simplify the code (here and in other places) by creating some short-hand define? e.g. mac_os_10_6_detected ?,0,0,0,0.987985908985138,0.99435555934906,0.98969167470932,0.0,accept,unanimous_agreement
1337132358,12611,"i think using macos-latest is enough, waiting for github action to get him up to speed with 13, which was just to run a verification, and now we can revert it, please do this. the minimum supported version of macos of github action is 11, so we don't need to do that either.",0,0,0,0.9505809545516968,0.97748464345932,0.9489620327949524,0.0,accept,unanimous_agreement
1337154882,12611,but what if we some day do some change that is incompatible with 11 and won't notice?,0,0,0,0.9126383066177368,0.8436456322669983,0.953417956829071,0.0,accept,unanimous_agreement
1337185168,12611,do you mean 10.6 instead of 11?,0,0,0,0.9841984510421752,0.9908115863800048,0.990084171295166,0.0,accept,unanimous_agreement
1337236700,12611,"i mean that same as we discovered now, a compilation issue with a certain sdk or os version, it could be some some future change we'll make will be incompatible with an older version (either pre 10.6, or 11.0), and then i'd like the ci to detect that before (or shortly after) merging.",0,0,0,0.9816847443580629,0.9861702919006348,0.9912506341934204,0.0,accept,unanimous_agreement
1337349002,12611,the description explaining this behavior has already been updated in the top comments.,0,0,0,0.987036406993866,0.9863728880882264,0.9948687553405762,0.0,accept,unanimous_agreement
1337353695,12611,"mac_os_x_version_10_6 is just the boundary point for these few code, perhaps there will be more boundary points in the future, i think it would be better to describe it directly.",0,0,0,0.9817473292350768,0.9901832938194276,0.9895852208137512,0.0,accept,unanimous_agreement
1337370910,12611,"daily.yml: [a link] run ci: [a link] that's what you're supposed to want. but i still have my doubts, there's no way to predict when macos will come up with broken compatibility changes, and we could still end up with what we're experiencing now.",-1,-1,0,0.7986313700675964,0.5538902282714844,0.7559269666671753,-1.0,accept,majority_agreement
1338089463,12611,what you did seems right. of course we cant protect from their compatibility changes introduced by future versions. but at least i want to protect from our changes breaking compatibility with an older version. please make a pr,0,0,1,0.9107566475868224,0.9601412415504456,0.6813223958015442,0.0,accept,majority_agreement
1338094422,12611,"i mean, in the past we used to use fstat64 only when mac_os_x_version_10_6 is not defined. so i assume any version that's older than 10.6. (it was defined in all newer versions). and now we're using __mac_os_x_version_min_required (if defined and set to lower than 1060). so i assume older versions don't have that define, and in newer ones it is set to higher value? shouldn't we use `>=` instead of `<`?",0,0,0,0.9815770983695984,0.9919945001602172,0.9894979000091552,0.0,accept,unanimous_agreement
1338095543,12611,"yeah, but it makes the condition complicated, so extracting it to a separate line will help, even if it's just for one condition. also, the same one happens to be used in 3 conditions. if we'll have more boundary points in the future, we can add more of these.",0,0,0,0.965481162071228,0.9534124732017516,0.9879000186920166,0.0,accept,unanimous_agreement
1339470333,12611,"i see that `__mac_os_x_version_min_required` already exists in macos sdk 10.1, so we can assume that it was always there. a second thought, i feel like we're misusing `__mac_os_x_version_min_required`, which lets the developer tell the compiler that we want the program to be able to be executed at a certain minimum version, but in reality, we're forcing the use of `fstat64` up to 10.6, and `fstat` after that. in that case i think #12601 would have been more appropriate , at least it wouldn't have been confusing. btw, we can use the `make redis_cflags='-mmacosx-version-min=10.1'` command to make this pr compile fail.",0,0,0,0.6587923169136047,0.9881069660186768,0.9703070521354676,0.0,accept,unanimous_agreement
1339480151,12611,"`int fstat64(int, struct stat64 *) __osx_available_but_deprecated(__mac_10_5, __mac_10_6, __iphone_na, __iphone_na);` from the definition of fstat64, it can be seen that it was changed from 10.5 and deprecated from 10.6. we can safely use fstat64 when the mac_os_x_version_max_allowed is less than 10.6, as it represents the highest available api version. the default definition of mac_os_x_version_max_allowed starts from 10.1, so we don't need to worry about it. using mac_os_x_version_min_required may seem less reasonable compared to this approach. for instance, if mac_os_x_version_min_required is set to a value lower than 1060 and mac_os_x_version_max_allowed is set to a value greater than 1060, we should use fstat. [code block] is this logic reasonable?",0,0,0,0.9876267313957214,0.9943873286247252,0.9891231656074524,0.0,accept,unanimous_agreement
1339576814,12611,"ok, i think i understand what i was missing so far. the min_required thing is a way for for the user to tell the build which versions are expected to run the binary we're producing, and in our case it is implicitly defined by the sdk rather than by us. i personally don't care much for macos builds, i assume they're only used for development and testing, and that no one circulates binaries, and we can assume that the system that builds them is the one that runs them. maybe i'm wrong. am i? in that light, it doesn't matter if we use min_required or max_allowed, we can't support both versions in the same build anyway. anyway, my attention is needed elsewhere. i delegate the decision to you (if you're willing to take it), please just make sure it is explained in the code / commit message, and we have some ci coverage for what we can easily get.",-1,0,0,0.9442298412322998,0.8134875297546387,0.7980296015739441,0.0,accept,majority_agreement
1339640569,12611,"i tend to use `__mac_os_x_version_max_allowed`, which is the recommended way to determine version from the official documentation. [a link] [code block]",0,0,0,0.9864367842674256,0.9921648502349854,0.9935675263404846,0.0,accept,unanimous_agreement
1339677482,12611,"okay, i agree.",0,0,0,0.918596625328064,0.9435700178146362,0.9773266911506652,0.0,accept,unanimous_agreement
1339800835,12611,"i do agree with adding `mac_os_10_6_detected`, i thought about it before, but i kept quiet.",0,0,0,0.9696388840675354,0.9803867936134338,0.9792032241821288,0.0,accept,unanimous_agreement
1339844955,12611,okay.,0,0,0,0.9698997735977172,0.9151892066001892,0.9765366315841676,0.0,accept,unanimous_agreement
1339849033,12611,please add this to `fmacro.h`,0,0,0,0.9789453148841858,0.9936516284942628,0.9951933026313782,0.0,accept,unanimous_agreement
1339864884,12611,"i just thought about it too, but `__mac_os_x_version_max_allowed` is defined after `#include `.",0,0,0,0.9879438877105712,0.9935691356658936,0.9937717318534852,0.0,accept,unanimous_agreement
1339875949,12611,"yes, you are right, let's keep it as now.",0,0,0,0.95577871799469,0.8634045124053955,0.960553765296936,0.0,accept,unanimous_agreement
1339989515,12611,"please add some comments to this to explain why we are doing this, maybe refer to the official documentation.",0,0,0,0.9790515899658204,0.9814473390579224,0.9913504123687744,0.0,accept,unanimous_agreement
1339991870,12611,"please also apply [a link] to this pr, and put it after `test-macos-latest-cluster` block.",0,0,0,0.9884400367736816,0.9938411712646484,0.9950189590454102,0.0,accept,unanimous_agreement
1342043371,12611,"looks good, please finish the rest before merging.",1,1,0,0.8411303162574768,0.5614758729934692,0.6381831765174866,1.0,accept,majority_agreement
1342904526,12611,"may i know, what does `__mac_os_x_version_max_allowed` translates to? who is responsible for setting this max version value? is it compiler? or is it us? do we define this via some build file?",0,0,0,0.9880457520484924,0.9922548532485962,0.9928507804870604,0.0,accept,unanimous_agreement
1342905543,12611,please add a comment mentioning the detailed reasoning behind this.,0,0,0,0.9809685945510864,0.9801827669143676,0.993486762046814,0.0,accept,unanimous_agreement
1342908902,12611,"could you please define `mac_os_10_7_detected` at the start of this file, similar to `mac_os_10_6_detected`. being consistent always helps, thanks! please add a comment to, this will greatly help in future to tackle similar problems if observed.",1,1,1,0.9745602011680604,0.9697507619857788,0.9824994802474976,1.0,accept,unanimous_agreement
1343432830,12611,`__mac_os_x_version_max_allowed` is to determine the highest macos version we want to run on. it is determined by the sdk: [code block] also refer to the document (conditionally compiling for different sdks): [a link],0,0,0,0.9881057739257812,0.994602620601654,0.994717538356781,0.0,accept,unanimous_agreement
1343433921,12611,"it's only used in one place, so it's not the same as mac_os_10_6_detected which is used in more than three places.",0,0,0,0.9853277802467346,0.9907004237174988,0.9923696517944336,0.0,accept,unanimous_agreement
1346224183,12611,"i'm okay, but remember it's not about one place or three places. it's about consistency and that always helps in the long run. tomorrow the issue could arrive for another versions, and if we maintain all such things at a single place really helps. ideally we should have a separate header file for maintaining such things. thanks!",1,1,1,0.973634958267212,0.9942381381988524,0.9910455346107484,1.0,accept,unanimous_agreement
1346227541,12611,thanks!,1,1,1,0.9308210611343384,0.9051083922386168,0.8631753921508789,1.0,accept,unanimous_agreement
1346232058,12611,??,0,0,0,0.7592602372169495,0.6925134658813477,0.9506898522377014,0.0,accept,unanimous_agreement
1349608568,12611,[a link] this is the reason why we don't put it in `fmacros.h`,0,0,0,0.9819732904434204,0.9943643808364868,0.9948939085006714,0.0,accept,unanimous_agreement
748790946,9774,why are we catching these exceptions? also if the test fails midway through these changes will get lost.,0,0,0,0.944147288799286,0.7305241227149963,0.9860471487045288,0.0,accept,unanimous_agreement
753402050,9774,"good question. i was copying what existing tests did. looking at it now, it makes more sense to let the exceptions be raised and fail the test, instead of catching and dropping them. re: tests failing midway through. if one test case fail, does the test framework continue to run the remaining tests? if yes, this sounds like the generic issue, i.e. the lack of isolation between cluster tests. how do existing tests handle prevent ""leaks""?",1,1,1,0.5451581478118896,0.8265246152877808,0.930634379386902,1.0,accept,unanimous_agreement
757686028,9774,"yeah, the testing framework is a little bit silly in that it doesn't do a full reset of the cluster nodes.",-1,-1,-1,0.8854041695594788,0.9437796473503112,0.916381061077118,-1.0,accept,unanimous_agreement
757686583,9774,this isn't accurate anymore.,-1,0,0,0.7013111114501953,0.4989315569400787,0.8841691613197327,0.0,accept,majority_agreement
757715820,9774,fixed.,0,0,0,0.9810503125190736,0.979083240032196,0.9905837774276732,0.0,accept,unanimous_agreement
757885604,9774,"so this is similar to the client output buffer limit, right? dropping connections when they consume too much memory. which is suppose to be the case only when a cluster node hangs (or on a burst of local publish calls)?. i see that there too the limit is enabled by default for some types. specifically, the replica client are limited to 256mb, and the pubsub clients to 32mb. i assume that considering that there are usually not a lot of replicas, this makes the cluster nodes more similar to pubsub clients, so maybe we should aim much lower with the default limit? for clients, we now also have a limit for the sum memory of all of them (`maxmemory-clients`) but i suppose that for cluster nodes we don't need that (unlike clients, their number is bound and controlled by an admin)",0,0,0,0.9651747941970824,0.9889095425605774,0.9581379294395448,0.0,accept,unanimous_agreement
757885877,9774,"i suppose we better use differed reply, rather than run the loop twice.",0,0,0,0.9824013113975524,0.9576950669288636,0.976161777973175,0.0,accept,unanimous_agreement
757886375,9774,is it really needed to expose the fd to users?,0,0,0,0.9836283922195436,0.9923134446144104,0.9889777302742004,0.0,accept,unanimous_agreement
757886449,9774,this is another interface change,0,0,0,0.9855397939682008,0.9789018034934998,0.9919201135635376,0.0,accept,unanimous_agreement
757922941,9774,"for some reason i thought we also exposed the fd in client list, but we don't. i would agree that i don't think we should emit it.",0,0,0,0.891670823097229,0.9596813321113586,0.9792078137397766,0.0,accept,unanimous_agreement
757923253,9774,"i forgot where we came up with 1gb, but lowering seems reasonable. i think the limit is somewhere in between the two. we expect the other side to be consuming the data as fast as possible, like a replica, but it also has the high write amplification like pubsub. since each individual link is small, i agree that 32mb sounds reasonable.",0,0,0,0.9701218605041504,0.9640717506408693,0.962676167488098,0.0,accept,unanimous_agreement
758600388,9774,"this feature aims to protect against any case where a peer cannot drain cluster link send buffers as fast as redis can fill them, e.g. hang peer, slow peer, etc. i chose 1gb as the default limit based on the max possible size of a single pubsub command, which is 1gb by default (`client-query-buffer-limit`'s default value). i wanted cluster link buffer to be able to fit at least a single pubsub command by default. let me know what you think.",0,0,0,0.97038471698761,0.9799304008483888,0.6605674624443054,0.0,accept,unanimous_agreement
758601109,9774,removed `fd` from the `cluster link` output.,0,0,0,0.9846593141555786,0.9948786497116088,0.9947625994682312,0.0,accept,unanimous_agreement
758601418,9774,changed. didn't know deferred reply is a thing.,-1,0,0,0.6004276871681213,0.8695729970932007,0.5651569962501526,0.0,accept,majority_agreement
758608188,9774,"yes. in general, imo memory consumption on the cluster bus has been a blind spot. for example, before we had [a link], cluster link buffers never shrunk and could grow unbounded, but we have no way to observe/monitor it while it was happening.",0,0,0,0.7649592757225037,0.8679362535476685,0.9359662532806396,0.0,accept,unanimous_agreement
759228338,9774,"by ""interface change"" i meant it should be listed in the top comment, for the purpose of release notes and approval of reviewers that don't have time to read the code. i.e. all interface changes are ""major decisions"" that must have lazy consensus by the core-team.",0,0,0,0.9592360258102416,0.9923027753829956,0.9848006963729858,0.0,accept,unanimous_agreement
759231122,9774,"i suppose that effectively this means for many deployments as if the default is practically unlimited (will still cause mass eviction / oom). maybe that's a good thing, to consider that as if it's not a ""breaking change"", i.e. the new default has the same behavior as the old versions, but if we look at it like that, maybe just set it to 0 by default? if we have any specific reasoning like the one you just mentioned, maybe we should document it in the redis.conf and also in the top comment.",0,0,0,0.9570035338401794,0.985919713973999,0.9738851189613342,0.0,accept,unanimous_agreement
759532841,9774,"i dont know if i agree that the default of 1gb is practically unlimited. 1gb is indeed a generous limit but it still offers some protection which is better than none, because slow peers due to network issues are real issues. i believe the protection offered by this new limit should be turned on by default. i would even prefer lowering it to 32mb than `0`, but imo 1gb makes sense because my reasoning in the previous post. added this reasoning to `redis.conf` and top comment.",0,0,0,0.8157173991203308,0.9379647374153136,0.8848333954811096,0.0,accept,unanimous_agreement
759533212,9774,i see. good to know. thanks for the info. added to the top comment.,1,1,1,0.9806957840919496,0.9904893636703492,0.9935870170593262,1.0,accept,unanimous_agreement
759560021,9774,i suppose we should add a log message here to explain what happened?,0,0,0,0.9823186993598938,0.9874234795570374,0.9925690293312072,0.0,accept,unanimous_agreement
759561904,9774,"i suppose one problem with 32mb is that pubsub messages might get constantly dropped and it would be very hard to notice. unlike a regular pubsub client, which will get repeatedly disconnected if large messages are put in it, the cluster link will just get dropped and re-established, but the ""connected"" pubsub client won't notice anything. so i guess i'm back in the 1gb camp, and we'll use it more as a mechanism to make sure it doesn't grow unbounded.",0,0,0,0.9108436703681946,0.7478145956993103,0.9383846521377563,0.0,accept,unanimous_agreement
759574142,9774,"i was arguing that for **some** deployments it's practically unlimited. i.e. ones with not a lot of memory (either physical, or just the maxmemory config), or ones with a lot of cluster nodes. so considering that, i was arguing that maybe the default should be disabled, and thus not changing default behaviour on upgrades. p.s. note that nearly all the memory limit setting in redis are off by default (except for client buffers). this is because it's impossible to come up with a number that will be a good default for everyone. anyway, considering what wrote, about getting disconnections and reconnection, resulting the silent loss of messages with no clear issue indicated anywhere, i'm not sure i like that feature at all..",0,0,0,0.7475748062133789,0.8625068664550781,0.943468987941742,0.0,accept,unanimous_agreement
759603869,9774,"i hear you about it's impossible to pick a default to make everyone happy. i also agree that **silently** dropping cluster links and pubsub broadcast messages is bad. please allow me to re-visit why i wrote this pr in the first place. before this pr, cluster link buffers can grow unbounded and: 1. it's impossible to observe if it is happening 2. it's impossible to isolate which link is using memory 3. it's impossible to mitigate it with minimal impact on the server (there is no easy way to free a specific cluster link that is over-using memory). in this pr: 1. `mem_cluster_links` info field is introduced to address (1) 2. `cluster links` command is introduced to address (2) 3. `cluster-link-sendbuf-limit` config is introduced to address (3). in this context, re: `enabling cluster-link-sendbuf-limit by default or not`. i was leaning toward enabling by default. because i trust the default of 1gb will not produce ""false alarms"". that is, we never expect a cluster link to use >1gb by default. when a cluster link does, it means redis is operating in an abnormal and degraded mode, which we want to get out of. enabling by default just means redis would auto-mitigate such an abnormal situation, which is a net positive. on smaller deployments where there is not a lot of memory, this auto-mitigation will never take effect unfortunately, so redis regresses to its current behavior, but at least it doesn't make things worse. re: `using 1gb as default`. i guess my reasonings can be summarized as: 1. in conjunction with `client-query-buffer-limit'`s default value of 1gb, a default 1gb of `cluster-link-sendbuf-limit` should/would not produce false alarms, which is important. 2. while it's impossible to pick a default everyone likes, sometimes we still have to pick a sensible number to give us some bottom line protection. e.g. `client-query-buffer-limit` default to 1gb is a good example. i tried to follow that. re: `silently dropping cluster links and pubsub messages`. i agree this is bad. this is a separate issue. it seems like whenever `cluster-link-sendbuf-limit` takes effect and frees a link, we also want to print a log and/or increment a metric count (e.g. a `cluster_links_freed_oom` info field, etc). so it's not ""silent"". i can add that in the next revision if we all agree to if we want a log, a metric, or both. thank you for your feedback. please let me know your thoughts.",-1,-1,-1,0.9518772959709167,0.7491165399551392,0.9341052770614624,-1.0,accept,unanimous_agreement
759682242,9774,"i'm still in favor of setting 1gb, but only making this available in redis 7. in some sense it is a backward breaking change, but it is bounding the problem moving forward.",0,0,0,0.9665094614028932,0.839231550693512,0.9530624747276306,0.0,accept,unanimous_agreement
763744109,9774,decision by core team was to set the default to 0.,0,0,0,0.9836615920066832,0.9884915351867676,0.991789937019348,0.0,accept,unanimous_agreement
768188965,9774,"added a warning log message, considering this is not expected in normal operation.",0,0,0,0.9869333505630492,0.9840960502624512,0.9941641688346864,0.0,accept,unanimous_agreement
768189064,9774,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
768196551,9774,let's move this into the `cluster info` command.,0,0,0,0.9883775115013124,0.993421733379364,0.9947762489318848,0.0,accept,unanimous_agreement
768213556,9774,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
768354744,9774,"the documented default, and the default value in the conf file are outdated (the one in config.c is ok)",0,0,0,0.967745304107666,0.993448793888092,0.987200140953064,0.0,accept,unanimous_agreement
768366668,9774,while i'm here i guess i'll fix this.,0,0,0,0.972615122795105,0.8617944717407227,0.972253143787384,0.0,accept,unanimous_agreement
1800655877,13592,we can save a variable and avoid to assign it if it's null; [code block],0,0,0,0.9878740906715392,0.9902563095092772,0.9947032332420348,0.0,accept,unanimous_agreement
1800668359,13592,can we pass the `new` argument from the `lookupstringforbitcommand()` method? this avoids `sdslen()` again and is more readable than this line.,0,0,0,0.9870710968971252,0.9949511289596558,0.9944788217544556,0.0,accept,unanimous_agreement
1800683715,13592,we shouldn't change these lines.,0,0,0,0.7734315991401672,0.946111023426056,0.8763083219528198,0.0,accept,unanimous_agreement
1800713794,13592,"this also means that server->expires, server->pubsub_channels will also allocate this memory, but nevert be used. what about using dynamic meta allocation, like dict meta?",0,0,0,0.9875794053077698,0.9897214770317078,0.9942877888679504,0.0,accept,unanimous_agreement
1800721641,13592,missing stream?,0,0,0,0.8754459619522095,0.9722350239753724,0.9691864252090454,0.0,accept,unanimous_agreement
1801321757,13592,"tried to avoid nested conditions and opt branching. a matter of style. lazily prefer to leave it as is, unless you have strong opinion about it.",0,0,0,0.7352700233459473,0.8850842118263245,0.9439674019813538,0.0,accept,unanimous_agreement
1801322898,13592,how does your suggestion avoid `sdslen()`?,0,0,0,0.9795987606048584,0.9938595294952391,0.9953389167785645,0.0,accept,unanimous_agreement
1801328222,13592,thanks.,0,1,0,0.5150366425514221,0.5804154276847839,0.5270382761955261,0.0,accept,majority_agreement
1801329615,13592,will be supported later on.,0,0,0,0.9818766117095948,0.9890674948692322,0.992470383644104,0.0,accept,unanimous_agreement
1802230449,13592,at least we don't need to assign `byte + 1` or `sdslen(o->ptr) - oldlen` to `_stringgrowsize` if _stringgrowsize is null.,0,0,0,0.9885666966438292,0.9946231842041016,0.9879404306411744,0.0,accept,unanimous_agreement
1802232252,13592,not sure it's right. [code block],0,0,0,0.8954599499702454,0.9731402397155762,0.5845243334770203,0.0,accept,unanimous_agreement
1806082127,13592,"i don't think we need to rename this name, whatever we use it for internal or external, both are metadata. and the top comments of this struct are needed to update",0,0,0,0.9857924580574036,0.981830894947052,0.986968457698822,0.0,accept,unanimous_agreement
1806149507,13592,"both `removekeysizeshist` and `addkeysizeshist` need get the length of redis objects maybe you should abstract a function like `size_t rm_valuelength(redismodulekey *key)` to get the length of value, we don't even have such a function",0,0,0,0.9852352142333984,0.994140326976776,0.9909633994102478,0.0,accept,unanimous_agreement
1806303826,13592,"[code block] may you want to use oldbin? maybe we can use underline naming method for variables more uniformly, just like most variables in redis.",0,0,0,0.9891659617424012,0.9935956597328186,0.9938399195671082,0.0,accept,unanimous_agreement
1806311922,13592,"if we don't want to get the return value after `++/--`, maybe `a++/a--` looks more natural.",0,0,0,0.9811536073684692,0.9740447998046876,0.982544481754303,0.0,accept,unanimous_agreement
1806328410,13592,"currently we don't implement it right? and include enum type `largekey_type` as above, so should we remove them? i think many users(include me) want this feature, if you implement, for the command name, how about `bigkey` instead of `largekey` since in redis-cli we define bigkey concept, and bigkey widely used as i know",0,0,0,0.9781935214996338,0.99092835187912,0.9888912439346312,0.0,accept,unanimous_agreement
1806368618,13592,"actually i don't think we need the new two structs, they should be attributes of corresponding structs. and we provide some functions to update them, maybe some wrapper functions are added in `db.c`. do i miss somethings?",0,0,0,0.9343088865280152,0.985676884651184,0.988125205039978,0.0,accept,unanimous_agreement
1809117681,13592,"i think we still need to maintain some distinction. since following my last commit we conditionally add the histogram to dict, only in kvstore case of ""keys"".",0,0,0,0.9864017367362976,0.9834451079368592,0.9848146438598632,0.0,accept,unanimous_agreement
1809118347,13592,it is too short and too specific to be bothered about. please note that stream is not included in the party.,0,-1,0,0.6665589213371277,0.67146235704422,0.9320220947265624,0.0,accept,majority_agreement
1809129337,13592,"originally that was the intention. removed. no further plans, at least for now.",0,0,0,0.9189767241477966,0.9599875211715698,0.9757434725761414,0.0,accept,unanimous_agreement
1809134726,13592,i wanted some clear declaration of this struct. one optionally attached to kvstore and another optionally per dict in kvstore. i think the logic to update them is rather simple and clear. it is being made via single function `updatekeysizeshist()`. so i didn't feel there is a need to further arrange this code. lmk if you think otherwise.,0,0,0,0.7995681166648865,0.9649853706359864,0.9636889696121216,0.0,accept,unanimous_agreement
1810731884,13592,use assertion instead?,0,0,0,0.9830514192581176,0.9920458793640136,0.9831010103225708,0.0,accept,unanimous_agreement
1810734319,13592,"this may seem odd, we just want to avoid null meta, but it is never used.",0,-1,0,0.610730767250061,0.5470425486564636,0.8920625448226929,0.0,accept,majority_agreement
1810738270,13592,forget to remove?,0,0,0,0.8802942037582397,0.9797536730766296,0.8943114876747131,0.0,accept,unanimous_agreement
1810854243,13592,ok,0,0,0,0.9667208194732666,0.8787186145782471,0.9233372807502748,0.0,accept,unanimous_agreement
1810854580,13592,please consider the comment: [code block],0,0,0,0.9875230193138124,0.9871129393577576,0.9953352808952332,0.0,accept,unanimous_agreement
1811599572,13592,it's not being used?,0,0,0,0.9208861589431764,0.9566797614097596,0.980113685131073,0.0,accept,unanimous_agreement
1818005344,13592,followed your recommendation. thanks!,1,1,1,0.961408793926239,0.9881455898284912,0.9908419847488404,1.0,accept,unanimous_agreement
1818073780,13592,maybe we shouldn't assume the size can't be larger than 2^48. [code block],0,0,0,0.9844501614570618,0.989327073097229,0.9821323156356812,0.0,accept,unanimous_agreement
1818075103,13592,"should we exit when the old bin is equal to new bin? in most case, they shouldn't change bin frequently.",0,0,0,0.9836913347244264,0.992020308971405,0.992251455783844,0.0,accept,unanimous_agreement
1818077542,13592,it's more readable to convert it to `unsigned long long` and print. another discussion here: [a link],0,0,0,0.9830635190010072,0.9698538184165956,0.9935166835784912,0.0,accept,unanimous_agreement
1818084187,13592,it will be much harder to catch such issue later on. i was even hold myself from being more aggressive with `serverassert`. wdyt?,-1,-1,0,0.5841918587684631,0.5381307601928711,0.9139873385429382,-1.0,accept,majority_agreement
1818084270,13592,most of the calls to `updatekeysizeshist` are being selectively applied following of a modification. i wouldn't be bothered to opt this scenario.,0,0,0,0.974631130695343,0.965538501739502,0.985765278339386,0.0,accept,unanimous_agreement
1818084366,13592,suggested change just the same. i need glasses :),1,1,0,0.9806953072547911,0.996351957321167,0.8776347637176514,1.0,accept,majority_agreement
1818085217,13592,"if a dict has a length of 8, it means that the following 7 inserts are nop and are increasing and decreasing at the same bin. am i missing something?",0,0,0,0.9541250467300416,0.9075700044631958,0.9743753671646118,0.0,accept,unanimous_agreement
1818085878,13592,i have no opinion with either way.,-1,-1,-1,0.8641397356987,0.9472952485084534,0.7882909774780273,-1.0,accept,unanimous_agreement
1818086577,13592,"you are not missing anything. except that once we evaluate the bin, most of the ""computation"" is beyond us. so we can either add another condition to verify if they are equal or just let the flow make ++ and -- blindly.",0,0,0,0.9786938428878784,0.975214183330536,0.9876440167427064,0.0,accept,unanimous_agreement
1818086790,13592,"note also that i set max_keysizes_bins to be 48. i could have set it 64 and close my eyes. but i wanted that if we have a calculation issue, we better tackle it early on.",0,0,0,0.9605799317359924,0.9645516276359558,0.9889934659004213,0.0,accept,unanimous_agreement
1818097019,13592,i thought you just wanted to save some memory.,0,0,0,0.9605716466903688,0.9455592036247252,0.9124841094017028,0.0,accept,unanimous_agreement
1818097507,13592,also :),1,1,0,0.8495262861251831,0.9729107618331908,0.9868309497833252,1.0,accept,majority_agreement
1818099671,13592,"well, since there isn't any regression, we can leave it as it is.",0,0,0,0.985032320022583,0.9909088015556335,0.9762962460517884,0.0,accept,unanimous_agreement
1818261974,13592,use `wait_for_ofs_sync` to wait for master/slave synchronization to complete?,0,0,0,0.9860250353813172,0.994596540927887,0.9953731894493104,0.0,accept,unanimous_agreement
1818921579,13592,"either way, it makes busy wait till condition fullfils. i wouldn't bother to change (as it is already written and working..)",0,-1,-1,0.9412618279457092,0.815068781375885,0.5401009917259216,-1.0,accept,majority_agreement
1820199601,13592,"now we have three same code, so i also prefer to add a new function to get the length of key. although stream is not implemented, but it will be skipped in updatekeysizeshist(), which i think it's fine.",0,0,0,0.9689266085624696,0.965282380580902,0.8864663243293762,0.0,accept,unanimous_agreement
1820253353,13592,the code looks better than i expected. now removekeysizeshist() and addkeysizeshist() become a trivial single line call to updatekeysizeshist + length. so we can discard those functions as well!,0,1,1,0.7720916867256165,0.7440128326416016,0.9115739464759828,1.0,accept,majority_agreement
1820302287,13592,"hi i still think we don't need to create a new struct and add here and `kvstoredictmetadata` , as we know, `key_count`, `overhead_hashtable_lut ` also are just statistics, extra metadata makes it more complex. ping you bring the `kvstore` struct, wdyt?",0,0,0,0.9786213040351868,0.9240819215774536,0.98387211561203,0.0,accept,unanimous_agreement
1820362676,13592,i didn't read the pr - can't we use the dict metadata of each dict inside the kvstore? or is that unnecessary and will take too much memory?,0,0,0,0.6981569528579712,0.946557343006134,0.9890243411064148,0.0,accept,unanimous_agreement
1820418433,13592,the histogram is maintained at two levels. one per kvstore and one per slot. this gives future capability in clustering mode to quickly update kvstore/db level histogram when deleting a slot or have more granular report. whatever we decide in this thread. please let's have implementation at a distinct pr. we need to cherry-pick this commit asap into earlier version.,0,0,0,0.983515441417694,0.9861161708831788,0.9818409085273744,0.0,accept,unanimous_agreement
642047000,9003,i would rather use a separate `config set` line which will carry a comment explaining why we disable it.,0,0,0,0.978423535823822,0.9921918511390686,0.9855424165725708,0.0,accept,unanimous_agreement
642049894,9003,"what this check does (maybe a more explicit comment is needed) is trying to access the true size of the replica buffers (instead of counting `mem_clients_slaves`). for that, takes the total used memory delta and deducts the client buffers (`mem_clients_normal`) from the delta. i think we should do the same for the slave's query buffer rather than assume 40k. i.e. find the replica in the client list, and extract the old and new size of the query buffer. alternatively, if that buffer isn't expected to change, or is insignificant for the test, we can just forget about it. the purpose of the `delta_max` variable (again maybe a better comment is needed) is to measure the accuracy of the ability of redis to calculate the size of the replica buffers (by matching the size redis measured for them, to the effect we see they have on the total allocated memory). the threshold of `$cmd_count / 2` is that low because it says that even if there was off by as little as half a byte per command, we could have detect that. i.e. in the past we didn't count the internal fragmentation (some 30%), which is why we added that test. bottom line, if we deduct the query buffer memory from the measurement (both old and new), there's no need to mess with the threshold.",0,0,0,0.9857607483863832,0.9933244585990906,0.987435221672058,0.0,accept,unanimous_agreement
642051374,9003,"i'd like to find a way to avoid long sleeps. if we keep adding long sleeps to the tests, eventually they'll take very long. instead you should make some loop to wait for your desired effect (and maybe a comment explaining what you do). what exactly are we waiting for here? maybe we can skip this part of the test?",0,0,0,0.914445161819458,0.9747392535209656,0.9739897847175598,0.0,accept,unanimous_agreement
642051479,9003,"this loop will normally run for 2 seconds, right? 8-(",-1,-1,-1,0.9446909427642822,0.9374760389328004,0.9955560564994812,-1.0,accept,unanimous_agreement
642052808,9003,should use macro instead of literal constant?,0,0,0,0.9861333966255188,0.9935353994369508,0.9892922639846802,0.0,accept,unanimous_agreement
642053145,9003,"since it can only be used here, i'm not sure if i need to add a macro for it.",0,0,0,0.9204007387161256,0.9499615430831908,0.9682308435440063,0.0,accept,unanimous_agreement
642054663,9003,"not really, due to another bug, which was fixed in #5013 calculating [code block] is before [code block], and in the absence of message stacking, it will always be 0. [a link]",0,0,0,0.9844884872436525,0.9932464361190796,0.9752864837646484,0.0,accept,unanimous_agreement
642054962,9003,good. forget it exists.,0,0,1,0.5867924094200134,0.5757499933242798,0.9568396210670472,0.0,accept,majority_agreement
642064955,9003,"let's put these tests inside a `$::accurate` check. this way when we merge #5013, these new tests will not slow down the ci runs.",0,0,0,0.9832218289375304,0.9935937523841858,0.9940235018730164,0.0,accept,unanimous_agreement
642065418,9003,ok.,0,0,0,0.9735831022262572,0.9740158319473268,0.980760931968689,0.0,accept,unanimous_agreement
642065924,9003,"does this test also add [code block]? this is a test for [code block] being resized abnormally, which will prevent the bug from occurring again in the future.",0,0,0,0.9791181087493896,0.992169201374054,0.9933428168296814,0.0,accept,unanimous_agreement
642069076,9003,"i think so.. maybe change the text in the doc help for `--accurate` to mention it includes ""slow time driven tests"" too. this way we'll spot a regression, it's just that we'll spot it on the next day, and not when the pr that introduces it will be merged. please also add some comments to both tests as to what you're waiting before each of these sleeps, and why. and add some comment next to the `::accurate` check to explain why it's there.",0,0,0,0.9307231903076172,0.990183651447296,0.9665197134017944,0.0,accept,unanimous_agreement
642085003,9003,i think that because this constant is measured against other constants it may be better to declare all at the same place. i.e. it would make no sense to make it lower than 2*proto_iobuf_len. e.g. even an unforeseen side effect of #5013 caused this line to misbehave.,0,0,0,0.7799568772315979,0.989414930343628,0.9795202016830444,0.0,accept,unanimous_agreement
642841847,9003,"i think you better convert the block that extracts the size of the query buffer to be a function so that you can run it twice. we extract the memory usage details before and after the kill, and in this line we calculate the difference. and we deduct the ""repl"" from both so that we only see the memory usage delta without the ""repl"". but the thing is (what you discovered) is that we in addition to deducting the ""repl"" (i.e. `mem_not_counted_for_evict`), we also need to deduct the slave query buffer (due to the acks inside it that are not in the control of that test). so i think we need to deduct that size from both measurements (`killed_used_no_repl`, `used_no_repl`) rather than change the line you changed here. and also add a comment as to why we're deducting it (due to the acks).",0,0,0,0.9799916744232178,0.9909220337867736,0.9805933237075806,0.0,accept,unanimous_agreement
642843251,9003,"i think this may be unreliable (won't work on slow vms). we can change that whole block to a wait_for_condition, and put the entire test in an `if`",0,0,0,0.9462297558784484,0.9509665369987488,0.9703518152236938,0.0,accept,unanimous_agreement
642844962,9003,"i know is cooking some improvements to the `--tags` system, and mentioned that maybe a better approach would be to use the `slow` tag. the disadvantage in my eyes is that it'll be opt-out rather than opt-in. but i guess that's already the case with other slow test, like the ones in sort.tcl, expire.tcl etc (that are already tagged). p.s. if we keep that `if` it should be outside the `test` declaration (not inside it)",0,0,0,0.9316127300262452,0.977946937084198,0.9747254252433776,0.0,accept,unanimous_agreement
643004877,9003,"i guess ```-tag`` is used to execute a certain series of tags, which should not be applicable to slow tests.",0,0,0,0.9897097945213318,0.986907720565796,0.9793959856033324,0.0,accept,unanimous_agreement
643005686,9003,done it. use a new way to verify slave query buffer.,0,0,0,0.9852631092071532,0.9840408563613892,0.9883070588111876,0.0,accept,unanimous_agreement
643587247,9003,thank you so much!,1,1,1,0.9832773208618164,0.9741079807281494,0.9891602396965028,1.0,accept,unanimous_agreement
644058055,9003,"sorry for dragging this further. i feel a bit uncomfortable. before #7875, this code thought a newly born client's query buffer is small (32k), and didn't consider releasing it. #7875 didn't actually increase memory consumption (used_memory or rss, since we use sds_noinit), but it caused this code to release the buffer quickly. in this pr, we wanna introduce a change that will retain bigger allocation and avoid releasing them. i.e. in redis 6.0 we should have released an allocation as soon if it's bigger than 32k, and now we'll avoid releasing it unless it's bigger than 64k. maybe instead, we need to change the code that allocates the query buffer to avoid the greediness of sdsmakeroomfor? -steinberg wdyt?",-1,-1,-1,0.9890901446342468,0.9893653392791748,0.9911462664604188,-1.0,accept,unanimous_agreement
644069170,9003,"i'm still on the fence back and forth about this. waiting to see how #9033 evolves in order to avoid repeated changes. if you can, please post your thoughts. i.e. i'd like to find a way to make these time-driven tests an opt-in. maybe tag them as `slow`, but also have the `-slow` skip tag defined by default when someone just runs the `./runtest`, and implicitly removed when someone adds `--accurate`.",0,0,0,0.9307788610458374,0.9310608506202698,0.6170786619186401,0.0,accept,unanimous_agreement
644095576,9003,"i am waiting for #9033 i see that it supports ignore specified tags, which is exactly what is needed. but i can't find the comment now.",0,0,0,0.9251641631126404,0.9714866876602172,0.9648246169090272,0.0,accept,unanimous_agreement
644103928,9003,"this should be the most appropriate, i wanted to do this at first, but sds cannot do this directly. it needs to be something like the following, but i always find it a bit odd [code block]",0,0,0,0.9114595651626588,0.9285280108451844,0.7695174217224121,0.0,accept,unanimous_agreement
644110984,9003,take back the above comment. too sleepy. i can't think of a way to allocate a fixed 32k size sds.,-1,-1,-1,0.9709410071372986,0.9801592826843262,0.8352845311164856,-1.0,accept,unanimous_agreement
644529067,9003,"i attempted to add a non-greedy version of sdsmakeroomfor in the past, it didn't eventually make it in since i found another solution to the problem i was dealing with. but maybe it's time to do that now. i.e. to be used for the initial size, not for the later growing.",0,0,0,0.9234254360198976,0.9763271808624268,0.9507099390029908,0.0,accept,unanimous_agreement
644553433,9003,curious to know how you achieved this.,0,-1,0,0.8294050097465515,0.9672613739967346,0.9241706132888794,0.0,accept,majority_agreement
644564996,9003,"maybe i'm missing something... iirc i renamed sdsmakeroomfor to _sdsmakeroomfor and made it take an `exact` argument. then i wrapped it with two functions sdsmakeroomfor that has the original signature, and sdsmakeroomforexact (which has the same interface, but passes 1 to the `exact` argument. then the _sdsmakeroomfor function avoid adding the extra 1mb or *2 when the exact flag is on.",0,0,0,0.9755166172981262,0.9819806218147278,0.8833290934562683,0.0,accept,unanimous_agreement
644565924,9003,"i wouldn't get the exact amount i asked for since the internal fragmentation is added (up to 30%), but at least i turn off the 200% extra that the greediness mechanism adds..",0,0,0,0.631353497505188,0.8926952481269836,0.9683069586753844,0.0,accept,unanimous_agreement
644575078,9003,"but there is a problem, like [code block], although i want to allocate 32k, but because the hdr of sds is 1 byte more, so the final memory will be 40k, want to allocate 32k need [code block].",0,0,0,0.9655646085739136,0.9616340398788452,0.9106513857841492,0.0,accept,unanimous_agreement
644578386,9003,you mean ignore the extra memory? [code block],0,0,0,0.9848459959030152,0.9925394654273988,0.989184021949768,0.0,accept,unanimous_agreement
644585058,9003,"no, i just mean the greediness of: [code block] note that we actually really intended to allocate 16k (`proto_iobuf_len`), but because of the greediness we attempt to allocate 32k, which then grows to 40k due to sds header and internal frag. instead, if we'll really ask to allocate 16k, it'll grow to some 20k with sds header and internal frag. this will let us bring back proto_resize_threshold to 32k as it was in the past.",0,0,0,0.875690758228302,0.9789842963218688,0.9802650213241576,0.0,accept,unanimous_agreement
644588009,9003,"ohh, this is indeed a good idea, querybuf will be larger than 32k in the second expansion, let me make the change.",1,1,1,0.8594205379486084,0.5212973952293396,0.9312404990196228,1.0,accept,unanimous_agreement
645321301,9003,"[a link] i did not modify this expansion, i think since it has been expanded to proto_mbulk_big_arg(32k), then let it be bigger to avoid realloc next time.",0,0,0,0.9885005950927734,0.9902195334434508,0.9945383667945862,0.0,accept,unanimous_agreement
646102557,9003,"is that technically right? i don't think we'll always add `addlen * 2`. addlen can be 10mb, and we'll only add 1mb. i suppose the comment can be vague, just saying we preallocate for future growth and avoid repeated re-allocations. [code block]",0,0,0,0.984811544418335,0.9834148287773132,0.9915440082550048,0.0,accept,unanimous_agreement
646102804,9003,"i'm having second thoughts about the ""exact"" term i specified. it was good to emphasize the design, but i'd like to suggest another term. [code block]",0,0,-1,0.9024583697319032,0.8299158811569214,0.5858618021011353,0.0,accept,majority_agreement
646102885,9003,let's change `exact` to `greedy` (negating it),0,0,0,0.984687864780426,0.99055415391922,0.9897902607917786,0.0,accept,unanimous_agreement
646103067,9003,"i still think we want a separate / explicit `proto_resize_threshold` define in server.h this mechanism has nothing to do with the `big_arg` mechanism (that's used to avoid memcpy). i just said i'd rather avoid increasing it from 32k to 64k, but still think the separate constant is good.",0,0,0,0.8447812795639038,0.8267712593078613,0.9563988447189332,0.0,accept,unanimous_agreement
646103828,9003,"i discussed this in length with -steinberg last week. we think that in some cases we still want to use the greedy version here. there are some 3 states here: 1. we're allocating the query buffer for the first time, in order to read a small argument into it. in this case we wanna use the non-greedy mode. 2. we're accumulating again and again to the query buffer, in this case we wanna use the greedy mode. 3. we detected a big_arg, and we're gonna allocate a dedicated query buffer for it (we should set a boolean flag in the `if` above), in which case we wanna use the non-greedy mode.",0,0,0,0.9442800283432008,0.9833938479423524,0.8986944556236267,0.0,accept,unanimous_agreement
646106789,9003,"i think i spoke about that in this [a link]. when we detect big_arg, we're gonna copy (re-purpose) that sds to the argv array, and create a new query buffer. we have no use for the extra space in there. i think that line should be modified to the non-greedy. am i missing anything?",0,0,0,0.963773787021637,0.9730595350265504,0.9848188161849976,0.0,accept,unanimous_agreement
646213277,9003,"thanks , it's hard to come up with a good name and comment.",-1,1,1,0.5652430653572083,0.969510018825531,0.741860568523407,1.0,accept,majority_agreement
647391090,9003,"here's where i'm stumped, i can't use [code block] to determine the first expansion, because the [code block] type is [code block] when [code block], resulting in sdsalloc is 4. or change the [code block] initialization code to [code block], this way is not readable.",0,0,-1,0.864517092704773,0.7438685894012451,0.6488292217254639,0.0,accept,majority_agreement
647427231,9003,"also note that in case `greedy` is 1 it means that we hope to read as much as possible from the socket. in that case, i think, we should pass `sdsavail` and not `readlen` to the socket read: [code block]",0,0,0,0.9868969321250916,0.992138683795929,0.9919533133506776,0.0,accept,unanimous_agreement
647438261,9003,"-steinberg i'm not sure greed is about reading as much data as possible, the query buffer has already broken 20k (under jemalloc) and since it's already over 20k, let it be greedy. wdyt?",0,0,0,0.8857514262199402,0.8131603598594666,0.6783937215805054,0.0,accept,unanimous_agreement
649011334,9003,"i agree with yoav. we need to realize that we have two different things that we can be greedy or non-greedy about: 1. memory allocations to avoid repeated reallocs of gradual, incremental growth. 2. read system calls. we normally wanna ask to read for as much as we can (all the memory we allocated), so that in total we'll have less system calls (each one will just return what the os already has, it's non-blocking anyway). the case were we don't wanna be greedy (in **both** malloc and read aspects) is the case of the a big_arg, which we later wanna copy (re-purpose) as is into argv, instead of doing a memcpy. another place were we don't wanna be greedy, is the initial allocation of the default query buffer, we want to start the greediness only above a certain size, in order to avoid the conflict with the resizing cron.",0,0,0,0.8410192728042603,0.896085262298584,0.9232549071311952,0.0,accept,unanimous_agreement
649648510,9003,"i was thinking that if use sdsavalid to read, a connection expanded to 64k would handle a lot more commands than an unexpanded one, but the connection is not fair.",0,0,-1,0.7399389743804932,0.6112122535705566,0.8365173935890198,0.0,accept,majority_agreement
650478801,9003,"yeah, we're not trying to be fair anyway.. so we rather issue less system calls and overall process more commands per second.",-1,0,0,0.8983110189437866,0.5594514608383179,0.5769094228744507,0.0,accept,majority_agreement
651393418,9003,"-steinberg it's dangerous to use [code block] to read. 32bit 1) expand querybuf to over 2.1g. 2) returns of [code block] will likely overflow. the return value of [code block] should be [code block], not the current [code block].",-1,0,0,0.7768278121948242,0.9574280977249146,0.6604034304618835,0.0,accept,majority_agreement
651494735,9003,i can't see why this change has more of a potential of causing an issue on 32bit than the original code. in both cases we keep expanding the query buff by calling `sdsmakeroomfor` so it might eventually overflow on a 32bit machine. this is a bug in any case. we should change fix connread to return `ssize_t`.,0,0,0,0.915921688079834,0.935931384563446,0.956102728843689,0.0,accept,unanimous_agreement
651506243,9003,"-steinberg yes, sdsmakeroomfor will overflow and trigger the assertion in case of constant expansion. but before it overflows, [code block] will cause truncation. in any case, fix [code block] to return ssize_t.",0,0,0,0.9886306524276732,0.9901241660118104,0.9517245888710022,0.0,accept,unanimous_agreement
651550467,9003,"`connread` can be fixed, but note that this is a theoretical issue that can never really happen. this method reads from a socket or a pipe, it reads what's available in the os buffers, it'll never be more than a few megs. i think your last push should be reverted, i think readlen is better be size_t, and i do think we wanna use sdsavail",0,0,0,0.9755287766456604,0.987692892551422,0.9833872318267822,0.0,accept,unanimous_agreement
651595976,9003,ssl_write takes an int.. i suppose we better clamp the input rather than truncate it (possibly leading to negative value),0,0,0,0.9829834699630736,0.967409372329712,0.9891684055328368,0.0,accept,unanimous_agreement
651600867,9003,"then i'll revert this change first, as it doesn't cause a bug.",0,0,0,0.9609025120735168,0.9826657772064208,0.9891955852508544,0.0,accept,unanimous_agreement
651612596,9003,i think [code block] and [code block] should be upgraded to [code block] and [code block],0,0,0,0.9835795760154724,0.9933064579963684,0.9837819337844848,0.0,accept,unanimous_agreement
651624373,9003,"i'm arguing that we should lave the entire set of `conn` changes for another pr. this pr is already too complicated to follow, and as i stated earlier, connread will never actually return more than a few megabytes (that are already present in the os socket buffers), so there's no real bug in the new code we introduce in networking.c",0,0,0,0.8678194284439087,0.9422867894172668,0.9808985590934752,0.0,accept,unanimous_agreement
651654695,9003,"sorry for the misunderstanding, done it.",-1,-1,-1,0.9840131998062134,0.9906546473503112,0.991837203502655,-1.0,accept,unanimous_agreement
1137873870,11907,"we have a separate command for pattern subscription (psubscribe vs subscribe), should we be consistent and add a separate command (psubscribers vs subscribers) instead of adding nested parameters?",0,0,0,0.989498496055603,0.9944186210632324,0.9906530380249025,0.0,accept,unanimous_agreement
1137876459,11907,"should we do pattern matching on patterns or should we only search for an exact match? e.g. if there is a subscriber for `foo.news.*`, but the search is for `foo.*` should it yield results?",0,0,0,0.9862610697746276,0.99415522813797,0.992197573184967,0.0,accept,unanimous_agreement
1152265842,11907,"exact match over pattern is done in acl pubsub validation as well, so thought of flowing the same behavior here. doing a pattern matching, would add some cost. we could add another option to the api i.e. `match [exact|glob]` to define the behavior and make it available for all the subscription type (global|shard|pattern). wdyt ?",0,0,0,0.9863118529319764,0.9933638572692872,0.9928600192070008,0.0,accept,unanimous_agreement
1152266551,11907,"initially i thought about the same. with this option, we don't need to add subcommand for each subscription type (more boilerplate code). also, by having an option in the api we could also introduce more options in the future if reqd. would like to stick with this option unless folks have a strong pushback.",0,0,0,0.9663400053977966,0.987370491027832,0.9538286328315736,0.0,accept,unanimous_agreement
1159330944,11907,"i'm okay either way, just wanted to call out that it's slightly inconsistent with existing commands.",0,0,0,0.940476655960083,0.9116550087928772,0.6604166030883789,0.0,accept,unanimous_agreement
1159333890,11907,"i think it's fine if we keep it exact, just need to call out it explicitly in the documentation.",0,0,0,0.9757103323936462,0.9403533339500428,0.9532675743103028,0.0,accept,unanimous_agreement
1160147831,11907,"i don't know what this means. `o(n) for the subscribers subcommand, where n is the number of clients subscribed to the questions channels or patterns.` ?",0,0,0,0.9281730651855468,0.9771684408187866,0.9488566517829896,0.0,accept,unanimous_agreement
1160148901,11907,might be better as an enum value.,0,0,0,0.9801639914512634,0.9927027225494384,0.9851228594779968,0.0,accept,unanimous_agreement
1160150015,11907,[code block] i assume we aren't case sensitive here.,0,0,0,0.982182800769806,0.9806293249130248,0.9926708936691284,0.0,accept,unanimous_agreement
1160150265,11907,this pr should stand on its own without modules.,0,0,0,0.9838320016860962,0.989679992198944,0.9893571734428406,0.0,accept,unanimous_agreement
1160979566,11907,"thoughts on this just being client info which what the acl log returns? at the very least i think we should also add ip, which is often more useful the name.",0,0,0,0.977075457572937,0.9711914658546448,0.972727596759796,0.0,accept,unanimous_agreement
1160983986,11907,this response is pretty deep. i'm going to propose the following layout: [code block],0,0,0,0.8365378379821777,0.5645952224731445,0.7316802144050598,0.0,accept,unanimous_agreement
1160987090,11907,"i think this should be array length 0, not null.",0,0,0,0.986019492149353,0.9764012694358826,0.9862372875213624,0.0,accept,unanimous_agreement
1160988038,11907,"i would return the same map size consistently, name can be null.",0,0,0,0.986825168132782,0.9911549091339112,0.9906066656112672,0.0,accept,unanimous_agreement
1171641362,11907,"acl log has a lot of details about the client, some of them are also not that valuable in pubsub context. client could always fall back to `client list id ` to retrieve all the details. wdyt ?",0,0,0,0.9839752912521362,0.9881219863891602,0.9911675453186036,0.0,accept,unanimous_agreement
1174235033,11907,"discussed with madelyn offline, `addr` is used generally to figure out/debug the traffic source. adding it.",0,0,0,0.9889968633651732,0.9816870093345642,0.9937049746513368,0.0,accept,unanimous_agreement
1185458099,11907,"patterns are also global. the naming of ""channel"", ""pattern"", ""shard-channel"" make the most sense to me.",0,0,0,0.973879873752594,0.991633415222168,0.9890795350074768,0.0,accept,unanimous_agreement
1185617605,11907,"oran was also suggestion in another pr `global` word is something which isn't coined anywhere. i find the naming above fine, will update.",0,0,0,0.968021273612976,0.9820974469184875,0.9521602392196656,0.0,accept,unanimous_agreement
1186471569,11907,which other pr uses global?,0,0,0,0.9810048937797546,0.9895225167274476,0.9946000576019288,0.0,accept,unanimous_agreement
1189465287,11907,use 4 spaces instead of tab?,0,0,0,0.98597252368927,0.9932562112808228,0.9921954870224,0.0,accept,unanimous_agreement
1191358961,11907,let's just keep this with the argument parsing code. this isn't going to be re-used.,0,0,0,0.9343040585517884,0.9884344339370728,0.9879488945007324,0.0,accept,unanimous_agreement
1191360728,11907,let's just return an empty string so the return type is consistent. otherwise come clients will need to do null/unwrapping of the response.,0,0,0,0.9878111481666564,0.990009307861328,0.9899847507476808,0.0,accept,unanimous_agreement
1191364013,11907,"we should prevent duplicate match and count arguments. count is less important, but someone might think `match foo match bar` is valid syntax, and it will be accepted and only return bar.",0,0,0,0.9877705574035645,0.9912477731704712,0.9920873045921326,0.0,accept,unanimous_agreement
1191365305,11907,[code block] is the more canonical form.,0,0,0,0.9853654503822328,0.9889004230499268,0.99095356464386,0.0,accept,unanimous_agreement
1191404652,11907,"this still seems clunky and i'm trying to think through how modules well work. having a separate section entirely for modules is weird. i was also thinking about how module apis don't really map to the current id + addr format. so maybe instead of having a separate section for modules like we originally discussed, we just add different fields for modules in the client info section? the result would be changing this to a map between channel name and list of subscribed clients.",-1,-1,-1,0.9851908087730408,0.9791985750198364,0.985468089580536,-1.0,accept,unanimous_agreement
1191405435,11907,you could just use the existence of pat as an indication to use_pattern. then you can default it properly to null.,0,0,0,0.9888767600059508,0.9923503994941713,0.993372678756714,0.0,accept,unanimous_agreement
1191413143,11907,"[code block] i would expect count to be number of subscriptions returned, not number of channels returned. i am okay returning more than 1000 subscriptions in order to return all the subscriptions from a client. if each channel has 10k clients, that is 10m responses, which seems like a high default.",0,0,0,0.9478597640991212,0.9851691722869872,0.9869815707206726,0.0,accept,unanimous_agreement
1191415591,11907,"a minor preference: i generally dislike parse functions and parsed argument structs unless they are re-used between multiple calls. i would rather the top level redis command do the parsing, and then call a subcommand with the arguments.",-1,0,0,0.9041966795921326,0.949682891368866,0.7889109253883362,0.0,accept,majority_agreement
1191482492,11907,nice suggestion. this should keep the results more bounded but we could breach the count in some cases :thumbs_up:,1,1,1,0.9373977780342102,0.9894282221794128,0.9962272644042968,1.0,accept,unanimous_agreement
1191485020,11907,"the size of the parsing code is around 40 lines. so, keeping it separate still keeps the top level redis command function compact. i'm moving the invocation of parsing the arguments though to the top level redis command.",0,0,0,0.9863538146018982,0.9783571362495422,0.9934635162353516,0.0,accept,unanimous_agreement
1191720874,11907,had a discussion offline. would revisit if the module subscription information would be requirement by clients. for now decided to remove a level of nesting to keep things simple.,0,0,0,0.9789945483207704,0.9808765053749084,0.9842150807380676,0.0,accept,unanimous_agreement
1191792631,11907,"sure. again, not a strong preference. i find the extra abstraction of having an args struct not worth trying to keep it to 40 lines, but i'm okay with it.",0,0,0,0.8441317081451416,0.5967503786087036,0.7975823283195496,0.0,accept,unanimous_agreement
1200372259,11907,a little bit odd to pass the argument by value and not reference.,-1,-1,-1,0.7815887331962585,0.952187716960907,0.8686264753341675,-1.0,accept,unanimous_agreement
1200373642,11907,"isn't it odd that we stop the loop past the count limit? if we have one channel with a ton of clients (of a very low limit), we'll pass the limit by a lot.",0,-1,0,0.897713840007782,0.5033372640609741,0.6883980631828308,0.0,accept,majority_agreement
1201104587,11907,"the alternative is we don't give complete client results, which seems worse from a debugging api. i wouldn't expect a single client to be listening to millions of connections, but maybe there are use cases i am not aware of?",0,0,0,0.5460909008979797,0.5457618236541748,0.8215175867080688,0.0,accept,unanimous_agreement
1204818973,11907,changed to pass by reference.,0,0,0,0.9845119714736938,0.9898449182510376,0.9940624833106996,0.0,accept,unanimous_agreement
1391817604,12742,"i don't really want to lose the history of the cluster code with this refactor, and i realized we're losing it mostly because we want to call the ""api"" cluster.c, which i don't care that much about. instead maybe we we leave this file cluster.c, put the api in `cluster_api.c`, and then name flotilla `flotilla.c`? (i still don't want to call it flotilla but we can punt that)",-1,0,0,0.8115986585617065,0.8327768445014954,0.5192857384681702,0.0,accept,majority_agreement
1391819933,12742,"module thread! i still am questioning why we aren't using modules to load this information. we have introduced the concept of first party extensions/modules whatever with tls, and it has the ability to add commands, so why not continue to use that logic here. fyi. i would rather us think about pluggability as a first class citizen of the future of redis.",-1,-1,-1,0.8898922801017761,0.5923646092414856,0.5732623934745789,-1.0,accept,unanimous_agreement
1391820196,12742,"by convention redis almost always uses /*, even for single line stuff.",0,0,0,0.981631636619568,0.9794799089431764,0.9867058396339417,0.0,accept,unanimous_agreement
1391859681,12742,not using tabs,0,0,0,0.817506730556488,0.9484947323799132,0.9829038977622986,0.0,accept,unanimous_agreement
1391860347,12742,"i believe the .phony is a more commonly used paradigm, is there a reason you are doing it this way?",0,0,0,0.6862009763717651,0.9805155992507936,0.9920684099197388,0.0,accept,unanimous_agreement
1391861802,12742,i think we normally use _ for naming of the .h and .c files.,0,0,0,0.9890522360801696,0.9896775484085084,0.98920738697052,0.0,accept,unanimous_agreement
1392184422,12742,"if we do file renames in a separate commit from mass code rename, and copy-paste code moves, it shouldn't matter for git (it'll be able to understand where the code went to). please ack you did that. on the other hand, if the same commit splits one file into 3, then git won't be able to realize anything about the rename (and it doesn't matter which one will be named cluster.c)",0,0,1,0.9328174591064452,0.9514484405517578,0.8476682305335999,0.0,accept,majority_agreement
1392191501,12742,maybe this should be a new sub-command in cluster? like we have with sentinel debug?,0,0,0,0.9860187768936156,0.99448424577713,0.9892802834510804,0.0,accept,unanimous_agreement
1392192406,12742,note that debug help still refers to clusterlink kill,0,0,0,0.9886885285377502,0.9845128655433656,0.9936269521713256,0.0,accept,unanimous_agreement
1392194388,12742,should this be part of the repo? or a gitignore file?,0,0,0,0.9876995086669922,0.9949321150779724,0.9935949444770812,0.0,accept,unanimous_agreement
1392199375,12742,"we already have a similar (different) mechanism for sentinel, see the sentinel and only_sentinel command flags. i'd rather not introduce a new ""system"" (`feature_flags`) for that. that is, if we don't take the first-party module approach discussed in the other comment.",0,0,0,0.9869065284729004,0.9937111139297484,0.9913963675498962,0.0,accept,unanimous_agreement
1392391021,12742,"i agree it's a good idea, but let's take it in a follow up pr. the purpose of this one is a for a quick shifting of code from one place to the other, with minimal or actually no change of behavior. we need it to be merged quickly so that we don't accumulate conflicts, and we need it to be done carefully so that we keep as much history as possible. logical changes can be applied later, just let's try to avoid renaming or moving the same thing twice.",0,1,1,0.6619876623153687,0.7917881011962891,0.8435893654823303,1.0,accept,majority_agreement
1392397934,12742,"we can also use `ifdefs` like we did for cli_commands.c, maybe it plays more naturally with the current approach building one cluster or the other. but either way, i'd like to avoid different content of commands.def depending on the build flags.",0,0,0,0.9837141633033752,0.9924291968345642,0.9902149438858032,0.0,accept,unanimous_agreement
1392468043,12742,oran sez: remove this and put it into a different pr,0,0,0,0.9836035966873168,0.9799848794937134,0.9911352396011353,0.0,accept,unanimous_agreement
1392504504,12742,"i changed it so that first cluster.c is first renamed to cluster-legacy.c in the first commit. now ""git blame"" on cluster-legacy.c shows full history.",0,0,0,0.5597095489501953,0.9902530908584596,0.9924364686012268,0.0,accept,unanimous_agreement
1392506970,12742,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
1392520659,12742,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
1392602896,12742,".phony is for when you need a target that will never exist and forces other targets to run since they are dependencies to the .phony. this is different. here i have a generated file as the target but even if it exists, i want the target to run. if i call it .phony it creates a loop in the dependencies (i just tried it again).",-1,0,0,0.5535466074943542,0.9555325508117676,0.9591166973114014,0.0,accept,majority_agreement
1392606513,12742,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
1392732644,12742,will switch to a sentinel style solution tomorrow,0,0,0,0.9773557186126708,0.9930105805397034,0.9928516745567322,0.0,accept,unanimous_agreement
1392920173,12742,"if it's just a quick shift, let's remove all the code generation stuff and leave the commands as is. none of this is strictly needed for the shifting. we can restructure the commands when we have the extensions sorted.",0,0,0,0.9874194264411926,0.9925796389579772,0.991141438484192,0.0,accept,unanimous_agreement
1392925920,12742,nit: spacing is weird here and not aligned. [code block],-1,-1,-1,0.9791185259819032,0.9870991110801696,0.9932538866996764,-1.0,accept,unanimous_agreement
1392927528,12742,nit: weird indentation here [code block],-1,-1,-1,0.9827641844749452,0.9807923436164856,0.9878724813461304,-1.0,accept,unanimous_agreement
1392942755,12742,let's document the return code if this is changing.,0,0,0,0.987821877002716,0.9814420342445374,0.9942418932914734,0.0,accept,unanimous_agreement
1392956568,12742,"there are a lot of cases where you are changing spacing (and i'm going to stop commenting on it), which will also remove git history. i don't want to go through them all, but the general practice has been don't touch lines to make white spacing changes)",0,-1,0,0.802639901638031,0.5315626859664917,0.982102870941162,0.0,accept,majority_agreement
1393008960,12742,"this isn't really ""confirmed"" reachable. this is just nodes that have been accepted into the cluster, like if a node is gossiped about this will return true even though we may never be able to reach it. so we might want to invert this to be like: [code block] and just return the check? like in flotilla this will never return, presumably, since nodes will never be added if they aren't confirmed.",0,0,0,0.9590428471565248,0.9822847843170166,0.9847687482833862,0.0,accept,unanimous_agreement
1393010070,12742,"yes, that would be easiest!",1,1,0,0.6439037322998047,0.6173323392868042,0.7715688347816467,1.0,accept,majority_agreement
1393013227,12742,"in the legacy cluster world, a node that is not a master might not necessarily be a slave, we might just not know. which is why we have explicit checks for both. so i think this does need to check the salve flag.",0,0,0,0.9833462238311768,0.9755638241767884,0.9854745864868164,0.0,accept,unanimous_agreement
1393977514,12742,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1393986208,12742,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
1393993574,12742,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
1393994009,12742,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
1393999133,12742,fixed,0,0,0,0.975196123123169,0.9281549453735352,0.920660674571991,0.0,accept,unanimous_agreement
1394046073,12742,added documentation in cluster.h,0,0,0,0.9625172019004822,0.990757942199707,0.983086109161377,0.0,accept,unanimous_agreement
1394059624,12742,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1394067215,12742,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1395690910,12742,fixed em all!,0,1,1,0.500731348991394,0.8618036508560181,0.9408548474311828,1.0,accept,majority_agreement
1395691316,12742,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1395717301,12742,"if we want to move this to a different command i propose that we do that in a separate pr, ok? i do not understand your second comment.",-1,0,0,0.6859089732170105,0.9682877659797668,0.9417828917503356,0.0,accept,majority_agreement
1395986173,12742,"yes. let's keep the interface changes for later. the thing is that debug.c has the list if sub-commands in debug help. but each implementation of cluster.c implements it separately, and can support a different set of sub-commands. maybe we need to split the code in a way that the c files can only implement one specific sub-command. or move the portion of the help message to a separate cluster function too",0,0,0,0.9779725074768066,0.9855393171310424,0.9822090268135072,0.0,accept,unanimous_agreement
1396059479,12742,"omg, i forgot to merge that. will fix in a way similar to how i handled cluster command help. that was in the original pr and i forgot",0,-1,0,0.8677614331245422,0.8105955123901367,0.9052556753158568,0.0,accept,majority_agreement
1396819053,12742,"i thought about this some more and decided that moving forward, especially for flotilla, it makes sense to have a cluster subcommand ""debug"" that can do all kinds of stuff (we have all kinds of plans already). as such, i took a minimalist approach to this function and simply put an #ifndef around clusterlink kill. , ok if i mark this resolved?",0,0,0,0.9234046936035156,0.8198851346969604,0.9587220549583436,0.0,accept,unanimous_agreement
1397095740,12742,"it's still odd that the sub-command list is documented in one file, but the string matching for that sub-command is in another. imho we have 3 options: 1. make a dedicated function for node killing, have the string matching done in debug.c 2. add a function that returns the help string of the cluster related sub-commands, so that each implementation can document and implement any sub-command list it wishes. 3. introduce a sub-sub-command named debug cluster or a command named cluster debug. (the first option is preferable since it doesn't add a new command). note that changes inside the debug command are not considered breaking changes (only meant to be used by tests) i prefer option 2. wdyt?",0,0,-1,0.9256629943847656,0.9734526872634888,0.8936217427253723,0.0,accept,majority_agreement
1398244748,12742,"i am fine with option 2, that's what i originally had in a previous version. will do that monday am first thing.",0,0,0,0.9398348927497864,0.8193142414093018,0.8223158121109009,0.0,accept,unanimous_agreement
1398373649,12742,"since this is not part of this pr, i think we should drop this. and any reference to ""flotilla"" from the current pr. instead, let's add redis_cluster_legacy that can be turned off. is it easy to also make the necessary changes so that redis can be compiled and run with `cluster_enabled`, even with the legacy cluster excluded? i.e. i imagine that it would work with all the slot awareness and restrictions, but without any cluster commands and cluster bus. if this is complicated, let's leave it for a future pr, but at least in this one, avoid the ""flotilla"" defines and referring to files that don't exist, and instead prepare the ground for being able to just exclude the legacy cluster in a later pr.",0,0,0,0.951326549053192,0.9924559593200684,0.9859407544136048,0.0,accept,unanimous_agreement
1399066707,12742,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1399281009,12742,done. no mention of flotilla in the code base at all,0,0,0,0.9816530346870422,0.9743127822875975,0.980305790901184,0.0,accept,unanimous_agreement
1399384044,12742,i'm not sure i like it. can we instead call both and let the cluster do any additional changes it requires?,-1,-1,-1,0.9668951034545898,0.6239660978317261,0.909798800945282,-1.0,accept,unanimous_agreement
1399393142,12742,unnecessary indentation change (not sure it's right anyway),-1,0,-1,0.6969628930091858,0.8893734812736511,0.8105079531669617,-1.0,accept,majority_agreement
1399524669,12742,i do not understand your comment.,-1,-1,-1,0.9365766644477844,0.6883891820907593,0.7172856330871582,-1.0,accept,unanimous_agreement
1399526151,12742,my suggestion was something like: [code block] the legacy cluster should throw an error.,0,0,0,0.9785929322242736,0.9841665029525756,0.988824188709259,0.0,accept,unanimous_agreement
1399550939,12742,"just spoke to about this. what we said was that we want to add an ""if cluster mode"" to this code to make it more self contained and more explicit (even though this code can never be reached when not in cluster mode).",0,0,0,0.9807865023612976,0.9867563247680664,0.9902732968330384,0.0,accept,unanimous_agreement
1399555610,12742,the legacy cluster should throw an error...if it is invoked somehow while in cluster mode? like panic?,-1,0,0,0.5982722043991089,0.9429498314857484,0.8798421025276184,0.0,accept,majority_agreement
1399560938,12742,we can't panic unfortunately because we don't want to allow some elevated admin user to cause crashes easily. perhaps clusterpromoteselftomaster should allow throwing an error.,0,0,-1,0.9025193452835084,0.8572171330451965,0.7784343361854553,0.0,accept,majority_agreement
1399578627,12742,and then what is done with the error when it is caught?,0,0,0,0.9759928584098816,0.9912254214286804,0.9786108136177064,0.0,accept,unanimous_agreement
1399601339,12742,"i don't consider psync failover a feature that's cluster specific, so this code is not cluster specific. the suggestion to make it an `if-else` does improve the situation a bit, but i wonder if we can't just run both i.e. do we see a case where in the cluster mode we won't need to promote the local instance?",0,0,0,0.9437147974967957,0.9421491622924804,0.978765070438385,0.0,accept,unanimous_agreement
1400167195,12742,", we'll talk but if i understand you correctly, in the current cluster implementation there is no cluster bus support for implementing psync failover. this change makes it possible for *other* cluster implementations to support psync failover.",0,0,0,0.9812503457069396,0.9667150378227234,0.9855959415435792,0.0,accept,unanimous_agreement
858452810,10636,"are you ok with that? 50ms busy loop by default on any redis startup on linux? there would be a config to supress the warning, which will also suppress the test, but still, i suppose that someone starting up many instance of redis by some script will be hit by that.",0,0,0,0.9825091361999512,0.9558562636375428,0.949787437915802,0.0,accept,unanimous_agreement
858455311,10636,-steinberg please publish some results you got when you tested it in the top comment.. so we know how far the threshold is from generating false positives and false negatives.,0,0,0,0.9789976477622986,0.967564046382904,0.9830024838447572,0.0,accept,unanimous_agreement
858457074,10636,"maybe we wanna make it easier on people (like we did for thp and others), and give them an example of the bash command they should run.",0,0,0,0.9776298999786376,0.9908446669578552,0.9766194224357604,0.0,accept,unanimous_agreement
858458719,10636,debug logging? (remove),0,0,0,0.9776025414466858,0.9885442852973938,0.991644322872162,0.0,accept,unanimous_agreement
858460268,10636,"won't it be faster to use `strchar`, and call it repeatedly till we find the last one? considering this field is at the beginning, and parsing rss is done frequently.",0,0,0,0.9875147342681884,0.990770161151886,0.984483540058136,0.0,accept,unanimous_agreement
859528842,10636,"yes, oops.",-1,-1,-1,0.9778643250465392,0.8268706202507019,0.90273779630661,-1.0,accept,unanimous_agreement
859555882,10636,in any case we'll need to scan the string to the end otherwise we don't know we found the last one. i'll change this to `strrchr()` because currently using `strchr()` is a bug in case there are `)` in the file name.,0,0,0,0.987973928451538,0.9818938970565796,0.9938318729400636,0.0,accept,unanimous_agreement
859891174,10636,leaking `fp` when we return null here.,0,0,0,0.9404747486114502,0.9854912757873536,0.985327124595642,0.0,accept,unanimous_agreement
860551946,10636,"the problem is that we can't be sure running a specific command would result in the desired result. even if the clocksource is changed it might be changed to a non-safe one, so i'm not sure. this is the current message: `warning slow system clocksource detected. this can result in degraded performance. consider changing the system's clocksource. current clocksource: %s. available clocksources: %s.` i can change it to: `warning slow system clocksource detected. this can result in degraded performance. consider changing the system's clocksource. current clocksource: %s. available clocksources: %s. for example: run the command 'echo tsc > /sys/devices/system/clocksource/clocksource0/current_clocksource' as root. to permanently change the system's clocksource you'll need to set the 'clocksource=' kernel command line argument.`",0,0,-1,0.6417805552482605,0.8771008253097534,0.5568828582763672,0.0,accept,majority_agreement
860559337,10636,"i think it's better.. the text still indicates that we're not confident this is the right thing.. but for the majority of the users seeing this, they'll be able to solve the problem without a round trip to google search. and arguably for many of them, they don't have the time or capacity to really understand the problem and risks anyway.",0,0,0,0.572064220905304,0.9277190566062928,0.5017667412757874,0.0,accept,unanimous_agreement
860785387,10636,"ok, update message.",0,0,0,0.9860207438468932,0.9831963777542114,0.9936349391937256,0.0,accept,unanimous_agreement
862476884,10636,i have to set i don't like that - not the busy loop and not the heuristics we have to apply that may also lead to false positives.,-1,-1,-1,0.9740240573883056,0.9434255361557008,0.8651789426803589,-1.0,accept,unanimous_agreement
862486165,10636,"i wouldn't define that as heuristics.. that's the real right way to test.. i.e. we don't care how it's configured. but rather the fact it uses ""system"" time. note that the threshold for telling them apart is very clear.. i just wish there was a way to do that with just one call and not a loop",-1,0,0,0.590871274471283,0.9031619429588318,0.9120908379554749,0.0,accept,majority_agreement
862491425,10636,"i think it is a heuristic, because we're comparing wall clock time with cpu stime.",0,0,0,0.9796999096870422,0.9617432951927184,0.9765584468841552,0.0,accept,unanimous_agreement
862506263,10636,"the check is basically built out of 3 steps: 1. read stime from proc fs. 2. busy loop longer than a system tick calling `clock_gettime()`. 3. read stime from proc again. steps 1 and 3 are by definition a system call. step 2 is either a system call on an un-optimized system or a a vdso call or an optimized system. the _theoretical_ logic of the test is simple and not heuristic: if this is an un-optimized system, the stime diff will be larger than 0. in _practice_ since steps 1 and 3 perform system calls to read from proc fs then there's the slight chance that the stime diff will be affected by the procfs reads. this is what's heuristic about the test, but there's a very safe margin here. on the other hand it surprised me that the un-optimized xen implementation spent only ~30% of the time in the system call. so i'm not totally sure what's happening there. but i'm sure it's due to, at least partially, not going through vdso on all calls to `clock_gettime()` which is enough to degrade performance.",0,0,0,0.9722860455513,0.9921073317527772,0.9830549955368042,0.0,accept,unanimous_agreement
864482409,10636,"i just tested it on my machine, and it looks like getrusage is much more accurate than `/proc/self/stat`. even a loop of system_hz / 10 results in accurate readings (not rounded to the next jiffy). here are some measurements i got |utime|stime|loops| |---|---|---| |669| 334|14065 |336| 671|11475 |1003| 0|12625 |669| 334|14053 |1006| 0|12578 |1003| 0|51488 |670| 335|13639 with the above i could be getting some false positives. but with a loop for 1 jiffy: |utime|stime|loops| |---|---|---| 8570| 1433| 151897 10005| 0| 126577 9132| 494| 115087 9844| 0| 135356 9995| 0| 123566 8888| 1117| 126502 50004| 0| 1567099 i suppose using a minimum of 1 jiffy or 1000 calls (for slow systems to make sure we have many more clock_gettime readings vs getrusage calls), and setting the threshold to 50% rather than 10% could be good.",0,0,0,0.8724231123924255,0.9739933013916016,0.8936169147491455,0.0,accept,unanimous_agreement
864547782,10636,"it still seems to me that the timing we get from `getrusage()` is very coarse and is probably jiffy bound. this is especially problematic for the `xen` clocksource because it's not really 100% kernel or 100% user. i put some detailed test results here: [a link] analyzing those results we see: * `getrusage()`'s `stime` resolution is roughly 3,000 usec, which is less than the system tick of 10,000 usec but still very coarse. having any sub-jiffy test time leads to inconclusive results. * the `xen` clocksource has the largest disparity in results. even with test time of a jiffy or longer we see time spent in both system call and user space is significant and varies between tests. * having said the above about `xen`, with long enough tests (50,000 usec or more) we can clearly see that the `xen` clocksouce does indeed spend significant and detectable time in the kernel: for the 50,000 usec tests, we see a rare minumum of 14% stime and a median of 27% stime. so i recommend leaving the test as is. anything under the 50,000 usec test risks not detecting the slowness of `xen` since we might get results under the 10% stime threshold on `xen`.",-1,0,0,0.6730684041976929,0.7766404151916504,0.8797023892402649,0.0,accept,majority_agreement
867459747,10636,"i discussed it with yossi, we still fear from the overheads of this check. the proposed solution is: 1. add some `redis-server --check-system` mode (similar to `--test-memory`), which will do some system checks and report output in stdout and exit code. 2. in normal startup of redis, simply check the configured clock source in `/proc` and report a warning if we see `xen`. (the warning should mention the `--check-system` feature, and can be disabled)",-1,0,0,0.5810428857803345,0.9614663124084472,0.7515237331390381,0.0,accept,majority_agreement
867960871,10636,done. please re-review.,0,0,0,0.9756548404693604,0.9530596733093262,0.9921430349349976,0.0,accept,unanimous_agreement
868315584,10636,"while we're doing some tech-debt cleanup, let's move all the thp related code from latency.c",0,0,0,0.9779141545295716,0.9863322973251344,0.991144359111786,0.0,accept,unanimous_agreement
868317405,10636,i think we need to keep the camel case convention,0,0,0,0.9794626832008362,0.9311683773994446,0.9830672144889832,0.0,accept,unanimous_agreement
868321034,10636,maybe it would be clearer if the `exit` is moved here (using the return value)?,0,0,0,0.988020360469818,0.9952194094657898,0.9856438636779784,0.0,accept,unanimous_agreement
868321646,10636,maybe `checkxenclocksource`?,0,0,0,0.9878091812133788,0.9938878417015076,0.994382381439209,0.0,accept,unanimous_agreement
868324417,10636,"why did you not move the linuxmadvfreeforkbugcheck to the new file, and change the way it returns errors to be printed? like others? it should be part of the system check...",0,0,0,0.9704675674438475,0.9871075749397278,0.9828624129295348,0.0,accept,unanimous_agreement
868326249,10636,"come to think of it, maybe we should bring the check from [a link] in here. wdyt?",0,0,0,0.9798834919929504,0.9703664183616638,0.984439492225647,0.0,accept,unanimous_agreement
868326703,10636,i think we wanna use the `checkignorewarning` mechanism to allow disabling that warning,0,0,0,0.9886150360107422,0.9875202178955078,0.9893749952316284,0.0,accept,unanimous_agreement
868327460,10636,"i suppose this should be `redis ltd`? (like in functions.c). p.s. much of this code is copy paste, not sure what's the guideline in that case.",0,0,0,0.9842115044593812,0.9866577982902528,0.9750878810882568,0.0,accept,unanimous_agreement
868330864,10636,let's add a top comment for each of these functions with it's role and reason why it is needed. plus some description of the interface (return values).,0,0,0,0.9855138063430786,0.977607786655426,0.9936248064041138,0.0,accept,unanimous_agreement
868336169,10636,do we need both `xen` and `clocksource` here? maybe just `clocksource`? p.s. i would rename one to `xen-clocksource` and the other to `slow-clock_gettime` or `slow-clock`,0,0,0,0.9884870052337646,0.995100200176239,0.9948293566703796,0.0,accept,unanimous_agreement
868734793,10636,i think it works.,0,0,1,0.9385777115821838,0.7020629644393921,0.7588219046592712,0.0,accept,majority_agreement
868882425,10636,"i agree, but `version()` and `usage()` take the other approach while `memtest()` does the exit externally. so there's some inconsistency here. i'll change.",0,0,0,0.984386384487152,0.941047430038452,0.9795255661010742,0.0,accept,unanimous_agreement
868882518,10636,:+1:,0,0,0,0.7570654153823853,0.9166757464408876,0.9328674077987672,0.0,accept,unanimous_agreement
868886252,10636,:+1:,0,0,0,0.7570654153823853,0.9166757464408876,0.9328674077987672,0.0,accept,unanimous_agreement
868887082,10636,"you sure? the check now has no disadvantages, and in all known cases we don't want `xen` clocksource. lets add this only in the future if needed.",0,0,0,0.9813372492790222,0.9740900993347168,0.9814669489860536,0.0,accept,unanimous_agreement
868887705,10636,":+1: oops, missed the arm stuff.",-1,-1,0,0.9788378477096558,0.6691422462463379,0.6591071486473083,-1.0,accept,majority_agreement
868912238,10636,"i copied it from some file that was copiright `redis labs` with no ""ltd"" and just removed the ""labs"". anyway i'll add the ""ltd."". re guidelines i have not idea, probably we need to have multiple copyright lines something like: [code block] let me know...",0,0,0,0.9598640203475952,0.8617736101150513,0.9895290732383728,0.0,accept,unanimous_agreement
868929874,10636,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
868945876,10636,"i thought someone may be bothered by the warning print. but on a second thought, we don't have any way to disable the thp or other warnings either.. so ok.. but please ack.",0,0,-1,0.7118983268737793,0.7607744336128235,0.9629477858543396,0.0,accept,majority_agreement
868946921,10636,we do you have an insight on that (moving code to a different file)?,0,0,0,0.9881415367126464,0.987280547618866,0.9939889907836914,0.0,accept,unanimous_agreement
869004198,10636,p.s. aren't we also missing checktcpbacklogsettings?,0,0,0,0.9856722354888916,0.9943974018096924,0.9948644042015076,0.0,accept,unanimous_agreement
869008973,10636,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
869010724,10636,"i don't see a problem in not having a way to disable, but i do think we need to emit different warnings: * when `xen` source is detected, indicate it *might* be an issue and suggest to run the check. * when we actually measure a slow `clock_gettime()`, indicate there is a real issue and a possible solution if `xen` is used (but remember it could also be a totally different problem / platform).",0,0,0,0.9761933088302612,0.984385311603546,0.9724959135055542,0.0,accept,unanimous_agreement
869011879,10636,"new file should carry old file's notice, and if it includes additional changes then the copyright line you suggested above can be added as well.",0,0,0,0.987307071685791,0.9875997304916382,0.9951252341270448,0.0,accept,unanimous_agreement
869013187,10636,this checks that the system can be configured according to the `tcp-backlog` configuration. so it's not a generic system check. what do you think?,0,0,0,0.9864598512649536,0.991445779800415,0.9880220890045166,0.0,accept,unanimous_agreement
869020235,10636,"ok.. so because it reacts to a config config, it is different.. (also must be run later in the startup sequence).",0,0,0,0.9681382179260254,0.991287648677826,0.976448118686676,0.0,accept,unanimous_agreement
869905412,10636,"well, i suppose we can do that in another pr later..",0,0,0,0.9689646363258362,0.9811091423034668,0.9883201122283936,0.0,accept,unanimous_agreement
869944399,10636,this line in redis_test is redefined. [a link],0,0,0,0.988234043121338,0.9897011518478394,0.9956246018409728,0.0,accept,unanimous_agreement
870002811,10636,i wonder if we can move these check codes into syscheck.c altogether.,0,0,0,0.8665240406990051,0.9777672290802002,0.959758162498474,0.0,accept,unanimous_agreement
870018001,10636,what do you mean? (not sure of the context of your last message),0,0,0,0.523180365562439,0.9758567214012146,0.9785915613174438,0.0,accept,unanimous_agreement
870021392,10636,"now all the checking methods have been moved to syscheck.c, but there is still some checking code in server.c, i think it is more reasonable to put them all together.",0,0,0,0.9825356006622314,0.9908129572868348,0.9882383942604064,0.0,accept,unanimous_agreement
870031645,10636,"ok, but we did that already (except for the tcp_backlog one that's tied to a config value). and this comment of yours is in a thread about whether or not to add a `checkignorewarning` to silence the print. so i'm not certain about the context, maybe i'm missing your intention.",0,0,0,0.9217510223388672,0.9043034315109252,0.9836525917053224,0.0,accept,unanimous_agreement
870036500,10636,thanks. fixed.,1,1,1,0.8839593529701233,0.9529776573181152,0.921301543712616,1.0,accept,unanimous_agreement
870065515,10636,"the logic is that `--check-system` is used to run **all** available system checks and set an appropriate exit code. this can be done by install scripts, etc. to verify the system is correctly configured. this means the checks can also be inefficient or even leave the process in a problematic state. on the other hand the checks which are executed on normal server startup have to be fast and not affect the process's state. i changed the warning messages based on your comment. i'm resolving this. re-open if needed.",0,0,0,0.973238468170166,0.9772408604621888,0.9743460416793824,0.0,accept,unanimous_agreement
870066472,10636,"now that each test prints a different warning message, having both of them provides the user with more details. i'm for keeping both. updated the test names.",0,0,0,0.9341959357261658,0.9677648544311525,0.8884832859039307,0.0,accept,unanimous_agreement
870078016,10636,"-steinberg ohh, i missed it, i thought it was just optimization. if so, i don't think it seems appropriate to brink the #10467 check here, when building a docker image, this check will not fail, because it is not built under qemu, until the image is actually running in qemu, it will be will fail.",0,0,0,0.6958245635032654,0.927487015724182,0.8560810685157776,0.0,accept,unanimous_agreement
870081444,10636,decided to put this test under the `--check-system` mode instead of on startup.,0,0,0,0.98317688703537,0.9944834113121032,0.9911507368087769,0.0,accept,unanimous_agreement
870082063,10636,done.,0,0,0,0.975940763950348,0.9640594124794006,0.9897913336753844,0.0,accept,unanimous_agreement
870164378,10636,"it may still be a thing that we can suggest to users to run. but i agree it'll not be valuable for plain docker users. and i suppose others are not expected to use qemu.. anyway, we can reconsider in the future.",0,0,0,0.9434415698051452,0.9696244597434998,0.958660125732422,0.0,accept,unanimous_agreement
873106833,10636,[code block] ?,0,0,0,0.988338053226471,0.9873912930488586,0.9939754605293274,0.0,accept,unanimous_agreement
873107113,10636,split this line?,0,0,0,0.9803646802902222,0.9782362580299376,0.9907594919204712,0.0,accept,unanimous_agreement
873107136,10636,split this line?,0,0,0,0.9803646802902222,0.9782362580299376,0.9907594919204712,0.0,accept,unanimous_agreement
873107501,10636,"if someone is running a non-durable variant of redis, thp can be a good thing since it reduce tlb misses. it seems like the warning message doesn't really address that situation very clearly.",0,0,0,0.9341721534729004,0.935882329940796,0.9490603804588318,0.0,accept,unanimous_agreement
874316915,10636,"maybe we can change `linuxmemorywarnings()` to `int checklinuxmemorywarnings(sds *err_msg)`, so we don't need to repeat `serverlog(ll_warning, ...)` and `sdsfree(...)` multiple times. [code block]",0,0,0,0.9863854050636292,0.9951438903808594,0.989657700061798,0.0,accept,unanimous_agreement
874408993,10636,but we might want to print both warnings.,0,0,0,0.9822573065757751,0.9658826589584352,0.985742211341858,0.0,accept,unanimous_agreement
874424710,10636,"indeed, i was wrong. btw, when i try to add madv dontneed detection based on this pr and output warnings, i can only copy most of the warning ouput code similar to `checklinuxmadvfreeforkbug`, which is not very comfortable.",-1,-1,0,0.9314830899238586,0.6964237689971924,0.5368480086326599,-1.0,accept,majority_agreement
874425139,10636,"i think there might be other instances where a fork might cause thp issues. redis might fork for module processing (`child_type_module`) or for disk based replication. i was under the impression that this should always be turned off. but you are right that there are other cases. i have a feeling that too much detail here will become cumbersome. for the general use case we should recommend turning this off. it might be wise to add a link to the docs website for a detailed explanation, and perhaps do the same for all the other warnings. the downside being that we'll have to keep the link valid.",-1,-1,0,0.6814613342285156,0.5381956696510315,0.924150049686432,-1.0,accept,majority_agreement
878870801,10636,"i don't think a link to the website is suitable, might get outdated. i think we need to provide enough information so that people can google it, or find an answer in stack overflow. i'd prefer to avoid providing incorrect or misleading information, so in this context maybe we should replace `this will create latency and memory usage issues with redis` with `this may ...`. but i'll leave that for another opportunity (this pr just relocates that text, it didn't introduce it).",0,0,0,0.7565264105796814,0.9529399275779724,0.9542255401611328,0.0,accept,unanimous_agreement
924143196,10969,why?,0,0,0,0.6633803844451904,0.8699262738227844,0.9622438549995422,0.0,accept,unanimous_agreement
924143786,10969,i see now we propagate after each operation (which is generally better i guess) - i think we can completely delete `server.propagate_no_multi`,0,0,0,0.9856361150741576,0.97788268327713,0.9810101389884948,0.0,accept,unanimous_agreement
924148374,10969,"i think this function is unnecessary (only used in one place, we can just copy the two lines there)",0,0,0,0.931970238685608,0.9693292379379272,0.977514147758484,0.0,accept,unanimous_agreement
924149233,10969,what's the difference between `len` and `numops`?,0,0,0,0.978099524974823,0.9923262596130372,0.9919511079788208,0.0,accept,unanimous_agreement
924154684,10969,"i mean, i can see that `len` is the number of ""taken"" elements and `numops` is the number of taken elements that have a `target` (i.e not the ""placeholder"" ones) - but do we really need it? the placeholder must be filled before calling `propagatependingcommands` (we should assert that `target` exists) so maybe we can drop `len` and use only `numops`, which will be incremented, regardless of whether it's a placeholder or not",0,0,0,0.983558475971222,0.9941012263298036,0.9872967004776,0.0,accept,unanimous_agreement
924155223,10969,see comment [a link],0,0,0,0.985617220401764,0.9847903847694396,0.9952860474586488,0.0,accept,unanimous_agreement
924155636,10969,let's assert `!op->target`,0,0,0,0.972230076789856,0.9932886958122252,0.9951885938644408,0.0,accept,unanimous_agreement
924155953,10969,how is that possible?,0,0,0,0.975644052028656,0.982111930847168,0.9079554677009584,0.0,accept,unanimous_agreement
924156814,10969,what about `zfree(oa->ops)`?,0,0,0,0.9877447485923768,0.9938492178916932,0.9940187931060792,0.0,accept,unanimous_agreement
924157758,10969,the placeholder is not necessarily be set in case the command did not cause any effects and does not need to be replicated.,0,0,0,0.9857133626937866,0.992401123046875,0.991333544254303,0.0,accept,unanimous_agreement
924165740,10969,also its possible that it will be left empty if the command called `preventcommandpropagation` and propagate the data by itself (like `spop`),0,0,0,0.9889974594116212,0.9942334294319152,0.9914564490318298,0.0,accept,unanimous_agreement
924166972,10969,we reuse the array so we will not have to allocated it each time.,0,0,0,0.9852818846702576,0.9887113571166992,0.9940985441207886,0.0,accept,unanimous_agreement
924172537,10969,"without mark that we are on nested call, the first `rm_call` that will be invoke by the module will cause the data to be replicated. if the module perform more then one `rm_call`, those will not be replicated in a single `multi + exec`.",0,0,0,0.988581120967865,0.9927719235420228,0.9932926893234252,0.0,accept,unanimous_agreement
924226571,10969,add comment: we add this in order to prevent any rm_call that may exist in the notify cb to be propagagted immediatly.. we want them in multi/exec with the del command,0,0,0,0.983659029006958,0.9945923686027528,0.9948831796646118,0.0,accept,unanimous_agreement
924228898,10969,comment that we do not zfree on purpose,0,0,0,0.9375115036964417,0.9524340033531188,0.9822101593017578,0.0,accept,unanimous_agreement
924234999,10969,"maybe do that just in case the command is ""write"" or ""may-replicate""",0,0,0,0.9872065782546996,0.994772970676422,0.9887268543243408,0.0,accept,unanimous_agreement
924244097,10969,trim the last element of the ops array (it's either been replicated or it's a placeholder),0,0,0,0.9877002239227296,0.9942893981933594,0.99409157037735,0.0,accept,unanimous_agreement
924248610,10969,add test: module does rm_call(write-cmd) inside a key-miss notification. the read command that caused key-miss should not be replicated.,0,0,0,0.988397181034088,0.9936007857322692,0.9954817295074464,0.0,accept,unanimous_agreement
924249854,10969,"capacity, numops: stays the same len -> used please add comment in the struct",0,0,0,0.9861650466918944,0.9909634590148926,0.995153784751892,0.0,accept,unanimous_agreement
924290032,10969,"please make propagatenow take dbid=-1, meaning it should not emit any select (db-neutral command)",0,0,0,0.988734245300293,0.9928695559501648,0.995050847530365,0.0,accept,unanimous_agreement
929048738,10969,please document what dictid == -1 means (db-neutral command),0,0,0,0.9890623688697816,0.99116450548172,0.9947158694267272,0.0,accept,unanimous_agreement
929050114,10969,please make sure that -1 is passed explicitly (never pass `server.slaveseldb` as `dictid`) update the comment above the assertion,0,0,0,0.988741934299469,0.9947723746299744,0.99558287858963,0.0,accept,unanimous_agreement
929052003,10969,/* propagate the del command */,0,0,0,0.985310673713684,0.9923350214958192,0.9945058226585388,0.0,accept,unanimous_agreement
929052631,10969,i guess you over-replaced :),1,1,0,0.9545283317565918,0.995100200176239,0.9341570734977722,1.0,accept,majority_agreement
929053489,10969,.. is an unused placeholder ..,0,0,0,0.8914182782173157,0.9249894618988036,0.9815993905067444,0.0,accept,unanimous_agreement
929059981,10969,"maybe it should just return the index of the appended op, instead of the total number of ops?",0,0,0,0.9852327704429626,0.9934951663017272,0.984485387802124,0.0,accept,unanimous_agreement
929061221,10969,let's add os->numops-- after the `continue`,0,0,0,0.9886817932128906,0.9927514791488647,0.9952013492584229,0.0,accept,unanimous_agreement
929061677,10969,we can assert these (the loop should have zeroed them both),0,0,0,0.9869481325149536,0.9891822934150696,0.9930012226104736,0.0,accept,unanimous_agreement
929064543,10969,please use a better name (cmd_prop_index for exmaple),0,0,0,0.9813470840454102,0.9927480816841124,0.9950112104415894,0.0,accept,unanimous_agreement
929108637,10969,why?,0,0,0,0.6633803844451904,0.8699262738227844,0.9622438549995422,0.0,accept,unanimous_agreement
929108851,10969,please trim empty lines,0,0,0,0.9860563278198242,0.9864740967750548,0.992731273174286,0.0,accept,unanimous_agreement
929155630,10969,"as mentioned on the top comment: on key miss event, if a module performed some write command on the event (using rm_call), the dirty counter would have increase and the read command that cause the key miss event would have been replicated to the replication and aof. to avoid this, we perform the replication only on write or may_replicate commands. this will prevent replicating read commands even if the dirty counter was increased. test was added to verify this scenario. added a comment on the code itself as well.",0,0,0,0.985584020614624,0.9940496683120728,0.9905502796173096,0.0,accept,unanimous_agreement
929177431,10969,but what about lazy-expire? how does that work? imagine a get that causes the propagation of del... from what i can see from the code they would both propagate (which is not the best) but now after your change none of them would propagate (which is worse). please cmiiw and add a test if i'm not,0,0,0,0.9293439388275146,0.9074001908302308,0.9569189548492432,0.0,accept,unanimous_agreement
929179663,10969,"mmm idk, i feel it's a bit confusing... maybe [code block]",-1,-1,-1,0.9658864736557008,0.9582525491714478,0.7101325392723083,-1.0,accept,unanimous_agreement
929185933,10969,"i believe only the `get` will not be propagated, let me write a test for it.",0,0,0,0.8996983766555786,0.9857103228569032,0.9906063079833984,0.0,accept,unanimous_agreement
929203298,10969,pushed another commit with the test.,0,0,0,0.9733418822288512,0.9902015328407288,0.9874603748321532,0.0,accept,unanimous_agreement
929230371,10969,"we don't use the term ""primary"" at least not yet. for now, mixing up different terminologies just causes confusion imho.",-1,0,0,0.7017332911491394,0.9064528942108154,0.7465545535087585,0.0,accept,majority_agreement
929230741,10969,it should be shorter to match it to a mark with two bits (`flags` mentioned only once),0,0,0,0.9866755604743958,0.993697226047516,0.9874542951583862,0.0,accept,unanimous_agreement
929252914,10969,"in such tests, i always prefer to add another dummy command, e.g. set so i can verify there are no other unexpected commands after del",0,0,0,0.9767178893089294,0.993058443069458,0.9885106086730956,0.0,accept,unanimous_agreement
930713501,10969,remove epty line,0,0,0,0.9778686165809632,0.9741394519805908,0.9942732453346252,0.0,accept,unanimous_agreement
930714119,10969,"""if we got here with cmd_prop_index == -1, the command ...""",0,0,0,0.9872209429740906,0.991750419139862,0.9891458749771118,0.0,accept,unanimous_agreement
930996405,10969,placeholder is not necessarily be used.,0,0,0,0.9793572425842284,0.9724440574645996,0.9899539947509766,0.0,accept,unanimous_agreement
931036038,10969,target of 0 means not to propagate anywhere? maybe a comment here can explain the scenario? would be nice if we would add some comment next to `target`'s declaration too. it would also be nice to explain the interface in the top comment of the function,0,0,0,0.9501258730888368,0.9779012203216552,0.9914769530296326,0.0,accept,unanimous_agreement
931057904,10969,git diff gets confused between redisoparrayset and redisoparrayappend. maybe if we move redisoparrayset to be above redisoparrayappend it'll look better (easier to review) let's also add some comment that it's here to update a placeholder (explaining the assertion)?,0,0,0,0.8298636674880981,0.9800993800163268,0.9396270513534546,0.0,accept,unanimous_agreement
931069813,10969,"are you sure this function is properly named? for me, the name suggests that it is always used with a placeholder. but actually, it's more an ""alsopropagateraw"" that's used as an ""append or replace"" thing. i suggest to rename and add a comment.",0,0,0,0.9868804216384888,0.9923496246337892,0.992298662662506,0.0,accept,unanimous_agreement
931093607,10969,"this is a temporary solution, right? we will revert back to using rewriteclientcommandvector as soon as we can afford to move the keyspace notification to before the `dbdelete`. so let's comment all of that in some todo comment in the code (not just commit comment). will also better explain this odd code (different from other similar commands) when someone looks at it.",0,0,0,0.979259729385376,0.9885308742523192,0.9746870398521424,0.0,accept,unanimous_agreement
931098179,10969,"i think i expected a documentation update (in module.c) to mention people shouldn't do that. it's ok that the tests does it, so the code path is covered, but the tests should maybe have a comment that it's temporary (for coverage), until we can afford to add an assertion.",0,0,0,0.9833963513374328,0.9879053831100464,0.9643838405609132,0.0,accept,unanimous_agreement
931115604,10969,"this is not gonna change, when we fix the code in t_set.c, right? still maybe drop here a comment what makes this case special (explicitly stating that it's not gonna change)",0,0,0,0.9827151894569396,0.9714747667312622,0.9800050258636476,0.0,accept,unanimous_agreement
931117248,10969,"ohh, the comment i expected in the module's c code is here.. still maybe drop a comment on the other end too.",0,0,0,0.9541516304016112,0.9793118238449096,0.9830938577651978,0.0,accept,unanimous_agreement
931844172,10969,"actually i am not sure, i discussed with whether or not it is right to do `rewriteclientcommandvector` or a command that don't want to replicate itself should just do `preventcommandpropagation` and propagate what it want. currently we have a mix of 2 ways to achieve the same thing ... but we can discuss it on another pr/issue.",0,0,0,0.9216373562812804,0.8597643375396729,0.9567909240722656,0.0,accept,unanimous_agreement
931844366,10969,will add a todo anyway ...,0,0,0,0.9809924960136414,0.9783890843391418,0.9930168390274048,0.0,accept,unanimous_agreement
931849444,10969,"this is going to change, notice that the `del` comes after `incr notifications` when we fix the key space notification ordering the `del` will come before. i will add a comment.",0,0,0,0.987644374370575,0.989408016204834,0.9953045845031738,0.0,accept,unanimous_agreement
932207835,10969,"not sure that warning should be placed here. i don't see any details about something ""special"" in the link provided here. i guess the warning you added above is enough.",0,0,0,0.95575749874115,0.8859525322914124,0.9058871865272522,0.0,accept,unanimous_agreement
932238761,10969,"ohh, i wanted to put it here but then decided that its better to put it above and forgot to delete it...",-1,0,0,0.7843850255012512,0.8181688189506531,0.8688815236091614,0.0,accept,majority_agreement
885713414,10747,"you should use mkgroup (we want the default behavior to be avoiding creating a group, to keep backward compatibility)",0,0,0,0.9876254200935364,0.9925938248634338,0.9945030212402344,0.0,accept,unanimous_agreement
885731169,10747,"thanks, i will update it.",1,1,1,0.5582407712936401,0.7078995108604431,0.5860733389854431,1.0,accept,unanimous_agreement
990757333,10747,"you have indentation issues, your editor inserts tabs in some places. please go over all the modified files and fix them.",0,0,0,0.9875665903091432,0.9305201768875122,0.9871495366096495,0.0,accept,unanimous_agreement
990757420,10747,added white space at the end of line that doesn't have any changes otherwise,0,0,0,0.9867936968803406,0.9875249862670898,0.9918471574783324,0.0,accept,unanimous_agreement
990757535,10747,"i don't think we need to mention all the supporting commands, just mention is't not supported for xread",0,0,0,0.9842513799667358,0.8784064054489136,0.984812557697296,0.0,accept,unanimous_agreement
990757718,10747,white space,0,0,0,0.9700245261192322,0.9725161194801332,0.9741135239601136,0.0,accept,unanimous_agreement
990757741,10747,whitespace,0,0,0,0.98747456073761,0.9243230819702148,0.9755821228027344,0.0,accept,unanimous_agreement
990757793,10747,whitespace,0,0,0,0.98747456073761,0.9243230819702148,0.9755821228027344,0.0,accept,unanimous_agreement
990758021,10747,"let's keep the old error code / behavior (nogroup), with a detailed message saying the key is missing...",0,0,0,0.9747195243835448,0.9777182936668396,0.9929343461990356,0.0,accept,unanimous_agreement
990758058,10747,indentation is wrong.,-1,-1,-1,0.7647757530212402,0.6590532660484314,0.8277490139007568,-1.0,accept,unanimous_agreement
990758139,10747,indentation is wrong.,-1,-1,-1,0.7647757530212402,0.6590532660484314,0.8277490139007568,-1.0,accept,unanimous_agreement
990758498,10747,why would it ever fail? we already know the group doesn't exist. please drop this.,-1,0,-1,0.7248677015304565,0.7050011157989502,0.9778258800506592,-1.0,accept,majority_agreement
990758845,10747,"indentation issues.. why do we set `mkgroup` when argc==4? i don't like this assumption, it can break in the future. i understand that the current command syntax forces us to count things in order to guess what's coming next, but at least let's actually match strings that we can.",-1,-1,-1,0.8371838331222534,0.5434671640396118,0.966377854347229,-1.0,accept,unanimous_agreement
990759057,10747,indentation,0,0,0,0.982236921787262,0.822169840335846,0.9911677837371826,0.0,accept,unanimous_agreement
990759791,10747,i'd rather move the lookup (ksn) and type check to after processing the arguments and syntax errors.,0,0,0,0.9699069857597352,0.990395963191986,0.9870206117630004,0.0,accept,unanimous_agreement
990759960,10747,"again, error that can't actually happen. please drop (and fix indentation issues and tabs)",0,0,0,0.8921595811843872,0.5018960237503052,0.8999484777450562,0.0,accept,unanimous_agreement
990760015,10747,let's keep the old error code.,0,0,0,0.9751574993133544,0.96652090549469,0.988098442554474,0.0,accept,unanimous_agreement
990760330,10747,"i'd suggest to move the type check and all creations to after argument parsing. i know it wasn't the case, but let's improve.",0,0,0,0.9499589800834656,0.9711524248123168,0.9899555444717408,0.0,accept,unanimous_agreement
990760383,10747,drop error that can't happen.,0,0,0,0.9563950300216676,0.8790767788887024,0.8012416958808899,0.0,accept,unanimous_agreement
990760515,10747,let's keep the error code,0,0,0,0.9820297360420228,0.9723163843154908,0.9924930930137634,0.0,accept,unanimous_agreement
990760537,10747,drop impossible error,0,0,-1,0.972650408744812,0.5382572412490845,0.9270651936531068,0.0,accept,majority_agreement
995910231,10747,"i will update the codes following your comments, and rebase it as well. thanks oran",1,1,1,0.9671106934547424,0.985382914543152,0.9682220220565796,1.0,accept,unanimous_agreement
999861873,10747,"hi oran, here i have one concern, but so far i have no better idea. please comment it if you have better idea on it. for the command xpending, it could be `xpending [ [ ]]` or `xpending [ ] [mkgroup]` the last argument could be **consumer** or [mkgroup], so the only way to distinguish is to use `strcasecmp(c->argv[j]->ptr, ""mkgroup"")`. if i move the mkgroup augement to the front of the idle or ` `, it will break current change. thus, i choose my current code. if you have better arugment format or better coding logic, welcome to comment here.",0,0,0,0.9202641248703004,0.9601616859436036,0.8299374580383301,0.0,accept,unanimous_agreement
1002706299,10747,"i see that in 6.2 we chose to extend this command by adding optional arguments (the idle) before the ` `. so in this case, since mkgroup isn't related to the range specification, i think it should come right after ` `",0,0,0,0.9848302602767944,0.9916489124298096,0.9913685917854308,0.0,accept,unanimous_agreement
1002706604,10747,as i noted here [a link] i think it should come before the `filters` block.,0,0,0,0.9878095388412476,0.9889686107635498,0.9938207268714904,0.0,accept,unanimous_agreement
1002706771,10747,indentation,0,0,0,0.982236921787262,0.822169840335846,0.9911677837371826,0.0,accept,unanimous_agreement
1002707021,10747,white space,0,0,0,0.9700245261192322,0.9725161194801332,0.9741135239601136,0.0,accept,unanimous_agreement
1002707064,10747,white space,0,0,0,0.9700245261192322,0.9725161194801332,0.9741135239601136,0.0,accept,unanimous_agreement
1002707311,10747,let's move the creation of the group to after argument parsing. so that we know we're not making changes if the command is gonna fail on an error.,0,0,0,0.9808989763259888,0.98075670003891,0.9899023771286012,0.0,accept,unanimous_agreement
1002710587,10747,please make sure your code doesn't contain tabs.,0,0,0,0.9795281887054444,0.9791046380996704,0.9918184280395508,0.0,accept,unanimous_agreement
1002710704,10747,"indentation by 4, not 2.",0,0,0,0.9730543494224548,0.9800518751144408,0.9823758006095886,0.0,accept,unanimous_agreement
1017132120,10747,"address this comment, create the group if necessary after the argyment parsing part, please take a look",0,0,0,0.979458749294281,0.9869012236595154,0.9952008724212646,0.0,accept,unanimous_agreement
1017132750,10747,check all code styles and update them. thanks a lot,1,1,1,0.9816221594810486,0.9856163263320924,0.9796559810638428,1.0,accept,unanimous_agreement
1032908167,10747,"didn't we already lookup the key and group? we saved the group into `groups`, there's no need to re-lookup. let's do the same thing for the keys and also avoid the other lookupkeyread below.",0,0,0,0.98698490858078,0.9914705157279968,0.9946868419647216,0.0,accept,unanimous_agreement
1032914500,10747,isn't this outdated? let's match it to `j`,0,0,0,0.9828974604606628,0.982042133808136,0.9929049611091614,0.0,accept,unanimous_agreement
1032914549,10747,"please add a comment (""expecting at least start, end, count to follow"", right?)",0,0,0,0.983063280582428,0.9923082590103148,0.9942538142204284,0.0,accept,unanimous_agreement
1032915512,10747,"optional arguments are interchangeable, you shouldn't search for it only at the last argument. why not move it to the argument parsing? (where you already skip that arg anyway)",0,0,0,0.980715274810791,0.9850524067878724,0.9913390278816224,0.0,accept,unanimous_agreement
1032915852,10747,let's move all of that (and the lookupkey at the top of this function) to after the argument parsing. no sense in looking up the key if we have a syntax error.,0,0,0,0.5852980613708496,0.9894166588783264,0.9856845140457152,0.0,accept,unanimous_agreement
1032916219,10747,"the tests still has tabs in them, please change to spaces..",0,0,0,0.9832565188407898,0.953405737876892,0.9947939515113832,0.0,accept,unanimous_agreement
1032916401,10747,why do we need all these sleeps?,0,0,0,0.934072494506836,0.8881160020828247,0.6537155508995056,0.0,accept,unanimous_agreement
1048536023,10747,"i will address your comments in next a few days, sorry for that.",-1,-1,-1,0.988292157649994,0.992562472820282,0.9925294518470764,-1.0,accept,unanimous_agreement
1063563264,10747,"hi oran, i already update all code logic, the process will be first parse the argument, and then check the key, finally check the group. and also i fix all code styles, please check the latest codes, thanks for your hard working.",1,1,1,0.9741267561912536,0.8446252942085266,0.9846237301826476,1.0,accept,unanimous_agreement
1411393863,10747,adressed this comment when i updated [a link],0,0,0,0.9866418838500975,0.9781339764595032,0.9955872297286988,0.0,accept,unanimous_agreement
1411394199,10747,adressed this comment when i updated following comment [a link],0,0,0,0.9863415360450744,0.975969135761261,0.9955625534057616,0.0,accept,unanimous_agreement
1411394454,10747,added the comment when i updated [a link],0,0,0,0.9881978631019592,0.9886707067489624,0.9957594275474548,0.0,accept,unanimous_agreement
1411394908,10747,updated this when i changes are made for [a link],0,0,0,0.987975299358368,0.992155373096466,0.995236337184906,0.0,accept,unanimous_agreement
1411395562,10747,correcetd all intendation in the file.,0,0,0,0.9887592792510986,0.979022204875946,0.9958296418190002,0.0,accept,unanimous_agreement
646093479,8999,"i don't think `callback_refactor` is a good name (seems to match the current state of mine, but isn't good for long term). let's either call it `datatype2` (rename if we find a better name for the callbacks themselves too)",0,0,0,0.9677613973617554,0.975674569606781,0.9543282985687256,0.0,accept,unanimous_agreement
646094361,8999,"let's not use the term ""refactored"". maybe ""enhanced""? how about moving that whole block (casting to `modulevalue` and creating the `ctx` etc) to module.c? i.e. create a function that's responsible for calling the right callback, and also providing the right value (1) if there's no callback defined?",0,0,0,0.9865938425064088,0.9944663643836976,0.9895582795143129,0.0,accept,unanimous_agreement
646095462,8999,"i can't comment on a line with no change, but i see a call to `free_effort` a few lines above this one, i suppose it needs to be handled (call the alternative if defined)",0,0,0,0.9825602173805236,0.984248697757721,0.9930603504180908,0.0,accept,unanimous_agreement
646095833,8999,"i'd vote to move this (casing to `modulevalue`, selection between the different callbacks and creation of the context to module.c). i'd imagine it also means the new structs you probably defined in redis.h can move to modle.c too (make them a bit more opaque).",0,0,0,0.983755350112915,0.9896314740180968,0.9926435351371764,0.0,accept,unanimous_agreement
646096616,8999,"i suppose that we'd rather remove the key-name arguments from this function completely, and let the user get all the metadata from the context? that means the context should hold 2 database ids (a ""from"" and a ""to""). alternatively, if we don't wanna mess `redismodulekeyoptctx` with two key names and two database ids, we can let the new callback we define take only the ""from"" part (i.e. take `fromkey` and `fromdbid`), and let the user get the ""to"" part from the context. if we wanna be more explicit, then the new callback should take all 4 of these (two keynames, and 2 dbids), and let the context hold the ""to"" but be unused (keep a context for some future extension).",0,0,0,0.9834986329078674,0.9930930137634276,0.987820029258728,0.0,accept,unanimous_agreement
646096933,8999,what about `redismodule_getdbfrommodulekey`? let's add that one too,0,0,0,0.9876325130462646,0.9948785305023192,0.9950855374336244,0.0,accept,unanimous_agreement
646097098,8999,"the documentation in the top of this function needs to be extended, to mentioned the ""extended"" callbacks.",0,0,0,0.9881070852279664,0.990142583847046,0.9942658543586732,0.0,accept,unanimous_agreement
646097506,8999,"do we need this? (`redismodule_experimental_api`), if not, let's drop it.",0,0,0,0.9883481860160828,0.9950227737426758,0.9939038157463074,0.0,accept,unanimous_agreement
646097687,8999,"some people copy code from these tests, let's use rm_assert",0,0,0,0.9891358613967896,0.9836617112159728,0.9875614643096924,0.0,accept,unanimous_agreement
646098274,8999,let's use rm_assert instead (just to avoid people copying this code to their modules),0,0,0,0.985326647758484,0.9891457557678224,0.9917146563529968,0.0,accept,unanimous_agreement
646098923,8999,"don't / shouldn't we handle the ""copy_to"" with the copy callback? i.e. rely on keyspace notification only for move and rename, but not for copy.",0,0,0,0.9407017230987548,0.9940107464790344,0.99116313457489,0.0,accept,unanimous_agreement
646099225,8999,"maybe add a few more lines as to what exactly the module does (so it's easier to read the code). i.e. your comment says what it comes to test, but if there was some comment that describes what the module mimics, or how it operates, it'll be easier to understand the code.",0,0,0,0.98111754655838,0.9804574847221376,0.9916861653327942,0.0,accept,unanimous_agreement
646099998,8999,"maybe if we actually use these in the global data the test would make more sense, and also will be more useful (i.e. it'll use these strings instead of just checking for null, and have a chance to detect more bugs). i.e. each slot of your global db array hold a list of the keys we know it has (maybe use rm_createdict`) on the other hand, i don't want to complicate the test code too much (both for readability and your coding effort). so, please consider, but feel free to reject that idea.",0,0,0,0.8598647117614746,0.9287816286087036,0.9675195217132568,0.0,accept,unanimous_agreement
646100176,8999,"let's use rm_assert. i rather avoid people using `abort` in real modules, and want to prevent someone copying this to a real module.",0,0,0,0.8207131624221802,0.9871543645858764,0.9915665984153748,0.0,accept,unanimous_agreement
646223172,8999,we do need it because the api `subscribetokeyspaceevents` is currently in experimental apis.,0,0,0,0.9896458983421326,0.9898661971092224,0.993654727935791,0.0,accept,unanimous_agreement
646547807,8999,i am rewriting this test.,0,0,0,0.966598629951477,0.9435129761695862,0.9648083448410034,0.0,accept,unanimous_agreement
647091359,8999,"a suggestion: change to `getdbidfromio`, just like `getkeynamefromio`",0,0,0,0.9846727252006532,0.9932130575180054,0.994295299053192,0.0,accept,unanimous_agreement
647135932,8999,"okay, modified :)",1,1,0,0.9416689276695251,0.9923537969589232,0.9676328897476196,1.0,accept,majority_agreement
647526129,8999,"i think this text and / or diagram below can be improved to specify how this is related to keys in redis, and what is stored in global memory. when i read this i didn't understand it, and had to read the code to follow up. i.e. that there's an array of dictionaries in global memory, a dict per db id. in each dict the key is the key name (key that's also registered in redis as a key). it is clear from the diagram what the dict holds, but not entirely clear what's stored in the redis database. maybe it is sufficient to give the columns below a title. i.e. ""db id"", ""key name"", etc. and also state clearly what we store in the redis database per key.",0,0,0,0.9742446541786194,0.9744059443473816,0.9223812222480774,0.0,accept,unanimous_agreement
647533042,8999,why did you add these tags (`enhanced` and `callbacks`)?,0,0,0,0.9860668778419496,0.993871808052063,0.9946597218513488,0.0,accept,unanimous_agreement
647899520,8999,"i have added several diagrams to illustrate the correspondence between **redis key** and **mem pool**。 in short, the value stored in the redis dict is **memallocobject**, which records the meta-information of the mem pool, that is, `size` indicates that a total of several mem blocks are allocated, `used` indicates the number of used mem blocks, and `mask` indicates which mem block is occupied, is a bitmap.",0,0,0,0.985653042793274,0.9915646314620972,0.9853085875511168,0.0,accept,unanimous_agreement
1608348367,13285,the reason why we don't rewrite it as single command(max aof_rewrite_items_per_cmd item in one command) is that we don't support set the ttl for individual field now? it seems werid that we will generate three command if there are three fields with ttl after aof rewrite.,0,0,0,0.9858669638633728,0.9896734952926636,0.9891809821128844,0.0,accept,unanimous_agreement
1609656083,13285,i think we should avoid this style of comment in parameter.,0,0,0,0.9629035592079164,0.9687075018882751,0.9777937531471252,0.0,accept,unanimous_agreement
1609708521,13285,using `lpget()` which can get the buf at the same time? it will save the `ll2string()` below.,0,0,0,0.989730954170227,0.99482262134552,0.9940664768218994,0.0,accept,unanimous_agreement
1609751646,13285,why do we put these into executeunit?,0,0,0,0.9758384823799132,0.9819045662879944,0.9946797490119934,0.0,accept,unanimous_agreement
1609885684,13285,"the most problematic case is when all fields has different ttls. we can try optimize adjacent fields with same ttl. - yet, the iteration is not based on ttls.",0,0,0,0.947233498096466,0.7319636940956116,0.7957628965377808,0.0,accept,unanimous_agreement
1609897453,13285,bad copy paste of code (even though it makes no harm). thanks!,1,1,-1,0.8956764936447144,0.9127674102783204,0.9887182712554932,1.0,accept,majority_agreement
1611040440,13285,can this be put into randpath? i doubt why we need the `usehexpire` parameter?,0,0,0,0.9833745956420898,0.9905981421470642,0.9890310168266296,0.0,accept,unanimous_agreement
1611045005,13285,is it unnecessary?,0,0,0,0.9167554974555968,0.975268006324768,0.9745508432388306,0.0,accept,unanimous_agreement
1611141142,13285,blindly followed `useexpire`. removed. thanks.,1,1,1,0.8573222160339355,0.9315662980079652,0.9640769362449646,1.0,accept,unanimous_agreement
1611238808,13285,~~forget to *1000?~~ edit: missed the *1000 above.,0,0,0,0.7558065056800842,0.9804176092147828,0.9358446002006532,0.0,accept,unanimous_agreement
1611348776,13285,is it more readable to move these code that is executed for replication info if? like: [code block],0,0,0,0.9877734780311584,0.9938914775848388,0.9941408038139344,0.0,accept,unanimous_agreement
1611563217,13285,please consider my last commit,0,0,0,0.977851629257202,0.9798157215118408,0.9937076568603516,0.0,accept,unanimous_agreement
1612612148,13285,"if `o` was deleted from db in `hashtypegetvalue`, we will continue to use `o` after here. i think we should consider whether the propagate and deletion should be put in the `hashtypegetvalue`, maybe it should be up to the caller.",0,0,0,0.9884013533592224,0.9949512481689452,0.9903539419174194,0.0,accept,unanimous_agreement
1613005020,13285,yaacov says current decision is to delete hsetf and hgetf commands. we will hot have these commands. need to do this some other way.,0,0,0,0.9766538739204408,0.8772780299186707,0.9891194105148317,0.0,accept,unanimous_agreement
1613279596,13285,"11 ms is too short, i get a test failure here. the hpexpire* commands are all the same. [code block]",0,0,0,0.9122297763824464,0.7210700511932373,0.8290162086486816,0.0,accept,unanimous_agreement
1613338291,13285,you may add a test for this case,0,0,0,0.9862895011901855,0.9900952577590942,0.9956374764442444,0.0,accept,unanimous_agreement
1613968595,13285,"the comment may not be necessary. otherwise, please reword it, a bit hard to understand.",0,0,0,0.5930435061454773,0.7001953125,0.9600943326950072,0.0,accept,unanimous_agreement
1613977562,13285,"out of curiosity, why are we doing this? is it needed somewhere?",0,0,0,0.632171094417572,0.9634284377098083,0.9604995250701904,0.0,accept,unanimous_agreement
1615136257,13285,"perhaps this can be somehow optimized to include multiple expired fields in one key on a single `repl backlog` entry? obviously not for now, but maybe open a ticket for that (or whatever)",0,0,0,0.9862710237503052,0.9940834641456604,0.9849409461021424,0.0,accept,unanimous_agreement
1615136332,13285,nitpack: `listpac` -> `listpack`,0,0,0,0.9877657890319824,0.9936652183532716,0.9945567846298218,0.0,accept,unanimous_agreement
1615142418,13285,nice catch. only now i reach to make another iteration to refine the logic around it. i will fix it. thanks.,1,1,1,0.98285311460495,0.9941648840904236,0.9954591989517212,1.0,accept,unanimous_agreement
1615142760,13285,ok. the alternative is to send two commands of hset & hpexpire.,0,0,0,0.9879023432731628,0.990041434764862,0.994013249874115,0.0,accept,unanimous_agreement
1615145996,13285,"sure. as you are aware of these changes now, shall we merge this one: [a link]",0,0,0,0.963589370250702,0.9841671586036682,0.9930106997489928,0.0,accept,unanimous_agreement
1615180515,13285,"you mean, if all the fields got expired then we can discard the entire hash in a single command? if that so, then we need to iterate to the end of the hash and only then to decide whether to re-iterate and send multiple commands or a single command?",0,0,0,0.9866502285003662,0.9913309812545776,0.9880487322807312,0.0,accept,unanimous_agreement
1615181282,13285,"that is one option, but perhaps `hdel` can support deleting multiple keys, even if not the entire hash? but even so, maybe you can add `hdel` commands on the go and if you find out all the fields were expired, you can remove the hdel commands and add a `del` command for the key?",0,0,0,0.9888899326324464,0.993842363357544,0.9925198554992676,0.0,accept,unanimous_agreement
1615225328,13285,ok. i will mark it as todo.,0,0,0,0.9788368344306946,0.9444512128829956,0.9897626638412476,0.0,accept,unanimous_agreement
1615408187,13285,"hash length of 1 is not just due to expiry, it can also caused by some buggy commands or corrupted data, i think we should treat them differently.",0,0,0,0.9585153460502625,0.9529905915260316,0.9662761092185974,0.0,accept,unanimous_agreement
1615814843,13285,"i realize that we forget to check if `hashtypelength(o, 0)` returns 0, in this case, we should skip it and replicate to slave like `hashmd`.",0,0,0,0.9782042503356934,0.9906851649284364,0.9893413186073304,0.0,accept,unanimous_agreement
1615952114,13285,", i reviewed it again. i think it is harmless. please review it.",0,-1,1,0.8643553853034973,0.9153584837913512,0.9411041140556335,,review,no_majority_disagreement
1615952976,13285,adapted. thanks.,1,1,1,0.7947501540184021,0.9703031182289124,0.9686017036437988,1.0,accept,unanimous_agreement
1615954867,13285,"already have one. please see `test ""hpexpire(at) - test 'lt' flag ($type)""`",0,0,0,0.9805529713630676,0.9944684505462646,0.9950330257415771,0.0,accept,unanimous_agreement
1615960831,13285,"consider the case of `hincrby` of an expired field. it might increase an obsolete value. alternatively, the command can implement the logic of checking if the field is expired and make lazy-expiration before using it. in that case, it is better to have a common logic, similar to `lookupkey()` wrt. to keyspace. so this way `hashtypegetvalue()` ended up. please lmk if you have any comments.",0,0,0,0.9868974089622498,0.9932639598846436,0.98492693901062,0.0,accept,unanimous_agreement
1615968967,13285,fixed. thanks.,1,1,1,0.8936524391174316,0.9793950915336608,0.9658035039901732,1.0,accept,unanimous_agreement
1616124833,13285,"maybe you just need to two versions of `hashtypegetvalue()`. one might expire, other one doesn't. call it depending on the use case. i just have one concern, it increases corner cases a lot. for example, currently, in hmgetcommand(): [code block] `addhashfieldtoreply()` will call `hashtypegetvalue()`. it might expire the key itself. then `o` will be dangling pointer in the loop. i see there is a similar problem for `hsetnxcommand()` as well. maybe we should selectively call `hashtypegetvalue()` version that expires key. so, you caller knows the danger.",0,0,0,0.9596530795097352,0.9862200021743774,0.961463451385498,0.0,accept,unanimous_agreement
1616140847,13285,maybe just to propagate the `getfieldres` by function `addhashfieldtoreply()` as well.,0,0,0,0.9885087609291076,0.9941012263298036,0.9872590899467468,0.0,accept,unanimous_agreement
1616141435,13285,"just a note to all of us, maybe we can implement this logic with lpfindcb() in future to avoid performance cost of lpnext() calls.",0,0,0,0.9836496114730836,0.9928781390190125,0.9849629998207092,0.0,accept,unanimous_agreement
1616496999,13285,"i still worried about wether this code will cause some performance problems, if we don't handle it in this pr, please add a note in the top comment to avoid forgetting it.",-1,-1,-1,0.942105770111084,0.7315046191215515,0.9428992867469788,-1.0,accept,unanimous_agreement
1616515101,13285,"if i use `hexpire` command to create a hash with ttl fields, then operate the hash with `rm_hashset`, will thia assertion be triggered?",0,0,0,0.9899865984916688,0.9954882264137268,0.9941896200180054,0.0,accept,unanimous_agreement
1616516017,13285,what aboult making them in single `if`?,0,0,0,0.9305992722511292,0.896518886089325,0.9883434176445008,0.0,accept,unanimous_agreement
1616520612,13285,this will create a empty hash if enter the `if` below: [code block],0,0,0,0.9879955649375916,0.9932880997657776,0.9959139227867126,0.0,accept,unanimous_agreement
1616520896,13285,here is the same.,0,0,0,0.9813848733901978,0.9910105466842652,0.9926486611366272,0.0,accept,unanimous_agreement
1616538023,13285,"yes, it's harmless but it's also nop, we only do the `alsopropagate` here, and we don't notify any event to module or process any other commands. please point out if i'm wrong.",0,-1,0,0.904998540878296,0.682296872138977,0.9860647916793824,0.0,accept,majority_agreement
1616606974,13285,"i just seems like most of the time we don't need to expire fields. so, i thought it might be simpler to avoid it as much as possible. just consider if this is the case.",0,0,0,0.9161214232444764,0.9523871541023254,0.9806148409843444,0.0,accept,unanimous_agreement
1616671783,13285,"can it return here if oldvalue is zero though? it seems like, this logic was same even before this pr. i agree it looks a bit obsecure.",0,0,0,0.919265866279602,0.7996963262557983,0.9519091248512268,0.0,accept,unanimous_agreement
1616694111,13285,"ohh, you're right, it won't enter the overflow when oldvalue is 0. ~~but it's still a bug that's been around for a while.~~",0,0,0,0.4975147545337677,0.6610441207885742,0.8961600065231323,0.0,accept,unanimous_agreement
1616733212,13285,it can be invoked either by the activeexpirecycle() cron job or through an actual query from the client.,0,0,0,0.9880867004394532,0.9944090247154236,0.9944668412208556,0.0,accept,unanimous_agreement
1616755188,13285,"i can't reproduce it yet, mark as resolved.",0,0,0,0.9739884734153748,0.9736560583114624,0.987864077091217,0.0,accept,unanimous_agreement
1616760443,13285,i think we shouldn't swip it under the rug. there is an added value that everything is one place and it is reflected in the api. maybe we can have wrapper functions that simplifies it. similar to the approach of `lookupkey()` family,0,0,0,0.9763002395629884,0.9665880799293518,0.973603904247284,0.0,accept,unanimous_agreement
1616764140,13285,"ok, let's leave it as now.",0,0,0,0.9795422554016112,0.9868693947792052,0.9875794053077698,0.0,accept,unanimous_agreement
1616790297,13285,"note: later, maybe we can add a check to avoid creating these objects if we are not going to propagate anything.",0,0,0,0.9801165461540222,0.98221093416214,0.9888877272605896,0.0,accept,unanimous_agreement
1616800286,13285,"actually i also have the feeling as ozan, if `o` is implicitly deleted in `hashtypegetvalue`, the caller will need to know the detail implement of `hashtypegetvalue` or need to read the comment for it, otherwise, it's dangerous.",-1,0,0,0.5354007482528687,0.8351039290428162,0.9060127139091492,0.0,accept,majority_agreement
1616831010,13285,"regarding this matter, i am seeking input from those experienced with modules: - we likely need to pass the mode/flags of the opened key and respond appropriately. - should we update the opened key if the key was deleted due to last field expiration? , perhaps you can assist. thanks.",1,1,1,0.9037182331085204,0.852212131023407,0.9617958068847656,1.0,accept,unanimous_agreement
1616873862,13285,in this file there are more spaces after comma. therefore i think we should strive to push spaces.... until we shall have code styling convetnion.,0,0,0,0.9683104753494264,0.9275032877922058,0.9851022958755492,0.0,accept,unanimous_agreement
1616877352,13285,"we have two styles, a comma followed by a space, and one without, but not mixing the two styles in a function call looks miserable.",-1,-1,-1,0.9823992252349854,0.9789061546325684,0.9914753437042236,-1.0,accept,unanimous_agreement
1153582811,11982,"the safe thing to do here might be to also update `rm_alloc`, `rm_calloc`, etc. to do an `extend_to_usable` so that only the usable size is seen at all times. however, afaict the redismodule functions don't show themselves as allocators (i.e. no `alloc_size` attribute) so they're unlikely to trip over this.",0,0,0,0.98423033952713,0.9943963289260864,0.9899510741233826,0.0,accept,unanimous_agreement
1155318646,11982,let's add a big comment here describing the problem and how it's solved.,0,0,0,0.9842118620872498,0.9663466811180116,0.993586242198944,0.0,accept,unanimous_agreement
1155320794,11982,"correct me if i'm wrong, since this function only takes `ptr` as input, and the caller doesn't use any returning pointer, then the compiler won't care about anything we do with the pointer here. regarding your comment about rm_alloc, these functions use functions that do have the attribute down the line, so in theory the compiler could have still kept track of the allocation size. so what's preventing that is the fact that it's used in a different module, right? i.e. if redis would have used rm_alloc internally it will be vulnerable. i agree, let's fox rm_alloc and rm_realloc and add the attribute to them, so that if the module uses rm_mallocusablesize it'll be protected.",0,0,0,0.8325877785682678,0.8919682502746582,0.928863286972046,0.0,accept,unanimous_agreement
1155329177,11982,"that comment was a little bit unclear to me at first, so let me start from the beginning. we currently have two patterns in the code: 1. calling a plain `zmalloc` or `zrealloc` and then calling `zmalloc_usable_size` and using that memory. 2. calling `zmalloc_usable` and using the size it returns. most of the places can be converted to use approach [2] as you did, and we need to avoid using [1] if we can. it would have been nice to completely obliterate zmalloc_usable_size, but since we can't we need to document that anyone who uses it needs to also call extend_to_usable manually. let's document that in zmalloc.h, and also as you did here (no `todo:` though, and no zmalloc_usable_size_safe which i suggest to drop, see other comment)",0,0,0,0.8839583992958069,0.9740183353424072,0.9631487727165222,0.0,accept,unanimous_agreement
1155329580,11982,"we already have too many allocation functions, and i'd like to avoid adding the `safe` option. what i'd suggest to do instead is: 1. rename the current `z[try]malloc_usable` family to `z[try]malloc_internal` and don't expose them to users outside zmalloc.c 2. expose a new set of `zmalloc_usable` family that use `zmalloc_internal` and `extend_to_usable` implicitly. 3. go over all the users of `zmalloc_usable_size` and convert them to use the `zmalloc_usable` family if possible (as i think you did). 4. drop `zmalloc_usable_size_safe`, i don't like to pass a reference to a pointer, don't know if the caller kept the original somewhere, i'd rather have the `malloc` or `realloc` approach that returns it.",0,0,0,0.9530860781669616,0.9906244874000548,0.9899820685386658,0.0,accept,unanimous_agreement
1155330372,11982,"imho this is what we should do: 1. eliminate zmalloc_usable_size_safe (it's odd, and doesn't really help here). 2. add the malloc_size attribute to rm_alloc and rm_realloc, rm_tryalloc, rm_calloc 3. since we can't change the semantics of rm_mallocusablesize and document how it should be used (i.e. together with extend_to_usable, what we should do is make sure rm_alloc family uses extend_to_usable or better yet zmalloc_usable internally before returning the pointer to the module (and add some comment explaining it)",0,0,0,0.969944417476654,0.9850362539291382,0.9170584678649902,0.0,accept,unanimous_agreement
1155687498,11982,let's add a comment inside the implementation (of just this function) to explain why it uses zmalloc_usable and not a plain zmalloc (i.e. so that it's surely safe for modules to use the memory rm_mallocusablesize tells them they can use. let's also add a comment in rm_mallocusablesize referring to this comment.,0,0,0,0.987949013710022,0.99337500333786,0.993867576122284,0.0,accept,unanimous_agreement
1155689607,11982,"let's give the module control this attribute from outside (if it'll ever be needed), by following the footsteps of redismodule_attr_printf",0,0,0,0.987885355949402,0.992846667766571,0.9932194352149964,0.0,accept,unanimous_agreement
1155711598,11982,there's no point in calling extend_to_usable here. we don't return the pointer to the caller.,0,0,0,0.8792474269866943,0.9864060282707214,0.9767006039619446,0.0,accept,unanimous_agreement
1155784044,11982,i see you reverted all changes in listpack. don't we need to use zmalloc_usable in listpack_malloc.h (and some comment explaining it)? i.e. same as we did in module.c,0,0,0,0.974380910396576,0.9932215213775636,0.9886375069618224,0.0,accept,unanimous_agreement
1155844688,11982,"yes, because i made `zmalloc_usable_size()` safe, and i think `lp_malloc_size()` will be called much less frequently than malloc/realloc in listpack. do you mean we should avoid approach [2] ultimately? i'll modify it, i need to benchmark them.",0,0,0,0.98145592212677,0.9820928573608398,0.9908992052078248,0.0,accept,unanimous_agreement
1155895107,11982,"i don't think you made it safe, see my comment [a link] i'm not sure we can use approach [2] in listpack, it would mean that listpack needs to save the size somewhere. so i think listpack can keep using approach [1], but it still needs to make sure to use zmalloc_usable (a wrapper of it), or any other way so that the pointer it works with is one that was returned by the dummy realloc.",0,0,0,0.950592577457428,0.9678011536598206,0.9847750067710876,0.0,accept,unanimous_agreement
1155942606,11982,done with adding redismodule_attr_alloc in [a link],0,0,0,0.9892849326133728,0.9870412349700928,0.9956843852996826,0.0,accept,unanimous_agreement
1155943243,11982,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1155947122,11982,done in [a link],0,0,0,0.9885184168815612,0.9881112575531006,0.9955646991729736,0.0,accept,unanimous_agreement
1155957379,11982,"sorry i probably don't understand this change fully, but it looks like it exposes the allocator interface in modules as being standard allocators using `alloc_size`, is that correct? if yes, then this may end up exposing the extra space usage problem to users of modules too, i.e. user applications may request `x` bytes and `redismodule_mallocusablesize` may return `x+n` bytes available, thus resulting in the breakage externally.",-1,-1,-1,0.9853261709213256,0.9514955282211304,0.9672966003417968,-1.0,accept,unanimous_agreement
1155978319,11982,this basically prevents the compiler from seeing the allocations altogether.,0,0,0,0.9813971519470216,0.9188646674156188,0.9923698902130128,0.0,accept,unanimous_agreement
1155992769,11982,move this comment to inside the function (should not be part of the docs),0,0,0,0.9883819222450256,0.991614580154419,0.9944398403167723,0.0,accept,unanimous_agreement
1155995650,11982,please figure out how standard this attribute is. and if standard enough let's remove the `__gnuc__` check (just use the `ifndef` so that users can override it from outside.,0,0,0,0.9871188402175904,0.9945163130760192,0.9945023059844972,0.0,accept,unanimous_agreement
1156001734,11982,"i was thinking of a macro or an inline function that adds `null` so that we don't need to change the lines who call this. another thing i was wondering was maybe to completely eliminate this file (i.e. now that listpack is just a plain part of redis, and not an external library, it can directly use zmalloc). but then, maybe we won't have a good place to put this comment in, so maybe keep this file, but use the macro i suggested above?",0,0,0,0.925017476081848,0.9781895279884338,0.9740833640098572,0.0,accept,unanimous_agreement
1156015161,11982,"ohh, you're right. for some reason i thought that since we change the implementation to use the dummy realloc, we can expose the alloc_size tip to the compiler, but that's actually wrong. i.e. when the module is compiled, the compiler isn't aware of what we did inside redis, and all it sees is the requested size, allowing it to do fortification which would break. please drop these attributes. i think we can keep the other change to module.c though, and use malloc_usable. it would mean that for modules that are statically linked with redis (e.g. our tls module), using rm_mallocusablesize will be safe. [edit] actually, maybe that's irrelevant since modules use the module api via a set of global variable function pointers?",0,0,0,0.9013871550559998,0.7849732637405396,0.7645171880722046,0.0,accept,unanimous_agreement
1156017121,11982,"actually, following the discussion in [a link] we must drop these attributes.",0,0,0,0.9848543405532836,0.9926422238349916,0.9920774102211,0.0,accept,unanimous_agreement
1156074582,11982,"but we use `zmalloc_usable_internal()` internally, which uses these attributes, and the compiler ends up seeing the size that contains the extra memory, is there a problem with that?",0,0,0,0.9836422204971312,0.9705384969711304,0.9916369318962096,0.0,accept,unanimous_agreement
1156094928,11982,"this set of apis internally call extend_to_usable, which will tell the compiler what's the right size. adding the attribute here would mean the compiler sees the requested size rather than the allocated one.",0,0,0,0.9889426231384276,0.991893708705902,0.9932739734649658,0.0,accept,unanimous_agreement
1156103266,11982,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1156103432,11982,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1156103641,11982,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
1156136263,11982,"basically the allocated size (and the allocation itself) never really escapes these interfaces unless the functions get inlined (e.g. with lto). as a result, fortification may not happen at all for calls to these functions if lto is not enabled. so it might make sense to also test with lto to be sure that everything is covered.",0,0,0,0.9835919141769408,0.9908888339996338,0.990997552871704,0.0,accept,unanimous_agreement
1156221622,11982,"we do test with lto nowadays (enabled for all out builds in our dev branch and next release, but not in the previous one, in which the problem was uncovered), but i don't think we have any ci that uses the latest compiler (the one in which the problem was uncovered). maybe we can add a ci job for that. regarding the actual change (dropping the attribute from the zmalloc interface), what do you suggest? keeping it while the fix that uses the dummy realloc internal to it, would make the fix ineffective (the complier will see the requested size). so the only other option is for the code that uses the allocation to directly use the dummy realloc.. i think we can keep the current code, and maybe add ci with bleeding edge compiler.",0,0,0,0.9758635759353638,0.9786776304244996,0.9881060123443604,0.0,accept,unanimous_agreement
1156303208,11982,"right, that's the only other option, which i reckon will increase the number of calls to the dummy allocator. i hope to get rid of that overhead in a future gcc and hopefully clang will fix that too.",0,0,0,0.9279460310935974,0.926417112350464,0.982792317867279,0.0,accept,unanimous_agreement
1161588906,11982,"maybe that attribute should move to the public interface? or maybe not because it'll mean we have to add it to several of them? if we do that (move it), it'll also assist fortification without lto. i have a feeling we already discussed it, but wanted to raise it again.",0,0,0,0.9542860984802246,0.9738301634788512,0.9807784557342528,0.0,accept,unanimous_agreement
1161611453,11982,"do you mean to add it to `z[*]_usable`? if so `extend_to_usable()` will be useless, the compiler will only see the size passed by `z[*]_usable`.",0,0,0,0.9888579845428468,0.9937200546264648,0.9943479895591736,0.0,accept,unanimous_agreement
1161622245,11982,"no, i mean to add it to all the other zmalloc functions (excluding the `_usable` one) i suppose that's more or less what happens today due to lto (the compiler will see the attribute to the inner function)",0,0,0,0.9866503477096558,0.9899222254753112,0.9924412965774536,0.0,accept,unanimous_agreement
1161678136,11982,"your question led me to a bug, in any case, `ztrymalloc_usable_internal()` should not be inlined anyway, otherwise alloc_size attribute will not work. so the attribute of ztrymalloc_usable_internal should be moved outside.",0,0,0,0.9787738919258118,0.9869399666786194,0.992749571800232,0.0,accept,unanimous_agreement
1161690598,11982,fully ci: [a link],0,0,0,0.9862918257713318,0.9342020750045776,0.9890276193618774,0.0,accept,unanimous_agreement
1161766724,11982,"ok, great.. and the fact it exposed an warning is an indication that it works better... i suppose that if we want better fortification we can also mark them as `noinline`, but i suppose it's better to just leave it for the compiler (once [a link] will be solved). i.e. unlike the case of `extend_to_usable` in which we must work around that bug. so i suppose this is ready to be merged once your ci passes. meanwhile, you can prepare the other pr with the extra ci and the compilation fixes..",1,1,1,0.967047154903412,0.8997147083282471,0.7231860756874084,1.0,accept,unanimous_agreement
1161773556,11982,"i'm not sure if noinline will bring performance impact, i need benchmark. i'll do other thing.",0,-1,-1,0.7367539405822754,0.5432650446891785,0.5651129484176636,-1.0,accept,majority_agreement
1161828898,11982,"i don't think it'll bring any impact, but i suppose we shouldn't take any action here and just let the compiler do it's thing. if the compiler is currently limited, let it be.. i assume by ""other thing"" you mean the ci pr... not any change to the code in this one..",0,0,0,0.9425510168075562,0.9422907829284668,0.8507324457168579,0.0,accept,unanimous_agreement
1650293296,13359,why it can't support non-x86? it seems that gcc and clang are all support __builtin_popcountll().,0,0,0,0.9860659241676332,0.9885768294334412,0.9850698709487916,0.0,accept,unanimous_agreement
1650295441,13359,"i'm not sure whether it can make performance boost on arm or risc-v, i add macro just for safety. is it a little bit aggressive to instead all origin algorithm?",0,0,0,0.5979980826377869,0.812663197517395,0.8775026798248291,0.0,accept,unanimous_agreement
1650298954,13359,"yes, we need more benchmark on all the architectures, we can replace the origin algorithm if it make performance boost in all architectures.",0,0,0,0.9801472425460817,0.9859857559204102,0.9920733571052552,0.0,accept,unanimous_agreement
1650301097,13359,i would trust gcc to use the fastest method. if the compiler is new enough to use __builtin_popcountll then it will use an instruction if possible. if not then it will use some optimized algorithm.,0,0,0,0.9582685232162476,0.9902210235595704,0.9875754117965698,0.0,accept,unanimous_agreement
1765976679,13359,we need to align p to 8 bytes here. [code block],0,0,0,0.9869576692581176,0.992952287197113,0.9952486157417296,0.0,accept,unanimous_agreement
1766203487,13359,what about expand them directly? [code block],0,0,0,0.9882450103759766,0.9936590790748596,0.995086133480072,0.0,accept,unanimous_agreement
1768040327,13359,"what about replacing it by using `#if defined(__x86_64__)`? or as did in #13558, then put it in the config.h [code block]",0,0,0,0.9893458485603333,0.9955068826675416,0.9951823353767396,0.0,accept,unanimous_agreement
1768051739,13359,"sure, #13558 is a more accurate way. i will change like that.",0,0,0,0.6482092142105103,0.959520161151886,0.98491108417511,0.0,accept,unanimous_agreement
1769873395,13359,"that's the same lookup table as below, let's share it. maybe instead of introducing two different functions, this single function can have two branches. iiuc it's the same algorithm, and the only difference is less loops using a specific instruction..",0,0,0,0.9703848361968994,0.915263533592224,0.9906378984451294,0.0,accept,unanimous_agreement
1769895230,13359,"i don't think we need this one, i think we can rely on `__builtin_cpu_supports` (which i assume will be optimized at compile time in case the compiler is sure about the outcome). maybe someone can validate that?",0,0,0,0.9835808277130128,0.9833018183708192,0.9881318807601928,0.0,accept,unanimous_agreement
1770345849,13359,"do agree. we have to have two functions, because we need `__builtin_cpu_supports()` to decide which one to use.",0,0,0,0.9816694855690002,0.9859945774078368,0.9852116107940674,0.0,accept,unanimous_agreement
1770425236,13359,"we can do it in one function as well. the optimized part can be an early exist that's inside an `if` and maybe an `#if`. but since it's the same algorithm, and the same lut, i think it'll be cleaner.",0,0,0,0.9829235672950744,0.9806333184242249,0.9878439903259276,0.0,accept,unanimous_agreement
1770522341,13359,done with [a link].,0,0,0,0.988278329372406,0.9842276573181152,0.9958213567733764,0.0,accept,unanimous_agreement
1770524926,13359,please take a look.,0,0,0,0.9707372188568116,0.9245522022247314,0.965773344039917,0.0,accept,unanimous_agreement
1770538384,13359,"by using an early exit flow in the optimal path, we can avoid indentation and blamelog changes to the existing lines.",0,0,0,0.9818798303604126,0.9922006726264954,0.9904515743255616,0.0,accept,unanimous_agreement
1770550661,13359,done with [a link],0,0,0,0.9886857271194458,0.9809236526489258,0.9957758784294128,0.0,accept,unanimous_agreement
1770578554,13359,"maybe you already discussed it, i don't see it being mentioned. why do we process more than one __builtin_popcountll in the loop? trying to hit a simd optimization?",0,0,0,0.973967671394348,0.7379648685455322,0.982554018497467,0.0,accept,unanimous_agreement
1770579349,13359,"i.e. in the original code, i suppose we handled 28 bytes, in less than 28 operations, and avoided overflows in with bitmasks and shifts. but here it just looks like loop unrolling, into different variables and summing at the end, so i assume there's some intention here, lets mention it in the comment.",0,0,0,0.9837270975112916,0.9877635836601256,0.9895610809326172,0.0,accept,unanimous_agreement
1770721447,13359,"answer is here: [a link] the bottom line is to reduce the latency caused by bits accumulation (it takes two instructions to add and assign), and to use `cnt` to avoid dependencies between the four lines of code.",0,0,0,0.9878163933753968,0.9944292306900024,0.9931789636611938,0.0,accept,unanimous_agreement
1770732427,13359,agree. this way seems concise.,0,0,0,0.968076229095459,0.9640154838562012,0.9510474801063538,0.0,accept,unanimous_agreement
1770776720,13359,so maybe explain it in a short comment?,0,0,0,0.9754505157470704,0.9889857769012452,0.991960108280182,0.0,accept,unanimous_agreement
1770848322,13359,do you want me to do it?,0,0,0,0.9802026748657228,0.9785609245300292,0.9849613904953004,0.0,accept,unanimous_agreement
1774763020,13359,"sure, thanks, a bit busy these days",1,1,0,0.7953012585639954,0.9327147603034972,0.8391804695129395,1.0,accept,majority_agreement
1774766647,13359,"no matter, i had done it, please see if you have anything to add.",0,0,0,0.97099506855011,0.9724527597427368,0.8601068258285522,0.0,accept,unanimous_agreement
530571538,8094,"isn't latitude related to height and longitude to width, as per: ![a link] ----- on a second comment: wdyt about fixing ( if you agree on the lat/long discussion above ) and replacing: [code block] by: [code block] it will cut the computation by half on that function. ps (as a bonus): can we also ensure constant correcteness of longitude,latitude,height, and width.",0,0,0,0.6071857213973999,0.8912476301193237,0.9923835396766664,0.0,accept,unanimous_agreement
530572930,8094,"given that `geohashestimatestepsbyradius` will return an higher number of steps for small distances, isn't it enough to use as input for `rectangle_type` the minimum of width and height?",0,0,0,0.9858866930007936,0.9936577677726746,0.9920957684516908,0.0,accept,unanimous_agreement
530597235,8094,you can union these two so that it saves a little bit of memory. it'll fit in a cache line then.,0,0,0,0.9836773872375488,0.9857762455940248,0.9915000796318054,0.0,accept,unanimous_agreement
530598402,8094,"since we are already introducing a new command. maybe the one above it should be geobboxstore and this one is just geobbox? it's a little different from georadius, but it fits better with zunionstore type commands. it should also probably have the use-memory flag, since it uses memory.",0,0,0,0.9855687022209167,0.9903557300567628,0.9871663451194764,0.0,accept,unanimous_agreement
530718188,8094,"i agree with you. this is my mistake, thank you.",-1,1,1,0.7939711809158325,0.9839613437652588,0.7411789894104004,1.0,accept,majority_agreement
530731907,8094,"i think the longest radius in rectangle (or other shapes) should be chosen. for example, width=200km, height=1km, if steps are calculated according to height, the black area will miss the search. ![a link]",0,0,0,0.9315170049667358,0.9807376265525818,0.9732980728149414,0.0,accept,unanimous_agreement
530988324,8094,"if we look at the `geohashestimatestepsbyradius()` code we see that the smaller the difference the larger the steps ( meaning precision ). if i understood correctly this function is not changing ranges of search but only increasing/decreasing precision based on distance. if we agree on that, then using the smallest distance should be enough. wdyt? [code block]",0,0,0,0.9821403622627258,0.9632279872894288,0.9893115162849426,0.0,accept,unanimous_agreement
531006011,8094,"let's focused on a case: after compiling with the current code, execute the following command, can find the result [code block] next modify the code, compile and restart redis [code block] execute the same query again: [code block] will not find test",0,0,0,0.983117938041687,0.988587200641632,0.9920181632041932,0.0,accept,unanimous_agreement
532522217,8094,needs to be updated.,0,0,0,0.9396960139274596,0.9780574440956116,0.9946845173835754,0.0,accept,unanimous_agreement
532523159,8094,"given that this performs radius and box search, it should be called something else, e.g. geoappendifwithinshape",0,0,0,0.985542058944702,0.9949609041213988,0.9932780861854552,0.0,accept,unanimous_agreement
532526567,8094,please add inline comment descriptions,0,0,0,0.98398756980896,0.9878371953964232,0.9946820139884948,0.0,accept,unanimous_agreement
533070386,8094,"thanks, already updated.",1,1,1,0.550837516784668,0.7509425282478333,0.7648113965988159,1.0,accept,unanimous_agreement
533071819,8094,"thanks for your review. the `use-memory` flag has been added, and i think `georadius` and `georadiusbymember` are also needed, so i added it by the way. about command name, i think using `_ro` at the end can be consistent with georadius, which is more user-friendly. (geo's user) wdyt?",1,1,1,0.7591677904129028,0.9642966985702516,0.9617799520492554,1.0,accept,unanimous_agreement
533186385,8094,"yeah, the _ro is what i'm thinking too despite the lack of beauty in it.",0,0,0,0.8839522004127502,0.5658032298088074,0.8764732480049133,0.0,accept,unanimous_agreement
533747052,8094,"these commands with an optional store argument are causing a lot of pain (it's hard to flag them as write or read commands, and it's hard to extract the key names from the arguments). i much rather find an opportunity to deprecate the existing ones (and sort) and create new ones that are similar to sunion/sunionstore (i.e. there are specific variants that are always store or non-store). so while at that subject (of deprecating things), i would like to suggest the following: * `geofind src_key ...` * `geofindstore dest_key src_key ... [storedist]` the rest of the arguments for both are: `longitude latitude width height m|km|ft|mi box|round [bymember member] [withcoord] [withdist] [withhash] [count count] [asc|desc]` meaning: 1. we only have two commands, one that always stores, and one that never stores. instead of the 4 commands we already have, and the 4 we were going to add. 2. the store variant can either store the results, or the dist (same as the original commands had both store and storedist arguments), but the key name is in a fixed position and easy to extract from the command arguments. 3. the commands have a bymember optional argument (instead of the specific command variant for that) 4. both commands take center long/lat and width/height, and the width/height can either define a rectangle, or an ellipse (or a circle if width==height). if we can agree on that, we can summon others for additional discussion / approval. (haven't yet reviewed the code, but i imagine all these commands are sharing a lot of the code anyway, so splitting them into different commands or unifying them doesn't matter much to the implementation)",-1,0,-1,0.9273416996002196,0.8701956868171692,0.8688437938690186,-1.0,accept,majority_agreement
533835116,8094,"+1 to deprecation and new command. however, shouldn't by member use the member instead of a provided lat/long? i also think it's worth separating out the notion of a circle and doing by radius. the last nit is that i would do geosearch instead, to me find just means find 1. [code block]",0,0,0,0.9110597372055054,0.9768276214599608,0.988155722618103,0.0,accept,unanimous_agreement
533871107,8094,"thanks for your suggestion, i agree with `geosearch` and `geosearchstore`: [code block] ps: - `frommember` and` fromloc` cannot exist at the same time and one must exist - `byradius` and `bybox` are the same as above. - although new syntax has been added, we need to be compatible and reuse the previous code as much as possible.",1,1,1,0.8226839303970337,0.7830755710601807,0.9553501605987548,1.0,accept,unanimous_agreement
533931341,8094,"sounds good to me. so if we go that way we don't have to support ellipse (single radius). i guess we can add both horizontal and vertical radius, but i don't think that's needed. also, this syntax allows extending it in the future, like supporting non-axis-aligned bounding box too.",1,1,1,0.9329822659492492,0.6879621148109436,0.8256988525390625,1.0,accept,unanimous_agreement
533935182,8094,feels odd to have this discussion inside a pr review comment. i'll move it to the [a link] (which has more watchers too):,-1,-1,-1,0.9672864675521852,0.9429031610488892,0.9653747081756592,-1.0,accept,unanimous_agreement
535915218,8094,geosearch/geosearchstore has been added.,0,0,0,0.987799882888794,0.9935142993927002,0.9921720027923584,0.0,accept,unanimous_agreement
535915875,8094,"thanks, has been updated in geosearch/geosearchstore, please review when you have time",1,1,1,0.6805130243301392,0.849387526512146,0.8766390085220337,1.0,accept,unanimous_agreement
537034312,8094,"considering the order or arguments in geohashgetdistanceifinradius (radius is last), i guess we want to move the `bounds` to be last (and maybe rename it to `rectangle` so it's clear what needs to be inside what)",0,0,0,0.9855395555496216,0.9929561614990234,0.9919095635414124,0.0,accept,unanimous_agreement
537034776,8094,is this what you meant? [code block],0,0,0,0.9853174090385436,0.9918136596679688,0.9958367347717284,0.0,accept,unanimous_agreement
537035335,8094,"this function needs to be renamed (no longer specific for ""radius""). don't forget to edit the top comment too",0,0,0,0.9768165946006776,0.9863038659095764,0.995834231376648,0.0,accept,unanimous_agreement
537040036,8094,1. don't we need to use w/2 and h/2 (instead of full width and height)? 2. let's move the multiplication with shape->conversion to be done after in a separate line (will make it more readable).,0,0,0,0.9842970967292786,0.9940539002418518,0.9906501770019532,0.0,accept,unanimous_agreement
537040327,8094,"if i'm not mistaken the definition of ""radius"" here seems to be different compared to the one in geohashgetdistanceifinrectangle. i.e. is the circle is bound by the box, or the box bound by the circle? (which one is inside the other). is that on purpose? (i didn't think much into it yet)",0,0,0,0.9730117917060852,0.9824563264846802,0.9737691283226012,0.0,accept,unanimous_agreement
537040973,8094,comment needs an update,0,0,0,0.9839215278625488,0.9829086065292358,0.9935085773468018,0.0,accept,unanimous_agreement
537042701,8094,"these should probably not be called ""width"" and ""height"". at least in the case of circular, their's w/2 and h/2. which also indicates that in case of box you have a bug here (adding full width to the right and full width to the left)",0,0,0,0.9831855297088624,0.9802156090736388,0.9893617033958436,0.0,accept,unanimous_agreement
537044731,8094,"considering that this function can convert a box into a box. we better add some comment (here or at the top) that explains the complication (i suppose converting from meters to long/lat, but maybe that's not the whole story).",0,0,0,0.981927454471588,0.991467833518982,0.98786199092865,0.0,accept,unanimous_agreement
537045769,8094,"why do we have both width and height and also bounds? maybe i'm missing something, in which case it would better be described in a comment.",0,0,0,0.9246960878372192,0.9625455141067504,0.9754873514175416,0.0,accept,unanimous_agreement
537046251,8094,i would rather return a syntax error if `store` present in when geosearch is set. p.s. please avoid line comments (`//`),0,0,0,0.98579341173172,0.9934242963790894,0.992658793926239,0.0,accept,unanimous_agreement
537048573,8094,"this isn't enough. you'll only get here if you one one extra argument left to parse. i.e. geosearchstore...storedist won't work if storedist is the last argument. and also, you have an excess `i++` here. i think it would be better to have the original ""store"" and ""storedist"" arguments be excluded when geosearch is set, and have a separate ""storedist"" case for the geosearch case.",0,0,0,0.9717312455177308,0.9633184671401978,0.9282765984535216,0.0,accept,unanimous_agreement
537049286,8094,this is a bit confusing. maybe we better split this block into two blocks (one for fromxxx and one for byxxx)?,-1,-1,-1,0.9354954361915588,0.9419528245925904,0.7516838312149048,-1.0,accept,unanimous_agreement
537052262,8094,"i think i would have rather to leave the original `extractdistanceorreply` intact instead of what you did which was copy the majority of the code out of it (and repeat it 3 times), i suppose so that you can re-use just the conversion part for the 4th place. i.e. i vote to restore the original extractdistanceorreply (to be used in 3 places), and add a similar extractboxorreply (to be used once, and clear out some of the clutter from the ""bybox"" portion.",0,0,0,0.981599509716034,0.9893436431884766,0.9751526117324828,0.0,accept,unanimous_agreement
537270346,8094,"ohh, maybe i'm wrong. i thought x1,y1,x2,y2 define a second box (to be matched against `bounds`). but that indeed doesn't make sense. from your comment i understand that x1,y1 define the center of the box (or circle in the radius counterpart). and that x2,y2 define the point to be searched. please rename these and / or add comments to make it clear (in both radius and rectangle variants)",-1,0,0,0.5348740220069885,0.8328579068183899,0.911501169204712,0.0,accept,majority_agreement
537323168,8094,"considering that `bounds` is a cache, we can either completely eliminate it (whoever needs it can re-compute it on the spot, so that the geoshape struct only contains the needed data to specify the shape. i.e. having a cache is a redundant (duplicate) info that is hard to tell if updated or not. or alternatively at least move it to serve the radius too. but also, i don't like the fact it's an array of 4 elements (hard to tell which ones is x and which ones are y), so more comments are needed to document its purpose and meaning.",-1,0,0,0.9093150496482848,0.9125595688819884,0.6578633785247803,0.0,accept,majority_agreement
537324952,8094,"clarification, the reason i gave this comment is because of the `sqrt` above. which computes a radius of a box that bounds the shape's box. but maybe that sqrt was just a bug.",0,0,0,0.923416554927826,0.9807604551315308,0.9894380569458008,0.0,accept,unanimous_agreement
537510896,8094,"so this method returns the ""distance to be used"", and also optionally returns the raw data (raw radius and raw conversion)? top comment needs to be updated. i see we no longer used the output parameter, except for checking the error. maybe it should be just that (and `int` return for success / failure)",0,0,0,0.9870656728744508,0.9916969537734984,0.9935558438301086,0.0,accept,unanimous_agreement
537513469,8094,so this method returns the raw conversion factor in both the return value and output parameter? i guess one of them can be removed (let's make it return an `int` for success / failure) and a top comment is needed.,0,0,0,0.988389492034912,0.992485761642456,0.9917669892311096,0.0,accept,unanimous_agreement
537516041,8094,comment is outdated [code block],0,0,0,0.9450920820236206,0.988941490650177,0.9249421954154968,0.0,accept,unanimous_agreement
537517678,8094,i think i'd rather have a dedicated flag rather than rely on `radius_nostore`,0,0,0,0.9853423833847046,0.9887456297874452,0.9865489602088928,0.0,accept,unanimous_agreement
537521266,8094,i think this won't be needed if we'll use a separate flag for the geosearchstore variant,0,0,0,0.9874008297920228,0.986312210559845,0.9849838614463806,0.0,accept,unanimous_agreement
537528924,8094,"this method now has a side effect that it writes into the `shape->bounds`. maybe it should now be called `geohashcalculateareasbyshape` (i.e. ""calculate"" instead of ""get""). and/or at the very least mention it in the top comment. p.s. i'm still not certain we need the `bounds` member in the shape at. why isn't it enough that it's here on the stack like it used to be?",0,0,0,0.9429308772087096,0.9904916882514954,0.9883726239204408,0.0,accept,unanimous_agreement
537531591,8094,"i'm not certain this is the right thing to do. maybe we need an ""geohashestimatestepsby**box**"" instead of convert our box to a circle? can you look into that? p.s. if we keep this, i think it'll look nicer if the conversion will be done in a separate line after the ternary operator.",0,0,0,0.9356942772865297,0.964374542236328,0.6776415705680847,0.0,accept,unanimous_agreement
537543278,8094,"something still doesn't feel right here. the `geohashgetdistanceifinradius` makes sense, you get two points ""1"" and ""2"" to measure the distance between them, and return it only if smaller than a ""radius"" distance. here we get two points (""1"" and ""2""), and i would imagine that also a width/2 and height/2, to return the the distance between the two points only if smaller than width/2 horizontally, and height/2 vertically. but instead we get ""bounds"" which is a 4 element long / lat thing. also, looking at `geohashboundingbox` i see that `bounds` already has shape->xy embedded in it, so these are not just w/2 and h/2. lastly, i remind you that our `bounds` is bloated (using a fake radius that's generated by max(w/2,h/2), so checking here against `bounds` is probably a bug. my advise: this function should probably get width and height as input instead of bounds.",0,0,-1,0.8759098649024963,0.9563196301460266,0.5551563501358032,0.0,accept,majority_agreement
537999194,8094,"thanks, already updated.",1,1,1,0.550837516784668,0.7509425282478333,0.7648113965988159,1.0,accept,unanimous_agreement
538000495,8094,"all coordinates (x, y, bounds) are in long/lat all distances (width, height, radius) are in meters. if we use width and height as parameters, we need to recalculate the latitude and longitude (meters to degrees), to avoid calculation, we pass bounds.",0,0,0,0.9832749962806702,0.9936729669570924,0.9937119483947754,0.0,accept,unanimous_agreement
538001805,8094,"we use radius to determine the steps, which is an approximate interval of geohash, because we will search for 8 nearby areas, so max(w/2,h/2) is correct.",0,0,0,0.984650492668152,0.99064964056015,0.994379460811615,0.0,accept,unanimous_agreement
538187880,8094,"in some cases, maybe if the box is very long and narrow, maybe we can do better (maybe find a totally different number of steps (not even a 3x3 set, maybe a 2x6 set, or 2x8). but i'm ok to overlook this for now.",0,0,0,0.7789314985275269,0.9725717306137084,0.9440653920173644,0.0,accept,unanimous_agreement
538205044,8094,i would have negated this flag (i.e. call it `geosearchstore`),0,0,0,0.9861438274383544,0.9888624548912048,0.9930654764175416,0.0,accept,unanimous_agreement
538238044,8094,"i will update to `geosearchstore` yes, some tcl tests are done like this yes, see `test {geosearch vs georadius}` not yet, i will add some tests.",0,0,0,0.9856516122817992,0.990549623966217,0.9936554431915284,0.0,accept,unanimous_agreement
538532631,8094,the geohashcalculateareasbyshapewgs84 function finally excludes areas that do not need to be searched. [code block],0,0,0,0.9888595342636108,0.9944708347320556,0.9941648840904236,0.0,accept,unanimous_agreement
538591930,8094,"it excludes areas not covered by the radius we generated, but this radius is not optimal, so in practice it may include areas that are outside our box. also iiuc this trick with radius can cause us to use non-optimal resolution and be inaccurate. ![a link] in the above image, we could have been searching only in the 6 small light gray boxes. but instead, we'll be searching in the 9 larger boxes, and skip the 5 on the top and right raw (so end up searching in the 4 large boxes on the bottom left (the majority of that area is outside the ideal search area (the one painted in light gray)",0,0,0,0.8601292371749878,0.8403198719024658,0.8531367778778076,0.0,accept,unanimous_agreement
538596018,8094,"also, i now realize that the way we converted the box to a circle isn't right (a bug): ![a link] seems that we need to call pythagoras back to the game!",-1,-1,-1,0.9638484120368958,0.6746911406517029,0.7154515981674194,-1.0,accept,unanimous_agreement
539035344,8094,"no, for the above picture, we will only search two boxes, the middle one and the one below it. notice: we use box (min_lon, min_lat, max_lon, max_lat) to exclude the useless search area, instead of using the circle calculated by radius, so the 2 boxes in the lower left corner will also be excluded. seems that we need to call pythagoras back to the game! currently max(w/2, h/2) is used, and because we will search 9 nearby areas, the current code is no problem, because the 9 areas must completely include the box, even if some areas are excluded by the box later , it has no effect.",0,0,0,0.843373715877533,0.8727113604545593,0.8440723419189453,0.0,accept,unanimous_agreement
539069608,8094,"thank you. you're right in both cases. i'm still feel a bit worried that some of the logic with the ""steps"" calculation can go wrong in some edge case due to the fact the radius is smaller than it should be, but i don't have any evidence for that. maybe one day we can write a fuzz tester that tests random points around the box corners (inside and outside) of that box, and places a box with random dimensions, and random locations on the glove to verify that it doesn't have bugs. but let's keep that for a separate pr. regardless i also still feel that it can be made more efficient (searching the 6 smaller gray boxes in my example rather than two larger ones. but also, let's keep that for some future date. i think a comment is needed next to where we calculate the inaccurate radius to explain why it's safe, please add that.",1,1,1,0.7806776762008667,0.969351589679718,0.9676498770713806,1.0,accept,unanimous_agreement
539214922,8094,"thanks,already updated.",1,1,1,0.550837516784668,0.6949047446250916,0.760974109172821,1.0,accept,unanimous_agreement
539829299,8094,"nitpick: ""exactly one of frommember or fromloc can be specified for %s"" is slightly more concise. it would also be nice to throw this exception when you provide both, as opposed to the syntax error you currently throw.",0,0,0,0.9838101863861084,0.9878607392311096,0.9843201637268066,0.0,accept,unanimous_agreement
539864239,8094,"i mean frommember and formloc, they cannot exist at the same time, but one of them must exist. your suggestion is clearer and i have updated it, thanks.",1,1,1,0.9233286380767822,0.9268537163734436,0.9708560705184937,1.0,accept,unanimous_agreement
673660440,2795,"we don't use line comments `//` in redis. was gonna change the comment style, but i think it isn't really needed, so eliminated a few lines. [code block]",0,0,0,0.9812865853309632,0.9743303060531616,0.9901846647262572,0.0,accept,unanimous_agreement
673664388,2795,"let's reply with syntax error if there are conflicting flags. we can do that during parsing (the same way it is done in `parseextendedstringargumentsorreply`), but i think this form of argument parsing and also of checking for conflicting flags is harder to follow. i would suggest to copy the boilerplate from `zaddgenericcommand` (both the parsing and conflict checking), and put it into a parseextendedexpirearguments**orreply**. note that only lt/gt are mutually exclusive with nx, but not with xx.",0,0,0,0.97343510389328,0.9883753061294556,0.9917659163475036,0.0,accept,unanimous_agreement
673669027,2795,"the docs say that `0` is returned when the key doesn't exist. i suppose it makes sense to at least let the caller distinguish between non-existing key and a skipped operation due to flag. one option could have been to return `-1` in these cases, but considering that this is inconsistent with the `-1` and `-2` values returned by the ttl command, maybe that's not a wise idea. maybe like the linked issue asks for, we better add a way to just return the ttl. it's true that the user can pipeline a ttl command right after this one, but i suppose it'll be more convenient to let them use this in one go. i suggest to add a `get` flag, which will change the return value from 0/1 to the same return value ttl command group has (see `ttlgenericcommand`). i.e. it would be relative/absolute and ms/sec depending on the expire variant that was used, and we'll have to also return -2 and -1 in the appropriate places. p.s. another wild idea is to also support an incr flag (for the non-absolute expire variants, when `basetime` is not 0), in which case we increment the existing expiration time (similarly to the zadd feature).",0,0,0,0.974760115146637,0.988954782485962,0.9824584126472472,0.0,accept,unanimous_agreement
673691396,2795,"trying to follow the logic (maybe a comment is needed)... if the key doesn't have expire time, it's as is it has an infinite expire time (expires in the far far future), we consider that as if our new expire time is **not** grater than that infinite number. right? p.s. we do have a test that covers that, right?",0,0,0,0.9112280607223512,0.9795662760734558,0.9856796860694884,0.0,accept,unanimous_agreement
673703243,2795,"so here, like in the gt case, we wanna consider non-volatile keys as having infinite expire time, right? so any expiration time would be less than infinite, in that case we probably wanna add an ` && current_expire != -1`. i suppose your reasoning for not adding it was that `when` is surely positive (unix time), so if `current_expire` is -1, there's no need to check (any positive `when` is grater than `-1`, and thus should be aborted since it's not less than infinite). but iirc, in theory `when` can be negative at this stage, so what would happen is that instead of proceeding and deleting the non-volatile key after the `checkalreadyexpired` check, we'll abort here . let's add a test for that case.",0,0,0,0.96576189994812,0.9854926466941832,0.9853461980819702,0.0,accept,unanimous_agreement
673706061,2795,i think all these tests would benefit from adding a check on the result of the ttl to check if the expiration time was modified and if the key exists. i.e. not just verify the return value of the expire command. in that case we wanna use very distinctive expiration times so that we don't have timing issues comparing them. the above test could be ok (100 and 200 seconds). so we can assert that the ttl is >50 <= 100 [code block],0,0,0,0.9715750217437744,0.98543119430542,0.9715793132781982,0.0,accept,unanimous_agreement
673706909,2795,"to avoid timing issues, when we work with milliseconds, let's use values such as 200,000 (200 seconds).",0,0,0,0.9840965270996094,0.9907508492469788,0.9911623001098632,0.0,accept,unanimous_agreement
673735551,2795,would it be better to change it to `expire_*`? like `zadd_nx`.,0,0,0,0.9881873726844788,0.9951714873313904,0.9913899302482604,0.0,accept,unanimous_agreement
673942782,2795,`flag_no_flags` is never used. do we need it?,0,0,0,0.9886158108711244,0.9884920120239258,0.9930095672607422,0.0,accept,unanimous_agreement
674118170,2795,updated to use it as initial value of `flags` following `t_string.c`,0,0,0,0.98336523771286,0.9950036406517028,0.9950169920921326,0.0,accept,unanimous_agreement
674125165,2795,yes and there is a test for this case: [a link],0,0,0,0.984410285949707,0.9790056347846984,0.9921522736549376,0.0,accept,unanimous_agreement
674126154,2795,good catch,1,1,1,0.9703027606010436,0.981269359588623,0.9915775060653688,1.0,accept,unanimous_agreement
674541519,2795,i think these options are not frequently used like `setnx` so use them as options can be sufficient.,0,0,0,0.98434180021286,0.9867836236953736,0.9796018600463868,0.0,accept,unanimous_agreement
674604486,2795,"i think you may be missing the point, or maybe it's me.. i think the ask was for a better prefix to the defines rather than a generic ""flag"".",0,0,0,0.961808145046234,0.983558714389801,0.9602490663528442,0.0,accept,unanimous_agreement
674606486,2795,i think that the `break` here should actually be returning a syntax error response and fail the command.,0,0,0,0.9522952437400818,0.9515535831451416,0.9770517945289612,0.0,accept,unanimous_agreement
674614145,2795,"sorry, what i mean is prefix.",-1,-1,-1,0.986585259437561,0.9928227066993712,0.9856254458427428,-1.0,accept,unanimous_agreement
674879785,2795,i see :joy:,1,1,1,0.97433340549469,0.97844398021698,0.9956645369529724,1.0,accept,unanimous_agreement
675029946,2795,"i think that's a bad name for that flag. it designates that there are no flags, not that there is on expire. got also, being 0, it's not really a flag, and i think we actually don't need it. just use hard coded 0 instead (for an integer named ""flags"" it's logical to just init to 0)",-1,-1,-1,0.9606263637542723,0.8978902697563171,0.8961070775985718,-1.0,accept,unanimous_agreement
675607186,2795,test case added,0,0,0,0.9858930706977844,0.9900078773498536,0.9938977360725404,0.0,accept,unanimous_agreement
675613106,2795,the check here is for `lt`. perhaps it's a typo with `we fail the gt`? so does the `lt` below.,0,0,0,0.9863377213478088,0.9942830204963684,0.9893934726715088,0.0,accept,unanimous_agreement
675971439,2795,"i still suggest not to use the return value of `expire` commands for ttl. it introduces additional complexity for various clients to distinguish *return code* and *value* for this write operation, that defined by an optional flag. and also i think returning `0` makes sense for this new scenario. we can extend its meaning along with these new features. the `0` means nothing changed with this write operation, it can be a key not exist or the operation is skipped.",0,0,0,0.9733438491821288,0.9891855716705322,0.9795621633529664,0.0,accept,unanimous_agreement
676110255,2795,yes. typo.,0,-1,0,0.9865882992744446,0.8327223658561707,0.9704842567443848,0.0,accept,majority_agreement
676110981,2795,ok. we can stop here. already a big step forward. get and incr arguments can be added later if we wish (nothing here that prevents that),0,0,1,0.9261103272438048,0.9605915546417236,0.7682279348373413,0.0,accept,majority_agreement
676112488,2795,"since xx and gt/lt can come together, we may be doing `getexpire` twice. i wanna suggest a small refactoring (conceptually, not in loc), and do something like this: ```c if (flag) { current_expire = getexpire(c->db, key); if (flag & expire_xx) { ... } if (flag & expire_nx) { ... } if (flag & expire_gt) { ... } if (flag & expire_lt) { ... } }",0,0,0,0.9858241081237792,0.9878408312797546,0.9907903671264648,0.0,accept,unanimous_agreement
676112841,2795,"i think it'll be slightly more readable if we convert the constants that are in seconds to values in the range of `100`, and only use 100,000 for the ones that are in milliseconds. [code block] same for the rest of the tests below.",0,0,0,0.9856088757514954,0.9813453555107116,0.98234760761261,0.0,accept,unanimous_agreement
676113997,2795,"i'm actually not sure if there's high value to test the p variants at all (considering they use common code). instead (or in addition to), i'd maybe we can add one test that uses nx/xx/gt/lt on a key that's totally missing? also kinda pointless since this code is unreachable today when the key is missing, but maybe it'll expose an issue when the code is changed one day.",-1,-1,0,0.832970917224884,0.6113243699073792,0.5707926750183105,-1.0,accept,majority_agreement
676114186,2795,"the previous test has the same name, let's rename one of them, or both. i.e. the first one is `expire with gt on a key with low ttl` the second one is `expire with gt on a key with high ttl` and we do have a test below that's `expire with gt option on a key without ttl`",0,0,0,0.9826505780220032,0.9937893748283386,0.9936461448669434,0.0,accept,unanimous_agreement
676114325,2795,"let's add a check for the resulting ttl (i.e. check that it's still non-volatile). and also add the inverse test, that uses xx and lt and succeeds.",0,0,0,0.9874575734138488,0.9926417469978333,0.9945068955421448,0.0,accept,unanimous_agreement
676115121,2795,"again, let's rename both tests, one saying `low ttl` and the other saying `high ttl`",0,0,0,0.9840457439422609,0.9885610938072203,0.9922123551368712,0.0,accept,unanimous_agreement
676115484,2795,maybe add the same thin on a non-volatile key?,0,0,0,0.9850131273269652,0.992591142654419,0.9908778071403505,0.0,accept,unanimous_agreement
676572290,2795,same comment repeats a few times below.,0,0,0,0.9822072982788086,0.9562665224075316,0.9893977642059326,0.0,accept,unanimous_agreement
676590777,2795,fixed by add conflicting commands name to comments,0,0,0,0.9845455884933472,0.9902316927909852,0.9917320013046264,0.0,accept,unanimous_agreement
512229173,7953,+use-memory,0,0,0,0.937146782875061,0.9652868509292604,0.9869771599769592,0.0,accept,unanimous_agreement
512236928,7953,"i don't think we got strong conensus on this, but i think you should be able to copy in cluster mode, you just can't copy between dbs.",0,0,0,0.9754487872123718,0.9521404504776,0.955449640750885,0.0,accept,unanimous_agreement
512390580,7953,"thanks ! i've fixed the flag in the command. i also fixed the copy command a bit. but the code doesn't pass the test. what do i need to do to make sure my code passes the test? also, should i combine my commits into one?",1,1,1,0.979945719242096,0.9617893099784852,0.9921382069587708,1.0,accept,unanimous_agreement
512412914,7953,"this isn't the same as the syntax as well. you should also be looking for the keyword db, so ""copy key key2 db 5 or something. this allows us to be more future proof in adding more arguments here.",0,0,0,0.9852286577224731,0.9899966716766356,0.9937291145324708,0.0,accept,unanimous_agreement
512413698,7953,it would be nice to add a test for all the different types. you can use debug digest to validate that the key/values are the same.,0,0,0,0.9528685808181764,0.9841172099113464,0.9873337745666504,0.0,accept,unanimous_agreement
512543866,7953,"i guess `fast` should be removed? considering some types may require o(n) loops? also, not sure about `` the only hint in the docs is: [code block] so maybe i'd consider copy similar to brpoplpush? i guess not (we should keep ``), but wanted to raise this concern to see if anyone has any feedback.",0,0,0,0.9758777618408204,0.9897708892822266,0.9769899845123292,0.0,accept,unanimous_agreement
513104491,7953,lookupkeyread,0,0,0,0.9877105355262756,0.971625804901123,0.9723770022392272,0.0,accept,unanimous_agreement
513107118,7953,"a quicklist is a linked list of ziplists, which are binary blobs. you should be able to copy each blob and string them together in a quicklist, it'll probably be much faster than this.",0,0,0,0.9715037941932678,0.9767275452613832,0.989459753036499,0.0,accept,unanimous_agreement
513107755,7953,"same comment as before, ziplists are binary blocks in an allocation, you can just copy the whole thing.",0,0,0,0.988589644432068,0.9905717372894288,0.993077516555786,0.0,accept,unanimous_agreement
513109492,7953,would prefer to error instead of silently ignoring bad arguments.,0,0,-1,0.5521615743637085,0.7097292542457581,0.9203516840934752,0.0,accept,majority_agreement
513111796,7953,this shouldn't be possible? would prefer to assert here.,0,0,0,0.961879312992096,0.9306263327598572,0.9778023958206176,0.0,accept,unanimous_agreement
513113971,7953,"i was going to suggest building a helper method for this that just adds an sds array directly without converting them to robjs. that would be nice, but streamappenditem() is a sprawling function. you could also see if you can do the same optimization and just copy the list packs.",0,0,0,0.938330888748169,0.9603296518325806,0.9789855480194092,0.0,accept,unanimous_agreement
513114156,7953,still needed?,0,0,0,0.9770442843437196,0.9815264344215392,0.9908512234687804,0.0,accept,unanimous_agreement
513114908,7953,"not sure how i feel about this specifically, but we maybe should retain the lru information. we could also document the fact we just don't do that.",0,0,-1,0.7292903661727905,0.920425295829773,0.6389290690422058,0.0,accept,majority_agreement
513115006,7953,"looks like the stream digest doesn't include consumer group information, probably worth expanding on that.",0,0,0,0.979556441307068,0.9814019799232484,0.9822953939437866,0.0,accept,unanimous_agreement
513115169,7953,[code block] keeps the indentation down.,0,0,0,0.985256850719452,0.9916285276412964,0.9929526448249816,0.0,accept,unanimous_agreement
513115805,7953,"do you agree that it makes sense to copy all of the consumer group information when we copy the stream. it seems weird to me, but it is metadata on the stream but also isn't directly data about the stream. do you have any thoughts?",-1,-1,-1,0.6905096173286438,0.9561148881912231,0.957650899887085,-1.0,accept,unanimous_agreement
513229028,7953,"yes, i think cgs and consumers should be copied as well... as i see it, copy should provide a perfect copy of the key, i.e. executing the same command on both keys should have identical result",0,0,0,0.9490754008293152,0.9562947750091552,0.9866129755973816,0.0,accept,unanimous_agreement
513241438,7953,"i agree, let's avoid going over the individual elements and just run over the rax and copy the listpacks.",0,0,0,0.9797709584236144,0.939487636089325,0.9826613068580629,0.0,accept,unanimous_agreement
513242144,7953,"good idea about indentation. just a nit pick about the `if`, i prefer actions that change the execution flow (goto, break, return), to be on a line of their own (unless they come in an heavily repeated pattern)",1,1,1,0.9372547268867492,0.9173256158828736,0.8965455293655396,1.0,accept,unanimous_agreement
513243110,7953,"actually, for some unclear reason, redis uses lookupkeywrite when reading keys on behalf of a write operation. looking at sunionstore, this intent is clear. see [a link]",0,0,0,0.9844676852226256,0.9916113018989564,0.9903141856193542,0.0,accept,unanimous_agreement
513251181,7953,"we recently made an effort to replace many of the dbdelete+dbadd pairs with setkey (see sunionstore and alike). the difference is that `setkey` retains the lru of the destination key. however, my above note is actually unrelated since we're talking of the lru of the source key. from what i can tell, both move and rename, retain the lru of the source key, so i'm guessing copy should do the same? or if we consider that a new object (unlike move and rename), we should behave similarly to restore replace (create a fresh new key)? or maybe this is in some way similar to sunionstore being called with one input (clones a set and keeps the destination lru)? /core-team please share your thoughts. (i'm leaning towards the restore replace behavior)",0,0,0,0.9767515659332277,0.9809306263923644,0.9887003302574158,0.0,accept,unanimous_agreement
513253714,7953,"i'm not certain we want digest to include it. there are commands that modify these which consider them metadata. iirc they do perform `dirty++` and are propagated to replicas and rdb/aof, and only avoid doing signalmodifykey (invalidating watch), so maybe that means that they should indeed be in the digest. anything to add?",0,0,0,0.9324486255645752,0.9337589144706726,0.9624024629592896,0.0,accept,unanimous_agreement
513431252,7953,since cgs go in the aof and rdb i think they should be included in the digest,0,0,0,0.9853339195251464,0.9912331700325012,0.9908517003059388,0.0,accept,unanimous_agreement
513436315,7953,i vote for: src's lru should remain unchanged (like move) dst's lru should be changed (like restore replace),0,0,0,0.9658759236335754,0.9884710311889648,0.98389995098114,0.0,accept,unanimous_agreement
517539725,7953,i think we should keep,0,0,0,0.9492964148521424,0.8646159768104553,0.9733624458312988,0.0,accept,unanimous_agreement
517547039,7953,"ok, point taken, it's weird behavior but good to know.",-1,-1,1,0.7108948230743408,0.9289650321006776,0.5816062688827515,-1.0,accept,majority_agreement
517606533,7953,"i recently remembered that zslinsert (used by zsetadd) is more efficient when iterating on the list backwards: [a link] it may be a topic for another pr to improved zslinsert, but maybe in the meanwhile we wanna run backwards here too (and put a comment saying why)?",0,0,0,0.9751787781715392,0.9866005778312684,0.9877975583076476,0.0,accept,unanimous_agreement
519180025,7953,"i don't like this intimate code that messes with the intset internals being in object.c i.e. `intrev32ifbe(is->length)` so i would have argued that this block should be promoted to some `intsetdup` function that will be implemented in intset.c and called here. but in fact, there's simply a better, easier way to do do. just call `intsetbloblen` then malloc and memcpy the entire thing without bothering to understand what's inside.",-1,-1,-1,0.980667233467102,0.8503841757774353,0.7155575156211853,-1.0,accept,unanimous_agreement
519180150,7953,"i see you did this for ziplist, why didn't you do that for intset?",0,0,0,0.9797216653823853,0.9902544617652892,0.985834777355194,0.0,accept,unanimous_agreement
519180405,7953,"it's a good idea to call dictexpand here too, so that it'll be created with the right size and not go though rehashing. same in the other paces that we create a dict which we know it's final size",0,0,0,0.5501694083213806,0.9073752760887146,0.773015022277832,0.0,accept,unanimous_agreement
519181300,7953,"i don't think we want to invent a new ""nodb"" error code. probably best to reply with the same ""invalid db index"" that's used in select""",0,0,0,0.9759170413017272,0.6067664623260498,0.978044331073761,0.0,accept,unanimous_agreement
519264242,7953,"use `dictsize(d)` instead of `d->ht[0].size`. it's both nicer not to access the internals of the dict, but also more ""correct"" since if the source dict is in the process of rehashing, it's records are split between ht[0] and ht[1].",0,0,0,0.9825260639190674,0.9909787178039552,0.9890840649604796,0.0,accept,unanimous_agreement
519264632,7953,we should better use `dictexpand` here too (see that rdb.c does it also).,0,0,0,0.9873907566070556,0.9941707253456116,0.9940780401229858,0.0,accept,unanimous_agreement
519264785,7953,"speaking of rdb.c, i see that rdb.c does this: [code block] and you used `zsetadd` which seems to be a top level function (used mainly for the command implementation: `zaddgenericcommand`) i think it's better to use zslinsert and dictadd directly in this case.",0,0,0,0.9838723540306092,0.9922230839729308,0.98964124917984,0.0,accept,unanimous_agreement
519266271,7953,"iiuc what this code does it: 1. create a nack 2. insert it to the group and the consumer 3. if the group insertion failed (since the group already has one): 1. delete the newly created nack 2. locate the the group nack 3. remove the newly added consumer nack 4. add the group nack into the consumer. to me this seems like a complicated and wrong approach, the more trivial one imho is: 1. search the group, if it already has one: 1. add it to the consumer 2. else: 1. create a new nack 3. add to both the group and consumer advantage: - more logical approach imho (and probably shorter too) - not allocating a nack just in order to free it soon. - involves 3 rax searches max (1 find and 2 insertions), existing approach has 5 (2 insertions, find, removal and insertion)",-1,0,-1,0.8101309537887573,0.8348303437232971,0.608870267868042,-1.0,accept,majority_agreement
519395397,7953,"looking at your recent change, i don't think that's good. the pel record in the consumer is expected to be the same pointer as the one in the consumer group pel. i see your recent code just calls `raxtryinsert` and `raxinsert`, so if the same record exists in two consumers, one will be shared with the group, and the other one will not (memory leak later). however, i see that raxtryinsert and raxinsert can return the existing pointer if there's a clash. so you can use that. this will mean that you'll have just two searches (not 3 as in my previous proposal), but only other hand you'll have excessive calls to malloc / free, i suppose that's not so bad, and the code will be cleaner.",0,0,0,0.9113942980766296,0.9384926557540894,0.7556940913200378,0.0,accept,unanimous_agreement
519508119,7953,"thanks i'm sorry but, i didn't understand exactly how to fix it, so i took a look at rdb.c to fix it. would this fix be a problem?",-1,-1,-1,0.9858684539794922,0.9922980666160583,0.9888913631439208,-1.0,accept,unanimous_agreement
519577644,7953,"new code looks good. (being the same approach that rdb loading takes, it can't be wrong) also, it seems i got confused, one nack record can't exist in two consumers.",1,1,1,0.9542954564094543,0.7182594537734985,0.9577487111091614,1.0,accept,unanimous_agreement
520168967,7953,not used,0,0,0,0.9469820857048036,0.9175628423690796,0.9867091178894044,0.0,accept,unanimous_agreement
520169025,7953,not used,0,0,0,0.9469820857048036,0.9175628423690796,0.9867091178894044,0.0,accept,unanimous_agreement
520228768,7953,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
520228802,7953,done,0,0,0,0.976450741291046,0.8974218964576721,0.8682363629341125,0.0,accept,unanimous_agreement
520793610,7953,ref: the `replace` logic in `restore` [code block],0,0,0,0.9885737895965576,0.9897889494895936,0.9954366087913512,0.0,accept,unanimous_agreement
521337238,7953,"are you sure? the ""del"" notification in restore is only in case the new key is expired, and restore deleted the old key. it's something i recently copied from expireat (when ttl is in the past). in the case restore succeeds it only does: [code block] taking another example, sinterstore it does: [code block] or (only in case a key was deleted, and the stored key is empty): [code block] so i think in this case we just want the ""copy_to"" notification, not the ""del"" one",0,0,0,0.9804845452308656,0.9902620911598206,0.9894150495529176,0.0,accept,unanimous_agreement
521417669,7953,you are of course correct - the `del` isn't needed here.,0,0,0,0.9829918742179872,0.9900543689727784,0.9840593338012696,0.0,accept,unanimous_agreement
521596422,7953,"this trick of using `selectdb` to check if the dbid is in range is not very good. if we exit with syntax error on the next argument, the selected db remains the dest db. either re-select the original db right away, or just match the dbid range manually.",0,0,0,0.9382955431938172,0.9140469431877136,0.9410284757614136,0.0,accept,unanimous_agreement
507125314,7912,"we'll require to bump the version number here to maintain abi compatibility, as modules compiled with an older `redismodule.h` will have a smaller `redismoduletypemethods` and may end up with a junk pointer.",0,0,0,0.9812926650047302,0.9830604195594788,0.9889163970947266,0.0,accept,unanimous_agreement
507132056,7912,i think this test might be flaky working at a byte level. i would consider allocating more substantial amount of memory in the test module (e.g. 500kb per entry or so) so it the effect would be more observable and robust.,0,0,0,0.969565749168396,0.9609692096710204,0.8584734201431274,0.0,accept,unanimous_agreement
507372648,7912,"ok, thank you for your review. i added a v3 version of api, which included free_effort.",1,1,1,0.9138343334197998,0.9569692611694336,0.9310571551322936,1.0,accept,unanimous_agreement
507378516,7912,"yes, i directly refer to'lazyfree.tcl' and change the memory allocation amount to 100000, which has far exceeded lazyfree_threshold. at the same time, because of the'lazyfreed_objects' information, i can be sure that the memory of this module is lazyfreed",0,0,0,0.9831331372261048,0.9912644624710084,0.99092835187912,0.0,accept,unanimous_agreement
514304716,7912,"maybe we want to let the module have access to the `mt` (`val`) too? some modules may want to look into some variable they have there, and be forced to do rm_openkey for that. another alternative is maybe pass a `redismodulekey` and then they can get the key name via rm_getkeynamefrommodulekey, and value via rm_moduletypegetvalue what do you guys thing?",0,0,0,0.9823550581932068,0.9931372404098512,0.990913152694702,0.0,accept,unanimous_agreement
514307922,7912,how about something in these lines: [code block],0,0,0,0.9849612712860109,0.9858546853065492,0.9919501543045044,0.0,accept,unanimous_agreement
514308729,7912,why did you move that away from the struct?,0,0,0,0.9404982924461364,0.9872331619262696,0.9923664927482604,0.0,accept,unanimous_agreement
514708209,7912,"because `#define redismodule_core 1` is in server.h, as originally designed, i can't access `redismodule_type_method_version` in module.c . so i just moved it outside of the `redismodule_core` macro and put it in as easy to see as possible.",0,0,0,0.9870686531066896,0.992272138595581,0.98996239900589,0.0,accept,unanimous_agreement
514709823,7912,"yes, let me add.",0,0,0,0.9831740260124208,0.9816293716430664,0.9915128350257874,0.0,accept,unanimous_agreement
514712554,7912,"well, if necessary, i'd prefer to just pass `val` over because it's already there.",0,0,0,0.9838718175888062,0.9913506507873536,0.986613929271698,0.0,accept,unanimous_agreement
515587178,7912,"what do you think? i suppose a void* value is consistent with other apis: [code block] i'm ok with this, but i want to give it a bit more thought so that we don't regret it in the future. the alternative of providing a `redismodulekey*` will let the user get the key name, value and also other things (like lru) from it.",0,0,0,0.9743194580078124,0.9767084717750548,0.944111168384552,0.0,accept,unanimous_agreement
515592073,7912,"i lean towards just passing the value, i don't see any real need to manipulate the key (after all it's getting unlinked) and it's more consistent with the other calls.",0,0,0,0.9156864285469056,0.9380626082420348,0.965541124343872,0.0,accept,unanimous_agreement
515593441,7912,"this `if` isn't really needed, (the struct we allocated on the stack always support them (otherwise it wouldn't have compiled 8-) .) the reason i asked to add that api, so the module would be able to know if redis is gonna ignore it or not.. i don't have anything to say against this test (adds coverage for this api), but if someone would use this as an example, it may be misleading. maybe change this `if` into one that returns an error and exists? (module load fails)",0,0,0,0.9112343788146972,0.8397853970527649,0.8934861421585083,0.0,accept,unanimous_agreement
515594210,7912,"this is a long loop, that can take a while to execute. if we need it that long, maybe convert it to use a deferring client (pipeline)",0,0,0,0.9850127696990968,0.9683844447135924,0.9854865074157716,0.0,accept,unanimous_agreement
516044656,7912,"ok, changed to pipeline.",0,0,0,0.986068606376648,0.989682674407959,0.982451856136322,0.0,accept,unanimous_agreement
516044938,7912,updated.,0,0,0,0.975935995578766,0.9856141209602356,0.9768958687782288,0.0,accept,unanimous_agreement
516047237,7912,"okay, it has been changed: when the redis runtime version is lower than the module version, the loading will fail.",0,0,0,0.9781423807144164,0.9857863187789916,0.99222332239151,0.0,accept,unanimous_agreement
519400486,7912,i now realize that we're missing a call to modulenotifykeyunlink here (better be done before calling `dictsetval`). which makes me wonder what else are we missing?,0,0,0,0.8653334379196167,0.984504222869873,0.9865903854370116,0.0,accept,unanimous_agreement
520197405,7912,"i see this is a direct translation from os, but i think the notion of free_effort is unnecessary and confusing from a module context. i feel like a better callback would be, can_free_async(), which can make it's own decision about whether or not this is worth freeing async.",0,0,0,0.7308560609817505,0.9652202129364014,0.896354615688324,0.0,accept,unanimous_agreement
520327174,7912,"what do you mean by ""os""? we're trying to match the effort to: [code block] i think a name like `can_free_async` is misleading (it's possible that it ""can"" but better not do that). if we're seeking a boolean return, maybe a better name would be `should_free_async`. but then if we some day let users control this constant via command or config, the modules will need to be able to query it. i think returning the complexity (how many pointers you have to free, or how many loops you'll need to run) makes sense as a return value. i suppose we better document that 0 indicate not to be released by a thread.",0,0,0,0.9489527940750122,0.9842351675033568,0.9893873929977416,0.0,accept,unanimous_agreement
520371087,7912,"open source? i didn't know what to call none module redis code, redis core maybe? i still think should free async makes a more sense. the lazy free estimate is an approximation for ""should we free this async"". a module doesn't need to make the same decision we do. i also think we should never expose the lazy free effort as a parameter, without some type of conversion in between. you could be more explicit and pass the effort to the module callback function and it can choose if it wants to ignore it. i just think we should have more thoughtful apis. from an outside user it's very hard to understand.",0,0,0,0.7192568182945251,0.9376586079597472,0.9614058136940002,0.0,accept,unanimous_agreement
