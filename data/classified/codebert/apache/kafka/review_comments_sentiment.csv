id,pr_number,user,created_at,body,codebert_sentiment_label,codebert_confidence
113856314,2929,onurkaraman,2017-04-28T05:53:31Z,can we contain the `javaconverters._` import to be within the specific method needing the conversion as is being done elsewhere in kafkacontroller? importing at the file-level can lead to a lot of surprises when reading the code.,0,0.9913092851638794
113856373,2929,onurkaraman,2017-04-28T05:54:07Z,remove. this import already exists.,0,0.9749880433082581
113856447,2929,onurkaraman,2017-04-28T05:55:07Z,"every other data structure in the controller uses the old topicandpartition. for consistency, can we use topicandpartition instead of topicpartition?",0,0.9924091100692749
113856721,2929,onurkaraman,2017-04-28T05:57:39Z,can just be: [code block],0,0.9923270344734192
113856779,2929,onurkaraman,2017-04-28T05:58:18Z,can just be: [code block],0,0.9923270344734192
113857148,2929,onurkaraman,2017-04-28T06:02:27Z,can we make this naming consistent with topicdeletionstopreplicaresult? we can either change the other class name or maybe change your new class to something like leaderandisrresult or leaderandisrresponseresult?,0,0.9946208000183105
113973577,2929,lindong28,2017-04-28T16:51:48Z,i think it may be better to rename `topicdeletionstopreplicaresult` to `topicdeletionstopreplicaresponsereceived`. but i don't have a strong opinion on this. i can also rename `leaderandisrresponsereceived` to `leaderandisrresponseresult`. do you have a strong preference between the two?,0,0.9747222661972046
113973608,2929,lindong28,2017-04-28T16:51:59Z,sure. fixed now.,0,0.9868775010108948
113973627,2929,lindong28,2017-04-28T16:52:07Z,sure. fixed now.,0,0.9868775010108948
113975537,2929,lindong28,2017-04-28T17:02:05Z,i was thinking that we may want to use the java version for new code so that we can gradually migrate to the java version. i have change the code to use topicandpartition.,0,0.9756753444671631
113975948,2929,lindong28,2017-04-28T17:04:27Z,fixed now.,0,0.9818974137306213
113975960,2929,lindong28,2017-04-28T17:04:32Z,fixed now.,0,0.9818974137306213
113984161,2929,onurkaraman,2017-04-28T17:47:26Z,i'd prefer renaming `topicdeletionstopreplicaresult` to `topicdeletionstopreplicaresponsereceived`.,0,0.9937494993209839
114925916,2929,ijuma,2017-05-05T03:03:47Z,this rule doesn't apply to `javaconverters` since you need explicit `asscala` and `asjava` calls anyway. that rule was for `javaconversions` which did things automatically and has been deprecated.,0,0.9952680468559265
114925955,2929,ijuma,2017-05-05T03:04:37Z,"yeah, we definitely want to migrate all the code to the java class. it probably makes sense to do the whole class in one go though.",0,0.9779967665672302
119011953,2929,becketqin,2017-05-30T04:52:54Z,why should we rename the class?,0,0.9861345887184143
119012138,2929,becketqin,2017-05-30T04:55:35Z,this was a public api so it seems worth keeping and maybe mark it as deprecated.,0,0.9880619049072266
119012234,2929,becketqin,2017-05-30T04:56:56Z,maybe add some java doc to describe the exception a little?,0,0.9888601899147034
119012458,2929,becketqin,2017-05-30T05:00:15Z,can we add java doc for metadata request v3?,0,0.9944948554039001
119012849,2929,becketqin,2017-05-30T05:06:29Z,java doc is missing.,0,0.9521708488464355
119012994,2929,becketqin,2017-05-30T05:07:39Z,nit: name is a little different from the way zk_version was named.,0,0.8939333558082581
119013074,2929,becketqin,2017-05-30T05:08:58Z,can just fall through.,0,0.9849734306335449
120798287,2929,lindong28,2017-06-08T04:35:36Z,thanks for the information .,0,0.7220116257667542
120800388,2929,lindong28,2017-06-08T05:03:46Z,this patch adds the scala class `leaderandisrpartitionstate` and `metadatapartitionstate`. `metadatapartitioninfo` makes it more explicit that this is a java class that corresponds to `metadatapartitionstate`.,0,0.9943807721138
120800491,2929,lindong28,2017-06-08T05:05:06Z,then i wouldn't bother to rename this class if it is public api.,0,0.8769717812538147
120800642,2929,lindong28,2017-06-08T05:06:43Z,sure. i added this comment: `miscellaneous disk-related ioexception occurred when handling a request`.,0,0.9916067123413086
120800786,2929,lindong28,2017-06-08T05:09:03Z,sure. added this comment: [code block],0,0.9884172081947327
120800846,2929,lindong28,2017-06-08T05:10:00Z,good catch. thanks. i replaced it with `is_new` both here and in the protocol.java.,1,0.9941164255142212
120800894,2929,lindong28,2017-06-08T05:10:51Z,i forgot this is java not scala. good point. fixed now.,1,0.6613935828208923
121294118,2929,becketqin,2017-06-11T23:12:45Z,"the comment seems a little convoluted. i think it can just be ""whether the replica should have existed on the broker or not.""",0,0.6953251957893372
121294281,2929,becketqin,2017-06-11T23:20:33Z,"do we need to create `leader_and_isr_request_live_leader_v1`? it seems that we do not have a consistent convention on when to create a new internal field version. my preference is that we always bump up request/response version if either request or response version is bumped, because the version would be used for compatibility check. but for internal fields, we do not have to bump up version if there is no change.",0,0.9932804703712463
121294385,2929,becketqin,2017-06-11T23:26:10Z,"yes, this is a public api. renaming it requires a kip.",0,0.9827879071235657
121294648,2929,becketqin,2017-06-11T23:40:16Z,"if the default value of isnew is false, for brokers which are running ibp version lower than 0.11.1, replicas may not be created if a broker has a disk failure? in leaderandisrrequest earlier than v5, it actually means `create the replica if it does not exist`. in this case, i think it might make sense to keep the same behavior on the broker when storage failure is detected. i.e. let the entire broker halt if ibp is lower than 0.11.0.",0,0.9918395280838013
121294669,2929,becketqin,2017-06-11T23:40:52Z,"btw, can you also bump up `apiversions` as well?",0,0.9911609888076782
121294748,2929,becketqin,2017-06-11T23:44:31Z,good cleanup.,1,0.9691222906112671
121294952,2929,becketqin,2017-06-11T23:47:17Z,is this renaming necessary?,0,0.9912069439888
121295031,2929,becketqin,2017-06-11T23:52:10Z,the hierarchy here is a little strange. it might be clearer to create a new `abstractpartitionstate` class and let the partitionstate in leaderandisrrequest and updatemetadatarequest inherit from it.,0,0.8291104435920715
121295155,2929,becketqin,2017-06-11T23:56:56Z,see comments about the `partitionstate` hierarchy.,0,0.9925658702850342
121295230,2929,becketqin,2017-06-12T00:00:23Z,no need to do this if the struct does not contain the offline_replicas field. a big if statement seems simpler.,0,0.9810326099395752
121295331,2929,becketqin,2017-06-12T00:05:39Z,is this change intended? can the parent directories on different disk have the same name?,0,0.9878275394439697
121295556,2929,becketqin,2017-06-12T00:16:13Z,it is weird to pass in both controller and a member of the controller. the eventmanager field is already private to controller package so it is accessible from here.,-1,0.9791473746299744
121295627,2929,becketqin,2017-06-12T00:18:48Z,could be replaced by [code block].,0,0.9905209541320801
121296146,2929,becketqin,2017-06-12T00:39:50Z,no need to have the brackets around `brokerid`,0,0.9925123453140259
121296370,2929,becketqin,2017-06-12T00:48:03Z,some of the logics in this class are the same as in `onbrokerfailure()` probably worth trying to abstract them out to a shared method to handle offline replicas.,0,0.994502067565918
121296397,2929,becketqin,2017-06-12T00:49:05Z,no need to have eventmanager passed in.,0,0.9898444414138794
121296413,2929,becketqin,2017-06-12T00:49:40Z,empty java doc.,0,0.9829030632972717
121296662,2929,becketqin,2017-06-12T00:59:18Z,ditto above.,0,0.9803552627563477
121296804,2929,becketqin,2017-06-12T01:04:53Z,ditto above.,0,0.9803552627563477
121297063,2929,becketqin,2017-06-12T01:13:10Z,is a mutable map enough here?,0,0.9912262558937073
121297514,2929,becketqin,2017-06-12T01:22:21Z,why arraybuffer?,0,0.9709710478782654
121297615,2929,becketqin,2017-06-12T01:25:06Z,would a mutable map work here?,0,0.9932847023010254
121297859,2929,becketqin,2017-06-12T01:31:27Z,"there should not be duplicates in the `livelogdirs`, right? so we can just remove the dir for `livelogdirs`.",0,0.9941375255584717
121298466,2929,becketqin,2017-06-12T01:44:00Z,i did not see the logic to handle io failures in log segments loading. am i missing something?,0,0.549402117729187
121299795,2929,becketqin,2017-06-12T02:00:53Z,we should probably exit if broker id load or checkpoint fail.,0,0.9873237609863281
121305112,2929,becketqin,2017-06-12T03:19:54Z,"it seems that sometimes we are catching both ioexception and kafkastorageexception, sometimes we only catch kafkastorageexception. it might be better to only catch ioexception at the the direct thrown and convert them to kafkastorageexception. so in the caller methods we only need to catch kafkastorageexception.",0,0.9878292083740234
121305435,2929,becketqin,2017-06-12T03:25:16Z,this exception should probably extend from retriableexception instead of apiexception. a disk failure should not cause the client to throw exception to the users. the clients should just retry after the leadership moves to another healthy replica.,0,0.9919052124023438
121313873,2929,lindong28,2017-06-12T05:50:36Z,sure. i have updated the comment as you suggested.,0,0.9883020520210266
121313909,2929,lindong28,2017-06-12T05:50:58Z,sure. i updated the patch to removed `leader_and_isr_request_live_leader_v1`.,0,0.9953446984291077
121314572,2929,lindong28,2017-06-12T05:58:35Z,"regarding the first comment, it seems safer to disable replica creation if any replica offline. i think it is probably more backward compatible to do so -- currently leaderandisrrequest will fail to create replica if any disk is offline. regarding the second comment, good point. i should have updated the controller code to specify the version for leaderandisrrequest and updatemetadatarequest based on the configured `interbrokerprotocolversion`. i have updated the patch to do this and added `kafka_0_11_1_iv0` in `apiversion`. thanks!",1,0.982702374458313
121314687,2929,lindong28,2017-06-12T06:00:02Z,`metadataresponsepartitionstate` will be more consistent and clearer than `partitionmetadata` in describing the usage of this class. it is not necessary to change the class. i replaced the todo with a comment that says `this is used to describe metadataresponsepartitionstate`.,0,0.9919948577880859
121314881,2929,lindong28,2017-06-12T06:02:16Z,"sure. i think we can do that refactor. since this is not an important refactor, can we do this refactor later or even in separate patch to reduce the chance of conflicts with other commits? for now i replaced the todo with a comment that says `this is used to describe leaderandisrpartitioninfo`.",0,0.9899217486381531
121314992,2929,lindong28,2017-06-12T06:03:26Z,i think the current class name updatemetadatarequestpartitionstate is good enough. i have removed this todo.,0,0.9236465692520142
121315115,2929,lindong28,2017-06-12T06:04:43Z,"the current code is simpler than having an extra `if` statement. i am wondering what is the benefit of the extra `if` statement. it seems to have negligible impact on performance, right?",0,0.9235591888427734
121315417,2929,lindong28,2017-06-12T06:08:39Z,"yes, it is intended. i think `dir.getparent` is exactly the same as `dir.getparentfile.getabsolutepath` according to their java doc. `dir.getparent` is a bit shorter. i think parent directories on different disk must have the different name since they are specified as a list of strings using `log.dirs` config. they must be different so that kafka can distinguish between them.",0,0.9916229844093323
121315565,2929,lindong28,2017-06-12T06:10:44Z,good point. previously i think my ide tells me it can not be accessed as `controller.eventmanager`. i have updated it to use `controller.eventmanager`.,1,0.9169302582740784
121315578,2929,lindong28,2017-06-12T06:10:53Z,good point. fixed now.,1,0.8883477449417114
121315647,2929,lindong28,2017-06-12T06:11:47Z,great point. i have moved the overlapping logic to a new method named `onreplicabecomeoffline(newofflinereplicas: set[partitionandreplica])`.,1,0.9767623543739319
121315661,2929,lindong28,2017-06-12T06:11:56Z,sure. fixed now.,0,0.9868775010108948
121316067,2929,lindong28,2017-06-12T06:15:48Z,this comment seems ok since it is similar to the comment of `brokerchangelistener` and `isrchangenotificationlistener` etc. i can improve it. is there any example listener class's comment you want me to follow?,0,0.9824466705322266
121316335,2929,lindong28,2017-06-12T06:18:22Z,"i agree. but all existing listener class (e.g. partitionreassignmentlistener) takes this as the second argument. it seems better to keep the same code style for `logdireventnotificationlistener`, or we can update all of them to remove the second argument `eventmanager`. which solution do you prefer?",0,0.9833352565765381
121316376,2929,lindong28,2017-06-12T06:18:37Z,it is removed now. thanks.,1,0.9251085519790649
121316420,2929,lindong28,2017-06-12T06:18:44Z,it is removed now. thanks.,1,0.9251085519790649
121316852,2929,lindong28,2017-06-12T06:22:20Z,"i think it can be changed to a mutable map since a volatile var map can usually be replaced by a mutable map and vise versa. does kafka code has a preference between the two? i have chosen to use volatile var here because the code may be simpler. for example, i can simply do `checkpoints = checkpoints.filterkeys(_.getabsolutepath != dir)` in `logcleanermanager.handlelogdirfailure(dir: string)`.",0,0.9920542240142822
121317056,2929,lindong28,2017-06-12T06:24:16Z,"i think it can be changed to a mutable map since a volatile var map can usually be replaced by a mutable map and vise versa. does kafka code has a preference between the two? i have chosen to use volatile var here because the code may be simpler. for example, i can simply do `recoverypointcheckpoints = recoverypointcheckpoints.filterkeys(file => file.getabsolutepath != dir)` in `logmanager.handlelogdirfailure(dir: string)`.",0,0.99128258228302
121319054,2929,lindong28,2017-06-12T06:43:47Z,"previously i think it is ok not to handle failure in `loadlogs()` because the subsequent requests (e.g. fetchrequest, producerrequest, leaderandisrrequest) can trigger `handlelogdirfailure(...)`. handling log directory failure in `loadlogs()` could allow broker to fail faster if all log directories are offline at the cost of slightly more code. anyway, i have updated the code to handle io failure in log segments loading.",0,0.9938189387321472
121319440,2929,lindong28,2017-06-12T06:47:22Z,we need to pass `logmanager.livelogdirs` to `logcleanermanager` by reference and be able to propagate the change in `logmanager.livelogdirs` to `logcleanermanager`. therefore we need to change its type to arraybuffer so that it is mutable. does this make sense?,0,0.9940747618675232
121319883,2929,lindong28,2017-06-12T06:51:16Z,note that `livelogdirs` has type `arraybuffer[file]` and `dir` has type `string`. it seems that `arraybuffer` only allows remove by position in the array. it does not have a method to remove element by value.,0,0.9944055080413818
121320013,2929,lindong28,2017-06-12T06:52:20Z,"can you explain why we should let broker exit if broker id load fail? my concern is that this will cause broker to exit if any log directory goes offline, which defeats the purpose of this kip.",0,0.7920958399772644
121320570,2929,lindong28,2017-06-12T06:57:39Z,"it is possible to catch ioexception at the the direct thrown and convert them to kafkastorageexception. but the code change required for those try/catch/indentation is probably much more than the code needed for the extra exception in the catch. also, it is probably easier to verify that we catch both ioexception and kafkastrageexception in the request handling code than making sure we have a try/catch around every code that touches io. does this make sense?",0,0.9905356764793396
121320850,2929,lindong28,2017-06-12T07:00:26Z,i think it is probably better to keep `kafkastorageexception` as `apiexception` similar to the definition of`replicanotavailableexception`. the client code should not see `kafkastorageexception` if any replica is offline due to disk failure. instead the client should see e.g. `leadernotavailableexception` which is `retriableexception`. `kafkastorageexception` will only be received by controller. does this make sense?,0,0.9947511553764343
121347432,2929,ijuma,2017-06-12T09:32:10Z,"since it's an inner class of `metadataresponse`, there is no need to also add `metadataresponse` as a prefix to the inner class name.",0,0.9944429993629456
121349573,2929,ijuma,2017-06-12T09:41:19Z,"the intent is for `kafkacontroller.eventmanager` to be visible for testing (there's a comment next to the field). maybe we need to change the tests to access it reflectively since it's understandable that people may miss the comment. the reasoning is that by passing the `kafkacontroller` everywhere, it makes it harder to understand and limit the responsibility of each class. it would be nicer if we passed more granular instances . for example, this class needs `eventmanager`, `config`, `topicdeletionmanager` and `controllerchannelmanager`. if we passed those instead, we get a picture of what the class needs immediately instead of having to read every line of code.",0,0.9938255548477173
121349800,2929,ijuma,2017-06-12T09:42:24Z,i explained in another similar comment why `eventmanager` is passed explicitly.,0,0.9905479550361633
121350268,2929,ijuma,2017-06-12T09:44:36Z,"the semantics are not the same if you simply replace a volatile map with a mutable one in the face of concurrency (i haven't looked at the code, but the volatile implies that multiple threads are in play here).",0,0.9866460561752319
121351052,2929,ijuma,2017-06-12T09:48:27Z,you can remove it by value by using `def -= (x: a): this.type`.,0,0.9924620985984802
121467556,2929,lindong28,2017-06-12T16:56:01Z,"it may be useful to rename this class such that, instead of doing `new metadataresponse.partitionmetadata(...)` in the code, we can do `import org.apache.kafka.common.requests.metadataresponse.partitionmetadata` and `new partitionmetadata(...)` e.g. in `metadatacache.java`. the latter is more concise. anyway, i have replaced this todo with just a comment.",0,0.9891385436058044
121468083,2929,lindong28,2017-06-12T16:58:09Z,"thanks for the explanation. do you prefer to include `eventmanager` explicitly in the constructor of `controllerbrokerrequestbatch`, or is it ok to reference `eventmanager` via `kafkacontroller`?",1,0.6142506003379822
121468423,2929,lindong28,2017-06-12T16:59:26Z,thanks. i think i will keep the existing approach of including `controllereventmanager` in the constructor of those listeners since it is needed in the test. we can refactor them in a separate patch if it is necessary.,1,0.9032782912254333
121469351,2929,lindong28,2017-06-12T17:03:14Z,yeah i understand the meaning of volatile. can you explain a bit more specifically the case in which one can not be replaced by the other? thank you.,1,0.5788634419441223
121483933,2929,lindong28,2017-06-12T18:02:17Z,you are right. i have updated the patch to use `livelogdirs -= new file(dir)`.,0,0.9482077360153198
121559449,2929,ijuma,2017-06-13T00:33:56Z,"if one uses a volatile var, it's possible to update multiple entries in the map without exposing the intermediate states. with mutable maps, that's typically not possible without some form of external locking. on the other hand, one can lose updates by using a volatile var. generally, it's clearer to use a concurrentmap if that is the intent.",0,0.9903554916381836
121560258,2929,lindong28,2017-06-13T00:41:47Z,"thanks for the explanation . i have two follow-up questions. suppose we don't use a thread-safe map and choose to use an external lock to protect a non-thread safe map, then are these two approaches equivalent? and in this specific case, do you recommend me to replace the ` var map` with a `concurrentmap`?",1,0.9522542953491211
121563032,2929,ijuma,2017-06-13T01:08:16Z,"if you have an external lock during updates in both cases (like in this example), then the volatile version has the advantage that you don't need a lock on reads. the disadvantage is that there is potentially more copying. in this particular case, you are using `filterkeys` which is just a view on the underlying map. that doesn't seem like a good idea. aside from that, i have to look at the changes more closely to have a worthwhile opinion on what should be done here.",0,0.9700932502746582
121759231,2929,becketqin,2017-06-13T18:27:55Z,doing that later is fine.,0,0.9841921329498291
121762930,2929,becketqin,2017-06-13T18:42:07Z,"i am not sure about why it is safer to disable replica creation on a broker with failed directory. does that mean a broker will not get assigned any new replica as long as it has one disk failed? does that require controller awareness? but the controller does not know about that if it runs old ibp, right?",0,0.5477036237716675
121763195,2929,becketqin,2017-06-13T18:43:15Z,we should probably just remove the ` controller` if there is no java doc for it.,0,0.9911662936210632
121765991,2929,becketqin,2017-06-13T18:53:54Z,"this code is only called at startup time. it is to protect against data messed up from different brokers. since the broker hasn't started yet, it is probably ok for the broker to shutdown. users can remove the log dir from the path and restart the broker in this case.",0,0.994330644607544
121779680,2929,lindong28,2017-06-13T19:51:54Z,"note that this only matters when there is disk failure. let me try to explain it based in the following different scenarios: 1) all brokers are running old code. the choice of the default value doesn't matter in this case because the code in this patch won't be used. 2) brokers are rolling upgraded to use the new code but the ibp is still old. here is the concern with setting default value to true. suppose the broker is running new code and partition p1 is in an offline log directories of this broker. if controller is running old code and sends leaderandisrrequest asking this broker to be leader of p1, the broker will re-create partition p1 on a good log directory. the follower will truncate the log for p1 and the data will be lost. and kip-112 currently doesn't handle it the case that the offline disk is repaired and used again with p1 still in it. on the other hand, with default value set to false, broker will refuses to become leader for p1, controller will not handle re-elect leader for p1 because it is running old code. during this period partition will become unavailable because the producer/consumer will send request to this broker and receive notleadderforpartitionexception. however, this will only happen for a short period of time and the problem will be solved once the controller is moved to a broker which is running new code. thus in this case, it is safer to set default value to false. 3) all brokers are running new code but some brokers are still using old ibp. suppose controller sends leaderandisrrequest for a new partition p1 to a broker with offline log directory, the broker will refuse to create log for p1 and return error in leaderandisrresponse. since the controller is running new code, it will handle the error properly by re-electing leader for this partition. in the rare scenario that all brokers elected to be replicas for this partition have offline disk, the partition will be offline. but the chance of this happening is low and this will be addresses once the ibp is fully upgraded. 4) all brokers are running new code with the new ibp. in this case the leaderandisrrequest will explicitly specify the isnew field and the default value doesn't matter. does this make sense?",0,0.969189465045929
121779812,2929,lindong28,2017-06-13T19:52:31Z,thanks ! i will also think about it more.,1,0.9524537920951843
121780457,2929,lindong28,2017-06-13T19:55:32Z,i think the purpose of kip-112 is to make sure that broker be able to serve replicas on the good log directory even if there is bad log directory. we can not achieve this goal and the availability will be reduced if broker can not startup due to disk failure. can you explain a bit more why it is a concern if broker id load fails in one log directory? does this cause data corruption?,0,0.9720718860626221
121784846,2929,lindong28,2017-06-13T20:15:35Z,yeah you are right. i have removed it from the patch.,0,0.8841832280158997
122559063,2929,lindong28,2017-06-17T02:39:55Z,"discussed with offline. we decide to assume isnew = false if ibp is old. there are two options here when ibp is old. one is to be behavior of the current patch, i.e. broker will not shutdown if there is offline replica, and if there is new replica is assign to a broker will offline log directory, its creation will fail and the replica will be offline even if it can be created on a good replica. the other solution is to simply let broker shutdown if there is offline log directory. this allows new partition/topic to be assigned to only live broker and they won't be offline immediately after creation. we choose the first solution because it can keep the replicas on good log directories online at the cost of having all new replicas on that broker offline. it is likely that the number of new replicas assigned to that broker will be much less than the number of replicas on the good log directories of that broker. also, if user does prefer the second solution, he/she can manually shutdown that broker so that new replica will be online. i have updated the notes in `upgrade.html` to explain this.",0,0.978099524974823
122559075,2929,lindong28,2017-06-17T02:40:54Z,"discussed offline. i have updated the patch so that if there is ioexception when reading brokerid from metadata file, the corresponding log dir will be marked failure but the broker will not shutdown. on the other hand, after broker registers itself in the zookeeper, it will only try to checkpoint brokerid in the metadata files in the live log directory (i.e. `logmanager.livelogdirs`). most likely there won't be ioexception when writing to metadata files here. if there is, then broker will shutdown entirely.",0,0.9934040904045105
123092424,2929,becketqin,2017-06-20T20:53:29Z,"hmm, if that is the case, should the storage exception be converted to leadernotavailableexception when it is thrown for requests such as produce/fetch/listoffsets? also, in that case, does that mean the broker needs to hold on the response until the controller moves leadership? otherwise broker is essentially giving up leadership by itself without get the confirmation from the controller. another thing is that we need to make sure the error code returned matches what is reflected in the metadata response. i am not sure what is the best exception to return to the user in this case, but in general i would rather not reuse exceptions for different scenarios.",0,0.6523752808570862
123122372,2929,lindong28,2017-06-20T23:32:52Z,sure. i have made kafkastorageexception a retriable exception.,0,0.968716025352478
123122415,2929,lindong28,2017-06-20T23:33:18Z,i have fixed the issue by using the `if` statement as suggested.,0,0.9844918847084045
123651559,2929,becketqin,2017-06-23T00:30:24Z,we should also add a 0.11.1 version pointing to kafka_0_11_1_iv0,0,0.9951003193855286
123659570,2929,lindong28,2017-06-23T02:08:06Z,sure. i have updated the patch to address this issue. and the patch has been rebased onto the latest trunk.,0,0.9928181171417236
123817916,2929,becketqin,2017-06-23T18:38:02Z,do we need to create this field version?,0,0.9922235608100891
123832032,2929,becketqin,2017-06-23T19:54:25Z,"for these two cases, the broker needs to read data from internal topics asynchronously. it seems that in both case the broker will only log an error without notify the controller that they cannot serve as leaders for those two partitions.",0,0.9764960408210754
123836327,2929,becketqin,2017-06-23T20:20:01Z,looked a bit more. it seems that we are not handling the disk exceptions thrown from filerecords.readinto(). that method is also used by logcleaner. could you check?,0,0.9890166521072388
123840858,2929,becketqin,2017-06-23T20:45:37Z,the `truncateto` method can throw storage exceptions. if that storage exception happens in the `replicafetcherthread` it seems we are not handling that.,0,0.9857062101364136
123869098,2929,lindong28,2017-06-24T03:09:49Z,sorry. removed now.,-1,0.9913862943649292
123869183,2929,lindong28,2017-06-24T03:15:45Z,thanks for catching this. i have added `try/catch` for `truncateto`.,1,0.8192323446273804
123871120,2929,lindong28,2017-06-24T05:32:43Z,sure. i have updated the code to handle ioexception here.,0,0.9897574186325073
123884003,2929,becketqin,2017-06-24T19:40:12Z,this looks a little verbose. maybe it could just be `updatemetadatarequest.partitionstate`,-1,0.7435685992240906
123884171,2929,becketqin,2017-06-24T19:49:55Z,"should this class be in updatemetadatarequest? this patch introduces/modifies some classes containing similar fields, can we clean them up? we had some discussion on that before and i though a follow up patch is also fine. could you create another ticket to track this? more specifically, if there are common fields, an abstract partition state class would probably help. if there are additional partition state in different requests, those partitionsstate class should ideally extends from the abstract class and sit together with the corresponding requests.",0,0.9818904399871826
123884367,2929,becketqin,2017-06-24T20:01:18Z,"we are already checking the `isreplicalocal(replicaid)` above, can this logic be merged into that if statement?",0,0.9935532808303833
124189370,2929,becketqin,2017-06-27T06:45:27Z,"typo, filel -> file",0,0.9733947515487671
124197932,2929,becketqin,2017-06-27T07:34:37Z,i have the same question here. is it just to make sure we do not *lose* the log that failed to be removed?,0,0.9816577434539795
124200168,2929,becketqin,2017-06-27T07:47:39Z,is this the same as`logmanager.livelogdirs`?,0,0.9945031404495239
124413939,2929,becketqin,2017-06-27T22:35:56Z,"it seems that calling `replicamanager.handlelogdirfailure()` may cause deadlock here. say the broker is handling an leaderandisrrequest, it will first grab the `replicamanager.replicastatechangelock` and then grab the `abstractfetcherthread.partitionmaplock`. however, when handling disk failure in `replicafetcherthread.processpartitiondata()`, the locking order is reversed. one way to solve this is to add an abstract error handling method in abstractfetcherthread and invoke that out of the `partitionmaplock`.",0,0.9903213381767273
124416864,2929,becketqin,2017-06-27T22:55:08Z,logdirutils?,0,0.9875303506851196
124417294,2929,becketqin,2017-06-27T22:58:13Z,"it seems that in the existing code the broker will halt if `logmanager.cleanuplogs()` sees a disk exception here. but with the patch, it will just silently fail.",0,0.9592002630233765
124418494,2929,becketqin,2017-06-27T23:07:19Z,is this block needed?,0,0.9903821349143982
124429369,2929,lindong28,2017-06-28T00:32:18Z,sure. it is renamed now.,0,0.9876639246940613
124429977,2929,lindong28,2017-06-28T00:38:11Z,"sure. i can clean them up. in the interest of reducing conflicts with other patches, i refactor the code and clean it up in a follow up patch. i will create the ticket after this patch is committed.",0,0.988297164440155
124430275,2929,lindong28,2017-06-28T00:41:32Z,the `isreplicalocal(replicaid)` used above is only called if `replicaid` is not in `assignedreplicamap`. i couldn't find a good way to merge them. do you have a good way to do it?,0,0.9791550040245056
124430429,2929,lindong28,2017-06-28T00:43:07Z,thanks. fixed now.,1,0.9247483015060425
124430768,2929,lindong28,2017-06-28T00:46:48Z,not exactly the same because `config.logdirs` is a list of string whereas `logmanager.livelogdirs` is a list of file. i have updated the code to avoid the `if` statement.,0,0.9922940731048584
124438217,2929,lindong28,2017-06-28T02:07:35Z,great catch! it is fixed now.,1,0.9955857992172241
124439381,2929,lindong28,2017-06-28T02:19:21Z,good point. it is renamed now.,1,0.8903045654296875
124444527,2929,lindong28,2017-06-28T03:16:48Z,"thanks for catching this. this becomes a problem due to the use of `leaderepochcache` in kip-101. i have updated the patch to halt the system if `filenotfoundexception` is observed. while it is possible catch the ioexception thrown from this place and handle it, it will require a couple of try/catch/handle distributed across the code. and non-trivial change is needed to avoid deadlock because `replicafetcherthread.handleoffsetoutofrange()` may also trigger this code. i think the simplest approach is to just keep the existing code, i.e. halt the system if `filenotfoundexception` is thrown from here. i don't think it will affect the availability of jbod deployment because according to mayursh's comment, this `filenotfoundexception` is thrown if the broker is configured with raid. we can re-investigate this problem if this is also an issue when broker uses jbod.",1,0.7133943438529968
124445278,2929,lindong28,2017-06-28T03:25:41Z,yeah this is no longer needed in this test after a recent comment on jun 5. i will go through the core code after rebase but typically skip the test code if they pass. thanks for catching this! it is removed now.,1,0.9899376630783081
124479048,2929,becketqin,2017-06-28T08:19:26Z,"you are right, never mind.",0,0.6439488530158997
124685896,2929,junrao,2017-06-29T00:03:27Z,perhaps add a comment that summarizes what's changed in v1 of leaderandisr request?,0,0.9939501285552979
124686504,2929,junrao,2017-06-29T00:08:37Z,perhaps add a comment that summarizes what's changed in v4?,0,0.9928909540176392
124695356,2929,junrao,2017-06-29T01:37:04Z,could we avoid wrapping kafkastorageexception if e is already of kafkastorageexception?,0,0.9941760301589966
124696536,2929,junrao,2017-06-29T01:51:10Z,"state change log is for logging actions to requests from the controller. since this method could be called from serving non-controller request, perhaps it's better to just log it in the server.log.",0,0.9935519695281982
124711510,2929,lindong28,2017-06-29T04:49:26Z,i will replace `deleterecursively(...)` with `org.apache.kafka.common.utils.utils.delete(...)` in the next commit.,0,0.9938644766807556
124931997,2929,junrao,2017-06-29T23:01:39Z,"could we do filter { case (tp, log) .. } and map ( case (tp, log) ...} so that it's a bit clearer what's being referenced?",0,0.9924178123474121
124932600,2929,junrao,2017-06-29T23:06:13Z,is this worth logging?,0,0.9850500226020813
124932609,2929,junrao,2017-06-29T23:06:21Z,is this worth logging?,0,0.9850500226020813
124934166,2929,junrao,2017-06-29T23:18:20Z,we probably want to limit the places with direct zkutils access. perhaps it's better to send zk notification in replicamanger.handlelogdirfailure()?,0,0.9946017265319824
124935126,2929,junrao,2017-06-29T23:25:38Z,does this need to be synchronized inside logcreationordeletionlock since livelogdirs could be changed concurrently? offlinelogdirs could be called from a different thread for metric reporting.,0,0.9927071928977966
124935421,2929,junrao,2017-06-29T23:28:00Z,will it be worth adding a per logdir metric so that we can find out which individual log dir is online/offline?,0,0.9939790964126587
124936765,2929,junrao,2017-06-29T23:37:56Z,"perhaps it's better to only capture ioexception here? for other exceptions, it's probably better to just fail the broker as before.",0,0.9894651174545288
124940850,2929,junrao,2017-06-30T00:13:52Z,"there are a few places like logmanager.truncateto() where we call logmanager.handlelogdirfailure() directly. it seems that they should all call replicamanager.handlelogdirfailure() instead since it does things like taking the partition off allpartitions and removing the partition from replicafetchermanager, which need to be done on an offline logdir.",0,0.988964319229126
124947219,2929,junrao,2017-06-30T01:21:12Z,"so, here, we are not communicating the truncation error back to the replica fetcher thread. ideally, if the truncation fails, we shouldn't let the replica fetcher proceed with the subsequent fetching.",0,0.9895074963569641
124948445,2929,junrao,2017-06-30T01:30:13Z,is .toseq needed?,0,0.9929094910621643
124948786,2929,junrao,2017-06-30T01:33:58Z,"for consistency, it seems that we need to handle ioexception in truncatefullyandstartat() and call handlelogdirfailure() too?",0,0.9946655035018921
125063695,2929,junrao,2017-06-30T15:15:48Z,"we requeue the logs that failed deletion mostly because of ioexception. so, i am not sure if we need to requeue removedlog now.",0,0.9074028134346008
125064418,2929,junrao,2017-06-30T15:18:51Z,could we add a comment to explain what isnew means?,0,0.9802650213241577
125069246,2929,junrao,2017-06-30T15:40:50Z,"in line 709, we convert an ioexception to kafkastorageexception in log.append. i am wondering if this is needed since the caller of append handles both ioexception and kafkastorageexception. also, in replicamanager, sometimes we catch kafkastorageexception and some other times we catch both ioexception and kafkastorageexception. it would useful to make that consistent. for example, we can make the convention that ioexception will be throw from java library and kafkastorageexception will be throw in the kafka code (but not wrapping ioexceptions from java). then the caller will catch both ioexception and kafkastorageexception",0,0.9910734295845032
125073587,2929,junrao,2017-06-30T16:00:19Z,"hmm, not sure why we need the additional check here. if replicaid is not in assignedreplicamap, it probably shouldn't lead to a kafkastorageexception.",0,0.8056731224060059
125087026,2929,junrao,2017-06-30T17:13:36Z,we probably need to do the following optimization in delete() here? coreutils.swallow(forceunmap(mmap)),0,0.9946827292442322
125088146,2929,junrao,2017-06-30T17:19:41Z,unused import,0,0.9524969458580017
125094553,2929,junrao,2017-06-30T17:51:33Z,could we adjust the comment of the return value accordingly?,0,0.9927534461021423
125097858,2929,junrao,2017-06-30T18:05:59Z,partitionstate seems unused?,0,0.9841253757476807
125101226,2929,junrao,2017-06-30T18:21:56Z,"hmm, doloadgroupsandoffsets() just runs in a scheduler. should we call replicamanager.handlelogdirfailure() on ioexception too? if so, we probably want to do the same in txnmanager.",0,0.9934664368629456
125109233,2929,junrao,2017-06-30T19:02:30Z,"in controller failover, would it be worth to clean up all leftover sequence nodes in logdireventpath? those nodes won't be useful since the new controller will send a leaderandisrrequest to every broker on failover.",0,0.9882591962814331
125112249,2929,junrao,2017-06-30T19:19:03Z,"if a disk fail in the code path outside of the log cleaner, we should remove that dir from checkpoints too. is that logic added already?",0,0.9919978976249695
125120383,2929,lindong28,2017-06-30T20:05:00Z,thanks for catching this. i have updated the patch to say `leader_and_isr_request_v1 added a per-partition is_new field. this field specifies whether the replica should have existed on the broker or not`.,1,0.771335780620575
125120952,2929,lindong28,2017-06-30T20:08:44Z,"sure. i added the following comment for `update_metadata_request_partition_state_v4`, `update_metadata_request_v4` and `metadata_response_v5`. `... added a per-partition offline_replicas field. this field specifies the list of replicas that are offline`",0,0.9941089153289795
125121473,2929,lindong28,2017-06-30T20:12:07Z,sure. i fixed it with the follow code: [code block],0,0.9860976934432983
125121745,2929,lindong28,2017-06-30T20:13:47Z,previously i thought this is used for making partition state change. they are the same because previously all state change are triggered by controller request. i have changed the code to log it in the server.log.,0,0.9910889863967896
125123322,2929,lindong28,2017-06-30T20:23:17Z,"when `logcleaner` encounters ioexception when cleaning up the log, we want to mark the corresponding log directory as offline and inform controller of the log directory failure via zookeeper. note that this ioexception is not triggered by an external request and thus will not go through `replicamanager`. since we probably don't want to reference replicamanager via logmanager, `logmanager.handlelogdirfailure()` seems to be the only reasonable place to have this log of wrting to log directory notification znode. i couldn't find a better way to address this problem. do you have a better solution?",0,0.9167769551277161
125130310,2929,lindong28,2017-06-30T21:06:04Z,"another reason to put the logic of zookeeper notification in logmanger is that, currently logmanager is managing which logs are online or offline and thus is the source of truth of offline log directories. ideally we would like to put the logic of notification in the same place so that the notification is sent if and only if the offline log directories change.",0,0.9926438927650452
125136812,2929,lindong28,2017-06-30T21:52:18Z,"previously i think the chance of exception due to this race condition is so small (because disk failure should be rare) that we don't want to degrade performance by getting lock every time we read `livelogdirs`. for example, metrics reporting will access `abstractfetchermanager.fetcherthreadmap` and it seems fine so far. but strictly speaking, you are right that this can cause race condition and it is better to prevent this completely from any unknown consequence. so i made the following changes to address the problem: 1) use `_livelogdirs: arrayblockingqueue[file]` to record offline log directories. we don't have to worry about blocking operation because we will only remove log directory from it. i think this may be a little better than using `logcreationordeletionlock synchronized {}` every time we access `_livelogdirs` (e.g. `checkpointlogrecoveryoffsets()`, `checkpointlogstartoffsets` and metrics reporting) so that these access won't block `logmanager.createlog()` or `logmanager.asyncdelete()` 2) add `def livelogdirs: array[file] = _livelogdirs.asscala.toarray` so that we don't have to change test code to work with `arrayblockingqueue[file]`. 3) update various checkpoint() methods (e.g. `checkpointlogstartoffsetsindir(dir: file)`) so that they can handle the case that the directory in the input parameter gets removed from the checkpoint map right after the method begins.",0,0.9744547009468079
125137370,2929,junrao,2017-06-30T21:56:44Z,"we could probably pass in a onlogdirfailure callback to the logcleaner. an ioexception could be triggered in different places. however, independent of where it's triggered, we always want to react with the same process, which includes (marking the partition/replica as offline, remove partition from replicafetcher, notify the controller, etc). replicamanager seems to be the best place to consolidate that process.",0,0.9919203519821167
125138864,2929,lindong28,2017-06-30T22:07:56Z,"previously i don't think it is needed because if user wants to know which specific log directories are offline in addition to the offline log directory count, it probably means they want to fix the problem and they will login the machine anyway. in this case they can find the offline log directory name in the log. and user probably wants to fix the problem because the log itself gets deleted from the cluster because they need to see the exception trace to debug the problem. yes, it can make debug easier to have this metric. i have updated the patch with the following code: [code block]",0,0.9806385636329651
125139125,2929,lindong28,2017-06-30T22:10:15Z,sure. good point. i have updated the code to only catch `ioexception`.,1,0.5062103867530823
125142699,2929,lindong28,2017-06-30T22:44:00Z,"are you suggesting that `logmanager.handlelogdirfailure()` should invoke `replicamanager.handlelogdirfailure()` and `replicamanager` should be put in the constructor of the `logmanager`? this can be done. but i am worried that this creates circular dependency between `logmanager` and `replicamanager` and can make future development harder. in addition to the worry with this java class dependency, i also find hard to organize the methods. for example, say the broker receives a `producerequest`, triggers `replicamanager.appendtolocallog()`, which in turn calls `partition.appendrecordstoleader()` and fails with `ioexception`. note that we haven't touched `logmanger` in this path and thus `logmanger.handlelogdirfailure()` won't be called. now that the replicamanager catches an ioexception, ideally it should have its own method `handlelogdirfailure()` to deal with it, e.g. remove the corresponding topcpartition from `replicamanager.allpartitions` and `logmanager.logs`. then it become pretty straightforward to have `replicamanager.handlelogdirfailure()` to call `logmanager.handlelogdirfailure()`. but then it seems weird for `logmanager.handlelogdirfailure()` to invoke `replicamanager.handlelogdirfailure()` even though we can use some trick to make it work. do you have a solution to this circular invocation? currently if the ioexception is triggered by user's request, both `replicamanager.handlelogdirfailure` and `logmanager.handlelogdirfailure()` will be called so this is ok. if ioexception is triggered by e.g. `logcleaner`, only `logmanager.handlelogdirfailure()` will be triggered and some partition will still stay in `replicamanager.allpartitions`. as of now i don't find this to be a problem. because the next time any producerequest or fetchrequest tries to access a partition on that offline log directory, replicamanager will handle the log directory failure. also, i have updated the code so that `replicamanager.checkpointhighwatermarks()` will trigger `replicamanager.handlelogdirfailure()` if any partition in `allpartitions` is on an offline log directory. thus the period of inconsistency will be limited. does this address your concern?",-1,0.7080042958259583
125142923,2929,lindong28,2017-06-30T22:46:16Z,yeah i have concern with having `logmanager` call `replicamanager.handlelogdirfailure()`. we can continue the discussion in the other comment.,0,0.9872879981994629
125144710,2929,lindong28,2017-06-30T23:06:01Z,"yeah this can be improved. i removed this if statement and replaced this log with `info(s""stopping serving logs in dir $dir"")`.",0,0.9897112846374512
125144734,2929,lindong28,2017-06-30T23:06:16Z,no. i have removed this log.,0,0.9829094409942627
125144776,2929,junrao,2017-06-30T23:06:51Z,": my suggestion is that nobody should directly call logmanager.handlelogdirfailure() except for replicamanager.handlelogdirfailure(). the latter knows how to bring all parts to a consistent state with respect to ioexception, no matter where it's introduced. so, if a method hits an ioexception through replicamanager, we will just the ioexception bubble up to replicamanager and call replicamanager.handlelogdirfailure() there. if the ioexception is isolated logcleaner, we can somehow pass replicamanager.handlelogdirfailure() to logcleaner and let logcleaner call it. this way, any time a disk error is detected, it will be handled consistently no matter in which component the error is detected, which seems easier to reason about.",0,0.9908877611160278
125145180,2929,lindong28,2017-06-30T23:12:21Z,"sure. i have replaced this line with `val offlinetopicpartitions = logs.filter { case (tp, log) => log.dir.getparent == dir}.map { case (tp, log) => tp}`",0,0.9926543235778809
125145259,2929,lindong28,2017-06-30T23:13:35Z,hmm.. i couldn't remember why this is added in the first place.. removed now.,0,0.7206241488456726
125148715,2929,lindong28,2017-07-01T00:05:01Z,i see. do you think it is ok to have a method `logmanger.setlogfailurecallback()` that will be called in `kafkaserver.startup()` after the `replicamanager` is constructed? if yes then i will do it. we can not get not pass this callback to the constructor of `logmanager` because `logmanager` is instantiated before the `replicamanager`.,0,0.9903152585029602
125149426,2929,lindong28,2017-07-01T00:19:47Z,sure. i added the following java doc: [code block],0,0.985278844833374
125149731,2929,lindong28,2017-07-01T00:27:04Z,ok. i have updated the code to remove this re-enqueue logic.,0,0.9878799319267273
125152135,2929,lindong28,2017-07-01T01:57:02Z,"we need this check to address the issue we have been discussing in the other threads, i.e. the partition may have been removed in `logmanager` but not in `replicamanager`. in this case, replicaid will be in the assignedreplicamap even though the replica is offline. this additional check will make sure that `getorcreatereplica()` will throw kafkastorageexception in this case. more specifically, here is the currently workflow if logcleaner encounters ioexception: - `logmanager.handlelogdirfailure()` will remove this log dir and partitions and inform controller via zookeeper. - controller sends leaderandisrrequest for all partitions on this broker - `partition.getorcreatereplica()` for partitions on the offline log directory will throw kafkastorageexception, which in turn triggers `replicamanager.handlelogdirfailure()` so that those partitions can be removed from `replicamanager` as well.",0,0.992404043674469
125152284,2929,lindong28,2017-07-01T02:07:26Z,yeah i would like to invoke `replicamanager.handlelogdirfailure()` whenever there is ioexception. but this is not done yet because `logmanager` is not able to reference `replicamanager` since it is instantiated before the `replicamanager`. we can address this problem by doing `logmanager.setonlogdirfailurecallback()` after the replicamanage is instantiated. i find this to be a big ugly though. what do you think?,-1,0.948479950428009
125152579,2929,lindong28,2017-07-01T02:25:56Z,"btw, here is the current workflow if `logmanger.handlelogdirfailure()` is called by `logcleaner`. - `logmanager.handlelogdirfailure()` will remove this log dir and partitions and inform controller via zookeeper. - controller sends leaderandisrrequest for all partitions on this broker - `partition.getorcreatereplica()` for partitions on the offline log directory will throw kafkastorageexception, which in turn triggers `replicamanager.handlelogdirfailure()` so that those partitions can be removed from `replicamanager` and the `replicafetchermanager`.",0,0.9946446418762207
125152647,2929,lindong28,2017-07-01T02:29:54Z,sure. i have updated the patch to catch ioexception here. previously i had a long discussion with and we think it is ok to handle ioexception that currently doesn't trigger `halt()` in a followup patch. the reasons are recorded in this pull request. that is why i didn't catch ioexception here.,0,0.9891400337219238
125153306,2929,lindong28,2017-07-01T03:12:25Z,"the line in 709 is there before this patch. that is no longer needed after kip-112. i kept it there to avoid changing the indention of that code block so that the code diff and the code review can be a bit simpler. i will remove that conversion after most all comments have been addressed. besides the motivation of avoid changing code indentation, the current patch only convert ioexception to kafkastorageexception if the method needs to handle that ioexception before throwing that again. i assume that we don't want to have try/catch around all java library to convert ioexception to kafkastorageexception for code simplicity. as a result our kafka method may potentially throw both ioexception and kafkastorageexception and that is why some code needs to catch both. regarding the consistency, are you suggesting that the code that currently catches only the `kafkastorageexception` should be updated to catch both `ioexception` and `kafkastorageexception` and treat them as `kafkastoragexception`?",0,0.9770662188529968
125153341,2929,lindong28,2017-07-01T03:15:02Z,good point. i didn't realize we had this method. i have updated the code as suggested.,1,0.9392883777618408
125153345,2929,lindong28,2017-07-01T03:15:33Z,thanks. fixed now.,1,0.9247483015060425
125153388,2929,lindong28,2017-07-01T03:18:58Z,ah i should have done this. thanks for noticing this. i have updated the patch with the following comment: [code block],1,0.7515539526939392
125153403,2929,lindong28,2017-07-01T03:20:24Z,my bad.. removed now.,-1,0.9887231588363647
125153742,2929,lindong28,2017-07-01T03:43:25Z,good catch! i missed the fact that this method is run in a scheduler. sure. i have updated the patch to call relicamanager.handlelogdirfailure() in `doloadgroupsandoffsets()` when there is `ioexception`. i also reverted the change that was made to update the `responsemap` when there is `ioexception`. becket had similar comment and asked me to do the same in `transactionstatemanager`. i didn't do that because i am not sure i know `transactionstatemanager` good enough to handle ioexception in the best way. this is an existing problem with `transactionstatemanager` and probably other modules in kafka as well because they don't explicitly handle the scenario when the disk write operation fails. can we focus on the ioexception that currently causes `halt()` and leave the handling of ioexeption that are currently ignored (e.g. in `transactionstatemanager`) in follow up patch?,1,0.9507237076759338
125153969,2929,lindong28,2017-07-01T03:57:57Z,"no, that logic is not added. there are two reason i didn't do that. one reason is to avoid circular invocation. currently `logcleaner.handlelogdirfailure()` and `logcleanermanager.handlelogdirfailure()` will invoke `logmanager.handlelogdirfailure()`. it seems a bit ugly if we let `logmanager.handlelogdirfailure()` invoke `logcleanermanager.handlelogdirfailure()`. ideally the invoke between methods is a directed acyclic graph. the other reason is that it is not necessary to explicitly remove dir from `logcleanermanager.checkpoints` as long as `logmanager.handlelogdirfailure()` has already removed all partitions on the offline dir from `logmanager.logs`. note that all read or write operation on `logcleanermanager.checkpoints` is triggered by the partition in that log directory, which in turn comes from `logmanager.logs`. thus if all partitions on a dir is removed from `logmanager.logs`, it is guaranteed that this `dir` will no longer be used as key to access `logcleanermanager.checkpoints`. does this address the problem?",-1,0.5212858319282532
125154247,2929,lindong28,2017-07-01T04:22:13Z,good point. i have added the following methods in `logdirutils` and invoked this at the beginning of `oncontrollerfailover()`. [code block],1,0.7714216113090515
125369462,2929,lindong28,2017-07-04T00:07:26Z,i realized that there is one way to do this without using `logmanger.setlogfailurecallback ()`. we can provide `kafkaserver` to the constructor of `logmanager`. then `logmanager.handlelogdirfailure()` can call `kafkaserver.replicamanager.handlelogdirfailure()`. the disadvantage is that this exposes a log of things to `logmanger`. does this sound reasonable?,0,0.9929171800613403
125761540,2929,junrao,2017-07-05T21:25:42Z,it may not be efficient to do the exists check in every iteration of topicpartition since the exists check requires a scan of allpartitions. perhaps we could figure out the topics to be removed by first getting the uniqe topics from newofflinepartitions and then do the exists check on allpartitions?,0,0.9922001957893372
125762622,2929,junrao,2017-07-05T21:31:15Z,perhaps it's better to rename createlog to getorcreatelog?,0,0.9946289658546448
125773929,2929,junrao,2017-07-05T22:34:28Z,"hmm, currently, the java producer from 0.11.0.0 will treat this new exception as an unknown exception and won't retry. since we may add new error code that may be retriable in the future, perhaps we should make unknownserverexception a retriable error? if so, we probably want to do that in a separate patch and patch the 0.11.0 and probably the 0.10.2 branch as well.",0,0.9887204766273499
125796722,2929,junrao,2017-07-06T01:52:09Z,": good point on the circular dependency on constructing those objects. another approach that i am thinking is to have a diskfailurechannel which contains an in-memory queue. diskfailurechannel can be passed into all components such as logmananger, logcleaner, replicamanager, etc where io errors can be generated. if an io error happens in a component, it just enqueues the disk name into the diskfailurechannel. we can have a separate thread (maybe in replicamanager) that reads from diskfailurechannel and acts on it (e.g., remove partitions in replicamanager, remove logs in logmanager, remove partitions from replica fetcher), etc. this way, all disk errors will be handled consistently. the only thing is that disk errors will be handled asynchronously. however, i am not sure if disk errors need to be processed synchronously.",0,0.9194231629371643
125804911,2929,lindong28,2017-07-06T03:30:34Z,"thanks for the suggestion! one concern with having this queue for disk failure events is that, in the event a log directory fails, every attempt to access any replica in that log directory will generate a disk failure event for the same log directory. a lot of events may be instantiated and put into this queue which wastes cpu and memory. i am also concerned that we can not bound the number of events generated for a single disk failure since we don't know when the os will schedule that thread to read event from this queue. maybe we don't need this `diskfailurechannel`. we can just schedule a thread in `replicamanager` to read from `logmanager.offlinelogdirs` and call `replicamanager.handlelogdirs(dir)` when there is new offline log dir. i understand that the goal of this alternative approach is to make sure that the state in `replicamanager` (e.g. `replicamanager.allpartitions`) is consistent with the state in `logmanager` (e.g. `logmanager.logs`). and i agree that we can achieve this goal by having an extra thread in `replicamanager`. but i am not sure that the benefit of this alternative approach is worth the extra thread. note that the disadvantages of the alternative approach is: 1) it requires an extra thread in `replicamanager` which makes kafka's java class a bit more complicated; and 2) the log failure event will be processed asynchronously which potentially delays the controller notification and leader election. and we can not bound the delay. can you help me understand why it is necessary to keep state in `replicamanager` and `logmanager` consistent all the time? the current approach in the patch guarantees eventual consistency, i.e. the `replicamanager.handlelogdirfailure()` will be called after controller notification is sent and the broker receives `leaderandisrrequest` from controller. it seems that nothing will go wrong during the period of inconsistency -- if anything goes wrong then we will have the same issue with the alternative approach. and the alternative approach makes state consistent by delaying the execution of `logmanager.handlelogdirfailure()`. i will implement the alternative approach using an extra thread if the consistency is more important than the extra complexity and the potential delay in log failure handling.",1,0.9316359758377075
125806173,2929,lindong28,2017-07-06T03:47:24Z,good point. i replaced this with the following code: [code block],1,0.960280179977417
125806333,2929,lindong28,2017-07-06T03:49:38Z,sure. i have renamed this method as `getorcreatelog()`,0,0.9924403429031372
125807634,2929,lindong28,2017-07-06T04:07:01Z,now i understand the question. i am not sure we should make `unknownserverexception` a retriable error because i am a bit concerned with having unnecessary retry if we do that. i think we can keep the current practice by making an error retriable only if we know it should be retriable. is there any reason that we should make `unknownserverexception` retriable? i understand that `kafkastorageexception` was previously non-retriable because it is send to client as `unknownserverexception`. but i couldn't find anything wrong with making it retriable now. it also doesn't break any contract between client and server because client is now receiving a new error (i.e. kafkastorageerror) from client's perspective. is there any concern with this approach?,0,0.9507395625114441
126026144,2929,junrao,2017-07-06T21:54:51Z,"the issue that i am thinking is the following. the 0.11.0 client jar doesn't have the error code for kafkastorageexception. if the 011.1 server sends a kafkastorageexception to the 0.11.0 client, the client will treat it as an unknownserverexception and won't retry. however, ideally, we want the 0.11.0 client to retry in this case.",0,0.9761669635772705
126036453,2929,junrao,2017-07-06T22:55:31Z,": my thoughts are the following. (1) when reacting to a disk failure, it would be useful to handle this in order, e.g., removing the partition from replicamanager, followed by removing the log from logmanager. if you only remove the log from logmanager w/o removing the partition from replicamanager, then a request may hit an unexpected exception when trying to access the log, which is not ideal. (2) the notification to zk could take a long time if zk is not performing. doing the zk notification in a background thread reduces the potential latency impact to the client request. (3) we may implement a more sophisticated disk failure detection module (e.g., proactively verifying crcs in the log) in the future. having a diskfailurechannel allows us to integrate such a module easier (such a module only needs to interact directly with diskfailurechannel, instead of replicamanager). i agree that adding a separate disk failure handling thread adds a bit complexity, but probably not too much. to avoid building up the queue, perhaps diskfailurechannel can just maintain a disk dir set instead of a queue.",0,0.9851952195167542
126036708,2929,lindong28,2017-07-06T22:57:26Z,"i see. this makes sense. one concern with making `unknownserverexception` a retriable exception is that client may retry unnecessarily. maybe we can reduce unnecessary retries by distinguishing between `unknownserverexception` and `unknownexception`. an exception is an `unknownexception` if the error code is not found defined, .e.g. 0.11.0 client receives the error code for `kafkastorageexception`. thus the client wouldn't have to retry if server sends the error code of the existing server unknown exception. and the client will only retry unnecessarily if its client's version is (temporarily) lower than server's version. does this sound ok? i can submit a separate patch for 0.11.0 and 0.10.2 branch.",0,0.9873034358024597
126038803,2929,ijuma,2017-07-06T23:11:22Z,"the downside of any of the suggested approaches is that it won't help already released versions. another option would be to use an existing retriableexception when dealing with older clients. this would require bumping the relevant protocol versions though. going forward, it may make sense to define a `retriableunknownexception` that the broker can use to force older clients to retry.",0,0.9926797151565552
126090944,2929,lindong28,2017-07-07T08:08:48Z,"i agree with your points. thanks so much for the detailed explanation. i have updated the patch to include `logdirfailurechannel` and an extra thread in `replicamanager`. the `logmanager.handlelogdirfailure()` will only be called by `replicamanager.handlelogdirfailure()`, which in turn will only be called by that thread. and the offline log dir name will be put into `logdirfailurechannel` if there is new offline dir. the new thread will block waiting for new offline log dir. i have also updated the patch to revert changes such as the zkutils in the logmanager constructor. i have reviewed the changes and the entire patches myself before uploading it. i think all comments have been addressed. can you take another look at the patch? thanks much for your time!",1,0.9516631364822388
126091184,2929,lindong28,2017-07-07T08:10:28Z,i have updated the patch so that `logmanager.handlelogdirfailure()` will be called only by `replicamanager.handlelogdirfailure()`,0,0.9917928576469421
126091442,2929,lindong28,2017-07-07T08:12:13Z,i have updated the patch so that the partitions will be removed from the replica fetcher if truncation fails.,0,0.9923301339149475
126092808,2929,lindong28,2017-07-07T08:20:06Z,thanks for the suggestion. yes we can also name that new exception as `retriableunknownexception`. and `errors.forcode(code)` will return `retriableunknownexception` if the code is larger than maximum code of the defined error on the client side. my previous idea is to name the new exception as either `unknownexception` which will be retriable. the advantage is that the error will be more explicit about that it is -- a code that is not found in the client's library. the advantage of your solution is that we can re-use the new exception for any retriable exception. does this sound good to you?,1,0.7485107779502869
126236649,2929,junrao,2017-07-07T20:19:46Z,"hmm, if we bump up the protocol, wouldn't we have the same problem on the old client using the old protocol? i.e, if the broker hits a kafkastorageexception serving a request from the old client, we have to convert kafkastorageexception to sth that the old client can recognize.",0,0.9793211221694946
126243848,2929,lindong28,2017-07-07T20:57:01Z,"i guess i didn't understand ismael's suggestion w.r.t. the protocol version.. in my opinion, the long term approach is to have a new retriable exception, named as either `unknownexception` or `retriableunknownexception` such that an known error code will be translated to this exception on the client side. one short term solution we can do in this patch is to transform kafkastorageexception to the error code of notleaderforpartitionexception in produceresponse and fetchresopnse. this is hacky. but it should address this problem without causing any additional concern since producer/consumer shouldn't really care whether this is kafkastorageexception as long as it is retriable. what do you think of this short term solution?",-1,0.8353767991065979
126252343,2929,ijuma,2017-07-07T21:48:02Z,"yes, my suggestion was to bump the protocol so that we reuse an existing retriable exception for the old version and `kafkastorageexception` for the new version. and `retriableunknownexception` would be a way to avoid this hack in the future, but it doesn't help now.",0,0.9925200939178467
126256742,2929,lindong28,2017-07-07T22:18:36Z,"thanks much. this makes sense. i have updated the patch to include `unknownretriableexception`, bumped up the version of producerequest and fetchrequest, and converted kafkastorageexception to the error code of notleaderforpartitionexception for existing versions of produceresponse and fetchresponse.",1,0.9667028188705444
126448908,2929,junrao,2017-07-10T15:06:52Z,"hmm, this thread is interruptible. could we just make takenextlogfailureevent() block infinitely?",-1,0.6191809177398682
126462482,2929,junrao,2017-07-10T15:51:34Z,"this is going to affect how the replicafetchthread works. before this patch, if the replicafetchthread hits an ioexception during truncate, the affected replica will remain in the truncating state and the truncation will be retried. with the patch, since the ioexception is not propagated back to replicafetchthread, the replicafetchthread just assumes that the truncation has succeeded and moves onto the next stage. we want to preserve the original behavior.",0,0.9895411133766174
127005161,2929,lindong28,2017-07-12T16:30:58Z,this line can be removed. it probably becomes redundant after a rebase.,0,0.9897369742393494
127013042,2929,lindong28,2017-07-12T17:04:42Z,change java doc to the following ``` get the next offline log dir from logdirfailureevent queue. block waiting for up to the specified amount of time if there is no new offline log dir. ``,0,0.9938321113586426
127014976,2929,lindong28,2017-07-12T17:13:00Z,this can be removed now since we have `logdirfailurechannel`.,0,0.9930058717727661
127038150,2929,lindong28,2017-07-12T18:41:58Z,"never mind. this is still needed. if there is offline log dir, `getorcreatepartition()` will create the partition object before `getorcreatereplica()` fails with exception. in this case we need this code to remove the partition which doesn't have a valid local replica.",0,0.9273071885108948
127068479,2929,junrao,2017-07-12T20:51:59Z,could we adjust the above comment to reflect initialofflinedirs?,0,0.9949818253517151
127068824,2929,junrao,2017-07-12T20:53:23Z,this probably should be named islogdirectoroffline?,0,0.9906649589538574
127072655,2929,junrao,2017-07-12T21:09:18Z,_livelogdirs could change after the size check in line 77. should we tighten this up?,0,0.9913673996925354
127074402,2929,junrao,2017-07-12T21:17:20Z,should we swallow ioexception from the destroy() call?,0,0.9894826412200928
127075492,2929,junrao,2017-07-12T21:21:59Z,while load => while loading? ditto in line 292.,0,0.98346346616745
127077430,2929,junrao,2017-07-12T21:30:38Z,should we call logdirfailurechannel.maybeaddlogfailureevent() on initialofflinedirs? we call logdirfailurechannel.maybeaddlogfailureevent() on log dirs that fail during loading.,0,0.993089497089386
127078294,2929,junrao,2017-07-12T21:34:25Z,could we log the failed dir too?,0,0.9916227459907532
127078328,2929,junrao,2017-07-12T21:34:34Z,could we log the failed dir too?,0,0.9916227459907532
127084663,2929,junrao,2017-07-12T22:05:32Z,could we log the failed disk dir too?,0,0.9911817312240601
127084683,2929,junrao,2017-07-12T22:05:39Z,could we log the failed disk dir too?,0,0.9911817312240601
127236631,2929,junrao,2017-07-13T14:42:27Z,"should we add ""either""?",0,0.9931675791740417
127238635,2929,junrao,2017-07-13T14:49:02Z,"hmm, it doesn't seems that partition.deleterecordsonleader() can throw kafkastorageexception. it can throw ioexception though.",0,0.9815906286239624
127242028,2929,junrao,2017-07-13T15:00:27Z,perhaps it's simpler to just handle kafkastorageexception here instead of in line 579.,0,0.9938691854476929
127242867,2929,junrao,2017-07-13T15:03:26Z,perhaps it's simpler to just handle kafkastorageexception/ioexception here instead of in line 765?,0,0.995196521282196
127247023,2929,junrao,2017-07-13T15:17:18Z,"hmm, shouldn't we pass in the isnew flag to the getorcreatereplica() call in line 182 too?",0,0.9916744828224182
127262313,2929,junrao,2017-07-13T16:15:26Z,"once a partition is removed from allpartitions, future produce/fetch request will get an unknowntopicpartitionexception, ideally, it seems that they should get a kafkastorageexception for consistency?",0,0.9919227957725525
127267996,2929,junrao,2017-07-13T16:37:56Z,could we adjust the message a bit so that unknown_retriable can be distinguished from unknown? it would also be useful to add a comment on how it should be used differently from unknown.,0,0.9942851662635803
127268535,2929,junrao,2017-07-13T16:40:18Z,"hmm, i thought the plan is for uncaught exceptions still be unknown (i.e., not retriable), but if the server throws a new exception that's retriable, the server will send unknown_retriable to old clients.",0,0.8463968634605408
127270473,2929,junrao,2017-07-13T16:49:09Z,could we add some comment that describe the flow of how disk failure is handled here?,0,0.9926596283912659
127276896,2929,lindong28,2017-07-13T17:16:22Z,"i think it is probably not necessary to call this on initialofflinedirs. the purpose of calling `maybeaddlogfailureevent()` is to cleanup state (e.g. logmanager.logs) and notifying controller. for initialofflinedirs, the no state will be created for replicas in these offline log directories. and the broker hasn't registered itself in the zookeeper yet and thus controller will query this broker for state of all replicas afterwards -- thus no need to notify controller either. on the other hand, if any log directory fails during loading, it is possible that states have been created for some logs that directory but not others. in this case we need to call `maybeaddlogfailureevent()` to clean up the state.",0,0.993150532245636
127280905,2929,lindong28,2017-07-13T17:32:33Z,"i think it is probably ok to keep the current code. it is true that a log failure may happen right after the check in line 77. in this case the the caller may try to access that log directory that just became offline. however, there is no way to prevent this from happening since it is always possible for a log directory to become offline immediately before (or while) the caller tries to access it. thus caller code always needs to handle the possibility that log directory was removed from the state (e.g. `logmanager.recoverypointcheckpoints`). currently the only regular callers of `livelogdirs()` are those checkpoint routines. the code has handled with e.g. `this.recoverypointcheckpoints.get(dir).foreach(...)` to avoid nullpointerexception. does this make sense?",0,0.9936535358428955
127281494,2929,lindong28,2017-07-13T17:35:08Z,"initially i think it may be more concise to re-use the existing metric name with the additional tag. sure, i will replace this with `islogdirectoroffline`.",0,0.9885785579681396
127282168,2929,lindong28,2017-07-13T17:37:54Z,sorry. it is bad that i forgot to update comment. i have updated it to `create and check validity of the given directories that are not in the given offline directories...` i will go over the patch and see if there are other comments that i should update.,-1,0.993452787399292
127282599,2929,lindong28,2017-07-13T17:39:43Z,good point. i have updated the code as suggested.,1,0.9223363995552063
127283147,2929,lindong28,2017-07-13T17:41:39Z,thanks. i have fixed the typo now.,1,0.9258944392204285
127284560,2929,lindong28,2017-07-13T17:47:02Z,sure. i have also updated the corresponding comments in all checkpoint*() methods.,0,0.9910882711410522
127284651,2929,lindong28,2017-07-13T17:47:25Z,sure. fixed now.,0,0.9868775010108948
127284798,2929,lindong28,2017-07-13T17:48:01Z,sure. fixed now.,0,0.9868775010108948
127286069,2929,lindong28,2017-07-13T17:53:00Z,sure. fixed now.,0,0.9868775010108948
127289016,2929,lindong28,2017-07-13T18:04:32Z,i think this is ok. `isnew` flag is only matters for local replica. and the local replica of the leader broker must be in the insync replicas set and it will be created properly in line 173. maybe i can add a comment here. or do you like me to refactor the code a bit to call this method with the isnew flag?,0,0.9838622212409973
127291275,2929,lindong28,2017-07-13T18:14:03Z,yes that is the plan and it is actually implemented here. note that `errors.forexception(throwable t)` will return `errors.unknown` if the given exception is not listed in `errors.java`. and `errors.forcode(short code)` will return `errors.unknown_retriable` is the error code is out of the range of existing error codes listed in `errors.java`. our server code is not expected to call `errors.forcode(short code)` with a not-listed error code. the client may call `errors.forcode(short code)` with a not-listed error code if the client library version is smaller than the server library version and the server library has a new error code. in this case we want `errors.forcode(short code)` to return a retriable exception so that producer can re-send the message after metadata update. does this make sense?,0,0.9931322932243347
127294705,2929,lindong28,2017-07-13T18:27:30Z,sorry for the typo. it is removed now.,-1,0.9892439842224121
127300635,2929,lindong28,2017-07-13T18:50:23Z,yes you are right. previously i made a mistake that made me think that `arrayblockingqueue.take()` doesn't unblock after interruption. i have updated this to block infinitely.,0,0.8331211805343628
127301936,2929,lindong28,2017-07-13T18:55:37Z,good catch! you are right. i have updated the code to call `maybeaddlogfailureevent` and return kafkastorageexception if it is ioexception. i also updated the code not to catch kafkastorageexception.,1,0.9905647039413452
127305273,2929,lindong28,2017-07-13T19:08:56Z,sure. i have updated the patch as suggested.,0,0.9911383986473083
127307745,2929,lindong28,2017-07-13T19:20:02Z,sure. i have updated the code as suggested.,0,0.9912282228469849
127361245,2929,lindong28,2017-07-14T00:11:31Z,removed now.,0,0.9739603996276855
127361297,2929,lindong28,2017-07-14T00:12:02Z,fixed now.,0,0.9818974137306213
127376539,2929,lindong28,2017-07-14T03:02:30Z,"sure. i have renamed the variable `unknown` to `unknown_server_error` to distinguish it from `unknown_retriable`. i think it is reasonable because the corresponding exception is `unknownserverexception`. if we want to further differentiate the two, we also rename `unknown_retriable` to be `unknown_client_retriable` and rename `unknownretriableexception` to `unknownclientretriableexception`. what do you think? and i added the following comment for `unknown_retriable`. does that look ok? [code block]",0,0.9866933226585388
127377150,2929,lindong28,2017-07-14T03:10:28Z,sure i added the following comment. does this look ok? [code block],0,0.9818336367607117
127380697,2929,lindong28,2017-07-14T03:56:50Z,"good point. i have updated both the `logmanager.truncateto()` and `logmanager.truncatefullyandstartat()` so that these two method will call `maybeaddlogfailureevent()` and throw a kafkastorageexception if ioexception is caught. this preserves the previous behavior. based on your previous comments, i get that it is a bit ugly in when and where we should catch ioexception or kafkastorageexception. it is also not nice to have code that needs to decide whether we should throw the original kafkastoragexception or encapsulate the original ioexception into a kafkastorageexception. after thinking through this issue, i made the following changes to make the logic cleaner - `logdirfailurechannel` is now passed to the constructor of `log` and `logsegment` so that they can enqueue offline log dir when there is ioexception. - the patch guarantees if `maybeaddlogfailureevent()` is called before a new kafkastorageexception object is instantiated (except for very few scenarios where we know it is not needed). thus we do not need to call `maybeaddlogfailureevent()` when kafkastorageexception is caught. - we only need to call `maybeaddlogfailureevent()` when ioexception is caught. when ioexception is caught, we can either log the error and swallow the exception, or we can throw a new instance of kafkastorageexception so that the outside code can catch it and generate the proper error in the response.",1,0.6415671110153198
127380827,2929,lindong28,2017-07-14T03:58:34Z,actually i find it better to name the new error as unknownerrorcode. i will use it in the updated patch. i also moved the comment to `unknownerrorcodeexception.java`. do you think this name is better?,0,0.9891558289527893
127381549,2929,lindong28,2017-07-14T04:06:25Z,i still keep the code to catch `kafkastorageexception` since it may be useful if the underlying code re-throws kafkastorageexception in the future. it is a safe choice. but we no longer needs to call `maybeaddlogfailureevent` when kafkastorageexception is caught for the reasons explained in the other comment.,0,0.9908168315887451
127410791,2929,lindong28,2017-07-14T08:36:25Z,initially i thought it is ok and simpler to just return `unknowntopicpartitionexception` since the client only cares whether it needs to retry or not. but you are right that it is better and consistent to always return kafkastorageexception if client attempts to access a replica that is on an offline log directory. i have updated the patch with considerable change to achieve this consistency.,0,0.9882256984710693
127411380,2929,lindong28,2017-07-14T08:40:01Z,i added this comment to line 182: `we don't need to specify isnew flag since the local replica would have been created already`,0,0.9900638461112976
127600194,2929,lindong28,2017-07-16T06:53:27Z,"after more thought, i think it simpler to just specify the isnew flag so that future developer doesn't need to think about it. i have updated the patch to do so.",0,0.9757762551307678
127772691,2929,junrao,2017-07-17T17:37:25Z,"for code like this, perhaps it's useful to add a comment since it's easy to forget about the original reason over time.",0,0.9874516129493713
127794464,2929,junrao,2017-07-17T18:58:46Z,"hmm, now i am wondering if adding unknown_error_code is really a good idea. by adding this, the broker has to consider 3 different types of clients when adding a new retriable error: (1) clients that don't understand unknown_error_code; (2) clients that understand unknown_error_code, but don't understand the new specific error code (e.g., kafka_storage_error); (3) clients that understand the new specific error code. the broker has to send different error codes for those three different cases (1) send an existing retriable error (2) send unknown_error_code; (3) send the specific error code. we have to do this for each type of request that can receive the new error code. an alternative is the following. we don't introduce unknown_error_code. if the broker introduces a new retriable error, we bump up the request protocol. the broker (a) sends an existing retriable error for clients that don't understand the new specific error code; (b) sends the new specific error code otherwise. this seems simpler.",0,0.915998101234436
127807824,2929,junrao,2017-07-17T19:53:39Z,"if would be useful to double check which requests other than produce/fetch can receive and care about kafka_storage_error. it seems that offsetcommit, offsetforleaderepoch, listoffsets and deleterecords could receive this. not sure if they all care about it though. a few new requests for eos could probably also hit this, which can be addressed in s a separate patch.",0,0.9784333109855652
127811509,2929,junrao,2017-07-17T20:09:05Z,islogdirectoroffline => islogdirectoryoffline,0,0.9848479628562927
127814413,2929,junrao,2017-07-17T20:21:06Z,islogdirectoroffline => islogdirectoryoffline,0,0.9848479628562927
127827127,2929,junrao,2017-07-17T21:12:09Z,the comment seems outdated now.,0,0.8083242774009705
127837300,2929,junrao,2017-07-17T21:59:10Z,"hmm, not sure what the convention is now in handling ioexception at the log/logmanager level. we could (1) turn all ioexception in log to kafkastorageexception and call logdirfailurechannel.maybeaddlogfailureevent(). then, in replicamanager, we don't need to deal with ioexception. (2) let the ioexception for log to bubble to replicamanager and call logdirfailurechannel.maybeaddlogfailureevent() in replicamanager. it seems that the patch does a mix of both (1) and (2). in logmanager.getorcreatelog(), it seems it's possible for an ioexception to be thrown. in log, we are turning all ioexceptions to kafkastorageexception. it seems that it's better to pick either (1) or (2) and do it consistently in all places?",0,0.9826368689537048
127838104,2929,junrao,2017-07-17T22:03:17Z,"hmm, could we get ioexception here? i thought now the convention is to catch all ioexception in the log level and convert it to kafkastorageexception?",0,0.9815599918365479
127842977,2929,junrao,2017-07-17T22:32:36Z,perhaps it's better to use eq (reference equality).,0,0.989795982837677
127845994,2929,junrao,2017-07-17T22:49:50Z,this seems to break the convention of not calling maybeaddlogfailureevent on kafkastorageexception?,0,0.965236485004425
127846644,2929,junrao,2017-07-17T22:53:47Z,"hmm, the callers of getlogendoffset() don't seem to expect an exception.",0,0.8413408398628235
127849554,2929,junrao,2017-07-17T23:13:16Z,we don't need to mention producerequest here since it's not an inter broker request.,0,0.9908072352409363
127850607,2929,junrao,2017-07-17T23:20:51Z,should we do this on any ioexception?,0,0.9857204556465149
127858289,2929,junrao,2017-07-18T00:21:57Z,"the comment seems inaccurate. we are sending all replicas, not just live replicas in the leaderandisrrequest.",-1,0.9048832654953003
127864124,2929,junrao,2017-07-18T01:19:49Z,it would be useful to replace leaderandisrpartitionstate and metadatapartitionstate with partitionstate and updatemetadatarequest.partitionstate. this can be done in a followup cleaning patch.,0,0.9945411086082458
127864321,2929,junrao,2017-07-18T01:22:09Z,unused import timeunit,0,0.9792532920837402
127864547,2929,junrao,2017-07-18T01:24:18Z,"unused imports seq, set.",0,0.9792850017547607
127864941,2929,junrao,2017-07-18T01:28:24Z,it seems that we should check if the notification is of logdirfailureevent in logdireventnotification.process()?,0,0.9952001571655273
127865003,2929,junrao,2017-07-18T01:29:10Z,unused import,0,0.9524969458580017
127865578,2929,junrao,2017-07-18T01:34:27Z,using a null replicamanager to represent an offline partition seems a bit hacky. could we just add a new offline flag in the constructor?,-1,0.9631474614143372
127865966,2929,junrao,2017-07-18T01:38:40Z,could we add a comment that leader_and_isr_response_v1 can receive the new kafkastorage error code?,0,0.9946843981742859
127866463,2929,junrao,2017-07-18T01:44:15Z,check whether is offline log directory => check whether there is offline log directory ?,0,0.9895634055137634
127867135,2929,junrao,2017-07-18T01:52:02Z,"hmm, a couple of thoughts on this. if the broker is still on an old inter-broker protocol, the controller won't be able to handle the failed disk dir event. so, the broker will be up with offline replicas, but new leaders can't be elected. perhaps it's better to just failed the broker in the old way if the inter-broker protocol is old? related to this, i am wondering if it's useful to add a config to turn off this new feature. this way, if there is a bug, the user has the option to switch to the old behavior.",-1,0.6422297954559326
127867830,2929,junrao,2017-07-18T01:59:15Z,"in the following line in line 65, shouldn't we set the desired version to 4 if magic is on v2? super(apikeys.produce, (short) (magic == recordbatch.magic_value_v2 ? 3 : 2));",0,0.995486319065094
127885491,2929,lindong28,2017-07-18T05:32:18Z,"thanks much for the quick review! i think the current approach is probably simpler. the broker only needs to know 2 types of the clients instead of three, i.e. one that knows unknownerrorcodeexception and one that doesn't. if the request of the client suggests that the client knows unknownerrorcodeexception, then the broker will simply send the origin error code. the client library will convert the error to unknownerrorcodeexception if the error code is not recognized. otherwise, the broker should convert the new error code to an existing error code before sending the response. note that we need at most one `if/else` in each response to check whether the client knows unknownerrorcodeexception given the request version. on the other hand, the alternative approach requires kafka to potentially have multiple `if/else` in each response to check whether the clients know each newly-added error code. the number of check will increase overtime as we add more and more new error code. thus the current approach seems simpler. what do you think?",1,0.9853858947753906
127885621,2929,lindong28,2017-07-18T05:33:53Z,ah.. fixed now.,0,0.9456441402435303
127885629,2929,lindong28,2017-07-18T05:34:00Z,fixed now.,0,0.9818974137306213
127886423,2929,lindong28,2017-07-18T05:41:53Z,sure. i added this comment: [code block],0,0.9863816499710083
127889378,2929,lindong28,2017-07-18T06:11:39Z,"yeah had similar comment as well but i find that the patch in its current form is simpler. this is because not all exceptions bubble to the replicamanager. for example, both replicafetchthread and logclean may attempt to truncate the log which doesn't go through replicamanager. and we may have more ioexeption from new methods in the future. thus (2) alone wouldn't work. alternatively we can do (1) only, e.g. find all operations that may cause ioexception, catch/call logdirfailurechannel.maybeaddlogfailureevent() and re-throw a kafkastorageexception. my concern with this approach is that we will need to identify all possible calls that may throw ioexception and make sure that ioexception does not bubble up to replicamanager because otherwise we will return unknownserverexception in the response. this is doable but it requires carefully review of the code which may be error-prone both now and in the future development. on the other hand, if we can catch ioexception in the replicamanager where we generate the error code for various response, we can ensure that if any request handling incurs ioexception, we will trigger `maybeaddlogfailureevent` and return the proper error code. thus the current mixed approach seems simpler and more reliable than the approach (1). does this explanation sound reasonable? while i understand that consistency is a good feature, is there specific benefits of doing (1) only?",0,0.9894248247146606
127890064,2929,lindong28,2017-07-18T06:17:58Z,good point. i fixed all of them.,1,0.9883099794387817
127890791,2929,lindong28,2017-07-18T06:24:33Z,"no.. currently i didn't catch/try ioexception for methods like log.append(), logsegment.append() or offsetindex.append(). i feel that kafka' code will be cleaner and more reliable if we can catch ioexception in the methods which handle request and generate response. the only reason not all ioexception are caught in replicamanager or kafkaapi is that we have checkpoint file operation, replicafetcherthread or logcleaner which does io operation without requiring external request.",0,0.9816080927848816
127891075,2929,lindong28,2017-07-18T06:27:02Z,i see. i replaced the comment with this: `mark partition as offline in the cache if the local replica creation has failed due to offline log directory`,0,0.9932225942611694
127891341,2929,lindong28,2017-07-18T06:29:21Z,this is just for code simplicity of not having to duplicate the code of logging error and populating the response map. do you want me to separate them?,0,0.9818556904792786
127892176,2929,lindong28,2017-07-18T06:36:30Z,i think the behavior of throwing the exception is the same as returning none for `groupmetadatamanager`. i am not sure very what is the right behavior for `transactionstatemanager` if the corresponding partition is in offline log directory. previously i think it is reasonable to throw kafkastorageexception if the partition is offline. but i am not strong on this. i have changed it to return none instead.,0,0.8450180292129517
127892430,2929,lindong28,2017-07-18T06:38:32Z,"thanks. i see. i have removed producerequest, fetchrequest and metadatarequest from this comment.",1,0.9602667689323425
127894263,2929,lindong28,2017-07-18T06:51:19Z,"i have thought about catching ioexception here. after reading [a link] i am still not sure why we previously didn't halt the kafka on any ioexception here. there are also some ioexception that are explicitly thrown in this class that do not trigger halt. i couldn't find a reason not to catch ioexception either. i choose to be conservative by preserving the behavior by not doing this on all ioexception just in case we have a reason not to do so. would you like me to do this on any ioexception? alternatively, maybe we can discuss the handling of these specific ioexception in a followup patch?",0,0.9231008887290955
127894415,2929,lindong28,2017-07-18T06:52:19Z,good point. you are right. i removed the `live` here.,1,0.9852569699287415
127894505,2929,lindong28,2017-07-18T06:52:58Z,thanks!! i will do it in a followup patch.,1,0.989912211894989
127894624,2929,lindong28,2017-07-18T06:53:46Z,ah it somehow escaped from my reviews.. removed now.,0,0.9740686416625977
127894717,2929,lindong28,2017-07-18T06:54:26Z,my bad.. removed now.,-1,0.9887231588363647
127896162,2929,lindong28,2017-07-18T07:05:01Z,initially i think it is ok not to check it since there is only one type. it is similar to how we currently have a version field in the reassignment json file provided to `kafka-reassign-partitions.sh` but we currently don't check that version either. but it is also reasonable to check it. i have updated the code to throw illegalargumentexception is the event type value is not 1.,0,0.9843391180038452
127896355,2929,lindong28,2017-07-18T07:06:23Z,not sure why i missed these.. removed now.,0,0.6826038956642151
127897210,2929,lindong28,2017-07-18T07:12:18Z,"initially i wanted to avoid adding complexity to the constructor. sure, i have added isoffline flag to the constructor.",0,0.9917433857917786
127897438,2929,lindong28,2017-07-18T07:13:34Z,sure. i added this: `leaderandisrresponse v1 may receive kafka_storage_error in the response`,0,0.9920199513435364
127897524,2929,lindong28,2017-07-18T07:14:08Z,thanks for catching this. fixed now.,1,0.9032022356987
127898698,2929,lindong28,2017-07-18T07:21:48Z,"as long as the controller and the broker is running new code, the controller will be able to handle the failed disk dir event even if the inter-broker protocol is still old. more specifically, if there is log directory failure, the broker will write a sequential znode in zookeeper, the controller will send leaderandisrrequest, broker will specify error in the response, and the controller will trigger leader election. none of these steps require new inter-broker protocol. does this make sense? i am not sure we should add a config just to take care of the potential bug. ideally we don't want to add a config just for short-term use. the typical way of handling bug is to either hotfix the code or rollback to the last stable version. any kip or big code change may potentially have bug and it seems a big weird to add a config to handle the bug. adding this config is easy since all we need is to tell logdirfailurehandler to halt the broker when there is log directory failure. do you think it is necessary?",0,0.9628731608390808
127899953,2929,lindong28,2017-07-18T07:28:56Z,"no. this is the only improvement in my mind that i haven't made in this patch. i mentioned this in a comment after my last commit yesterday. as of this patch, producer will still send producerequest with version 3 if the message magic value is 2. this is because the newly-added produce version 4 is incompatible with 0.11 broker. as of now our producer determines the request version based on the minimum magic value in the data instead of using the apiversionsrequest to negotiate the this with the broker. this wasn't a problem in the latest kafka but this is causing problem for patches like kip-112 which wants to bump up producrequest version without bumping up the magic value. i don't think this is a critical problem for kip-112 since notleaderforpartitionexception in the response is a reasonable workaround. can i fix this issue in a followup patch later?",0,0.9799579977989197
127902927,2929,lindong28,2017-07-18T07:44:43Z,sure. i will go over all existing request and see if they need to handle kafkastorageexception specifically.,0,0.9863812327384949
127912013,2929,lindong28,2017-07-18T08:28:42Z,"another way i look at this is that, regardless of what the underlying code does, the outside code, i.e. those methods that determines the response, should catch all exception and determine the error in the response properly. this is similar to why we currently catch `throwable`. it is just that, instead of catching ioexception (as part of the throwable) and return unknownserverexception, it seems more reasonable to call `maybeaddlogdirfailure()` and return kafkastorageexception on ioexception.",0,0.9927706122398376
128041151,2929,junrao,2017-07-18T17:26:57Z,": ok, what you said about the approach in the patch makes sense. i was just wondering if we can achieve the same w/o introducing unknownerrorcode. the alternative that i suggested also just needs 1 if/else check. basically, you bump up the client request protocol, if the client is on the old protocol, the broker sends an existing retriable error code. otherwise, the broker sends the new specific error code. so, the logic is about the same as your patch, but we don't need to introduce unknown_error_code. this seems a bit simpler since we don't have to explain to the client developers the subtle difference btw unknown_error_code and unknown.",0,0.8988509178161621
128042260,2929,junrao,2017-07-18T17:30:51Z,": we don't necessarily have to go purely with (1) or (2). however, it would be useful to have a convention that we can follow in the future. could you summarize that convention? i seems that you are saying that all ioexception for client facing requests (but not inter broker requests) will be turned to kafkastorageexception in the log level?",0,0.99076908826828
128042285,2929,junrao,2017-07-18T17:30:58Z,"hmm, we do convert ioexception to kafkastroageexception in log.append(), right?",0,0.9889194369316101
128042324,2929,junrao,2017-07-18T17:31:05Z,"fetchrequest is used by inter broker replication. so, we need to include it.",0,0.9891882538795471
128042447,2929,junrao,2017-07-18T17:31:35Z,"in the future, we may need to add new event type. then, when upgrading a broker, the controller may see a new event type that it doesn't understand yet. so, it would be useful for the logic in the controller to be resilient to that.",0,0.989682674407959
128042652,2929,junrao,2017-07-18T17:32:21Z,"is that true? in controllerchannlemanager, if the inter broker protocol is before 0.11.1, the controller will send v0 of leaderandisrrequest and the response won't have kafkastorageerror, which means that the controller won't be able to move failed replicas to offline?",0,0.9878783822059631
128044355,2929,lindong28,2017-07-18T17:38:37Z,"for offsetcommitrequest, i have updated the patch so that server will send `errors.not_coordinator` in the response if there is kafka_storage_error. this is similar to how broker currently converts not_leader_for_partition to not_coordinator when handling offsetcommitrequest. no change on the client side is needed. for offsetforleaderepoch, the server will send kafka_storage_error and the replica fetcher thread will retry if there is error -- it doesn't care which error it is. thus no change is needed. for listoffsets, the server will send kafka_storage_error and the client will convert this error to stalemetadataexception which extends invalidmetadataexception. thus no change is needed.",0,0.9935139417648315
128045320,2929,lindong28,2017-07-18T17:42:24Z,oops.. i added it back.,0,0.714377224445343
128048615,2929,lindong28,2017-07-18T17:54:31Z,"hmm.. not sure if i fully understand the alternative approach. let say we introduced two new retriable errors a and b for produceresponse in the future. a is added in version 5 and b is added in version 6. if we have unknown_error_code, then the response handling logic would look like this: [code block] on the other hand, if we don't have unknown_error_code, then the response handling logic would look like this, which increases over time as we have more and more new errors. [code block] thus it seems that unknown_error_code can make things a bit easier. does this make sense?",0,0.9250365495681763
128049363,2929,lindong28,2017-07-18T17:57:19Z,"right, this makes sense.",0,0.9617744088172913
128050930,2929,lindong28,2017-07-18T18:03:02Z,"i still think it is true.. in this case, controller will send leaderandisrrequest v0 which doesn't explicitly specify the isnew flag. the broker will assume isnew = false when it attempts to create the local replica. and if there is log directory fail, then broker either dies (if it is running the old code) or the broker will specify kafkastorageexception in the response (if it is running the new code). then the controller can move failed replicas offline. this works because leaderandisrresponse v0 already allows broker to specify per-partition error code. does this make sense?",0,0.9883813261985779
128057016,2929,lindong28,2017-07-18T18:26:44Z,my bad... i missed this. i have removed this ioexception handling here.,-1,0.9893916845321655
128064844,2929,junrao,2017-07-18T18:58:50Z,got it. this is assuming that the new error code is a retriable error. how would the logic compare if the new error code is not retriable?,0,0.9817147254943848
128067682,2929,junrao,2017-07-18T19:08:02Z,"got it. i forgot that we don't convert the error code in leaderandisrresponse. then the issue is mostly when you have a mix of brokers with old and new code. if the controller happens to be on the broker with the old code, it wouldn't react to disk failure events until the controller is upgraded. in a larger cluster, rolling upgrade could take some time and leaving the offline replicas unprocessed for long is probably not ideal. if we only apply the new logic when the inter.broker protocol is 0.11.1, then the above issue can be addressed since at that point, we expect every broker to be on the new code. a minor related issue is that the offlinereplicas won't be propagated properly until the controller's inter broker protocol is on 0.11.1. this will affect the metadata response. not sure if we can avoid this completely. it would be useful to at least document this.",0,0.8665481209754944
128076192,2929,lindong28,2017-07-18T19:45:28Z,"if the new error is not retriable, then the client will convert the unknown error code to unknownserverexception which is non-retriable. i think it is a reasonable solution before the client library is upgraded.",0,0.9817420840263367
128076999,2929,lindong28,2017-07-18T19:48:56Z,both are good points. i will update the logdirfailurehandler so that it will halt the broker if the inter broker protocol is before 0.11.1.,0,0.8574215769767761
128078560,2929,lindong28,2017-07-18T19:55:33Z,"my previous convention is that: 1) ioexception should maybeaddlogdirfailureevent. 2) ioexception should either be logged or be re-thrown as kafkastorageexception. 3) kafkastorageexception should not trigger maybeaddlogdirfailureevent. previously i feel it is simpler to catch ioexception in the replicamanager similar to how we handle most other exceptions that happen during request processing. and i intend to avoid adding big try/catch because it typically makes code review harder. now i agree with you that it is a good idea to keep it consistent and try to catch ioexception before the replicamanager. i have updated the patch so that the replicamanger no longer needs to catch ioexception at all. ioexception is now caught in e.g. log, logmanager and checkpointfile. these ioexception will trigger maybeaddlogdirfailureevent() and be re-thrown as kafkstorageexception. i think this address the issue here.",0,0.8835914731025696
128079255,2929,lindong28,2017-07-18T19:58:32Z,i have updated the code so that replicamanager no longer needs to catch ioexception at all including here.,0,0.9881608486175537
128082294,2929,lindong28,2017-07-18T20:12:18Z,"i don't know why we don't halt the server on ioexception when reading or writing the checkpoint file. anyway, i have updated the patch to catch ioexception when reading/writing the checkpoint file, call maybeaddlogdirfailureevent(), and re-throw a kafkastorageexception. thus this issue is also addressed.",0,0.9786996841430664
128097699,2929,lindong28,2017-07-18T21:14:51Z,"ah, i probably misunderstood your previous question. if the new error code is non-retriable and client library already knows unknownerrorcodeexception, then the client library will treat the new error as a retraible error. it means that client may retry unnecessarily instead of failing fast. i think this is ok and better than having client failing immediately when it should retry.",0,0.5967026948928833
128097968,2929,junrao,2017-07-18T21:15:58Z,"hmm, if a new error is not retriable, the server code will probably look like the following. [code block] so, you don't really save code if the new error is not retriable. another thing that bothers me a bit is that the logic for handling a retriable error is a bit different from that for handing a non-retriable error. in the alternative approach, at least any new error code is handled in the same way.",0,0.7528836131095886
128106111,2929,lindong28,2017-07-18T21:53:32Z,"my use-case for unknownerrorcodeexception is based on the assumption that it is always ok for client to retry. the client should always have a reasonable timeout setting if it retries. thus if the original error is non-retriable, the client will block unnecessarily up to that timeout which is not that bad. also, for requests that don't want to retry on unknown error code, we can always update its response handling logic to skip retry if error == unknownerrorcodeexception. does this sound reasonable? if not, then i think we will have to add specific if/else for potentially a few requests for every new error in the future. i can remove the unknownerrorcodeexception if you prefer not to make the decision in this patch.",0,0.9340522885322571
128109393,2929,junrao,2017-07-18T22:10:42Z,the issue with retrying on any unknown error is that an app (e.g. mirrormaker) could set the retry to infinite and then it won't be aware of the error. adding a new if/else statement for every new error code is not necessary bad as long as the process is clear. adding unknownerrorcodeexception seems more complicated to me at this moment. perhaps we could remove it and reconsider it later if there is a need.,0,0.7543846368789673
128110294,2929,junrao,2017-07-18T22:14:52Z,"thanks. discussed this a bit with jason. it seems that we probably need to extend the current desired version logic to support the possibility of having multiple versions on the same magic (perhaps having a desired version range). so, we can do this in a followup jira. if you ping jason on that jira, he can help you with some suggestions.",1,0.9739539623260498
128133249,2929,lindong28,2017-07-19T01:13:44Z,"sure! after this pull request is closed, i will create tickets for all the todos mentioned in the discussion of this pull request. i will ping you and json for review later.",0,0.9611347317695618
128133400,2929,lindong28,2017-07-19T01:15:19Z,sure. i have removed the unknownerrorcodeexception in the latest patch.,0,0.9907721281051636
128367026,2929,junrao,2017-07-19T21:05:50Z,"islogdirectoryoffline => logdirectoryoffline ? the latter seems more consistent with underreplicated in partition. if we change the name, make sure that we change it consistently in the place where the metric is removed as well.",0,0.9946027398109436
128371038,2929,junrao,2017-07-19T21:22:57Z,should we catch ioexception in fetchoffsetsbytimestamp() in line 1041 too?,0,0.9949167966842651
128376413,2929,junrao,2017-07-19T21:47:24Z,since all accesses to logsegment are through log/logcleaner/logmanager/logcleanermanager. perhaps we can just catch ioexceptions in those places instead of here?,0,0.995149552822113
128390730,2929,junrao,2017-07-19T23:09:30Z,cleanup => clean up,0,0.8963494300842285
128396923,2929,junrao,2017-07-19T23:55:28Z,use exit.halt() to be consistent with what's in replicamanager?,0,0.9937224984169006
128397663,2929,junrao,2017-07-20T00:01:48Z,do we still need to call maybeaddlogfailureevent() on kafkastorageexception?,0,0.9919145107269287
128397699,2929,junrao,2017-07-20T00:02:13Z,do we still need to call maybeaddlogfailureevent() on kafkastorageexception?,0,0.9919145107269287
128399202,2929,junrao,2017-07-20T00:14:21Z,could we add some comment at the beginning of the class on the process of adding a new server side exception going forward?,0,0.9915807843208313
128400026,2929,junrao,2017-07-20T00:21:10Z,ioexception is unused now.,0,0.9747835397720337
128401597,2929,junrao,2017-07-20T00:35:49Z,unused import,0,0.9524969458580017
128404639,2929,junrao,2017-07-20T01:01:30Z,poll(0) => poll(10) to prevent busy loop?,0,0.9827813506126404
128404788,2929,junrao,2017-07-20T01:02:40Z,poll(0) => poll(10) to prevent busy loop?,0,0.9827813506126404
128542365,2929,junrao,2017-07-20T15:06:26Z,the comment seems inaccurate now.,-1,0.8713814616203308
128542947,2929,junrao,2017-07-20T15:08:22Z,could we just set the file to be unreadable and unwritable?,0,0.9925958514213562
128543296,2929,junrao,2017-07-20T15:09:22Z,should we assert the consumer sees at least 2 messages?,0,0.9935164451599121
128544125,2929,junrao,2017-07-20T15:12:14Z,"perhaps it's also useful to assert that logdireventnotificationpath is empty eventually. it may also be useful to verify the replica state for that replica in the controller is in offline state,",0,0.9957120418548584
128548154,2929,junrao,2017-07-20T15:25:34Z,perhaps it's better to use kafkaconfig.logdirsprop,0,0.9944443106651306
128550482,2929,junrao,2017-07-20T15:33:47Z,"to make this more robust, perhaps we need to disable the periodic metadata fresh in the producer?",0,0.9926441311836243
128551469,2929,junrao,2017-07-20T15:37:33Z,is sudo really needed?,0,0.9848923683166504
128552122,2929,junrao,2017-07-20T15:39:46Z,"this is for isr, not leader replica.",0,0.9880130290985107
128552194,2929,junrao,2017-07-20T15:40:00Z,leader => isr,0,0.9028081297874451
128559280,2929,junrao,2017-07-20T16:04:02Z,"""leader node"" doesn't cover the case when broker_type is follower.",0,0.9882057905197144
128559453,2929,junrao,2017-07-20T16:04:45Z,is sudo needed?,0,0.9913955330848694
128560468,2929,junrao,2017-07-20T16:08:41Z,is the test from line 161 to 174 necessary? it doesn't seem to be directly related to offline disks.,0,0.9863536953926086
128560625,2929,junrao,2017-07-20T16:09:19Z,topic2 actually has min.isr of 1.,0,0.9838990569114685
128561993,2929,junrao,2017-07-20T16:14:33Z,why is time-based log rolling needed here?,0,0.9914678335189819
128582900,2929,lindong28,2017-07-20T17:38:37Z,yeah.. i also prefer `logdirectoryoffline`. i changed it to `islogdirectoryoffline` because i didn't have a good reason not to use `islogdirectoryoffline` when asked previously. i have updated the patch to use `logdirectoryoffline`.,0,0.9851387143135071
128583248,2929,lindong28,2017-07-20T17:40:11Z,good catch. it is fixed now.,1,0.9722940325737
128632191,2929,lindong28,2017-07-20T21:12:23Z,"you are right. i missed this.. i should have gone over all methods in log.scala. i just went over all the methods in log.java and made sure the following rule is satisfied for any method in this class: 1) if the method is used during log load phase, which should only happen before the broker registers itself in the zookeeper, this method doesn't have to convert ioexception to kafkastorageexception. 2) otherwise, if the method in incurs i/o operation and may be called by other classes after broker has registered itself (excluding shutdown()), this method should catch ioexception, add it to log dir failure channel, and re-throw kafkastorageexception 3) otherwise, the method either doesn't throw ioexception, or it is only called by internal methods in log that belong to one of the two above categories, we don't need to catch ioexception in this method. i still keep an unnecessary conversion from ioexception to kafkastorageexception in `log.roll()`. it is unnecessary because it is currently only called by methods in log.scala that will catch ioexception. i still keep it there since it is a public method and may be used in the future. it is a bit tedious to go over all method and make sure ioexception is caught `iff` it is needed. so i choose to lean towards over-catch it in log.scala. i can remove it if needed. i also added the comment `we don't convert ioexception to kafkastorageexception in this method because this method may be called before all logs are loaded` to some methods in log.scala so that future develop can be aware of this.",0,0.9051142334938049
128634615,2929,lindong28,2017-07-20T21:24:12Z,good point. i have updated the code to the following with an extra comment. i think we don't have to catch ioexception for logging purpose here because the ioexception should specify the file name and be caught and logged by the caller. [code block],1,0.8128606677055359
128634780,2929,lindong28,2017-07-20T21:25:03Z,thanks for catching this. it is fixed now.,1,0.8696586489677429
128634986,2929,lindong28,2017-07-20T21:26:03Z,clearly i didn't review the patch careful enough.. sorry. it is fixed.,-1,0.9924289584159851
128635061,2929,lindong28,2017-07-20T21:26:24Z,i should have noticed this.. it is fixed now.,0,0.956059455871582
128639223,2929,lindong28,2017-07-20T21:48:19Z,good point. i added the following comment: [code block] i also added the following comment in `kafkastorageexception.java`: [code block],1,0.896758496761322
128639576,2929,lindong28,2017-07-20T21:50:21Z,ah.. i just realized that i can not rely on intellij to show the unused import in gray color. it is fixed now.,0,0.9002075791358948
128639643,2929,lindong28,2017-07-20T21:50:52Z,it is fixed now... i need to be more careful.,0,0.8168732523918152
128640385,2929,lindong28,2017-07-20T21:54:56Z,i missed this. it is fixed now.,0,0.9666808247566223
128644708,2929,lindong28,2017-07-20T22:20:45Z,"i just tested it by setting the file to be unwritable. the testproduceafterlogdirfailure() with pass. however, `kafkaservertestharness.teardown()` will fail with `java.nio.file.accessdeniedexception` because it is not able to delete the log directory. it is possible to swallow the exception so that the test will pass. but that the temporary log directory will not be removed after the test and will accumulate over time on the test server. according to the information provided below, it seems that the log directory can only be removed with sudo access if it is set to be unwritable. thus it seems simpler to just use the current approach by replacing the log directory with a file. [code block]",0,0.9914444088935852
128644975,2929,lindong28,2017-07-20T22:22:24Z,i think it is not necessary to use poll(10). `waituntiltrue()` will sleep for 100 ms before trying to poll() again.,0,0.9832128882408142
128646300,2929,lindong28,2017-07-20T22:31:01Z,"are you suggesting to set `retry.backoff.ms` to long_max when we create the producer? i am not sure we should do that because we need metadata to be refresh after producer sees kafkastorageexceptoin in the produceresponse, so that we can verify that producer can produce message after leadership is moved by controller. actually i intentionally set the `retry.backoff.ms` to 100 ms so that the producer can refresh the metadata almost immediately after it sees kafkastorageexception in the response. `metadata.max.age.ms` is 5 minutes by default which should be longer than the time needed for this test. thus it seems that the test is already robust since producer should not automatically refresh metadata unless it sees exception in the produceresposne. does it sound reasonable?",0,0.989032506942749
128652090,2929,lindong28,2017-07-20T23:11:14Z,i don't think we should.. the first message sent by the first produce has already been consumed by the first call of `poll()`. this is the second call of `poll()` and it is possible to consume only one message.,0,0.9871155023574829
128652222,2929,lindong28,2017-07-20T23:12:32Z,it is probably not necessary because `waituntiltrue()` will sleep for 100 ms before trying to poll() again.,0,0.9873260259628296
128654104,2929,lindong28,2017-07-20T23:26:38Z,good point. i have updated the test to assert both requirements.,1,0.8956895470619202
128654285,2929,lindong28,2017-07-20T23:28:06Z,good point. i have updated the patch to use `kafkaconfig.logdirsprop`.,1,0.8176136612892151
128654830,2929,lindong28,2017-07-20T23:32:08Z,my bad. i have fixed this.,-1,0.9917680025100708
128654940,2929,lindong28,2017-07-20T23:33:03Z,thanks. it is fixed now.,1,0.9445035457611084
128655255,2929,lindong28,2017-07-20T23:36:10Z,"is this because after the broker has opened the file handler for a log segment, it can continue read/write to the log segment even after the log directory is removed or marked as unreadable. i set the log rolling to 3 sec so that the broker will need to create new log segment every 3 seconds. then the server will be able to discover log directory failure when it attempts to create file for a new log segment.",0,0.9867026805877686
128655516,2929,lindong28,2017-07-20T23:38:25Z,"thanks. i added a line that says ""and another topic with partitions=3, replication-factor=3, and min.insync.replicas=1""",1,0.9657089114189148
128655798,2929,lindong28,2017-07-20T23:40:34Z,my bad.. i have updated it to say `broker %d should be in isr set`,-1,0.9904215335845947
128656024,2929,lindong28,2017-07-20T23:42:30Z,i think it may be useful. this is needed to verify that the broker can still server replicas on the good disks even if it has bad disks.,0,0.9141741394996643
128659071,2929,junrao,2017-07-21T00:08:19Z,i was referring to metadata.max.age.ms. we can leave it as it is since metadata.max.age.ms is 5 minutes by default.,0,0.9916852712631226
128659130,2929,junrao,2017-07-21T00:08:49Z,could we add a comment for that?,0,0.9915229082107544
128661501,2929,lindong28,2017-07-21T00:32:22Z,"in particular, i made the following code changes: 1) catch ioexception in log.fetchoffsetsbytimestamp() 2) catch ioexception in log.deletesegments() 3) catch ioexception in log.flush() 4) catch ioexception in log.delete() 5) catch ioexception in log.truncateto() 6) catch ioexception in log.truncatefullyandstartat() 7) catch ioexception in log.asyncdeletesegment() 8) removed ioexception catch code in logmanager.truncateto() 9) removed ioexception catch code in logmanager.truncatefullyandstartat() 10) removed ioexception catch code in logmanager.deletelogs() 11) removed ioexception catch code in logsegment.changefilesuffixes() 12) removed ioexception catch code in logsegment.delete()",0,0.9936186075210571
128676856,2929,lindong28,2017-07-21T03:21:13Z,yes.. i think it is needed. below is the error if this command is executed without sudo. [code block] i also tried to execute the command with and without sudo by logging into the vagrant node. here is what i found: [code block],0,0.9864736795425415
128677507,2929,lindong28,2017-07-21T03:29:19Z,ah... i realized that i can work without `sudo`. the `chmod a-rw /mnt/kafka-data-logs-1/ -r` can actually change the permission of this log directory. but it still returned error probably because this command attempts to read information of this log directory after it takes effect. i am able to avoid sudo by replacing the command with `chmod a-w /mnt/kafka-data-logs-2/ -r`.,0,0.9609431624412537
128678929,2929,lindong28,2017-07-21T03:48:41Z,sure. i added the following comment: [code block],0,0.9874124526977539
128679135,2929,lindong28,2017-07-21T03:51:24Z,yes. the sudo is needed in order to delete an unwritable log directory.,0,0.992659866809845
128679816,2929,lindong28,2017-07-21T04:01:28Z,never mind.. i originally used `offlinelogdirectorycount` instead of the `logdirectoryoffline`. thanks for the suggestion!,1,0.9651033878326416
128680876,2929,lindong28,2017-07-21T04:16:46Z,i updated the code to use `kafkaconfig.logdirsprop` only if the dir count > 1. this is because some tests such as offsetcommittest.scala assumes that there is only one log directory and the will fetch the log directory based on `log.dir`. it seems simpler to keep these tests and only update the `testutils.createbrokerconfig()` to fill in the property based on the directory number. [code block],0,0.9943239688873291
128804228,2929,junrao,2017-07-21T16:26:51Z,"could we just use the existing def replicasinstate(topic: string, state: replicastate)?",0,0.9942483901977539
128805708,2929,junrao,2017-07-21T16:34:35Z,"this method is actually called in places after log loading. but in all other places, ioexceptions are handled by the callers. perhaps we can adjust the comment a bit.",0,0.9923064112663269
128806377,2929,junrao,2017-07-21T16:37:50Z,"ditto as the above since it can be called after loading. also, we should change ?",0,0.9897929430007935
128806610,2929,junrao,2017-07-21T16:39:12Z,ditto as the above since it can be called after loading.,0,0.9894826412200928
128807592,2929,junrao,2017-07-21T16:44:48Z,it seems that logdirfailurechannel can be removed now.,0,0.9928880333900452
128818124,2929,lindong28,2017-07-21T17:36:06Z,i missed this. thanks for catching this. it is fixed now.,1,0.9434438943862915
128818202,2929,lindong28,2017-07-21T17:36:29Z,sure. i have removed this method.,0,0.9878409504890442
128818227,2929,lindong28,2017-07-21T17:36:36Z,it is fixed now.,0,0.9829234480857849
128818243,2929,lindong28,2017-07-21T17:36:41Z,sure. it is fixed now.,0,0.9863779544830322
128818272,2929,lindong28,2017-07-21T17:36:46Z,it is fixed now.,0,0.9829234480857849
128828324,2929,becketqin,2017-07-21T18:19:52Z,we also added producerequest v4.,0,0.992198646068573
128828858,2929,lindong28,2017-07-21T18:22:05Z,remove logdirfailurechannel from cleaner.,0,0.9882735013961792
128833298,2929,becketqin,2017-07-21T18:40:41Z,"not sure if this is in kip-113, but we should probably also consider assigning the partitions based on the actual logdir size instead/in addition to the number of partitions. we can have a follow up patch for this.",0,0.9931331276893616
128850166,2929,becketqin,2017-07-21T20:04:24Z,nit: onreplicabecomeoffline -> onreplicasbecomeoffline,0,0.9839085936546326
128850247,2929,becketqin,2017-07-21T20:04:43Z,effected -> affected,0,0.9878068566322327
128851186,2929,lindong28,2017-07-21T20:10:01Z,i will add code to catch and handle ioexception in `locklogdirs()`,0,0.9930357336997986
128887429,2929,becketqin,2017-07-22T02:49:22Z,there are a lot of similar try/catch logic in this class. maybe we can group them into a lambda like we did for inlock.,0,0.9887517094612122
128889008,2929,becketqin,2017-07-22T04:30:34Z,"in groupcoordinator and txncoordinator, we load the state using filerecords.readinto() and if ioexception occurs, currently we log it and let it go. i am not sure if this has been discussed before, but should we notify controller to reelect leader in this case? it does not have to be in this patch. we can do it separately. let's see what say.",0,0.9873645901679993
128889452,2929,becketqin,2017-07-22T04:50:50Z,can we add a comment explaining the logic here? i was confused first time see this logic.,0,0.9071869254112244
128889819,2929,lindong28,2017-07-22T05:17:13Z,i am not sure whether we should add comment regarding the producerequest. said earlier that we only need to add comments regarding requested used between brokers. i guess we can do this in the other followup patch if needed.,0,0.9782156348228455
128889832,2929,lindong28,2017-07-22T05:18:33Z,yeah i think it is useful. it is probably better to do it in kip-113 so that we can finish this kip sooner :),1,0.9772205948829651
128889837,2929,lindong28,2017-07-22T05:18:53Z,thanks! fixed now.,1,0.9865524172782898
128889858,2929,lindong28,2017-07-22T05:19:33Z,sure. fixed now.,0,0.9868775010108948
128889862,2929,lindong28,2017-07-22T05:19:48Z,good point. it is fixed now.,1,0.9410324692726135
128889977,2929,lindong28,2017-07-22T05:27:59Z,"i think both groupcoordinator and txncoordinator will access log directory via methods in log, e.g. `log.read` in `groupmetadatamanager.loadgroupsandoffsets()`. thus ioexception will be caught and trigger `maybeaddlogfailureevent()`. i think this handling of ioexception is good enough for `groupcoordinator`. if this handling of ioexception is not good enough for `txncoordinator`, it is probably an existing problem and needs feedback from the developers who are more knowledgeable in transaction related logic. yeah let's do it in a followup patch if any fix is need for `txncoordinator`.",0,0.9651551246643066
128889980,2929,lindong28,2017-07-22T05:28:20Z,fixed now.,0,0.9818974137306213
128890112,2929,lindong28,2017-07-22T05:36:58Z,sure. i have updated the comment to clarify this better.,0,0.982914924621582
128903577,2929,becketqin,2017-07-22T19:37:47Z,would it be better to put this method into coreutils?,0,0.9949500560760498
128903738,2929,lindong28,2017-07-22T19:45:05Z,i have thought about this. we can do it if we add another 1-2 parameters to this method. this is because both the object `logdirfailurechannel` and `dir` in the body of `maybehandleioexception` belong to `log`. thus the `maybehandleioexception()` in its current form can not be static. it seems to me that the code is simpler by putting it only in log. we can move it to coreutils with the extra parameter if you think that is better.,0,0.9720141887664795
452397898,9001,kowshik,2020-07-09T18:05:44Z,add doc,0,0.965431272983551
452397966,9001,kowshik,2020-07-09T18:05:50Z,add doc,0,0.965431272983551
452398154,9001,kowshik,2020-07-09T18:06:14Z,add doc,0,0.965431272983551
452398464,9001,kowshik,2020-07-09T18:06:49Z,remove word 'should',0,0.9909312725067139
452399744,9001,kowshik,2020-07-09T18:09:17Z,add doc to entire class,0,0.9859520196914673
452400240,9001,kowshik,2020-07-09T18:10:10Z,add doc to entire class,0,0.9859520196914673
452400376,9001,kowshik,2020-07-09T18:10:27Z,attributes can be final,0,0.9753409624099731
452401987,9001,kowshik,2020-07-09T18:13:20Z,1. add test code in `kafkaadminclienttest` 2. final variable names,0,0.9925139546394348
452402127,9001,kowshik,2020-07-09T18:13:36Z,add test code in `kafkaadminclienttest`,0,0.9913343787193298
452403561,9001,kowshik,2020-07-09T18:16:13Z,1 line gap before `cal`,0,0.9908491373062134
452406393,9001,kowshik,2020-07-09T18:21:18Z,eliminate and use invalid_request,0,0.9865843653678894
452406721,9001,kowshik,2020-07-09T18:21:49Z,eliminate and use invalid_request,0,0.9865843653678894
452407219,9001,kowshik,2020-07-09T18:22:42Z,"space between "","" and ""key""",0,0.991468071937561
452407255,9001,kowshik,2020-07-09T18:22:46Z,final,0,0.9202145934104919
452407329,9001,kowshik,2020-07-09T18:22:56Z,final,0,0.9202145934104919
452408614,9001,kowshik,2020-07-09T18:25:15Z,make variables final throught class add doc,0,0.9896677732467651
452410015,9001,kowshik,2020-07-09T18:27:45Z,fix apikeys,0,0.965294361114502
452410620,9001,kowshik,2020-07-09T18:28:54Z,eliminate timeout?,0,0.9861474633216858
452413347,9001,kowshik,2020-07-09T18:34:02Z,add doc and explain various cases,0,0.9878067374229431
452413777,9001,kowshik,2020-07-09T18:34:54Z,call the variable as `nodecontents` ?,0,0.9929904937744141
452418487,9001,kowshik,2020-07-09T18:44:00Z,perhaps add info about newfeatures and incompatiblebrokers.,0,0.9783381819725037
452418679,9001,kowshik,2020-07-09T18:44:24Z,can improve by splitting into few lines,0,0.9852452874183655
452426595,9001,kowshik,2020-07-09T18:59:05Z,check braces (),0,0.9773245453834534
452428079,9001,kowshik,2020-07-09T19:01:44Z,s/supported/supportedfeatures same for other one,0,0.9888221025466919
452428293,9001,kowshik,2020-07-09T19:02:07Z,"say ""if there are any feature incompatibilities found.""",0,0.9796035885810852
452428858,9001,kowshik,2020-07-09T19:03:22Z,add unit test add doc,0,0.9780594110488892
452432658,9001,kowshik,2020-07-09T19:10:56Z,shouldn't the code be waiting here?,0,0.9870108366012573
452435772,9001,kowshik,2020-07-09T19:16:57Z,add doc,0,0.965431272983551
452435913,9001,kowshik,2020-07-09T19:17:15Z,remove these 2 lines,0,0.9820614457130432
452436233,9001,kowshik,2020-07-09T19:17:41Z,revert the file eventually,0,0.9764708280563354
453842949,9001,abbccdda,2020-07-13T18:21:40Z,nit: get a ` { updatefinalizedfeaturesresult}` as well,0,0.9862298965454102
456123467,9001,abbccdda,2020-07-16T22:57:10Z,s/`as input a set of finalizedfeatureupdate`/`in a set of feature updates`,0,0.9926806092262268
456124708,9001,abbccdda,2020-07-16T23:00:50Z,"for the entire sentence, i assume you want to say something like [code block]",0,0.9782730340957642
456125212,9001,abbccdda,2020-07-16T23:02:31Z,"looking at `updatefinalizedfeaturesresult`, we don't have a per feature based error code returned. if this is the case, how could we know which feature is missing?",0,0.992366373538971
456126450,9001,abbccdda,2020-07-16T23:06:05Z,"we should suggest in what circumstances a user may require sending the request directly to the controller, to me if there is a case where user wants stronger consistency.",0,0.9859345555305481
456150664,9001,abbccdda,2020-07-17T00:25:56Z,we should consider using optional for `finalizedfeaturesepoch` to indicate absence.,0,0.9939741492271423
456151287,9001,abbccdda,2020-07-17T00:27:57Z,"nit: one parameter each line, with the first parameter on the same line as constructor name.",0,0.9906815886497498
456151476,9001,abbccdda,2020-07-17T00:28:41Z,nit: seems not necessary,0,0.5043739080429077
456151635,9001,abbccdda,2020-07-17T00:29:16Z,`false otherwise` doesn't provide too much useful info.,0,0.6683955192565918
456603010,9001,abbccdda,2020-07-17T18:20:41Z,nit: we could just `return new updatefinalizedfeaturesrequestdata().setfinalizedfeatureupdates(items)`,0,0.9950472116470337
456849186,9001,abbccdda,2020-07-19T02:19:21Z,missing header,0,0.9673138856887817
456855815,9001,abbccdda,2020-07-19T04:00:54Z,nit: put first parameter on this line.,0,0.9884248971939087
456855941,9001,abbccdda,2020-07-19T04:02:52Z,"the definition seems not aligned with the kip which states `updatefeatures`, do you think it's necessary to mention `finalized` in all the function signatures?",0,0.9937208890914917
456857080,9001,abbccdda,2020-07-19T04:19:26Z,"it looks weird to complete `callvialeastloadednode` in a controller response handler. i'm inclined to increase a bit on the code duplication, based on `if (options.sendrequesttocontroller())` to have two separate request traces like: [code block] and try to complete the same future.",-1,0.9830530285835266
456857730,9001,abbccdda,2020-07-19T04:29:50Z,"would be good to redundantly copy over the expected error codes from `admin.java` definition, similar to other response class such as `offsetcommitresponse`",0,0.9943851232528687
456858439,9001,abbccdda,2020-07-19T04:39:21Z,seems not necessary to have this helper as it doesn't reduce the code length.,0,0.9425747394561768
456858741,9001,abbccdda,2020-07-19T04:42:42Z,space,0,0.9714933633804321
456859001,9001,abbccdda,2020-07-19T04:45:45Z,"this is a bit unique, since we should commonly rely on the error code to propagate information instead of a message which has unbounded size. could you explain why we couldn't simply re-invent a new error code if existing ones are not sufficient?",0,0.9749441742897034
456859342,9001,abbccdda,2020-07-19T04:50:52Z,"we don't need to include the same error information twice, as the client side will recognize anyway.",0,0.9772927761077881
456859761,9001,abbccdda,2020-07-19T04:56:54Z,access should be private,0,0.9865559339523315
456859864,9001,abbccdda,2020-07-19T04:58:05Z,nit: the comment seems unnecessary on l3011,0,0.937905490398407
456859960,9001,abbccdda,2020-07-19T04:58:51Z,"commonly in scala we try to avoid using return, consider using `if-else` instead.",0,0.9924017190933228
456860187,9001,abbccdda,2020-07-19T05:01:31Z,`setting the allowdowngrade flag to true in the request`,0,0.9933459758758545
456862645,9001,abbccdda,2020-07-19T05:31:43Z,`apikeys.update_finalized_features api`,0,0.9908624887466431
456862745,9001,abbccdda,2020-07-19T05:33:11Z,we only need to mark testing only comment on the functions,0,0.9773585796356201
456863153,9001,abbccdda,2020-07-19T05:38:15Z,nit: mark the parameter as `logincompatibilities = true)`,0,0.9872226715087891
456863287,9001,abbccdda,2020-07-19T05:39:58Z,redundant {},0,0.6971908211708069
456863554,9001,abbccdda,2020-07-19T05:42:50Z,redundant {},0,0.6971908211708069
456863914,9001,abbccdda,2020-07-19T05:48:12Z,do we need this precision of exact wait time? could we just track the function start time and compare with current system time for expiration?,0,0.9903305768966675
456931477,9001,abbccdda,2020-07-19T17:03:30Z,"`for a new kafka cluster (i.e. it is deployed first time), we would like to start the cluster with all the possible supported features finalized immediately.` i think this comment is hard to understand if reader has zero context on the feature versioning. it would be good to include a short explanation on what does a `supported feature` mean, and what it means to be `finalized`. `the new cluster will almost never be started with an old ibp config thats less than kafka_2_7_iv0.` this sentence is positioned awkwardly. i would suggest we just propose `as a new cluster starting with ibp setting equal to or greater than kafka_2_7_iv0`",0,0.9756101369857788
456931559,9001,abbccdda,2020-07-19T17:04:23Z,"`then here is how we it` could be removed: `assuming this is the case, then the controller...`",0,0.9922943115234375
456932817,9001,abbccdda,2020-07-19T17:17:40Z,"maybe a newbie question here: since the `supportedfeatures` could be mutated, why couldn't we just assume its min level marks the `defaultfeatureminversionlevels`? trying to understand the necessity for secondary bookkeeping. might be good to also put reasonings in the meta comment as well to clear confusion.",0,0.9912147521972656
456934831,9001,abbccdda,2020-07-19T17:38:27Z,"if this is broker required feature set, i feel we could name it something like `brokerrequiredversionrange`. `updated` sounds a bit blur for reader, as it couldn't infer the subject.",0,0.975961446762085
456935073,9001,abbccdda,2020-07-19T17:40:37Z,what about the case where `existingversionrange.min() > updatedversionrange.max()` is true? for example: [code block] are we enabling version 3 as well?,0,0.9945012331008911
457072387,9001,abbccdda,2020-07-20T05:46:02Z,"is it ok for us to always do `updatefeatureznode`, since this call is idempotent?",0,0.9943550825119019
457075484,9001,abbccdda,2020-07-20T05:52:11Z,could the receiving broker analyze the request and decide to shut down itself? what's the gain we have by avoiding sending update metadata to incompatible brokers?,0,0.9834557175636292
457076040,9001,abbccdda,2020-07-20T05:53:19Z,replace with `nonempty`,0,0.9919513463973999
457076787,9001,abbccdda,2020-07-20T05:54:49Z,"could we avoid blocking controller processing here, by putting the callback into a delayed queue or sth?",0,0.9914715886116028
457077246,9001,abbccdda,2020-07-20T05:55:46Z,`incompatiblefeatures`?,0,0.9864039421081543
457077954,9001,abbccdda,2020-07-20T05:57:18Z,"nit: i have seen that we use both `map{` and `map {`, could we try using only one format consistently within the current file?",0,0.9926321506500244
457802220,9001,kowshik,2020-07-21T02:40:49Z,done. updated the doc now.,0,0.9605454802513123
457806176,9001,kowshik,2020-07-21T02:56:06Z,done.,0,0.9640594124794006
457806399,9001,kowshik,2020-07-21T02:57:00Z,done.,0,0.9640594124794006
457806541,9001,kowshik,2020-07-21T02:57:43Z,"to your point, this information is available in the error message returned in the response. the feature updates are atomically applied to zk by the controller i.e it is all or none. we don't have a use case (yet) where we have to programmatically learn which feature updates are incorrect. instead an error message with details seems sufficient to us. please let me know how you feel about it, and if you feel that we are better off in returning per-feature-update error code. this was discussed in the [a link], search for the word ""transaction"".",0,0.9514699578285217
457808548,9001,kowshik,2020-07-21T03:06:14Z,done.,0,0.9640594124794006
457809543,9001,kowshik,2020-07-21T03:10:05Z,done.,0,0.9640594124794006
457812340,9001,kowshik,2020-07-21T03:19:53Z,done. good point.,1,0.9524728059768677
457812690,9001,kowshik,2020-07-21T03:21:00Z,done.,0,0.9640594124794006
457812867,9001,kowshik,2020-07-21T03:21:44Z,done. removed.,0,0.9667683243751526
457813021,9001,kowshik,2020-07-21T03:22:17Z,done. removed.,0,0.9667683243751526
457813152,9001,kowshik,2020-07-21T03:22:53Z,done. good point.,1,0.9524728059768677
457815251,9001,kowshik,2020-07-21T03:32:07Z,done. good point.,1,0.9524728059768677
457821195,9001,kowshik,2020-07-21T03:56:30Z,it calls into couple other helper functions. let us keep it.,0,0.95803302526474
457821791,9001,kowshik,2020-07-21T03:58:56Z,done.,0,0.9640594124794006
457821925,9001,kowshik,2020-07-21T03:59:25Z,done.,0,0.9640594124794006
457823139,9001,kowshik,2020-07-21T04:04:34Z,"the purpose of the error message is to sometimes describe with finer details on what is the error (such as which feature update is incorrect). to your point, it seems there are existing response types that do allow for an error message, examples are: `createtopicsresponse`, `createpartitionsresponse`, `deleteaclsresponse` etc. there is ongoing related discussion under another pr review comment and we can continue the discussion there: [a link] .",0,0.9914594888687134
457872699,9001,kowshik,2020-07-21T06:46:14Z,done. updated the doc.,0,0.9706774353981018
457873376,9001,kowshik,2020-07-21T06:47:55Z,done.,0,0.9640594124794006
457876122,9001,kowshik,2020-07-21T06:54:17Z,"done. this case is also handled now. to your point, the case where `updated.max < existing.min` can never happen unless brokers get downgraded (after finalizing features at higher levels), and especially if the downgrade was done improperly (without applying feature tooling commands). it's a rare case. but even in that case, the broker will start crashing because of incompatibility in supported feature version max level, so the problem is found before it reaches this point.",0,0.9896960258483887
457879567,9001,kowshik,2020-07-21T07:02:03Z,not sure i understood. we will only update the `featureznode` if the status is not disabled currently (see the implementation below). what am i missing?,0,0.9379395842552185
457880383,9001,kowshik,2020-07-21T07:03:54Z,this handles the race condition described in the kip-584 [a link]. please refer to the kip for details. i have also added doc to this method.,0,0.9817264676094055
457883779,9001,kowshik,2020-07-21T07:11:03Z,done.,0,0.9640594124794006
457884903,9001,kowshik,2020-07-21T07:13:24Z,"i feel that there isn't a pressing reason to optimize this api path currently, and make it async. the api is not going to be frequently used, and an infrequent write to a zk node with low write contention feels like a relatively inexpensive case that we could block the controller on. please let me know how you feel.",0,0.6596901416778564
457885415,9001,kowshik,2020-07-21T07:14:28Z,done.,0,0.9640594124794006
457885467,9001,kowshik,2020-07-21T07:14:38Z,done. made the comment better. pls take a look.,0,0.7841711640357971
457890046,9001,kowshik,2020-07-21T07:23:55Z,"it is already explained in the class level doc. this is also explained in the kip-584 [a link]. this is needed because `defaultfeatureminversionlevels` is mainly for feature version deprecation. when we deprecate feature version levels, we first bump the `defaultfeatureminversionlevels` in a broker release (after making an announcement to community). this will automatically mean clients have to stop using the finalized min version levels that have been deprecated (because upon startup the controller will write the `defaultfeatureminversionlevels` to zk from within `kafkacontroller#setupfeatureversioning` method). once the write to zk happens, clients that are using the finalized features are forced to stop using the deprecated version levels. then, finally in the future when we remove the code for the deprecated version levels, that is when we will bump the min version for the supported feature in the broker. thereby we will completely drop support for a feature version altogether.",0,0.99558025598526
457891034,9001,kowshik,2020-07-21T07:25:44Z,done.,0,0.9640594124794006
457892024,9001,kowshik,2020-07-21T07:27:45Z,done. calling it `incompatiblefeaturesinfo` now.,0,0.9908444285392761
457892374,9001,kowshik,2020-07-21T07:28:29Z,done.,0,0.9640594124794006
457892622,9001,kowshik,2020-07-21T07:28:55Z,done.,0,0.9640594124794006
457892858,9001,kowshik,2020-07-21T07:29:25Z,done.,0,0.9640594124794006
457897331,9001,kowshik,2020-07-21T07:37:49Z,"done. made it the way you suggested, pls take a look. overall either way looked fine to me but the one you suggested is a bit simpler.",0,0.6614944338798523
457903477,9001,kowshik,2020-07-21T07:48:51Z,done.,0,0.9640594124794006
457903582,9001,kowshik,2020-07-21T07:49:04Z,done.,0,0.9640594124794006
457904782,9001,kowshik,2020-07-21T07:51:11Z,done. removed.,0,0.9667683243751526
457905010,9001,kowshik,2020-07-21T07:51:34Z,done.,0,0.9640594124794006
457939241,9001,kowshik,2020-07-21T08:50:07Z,done.,0,0.9640594124794006
457981705,9001,kowshik,2020-07-21T10:01:43Z,done. i'm calling it `brokerdefaultversionrange` now.,0,0.9830196499824524
457985348,9001,kowshik,2020-07-21T10:08:39Z,"done. removed the word ""finalized""in the context of this api.",0,0.98897385597229
457986837,9001,kowshik,2020-07-21T10:11:25Z,done.,0,0.9640594124794006
458503099,9001,abbccdda,2020-07-22T02:52:48Z,nit: do `{ describefeaturesresult}`,0,0.9921923279762268
458985306,9001,abbccdda,2020-07-22T18:06:59Z,nit: new line,0,0.930640459060669
458985676,9001,abbccdda,2020-07-22T18:07:40Z,could be simplified as `sendtocontroller`,0,0.9940468072891235
458986288,9001,abbccdda,2020-07-22T18:08:46Z,"why do we need this override, which seems to be exactly the same with super class?",0,0.9810503125190735
458987227,9001,abbccdda,2020-07-22T18:10:24Z,s/featurename/feature,0,0.955565333366394
459002813,9001,abbccdda,2020-07-22T18:37:41Z,"the two `call` structs only have two differences: 1. used different node provider 2. one would handle not controller, one not so i would suggest a bit refactoring to reduce the code redundancy, by providing a helper as: [code block]",0,0.992305338382721
459003818,9001,abbccdda,2020-07-22T18:39:25Z,"same here, why do we need this extension?",0,0.98826003074646
459004097,9001,abbccdda,2020-07-22T18:39:54Z,"as discussed offline, we need to extend the result as per feature.",0,0.991243839263916
459004701,9001,abbccdda,2020-07-22T18:40:56Z,couldn't we just use `isincompatiblewith`?,0,0.9942376613616943
459005027,9001,abbccdda,2020-07-22T18:41:29Z,why do we jump from code 88 to 91?,0,0.9759145379066467
459006265,9001,abbccdda,2020-07-22T18:43:34Z,"make sense, after looking further i realized that we also did some data format conversion.",0,0.9666406512260437
459008772,9001,abbccdda,2020-07-22T18:47:48Z,do we also need to check `allowautodowngrade` here?,0,0.9942229390144348
459009582,9001,abbccdda,2020-07-22T18:49:09Z,we could consider either making `data` to be private or remove this unnecessary accessor. i would prefer making it private.,0,0.99076908826828
459009753,9001,abbccdda,2020-07-22T18:49:24Z,same here for consistency.,0,0.9867039918899536
459010149,9001,abbccdda,2020-07-22T18:50:03Z,"spaces look weird, let's try to remove all `two space` cases in this file.",-1,0.9538419842720032
459014883,9001,abbccdda,2020-07-22T18:58:04Z,"my pt is that since we know the outcome (feature versioning will be disabled), we don't need to do one more lookup but just try to push the update. anyway, i think this is a nit.",0,0.9506456851959229
459183702,9001,abbccdda,2020-07-23T02:26:11Z,parameters could be on the same line to be consistent with l80,0,0.9941443800926208
459185058,9001,abbccdda,2020-07-23T02:32:59Z,"`testupdatefeatures` should be suffice, as we sometimes are not passing in a real error.",0,0.9908559322357178
459185171,9001,abbccdda,2020-07-23T02:33:32Z,nit: prefer using `error == errors.none`,0,0.9923120141029358
459186000,9001,abbccdda,2020-07-23T02:37:26Z,`collections.emptylist()` should be suffice.,0,0.9925916194915771
459186249,9001,abbccdda,2020-07-23T02:38:39Z,we should have a matcher checking whether the sent request is pointing at the correct controller id.,0,0.9928433299064636
459186371,9001,abbccdda,2020-07-23T02:39:08Z,"make it a variable, as `int controllerid = 1`",0,0.9940237402915955
459186681,9001,abbccdda,2020-07-23T02:40:44Z,`defaultfeaturemetadata` should be suffice. ak repo normally tries to avoid using `get` as func prefix.,0,0.994750440120697
459186760,9001,abbccdda,2020-07-23T02:41:09Z,nit: could use `utils.mkmap` to simplify here.,0,0.9929115176200867
459188638,9001,abbccdda,2020-07-23T02:50:16Z,nit: `zkclient.getdataandversion(featureznode.path)._2` should be suffice,0,0.9945981502532959
459188844,9001,abbccdda,2020-07-23T02:51:18Z,s/znode/znode,0,0.9829795360565186
459188931,9001,abbccdda,2020-07-23T02:51:41Z,s/ is is / is,0,0.934136688709259
459189057,9001,abbccdda,2020-07-23T02:52:09Z,remove `in zk`,0,0.9936332702636719
459189198,9001,abbccdda,2020-07-23T02:52:55Z,nit: s/it's/its,0,0.8563055396080017
459189220,9001,abbccdda,2020-07-23T02:53:03Z,nit: s/it's/its,0,0.8563055396080017
459189352,9001,abbccdda,2020-07-23T02:53:49Z,remove `one and`,0,0.9920868277549744
459189517,9001,abbccdda,2020-07-23T02:54:36Z,remove `and their version levels` or restructure as `the information about finalized features' version levels`,0,0.9939231276512146
459189854,9001,abbccdda,2020-07-23T02:55:55Z,"could we just remove ` the feature versioning system (kip-584) is enabled, and`? it does not provide any useful information.",0,0.9928956627845764
459189970,9001,abbccdda,2020-07-23T02:56:23Z,s/this status/the enabled status,0,0.9832878708839417
459190247,9001,abbccdda,2020-07-23T02:57:49Z,we don't need to capitalize `broker` here,0,0.9876680970191956
459190329,9001,abbccdda,2020-07-23T02:58:15Z,same here,0,0.9628711938858032
459190412,9001,abbccdda,2020-07-23T02:58:44Z,"s/`the reason to do this is that...`/`this process ensures we do not enable all the possible features immediately after an upgrade, which could be harmful to the application.`",0,0.9931308627128601
459190870,9001,abbccdda,2020-07-23T03:01:03Z,remove `then`,0,0.9921941757202148
459191665,9001,abbccdda,2020-07-23T03:05:05Z,{} could be removed.,0,0.9906823635101318
459192115,9001,abbccdda,2020-07-23T03:07:16Z,nit: would be easier to read if we always compare `existingversionrange` towards `brokerdefaultversionrange` instead of flipping in this statement.,0,0.9930579662322998
459192901,9001,abbccdda,2020-07-23T03:11:05Z,i think we need to override `equals` here.,0,0.9771832227706909
459192976,9001,abbccdda,2020-07-23T03:11:26Z,cache,0,0.9025143384933472
459193453,9001,abbccdda,2020-07-23T03:13:22Z,`no updatemetadatarequest will be sent to broker...`,0,0.9905990958213806
459193711,9001,abbccdda,2020-07-23T03:14:45Z,does `features` guarantee to be non-null?,0,0.992849588394165
459193767,9001,abbccdda,2020-07-23T03:15:02Z,format,0,0.9515261650085449
459194593,9001,abbccdda,2020-07-23T03:19:03Z,"yea, i'm a bit worried about such a blocking call here as we don't have a precedence for relying on zk connect timeout (18 seconds), besides the result doesn't matter to the controller (since client will do the retry). cc to see if they have a different opinion on this.",-1,0.9082847237586975
459195272,9001,abbccdda,2020-07-23T03:22:08Z,what `clients` are we referring to here?,0,0.9928333759307861
459195338,9001,abbccdda,2020-07-23T03:22:35Z,`the class is immutable in production`,0,0.9865967631340027
459528132,9001,abbccdda,2020-07-23T15:16:34Z,is it necessary to quote `incompatible`?,0,0.9894220232963562
459538486,9001,abbccdda,2020-07-23T15:30:57Z,could you explain a bit why we no longer use singletons for feature cache?,0,0.9903169870376587
459554866,9001,abbccdda,2020-07-23T15:54:51Z,we could explicitly mention this is `either or` result.,0,0.991134524345398
459556307,9001,abbccdda,2020-07-23T15:56:45Z,could be initialized closer to l3005,0,0.994642972946167
459562747,9001,abbccdda,2020-07-23T16:06:37Z,could we assert the expected version here?,0,0.9937119483947754
459563255,9001,abbccdda,2020-07-23T16:07:24Z,nit: new line,0,0.930640459060669
459564526,9001,abbccdda,2020-07-23T16:09:36Z,...`withinvalidsmallvalue`,0,0.990172266960144
459564664,9001,abbccdda,2020-07-23T16:09:48Z,...`withinvalidlargevalue`,0,0.9902021884918213
459565850,9001,abbccdda,2020-07-23T16:11:41Z,what's the purpose of this second test?,0,0.9876898527145386
459566826,9001,abbccdda,2020-07-23T16:13:14Z,nit: replace with `noncontrollerservers.head`,0,0.9929254055023193
459569818,9001,abbccdda,2020-07-23T16:17:56Z,this case seems not to be tested yet.,0,0.9629641771316528
459570396,9001,abbccdda,2020-07-23T16:18:54Z,format,0,0.9515261650085449
459653525,9001,abbccdda,2020-07-23T18:41:59Z,format,0,0.9515261650085449
459655758,9001,abbccdda,2020-07-23T18:45:44Z,we could refactor out a helper in `updatefeaturesrequest` to create `featureupdatekey`,0,0.9950265288352966
459658554,9001,abbccdda,2020-07-23T18:50:45Z,"could we add some unit tests in `kafkaapistest.scala`, once the refactoring is finished?",0,0.9955158829689026
460365110,9001,kowshik,2020-07-25T04:51:52Z,done.,0,0.9640594124794006
460365185,9001,kowshik,2020-07-25T04:52:57Z,done.,0,0.9640594124794006
460365229,9001,kowshik,2020-07-25T04:53:47Z,done.,0,0.9640594124794006
460365305,9001,kowshik,2020-07-25T04:54:32Z,done. removed now. didn't realize it was present in super class too.,0,0.9517275094985962
460365462,9001,kowshik,2020-07-25T04:56:23Z,done. actually `feature` is removed from this class now.,0,0.9867448210716248
460369033,9001,kowshik,2020-07-25T05:44:35Z,done. good point.,1,0.9524728059768677
460369103,9001,kowshik,2020-07-25T05:45:25Z,done. removed now.,0,0.9787948727607727
460369423,9001,kowshik,2020-07-25T05:49:31Z,done. removed this method now.,0,0.9824236631393433
460369509,9001,kowshik,2020-07-25T05:50:19Z,done. not intentional. changed to 89 now.,0,0.7450908422470093
460369545,9001,kowshik,2020-07-25T05:50:51Z,done.,0,0.9640594124794006
460370082,9001,kowshik,2020-07-25T05:57:51Z,done. made the attribute private.,0,0.9656450748443604
460370089,9001,kowshik,2020-07-25T05:58:03Z,done. made the attribute private.,0,0.9656450748443604
460370162,9001,kowshik,2020-07-25T05:59:09Z,done.,0,0.9640594124794006
460371001,9001,kowshik,2020-07-25T06:10:14Z,done.,0,0.9640594124794006
460371104,9001,kowshik,2020-07-25T06:11:43Z,done.,0,0.9640594124794006
460371146,9001,kowshik,2020-07-25T06:12:24Z,done.,0,0.9640594124794006
460371283,9001,kowshik,2020-07-25T06:14:31Z,done.,0,0.9640594124794006
460371443,9001,kowshik,2020-07-25T06:16:22Z,done.,0,0.9640594124794006
460371572,9001,kowshik,2020-07-25T06:18:05Z,done.,0,0.9640594124794006
460373122,9001,kowshik,2020-07-25T06:38:13Z,"i have improved the matcher now, but how do i check the correct controller id?",0,0.986554741859436
460373211,9001,kowshik,2020-07-25T06:39:17Z,`newversion` is more readable than `_2`.,0,0.9909182786941528
460373254,9001,kowshik,2020-07-25T06:39:52Z,done.,0,0.9640594124794006
460373296,9001,kowshik,2020-07-25T06:40:15Z,done.,0,0.9640594124794006
460373384,9001,kowshik,2020-07-25T06:41:31Z,done.,0,0.9640594124794006
460373389,9001,kowshik,2020-07-25T06:41:37Z,done.,0,0.9640594124794006
460373454,9001,kowshik,2020-07-25T06:42:14Z,done.,0,0.9640594124794006
460373463,9001,kowshik,2020-07-25T06:42:21Z,done.,0,0.9640594124794006
460373549,9001,kowshik,2020-07-25T06:43:36Z,done.,0,0.9640594124794006
460373561,9001,kowshik,2020-07-25T06:43:52Z,done.,0,0.9640594124794006
460373590,9001,kowshik,2020-07-25T06:44:08Z,done.,0,0.9640594124794006
460373616,9001,kowshik,2020-07-25T06:44:20Z,done.,0,0.9640594124794006
460373708,9001,kowshik,2020-07-25T06:45:15Z,done.,0,0.9640594124794006
460373729,9001,kowshik,2020-07-25T06:45:37Z,done.,0,0.9640594124794006
460373746,9001,kowshik,2020-07-25T06:45:51Z,done.,0,0.9640594124794006
460373809,9001,kowshik,2020-07-25T06:46:45Z,done.,0,0.9640594124794006
460374117,9001,kowshik,2020-07-25T06:50:59Z,"`featureznode` is a `case class`, and therefore the `equals` method is auto generated. let me know if i'm missing something. here is the doc: [a link]",0,0.9886360168457031
460374136,9001,kowshik,2020-07-25T06:51:22Z,done.,0,0.9640594124794006
460374558,9001,kowshik,2020-07-25T06:57:15Z,"we can not just push the update, because, we have to decide if the node needs to be created or existing node should be updated. that is why we read the node first to understand if it exists or not, then we update the existing node only if the status does not match (this avoids a zk write in the most common cases).",0,0.9930984377861023
460374653,9001,kowshik,2020-07-25T06:58:43Z,done.,0,0.9640594124794006
460375004,9001,kowshik,2020-07-25T07:03:27Z,"yes, `broker.features` is just empty when there are no features set or none decoded from the `brokeridznode`.",0,0.9928873181343079
460375038,9001,kowshik,2020-07-25T07:04:01Z,done.,0,0.9640594124794006
460375251,9001,kowshik,2020-07-25T07:06:15Z,done. i was referring to external clients of kafka. have updated the doc now.,0,0.9488328099250793
460375270,9001,kowshik,2020-07-25T07:06:32Z,done.,0,0.9640594124794006
460375378,9001,kowshik,2020-07-25T07:08:11Z,done. removed quotes.,0,0.9836748838424683
460375750,9001,kowshik,2020-07-25T07:13:11Z,"it became painful to write tests using singletons. particularly in `kafka.server.updatefeaturestest` we would like to simulate presence of multiple brokers and a controller within the same test process. then we would like to set incompatible features for some brokers, and compatible features for some others. using a singleton for feature cache made it impossible to set up such an environment for testing. that is why we no longer use a singleton, instead we instantiate the class once in `kafkaserver` and we use the object wherever needed.",-1,0.6870927214622498
460375901,9001,kowshik,2020-07-25T07:15:07Z,done.,0,0.9640594124794006
460375935,9001,kowshik,2020-07-25T07:15:25Z,done.,0,0.9640594124794006
460376009,9001,kowshik,2020-07-25T07:16:37Z,done.,0,0.9640594124794006
460376035,9001,kowshik,2020-07-25T07:16:42Z,done.,0,0.9640594124794006
460376322,9001,kowshik,2020-07-25T07:20:35Z,"it is explained in the test doc above, and, i have also added comments now. the purpose is to check that the zk watch on the featureznode was re-established by the broker, after the first update triggers a zk notification that populates the cache. the best way to check it is to update the node again and see if the notification is received by the broker again.",0,0.9910343289375305
460376477,9001,kowshik,2020-07-25T07:22:27Z,done.,0,0.9640594124794006
460376521,9001,kowshik,2020-07-25T07:22:56Z,done.,0,0.9640594124794006
460376578,9001,kowshik,2020-07-25T07:23:54Z,done.,0,0.9640594124794006
461412713,9001,kowshik,2020-07-28T08:35:14Z,done.,0,0.9640594124794006
461413382,9001,kowshik,2020-07-28T08:36:21Z,done.,0,0.9640594124794006
461413992,9001,kowshik,2020-07-28T08:37:29Z,done.,0,0.9640594124794006
461416641,9001,kowshik,2020-07-28T08:42:00Z,done.,0,0.9640594124794006
461417458,9001,kowshik,2020-07-28T08:43:22Z,"sure, we can hear what others say.",0,0.9704498052597046
461418384,9001,kowshik,2020-07-28T08:44:51Z,will take a look.,0,0.9468214511871338
461418530,9001,kowshik,2020-07-28T08:45:03Z,this method has changed greatly and it has been moved to `kafkacontroller.scala`.,0,0.9927482008934021
461418681,9001,kowshik,2020-07-28T08:45:17Z,this method has changed greatly and it has been moved to `kafkacontroller.scala`.,0,0.9927482008934021
461421563,9001,kowshik,2020-07-28T08:49:51Z,"hmm, there seem to be very few call sites and therefore seems ok to inline it. let me know!",1,0.9436720013618469
461424717,9001,kowshik,2020-07-28T08:54:59Z,added a test now in `updatefeaturestest.scala`. look for `testsuccessfulfeatureupgradeandwithnoexistingfinalizedfeatures`.,0,0.9932335019111633
461771992,9001,abbccdda,2020-07-28T18:03:35Z,nit: s/name/names,0,0.9477100372314453
462453975,9001,abbccdda,2020-07-29T17:08:15Z,"note in the post-kip-500 world, this feature could still work, but the request must be redirected to the controller inherently on the broker side, instead of sending it directly. so in the comment, we may try to phrase it to convey the principal is that `the request must be handled by the controller` instead of `the admin client must send this request to the controller`.",0,0.9943905472755432
462456942,9001,abbccdda,2020-07-29T17:13:03Z,should this a per feature error or a top level error?,0,0.9917474985122681
462458761,9001,abbccdda,2020-07-29T17:15:56Z,"for top level exception such as cluster authorization exception, we could just define a top level error code instead of check-marking every feature with the redundant error code. i know we have been a bit inconsistent in such a case, but personally feel having layered error codes could make the response handling clear of whether it is per feature issue, or a high level issue.",0,0.89527428150177
462458948,9001,abbccdda,2020-07-29T17:16:15Z,space,0,0.9714933633804321
462459015,9001,abbccdda,2020-07-29T17:16:21Z,same here,0,0.9628711938858032
462459152,9001,abbccdda,2020-07-29T17:16:34Z,same here,0,0.9628711938858032
462462109,9001,abbccdda,2020-07-29T17:21:30Z,`can be issued only to the controller.`/ `must be processed by the controller`,0,0.9935792684555054
462462268,9001,abbccdda,2020-07-29T17:21:47Z,`could be processed by any random broker`,0,0.993829071521759
462462801,9001,abbccdda,2020-07-29T17:22:41Z,same here,0,0.9628711938858032
462463977,9001,abbccdda,2020-07-29T17:24:33Z,"try to put first parameter on the same line as the constructor, and align the rest parameters.",0,0.9923054575920105
462465188,9001,abbccdda,2020-07-29T17:26:28Z,"this won't work well with string format, consider doing `orelse`",0,0.982344388961792
462465387,9001,abbccdda,2020-07-29T17:26:50Z,new line,0,0.911078155040741
462471038,9001,abbccdda,2020-07-29T17:36:28Z,"i suggest we build a static method in the `updatefeaturesrequest` class to avoid exposing the sub modules of feature data, such like: [code block]",0,0.9952564835548401
462472940,9001,abbccdda,2020-07-29T17:39:43Z,does this overlap with `completeunrealizedfutures` check? we could just keep one to reduce the checking complexity.,0,0.9914685487747192
462475689,9001,abbccdda,2020-07-29T17:44:02Z,"you are right, it seems not necessary.",0,0.9627776145935059
462477303,9001,abbccdda,2020-07-29T17:46:32Z,"do we need to make this a public error? it seems only be used internally, so could be made private if we don't have intention to let user catch.",0,0.9722064137458801
462480826,9001,abbccdda,2020-07-29T17:52:16Z,comment here since no better place: createapiversionsresponse on l198 could be made private,0,0.9931725859642029
462483315,9001,abbccdda,2020-07-29T17:56:31Z,nit: could be replaced with lambda,0,0.9896084666252136
462485886,9001,abbccdda,2020-07-29T18:00:41Z,should we also mention that this flag would fail the request when we are not actually doing a downgrade?,0,0.9882434010505676
462488078,9001,abbccdda,2020-07-29T18:04:41Z,"i'm actually wondering whether this is too strict in the perspective of a user. if they accidentally set a feature version larger than the cache, what they only care about is to be able to change the version to it. so it's a matter of whether we think this is a user error, or this could happen when user gets stale feature information from a broker while the downgrade already succeed eventually. if we want to keep this check, it makes sense to update the meta comments around `allowdowngrade` to inform user that the request could fail when the target version is actually higher than the current finalized feature.",0,0.9413053393363953
462489375,9001,abbccdda,2020-07-29T18:07:00Z,could be moved to the `updatefeaturesresponse`,0,0.9935041069984436
462492285,9001,abbccdda,2020-07-29T18:11:58Z,could we make `updates` as a pass-in parameter to avoid calling `maketestfeatureupdates` twice?,0,0.9954753518104553
462492825,9001,abbccdda,2020-07-29T18:12:58Z,nit: could use lambda,0,0.9836459159851074
462496091,9001,abbccdda,2020-07-29T18:18:17Z,"do we need to call `featurecache.waituntilepochorthrow(newnode, config.zkconnectiontimeoutms)` here to ensure the update is successful?",0,0.994949460029602
462498961,9001,abbccdda,2020-07-29T18:23:15Z,"i see, still wondering if we could just check whether `newfeatures` is equal to `existingfeatureznode.features`",0,0.9898837804794312
462500314,9001,abbccdda,2020-07-29T18:25:31Z,"are we good to proceed in this case? when there is no overlapping between broker default features and remote finalized features, is the current controller still eligible?",0,0.9868714809417725
462501301,9001,abbccdda,2020-07-29T18:27:19Z,"i see, what would happen to a currently live broker if it couldn't get any metadata update for a while, will it shut down itself?",0,0.9615879654884338
462502780,9001,abbccdda,2020-07-29T18:29:57Z,"i see, still i'm a bit worried future changes could break this assumption. not a bad idea to check `features != null`?",-1,0.9258412718772888
462504467,9001,abbccdda,2020-07-29T18:32:45Z,state the error explicitly here.,0,0.988771378993988
462627189,9001,abbccdda,2020-07-29T22:30:26Z,"yea, i mean you could use `val newversion = zkclient.getdataandversion(featureznode.path)._2`, but it's up to you.",0,0.9933422207832336
462649895,9001,abbccdda,2020-07-29T23:38:21Z,is this case covered by the case on l1931? could we merge both?,0,0.9953357577323914
462650343,9001,abbccdda,2020-07-29T23:39:44Z,we should be consistent and remove `()` from `maxversionlevel`,0,0.9941828846931458
462651241,9001,abbccdda,2020-07-29T23:42:50Z,nit: new line,0,0.930640459060669
462658154,9001,abbccdda,2020-07-30T00:05:36Z,"could you clarify the reasoning here? if structs are not the same, are we going to do a partial update?",0,0.9915363788604736
462714278,9001,abbccdda,2020-07-30T03:34:34Z,could we get a static method instead of initiating a new `finalizedversionrange` for a comparison every time?,0,0.9941195249557495
462715368,9001,abbccdda,2020-07-30T03:39:07Z,why don't we just use `system.currenttimemillis()` to avoid conversion between nano time?,0,0.987697184085846
462715603,9001,abbccdda,2020-07-30T03:39:57Z,seems not covered yet,0,0.9616350531578064
462716040,9001,abbccdda,2020-07-30T03:41:34Z,could be moved to `updatefeaturesresponse` as a utility.,0,0.9941921830177307
462716875,9001,abbccdda,2020-07-30T03:44:56Z,"some methods in the `brokerfeatures` are not covered by this suite, such as `defaultminversionlevel`, `getdefaultfinalizedfeatures` and `hasincompatiblefeatures`, you could use code coverage tool to figure out any missing part.",0,0.9943690896034241
462717083,9001,abbccdda,2020-07-30T03:45:45Z,indentation is not right.,0,0.5148141980171204
462718258,9001,abbccdda,2020-07-30T03:50:44Z,the meta comment for `finalizedfeaturecache` should be updated as it is now being accessed for both read and write,0,0.9950240254402161
462719027,9001,abbccdda,2020-07-30T03:54:08Z,nit: this could be extracted as a common struct.,0,0.9912276864051819
462719977,9001,abbccdda,2020-07-30T03:57:50Z,"could we only pass in `featurecache` to reduce the class coupling here? as we already have `brokerfeatures` as a private parameter, it shouldn't be too hard to set a helper to get supported features.",0,0.992557168006897
463880076,9001,kowshik,2020-07-31T23:01:47Z,"sorry, i do not understand why should describefeatures (in post kip-500) be handled only by controller?",-1,0.9845501780509949
463912157,9001,kowshik,2020-08-01T02:54:07Z,it does not overlap. this checks for unexpected responses for features that we never intended to update. `completeunrealizedfutures` is for futures that we never got a response for from the server -- we need to complete such futures exceptionally.,0,0.978931188583374
463912498,9001,kowshik,2020-08-01T02:57:46Z,this exception corresponds to `errors.feature_update_failed`. the caller of `adminclient#updatefeatures` can receive this exception whenever a feature update can not be written to zk (due to a zk issue). so this has to be a public error.,0,0.9919785261154175
463915406,9001,kowshik,2020-08-01T03:23:44Z,"updated the doc. let's keep the check, if it happens then it's a user error. especially because this can not happen if the user is using the tooling that we are going to provide in ak.",0,0.9834943413734436
463915409,9001,kowshik,2020-08-01T03:23:50Z,done.,0,0.9640594124794006
463915553,9001,kowshik,2020-08-01T03:25:20Z,"no, that is not required. please refer to the documentation above under `note` for this method where i have explained why.",0,0.9887967109680176
463916219,9001,kowshik,2020-08-01T03:34:23Z,isn't that what i'm using currently?,0,0.9554102420806885
463916470,9001,kowshik,2020-08-01T03:37:35Z,like how? i don't understand. isn't that what i'm doing currently?,-1,0.9254544377326965
463916610,9001,kowshik,2020-08-01T03:39:49Z,"if the broker has feature incompatibilities, then it should die as soon as it has received the zk update (it would die from within `finalizedfeaturechangelistener`).",0,0.9914355874061584
463916688,9001,kowshik,2020-08-01T03:40:25Z,done now.,0,0.9734506607055664
463934710,9001,kowshik,2020-08-01T07:31:07Z,"we should keep the existing check as it is. the reason is that if the existing node is `(disabled, {})` then here we would like to change it to `(enabled, features)`. therefore, we have to check the features as well as the `featureznodestatus`.",0,0.9942808151245117
463934948,9001,kowshik,2020-08-01T07:34:46Z,i do not understand the concern. which code path can possibly introduce `null` features attribute in `broker` object? it is impossible....,-1,0.9385892152786255
463935718,9001,kowshik,2020-08-01T07:44:14Z,"a value < 1 is indicative of a deletion request (a kind of downgrade request). it is for convenience of generating a special error message, that we handle the case here explicitly: `...less than 1 for feature...`.",0,0.9908258318901062
463936048,9001,kowshik,2020-08-01T07:48:44Z,done.,0,0.9640594124794006
463936098,9001,kowshik,2020-08-01T07:49:28Z,existing approach is equally readable too. i'd rather leave it this way.,0,0.9719207286834717
463936412,9001,kowshik,2020-08-01T07:54:05Z,"since the app depends on monotonically increasing elapsed time values, `system.nanotime()` is preferred. `system.currenttimemillis()` can change due to daylight saving time, users changing the time settings, leap seconds, and internet time sync etc.",0,0.9884588122367859
463937032,9001,kowshik,2020-08-01T08:02:25Z,"the `finalizedfeaturecache.getsupportedfeatures` api is not the right fit for the cache's public interface (it is quite unrelated to the other public apis of the cache). i'd rather not pollute the public api there, just for the sake of convenience.",0,0.9713286757469177
463937184,9001,kowshik,2020-08-01T08:04:35Z,just 2 occurrences (one in this test and other in the next test). i'd leave it the way it is as the test is readable with values inlined in the test body.,0,0.9904583692550659
465565925,9001,kowshik,2020-08-05T08:36:36Z,"actually this is an error case now. have updated the code with the fix, and with good documentation.",0,0.70169997215271
465570359,9001,kowshik,2020-08-05T08:44:21Z,"this does not seem to be required, since it is already achieved via `updatefeaturestest`. infact there we test using admin client, which is even better as it tests e2e client to server functionality. what do we gain by adding the additional tests in `kafkaapistest` ?",0,0.9887368083000183
465572011,9001,kowshik,2020-08-05T08:47:06Z,"i don't see that we consistently use a top level error code across other kafka apis, so i will leave it as it is. it feels ok for this api to not use it, as it does not make a significant difference.",0,0.9676020741462708
465572056,9001,kowshik,2020-08-05T08:47:12Z,answered below.,0,0.9894831776618958
467279790,9001,junrao,2020-08-07T21:29:27Z,the kip wiki has allowdowngrade at the topic level. could we update that?,0,0.9934002161026001
467282147,9001,junrao,2020-08-07T21:32:28Z,the kip wiki doesn't include this field.,0,0.9468581080436707
467309169,9001,junrao,2020-08-07T22:15:43Z,"when we roll the cluster to bump up ibp, it seems that it's possible for status to be enabled and then disabled repeatedly? this can be a bit weird.",-1,0.9521673917770386
467315417,9001,junrao,2020-08-07T22:40:05Z,"when we roll the cluster to bump up ibp, it seems that it's possible for the min of finalized version to flip repeatedly? this can be a bit weird. also, it seems that we should set min version based on the largest min version across all brokers?",-1,0.8941439986228943
467319530,9001,junrao,2020-08-07T22:57:09Z,"hmm, do we need to do this? if there is an incompatible feature, the broker will realize that and can just shut itself down.",0,0.8546025156974792
467326580,9001,junrao,2020-08-07T23:29:11Z,"if update.maxversionlevel < defaultminversionlevel, we throw an illegalstateexception. should we catch it and convert it to an error code?",0,0.9632719159126282
467330197,9001,junrao,2020-08-07T23:48:02Z,"since we are doing the compatibility check for every broker, do we need to special case here just for the broker feature on the controller?",0,0.9933699369430542
467333895,9001,junrao,2020-08-08T00:08:33Z,"if the broker discovers that it's incompatible, should it just shut itself down?",0,0.9123300313949585
467341811,9001,junrao,2020-08-08T01:04:11Z,could you explain how the default min version is different from the min in supportedfeatures?,0,0.9928643703460693
468000768,9001,junrao,2020-08-10T15:42:18Z,"the return type is different from the kip. which one is correct? since this is a public interface, in general, we don't want to expose anything other than truly necessary. this pr seems to expose a lot more public methods to the user. finalizedversionrange is in org.apache.kafka.common.feature. currently, all public interfaces are specified under javadoc in build.gradle. so, we need to either include that package in javadoc or move it to a public package.",0,0.9901032447814941
468000872,9001,junrao,2020-08-10T15:42:28Z,the return type is different from the kip. which one is correct?,0,0.977388858795166
468002060,9001,junrao,2020-08-10T15:44:20Z,the kip also exposes host() and port(). are they still needed?,0,0.9942670464515686
468005420,9001,junrao,2020-08-10T15:49:30Z,"the kip doesn't have describefeaturesoptions. if we are changing the kip, could we summarize the list of the things that are changed?",0,0.9746723175048828
468008294,9001,junrao,2020-08-10T15:53:53Z,"again, this method has a different signature from the kip.",0,0.9652292728424072
468009874,9001,junrao,2020-08-10T15:56:13Z,the kip doesn't have this method.,0,0.7877795696258545
468020800,9001,junrao,2020-08-10T16:14:00Z,handlenotcontrollererror() already throws an exception. should other errors like cluster_authorization_failed be treated in the same way?,0,0.9663015604019165
468084269,9001,kowshik,2020-08-10T18:04:56Z,i'm missing something. which lines on the kip-584 were you referring to? i didn't find any mention of the flag being at the topic level.,0,0.9090827107429504
468085443,9001,kowshik,2020-08-10T18:07:00Z,"yes, we changed to have an error code per feature update. i'll update the kip-584 write up.",0,0.9908808469772339
468089357,9001,kowshik,2020-08-10T18:14:32Z,"to be sure we are on same page, is this because of a controller failover during an ibp bump? it seems to me that this can happen mainly when ibp is being bumped from a value less than kafka_2_7_iv0 to a value greater than or equal to kafka_2_7_iv0 (assuming subsequent ibp bumps will be from kafka_2_7_iv0 to a higher value, so the node status will remain enabled). in general, i'm not sure how to avoid this node status flip until ibp bump has been completed cluster-wide.",0,0.9620702266693115
468097360,9001,kowshik,2020-08-10T18:29:32Z,"true, this is possible. good point. to be sure i understood, are you referring broadly to any future ibp bump? or specifically are you referring to the ibp bump from a value less than kafka_2_7_iv0 to a value greater than or equal to kafka_2_7_iv0? (since kafka_2_7_iv0 is the ibp where the feature versioning system gets activated) to answer your question, i'm not sure how to avoid the flip. it is to be noted that min version level changes are used only for feature version deprecation. due to the flipping values, it merely means some version levels would go a few times from deprecated -> available -> deprecated -> available...., until the ibp bump has been completed cluster-wide. i can't (yet) think of a case where the flip is dangerous, since: 1. we have this check: [a link] and 2. as best practice, we can recommend to not change a) minversion of supportedfeature as well as b) default minversionlevel within the same release. the reason being that we typically first deprecate a feature version level before we remove the code to drop support for it i.e. (b) usually has to happen before (a).",1,0.6473469734191895
468101982,9001,kowshik,2020-08-10T18:38:18Z,"good question. yes, the broker will shut itself down. but still there is a possible race condition that needs to be handled to prevent an incompatible broker from causing damage to cluster. the race condition is described in the kip-584 [a link]. please let me know your thoughts.",1,0.856960117816925
468103224,9001,kowshik,2020-08-10T18:40:39Z,"yes, excellent point. i'll fix this.",1,0.9911264777183533
468109791,9001,kowshik,2020-08-10T18:52:51Z,"it's required because `defaultminversionlevel` does not exist for a feature that's not in the supported list. however, i'll change the code to make the check more obvious to the reader (currently it's not).",0,0.9926376342773438
468111300,9001,kowshik,2020-08-10T18:55:30Z,"good question. the existing behavior is that it shuts itself down, as triggered by this loc. the reason to do it is that an incompatible broker can potentially do harmful things to a cluster (because max version level upgrades are used for breaking changes): [a link]",1,0.5806059241294861
468111785,9001,kowshik,2020-08-10T18:56:28Z,"sure, i'll update the pr documenting it.",0,0.9865520000457764
471627837,9001,junrao,2020-08-17T17:13:02Z,ok. there are a couple of places that this pr is inconsistent with the kip. 1. the kip has 2 levels of arrays: []featureupdatekey and []featurekey. this pr only has one array. 2. the kip has a timeoutms field and this pr doesn't.,0,0.9840294718742371
471806378,9001,junrao,2020-08-17T22:20:32Z,"my understanding of the race condition is that the controller finalizes a feature while there is a pending broker registration in the controller event queue. when the controller starts to process the new broker registration, it will realize that its supported feature is not compatible. here, it's seems that we will still process this new broker registration and only avoid sending updatatemetadatarequest to it. i am not sure if this helps since we already acted on this incompatible broker registration and some damage may already be done. the same updatatemetadatarequest will still be sent to other brokers and its metadata will be available to the clients. an alternative way is to just skip the handling of new broker registration if it's detected as incompatible.",0,0.807068407535553
494170995,9001,kowshik,2020-09-24T09:28:25Z,done. i have added a top-level error code now.,0,0.9659609794616699
494171030,9001,kowshik,2020-09-24T09:28:29Z,done.,0,0.9640594124794006
494171814,9001,kowshik,2020-09-24T09:29:49Z,"done. fixed the kip and the code, so that they align with each other now.",0,0.9825754165649414
494173396,9001,kowshik,2020-09-24T09:32:21Z,"done. i've updated the kip-584 write up, please refer to [a link] in the kip.",0,0.8868926763534546
494174446,9001,kowshik,2020-09-24T09:34:09Z,done. i've fixed this now to align with the kip.,0,0.948395311832428
494179911,9001,kowshik,2020-09-24T09:42:55Z,done. i've updated the kip to use `optional ` as well.,0,0.9755938053131104
494180021,9001,kowshik,2020-09-24T09:43:06Z,done. i've removed those methods from the kip.,0,0.974356472492218
494180167,9001,kowshik,2020-09-24T09:43:22Z,done. i've updated the kip to mention `describefeaturesoptions`.,0,0.9825748801231384
494180305,9001,kowshik,2020-09-24T09:43:36Z,"done. i've updated the kip to align with whats used here, so both are the same now.",0,0.9751793742179871
494180601,9001,kowshik,2020-09-24T09:44:03Z,done. the kip has been updated to have this method now.,0,0.926063597202301
494183456,9001,kowshik,2020-09-24T09:48:37Z,"done. fixed the code to not throw exception again when handling not_controller error. i'm not sure how could we treat it the same way. in the case of the not_controller error, the admin client code would retry the request once again when the exception is raised. but when cluster authorization fails, would a retry help?",0,0.9003694653511047
494519631,9001,kowshik,2020-09-24T18:20:37Z,done. i've changed the code such that we skip the broker registration if it's detected as incompatible.,0,0.9763690829277039
494542156,9001,kowshik,2020-09-24T18:54:14Z,done. this is fixed now.,0,0.9374632835388184
494569726,9001,kowshik,2020-09-24T19:46:20Z,done.,0,0.9640594124794006
494653251,9001,kowshik,2020-09-24T22:52:14Z,done.,0,0.9640594124794006
496093216,9001,junrao,2020-09-28T16:48:55Z,"space before ""name"".",0,0.9885703921318054
496099482,9001,junrao,2020-09-28T16:59:02Z,this is not included in the kip. should we update the kip?,0,0.9872667193412781
496104584,9001,junrao,2020-09-28T17:05:46Z,"since this is public facing, could we include the description in the kip?",0,0.9933910369873047
496118993,9001,junrao,2020-09-28T17:31:27Z,"since the user is not expected to instantiate this, should we make the constructor non-public?",0,0.9847829937934875
496120406,9001,junrao,2020-09-28T17:34:03Z,"since the user is not expected to instantiate this, should we make the constructor non-public?",0,0.9847829937934875
496122127,9001,junrao,2020-09-28T17:37:09Z,"this seems identical to supportedversionrange. should we just have one, sth like versionrange?",0,0.9577904939651489
496124713,9001,junrao,2020-09-28T17:41:52Z,are we adding the timeout option based on the kip discussion?,0,0.994804322719574
496131186,9001,junrao,2020-09-28T17:52:57Z,"""at a those "" typo?",0,0.9865981340408325
496211011,9001,junrao,2020-09-28T20:24:46Z,"i guess after the first step, deprecated finalized versions are no longer advertised to the client, but they can still be used by existing connections?",0,0.9931519031524658
496213232,9001,junrao,2020-09-28T20:29:04Z,perhaps isfeatureversioningsupported is a better name?,0,0.9658039212226868
496227488,9001,junrao,2020-09-28T20:56:44Z,is it useful to expose firstactiveversion to the client?,0,0.993472695350647
496253083,9001,junrao,2020-09-28T21:47:00Z,"could you define the default finalized features? also, default minimum version seems outdated now.",0,0.9884960651397705
496268711,9001,junrao,2020-09-28T22:22:21Z,perhaps it's better for the following code to use match instead if/else.,0,0.9923208355903625
496271143,9001,junrao,2020-09-28T22:29:17Z,setupfeatureversioning => maybesetupfeatureversioning ?,0,0.9929792284965515
496305291,9001,junrao,2020-09-29T00:20:56Z,map() is supposed to be used with no side effect. perhaps we could use match here.,0,0.991939127445221
496306005,9001,junrao,2020-09-29T00:23:48Z,"do we need to return the stacktrace to the caller? since this is unexpected, perhaps we can log a warn?",0,0.9878531694412231
496306586,9001,junrao,2020-09-29T00:26:06Z,indentation,0,0.822169840335846
496309833,9001,junrao,2020-09-29T00:38:35Z,featurecache => finalizedfeaturecache ?,0,0.991607666015625
496311550,9001,junrao,2020-09-29T00:45:23Z,"i think the convention is that if there is a top level error, the second level will just be empty since there is not need to process them individually.",0,0.9874118566513062
496312688,9001,junrao,2020-09-29T00:50:09Z,-1 => -1l?,0,0.9752979874610901
496315493,9001,junrao,2020-09-29T01:00:56Z,this package is not part of the javadoc and thus is not part of the public interface.,0,0.9877386093139648
496317328,9001,junrao,2020-09-29T01:08:23Z,"since we are including the timeout in the updatefeature request, perhaps we could just use that timeout here.",0,0.9892169237136841
496318368,9001,junrao,2020-09-29T01:12:25Z,featurecache => finalizedfeaturecache?,0,0.9929535984992981
496319189,9001,junrao,2020-09-29T01:15:24Z,"should we just verify the range [first_active_version, max]?",0,0.9949135780334473
496321312,9001,abbccdda,2020-09-29T01:23:04Z,"yea, you are right, i think this comment belongs to updatefeatures",0,0.643130362033844
496506413,9001,kowshik,2020-09-29T08:09:57Z,done.,0,0.9640594124794006
496509097,9001,kowshik,2020-09-29T08:12:24Z,done. updated the kip. please refer to [a link] section.,0,0.9504697918891907
496509282,9001,kowshik,2020-09-29T08:12:34Z,done. updated the kip. please refer to [a link] section.,0,0.9504697918891907
496511604,9001,kowshik,2020-09-29T08:14:42Z,"it is instantiated from `kafka.server.updatefeaturestest`, so have to keep the c'tor public.",0,0.9949309229850769
496511864,9001,kowshik,2020-09-29T08:14:55Z,"it is instantiated from `kafka.server.updatefeaturestest`, so have to keep the c'tor public.",0,0.9949309229850769
496523315,9001,kowshik,2020-09-29T08:25:21Z,"i considered this, however if we plan to expose `firstactiveversion` to the client, then, it is better to have 2 separate classes like we do now. this is because `firstactiveversion` will become an attribute only in `supportedversionrange` class.",0,0.9942604303359985
496523894,9001,kowshik,2020-09-29T08:25:52Z,"yes, it is already added. the base class: `abstractoptions` contains a `timeoutms` attribute and the value is set in the `updatefeaturesrequest`.",0,0.9946308135986328
496524072,9001,kowshik,2020-09-29T08:26:03Z,done.,0,0.9640594124794006
496524793,9001,kowshik,2020-09-29T08:26:44Z,"yes, correct. i have updated the doc mentioning the same.",0,0.9374356269836426
496524910,9001,kowshik,2020-09-29T08:26:50Z,done.,0,0.9640594124794006
496525949,9001,kowshik,2020-09-29T08:27:48Z,"this is a really good point. yes, i feel it is useful to expose it to the client via `apiversionsresponse`. i can change the kip suitably and then update the pr.",1,0.974741518497467
496526254,9001,kowshik,2020-09-29T08:28:04Z,"done. i reworded a bit and i'm now no longer using ""default finalized features"" and ""default minimum version"" in the wordings.",0,0.9563660621643066
496527539,9001,kowshik,2020-09-29T08:29:14Z,done.,0,0.9640594124794006
496528169,9001,kowshik,2020-09-29T08:29:47Z,done.,0,0.9640594124794006
496528445,9001,kowshik,2020-09-29T08:30:00Z,done.,0,0.9640594124794006
496530810,9001,kowshik,2020-09-29T08:32:23Z,done. good point. i'm now logging just a warning and i've removed the stacktrace from the return value.,1,0.8462878465652466
496531037,9001,kowshik,2020-09-29T08:32:31Z,done.,0,0.9640594124794006
496534914,9001,kowshik,2020-09-29T08:36:03Z,done.,0,0.9640594124794006
496535534,9001,kowshik,2020-09-29T08:36:37Z,done. great point.,1,0.990519642829895
496535646,9001,kowshik,2020-09-29T08:36:42Z,done.,0,0.9640594124794006
496538616,9001,kowshik,2020-09-29T08:39:26Z,done. i have now moved it to the package: `org.apache.kafka.clients.admin`.,0,0.9728930592536926
496543685,9001,kowshik,2020-09-29T08:44:03Z,"i agree. but note that in this method, we do not process an `updatefeaturesrequest`. this method is only called during controller election to setup feature versioning. so, i have incorporated your suggestion at the point where we process the request, look for `def processfeatureupdateswithactivecontroller` in this file where now i set the zk write timeout to be `min(timeoutms, config.zkconnectiontimeoutms)`.",0,0.9536261558532715
496544239,9001,kowshik,2020-09-29T08:44:33Z,done.,0,0.9640594124794006
496550557,9001,kowshik,2020-09-29T08:54:04Z,"we need to keep the existing validation. here is a case where `minversionlevel < firstactiveversion` is true, but still there are no incompatibilities: [code block] for example, the above can happen during step 1 of feature verison level deprecation. imagine the following: * a supported feature exists with `supportedversionrange={minversion=1, firstactiveversion=4, maxversion=7}` * the above feature is finalized at `{minversionlevel=2, maxversionlevel=6}` in zk already. then imagine a new kafka release is deployed that raises `firstactiveversion` for the supported feature from 1 -> 4 (in order to deprecate versions: 1,2,3). in such a case, during kafka server startup (where we check for feature incompatibilities), we would run into the comparison cited above between the new `supportedversionrange` and existing `finalizedversionrange`. but it is not considered to be a case of incompatibility.",0,0.9940325617790222
496901588,9001,abbccdda,2020-09-29T17:06:45Z,"do we want to have a different name from `org.apache.kafka.common.feature.finalizedversionrange`, such as `finalizedversionlevels`? same case for `supportedversionrange`, personally i feel the same class name makes the navigation harder.",0,0.9158340096473694
496916316,9001,abbccdda,2020-09-29T17:30:34Z,"i think we could just make the `firstactiveversion = minversion` by default, to avoid the requirement for configuring firstactiveversion",0,0.9935245513916016
496917029,9001,abbccdda,2020-09-29T17:31:41Z,similar here to make `firstactiveversion = minversion` as default.,0,0.9938889741897583
496917907,9001,abbccdda,2020-09-29T17:33:09Z,"so we are saving the zk epoch in a long, which was supposed to be an int field?",0,0.9933280944824219
497255894,9001,kowshik,2020-09-30T05:46:08Z,"yes, but can i do it in a follow-up pr? the reason is if i were to refactor it now, this pr will bloat up.",0,0.9763095378875732
497256162,9001,kowshik,2020-09-30T05:47:01Z,done. i've provided an overloaded c'tor now in `org.apache.kafka.common.feature.supportedversionrange` that only takes `minversion` and `maxversion` as parameters.,0,0.9938293099403381
497256475,9001,kowshik,2020-09-30T05:48:03Z,"as mentioned in above response to a different comment, i've provided an overloaded c'tor now in `org.apache.kafka.common.feature.supportedversionrange` that only takes `minversion` and `maxversion` as parameters.",0,0.9951797723770142
497257420,9001,kowshik,2020-09-30T05:51:12Z,we would like to avoid overflow issues once zk is gone in the future. this change is being done based on colin's suggestion in the kip-584 voting thread: - [a link] is colin's comment - [a link] is my response,0,0.9936239719390869
497399425,9001,kowshik,2020-09-30T10:17:16Z,done. the `firstactiveversion` is now part of `apiversionsresponse`. i added it in the recent commit: a7f4860f5f8bb87cfb01452e208ff8f4e45bcd8b.,0,0.987404465675354
497793784,9001,junrao,2020-09-30T20:53:28Z,"hmm, why do we need to take the min? if the zk data is propagated quickly, waituntilepochorthrow() will just return early.",0,0.8494635224342346
497813798,9001,junrao,2020-09-30T21:34:06Z,"i was looking at existing classes fro the return value. for example, createaclsresult deliberately makes the constructor non-public.",0,0.9810020327568054
497848498,9001,junrao,2020-09-30T23:05:04Z,it's useful to return an error message too.,0,0.9863200783729553
497850391,9001,junrao,2020-09-30T23:11:02Z,could we use collections.emptymap()?,0,0.9935761094093323
497856858,9001,junrao,2020-09-30T23:32:11Z,"this can throw an exception due to feature mismatch. currently, this forces the controller to move but keeps the broker alive. should we force the broker to exit in this case?",0,0.9149708151817322
498072158,9001,kowshik,2020-10-01T08:29:43Z,"done. good point, removed the min now.",1,0.7876065969467163
498092489,9001,kowshik,2020-10-01T09:03:09Z,done. good catch. also i've modified `org.apache.kafka.clients.admin.{supported|finalized}versionrange` classes to make constructors non-public.,1,0.9737095236778259
498093400,9001,kowshik,2020-10-01T09:04:48Z,would the default error message suffice?: `unable to update finalized features due to an unexpected server error.`,0,0.9851778149604797
498094043,9001,kowshik,2020-10-01T09:05:53Z,done.,0,0.9640594124794006
498113308,9001,kowshik,2020-10-01T09:38:02Z,"done. good point. it looks appropriate to me that we exit the broker in this case. i've captured the exception and added a call to `exit.exit(1)`, is there a better way to do it?",1,0.8015176057815552
498420758,9001,junrao,2020-10-01T17:55:31Z,"thinking about this a bit more. it seems that the intention of firstactiveversion is to avoid deploying a wrong version of the broker that causes the deprecation of a finalized feature version unexpectedly. however, the same mistake can happen with firstactiveversion since the deprecation of a finalized feature version is based on firstactiveversion. so, i am not sure if firstactiveversion addresses a real problem. in general, we tend to deprecate a version very slowly in ak. so, if the mistake is to deploy a new release that actually deprecates a supported version. old clients are likely all gone. so, moving finalized min version to supported min version may not cause a big problem. we can just document that people should make sure old versions are no longer used before deploying new releases. if the mistake is to deploy an old version of the broker whose maxsupportedversion is < maxfinalizedversion, we will fail the broker. so, this mistake can be prevented.",0,0.5282132625579834
498495464,9001,kowshik,2020-10-01T20:27:42Z,": i'd like to discuss an example that cites a problem i'm concerned about. let's say we have some feature `f` whose: * supported version range is: `[minversion=1, maxversion=6]` * existing finalized version range in the cluster is: `[minversionlevel=1, maxversionlevel=6]` now, let us say a point in time arrives when we need to deprecate the feature version `1`. let us say we bump up supported `minversion` to `2` in a subsequent major kafka release. before this new release is deployed, let us assume the cluster operator knows 100% that old clients that were using the feature at version `1` are gone, so this is not a problem. **problem:** still, if we deploy this new release, the broker will consider the following as a feature version incompatibility. * supported version range is: `[minversion=2, maxversion=6]` * existing finalized version range in the cluster is: `[minversionlevel=1, maxversionlevel=6]` upon startup of a broker thats using the new release binary, the above combination will crash the broker since supported `minversion=2` is greater than `minversionlevel=1`. basically the versioning system thinks that there is now a broker that does not support `minversionlevel=1`, which does not adhere to the rules of the system. we currently do feature version incompatibility checks during kafkaserver startup sequence, [a link]. here is my thought: this is where `firstactiveversion` becomes useful. by bumping it up during a release (instead of the supported feature's `minversion`), we are able to get past this situation. when `firstactiveversion`is advanced in the code, and the cluster is deployed, the controller (and all brokers) know that the advancement acts a request to the controller to act upon the feature deprecation (by writing the advanced value to the `featureznode`). so, in this case we would release the broker with the supported feature version range: `[minversion=1, firstactiveversion=2, maxversion=6]`, and the broker release wouldn't fail (because the intent is clearly expressed to the versioning system). what are your thoughts on the above? is there a different way to solve it better that i'm missing, without compromising the versioning checks enforced by the system?",0,0.982027530670166
498512579,9001,junrao,2020-10-01T21:04:51Z,": i was thinking what if we relax the current check by just making sure that maxversion of finalized is within the supported range. basically in your example, if supported minversion goes to 2, it's still allowed since it's less than maxversion of finalized. however, if supported minversion goes to 7, this fails the broker since it's more than maxversion of finalized. your concern for the relaxed check seems to be around deploying a wrong version of the broker by mistake. i am not sure if that's a big concern. if the wrong broker affects maxversion of finalized, the broker won't start. if the wrong broker affects minversion of finalized, if we deprecated slowly, it won't impact the existing clients.",-1,0.5861698985099792
498574911,9001,kowshik,2020-10-02T00:38:05Z,"does the below feel right to you? the key thing seems to be that you feel it is rare to deprecate feature versions in ak. i agree with the same. so, i propose we just do not have to solve the deprecation problem in this pr, until we find a clear route that the ak community agrees with. in this pr i propose to revert the `firstactiveversion` change, leaving the rest of the things the way they are. in the future, we can develop a concrete solution for version deprecation i.e. the part on how to advance `minversion` of supported feature, may be (or may not be) using `firstactiveversion` or other ways (it is up for discussion, maybe in a separate kip). i have made this proposed change in the most recent commit: 4218f95904989028a469930d0c266362bf173ece. regarding your thought: there is a consequence to relaxing the current check: the controller can not effectively finalize `minversionlevel` for the feature, because, with a relaxed check we do not know whether all brokers in the cluster support a particular `minversion` when the controller finalizes the `minversionlevel` at a particular value. it seems useful to keep the concept of `minversionlevel` like the way it is now (i.e. it is the lowest version guaranteed to be supported by any broker in the cluster for a feature). and as i said above, in the future, we can decide on ways to mutate it safely (maybe through `firstactiveversion` or other means).",0,0.9624047875404358
498959506,9001,junrao,2020-10-02T17:39:15Z,"this this case, existingfeatureznode.features is expected to be empty? could we log a warn if this is not the case and always set finalized to empty?",0,0.9953234791755676
498960633,9001,junrao,2020-10-02T17:41:40Z,should we call updatefeatureznode() so that we can get the logging?,0,0.9949295520782471
498980025,9001,junrao,2020-10-02T18:19:31Z,"this test may not be enough. the issue is that when a controller fails over, it's possible that new brokers have joined the cluster during the failover. so, if existingfeatureznode is enabled, it may not be reflecting the state in those newly joined brokers. so, it seems that we need to do the validation for every broker during controller failover in that case.",0,0.9852434396743774
499034372,9001,junrao,2020-10-02T20:25:16Z,"""we do not know whether all brokers in the cluster support a particular minversion when the controller finalizes the minversionlevel at a particular value."" the controller knows the minsupportedversion for all brokers, right? what if we do the following? when finalizing a feature, the controllers uses the highest minsupportedversion across all brokers as finalizedminversion, as long as it's <= finalizedmaxversion. on broker restart, we also advance finalizedminversion if the new broker's minsupportedversion has advanced (assuming still <= finalizedmaxversion).",0,0.9882141351699829
499036138,9001,junrao,2020-10-02T20:29:54Z,could we make the constructor non-public?,0,0.9905831813812256
499036605,9001,junrao,2020-10-02T20:31:03Z,could we make the constructor non-public?,0,0.9905831813812256
499102118,9001,kowshik,2020-10-03T01:14:01Z,done.,0,0.9640594124794006
499102130,9001,kowshik,2020-10-03T01:14:05Z,done.,0,0.9640594124794006
499102146,9001,kowshik,2020-10-03T01:14:17Z,done.,0,0.9640594124794006
499102163,9001,kowshik,2020-10-03T01:14:24Z,done.,0,0.9640594124794006
499102176,9001,kowshik,2020-10-03T01:14:36Z,done. excellent catch.,1,0.9950364232063293
499102266,9001,kowshik,2020-10-03T01:15:32Z,"awesome. this is a very good point. the approach you proposed is very elegant, and we should shoot for it, when were giving the benefit of the doubt on deprecation to the broker binary version. ill update the kip with details and share with community for feedback. as soon as that is done, i'll follow up in separate pr implementing this logic.",1,0.9938709735870361
499739889,9001,junrao,2020-10-05T16:54:25Z,it's a bit weird that featureznode.status is defined as featureznodestatus.value. it seems that it should be defined as just featureznodestatus?,-1,0.9843239188194275
499740489,9001,junrao,2020-10-05T16:55:28Z,should we log the non-empty features too?,0,0.9929337501525879
499753420,9001,junrao,2020-10-05T17:18:52Z,should we revert the changes here?,0,0.9921866655349731
499761963,9001,junrao,2020-10-05T17:34:20Z,"this is probably not enough since it only waits for the controller path to be created in zk, which happens before the processing of the finalized features.",0,0.9869354367256165
499775367,9001,junrao,2020-10-05T17:59:22Z,could we add feature to the javadoc above?,0,0.9941694736480713
499776675,9001,junrao,2020-10-05T18:01:47Z,should we use a version > 0?,0,0.993067741394043
499776894,9001,junrao,2020-10-05T18:02:14Z,typo thats,0,0.897704541683197
499810462,9001,kowshik,2020-10-05T19:05:24Z,"done. i have improved it now introducing a type definition called `featureznodestatus` that points to `value`. iiuc you were referring to this loc, correct? [a link] here the enum: `featureznodestatus` is defined and used in the same file. i thought i'd add an `import` to fix it like the below, but it was a little unusual to add an `import` statement right above the class definition: [code block] with my recent change, in the future it should be possible to `import featureznodestatus._` within other files when referring to the enum value.",0,0.9762468338012695
499811265,9001,kowshik,2020-10-05T19:06:45Z,done.,0,0.9640594124794006
499811752,9001,kowshik,2020-10-05T19:07:42Z,done. nice catch!,1,0.9960498213768005
499812076,9001,kowshik,2020-10-05T19:08:21Z,done.,0,0.9640594124794006
499816373,9001,kowshik,2020-10-05T19:16:34Z,done. good point.,1,0.9524728059768677
499816619,9001,kowshik,2020-10-05T19:17:03Z,done.,0,0.9640594124794006
499847021,9001,kowshik,2020-10-05T20:16:35Z,done. please take a look at the fix. i've added logic to wait for processing on a dummy event just after waiting for controller election. i'm hoping this will make sure the controller failover logic is completed before the test proceeds further to make assertions.,1,0.5321395993232727
501418496,9001,chia7712,2020-10-08T02:53:08Z,"the error message says it can't be null but there is no null check. for another, this check can happen early (when creating [code block])",0,0.9919758439064026
501432770,9001,chia7712,2020-10-08T03:51:37Z,"should we add an empty-parameter variety for [code block]? that is similar to other methods, like [code block] and [code block].",0,0.9953572154045105
501489060,9001,chia7712,2020-10-08T06:58:43Z,the top-level error message is not propagated.,0,0.9738301634788513
501575432,9001,kowshik,2020-10-08T09:26:06Z,done. addressed in #9393.,0,0.9874934554100037
501575489,9001,kowshik,2020-10-08T09:26:11Z,done. addressed in #9393.,0,0.9874934554100037
501575519,9001,kowshik,2020-10-08T09:26:13Z,done. addressed in #9393.,0,0.9874934554100037
102111062,2476,becketqin,2017-02-21T00:13:51Z,the variable names seem a little misleading. are all partitions without leader information unauthorized?,-1,0.6942936182022095
102111239,2476,becketqin,2017-02-21T00:16:05Z,should we use the exception returned by the broker in this case?,0,0.9935945868492126
102113712,2476,becketqin,2017-02-21T00:48:53Z,"when `client.poll(future, remaining)` returns true, the future may either contains a value (succeeded) or an error (failed). if the future has an error, calling `future.value()` will throw exception. it seems better if we can return the full results to the users even if some of the requests failed so the users will be able to know which partitions has failed to purge.",0,0.9930219054222107
102114179,2476,becketqin,2017-02-21T00:55:27Z,"it seems a single `consumernetworkclient.poll(0)` cannot guarantee all the requests are sent out. also, the interface might be a little weird that after `purgedatabefore()` is returned the users have to keep calling future.client.poll() otherwise the futures will not be completed. i am wondering how would user use the asynchronous purge in this case? at very least we should document this clearly.",0,0.8518348336219788
102114578,2476,becketqin,2017-02-21T01:00:08Z,this could just be a string concatenation.,0,0.9843770265579224
102116849,2476,becketqin,2017-02-21T01:29:45Z,this seems a little over optimizing. any reason we care about invoking time.milliseconds here more than in line 441 and everywhere else?,0,0.8292216062545776
102117137,2476,becketqin,2017-02-21T01:33:37Z,should we log the partition information and which replica is unavailable here?,0,0.9905495047569275
102117519,2476,becketqin,2017-02-21T01:38:43Z,should this be in write lock?,0,0.9929754734039307
102118327,2476,becketqin,2017-02-21T01:47:26Z,is this comment accurate?,0,0.9839099645614624
102118888,2476,becketqin,2017-02-21T01:54:33Z,nit: could be `mapvalues`.,0,0.9936956763267517
102119889,2476,becketqin,2017-02-21T02:06:32Z,"methods with three tuples as return value may be a little hard to follow, may be we can create a case class. at very least we should document each field of the return value.",0,0.9832826852798462
102121248,2476,becketqin,2017-02-21T02:22:07Z,do we want to distinguish between no_log_start_offset v.s. log_start_offset = 0? is it clearer to define the no_log_start_offset as -1?,0,0.9945801496505737
102146034,2476,lindong28,2017-02-21T07:37:14Z,agree. i have updated the names.,0,0.9765897393226624
102146077,2476,lindong28,2017-02-21T07:37:42Z,good point. i have updated code to use error from metadatarequest.,1,0.8935791850090027
102146450,2476,lindong28,2017-02-21T07:40:56Z,great point. i have updated the adminclient to create its own thread to do `client.poll(retrybackoffms)`. i find it necessary for adminclient to have its own thread in order to support both syn and async operation. i have also added `testlogstartoffsetafterasyncpurge()` to validate the asyn purge operation.,1,0.900198221206665
102147486,2476,lindong28,2017-02-21T07:49:25Z,"this should not be a problem for `purgedatabefore()`, because those `futures` provided to the `compositefuture` has been constructed in such a way that they never raises exception. those future will call `future.complete(result)` in case of `onfailure`, where result indicates has the error information. i agree it would be make `compositefuture` more useful if this class handles the logic of converting error to result and return the full results to user as you suggested. but i don't have a good way to do it now because `compositefuture` doesn't know the type of the return value -- it currently use template `t`.",0,0.9627407789230347
102147741,2476,lindong28,2017-02-21T07:51:19Z,is there any negative impact to use stringbuilder as compared to string concatenation? using stringbuilder here allows us to have the same code style as `tostring()` of other requests such as `producerequest` and `leaderandisrrequest`.,0,0.994047999382019
102147786,2476,lindong28,2017-02-21T07:51:46Z,good point. i have updated the log message as you suggested.,1,0.9121050238609314
102147860,2476,lindong28,2017-02-21T07:52:34Z,i think it is not bad to remove one unnecessary call to `time.milliseconds`. i removed it since you don't like it.,-1,0.4854874908924103
102148192,2476,lindong28,2017-02-21T07:55:22Z,i validated that we can not use `mapvalues()` here. this is because `mapvalues()` returns a map view which maps every key of this map to `f(this(key))`. the resulting map wraps the original map without copying any elements. as a result `status.ackspending = true` in the constructor of `delayedpurge` becomes no-op.,0,0.9942283630371094
102148242,2476,lindong28,2017-02-21T07:55:47Z,good point. i have updated the code to make it more readable.,1,0.94026118516922
102148307,2476,lindong28,2017-02-21T07:56:18Z,"i think we should use readlock since this method doesn't update leader or isr of the partition, right?",0,0.988359808921814
102148443,2476,lindong28,2017-02-21T07:57:24Z,it was not accurate. i have updated the comment to replace `all replicas of this broker` to `in-sync replicas of this broker`,0,0.9913045167922974
102148589,2476,lindong28,2017-02-21T07:58:36Z,i don't think it is necessary to distinguish between no_log_start_offset v.s. log_start_offset = 0. is there any use-case for no_log_start_offset?,0,0.979167103767395
102260819,2476,becketqin,2017-02-21T17:01:27Z,"not much difference, just for readability (see below) we can keep them the same as other requests. [a link]",0,0.9679603576660156
102263429,2476,becketqin,2017-02-21T17:12:12Z,"yes, you are right. read lock here is fine.",0,0.7146807909011841
102265149,2476,becketqin,2017-02-21T17:19:34Z,"in general, we want to identify the state of the system as clear as possible. the follower should not take any action if the log_start_offset on the broker is no_log_start_offset. but if the follower sees the leader returning the starting offset = 0 while the actual starting offset on the leader is not, this introduces confusion.",0,0.9792413115501404
102267118,2476,becketqin,2017-02-21T17:27:24Z,the kip stated that the consumer will put value -1l as the log_begin_offset.,0,0.9921305775642395
102267688,2476,becketqin,2017-02-21T17:29:46Z,"nit: in consumer we use the term ""earliest"" instead of ""smallest"", maybe we can make the term consistent.",0,0.9933506846427917
102269297,2476,becketqin,2017-02-21T17:37:30Z,maybe we should always use the latest version here?,0,0.9928678274154663
102269853,2476,becketqin,2017-02-21T17:39:51Z,latest version?,0,0.9822063446044922
102289505,2476,lindong28,2017-02-21T19:04:23Z,agree. i have updated the code to test all versions of fetchresponse.,0,0.979487955570221
102289533,2476,lindong28,2017-02-21T19:04:33Z,sure. updated to use latest version here.,0,0.9909723997116089
102289562,2476,lindong28,2017-02-21T19:04:42Z,sure. made the change.,0,0.9861053824424744
102289627,2476,lindong28,2017-02-21T19:04:58Z,nice catch. updated to use -1l here.,1,0.9235044121742249
103133485,2476,becketqin,2017-02-27T03:54:41Z,"the comment is a little confusing here. how about ""the offset before which the messages will be deleted.""",-1,0.8389800190925598
103134243,2476,becketqin,2017-02-27T04:09:47Z,sleeping here seems not ideal and may miss subsequent action invoked by the users. we probably want to have a long poll() and just wake up the networkthread when needed.,0,0.8435977101325989
103134387,2476,becketqin,2017-02-27T04:12:42Z,"since we have separate thread now, retry could be done without involving users, right?",0,0.9907921552658081
103136031,2476,becketqin,2017-02-27T04:45:50Z,nit: can we just call it timebeforelocalpurge?,0,0.9902093410491943
103136983,2476,becketqin,2017-02-27T05:02:36Z,"if we want to make this optimization, we should do it in line 330 as well.",0,0.9888601899147034
103138261,2476,becketqin,2017-02-27T05:26:55Z,the earliest offset allowed...,0,0.977940022945404
103138990,2476,becketqin,2017-02-27T05:38:11Z,"the statement here is a little misleading. logstartoffset is not used to ""decide"" the log retention. the log retention is still based on time/size limit. the logstartoffset will be updated by retention. a manual update of logstartoffset may trigger the log deletion.",0,0.9352208375930786
103139730,2476,becketqin,2017-02-27T05:49:15Z,"hmm, why would truncation change the startlogoffset? shouldn't truncation always be above the startlogoffset?",0,0.836133599281311
103140001,2476,becketqin,2017-02-27T05:53:11Z,"the update of logstartoffset should probably be synchronized and ensure no rewind will happen, otherwise a fetch request may see an incorrect logstartoffset.",0,0.9929785132408142
103140524,2476,becketqin,2017-02-27T06:00:58Z,"it seems we should be careful about when to delete the log segments. in the current code, when the leader deleted an old log segment. the low watermark will not increase immediately because the followers has not updated the logstartoffset yet. however, at this point if user tries to fetch from lw, they will receive an offset out of range exception, which is not expected. one solution would be letting the segment deletion to be based on the low watermark instead of logstartoffset. so we need to delay the log deletion until low watermark is updated. similarly the valid range of fetch request should be based on lw instead of logstartoffset. nit: there is an existing typo in line 729, which missed a ""t"" in ""deleteretentionmsbreachedsegments()"".",0,0.982993483543396
103140662,2476,becketqin,2017-02-27T06:02:53Z,"should it be an error to truncate beyond the logstartoffset? logstartoffset should not decrease, right?",0,0.979604959487915
103140993,2476,becketqin,2017-02-27T06:07:48Z,"it seems that we should also checkpoint low watermarks, right?",0,0.991680920124054
103272179,2476,lindong28,2017-02-27T18:07:47Z,"when there is no pending requests, `consumernetworkclient.poll(...)` blocks for up to `retrybackoffms`. it means the thread does poll() in kind of busy looping manner if we don't sleep here. also, the thread holds the lock on `consumernetworkclient` while blocked on `selector.poll()` which means the user will be blocked waiting for lock in order to enqueue requests.",0,0.977363109588623
103273306,2476,lindong28,2017-02-27T18:13:28Z,"yes we can, if we ask user to specify retries num and retry back off. current implementation assumes retries = 1. this seems like an optimization which may be added later?",0,0.9906089305877686
103273330,2476,lindong28,2017-02-27T18:13:35Z,sure. fixed now.,0,0.9868775010108948
103273660,2476,lindong28,2017-02-27T18:15:11Z,"do you mean `debug(""produce to local log in %d ms"".format(time.milliseconds - stime))`? i thought this `time.milliseconds` will only be evaluated if debug level logging is enabled, no?",0,0.9924567937850952
103274743,2476,lindong28,2017-02-27T18:20:09Z,sure. fixed now.,0,0.9868775010108948
103275187,2476,lindong28,2017-02-27T18:22:19Z,fixed.,0,0.979083240032196
103276622,2476,lindong28,2017-02-27T18:28:41Z,"i include this scenario because i couldn't provide that log truncation will always be above the logstartoffset. for example, we have had bug such that log may be truncated below high watermark in case of double failure.",0,0.9456486701965332
103276835,2476,lindong28,2017-02-27T18:29:37Z,sure. i changed it to `log deletion`.,0,0.9888572096824646
103288992,2476,lindong28,2017-02-27T19:23:42Z,good point. i just added `lock` around this.,1,0.9242081642150879
103293344,2476,lindong28,2017-02-27T19:42:11Z,"sure, the typo is fixed. in the current implementation, if user seeks to earliest offset, he/she will seek to the `logstartoffset` of the leader regardless of what is the low watermark. user will not seek to lw since lw is not even exposed to the user. is there any concern with this approach?",0,0.9905980229377747
103295145,2476,becketqin,2017-02-27T19:49:35Z,"if poll() itself is not a busy looping internally, we will not have a busy loop (even though it look like so). however, in the current case, if retry back off is set to 0, we do have a busy poll(). holding a lock and blocking on selector.poll() is strange, maybe we should reconsider that. even if that is true, we can still have a queue outside of the consumernetworkclient and wake up the sender thread to poll from that queue.",0,0.8920475244522095
103295641,2476,lindong28,2017-02-27T19:51:32Z,if everything is implemented correctly then log start offset should not decrease. but in reality we have seen unlean leader election during double failure where the logendoffset is truncated beyond high watermark. it seems safer to preserve the existing behavior of `truncateto()` and allow logstartoffset to be reduced if such truncation does happen instead of throwing exception. note that such truncation will only happen as part of unclean leader election initiated by the brokers themselves.,0,0.9927175045013428
103295886,2476,lindong28,2017-02-27T19:52:40Z,"no, we intentionally only checkpoint logstartoffset. is there any reason to checkpoint lowwatermark?",0,0.9890303015708923
103307226,2476,becketqin,2017-02-27T20:43:41Z,it will call `time.milliseconds` because it is an argument passed to the `debug()`.,0,0.993489146232605
103307455,2476,becketqin,2017-02-27T20:44:49Z,"if it is not an expected behavior, we should throw some exception instead of allowing the lw to decrease, right?",0,0.9735624194145203
103310427,2476,ijuma,2017-02-27T20:58:41Z,"i'm a bit confused about the discussion here, so i'll just explain how it works. :) whatever one passes as a parameter to `debug` is only evaluated if debug logging is enabled. at runtime, a `function0` is passed and the body of that function is the block of code passed as the parameter to `debug`. does that make sense?",1,0.9790700078010559
103362427,2476,becketqin,2017-02-28T02:16:09Z,"thanks for the clarification . you are right, i realized that after taking a closer look.",1,0.9783939719200134
103580604,2476,lindong28,2017-02-28T23:49:38Z,"discussed offline. given that existing apis such as `adminclient.listgroupoffsets(..)` and `kafkaconsumer.retrieveoffsetsbytimes(..)` would not retry and just expose the exception to user, it should be ok for `adminclient.purgedatabefore(...)` to do the same thing. if we think it is useful to retry for user, we probably want to discuss the new configs and do it in java adminclient as part of kip-117.",0,0.9939418435096741
103580824,2476,lindong28,2017-02-28T23:51:17Z,"discussed offline. given that `log.truncateto(...)` has explicitly consider the case that the targetoffset is smaller than base offset of the first log segment, it would be safer and simpler for us to assume that `log.truncateto(...)` can truncate to an offset smaller than logstartoffset.",0,0.9936647415161133
103580946,2476,lindong28,2017-02-28T23:52:03Z,"discussed offline. given that log.truncateto(...) has explicitly consider the case that the targetoffset is smaller than base offset of the first log segment, it would be safer and simpler for us to assume that log.truncateto(...) can truncate to an offset smaller than logstartoffset.",0,0.9931684732437134
103595573,2476,lindong28,2017-03-01T01:49:32Z,"i have updated the adminclient to remove the sleep operation. and the patch guarantees that if user thread attempts to send any request, it will get the lock on consumernetworkclient and enqueue the requests once the currehnt `client.poll(..)` exits. the user thread may still wait up to `maxretrybackoffms` in order to send the requests as of current implementation. this is because `consumernetworkclient.poll(...)` does not guarantee that it will unblock and send the request if there is available request to be send by `consumernetworkclient.send(...)`. the problem exists even if we have a queue outside of consumernetworkclient and use only one thread to call `consumernetworkclient.poll(...)` and `consumernetworkclient.send(...)`. having user thread wake up consumer may help reduce the chance of unnecessary block but doesn't prevent this from happening. ideally we want to be able to fix consumernetworkclient so that user's request should get sent immediately if there is no other inflight requests. but it turns out to be a non-trivial fix. the problem is that `consumernetworkclient.poll(...)` will hold the lock of `consumernetworkclient` while it is blocked on `nioselector.select(ms)`. if user calls `nioselector.wakeup()`, it may be lost if the sender thread is right before the `nioselector.select(ms)` while `nioselector.wakeup()` is called. if user attempt to get the lock of `consumernetworkclient` before calling `nioselector.wakeup()`, then it will block as well while trying to get the lock. we need to find a way for the `poll(...)` to release lock while it is waiting on `nioselector.select(ms)`. but i don't have an easy way to fix it.",0,0.9912051558494568
103671647,2476,ijuma,2017-03-01T12:21:50Z,"i didn't see this mentioned in the kip. this is a user facing cli tool, so we should mention it there.",0,0.9884865283966064
103671752,2476,ijuma,2017-03-01T12:22:42Z,"we can only do this once there's agreement that the next release is 0.11.0. luckily, i started that discussion recently and people seem to be in favour. :)",1,0.9914741516113281
103671959,2476,ijuma,2017-03-01T12:23:50Z,"since 0.10.0, we do the `iv0` thing (e.g. `kafka_0_11_0_iv0`). the version string should be changed accordingly.",0,0.9954817295074463
103672175,2476,ijuma,2017-03-01T12:25:02Z,an empty synchronized block doesn't do anything. is this still in progress?,0,0.9682084321975708
103681117,2476,ijuma,2017-03-01T13:21:02Z,"just so that we are on the same page. until this method is available in the java adminclient, there is no public api for it (i.e. the scala `adminclient` is an internal class), right? so, the tool is the only way to do it if one doesn't want to deal with breakage later.",0,0.9821982979774475
103748555,2476,lindong28,2017-03-01T18:00:15Z,i included it as a way for myself and probably reviewers to test the patch. i was not sure if it needs to be included in the patch. let me propose it in the mailing thread and specify it in the kip. i am ok to remove it if others don't think it is necessary.,0,0.9790913462638855
103748701,2476,lindong28,2017-03-01T18:00:59Z,great. thanks for confirmation :),1,0.9950743317604065
103749257,2476,lindong28,2017-03-01T18:03:45Z,i see. i changed this to `kafka_0_11_0_iv0`.,0,0.9917824268341064
103750145,2476,lindong28,2017-03-01T18:08:14Z,"it is actually needed as a way for user thread to get the lock to enqueue requests once sender thread has finished its current `client.poll(...)`. even though it is empty, this synchronzed block is still useful because some other thread may have the lock here. this trick will no longer be needed after kafka-4820 is committed.",0,0.9941680431365967
103751509,2476,lindong28,2017-03-01T18:14:51Z,have we explicitly stated in the code or documentation that this class is internal and should not be used by users? becket is not aware of this as well. it seems that user can already construct scala adminclient directly and that is how i expect this api to be used.,0,0.9813092350959778
103792810,2476,ijuma,2017-03-01T21:25:42Z,"since this is going away, i won't comment further. :)",1,0.9914906620979309
103793255,2476,ijuma,2017-03-01T21:27:59Z,i see. sounds good to ask in the mailing list thread if people think it's useful.,0,0.5214338898658752
103793302,2476,ijuma,2017-03-01T21:28:15Z,"if we keep this class, we need to update the comment.",0,0.9907953143119812
103794835,2476,ijuma,2017-03-01T21:35:34Z,"by the way, i think the code as it is now is a bit dangerous. imagine that there are some changes and this field starts being used in info logging. it's not unlikely that a bug will be introduced. is this optimisation really worth doing?",-1,0.9250872731208801
103795078,2476,ijuma,2017-03-01T21:36:36Z,what is the reason for this change?,0,0.9800325036048889
103795243,2476,ijuma,2017-03-01T21:37:29Z,what is the reason for this change?,0,0.9800325036048889
103796063,2476,ijuma,2017-03-01T21:41:20Z,"the vast majority of kafka code is not public api. the somewhat unintuitive way that public api is defined at the moment is by what has javadoc published: [a link] apart from that, the old producers and consumers are also public api (until we remove them). the admin package is definitely internal and that's why there was no kip for the scala adminclient when it was added in 0.9.0.0 (or any of the changes since).",0,0.9769153594970703
104300596,2476,lindong28,2017-03-05T00:07:59Z,ok. the optimization is removed now.,0,0.9812309145927429
104300644,2476,lindong28,2017-03-05T00:09:59Z,discussed offline. the issue is resolved after we change the definition of lowwatermark to be the minimum logstartoffset of all live replicas.,0,0.9907484650611877
104300648,2476,lindong28,2017-03-05T00:10:22Z,discussed offline. we don't need to checkpoint lowwatermark.,0,0.9778761863708496
104300660,2476,lindong28,2017-03-05T00:11:23Z,i have updated the kip to include this script and email the mailing thread about this addition. there is no objection so far. i assume we can include this script in the patch.,0,0.9141155481338501
104300670,2476,lindong28,2017-03-05T00:12:10Z,the `synchronized` has been removed in the patch after rebasing the patch onto the trunk. kafka-4820 has been committed to the trunk.,0,0.9932835102081299
104300696,2476,lindong28,2017-03-05T00:14:58Z,i see. i think the method is available in two ways. user can use the script without having to deal with breakage later. and user can also uses our internal api and will need to deal with breakage later. linkedin kafka team will use the second solution and is ok to deal with breakage later.,0,0.9032750725746155
104300714,2476,lindong28,2017-03-05T00:16:25Z,"thanks. i have updated the comment to ""a command for purging data of given partitions to the specified offset.""",1,0.9417902827262878
104300777,2476,lindong28,2017-03-05T00:19:27Z,it is a side effect of making change and reverting change in the process of implementing this patch. i have changed it to the original order.,0,0.9771414399147034
104301004,2476,lindong28,2017-03-05T00:38:27Z,i thought `setup()` and `teardown()` will be executed once for every test method (e.g. testconsumeafterpurge) but the initialization of `consumers` in `trait integrationtestharness` will be executed only once per test class (e.g. adminclienttest). i am wrong. i have reverted this change.,-1,0.6417784690856934
104834321,2476,junrao,2017-03-08T02:56:13Z,we probably want to add a comment that this is only used in the fetch requests from the followers.,0,0.9922061562538147
104834398,2476,junrao,2017-03-08T02:57:11Z,could we adjust the comment above accordingly?,0,0.9930053353309631
104834503,2476,junrao,2017-03-08T02:58:43Z,do we need to override this method to public?,0,0.9917764663696289
104834563,2476,junrao,2017-03-08T02:59:22Z,unused import,0,0.9524969458580017
104834590,2476,junrao,2017-03-08T02:59:42Z,"hmm, not sure about this. in general networkclient is not thread safe.",-1,0.7881886959075928
104834673,2476,junrao,2017-03-08T03:00:18Z,it's kind of weird to use a consumernetworkclient to implement purgedatabefore() since this api has nothing to do with consumer.,-1,0.9857425689697266
104834719,2476,junrao,2017-03-08T03:01:01Z,unused import,0,0.9524969458580017
104834774,2476,junrao,2017-03-08T03:01:42Z,%s => %d for oldlowwatermark and newlowwatermark,0,0.9882366061210632
104834848,2476,junrao,2017-03-08T03:02:37Z,"hmm, should we take max here?",0,0.9654216766357422
104834900,2476,junrao,2017-03-08T03:03:15Z,"to be consistent with the logic in recovery, should we initialize this to baseoffset?",0,0.9954032897949219
104834928,2476,junrao,2017-03-08T03:03:39Z,could we add the new param to javadoc above and adjust the comment accordingly?,0,0.9897994995117188
104834990,2476,junrao,2017-03-08T03:04:21Z,d% => %d,0,0.9382853507995605
104835046,2476,junrao,2017-03-08T03:05:03Z,unused import,0,0.9524969458580017
104835080,2476,junrao,2017-03-08T03:05:32Z,hasenough => lowwatermarkreached ?,0,0.9866926074028015
104835108,2476,junrao,2017-03-08T03:06:03Z,could we just reuse logflushoffsetcheckpointintervalmsprop instead of introducing a new config?,0,0.9949486255645752
104835196,2476,junrao,2017-03-08T03:07:03Z,should the comment be changed to all live replicas?,0,0.9933202266693115
104835279,2476,junrao,2017-03-08T03:08:04Z,"do we want to poll with 0 since it can burn cpu unnecessarily? also, instead of duplicating the code for waiting the consumer to be ready, could we factor it out to a private method and reuse?",0,0.9816240668296814
104835345,2476,junrao,2017-03-08T03:08:58Z,is there a need to test async? it seems the sync test is enough?,0,0.9909363389015198
104835380,2476,junrao,2017-03-08T03:09:23Z,"instead of the sleeping for a fixed amount of time, it would be better to do the checking in a waituntiltrue() method.",0,0.9895055890083313
104840525,2476,lindong28,2017-03-08T04:11:36Z,good point. maybe we should specify this in the explanation of the field instead of in the comment? i added following to the field's doc: the field is only used when request is sent by follower. for simplicity i didn't specify that the field will be set to -1 if the request is sent by consumer.,0,0.5888431072235107
104840843,2476,lindong28,2017-03-08T04:16:38Z,ah i should have updated the comment here. it is updated now.,0,0.9787052273750305
104841044,2476,lindong28,2017-03-08T04:19:13Z,my bad. i have changed it back to protected.,-1,0.9900001883506775
104841196,2476,lindong28,2017-03-08T04:21:38Z,thanks. fixed now.,1,0.9247483015060425
104841282,2476,lindong28,2017-03-08T04:22:59Z,yeah `networkclient` is not thread-safe. but `consumernetworkclient` explicitly stated in its java doc that it is thread-safe.,0,0.97890704870224
104841527,2476,lindong28,2017-03-08T04:26:14Z,"i agree this name is a bit weird. maybe we should either rename this class, or implement another `xxxnetworkclient` class to be used for sending requests by java adminclient in the future. as of now i don't have a simple solution for this. i think we can keep it as is and think more thoroughly in the java adminclient. what do you think?",-1,0.9677793383598328
104841631,2476,lindong28,2017-03-08T04:27:50Z,"sorry, i thought checkstyle will catch all unused import but i am wrong. it seems that checkstyle only does this check for java files. will check it manually in the future.",-1,0.9916346073150635
104841846,2476,lindong28,2017-03-08T04:30:57Z,thanks. fixed in both messages.,1,0.9630628824234009
104842139,2476,lindong28,2017-03-08T04:35:40Z,"if we truncate log using `truncatefullyandstartat` to an offset that is higher than the `logstartoffset`, i think we should keep the logstartoffset not changed instead of increasing it, right? it seems similar to the existing logic of updating `recoverypoint`, where we use `math.min`. another argument is that it is safer to assume a small logstartoffset.",0,0.9927819967269897
104842737,2476,lindong28,2017-03-08T04:43:59Z,"i think we still need to set this to -1 initially so that we can call `nextoffsetfromlog()` the first time we access `nextoffset()`. the longer answer: we can set initialize this to `baseoffset` in recovery because we will read all entries in `recovery()`. in the scenario that we do not call `recover()`, we need to initialize `nextoffset` to the `nextoffset` of the latest entry in the log segment file. to trigger this, we need to initialize `nextoffset` to -1 and call `nextoffsetfromlog()` the first time we access `nextoffset()`.",0,0.993316650390625
104847614,2476,lindong28,2017-03-08T05:38:08Z,good point. it is updated now.,1,0.8987495303153992
104847763,2476,lindong28,2017-03-08T05:39:01Z,my bad. thanks for catching this! fixed now.,-1,0.9892261624336243
104847789,2476,lindong28,2017-03-08T05:39:14Z,fixed now.,0,0.9818974137306213
104848112,2476,lindong28,2017-03-08T05:40:57Z,sure. replaced `hasenough` with `lowwatermarkreached`.,0,0.9920216202735901
104849219,2476,lindong28,2017-03-08T05:49:11Z,"i am not sure. it seems safer to have a separate config. the current default value of `logflushoffsetcheckpointintervalms` is 60 seconds. but we probably want logflushstartoffsetcheckpointintervalms to be set to a lower value because if a broker fails after user purge data but before the logstartoffset is checkpointed, the offset may not be preserved. having separate configs allows user to tradeoff between disk write overhead and logstartoffset persistence. also, it is probably cheaper to checkpoint logstartoffset than checkpointing recoveroffset. we only need to checkpoint logstartoffset for a partition if its logstartoffset > baseoffset, which only happens when user has explicitly requested data purge. thus the actually amount of data written to the log-start-offset-checkpoint file is probably much less than the data written to recovery-point-offset-checkpoint. this means that we can set logflushstartoffsetcheckpointintervalms to a lower value without worrying too much about its overhead.",0,0.9803415536880493
104849362,2476,lindong28,2017-03-08T05:50:56Z,thanks! updated now.,1,0.9739542007446289
104849612,2476,lindong28,2017-03-08T05:53:58Z,it seems that we don't have to worry about cpu burn because `testutils.waituntiltrue()` will wait for 100l between calls to `poll(0)`. sure. i updated the patch to move this wait logic into a separate method.,0,0.9864463806152344
104851102,2476,lindong28,2017-03-08T06:09:38Z,it is no longer needed after we add a dedicated thread in adminclient to do `poll()`. removed now.,0,0.9934792518615723
104851560,2476,lindong28,2017-03-08T06:15:06Z,this test with offline brokers is needed when we define lw to min offset of all replicas. but it is not needed anymore after we change it to beh min offset of all live replicas. i simply removed this part.,0,0.9927645325660706
105036939,2476,lindong28,2017-03-08T22:11:18Z,thought about this more. i think we should just set `logstartoffset` to `newoffset`. the reason is that `truncatefullyandstartat(...)` is supposed to create a new log. thus `logstartoffset` should be the same as `baseoffset` of the first segment.,0,0.9938306212425232
105060654,2476,junrao,2017-03-09T00:29:07Z,"ok, we can leave it as it is.",0,0.9875984787940979
105060659,2476,junrao,2017-03-09T00:29:10Z,"yes, that makes sense.",0,0.9692287445068359
105060668,2476,junrao,2017-03-09T00:29:15Z,"yes, that works. it's just that if we initialize to baseoffset (which is what nextoffsetfromlog() will return on an empty segment), _nextoffset is always initialized properly and we probably can get rid of the if test in nextoffset().",0,0.9683929681777954
105067509,2476,lindong28,2017-03-09T01:20:50Z,"i am not sure we can get rid of the if test in `nextoffset()`. suppose we initialize `_nextoffset` to `baseoffset` and the segment is not empty, when should we call `nextoffsetfromlog()` in order to set `_nextoffset` to the correct value? currently we need the if test in `nextoffset()` to call `nextoffsetfromlog()` on the first invocation of `nextoffset()`. did i miss something?",0,0.981530487537384
105333239,2476,junrao,2017-03-10T05:30:29Z,could this be private?,0,0.9903441071510315
105333267,2476,junrao,2017-03-10T05:30:54Z,thanks for the explanation. then this is fine.,1,0.71616131067276
105567622,2476,lindong28,2017-03-12T20:11:43Z,yeah it should be private. i will change it.,0,0.9481198787689209
106523663,2476,becketqin,2017-03-16T20:31:18Z,should this be `leader_not_available` instead?,0,0.9941423535346985
106525699,2476,becketqin,2017-03-16T20:40:21Z,"do we want to wait until the networkthread to exit before closing the `consumernetworkclient`? otherwise there will be some exception thrown and logged, which seems no ideal.",0,0.9368741512298584
106527195,2476,becketqin,2017-03-16T20:47:31Z,can we use a macro instead?,0,0.993514895439148
106549682,2476,becketqin,2017-03-16T22:47:38Z,the terminology lso is also used by kip-98 as last stable offset. just a note so that we do not introduce confustion.,0,0.990068256855011
106550281,2476,becketqin,2017-03-16T22:51:38Z,what is lbo?,0,0.9781264662742615
106550413,2476,becketqin,2017-03-16T22:52:31Z,hw -> lw,0,0.946040153503418
106550867,2476,becketqin,2017-03-16T22:55:53Z,would it be safer to set the initial value to -1l if it is only kept on the leader?,0,0.9947595000267029
106551121,2476,becketqin,2017-03-16T22:57:58Z,nit: we usually do not use the `_*` pattern in apache kafka.,0,0.9935293793678284
106551960,2476,becketqin,2017-03-16T23:03:44Z,attempt => attempting,0,0.8284775018692017
106560377,2476,becketqin,2017-03-17T00:09:41Z,shouldn't this be -1l?,0,0.9898680448532104
106568532,2476,becketqin,2017-03-17T01:29:44Z,we can probably make those methods protected.,0,0.9885817170143127
106569363,2476,becketqin,2017-03-17T01:40:25Z,this number seems a little too large for deleterecordsrequest.,0,0.5326101779937744
106571166,2476,becketqin,2017-03-17T02:03:40Z,this could be [code block],0,0.9919331669807434
106586044,2476,lindong28,2017-03-17T05:24:34Z,thanks. good catch. fixed now.,1,0.994573175907135
106587187,2476,lindong28,2017-03-17T05:40:53Z,"are you suggesting to wait for networkthread to exit before or after calling `client.close()`? if we call `client.close()` first, we can not prevent error from being logged because `selector.close()` will log error. if we wait for networkthread to exit first, then close() may become a blocking call which seems unnecessary. i agree with you that we do not want to throw exception here. but i am not sure why we should not log any error here. for example, `selector.close()` may log error if there is `ioexception`. i have updated the code to catch exception. does this address the problem?",0,0.976337194442749
106587383,2476,lindong28,2017-03-17T05:43:42Z,sure. fixed now.,0,0.9868775010108948
106587470,2476,lindong28,2017-03-17T05:45:01Z,sure. replaced `lso` with `logstartoffset`.,0,0.9928609728813171
106587521,2476,lindong28,2017-03-17T05:45:44Z,good catch. thanks. it means logbeginoffset. replaced it with logstartoffset.,1,0.9936830997467041
106587539,2476,lindong28,2017-03-17T05:46:07Z,thanks. fixed now.,1,0.9247483015060425
106587752,2476,lindong28,2017-03-17T05:49:36Z,"i used `_*` here because we have methods `lastcaughtuptimems`, `logstartoffset` and `lowwatermark`. what would you suggest to name these variables?",0,0.9952221512794495
106587831,2476,lindong28,2017-03-17T05:50:30Z,sure. changed it to -1l.,0,0.9833321571350098
106587893,2476,lindong28,2017-03-17T05:51:13Z,fixed now.,0,0.9818974137306213
106587916,2476,lindong28,2017-03-17T05:51:32Z,good catch. fixed now.,1,0.966352105140686
106588046,2476,lindong28,2017-03-17T05:53:18Z,good point. i changed it to 1.,1,0.9718286395072937
106588193,2476,lindong28,2017-03-17T05:55:28Z,cool. fixed now.,1,0.9740698933601379
106767687,2476,becketqin,2017-03-18T00:47:23Z,"it seems that if any exception is thrown from the network thread, the futures that have been returned will not be completed forever. ideally we will want to have those futures get an exception so that users do not wait on that indefinitely.",0,0.9619191288948059
106770832,2476,lindong28,2017-03-18T02:29:49Z,thanks for your review! i have fixed it in the last commit.,1,0.9855079054832458
106821825,2476,junrao,2017-03-19T23:00:48Z,should we update upgrade.html?,0,0.9936009049415588
106821828,2476,junrao,2017-03-19T23:00:59Z,should we rename offset to sth like fetchoffset so that it's clear how it's different from logstartoffset?,0,0.99332594871521
106821831,2476,junrao,2017-03-19T23:01:08Z,should we follow the convention by nesting partitions inside topics?,0,0.9935706853866577
106821839,2476,junrao,2017-03-19T23:01:25Z,"so, we are not calling maybeincrementleaderlw() when the old segments are deleted? this means that lw may not be accurate when there is only 1 replica?",0,0.9949530363082886
106821844,2476,junrao,2017-03-19T23:01:34Z,"hmm, it seems that we should be using the logstartoffset from the follower, not from the leader?",0,0.985162079334259
106821857,2476,junrao,2017-03-19T23:01:55Z,"if we modify the log, we should probably coordinate this with the log cleaner. in logmanager.truncateto(), we first abort the ongoing cleaning, then truncate and finally resume the cleaning. we probably should do the same here.",0,0.9945928454399109
106821867,2476,junrao,2017-03-19T23:02:15Z,should we adjust the comment above accordingly?,0,0.9936350584030151
106821871,2476,junrao,2017-03-19T23:02:27Z,"hmm, the change doesn't seem right. the first value should be startoffset and the second value should be logstartoffset?",0,0.8300052285194397
106821879,2476,junrao,2017-03-19T23:02:53Z,"is this comment still correct? i thought we check the delete offset is smaller than hw, which is less than log end offset?",0,0.9928135275840759
106821907,2476,junrao,2017-03-19T23:03:49Z,"is it important to track this metric, especially at partition level, given deleterecords is a rare operation?",0,0.9907997250556946
106821909,2476,junrao,2017-03-19T23:04:03Z,"hmm, could timestampoffset.offset be < localreplica.logstartoffset? it seems that the result returned from fetchoffsetfortimestamp() guarantees that timestampoffset.offset >= localreplica.logstartoffset?",0,0.9925665855407715
106821916,2476,junrao,2017-03-19T23:04:13Z,this is not a produce response.,0,0.9779687523841858
106821917,2476,junrao,2017-03-19T23:04:19Z,do we need this to be 10000? could we make it 60000?,0,0.9920879006385803
106821918,2476,junrao,2017-03-19T23:04:23Z,log begin offset => log start offset?,0,0.9944398403167725
106821926,2476,junrao,2017-03-19T23:04:40Z,"it seems that logstartoffset is only needed in replicafetcherthread. instead of adding it in partitionfetchstate, perhaps it's simpler to just add it here by calling getlogstartoffset()?",0,0.9953222870826721
106821934,2476,junrao,2017-03-19T23:04:54Z,"if we do this, perhaps there is no need to pass in metadatacache through methods like becomeleaderorfollower() and maybeupdatemetadatacache()?",0,0.9946900606155396
106837370,2476,lindong28,2017-03-20T05:48:26Z,i am not sure we have that convention. this is the same pattern used by `reassignpartitionscommand`. i can change it if you think the other pattern is better.,0,0.9549121260643005
106837391,2476,lindong28,2017-03-20T05:49:00Z,i didn't change it in order to reduce the amount of code change and conflicts with other patches. i will change it as you suggested.,0,0.9862343072891235
106838059,2476,lindong28,2017-03-20T06:03:20Z,"it seems ok because when there is no follower, lw is only used in the `purgeresponse` to tell user whether purge has finished. in this case the `purgerequest` would have triggered `maybeincrementleaderlw`.",0,0.9935963153839111
106838930,2476,lindong28,2017-03-20T06:20:34Z,good point. i have updated code so that `deletelogstartoffsetbreachedsegments` is called periodically by `logmanager` for non-compact topics and by `logcleaner` compact topics. `deleterecordsrequest` only needs to update `logstartoffset` of the `replica`.,1,0.6369082927703857
106839374,2476,lindong28,2017-03-20T06:27:55Z,sure. i updated the comment to say `return error on attempt to read beyond the log end offset or read below log start offset`. is this ok?,0,0.9924387335777283
106840055,2476,lindong28,2017-03-20T06:40:15Z,you are right. it is wrong after we add that check. i have removed this comment.,0,0.6741635799407959
106840295,2476,lindong28,2017-03-20T06:44:02Z,it is not important. i added it because we have similar per-partition metrics in `delayedproduce`. i realized that we don't per-partition metrics in `delayedfetch`. it is removed now.,0,0.9911812543869019
106840866,2476,lindong28,2017-03-20T06:52:31Z,good point. it is removed now.,1,0.8783869743347168
106840929,2476,lindong28,2017-03-20T06:53:38Z,my bad. i have corrected this comment now.,-1,0.9895855784416199
106841258,2476,lindong28,2017-03-20T06:59:03Z,"i like this to be smaller to reduce the chance that a logstartoffset updated by deleterecordsrequest is lost. this is useful e.g. if there is only one replica and the broker may crash. anyway, i will change it to 60 sec.",0,0.9686293601989746
106841300,2476,lindong28,2017-03-20T06:59:37Z,sure. fixed now.,0,0.9868775010108948
106843753,2476,lindong28,2017-03-20T07:28:19Z,oops... good point! thanks! i fixed the bug by passing `followerlogstartoffset` to `updatelogreadresult` via `logreadresult`.,1,0.9952422380447388
106843969,2476,lindong28,2017-03-20T07:30:10Z,i think the original error message is probably wrong. why the range of log segments depend on an offset provided by the user?,0,0.890674352645874
106844614,2476,lindong28,2017-03-20T07:37:08Z,`logstartoffset` is also needed in `replicamanager.readfromlocallog`. it seems reasonable to include it in the `fetchrequest.partitiondata` since `fetchrequest.partitiondata` is supposed to contain the same fields of `protocol.fetch_request_partition_v1`. does this make sense?,0,0.9950030446052551
106844878,2476,lindong28,2017-03-20T07:40:41Z,"sure. i have updated the code to remove `metadatacache` from parameters of methods `becomeleaderorfollower`, `maybeupdatemetadatacache` and `makefollowers`.",0,0.9950205087661743
106845566,2476,lindong28,2017-03-20T07:50:07Z,hmm.. i wasn't aware i need to change upgrade.html. i will do it tomorrow.,0,0.746290385723114
106956008,2476,lindong28,2017-03-20T16:58:20Z,"sorry, i missed the first `%d` in the message. i have corrected this now.",-1,0.9903826117515564
107039812,2476,junrao,2017-03-20T23:13:42Z,"ok, we can leave this as it is since the /admin/reassign_partitions path in zk already follows the same pattern.",0,0.9924207329750061
107039880,2476,junrao,2017-03-20T23:14:13Z,"if lw is only used for deleterecordresponse, do we need to store and maintain it in replica? could we just compute it on the fly when serving deleterecordrequests?",0,0.9952561259269714
107039905,2476,junrao,2017-03-20T23:14:24Z,"so, deleterecordsrequest can't be applied on a compacted topic? should we return an error code in the response in that case?",0,0.9924943447113037
107039943,2476,junrao,2017-03-20T23:14:38Z,i meant is there a need to include logstartoffset in partitionfetchstate in abstractfetcherthread.scala? it seems that only replicafetcherthread needs it.,0,0.993412435054779
107049639,2476,lindong28,2017-03-21T00:29:02Z,ah i see your point now. you are right that we don't have to include it in `abstractfetcherthread`. i have removed it from `partitionfetchstate` in `abstractfetcherthread` and the code change in `consumerfetcherthread` and `abstractfetcherthread` is much smaller now. thanks!,1,0.9948412775993347
107052078,2476,lindong28,2017-03-21T00:51:33Z,"yes we can compute it on the fly when we need it in e.g. in `delayeddeleterecords`. is there reason to do it on the fly instead of maintaining it in the `replica`? is it because you think the patch would be simpler if we compute it on the fly? i think both solution has the same performance. but maintaining it in replica in the same way as `hw` may make lw easier to reason about and extend in the future. for example, the code is easier to extend if we want to use `lw` in the future as a way to determine the minimum offset available for consumption (currently the minimum offset available for consumption varies between replicas because different replicas may have different logstartoffset).",0,0.9818485975265503
107052828,2476,lindong28,2017-03-21T00:58:38Z,"btw, the reason `maybeincrementleaderlw()` is not called when the old segments are deleted is that the concept of `lw` and partition is at a higher level than `logmanager`, `logcleaner` and `log`. ideally those classes such as `logmanager` do not contain reference to the higher level class such as `partition`.",0,0.9955636262893677
107058922,2476,lindong28,2017-03-21T02:04:36Z,i have updated `upgrade.html` to change latest version from 0.10.3.0 to 0.11.0 and specify change in the fetchrequet and fetchresponse.,0,0.9942159056663513
107195440,2476,junrao,2017-03-21T15:56:32Z,"my concern is that if we store it, but don't make it accurate, then someone may start using it in the future without realizing that it's only accurate at deleterecordrequest time. so, it's better to either store it and make it accurate, or not store it and always compute it accurately when needed.",0,0.9834558367729187
107281864,2476,lindong28,2017-03-21T21:35:35Z,"i see. i just updated the patch to store `lowwatermark` in `partition` instead of `replica` and always call `maybeincrementleaderlw()` when we retrieve `lowwatermark`. i still maintain lowwatermark as state so that we only need to call `trycompletedelayedrequests` if lowwatermark has increased. other than that, the `lowwatermark` is essentially computed on the fly developer access it through `partition.updateandgetlowwatermarkiflocal()`. i added a comment that says: `lowwatermark should always be accessed through updateandgetlowwatermarkiflocal() because we may not update lowwatermark when log segment is deleted`.",0,0.9900362491607666
107512572,2476,lindong28,2017-03-22T19:42:46Z,i will add back this javascript template in the next commit. guozhang just told me that we are expected to have a local webserver in order to read this upgrade.html.,0,0.9823367595672607
107589219,2476,junrao,2017-03-23T05:10:16Z,"it still seems that it's a bit weird to maintain lowwatermarkiflocal just to see if the value has changed. another way to do that is in partition.updatereplicalogreadresult(), we compute lw before and after calling replica.updatelogreadresult. then, we will know if lw has changed. we can further optimize it by only computing the lw if the deleterecordpurgatory is not empty.",-1,0.7423901557922363
107589225,2476,junrao,2017-03-23T05:10:22Z,we are resetting log-start-offset to the base offset of first segment?,0,0.9943384528160095
107589236,2476,junrao,2017-03-23T05:10:29Z,"this logic seems a bit dangerous. there is no synchronization between nextoffset() and the updating of nextoffset in append(). so they can step on each other. since the deleting record logic never deletes the active segment, it seems that we could just use the base offset of the next segment as the next offset of the current segment. then we don't need to maintain nextoffset per segment?",-1,0.7822418212890625
107589241,2476,junrao,2017-03-23T05:10:34Z,"i had a comment on this earlier. if deleterecords() can't be applied on a compacted topic, should we send some error code in the response?",0,0.9932397603988647
107748044,2476,lindong28,2017-03-23T18:26:29Z,that is a good idea. i have updated the patch to avoid maintaining lowwatermark as state of partition and compute it only on the fly. and `updatereplicalogreadresult` would only compute lw if deleterecordpurgatory is not empty.,1,0.908864438533783
107750331,2476,lindong28,2017-03-23T18:35:39Z,"this is kind of similar to what we do with recoverypoints if its checkpoint file is unreadable. for example, if recoverypoints checkpoint file is unreadable but `.kafka_cleanshutdown` file exists, we will reset recoverypoint to `activesegment.nextoffset` after warning `resetting the recovery checkpoint to 0`. here we assume the log-start-offset in the checkpoint file is 0 if checkpoint file is not readable. on a second thought, i agree it is confusing because we will always set `logstartoffset` to at least base offset of the first second if its checkpoint file is unreadable. i will remove this statement.",0,0.9416422843933105
107752878,2476,lindong28,2017-03-23T18:45:42Z,"my apology, i missed your comment here. `deleterecordsrrequest` can actually be applied on a compacted topic. `deleterecordsrrequest` will increase the logstartoffset. when `logcleaner` calls `log.deleteoldsegments()`, those log segments which breach the logstartoffset will be deleted.",-1,0.7907911539077759
107753068,2476,lindong28,2017-03-23T18:46:29Z,"sorry, i missed your comment there previously. my bad. deleterecordsrrequest can actually be applied on a compacted topic. deleterecordsrrequest will increase the logstartoffset. when logcleaner calls log.deleteoldsegments(), those log segments which breach the logstartoffset will be deleted. thus we don't need to send error code in response.",-1,0.9897214770317078
107779887,2476,junrao,2017-03-23T20:48:59Z,"hmm, in logcleaner, we have the following code. only logs configured as compacted and deleted are deletable and will call deleteoldsegments(). [code block]",0,0.9904195666313171
107785265,2476,lindong28,2017-03-23T21:12:04Z,"after kip-71 is committed, log compaction and deletion can co-exist. strictly speaking deleterecordsrequest can be applied on a compacted topic: if a topic is compacted and deletable, its log segment can be deleted by logcleaner; if a topic is non-compacted and deletable, its log segment can be deleted by the `logmanager.cleanuplogs()` which runs periodically. are you suggesting that deleterecordsresponse should provide error immediately if the topic is not deletable? this is certainly a good point. i missed this part previously. i will update the patch to do it. thanks!",0,0.8389540314674377
107806053,2476,lindong28,2017-03-23T23:16:43Z,"i get your concern. i am not sure we could just use the base offset of the next segment, because `nextoffset()` is a method that exists prior to this kip and is actually used by `log` to initialized `nextoffsetmetadata` (i.e. `nextoffsetmetadata = new logoffsetmetadata(activesegment.nextoffset(), activesegment.baseoffset, activesegment.size.toint)`). thus we actually need `nextoffset` of the active log segment. i have updated the patch so that `nextoffset()` is a read-only operation and only returns the cached next offset. and i make sure that for non-empty segment that is read from disk, we will always call `updatenextoffsetfromlog()` before the first call to its `nextoffset()`. i think it should resolve the problem.",0,0.9785013794898987
107819630,2476,junrao,2017-03-24T01:24:55Z,"before this patch, we have nextoffset(), which computes the next offset by scanning the last portion of the log. this could be expensive, but is only used during the initial log loading. i was suggesting that we could just keep the logic as it is. in deletelogstartoffsetbreachedsegments(), we always use the baseoffset of the next segment to check if a segment should be deleted. if a segment doesn't have the next segment, we know it's the active segment and won't be deleted. this way, we never need to call nextoffset() in deletelogstartoffsetbreachedsegments().",0,0.9882602691650391
107820483,2476,lindong28,2017-03-24T01:35:40Z,"thanks for the quick comment . yes it is possible to do that, i.e. we keep the previous expensive implementation of `nextoffset()` which scans the last portion of the log, and implement `deletelogstartoffsetbreachedsegments()` in such a way that the deletion of a segment depends on the baseoffset of the next segment. i am just not very sure about advantage of that approach as compared to the approach in the current patch. in comparison, that approach keeps nextoffset() expensive, and requires more complex implementation of `deletelogstartoffsetbreachedsegments()` because it can no longer re-use `deleteoldsegments(predicate)` to delete partition. the benefit of the approach is that we don't need to maintain `nextoffset` as state in `logsegment`. i am ok with the suggested approach. let me do that then.",1,0.9569610953330994
107825145,2476,lindong28,2017-03-24T02:34:51Z,"after thinking about this more, i agree that it is safer to keep less state in the class unless `nextoffset()` is called frequently. thus i agree the suggested approach is simpler. thanks .",1,0.9807311296463013
108008403,2476,junrao,2017-03-24T22:07:24Z,we could use mapvalues() here?,0,0.9940053820610046
108008598,2476,junrao,2017-03-24T22:09:03Z,"thinking a bit more. it seems that a delayeddeleterecord could be added right after the if check. in the next updatereplicalogreadresult() call, lw may not advance any more. then the response will be delayed. perhaps, if (replicamanager.delayeddeleterecordspurgatory.delayed() > 0) , we could just always call trycompletedelayedrequests()?",0,0.99118971824646
108008646,2476,junrao,2017-03-24T22:09:26Z,this is not very accurate. lw will increase with deleterecordsrequest or log deletion?,0,0.8891650438308716
108008660,2476,junrao,2017-03-24T22:09:33Z,should we initialize this to an unknownoffset?,0,0.9898138642311096
108009638,2476,lindong28,2017-03-24T22:18:10Z,"no we can not use `mapvalues()`. this is because `mapvalues()` returns a view and any write operation on that view will be ignored later, e.g. `status.ackspending = true` in `delayeddeleterecords`.",0,0.9940800070762634
108010888,2476,lindong28,2017-03-24T22:23:08Z,"yes i think it is correct. for example, if there is only one replica, deleterecordsrequest or log retention will immediately increase lw.",0,0.9820433259010315
108011703,2476,lindong28,2017-03-24T22:28:46Z,there is no existing variable named unknownoffset. there is `logoffsetmetadata.unknownsegbaseoffset` but i am not sure we should use unknownsegbaseoffset for logstartoffset. so i created `log.unknownlogstartoffset = -1l`. does address the problem?,0,0.9875762462615967
108012358,2476,lindong28,2017-03-24T22:34:33Z,"if there is only one live replica for this partition, then lw will increase immediately to the specified offset and the response can be sent to the client. otherwise, say there is at least one live follower for this partition, lw will not increase now. lw will increase in the next updatereplicalogreadresult() call, and the response can be sent back then. does this work?",0,0.9880892634391785
108092052,2476,junrao,2017-03-27T05:16:52Z,"to follow the convention in fetch_response, should this be named fetch_request_partition_v5?",0,0.9955507516860962
108092057,2476,junrao,2017-03-27T05:17:01Z,could you include the changes from kip-98 too?,0,0.995410144329071
108266895,2476,junrao,2017-03-27T20:08:06Z,"we don't read the logstartoffset from the checkpoint in this case, which is a bit inconsistent with how we load the log when the broker starts up. this seems ok for now since in the rare case when a follower loses the whole log (but still has the logstartoffset checkpoint), it can discover the logstartoffset from the leader quickly. not sure if we want to add a comment on this.",0,0.957738995552063
108287834,2476,lindong28,2017-03-27T21:44:53Z,"i am not sure i understand the problem of inconsistency here. i think this `createlog()` will only be called when the replica doesn't exist on the broker, which means the broker should not have logstartoffset for this replica, right? are you considering the scenario that the replica is deleted (either through stopreplicarequet or manually deleted via `rm -rf`) but the logstartoffset is still there? in that case i think we should actually ignore the outdated logstartoffset in the checkpoint file and read the value from leader. because logstartoffset can be considered as logically deleted if log file is deleted. does this make sense?",0,0.971433699131012
108288220,2476,lindong28,2017-03-27T21:46:54Z,"i think it may be better for owners of kip-98 to add this in the upgrade note (e.g. in kafka-4816) because they know much more about the change in kip-98 than i do.. anyway, i can go over the kip-98 doc and add things that i think necessary.",0,0.975346028804779
108291575,2476,ijuma,2017-03-27T22:02:38Z,", feel free to leave out the kip-98 change for now. i am about to file a jira for updating the upgrade notes for kip-98. this is not the only one.",0,0.9815296530723572
108301862,2476,lindong28,2017-03-27T23:07:34Z,thanks . then i won't include this in the patch.,1,0.8666755557060242
108301889,2476,lindong28,2017-03-27T23:07:45Z,sure. i will change it to be fetch_request_partition_v5.,0,0.9914388656616211
108305808,2476,lindong28,2017-03-27T23:38:42Z,"as of now, the base offset of the first segment of a compacted topic can be always 0. thus it seems ok to have its logstartoffset as 0. we can consider logstartoffset as the lower bound of the offset of the first message in the partition, but not necessarily the strict lower bound. i couldn't find any use-case that would be broken due to this definition.",0,0.9905470013618469
108326834,2476,becketqin,2017-03-28T03:17:00Z,"can we be more clear on this field. in the `fetchresponse` we have log_start_offset which have almost the same comment. maybe here we can say ""the smallest available offset across all live replicas.""",0,0.9923882484436035
108326881,2476,becketqin,2017-03-28T03:17:44Z,for the given topic => for the given partition.,0,0.9881414175033569
108329771,2476,junrao,2017-03-28T03:54:50Z,"i don't think it breaks anything. so, we can leave this as it is.",0,0.9526201486587524
108333754,2476,becketqin,2017-03-28T04:49:22Z,"there seems a very rare case that may result in message loss. assuming there is only one replica, consider the following sequence: 1. user deletes a topic, we are not deleting the log starting offset from the checkpoint file. 2. if the topic is created again with the same name and the partitions happen to be on the same broker. 3. user produced some messages and before the log starting offset is checkpointed, the broker went down. 4. now when the broker restarts, the old checkpointed log starting offset may be applied to the newly created topic, which may cause the messages that have been produced into the log to be unavailable to the users. this is a very rare corner case, though.",0,0.9789319634437561
108335119,2476,lindong28,2017-03-28T05:07:41Z,sure. updated now.,0,0.9880403876304626
108335175,2476,lindong28,2017-03-28T05:08:03Z,good catch. fixed now.,1,0.966352105140686
108335392,2476,lindong28,2017-03-28T05:10:53Z,good point. i fixed the problem by always do `checkpointlogstartoffsetsindir(removedlog.dir.getparentfile)` when a partition is deleted. the overhead will probably be smaller than checkpointing the cleaner offset which we already do everytime we delete a partition.,0,0.5492085218429565
103840661,2614,junrao,2017-03-02T02:42:05Z,"we may add new compression codec in the future. using the bits from 15 downwards makes adding new compression codec a bit easier in the future. also, unused should be 5-15.",0,0.9933313727378845
103840673,2614,junrao,2017-03-02T02:42:15Z,"in the comment above the class and in the kip wiki, lastoffsetdelta is after attributes.",0,0.9933217167854309
103840681,2614,junrao,2017-03-02T02:42:21Z,the comment is no longer valid?,0,0.9754727482795715
103840693,2614,junrao,2017-03-02T02:42:29Z,"hmm, should we be passing in delta timestamp?",0,0.985906720161438
103840712,2614,junrao,2017-03-02T02:42:36Z,the comment seems outdated. attributes are no longer used to indicate the presence of key and value.,0,0.9664502143859863
103840724,2614,junrao,2017-03-02T02:42:43Z,"could we spell out how this is calculated? also, does it include the length field?",0,0.9936683773994446
103840746,2614,junrao,2017-03-02T02:42:57Z,"if key is null, should we return -1, which is the current convention?. ditto for valuesize().",0,0.968978762626648
103840757,2614,junrao,2017-03-02T02:43:04Z,"we compute crc from timestamp, instead of attributes.",0,0.9919667840003967
103840767,2614,junrao,2017-03-02T02:43:09Z,timestamp => timestampdelta? ditto in sizeinbytes() and sizeofbodyinbytes().,0,0.9911625385284424
103840780,2614,junrao,2017-03-02T02:43:15Z,probably non-idempotent/non-transactional to make it clear?,0,0.9815511703491211
103840821,2614,junrao,2017-03-02T02:43:40Z,"for up-converted message, timestamp will be -1. but shouldn't timestamptype be the timestamptype of the topic?",0,0.9907490611076355
103840897,2614,junrao,2017-03-02T02:44:17Z,"the comment above suggests that lastoffset() is the same as nextoffset(), which seems inaccurate.",0,0.9470009207725525
103840910,2614,junrao,2017-03-02T02:44:25Z,shouldn't we return -1 if there is no key? ditto for valuesize().,0,0.985255241394043
103840930,2614,junrao,2017-03-02T02:44:37Z,should that be hasvalue() to be consistent with haskey()?,0,0.9943490624427795
103840934,2614,junrao,2017-03-02T02:44:42Z,should this be fixed?,0,0.990869402885437
103840949,2614,junrao,2017-03-02T02:44:51Z,should we return 0 or logentry.no_sequence?,0,0.9924730062484741
103840960,2614,junrao,2017-03-02T02:45:00Z,probably mention the magic in the error message.,0,0.9829848408699036
103840968,2614,junrao,2017-03-02T02:45:05Z,bytebufferlogentry => bytebufferoldlogentry ?,0,0.9927076697349548
103840980,2614,junrao,2017-03-02T02:45:10Z,integer => long? ditto in a few other places.,0,0.9775469303131104
103840998,2614,junrao,2017-03-02T02:45:19Z,it's a bit weird to assign lastoffset to firstoffset with old magic. perhaps adding a comment to explain why?,-1,0.9805343747138977
104274159,2614,ijuma,2017-03-04T01:44:08Z,"i think we should introduce a `byteutils` class and move all the relevant methods there. maybe we could do that in its own pr, which could be merged quickly independently of the message format changes?",0,0.9940164089202881
104276385,2614,hachikuji,2017-03-04T02:40:23Z,works for me.,0,0.9761236906051636
104345921,2614,junrao,2017-03-06T05:29:26Z,1 => logentry.magic_value_v1? ditto in line 84 below.,0,0.9948417544364929
104345937,2614,junrao,2017-03-06T05:29:39Z,"so, the old consumer won't work on the eos message format? if so, should we pin the fetchrequest version in consumerfetcherthread to an older version?",0,0.9920847415924072
104345956,2614,junrao,2017-03-06T05:30:02Z,"since maxmessagesize now applies to record set, it would be useful to change the description in kafkaconfig and describe that change in the upgrade section of the documentation.",0,0.993726372718811
104345961,2614,junrao,2017-03-06T05:30:07Z,entry probably should now be named logrecord?,0,0.9948229789733887
104345969,2614,junrao,2017-03-06T05:30:18Z,"in validatemessagesandassignoffsets(), should we further validate that there is only 1 log entry in records in eos format?",0,0.9947795867919922
104345976,2614,junrao,2017-03-06T05:30:26Z,does this need to be fixed? could we reuse abstractrecords.estimatesizeinbytes() for estimating the size for all magic?,0,0.9931809306144714
104495063,2614,junrao,2017-03-06T19:07:12Z,"hmm, this adds some complexity and i am not sure about the benefit. first, when sending the first few batches of the data in the producer or when the leaders are not on all brokers, we don't have a connection to all brokers. so the minusedmagic may not be very accurate. could we just rely on the down conversion logic on the broker side and make it clearer in the documentation that eos feature should be turned on only when the whole cluster has been upgraded?",-1,0.689384400844574
104495083,2614,junrao,2017-03-06T19:07:17Z,does this array need to be nullable?,0,0.9927483201026917
104495161,2614,junrao,2017-03-06T19:07:35Z,"could you add some comment on what needs to be done if we change the version of the key in the future? for example, do we have to explicitly delete keys on the old version since it won't be compacted out by the new version of the key?",0,0.993198573589325
104495190,2614,junrao,2017-03-06T19:07:44Z,should we support the write method here?,0,0.9936781525611877
104495211,2614,junrao,2017-03-06T19:07:49Z,the reference bytebufferloginputstream.bytebufferlogentry in the comment above is no longer valid.,0,0.9894611239433289
104495248,2614,junrao,2017-03-06T19:07:55Z,should we include laststableoffset?,0,0.9924547672271729
104495273,2614,junrao,2017-03-06T19:08:01Z,the error message seems to be the opposite.,0,0.8887409567832947
104495288,2614,junrao,2017-03-06T19:08:05Z,is the todo still valid?,0,0.9898854494094849
104495343,2614,junrao,2017-03-06T19:08:20Z,should timestamptype be hardcoded to createtime or should it use the topic level config? ditto for line 256 below.,0,0.9927593469619751
104495356,2614,junrao,2017-03-06T19:08:25Z,is 1024 guaranteed to be always large enough?,0,0.9893223643302917
104495396,2614,junrao,2017-03-06T19:08:38Z,"should we print out additional information related to eos format (e.g. pid, epoch, sequence) etc? should we support printing out the control message?",0,0.9946467280387878
104495429,2614,junrao,2017-03-06T19:08:44Z,"now that we have increased the param limit in checkstyle, do we still need this?",0,0.9945979118347168
105383915,2614,ijuma,2017-03-10T12:01:24Z,we should add a note that this is an internal class since the package doesn't make that obvious.,0,0.9801656007766724
105384533,2614,ijuma,2017-03-10T12:06:49Z,"nit: `maxusablemagic = math.min(usablemagic, maxusablemagic)`?",0,0.9934805631637573
105385120,2614,ijuma,2017-03-10T12:11:24Z,"i think this `switch` should be a separate method as it's the interesting logic that may need to be updated when we add more produce versions. maybe it should live in `producerequest`? and we should have a test that breaks when we add a new produce version to the protocol (if we don't already) so that we don't forget to update it (since the client would still work fine, it could go unnoticed).",0,0.9934908151626587
105386294,2614,ijuma,2017-03-10T12:20:42Z,"hmm, would it be better to have a `nodeapiversions.usableversion` that takes a `desiredversion` as well? we could the collapse these two branches and there would be no need to call `ensureusable`.",0,0.9928728342056274
105386464,2614,ijuma,2017-03-10T12:21:54Z,"it's an existing issue, but realised that this comment is out of date.",0,0.8055397868156433
105387601,2614,ijuma,2017-03-10T12:30:43Z,"can we just simply call `get` on the map? also, maybe we should return `null` if there's no element (like `map.get`).",0,0.9941956400871277
105388069,2614,ijuma,2017-03-10T12:34:39Z,maybe we could move the logic that creates the appropriate `usableversion` into a static factory method (or constructor) in `usableversion`.,0,0.994411289691925
105390691,2614,ijuma,2017-03-10T12:54:19Z,"i found the term `default` a bit confusing here. this is `usableversion`, right? i guess you were trying to avoid repeating it since the class name is `usableversion`. could we just call it `value`?",-1,0.6322898268699646
105390911,2614,ijuma,2017-03-10T12:55:59Z,"i think the field name should just be `apiversion`, no?",0,0.9917646050453186
105391297,2614,ijuma,2017-03-10T12:58:39Z,"this should be ""0.11.0-iv0"" and the rest should be updated accordingly.",0,0.9939942955970764
105392682,2614,ijuma,2017-03-10T13:08:27Z,"`create_time` is correct, see [a link]",0,0.9882082343101501
105394318,2614,ijuma,2017-03-10T13:19:26Z,"it makes sense to leave space for the compression type, but i'd hope we won't need more than 3 bits for it.",0,0.9689683318138123
105394549,2614,ijuma,2017-03-10T13:20:53Z,"would `basicrecord` or `simplerecord` be a better name? i think the key feature is that it just captures the essence of what a record is: timestamp, key, value (and potentially headers in the future?).",0,0.9931398034095764
105497417,2614,hachikuji,2017-03-10T21:55:38Z,"my guess is we'll have another message format bump before we run out of room for compression codecs, but i don't mind adding another bit if you think it's useful.",0,0.8700956702232361
105498031,2614,hachikuji,2017-03-10T21:58:44Z,"oh, i may have misunderstood. are you suggesting moving the transactional flag and timestamp type to the end of the second byte?",0,0.5920416116714478
105515378,2614,hachikuji,2017-03-11T00:20:03Z,"i do this validation inside `producerequest`. if there is more than one entry, we will raise `invalidrecordexception` before the request reaches `logvalidator`.",0,0.9919716119766235
105516191,2614,hachikuji,2017-03-11T00:29:01Z,"yes, i think we can.",0,0.9464551210403442
105516431,2614,hachikuji,2017-03-11T00:31:41Z,"if fetching in `read_uncommitted`, we do not compute the aborted transaction list. i thought `null` would be a good way to communicate this instead of an empty array, which would be ambiguous (are there no aborted transactions or did we just not compute them?).",0,0.9921897053718567
105516776,2614,hachikuji,2017-03-11T00:35:28Z,"discussed offline, but for posterity, down-conversion on the broker only helps when the broker supports the new produce request version. however, the client also needs to support older versions of the produce request, which must use older versions of the message format. the difficulty is that there is a delay between the time that the producer starts building the batch and the time that we send the request, and we may have chosen the message format based on out-dated metadata. in the worst case, we optimistically chose to use the new message format, but found that the broker didn't support it, so we need to down-convert on the client before sending.",0,0.965853214263916
105698631,2614,hachikuji,2017-03-13T16:02:00Z,"yeah, let's do this for now. we can add support in a follow-up if desired.",0,0.9854755997657776
105722433,2614,hachikuji,2017-03-13T17:33:41Z,i guess the todo should really go to the other constructor.,0,0.9730501770973206
105724542,2614,hachikuji,2017-03-13T17:42:04Z,we'd need to increase a bit more to capture this one too. increasing to 12 dropped two others.,0,0.9745838642120361
105732368,2614,hachikuji,2017-03-13T18:11:01Z,i assume you are asking whether we can support this method directly using the `filechannel`? i have implemented this in the latest commit.,0,0.9903762936592102
105733027,2614,hachikuji,2017-03-13T18:13:44Z,"yeah, that's fair. let me see if we can move it to `producerequest`.",0,0.8222547769546509
105746262,2614,hachikuji,2017-03-13T19:09:50Z,"yes, that sounds good.",1,0.6914747953414917
105767662,2614,junrao,2017-03-13T20:48:30Z,"since we already have 3 bits for compression, so leaving this as it is will be fine.",0,0.9833606481552124
105767710,2614,junrao,2017-03-13T20:48:40Z,"i was trying to say it seems that we (should) never do writes through fileloginputstream? if so, perhaps the implementation can just throw unsupportedexception?",0,0.9785336852073669
105770550,2614,hachikuji,2017-03-13T21:01:32Z,i guess the name is a little misleading. we're really reading here into the provided buffer. maybe the name should be `readinto`?,0,0.5649252533912659
105985925,2614,junrao,2017-03-14T18:09:16Z,"since we are including the exact key/value length, perhaps we should exclude the max key/value length in max_record_overhead?",0,0.9948594570159912
105985975,2614,junrao,2017-03-14T18:09:30Z,"perhaps name this to producerepoch to distinguish it from the partitionleaderepoch? if so, probably rename the variables in the class as well.",0,0.9953936338424683
105985994,2614,junrao,2017-03-14T18:09:37Z,should we pass in timestampdelta instead of timestamp?,0,0.9937543272972107
105987708,2614,hachikuji,2017-03-14T18:16:04Z,`simplerecord` works for me. i may have actually had this in the code at one time or another.,0,0.9825175404548645
106071613,2614,junrao,2017-03-15T02:02:41Z,it's a bit weird to call this maxusablemagic when we take the min. perhaps this and the method should be minusablemagic?,-1,0.9749846458435059
106071657,2614,junrao,2017-03-15T02:03:05Z,"hmm, the method doesn't do exactly what the comment says. if desiredversion is not usable, it doesn't seem to fall back to latest usable version. is the comment incorrect?",-1,0.49914446473121643
106071664,2614,junrao,2017-03-15T02:03:10Z,maybe useful to include the min/max version in the error message?,0,0.99177086353302
106071700,2614,junrao,2017-03-15T02:03:30Z,"this can be a bit tricky. it seems that maxusablemagic could change btw when size is computed in line 190 and in line 205. if the estimated size is not correct, we may not be able to append the record to the newly allocated recordsbuilder, which will cause the assertion in line 209 to fail.",0,0.7822763323783875
106071703,2614,junrao,2017-03-15T02:03:34Z,annotate this with ?,0,0.9922616481781006
106071718,2614,junrao,2017-03-15T02:03:46Z,legacyrecordbatch => abstractlegacyrecordbatch ?,0,0.9936221241950989
106071726,2614,junrao,2017-03-15T02:03:52Z,perhaps it's clearer to name this legacyrecord()?,0,0.9931318163871765
106071817,2614,junrao,2017-03-15T02:04:48Z,"the comment in loginputstream says it only does shallow iteration. however, here we are doing deep iteration. so, perhaps the comment needs to be changed?",0,0.9877133369445801
106071826,2614,junrao,2017-03-15T02:04:52Z,log logentries => logentries,0,0.9717931747436523
106071834,2614,junrao,2017-03-15T02:04:56Z,due => due,0,0.9405359029769897
106071846,2614,junrao,2017-03-15T02:05:04Z,epoch => producerepoch here and in the comment?,0,0.9938550591468811
106071855,2614,junrao,2017-03-15T02:05:09Z,could we call this producerepoch to distinguish it from partitionleaderepoch?,0,0.995108425617218
106071869,2614,junrao,2017-03-15T02:05:18Z,"hmm, is remaining() correct? it seems that limit() is right.",0,0.984074592590332
106071874,2614,junrao,2017-03-15T02:05:25Z,"hmm, the last message has offset 3. so, shouldn't position be 4?",0,0.9839518666267395
106071891,2614,junrao,2017-03-15T02:05:39Z,"could we print out whether this is a control record? and if so, perhaps print out more details about the control record?",0,0.992554247379303
106071917,2614,junrao,2017-03-15T02:05:54Z,could we print out leaderepoch as well. also epoch => producerepoch?,0,0.9938961863517761
106083563,2614,junrao,2017-03-15T04:21:17Z,"with this, it's possible to have no records added to the builder. does the builder support that at close() time?",0,0.991241455078125
106086048,2614,junrao,2017-03-15T04:58:44Z,it seems that the validation has been done in line 203?,0,0.9946064352989197
106086067,2614,junrao,2017-03-15T04:58:56Z,"hmm, why do we need to do this check? the batch could be on magic 2? ditto on the ensurenotcontrolrecord() check below.",0,0.9589608907699585
106239779,2614,hachikuji,2017-03-15T18:00:26Z,"i agree it reads a little weird, but i'm not sure `minusablemagic` is accurate. the minimum usable magic would always be 0, but we are actually trying to get the maximum magic value that is supported across all brokers, which means taking the minimum of the max versions supported by all.",-1,0.9408261179924011
106243896,2614,hachikuji,2017-03-15T18:15:53Z,i'll clarify the comment. what i was trying to say is that `loginputstream` only handles one level of iteration (it itself does not descend into compressed payloads).,0,0.9838888645172119
106247667,2614,hachikuji,2017-03-15T18:30:11Z,"the `toarray` we're delegating to begins from `buffer.position()`, so `remaining()` seems correct. i'll add a test case to figure it out.",0,0.992077112197876
106249688,2614,hachikuji,2017-03-15T18:37:57Z,"yes, we basically set the built records to `memoryrecords.empty` and reset the position in the underlying buffer.",0,0.9915796518325806
106251349,2614,hachikuji,2017-03-15T18:44:06Z,this was intended to be temporary until we have the transactional portion of kip-98. i didn't want to get too far into that validation in this patch if possible. does that seem reasonable?,0,0.9706315994262695
106257259,2614,hachikuji,2017-03-15T19:08:53Z,good catch. it seems we need to use the same value throughout this logic. we always have the code to handle conversion later if we need it.,1,0.9321146011352539
106258412,2614,hachikuji,2017-03-15T19:13:49Z,"should have known not to try to slip something by jun! fixing this is actually a bit tricky since we need to retain the control record long enough to update the consumer's position. this requires a bit of refactoring in `fetcher`, which i had intended to do in a follow-up. i'll see if there's an easier workaround for now.",-1,0.6584204435348511
106321514,2614,junrao,2017-03-16T01:23:48Z,"it seems that we should either use (1) 0 and buffer.limit() or (2) buffer.position() and buffer.remaining(), but not mixing the two? for (2), typically the buffer is in the write mode. in the read mode, (1) is probably what we want?",0,0.99480801820755
106322699,2614,ijuma,2017-03-16T01:35:51Z,seems like `offset` is ignored in the `else` case.,0,0.9880573749542236
106322962,2614,ijuma,2017-03-16T01:38:41Z,"the reason why `0` is being passed is that `position` is called in the overloaded `toarray` method. so, this is actually doing `2` although it's not too clear.",0,0.9859592318534851
106324045,2614,junrao,2017-03-16T01:50:08Z,"could we also print out baseoffset. basetimestamp, partitionleaderepoch, basesequence?",0,0.99480801820755
106342774,2614,hachikuji,2017-03-16T05:43:08Z,good catch,1,0.981269359588623
106454133,2614,ijuma,2017-03-16T15:45:48Z,"shouldn't we document the behaviour in 0.11.0 first? we can add a note about the previous behaviour at the end, but if someone sees these docs, they should be interested in 0.11.0.",0,0.992109477519989
106455746,2614,ijuma,2017-03-16T15:51:39Z,nit: would `struct.hasfield(transactional_id_key_name)` be a little better?,0,0.9938479065895081
106455926,2614,ijuma,2017-03-16T15:52:15Z,nit: would `struct.hasfield(transactional_id_key_name)` be a little better?,0,0.9938479065895081
106460700,2614,ijuma,2017-03-16T16:09:43Z,"could we call `usableversion.ensureusable(version)` here? also, maybe we can improve the exception message from that method to be as good as this one (i.e. include the supported versions).",0,0.9928291440010071
106461149,2614,ijuma,2017-03-16T16:11:24Z,"can we mention the requested `apikey` in the exception? also, it would be good to document that the method throws an exception instead of just returning `null` if no `apiversion` can be found.",0,0.9925992488861084
106478107,2614,junrao,2017-03-16T17:17:01Z,perhaps save this in a constant and reuse?,0,0.9915628433227539
106478136,2614,junrao,2017-03-16T17:17:07Z,"hmm, is headers nullable? if so, should we use -1 to represent null for consistency?",0,0.9916694164276123
106478167,2614,junrao,2017-03-16T17:17:14Z,this should now be named writedefaultrecordheader()? there are a bunch of places like that.,0,0.9862861037254333
106478340,2614,junrao,2017-03-16T17:17:53Z,this should be appendlegacyrecord()? there are a few other places referencing oldlogrecord.,0,0.9913448095321655
106525941,2614,ijuma,2017-03-16T20:41:31Z,nit: `batch`.,0,0.9867669939994812
106528086,2614,ijuma,2017-03-16T20:51:27Z,"have we settled on using `magic` instead of `messageformatversion`? we may need to clean-up some scala code later. personally, i think `messageformatversion` is less `magic` (see what i did there). ;)",1,0.9145285487174988
106535449,2614,ijuma,2017-03-16T21:25:42Z,should some of this github response be included in the code comments?,0,0.9924464821815491
106536471,2614,ijuma,2017-03-16T21:30:15Z,"to avoid this cast, we can add an overrides for `downconvert` in `filerecords` and `memoryrecords` that make the type more specific (where we know it cannot fail).",0,0.9929555654525757
106537132,2614,ijuma,2017-03-16T21:33:25Z,i think that makes sense for what it's worth.,0,0.8970205783843994
106541553,2614,ijuma,2017-03-16T21:56:35Z,"we don't have to do this now, but i wonder if `recordbatch` could simply be an abstract class and we could remove this one. or we could wait until we move to java 8, keep the interface and use default methods.",0,0.9817503690719604
106542021,2614,ijuma,2017-03-16T21:59:19Z,you don't need to say `beginning in 0.11.0` since that's the case for everything in this list.,0,0.9926244616508484
106542403,2614,ijuma,2017-03-16T22:01:33Z,is it worth saying something about `batch.size`? it seems that is what ensures that the batch will be of an appropriate size.,0,0.9931715726852417
106543613,2614,ijuma,2017-03-16T22:09:03Z,can we simplify this in a similar way as we simplified `networkclient`?,0,0.9943168759346008
106546543,2614,ijuma,2017-03-16T22:26:41Z,typo: `unusuable`,0,0.9897103905677795
106546942,2614,ijuma,2017-03-16T22:29:16Z,is this just an optimisation or it's a correctness issue?,0,0.971989095211029
106570149,2614,junrao,2017-03-17T01:50:37Z,"entry => batch ? also, the comment above still references entry.",0,0.9923426508903503
106570158,2614,junrao,2017-03-17T01:50:45Z,logentries => recordbatch? there are a few other places like that in this file.,0,0.9912362098693848
106570162,2614,junrao,2017-03-17T01:50:51Z,convertlogentry => convertrecordbatch?,0,0.992361307144165
106570181,2614,junrao,2017-03-17T01:51:05Z,we can only do this if headervalue.hasarray() is true? ditto for the crc computation in computechecksum() and in readfrom(). we can probably write a util for that.,0,0.9941322207450867
106570196,2614,junrao,2017-03-17T01:51:22Z,should we assert headerkey is not null?,0,0.9927667379379272
106570214,2614,junrao,2017-03-17T01:51:26Z,log_entry_overhead => record_batch_overhead ?,0,0.9904077649116516
106570219,2614,junrao,2017-03-17T01:51:31Z,"instead of ""magic v2"", referencing magic()?",0,0.9942901134490967
106570227,2614,junrao,2017-03-17T01:51:35Z,logentry => recordbatch ?,0,0.9899340271949768
106570233,2614,junrao,2017-03-17T01:51:40Z,1 => named constant?,0,0.990213930606842
106570245,2614,junrao,2017-03-17T01:51:46Z,could you add a bit more explanation on why the crc is useless?,0,0.9213511943817139
106570254,2614,junrao,2017-03-17T01:51:50Z,buildeosrecord => builddefaultrecord?,0,0.9932585954666138
106570260,2614,junrao,2017-03-17T01:51:55Z,onelogentry => onerecordbatch ?,0,0.9908930063247681
106570281,2614,junrao,2017-03-17T01:52:09Z,"in validatemessagesandassignoffsets(), when validating the defaultrecordbatch, should we also validate the the message count matches the actual number of messages in the array and the header count matches the actual number of headers?",0,0.9953420162200928
106570283,2614,junrao,2017-03-17T01:52:15Z,"instead of 0, referencing the constant?",0,0.9908197522163391
106581113,2614,junrao,2017-03-17T04:15:14Z,"ok, perhaps add a todo comment for now?",0,0.9924982190132141
106581349,2614,junrao,2017-03-17T04:18:30Z,could we include an error message to indicate that this is unexpected? or could we throw an illegalstateexception instead?,0,0.9908666610717773
106892521,2614,ijuma,2017-03-20T12:53:15Z,the implementation of this method in `legacyrecord` is: [code block] i think you need something similar here.,0,0.9930577278137207
106895148,2614,ijuma,2017-03-20T13:05:52Z,nit: shouldn't we represent this as `records => [record]` instead of having `recordscount` as a separate line?,0,0.9927566647529602
106896027,2614,ijuma,2017-03-20T13:10:21Z,"in the documentation above, we use `length` while here we use `size`. it would be good to be consistent.",0,0.8933387398719788
106896581,2614,ijuma,2017-03-20T13:13:16Z,is it ever possible that we use `defaultrecordbatch` with `magic == 0`?,0,0.9944658875465393
106898316,2614,ijuma,2017-03-20T13:21:36Z,is this uint32 or int32? the code does both. :),1,0.9923272728919983
106899598,2614,ijuma,2017-03-20T13:28:02Z,we should have a private method for reading the last offset delta. we are using `readunsignedint` in `lastoffset` and `getint` here.,0,0.995042085647583
106900105,2614,ijuma,2017-03-20T13:30:31Z,"this should be uint32, i believe.",0,0.9886365532875061
106913341,2614,ijuma,2017-03-20T14:26:05Z,"hmm, shouldn't we have more tests here? looking at the tests for the legacy records, some ideas: 1. tests like `simplerecordtest.*isvalid*`, but for `defaultrecordbatch`. 2. `legacyrecordtest.testchecksum` would be useful to have as well. 3. `simplerecord.buildeosrecord` should be renamed and moved here. 4. some tests involving compression? or is the idea that `memoryrecordstest` and `memoryrecordsbuildertest` cover those? it may be worth adding some javadoc to the test classes to give an idea of the what they're intended to test.",0,0.9922934770584106
106913783,2614,ijuma,2017-03-20T14:27:34Z,nit: logrecord -> record.,0,0.987880527973175
106914828,2614,ijuma,2017-03-20T14:31:11Z,"i think we should rename this class `legacysimplerecordtest` (or something like that) and move the tests that are not for `legacyrecord` elsewhere. also, if there are tests that would make sense for `defaultrecord`, we should port them.",0,0.9946784973144531
106915417,2614,ijuma,2017-03-20T14:33:09Z,should this be in `memoryrecordsbuildertest` (or `memoryrecordstest`)?,0,0.9950650334358215
106915947,2614,ijuma,2017-03-20T14:35:04Z,we should add a comment here.,0,0.9876325130462646
106916671,2614,ijuma,2017-03-20T14:37:33Z,nit: i would say exactly-once as not everyone is familiar with the eos terminology.,0,0.9601330161094666
106917876,2614,ijuma,2017-03-20T14:41:50Z,nit: would `struct.hasfield(transactional_id_key_name)` be a little better?,0,0.9938479065895081
106919175,2614,ijuma,2017-03-20T14:46:02Z,i think we should call the `validaterecords` method for all versions.,0,0.9876272678375244
106919335,2614,ijuma,2017-03-20T14:46:32Z,"if we do this check, should we not do it for other versions `magic_value_v1` too?",0,0.9955024123191833
106919624,2614,ijuma,2017-03-20T14:47:25Z,"instead of saying ""version 3 and above"", should we just say ""version $version""?",0,0.9943121671676636
106919757,2614,ijuma,2017-03-20T14:47:55Z,"i think we should call the `validaterecords` method for all versions. also, why do we only do it on `tostruct` instead of the constructor?",0,0.9937376976013184
106920410,2614,ijuma,2017-03-20T14:50:06Z,why was this moved to a separate line?,0,0.9898892045021057
106922600,2614,ijuma,2017-03-20T14:57:51Z,"maybe replace `unexpected` by `unknown`? given the versioning, it is expected that new versions will be introduced eventually.",0,0.9945637583732605
106929150,2614,ijuma,2017-03-20T15:20:29Z,"if you use `standardcharsets.utf_8`, you don't need the try/catch.",0,0.992594301700592
106929931,2614,ijuma,2017-03-20T15:22:48Z,is there a reason why we don't just call `crc32.crc32` here? was it while doing some experiments with other implementations?,0,0.9920318126678467
106933605,2614,ijuma,2017-03-20T15:36:00Z,"it's a bit odd that `legacyrecord` is referenced here. if this is the same for legacy and default, we should move it to a shared class. otherwise, it seems this logic should not live here any more.",0,0.6396788954734802
106934435,2614,ijuma,2017-03-20T15:38:55Z,shouldn't this pass the headers as well?,0,0.9928575754165649
106934918,2614,ijuma,2017-03-20T15:40:29Z,i wonder if some of these constructors that are only used by tests should be static factory methods to avoid accidental usage from non-test code.,0,0.8567087650299072
106935553,2614,ijuma,2017-03-20T15:42:47Z,"the formatting of this method doesn't seem to follow our java convention (yes, i know, intellij) since the `return` is in the same line as the `if`. using `&&` is a concise alternative.",0,0.9898362755775452
106967419,2614,hachikuji,2017-03-20T17:40:23Z,"an optimization i guess. we could construct a new `memoryrecords` with the stored buffer, but i didn't see a good reason to.",0,0.9547386765480042
106967704,2614,hachikuji,2017-03-20T17:41:30Z,"lol, looks like my mind got stuck somewhere between typing ""unusual"" and ""unusable"".",-1,0.5593016743659973
107003151,2614,hachikuji,2017-03-20T20:09:52Z,i could go either way... i ended up favoring `magic` mainly because it gives more concise variable and method names.,0,0.980998694896698
107003332,2614,hachikuji,2017-03-20T20:10:39Z,i debated on this... i'm inclined to leave it for later since this is internal.,-1,0.5464422106742859
107022774,2614,ijuma,2017-03-20T21:34:16Z,"note that this is only true before kip-74. after kip-74, this should never happen.",0,0.9920552372932434
107026003,2614,ijuma,2017-03-20T21:50:52Z,shouldn't we use the buffer position here?,0,0.9924644231796265
107041677,2614,hachikuji,2017-03-20T23:27:01Z,good point,1,0.9655349254608154
107043636,2614,hachikuji,2017-03-20T23:42:06Z,hmm... we should check with magnus which case it was that he was accidentally using. was it the old produce request version with the new format?,0,0.9392616748809814
107044557,2614,hachikuji,2017-03-20T23:48:56Z,that's fair,1,0.9400297403335571
107044757,2614,ijuma,2017-03-20T23:50:19Z,is it right that `0` is used if there is none for this and `producerid`? the constants at the top of the file seem to indicate that it's `-1`?,0,0.9956443309783936
107044853,2614,ijuma,2017-03-20T23:51:03Z,we should probably replace `message set` with `record batch` in the comments.,0,0.993819534778595
107045184,2614,ijuma,2017-03-20T23:53:34Z,`log overhead` -> `batch overhead`?,0,0.993943989276886
107045235,2614,ijuma,2017-03-20T23:53:59Z,`log entry` -> `record batch`,0,0.9934578537940979
107045406,2614,ijuma,2017-03-20T23:55:21Z,"wouldn't this be better as a top level interface? i think an inner interface would make sense if we called it `mutable` only. as it is, the name stands well on its own and it makes usage a bit less verbose.",0,0.9866666197776794
107047035,2614,ijuma,2017-03-21T00:08:17Z,the `shallow` should be removed. maybe we need to do a search and replace for that string.,0,0.9908291101455688
107048855,2614,ijuma,2017-03-21T00:22:43Z,that's a good point. maybe we should just add a comment saying that we don't validate older versions because some clients rely on that.,0,0.9106612205505371
107057682,2614,hachikuji,2017-03-21T01:50:20Z,i think we can remove these utilities. i didn't know about the methods already in `crc32` until i started updating that class.,0,0.9746973514556885
107057717,2614,hachikuji,2017-03-21T01:50:50Z,agreed,0,0.9622275233268738
107057751,2614,hachikuji,2017-03-21T01:51:12Z,you are my hero,1,0.9425013661384583
107059245,2614,hachikuji,2017-03-21T02:08:33Z,"after thinking about this, it might be better to move the attribute logic into the record classes. we'll duplicate a little code, but it seems better to keep the usage of record attributes encapsulated.",0,0.990153968334198
107146211,2614,ijuma,2017-03-21T12:57:36Z,nit: formatting (same as other case).,0,0.9798840284347534
107146442,2614,ijuma,2017-03-21T12:59:00Z,"nit, if you are importing everything in `record`, then there's no reason to specify `recordbatch` on its own, right?",0,0.9770012497901917
107146675,2614,ijuma,2017-03-21T13:00:13Z,why are we not defaulting to `current` any more? same for the other method.,0,0.9882163405418396
107146794,2614,ijuma,2017-03-21T13:00:54Z,do we need to have a method like this for message format 1?,0,0.9919265508651733
107147049,2614,ijuma,2017-03-21T13:02:08Z,nit: `logentry` -> `record`?,0,0.9931179285049438
107147536,2614,ijuma,2017-03-21T13:04:22Z,why don't we use `logentries` here and in other similar methods?,0,0.9933133721351624
107147613,2614,ijuma,2017-03-21T13:04:43Z,shall we call this `records`?,0,0.9938778281211853
107148607,2614,ijuma,2017-03-21T13:09:43Z,"unfortunately, there are a few magic values in these tests. how did you arrive at the correct values for the array fill and `segmentbytesprop`?",-1,0.8622099757194519
107148969,2614,ijuma,2017-03-21T13:11:14Z,"as you know, we have had a lot of issues with the cleaner in the past. and we don't have any system tests with compacted topics. do you feel like we have enough coverage for all message format versions?",0,0.9712362289428711
107149933,2614,ijuma,2017-03-21T13:15:44Z,it would be a bit clearer if we did: [code block],0,0.9902210235595703
107152276,2614,ijuma,2017-03-21T13:26:31Z,nit: entry -> record.,0,0.9762894511222839
107153794,2614,ijuma,2017-03-21T13:32:43Z,nice catch.,1,0.9854985475540161
107156070,2614,ijuma,2017-03-21T13:41:08Z,"if i understand correctly, you have two `flush` calls to ensure that we produce two batches, right? a few suggestions: 1. add a comment 2. rename the tests to make it clear that they're about record batches now, not records. 3. maybe we should do a `get` on the future in case it fails (in that case, we can probably remove the `flush()`).",0,0.9926880598068237
107157124,2614,ijuma,2017-03-21T13:45:19Z,"one more thing, we should consider changing the default to use the new format's overhead. at the moment it is: `val messagemaxbytes = 1000000 + messageset.logoverhead`.",0,0.9939017295837402
107157639,2614,ijuma,2017-03-21T13:47:20Z,"to avoid similar brittleness, would it be better to say something like `maxmessagesize - record_batch_overhead - 24` (the latter being the key size)?",0,0.9940904974937439
107159115,2614,ijuma,2017-03-21T13:52:44Z,should we be returning the current version in these stub returns?,0,0.9932030439376831
107160387,2614,ijuma,2017-03-21T13:57:21Z,"answering your question, this index is for the lz4 checksum value as the comment above says. maybe we should mention in the comment that it's not our message crc.",0,0.9917433857917786
107161317,2614,ijuma,2017-03-21T14:00:52Z,why do we need the `flush`? we are waiting until the future completes already?,0,0.9884253740310669
107161936,2614,ijuma,2017-03-21T14:03:08Z,`logentries` -> `records`.,0,0.9921425580978394
107162213,2614,ijuma,2017-03-21T14:04:15Z,is it intentional that we want to wait for a send to complete before doing the next send? is it related to how many batches we create?,0,0.9734411835670471
107162877,2614,ijuma,2017-03-21T14:06:35Z,how we get `12`? maybe worth adding a comment?,0,0.9895492792129517
107163216,2614,ijuma,2017-03-21T14:07:51Z,"hmm, can we not use a constant for the offset as we had before?",0,0.9749276638031006
107166963,2614,ijuma,2017-03-21T14:21:01Z,maybe we should have a shared constant for the magic offset since it's the same for all formats?,0,0.9946135878562927
107168486,2614,ijuma,2017-03-21T14:26:07Z,maybe we want to update this comment?,0,0.9915348291397095
107168520,2614,ijuma,2017-03-21T14:26:17Z,entry -> batch,0,0.9871072173118591
107168876,2614,ijuma,2017-03-21T14:27:23Z,i was wondering about the fact that `baseoffset` is not the same as `firstoffset` for compacted topics. do we care in cases like this?,0,0.8684646487236023
107169714,2614,ijuma,2017-03-21T14:30:03Z,seems like we need to update the scaladoc of this method. why are we now using `maxtimestamp` instead of the first timestamp?,0,0.9908650517463684
107170322,2614,ijuma,2017-03-21T14:32:15Z,logentry -> recordbatch,0,0.9893597364425659
107171955,2614,ijuma,2017-03-21T14:37:59Z,could some of this logic be moved to `fetchrequest` like we did for the `producerequest`? we could then also write a unit test to verify the behaviour (if we haven't already).,0,0.9942454695701599
107173311,2614,ijuma,2017-03-21T14:42:54Z,`logentryiteratormap` -> `recordbatchesiteratormap`,0,0.9936971068382263
107173784,2614,ijuma,2017-03-21T14:44:22Z,do we need to mention `recordbatch` explicitly here?,0,0.9948719143867493
107174475,2614,ijuma,2017-03-21T14:46:40Z,"should we change the message to mention batch size instead of message size? also, we may consider using `recordbatchtoolargeexception` (which already exists) although maybe later in case it may break things.",0,0.9946115016937256
107175231,2614,ijuma,2017-03-21T14:49:08Z,"nit: it may make sense to keep all the logic in one place. `shouldretainmessage` is only called from this method, so is there any reason not to just add the first check there as well?",0,0.992727518081665
107177315,2614,ijuma,2017-03-21T14:55:27Z,"we stated in `recordbatch` that `baseoffset` remains the same after compaction. it would be good to specify the behaviour of other header fields like `lastoffset` and `maxtimestamp`. furthermore, we should make sure to test the specified behaviour for these cases (i.e. compaction removes the first/last item in the batch, compaction removed the item with the max timestamp). do we have these tests already?",0,0.99440598487854
107180500,2614,ijuma,2017-03-21T15:05:51Z,nit: `s` is not needed and the line below.,0,0.9896606206893921
107181957,2614,ijuma,2017-03-21T15:10:49Z,haha,1,0.9297186732292175
107183186,2614,ijuma,2017-03-21T15:15:06Z,`maybebatch` or we can just remove the val altogether.,0,0.9925817251205444
107183305,2614,ijuma,2017-03-21T15:15:30Z,logentry -> recordbatch,0,0.9893597364425659
107183565,2614,ijuma,2017-03-21T15:16:32Z,shallowlogentry -> recordbatch,0,0.9863486289978027
107183893,2614,ijuma,2017-03-21T15:17:43Z,entries -> batches,0,0.9798197150230408
107183937,2614,ijuma,2017-03-21T15:17:54Z,we can remove the comment.,0,0.988488495349884
107184438,2614,ijuma,2017-03-21T15:19:43Z,"i don't understand this comment. what about compaction? also, we handle compressed and uncompressed the same now, so maybe there's no point in mentioning `uncompressed`?",0,0.717802107334137
107185244,2614,ijuma,2017-03-21T15:22:29Z,nit: space after `=`.,0,0.9909823536872864
107186719,2614,ijuma,2017-03-21T15:27:00Z,"it's a bit odd that we use all lowercase for the existing fields and camel-case for the new ones. would it make sense to use just one style (camel-case seems better, but not sure about compatibility guarantees)?",-1,0.8908264636993408
107187022,2614,ijuma,2017-03-21T15:28:05Z,"seems like we have no junit tests for `dumplogsegments` although the system tests do exercise it. i filed [a link] so that we can address this, but worth keeping in mind that manual verification is needed in the meantime.",0,0.9894315004348755
107193728,2614,ijuma,2017-03-21T15:50:46Z,"i removed this, the other `convert` method, `convertsize` and the tests that called these methods and the code compiled. seems like they are unused and can be removed. we must make sure that the conversion cases are still tested before removing the tests that call these methods.",0,0.992263913154602
107198136,2614,ijuma,2017-03-21T16:05:51Z,would it be clearer if we called this `outerrecord` or something?,0,0.9948440790176392
107200862,2614,ijuma,2017-03-21T16:16:00Z,we don't need to wrap `iterator`. the following makes it compile: [code block] what do you think?,0,0.9892287254333496
107226762,2614,hachikuji,2017-03-21T17:47:22Z,guess that's the danger of using the optimize imports shortcut.,0,0.9105032682418823
107264435,2614,hachikuji,2017-03-21T20:20:55Z,you are right. it seems unnecessary and the test works without it.,0,0.858026385307312
107268478,2614,hachikuji,2017-03-21T20:37:34Z,"right. a lot of the testing around the max message size is obviously sensitive to how the messages are batched. if possible, i'd like to save refactoring of these test cases for a follow-up.",0,0.9556776881217957
107268800,2614,hachikuji,2017-03-21T20:38:59Z,i think we can use `recordbatch.max_record_overhead`,0,0.984431803226471
107269975,2614,ijuma,2017-03-21T20:43:55Z,sounds good.,1,0.9417163729667664
107270196,2614,hachikuji,2017-03-21T20:44:52Z,i'm not sure we need a dependence on the offset here. maybe we can just flips some arbitrary bits in the payload?,0,0.8073535561561584
107272979,2614,ijuma,2017-03-21T20:56:40Z,"ah, i understand what you did now. maybe add a comment?",0,0.9510545134544373
107279979,2614,hachikuji,2017-03-21T21:27:11Z,"i think the invariant we are trying to maintain is that the offsets added to the index are strictly increasing, so using the base offset in place of the first offset seems sufficient and avoids the decompression needed to find the actual first offset.",0,0.9882460236549377
107281528,2614,hachikuji,2017-03-21T21:34:02Z,"the behavior is not actually different. recall that this is ""shallow"" iteration in the old code. the timestamp we are accessing is actually the max timestamp when the record is viewed as a batch. in the uncompressed case, the ""batch"" has just a single record so the timestamp is the same as its max timestamp. in the compressed case, the timestamp is the max timestamp of all records in the batch. we preserve the old behavior and adopt the old compressed behavior for the new message format. i can update the comment to clarify this.",0,0.989418089389801
107283016,2614,hachikuji,2017-03-21T21:40:57Z,"it is possible, but i am not sure conversion is something we want to hide too deeply. maybe we can consider this for a follow-up?",0,0.8458362221717834
107286163,2614,hachikuji,2017-03-21T21:56:43Z,"this is a good point. the current usage of `recordbatchtoolargeexception` is to indicate when a batch exceeds the log segment size, but this only really made sense for the old format without compression. it might be worthwhile considering in a follow-up whether we have need to reuse this error for other purposes. for now, i'll update the message.",0,0.9580070972442627
107290844,2614,hachikuji,2017-03-21T22:22:17Z,"see memoryrecordstest.filterto. the test is kind of a bear, but it covers a large number of cases. i'll update the doc for `lastoffset` and `maxtimestamp`.",0,0.7815070748329163
107292917,2614,hachikuji,2017-03-21T22:34:27Z,"yeah... debated on this. all lower-case is hard to read (e.g. ""partitionleaderepoch""), but i wasn't sure about compatibility.",-1,0.9194003343582153
107294949,2614,ijuma,2017-03-21T22:46:13Z,"ok, maybe we can consider using camel-case for the existing fields in a follow-up.",0,0.9908267855644226
107295245,2614,ijuma,2017-03-21T22:48:12Z,"follow-up is fine. generally, i think it's a good pattern to keep the logic in `kafkaapis` simple since it makes it harder to test.",0,0.855431854724884
107296984,2614,hachikuji,2017-03-21T22:58:41Z,"yeah, that's a good idea.",1,0.9075272083282471
107297922,2614,hachikuji,2017-03-21T23:04:56Z,good call. seems better.,1,0.952478289604187
107298677,2614,hachikuji,2017-03-21T23:09:57Z,"yes, i agree. there are probably ways we can do it so that we keep so visibility into the fact that the down-conversion is happening behind the scenes (maybe just comments).",0,0.9811897277832031
107316444,2614,ijuma,2017-03-22T01:37:53Z,"i was going to suggest removing this, but was unsure. happy that you did it anyway. :)",1,0.9958103895187378
107318058,2614,ijuma,2017-03-22T01:55:28Z,"my bad, you're right. thanks for updating the comment.",-1,0.9392766952514648
107327673,2614,ijuma,2017-03-22T03:43:37Z,"copied and pasted from the method comment, so we can delete it, i think.",0,0.9908210635185242
107328065,2614,ijuma,2017-03-22T03:48:46Z,was this never required? it seems like we don't do it any more.,0,0.9762344360351562
107334914,2614,junrao,2017-03-22T05:25:37Z,move this to previous line?,0,0.9894486665725708
107334929,2614,junrao,2017-03-22T05:25:48Z,logentries => recordbatch?,0,0.9902831315994263
107334933,2614,junrao,2017-03-22T05:25:51Z,the the => the,0,0.8006092309951782
107398114,2614,ijuma,2017-03-22T12:14:51Z,do you know why we had 2 builders?,0,0.9822279810905457
107412161,2614,ijuma,2017-03-22T13:29:38Z,did we decide on this one?,0,0.9903951287269592
107415960,2614,ijuma,2017-03-22T13:45:00Z,nice that we avoid the overhead of the streams here.,0,0.7034240961074829
107425811,2614,ijuma,2017-03-22T14:22:21Z,"yes, i agree that it's worth adding a brief comment explaining until we fix the issue.",0,0.9286288619041443
107441751,2614,ijuma,2017-03-22T15:15:15Z,"is it ok that we don't check the magic here, but we do for the append that takes a legacy record?",0,0.9822973012924194
107494215,2614,hachikuji,2017-03-22T18:23:25Z,looks like i forgot this one. i'll fix.,0,0.9103047847747803
107498549,2614,hachikuji,2017-03-22T18:39:56Z,"yeah, that's a good question. i'm not sure there's a good reason for the check in the `legacyrecord` case. i think initially we were doing something like copying the bytes directly, so it may have made more sense before.",0,0.8607178926467896
107499252,2614,hachikuji,2017-03-22T18:42:53Z,"oh, i guess we still do the memory copy in this case. the question is whether we should?",0,0.9137579798698425
107510450,2614,hachikuji,2017-03-22T19:32:49Z,i think we were verifying the auto-incrementing behavior. i will verify that we have both cases covered.,0,0.969944417476654
107539054,2614,ijuma,2017-03-22T21:34:50Z,this method is only used by `bytebuffermessageset` (i.e. scala clients) so it seems ok to favour consistency over optimisation in this case.,0,0.9941403269767761
107768943,2614,ijuma,2017-03-23T19:58:09Z,why doesn't assertequals work here?,0,0.9833789467811584
107769018,2614,ijuma,2017-03-23T19:58:34Z,would it be worth adding some timestamp assertions as well?,0,0.9930636286735535
107773329,2614,ijuma,2017-03-23T20:19:57Z,"`non-compressed` should be removed, right?",0,0.9932931661605835
107773377,2614,ijuma,2017-03-23T20:20:11Z,`verifyconvertedbatches`,0,0.9936674237251282
107774031,2614,hachikuji,2017-03-23T20:23:08Z,"we only convert messages when necessary. so if we down-convert a batch to version 1, and we have messages which are magic 0, we won't up-convert them to 1.",0,0.9853286147117615
107774243,2614,hachikuji,2017-03-23T20:24:03Z,ack. may as well.,0,0.6126435399055481
107839904,2614,junrao,2017-03-24T06:02:41Z,"actually, if crc only covers from attributes to the end, do we really need to switch partitionleaderepoch and crc?",0,0.9932750463485718
107886287,2614,ijuma,2017-03-24T11:52:21Z,"it's true that the change is not strictly needed. the reasoning for the switch is that this way the crc includes everything that follows it (same as for v0 and v1 formats). in v0 and v1, the offset and length are before the crc and are not included in the computation. in v2, the offset, length, partitionleaderepoch and magic are before the crc and not included in the computation. given that, do you think the benefit is worth the switch?",0,0.99284827709198
107915842,2614,junrao,2017-03-24T14:33:18Z,"earlier, jason's proposal is to put crc to the very end after records and covers everything from magic. if we do that, the switch is not ideal, but makes sense. if crc is still at the front, then it seems leaving crc in its current location causes less confusion.",0,0.968976616859436
107921226,2614,ijuma,2017-03-24T14:55:05Z,"if we leave the crc in the same position as in v0 and v1, would you still change the computation to be from attributes to the end? a couple of alternatives (each with pros/cons): 1. include magic in the crc computation, but not partitionleaderepoch (con: we'd have to call `checksum.update` twice instead of once). 2. compute the crc from magic to the end (as it was before), but with partitionleaderepoch always assumed to be -1. this makes the computation simple on the producer side, but it's a bit tricky after the partitionleaderepoch has been set. this is a bit similar to how tcp includes the checksum field in the checksum computation, but assumes it to be always 0 (to avoid the chicken and egg problem).",0,0.9898114204406738
107945087,2614,hachikuji,2017-03-24T16:30:20Z,"i think we can swap the crc and leader epoch fields in the current version, but keep the scope of the crc unchanged. in other words: [code block] it's a little odd that we change the scope of the crc in this format, but perhaps it's less odd than changing the location of the field entirely.",0,0.9417040348052979
107954369,2614,hachikuji,2017-03-24T17:13:11Z,"this is a tough one. it's nice being consistent with the old format to some extent, but clients would still need to look at the magic byte first to figure out how to validate the crc, so maybe the consistency win is marginal. the main advantage of the format in the current patch is that it's clear at a glance what is covered by the crc, so it seems easier to explain.",0,0.6026595234870911
107982462,2614,ijuma,2017-03-24T19:27:43Z,discussed offline and jun said he was ok with leaving as is.,0,0.984502375125885
108027606,2614,lindong28,2017-03-25T04:13:03Z,bug: we should use `partitionresponseheader` instead of `partitionresponse` to get the response. i guess this is not discovered by any test because the current patch always has `last_stable_offset = -1l`?,0,0.9712718725204468
108040126,2614,ijuma,2017-03-25T16:48:09Z,thanks for catching this . this field won't be used until the transactional code lands. i submitted a pr with tests: [a link],1,0.8795244693756104
139199834,3874,ijuma,2017-09-15T16:59:14Z,i assume this is not intentional :),1,0.9579291939735413
139200069,3874,lindong28,2017-09-15T17:00:26Z,i made this to skip findbug and speedup test execution while i am still debugging my test :),1,0.9154134392738342
139200184,3874,lindong28,2017-09-15T17:00:59Z,the code is almost ready. i will let you know once it is done today.,0,0.6181272864341736
139200865,3874,tombentley,2017-09-15T17:04:32Z,"`renameddir` was instantiated in the line above, it can't possibly `== dir`. i think you mean `.equals()`",0,0.9945287108421326
139204236,3874,tombentley,2017-09-15T17:20:39Z,but if replication factor == 1 we've lost the log? from the description you give it sounds like we lose track of the state of the renaming because the only information to go on are the names of the files in the directory. could this be solved by having a transaction log file for the deletion in the same directory?,0,0.964718759059906
139204483,3874,ijuma,2017-09-15T17:21:46Z,`==` in scala is _not_ reference equality.,0,0.9899525046348572
139206306,3874,tombentley,2017-09-15T17:29:35Z,why is this necessary? a comment to explain why would be useful.,0,0.9821886420249939
139206895,3874,tombentley,2017-09-15T17:32:07Z,doh! thank you.,1,0.972735583782196
139276166,3874,lindong28,2017-09-16T02:26:05Z,thanks for the comment. the patch you saw was fully ready for review. the patch has been updated now with better code.,1,0.8866199851036072
139276169,3874,lindong28,2017-09-16T02:26:25Z,i will comment on this later.,0,0.980127215385437
139527305,3874,junrao,2017-09-18T20:11:53Z,perhaps we can just get rid of the return value since it always returns errors.none?,0,0.9920430779457092
139529322,3874,junrao,2017-09-18T20:20:37Z,"i thought if destinationdir is any, we will also cancel any existing disk movement?",0,0.9926211833953857
139531084,3874,junrao,2017-09-18T20:27:42Z,there is one otherwise in 1) and another in 2). it's very not clear which is matched to which if.,0,0.8991634845733643
139532975,3874,junrao,2017-09-18T20:35:32Z,it seems that 1) and 2) are in reverse order of the code below.,0,0.9917620420455933
139534077,3874,junrao,2017-09-18T20:40:13Z,should logmanager.updatepreferredlogdir() only remember the preferred log dir if the log doesn't exist?,0,0.9946940541267395
139534824,3874,junrao,2017-09-18T20:43:15Z,should we handle the case when destinationdir is any?,0,0.9917876124382019
139536481,3874,junrao,2017-09-18T20:49:55Z,we use ( for .filter and { for .map. we probably want to be consistent.,0,0.9891310930252075
139539863,3874,junrao,2017-09-18T21:03:29Z,"probably simpler to say ""if the replica is not created or is offline"".",0,0.9868860244750977
139554816,3874,junrao,2017-09-18T22:16:43Z,it seems that we can just combine the logging here and that in line 1398?,0,0.9947662353515625
139555164,3874,junrao,2017-09-18T22:18:40Z,"could we add a comment to explain futurelogs a bit? also, for consistency, should we rename logs to sth like primarylogs or currentlogs?",0,0.9949616193771362
139555761,3874,junrao,2017-09-18T22:22:13Z,we probably want to do foreach{ topicpartition => ...} to be consistent?,0,0.9942920207977295
139557211,3874,junrao,2017-09-18T22:31:11Z,perhaps offlinedirs could be a set?,0,0.9940007328987122
139558508,3874,junrao,2017-09-18T22:39:37Z,should we add isfuture to the param list in the comment above?,0,0.9948714971542358
139558693,3874,junrao,2017-09-18T22:40:43Z,"hmm, it seems that every time we truncate a log, we want to truncate the future log to the same offset? ditto for truncatefullyandstartat().",0,0.5840023159980774
139559651,3874,junrao,2017-09-18T22:46:53Z,should we add the missing param topicpartition and isfuture in the comment above?,0,0.9950018525123596
139560220,3874,junrao,2017-09-18T22:50:27Z,new params missing in the comment above.,0,0.989993155002594
139562965,3874,junrao,2017-09-18T23:08:38Z,it seems that this should be an illegalstateexception since this is not expected?,0,0.9739702343940735
139563311,3874,junrao,2017-09-18T23:10:55Z,"if we check the preferredlogdir when it's added, it seems this should also be an illegalstateexception.",0,0.9857494831085205
139566414,3874,junrao,2017-09-18T23:33:03Z,typo direcotory,0,0.9730674028396606
139566677,3874,junrao,2017-09-18T23:35:00Z,"we probably want to use consistent naming in comments and variables(e.g., primary/secondary or current/future or sth else.)",0,0.9927617907524109
139567451,3874,junrao,2017-09-18T23:40:32Z,"could we move in the following sequence to avoid this corner case issue? 1. rename futurelog to log.completed. 2. rename currentlog to log.deleted. 3. rename log.completed to log. this way, if we fail at any step, we will have either log.completed or log to recover from. we probably also don't need the logic to rename back in the failure case. we just need some extra logic in loadlogs().",0,0.9937965869903564
139572154,3874,junrao,2017-09-19T00:16:49Z,should we include futurelogs in logsbytopicpartition too?,0,0.9942559599876404
139572695,3874,junrao,2017-09-19T00:22:02Z,could we use named variables instead of _._1 and _._2?,0,0.9949122071266174
139576864,3874,junrao,2017-09-19T01:03:50Z,"this doesn't seem to be a complete sentence. are we missing ""when"" before ""the future""?",0,0.9257190823554993
139578305,3874,junrao,2017-09-19T01:19:00Z,"the kip says using zero-copy to move data btw disks, but this is not. we probably can file a separate followup jira to revisit whether such an optimization is worth doing.",0,0.990900993347168
139579858,3874,junrao,2017-09-19T01:35:23Z,"hmm, this doesn't look right. it seems that we want to use the future replica's latest epoch to build the leaderepochrequest.",0,0.5022855997085571
139582141,3874,junrao,2017-09-19T01:58:07Z,we probably want to use current/future replica instead of leader/follower.,0,0.991175651550293
139812138,3874,junrao,2017-09-19T20:42:26Z,replicafetchermanager probably needs to be changed accordingly?,0,0.9912444949150085
139834520,3874,junrao,2017-09-19T22:28:37Z,"after we do the swap, there is no checkpoint file for log cleaner. this means that we need to clean the compacted topic from the beginning, which is not ideal. one option is to copy the checkpoint to the destination log dir at the beginning of the data movement.",0,0.9680763483047485
139835264,3874,junrao,2017-09-19T22:33:34Z,"hmm, do we need this? it seems that any replica being moved across disks should be subject to throttling. the reason that we have this for inter-broker replication throttling is to avoid throttling replicas already in sync.",0,0.9185116291046143
139835968,3874,junrao,2017-09-19T22:37:48Z,typo betwee,0,0.9442986249923706
139836442,3874,junrao,2017-09-19T22:40:29Z,"we have another quota for log cleaning, which is also intra broker. to avoid confusion, would it be better to name this sth like ""replication.across.dirs.throttled.rate""?",0,0.989701509475708
139836798,3874,junrao,2017-09-19T22:42:41Z,"hmm, this wasn't in the kip. do we need this at the topic level?",0,0.8564413785934448
139843596,3874,junrao,2017-09-19T23:32:07Z,"to make it clear, would it be better to rename assignedreplicas to replicasassignedtofuturedir?",0,0.99540776014328
139844894,3874,junrao,2017-09-19T23:42:00Z,does log need to be var?,0,0.9898723363876343
139846597,3874,junrao,2017-09-19T23:55:45Z,"hmm, why do we need to remove newofflinepartitions from replicaalterdirmanager?",0,0.9639946222305298
139849668,3874,junrao,2017-09-20T00:19:58Z,"hmm, the issue with this approach is that if one thread has no partition left and another thread has multiple partitions, we can't let the former to pick up the load from the latter. an alternative is to put all partitions in a queue and let alterreplicathreads pick up one partition at a time from the queue. this will improve the thread utilization.",0,0.9463120698928833
139851404,3874,lindong28,2017-09-20T00:32:57Z,sure. i will update the patch to get rid of the return value in this method.,0,0.9899142980575562
139852351,3874,lindong28,2017-09-20T00:41:27Z,"ah i forgot this. i just checked the kip-113 wiki and it does say that broker will cancel existing movement if ""any"" is specified as the destination log directory. i am wondering if we should to make the cancellation operation more explicit by saying, if ""cancel"" is specified as the destination log directory, the existing movement of this replica should be canceled. the issue with the existing design in the wiki is that user can not distinguish between ""don't care"" and ""cancel existing movement"". what do you think?",0,0.9677008986473083
139852501,3874,lindong28,2017-09-20T00:42:38Z,yeah it is more readable to reorder the comment. i will change it as suggested. thanks.,1,0.9594742059707642
139854278,3874,junrao,2017-09-20T00:59:03Z,"yes, explicitly modeling cancellation will be better. perhaps we can change alter_replica_dir_request to sth like the following. alterreplicadirrequest => [movedpartitions] [cancelledpartitions] movedpartitions => logdir [topic [partitions]] cancelledpartitions => [topic [partitions]] with that, i am not sure we still need to support any in logdir anymore.",0,0.9908189177513123
139854818,3874,lindong28,2017-09-20T01:04:35Z,"i have considered the suggested approach. i think the current approach may be simpler. - if we only remember the preferred log dir when the log doesn't exist, then in order to create the future log in the destination directory, the destination log directory needs to be passed to both `partition.getorcreatereplica(...)` and `logmanager.getorcreatelog()`, thus adding one more parameter to each method. - in addition, the suggested approach means that there will be two different ways that destination log directory is passed to logmanager, i.e. `logmanager.getorcreatelog(...)` and `logmanager.updatepreferredlogdir(...)`. this makes the logic a bit more complicated than the current patch. on the other hand, i think we only need to do `logmanager.updatepreferredlogdir()` if neither the current log nor the future log is in the user-specified log directory. i will update the patch to do it. what do you think?",0,0.9894850850105286
139855447,3874,lindong28,2017-09-20T01:11:06Z,my bad.. i have updated the comment as shown below: [code block],-1,0.9901018142700195
139855723,3874,lindong28,2017-09-20T01:14:06Z,"in the current patch, `any` will be read and filtered by `reassignpartitionscommand` such that broker will not see or handle `any` as the destination log directory. this may change if we want to allow user to cancel ongoing movement. i will reply to the other command after thinking through this.",0,0.9937700629234314
139855851,3874,lindong28,2017-09-20T01:14:55Z,sure. i have updated the patch to use `}` consistently.,0,0.9926700592041016
139855941,3874,lindong28,2017-09-20T01:15:47Z,good point. i have updated the comment as suggested.,1,0.9145790934562683
139856155,3874,lindong28,2017-09-20T01:17:43Z,i think `replicaalterdirmanager` will only be able to fetch data from source log of a partition if the source log of the partition is on an offline log directory. thus newofflinepartitions should be removed from replicaalterdirmanager. does this make sense?,0,0.9937745332717896
139856530,3874,junrao,2017-09-20T01:21:52Z,"yes, that makes sense.",0,0.9692287445068359
139856926,3874,lindong28,2017-09-20T01:26:19Z,sure. i have updated the patch to combine these two statements and the statement in line 1401 into this: [code block],0,0.9914351105690002
139856929,3874,junrao,2017-09-20T01:26:21Z,got it. make sense. thanks.,1,0.982234537601471
139858472,3874,lindong28,2017-09-20T01:42:28Z,sure. i have fixed this as suggested. i will pass over the entire patch later to see if this needs to be fixed in anywhere else.,0,0.9890677332878113
139858629,3874,lindong28,2017-09-20T01:44:04Z,sure. i have updated the patch to use set.,0,0.9905045628547668
139859230,3874,lindong28,2017-09-20T01:50:05Z,you are right. i have updated the patch to document `isfuture` for all methods in logmanager as appropriate.,0,0.8882924914360046
139859392,3874,lindong28,2017-09-20T01:51:53Z,sure. i have updated the patch to document parameters of this method.,0,0.9901676177978516
139859579,3874,lindong28,2017-09-20T01:53:57Z,sure. i have updated the patch to document all parameters of this method.,0,0.9899269342422485
139859792,3874,lindong28,2017-09-20T01:56:03Z,sure. i have updated the patch to use illegalstateexception here.,0,0.9855222702026367
139859805,3874,lindong28,2017-09-20T01:56:11Z,good point. i have updated the patch to use illegalstateexception here.,1,0.6474259495735168
139868382,3874,lindong28,2017-09-20T03:30:21Z,"good point regarding the cleaner checkpoint. i am wondering if it may be better to simply pause log cleaner for all those partitions that are being moved to other log directories. this approach may have two advantages over the suggested approach of saving copying the checkpoint file at the beginning of the data movement: - the broker performance is better than the suggested approach. with the suggested approach, broker needs to clean the data after the checkpoint twice. it is better to only do log cleaning after the partition has been moved to the destination log directory. - the implementation is simpler than the suggested approach. with the suggested approach, the offset for the same partition will be recorded twice in two log directories. and we will need to have more logic in logcleanermanager.allcleanercheckpoints() to differentiate between checkpoint of primary log and the checkpoint of the future log. and we probably need to take more care to keep the checkpoints across log directories consistent if e.g. log renames during swap phase failed. the only concern may be that the size of the compacted partition in the source log directory may be larger than if it is compacted. it is only a concern if replica movement takes a long time. and if this is the case, we probably already have problem with the size of the future log in the destination log directory anyway. what do you think?",0,0.8217981457710266
139870056,3874,lindong28,2017-09-20T03:51:41Z,"`any` is only used in the json file that is provided to the `reassignpartitionscommand`. this is necessary in the case that user only wants to specify log directory for one out of three replicas for a given partition. in that case the `log_dirs` field in the json file will be something like `[""any"", ""/path/to/logdir"", ""any""]`. also note that `reassignpartitionscommand` will filter out the `any` before it constructs alterreplicadirrequest. thus `any` will not be specified as log directory in alterreplicadirrequest and broker does not need to understand this constant. after more thinking, i think we probably don't need to provide a constant for user to cancel ongoing reassignment. there are two use-case for cancelling replica movement. one use-case is that user wants the replica to stay in the current log directory and he/she already knows the absolute path of the current log directory. in this case user can simply reassign partition again using the current log directory as the destination log directory. replicamanager will stop replica movement as appropriate. the other use-case is that user wants to save broker io by stop moving replica. in this case it is probably better to use quota to throttle replica movement. and user can also use either `kafka-log-dirs.sh` or `adminclient.describereplicalogdir` to read the current log directory (and lag) of the partitions that are being moved, and reassign replica again with the current log directory as the destination log directory. thus it seems that we don't need to support explicit cancellation. also, given that we are on a tight schedule to put this patch in 1.0 release, it may be better to try to reduce big changes to the patch unless it is necessary for the jbod feature.",0,0.9953715205192566
139875419,3874,lindong28,2017-09-20T04:56:06Z,thanks. i have updated the patch to fix it.,1,0.7983118295669556
139875907,3874,lindong28,2017-09-20T05:03:18Z,good point. i have updated the patch to consistently use current/future in the comment everywhere in this patch. i verified this by searching for primary in the diff.,1,0.9068595767021179
139876330,3874,lindong28,2017-09-20T05:08:49Z,this method is only used in test. we can not naively include futurelogs in logsbytopicpartition because it returns a map with topicpartition as key. i have updated the patch to remove this method and replaced its use in test with logmanger.getlog().,0,0.9935646653175354
139876533,3874,lindong28,2017-09-20T05:11:11Z,sure. it is fixed now.,0,0.9863779544830322
139878127,3874,lindong28,2017-09-20T05:29:13Z,my bad. it is fixed now.,-1,0.9912278652191162
139878292,3874,lindong28,2017-09-20T05:31:07Z,yes. we should consider zero-copy. we probably don't have time to investigate it in this patch due to the 1.0 release deadline.,0,0.9894270896911621
139878466,3874,lindong28,2017-09-20T05:32:42Z,"ah, my bad.. it is fixed now.",-1,0.9901924133300781
139879142,3874,lindong28,2017-09-20T05:39:57Z,i maybe wrong here because i have not read through the kip wiki of this epoch. the idea here is that replicaalterdirthread will always copy&past the epoch from the current replica to the future replica of this partition. thus it is safe to simply read the epoch and epoch offset from the current replica's cache. did i miss something here?,0,0.9851691722869873
139879604,3874,lindong28,2017-09-20T05:44:50Z,"yeah i have thought about this problem. the thing is that it requires change in the abstractfetchermanager to address this issue, or we need to create a new manager class for replicaalterdirthread. the code will be more complicated with either solution. currently the replica is assigned to threads using abstractfetchermanager.getfetcherid(...). suppose the hash function is good, it should roughly evenly balance the partition across the available replicaalterdirthread. maybe we can have a follow up jira to optimize this if the load imbalance across threads turn out to be an issue. does this sound ok?",0,0.9651480913162231
139879668,3874,lindong28,2017-09-20T05:45:30Z,my bad. thanks for catching this. it is fixed now.,-1,0.9931192398071289
139879987,3874,lindong28,2017-09-20T05:48:45Z,ah.. it is fixed now.,0,0.9448362588882446
139880505,3874,lindong28,2017-09-20T05:54:47Z,is `log.cleaner.io.max.bytes.per.second` the config for throttling log cleaning? i am not sure it is easy to be confused with `intra.broker.replication.throttled.rate`. the former uses `log.cleaner` in the name thus we know it is for log cleaner. the latter uses `replication` in the name and therefore we know it is for replication within the broker. did i miss something here?,0,0.9842010140419006
139881125,3874,lindong28,2017-09-20T06:00:27Z,yeah it wasn't in the kip.. it seems useful and reasonable to include in this patch. i can document this sensor in the kip-113 wiki. i think it may be useful to have it as topic level for debug purpose. but i am not strong on this. i have updated the patch to only record it for `alltopicsstats`.,0,0.9388225674629211
139881570,3874,lindong28,2017-09-20T06:05:15Z,sure. i have renamed variables in this method and in reassignpartitions() as appropriate.,0,0.9941301941871643
139882608,3874,lindong28,2017-09-20T06:14:48Z,it needs to be var because `partition.maybedeleteandswapfuturereplica()` needs to do `replica.log = futurereplica.log`. alternative we can replace the current replica with the future replica in partition.allreplicasmap. but that means we need to copy states such as lastfetchtimems from the current replica to the future replica. and it takes extra care to maintain this when we add new state in the replica in the future. thus i choose the current approach because it is simpler.,0,0.9922747015953064
139883108,3874,lindong28,2017-09-20T06:18:41Z,"i have replied to the other comment. i think we probably don't need to change alterreplicadirrequest or reassignpartitionscommand. replicamanager will not need to handle the case when destinationdir is any because alterreplicadirrequest is not expected to specify ""any"" as log directory.",0,0.9879586696624756
139884242,3874,lindong28,2017-09-20T06:28:16Z,sure. i added the following comment and renamed `logs` to `currentlogs`. [code block],0,0.9919344186782837
139885668,3874,lindong28,2017-09-20T06:40:07Z,"my gut feel is that the logic is harder to be correct if we add more suffix and more rename steps. for example, the following sequence of events may happen with the suggested approach: - futurelog is successfully renamed to log.completed. - currentlog can not be renamed due to log directory failure. - log.completed is renamed to log. if we do not rename it to log now, then when the broker starts with currentlog still offfline, broker will forget about currentlog and will need to rename log.completed to log - now broker restarts again with currentlog online. broker sees two copies of log for the same partition. it will be hard for broker to decide which one to use if the log has been truncated when currentlog is still offline. i think the current approach has simpler with less suffix. it will cause the replica to be deleted in very rare scenario. and even then the broker should be able to recover from this as long as rf > 1. if rf = 1, kafka can not ensure no data loss anyway due to disk failure.",-1,0.7011086344718933
139891303,3874,lindong28,2017-09-20T07:15:24Z,"currently the the future replica will only be written by the replicaalterdirthread. and the current log will only be written by replicafetcherthread and kafkarequesthandler. the replicaalterdirthread is responsible for fetch data from current log to the future log in the same way that replicafetcherthread fetches data from leader to follower. the advantage of this design is that 1) the design is simpler because replicaalterdirthread uses essentially the same logic as replicafetcherthread; and 2) most new logic for intra-broker replication is handled by replicaalterdirthread and replicafetcherthread won't need to worry about the future log. in order to address this problem cleanly while still keep the pattern described above, i have updated the patch so that logmanager.truncateto() will always be called from partition.truncateto(). and the same for truncatefullyandstartat(). in partition.truncateto() will grab the read lock `partition.leaderisrupdatelock` before truncating the log. with the use of partition.leaderisrupdatelock, the current patch ensures that when `partition.maybedeleteandswapfuturereplica()` calls `logmanager.deleteandswapfuturelog`, it is guaranteed that `replica.logendoffset == futurereplica.logendoffset` and no thread can truncate or write the log because all write operation will need to grab `leaderisrupdatelock`. therefore, if the replicafetcherthread truncates the log to an offset smaller than the log end offset of the future log, it is guaranteed that replicaalterdirthread() will receives offsetoutofrangeexception and truncate the future log as well. does this make sense?",0,0.9910714626312256
139891823,3874,lindong28,2017-09-20T07:18:43Z,"just to double check, are you suggesting that we don't need `intrabrokerreplicationthrottledreplicasprop` and should assume that `intrabrokerreplicationthrottledrateprop` is applies to all replicas? i think it makes sense. i will update the patch after confirmation.",0,0.9894869327545166
140006970,3874,ijuma,2017-09-20T15:34:42Z,"seems like we made a bit of a mistake with the existing throttling configs in that they don't specify the unit. the log cleaner setting gets that right. also, it seems like `replication` should be reserved for data transfer between two replicas. are there two replicas here or is this just a case of copying data from one log dir to another?",0,0.9777381420135498
140017132,3874,junrao,2017-09-20T16:08:15Z,"yes, that's not a bad idea. we could pause log cleaning during disk movement and copy the cleaning point after the movement completes.",-1,0.752561092376709
140017691,3874,junrao,2017-09-20T16:10:29Z,"yes, we could make it simple for now that the only way to cancel is to specify the source log dir in alterreplicadirrequest.",0,0.9943355917930603
140021307,3874,junrao,2017-09-20T16:24:44Z,"after a power failure, it's possible for the future replica to have more data than the current replica after recovery. new data could then be appended to the current replica before the future replica resumes replicating. you could have data like the following. current replica: offset: 0 1 2 epoch: 1 1 2 value : v1 v2 v4 future replica: offset: 0 1 2 epoch: 1 1 1 value : v1 v2 v3 to reconcile the replicas, you want to use future replica's latest epoch (i.e. 1) to find the offset of the last offset in that epoch in the current replica so that the future replica can get rid of v3 and copy v4 over.",0,0.9891595244407654
140023208,3874,junrao,2017-09-20T16:32:18Z,"i was thinking that longer term, it may be better to have a single quota that covers all i/os within a broker (including log cleaner, moving data across disks, etc). in that case, a config name with ""intra.broker"" may be more appropriate. however, if we use that name for moving data across disks, it may make future naming a bit harder.",0,0.9883197546005249
140023952,3874,junrao,2017-09-20T16:35:04Z,"if we enable replication quota, the quota metric already tracks the byte rate across all moving partitions. so this seems redundant?",0,0.9850902557373047
140029825,3874,junrao,2017-09-20T16:58:12Z,"hmm, does it guarantee that? after the current replica truncates the data, new data could have been written to the current replica. when the future replica fetches from the current replica again, it may have seen the new data and therefore won't receive offsetoutofrangeexception. this will potentially lead to inconsistent data between the future and the current replica.",0,0.9205282330513
140030015,3874,junrao,2017-09-20T16:58:55Z,"yes, that's my suggestion.",0,0.9505334496498108
140030170,3874,lindong28,2017-09-20T16:59:40Z,good point. i didn't consider the scenario that the future log may be ahead of the current log. i will updated the patch to use the latest epo of the future replica here.,1,0.7409576773643494
140031247,3874,lindong28,2017-09-20T17:04:23Z,thanks. i have updated the patch as suggested.,1,0.7738171219825745
140032664,3874,lindong28,2017-09-20T17:10:02Z,you are right. we no longer need this metric now that we will apply quota to all topic partitions. i have removed this metric from the patch.,0,0.857507586479187
140034012,3874,junrao,2017-09-20T17:15:18Z,"yes, we can probably optimize this in the future if needed.",0,0.9850550889968872
140038010,3874,junrao,2017-09-20T17:30:37Z,": in general, i agree the simpler the better. however, changing suffix in the future potentially will be even more complicated in order to support upgrade. so, it's worth thinking a bit more to see if we can get things right in the first place. for the approach that i described above. i was thinking that if any step fails, you stop and skip the rest of the steps. you only clean this up during log recovery on startup. for the scenario that you described, the sequencing will be the following. a) futurelog is successfully renamed to log.completed. b) currentlog can not be renamed due to log directory failure. c) currentlog will be marked offline and disk movement is stopped. d) broker is restarted and the log dir for currentlog is still offline. disk movement is still stopped and log.completed is untouched. e) broker is restarted and the log dir for currentlog is online. continue with step 2) and 3) above during log recovery. this is a bit more complicated than your approach, but seems safer and matches how we do swapping in log cleaner.",0,0.896756112575531
140038900,3874,lindong28,2017-09-20T17:33:45Z,"it is two replicas here instead of simply copying data from one log dir to another because we are maintaining states such as epoch and high watermark in the future replica. i think it is a good idea to have a single config to throttle all i/os within a broker. given that this probably needs to deprecate the existing `log.cleaner.io.max.bytes.per.second` config, maybe we should do it in a separate kip and find a good name for it? regarding this patch, i think `intra.broker.replication.throttled.rate` is ok because this name says ""replication"" which means fetching data from one replica to another. i am also good with `across.dirs.replication.throttled.rate` (which is more consistent with `leader.replication.throttled.rate`). do you prefer me to change the name to `across.dirs.replication.throttled.rate`?",0,0.9896915555000305
140062197,3874,junrao,2017-09-20T18:59:37Z,how about log.dirs.balancing.io.max.bytes.per.second ?,0,0.9938849806785583
140063395,3874,junrao,2017-09-20T19:04:27Z,typo ofr,0,0.9727076292037964
140065045,3874,lindong28,2017-09-20T19:11:26Z,sure. i have updated the patch to rename this config and related variables as suggested.,0,0.9923130869865417
140086569,3874,junrao,2017-09-20T20:40:06Z,"should we remove the future replica too? otherwise, we may pick up the wrong futurereplica.logendoffset if logdir is changed again.",0,0.9792048335075378
140088276,3874,junrao,2017-09-20T20:47:14Z,"hmm, the logic seems to be the reverse of the comment.",0,0.9808355569839478
140090819,3874,junrao,2017-09-20T20:57:47Z,should we check if destinationdir is offline too and return an error if so?,0,0.9926901459693909
140097808,3874,junrao,2017-09-20T21:27:55Z,we should be using futurereplica's hw instead of currentreplica.,0,0.9916509985923767
140107358,3874,junrao,2017-09-20T22:17:02Z,"hmm, if the replica is a future one, it seems that we don't read the hw from the checkpoint. this may impact the initial offset for replication in the future replica.",0,0.9379476308822632
140109134,3874,lindong28,2017-09-20T22:28:01Z,"great point.. i have been thinking about the right solution since your comment. i have addressed the problem with the following changes to the patch: - add methods truncateto() and truncatefullyandstartat() in partition.scala. both methods need to grab readlock of leaderisrupdatelock before truncating the log. - add method appendrecordstofuturereplica() in partition.scala. this method needs to grab inwritelock of leaderisrupdatelock first. if leo of the current replica >= leo of the future replica, this method will append data to the future log. otherwise, this method will throw offsetoutofrangeexception. this method ensures that, if the current replica is truncated after replicaalterdirthread fetches from the current replica but before replicaalterdirthread try to append data to the future replica, the data will not be appended. - abstractfetcherthread.processfetchrequest() will catch offsetoutofrangeexception thrown from processpartitiondata(). when this exception is caught, the future replica will be truncated with handleoffsetoutofrange and marked for truncation. and the future replica will be truncated again based on the epoch when replicaalterdirthread calls maybetruncate() next time. does this solution sound ok? i am not sure very sure whether we need to both do handleoffsetoutofrange() and mark the log for truncation. maybe we need only one of them?",1,0.9827407002449036
140110357,3874,junrao,2017-09-20T22:35:50Z,are we really removing the partition from the source checkpoint file as the comment says?,0,0.9950031638145447
140111701,3874,lindong28,2017-09-20T22:44:47Z,my solution has a flaw. let me think about how to fix it..,-1,0.98005211353302
140112065,3874,junrao,2017-09-20T22:47:32Z,should we remove future replicas for newofflinepartitions too?,0,0.9939186573028564
140115757,3874,junrao,2017-09-20T23:13:41Z,"hmm, i am not sure that we should do line 1080-1090 on every leaderandisr request especially the controller could re-send the same leaderandisr request. it seems that it's enough to just do this on the very first leaderandisr request (i.e., inside ""if (!hwthreadinitialized) {"").",0,0.8835155367851257
140122257,3874,lindong28,2017-09-21T00:03:31Z,"after more thinking, i made the following change to address the issue. - add method appendrecordstofuturereplica() in partition.scala. this method needs to grab inwritelock of leaderisrupdatelock to prevent race condition with log truncation on the current replica. after appending records to the future replica, this method will do the following. [code block] here is why this could address the issue. in order for the issue in this thread to happen, the following events need to happen: 1) replicaalterdirthread fetches some messages from the current replica 2) the current replica is truncated such that some data that was fetched above will be deleted from the current replica 3) new data is appended to the current replica after log truncation 4) replicaalterdirthread now appends the fetched data to the future replica. this causes inconsistency because it appends some data that was just truncated on the current replica. with the change made above, in step 4) the replicaalterdirthread will notice that the latest epoch of the current replica is larger than the latest epoch of the future replica while the offset of the first message with that epoch in the current replica is smaller than the offset of the last message in the fetched records. then the replicaalterdirthread can truncate the future replica to solve the problem. does this make sense?",0,0.990053117275238
140122398,3874,lindong28,2017-09-21T00:04:44Z,thanks. it is fixed now.,1,0.9445035457611084
140122619,3874,lindong28,2017-09-21T00:06:29Z,thanks for catching this. it is fixed now.,1,0.8696586489677429
140122997,3874,junrao,2017-09-21T00:09:50Z,"i was thinking that one way to do this is that if the current replica truncates, we just remove the partition from the replicaalterdirthread and add it back again. this will force the initialization with proper truncation if needed.",0,0.9849764108657837
140123008,3874,lindong28,2017-09-21T00:09:58Z,thanks. you are right. i have updated the patch to fix this bug.,1,0.9872937202453613
140123222,3874,lindong28,2017-09-21T00:12:05Z,"i think alterreplicadir() already checks whether the destinationdir is offline at the beginning. if it is offline, it will return kafkastorageexception as error.",0,0.9916691780090332
140128580,3874,lindong28,2017-09-21T00:58:12Z,"my concern with doing it only on the first leaderandisrrequest is that this imposes two restrictions that it actually enforced now but may not be true in the future. one restriction is that controller needs to send all partitions in the first leaderandisrrequest to a broker. it is true as of now. but from design perspective broker should also be able to setup partition state properly if the partition is specified in the subsequent leaderandisrrequest. another restriction is that broker always need to shutdown after receiving stopreplicarequest with delete = false. otherwise, when broker receives leaderandisrrequest to be leader/follower for a partition, state of this partition may not be setup properly. this is also true for now. but it is just not very nice because ideally we should be able to send stopreplicarequest and leaderandisrrequest to stop/start a partition in a broker. i have updated the patch to address the problem by only doing line 1080 - 1090 for partitions that are online and not already created before the broker receives this leaderandisrrequest.",0,0.9865632057189941
140128968,3874,lindong28,2017-09-21T01:02:10Z,"newofflinepartitions will be removed from replicamanager.allpartitions. i think we probably don't need to remove the replica from partition.allreplicasmap if the partition object itself is going to be removed and garbage collected, right?",0,0.989547073841095
140129564,3874,lindong28,2017-09-21T01:08:09Z,previously i think it is more accurate to just use the hw of the current replica. i have updated the patch to use hw of the future replica.,0,0.9852223992347717
140130152,3874,lindong28,2017-09-21T01:13:58Z,"yes i think so. it is same way as how logcleaner.updatecheckpoints() is used to remove partition from cleaner offset checkpoint file. logmanager.asyncdelete() will delete the log from logmanager.futurelogs before it calls `cleaner.updatecheckpoints`. the caller of altercheckpointdir(), in this case logmanager.deleteandswapfuturelog(), needs to update logmanager.currentlogs before it calls logmanager.deleteandswapfuturelog(). then `updatecheckpoints(sourcelogdir, none)` will remove the partition from source log directory and updatecheckpoints(destlogdir, option(topicpartition, offset)) will add the partition to the destination log directory.",0,0.9934090375900269
140130593,3874,lindong28,2017-09-21T01:18:53Z,"i think we actually read hw from the checkpoint if the replica is a future one. when the future replica is newly created, it is ok that we don't have hw for the future replica because the log for this future replica is empty. then `replicamanager.checkpointhighwatermarks()` will checkpoint hw for the future replica in the destination log directory. when broker restarts and load the log, partition.getorcreatereplica() will read the hw checkpoint in the destination log directory for future replica as well. does this make sense?",0,0.9940333962440491
140131155,3874,lindong28,2017-09-21T01:24:40Z,"it seems that all other issues have been addressed. i need to think more about this issue more. let me first fix the test, cleanup the patch and upload it.",0,0.9289759993553162
140131332,3874,junrao,2017-09-21T01:26:46Z,thanks for the explanation. makes sense.,1,0.5863615870475769
140131769,3874,junrao,2017-09-21T01:31:31Z,"ok, sounds good.",1,0.7017148733139038
140131983,3874,junrao,2017-09-21T01:34:06Z,thanks. make sense. missed that isreplicalocal() covers future replica too.,1,0.9857534170150757
140163072,3874,lindong28,2017-09-21T07:04:14Z,"i think the suggested approach will work. i am just wondering if the following approach would be simpler: in logmanager.deleteandswapfuturelog(): 1. rename futurelog to be the current log 2. rename currentlog to be deleted. and here is how we handle log directory failure: 1) futurelog is successfully renamed to be the current log 2) currentlog can not be renamed due to log directory failure 3) the log in the source log directory will be marked offline. the log in the destination log directory will serve as the current log and this partition is still online. 4) broker is restarted and the source log directory is still offline. nothing needs to be done. the partition is online. 5) broker is restarted and the source log directory is online. but the destination log directory is online. in this case the log in the source log directory will be truncated based on the leader epoch and will be try to catch up with the leader. 6) broker is restarted and both source and destination log directory is offline. logmanager.loadlogs() will choose the one with the larger latestepoch as the current log. if these two replicas has the same leader epoch, then the one with the larger nextoffset will be chosen as the current log. the other log will be marked for deletion. the advantage of this solution is that we don't need to new suffix, and we don't need to have the logic of renaming a log directory back-and-forth. this solution takes advantage of the leaderepoch to resolve conflicts. do you think this would be a good solution?",0,0.9709921479225159
140326737,3874,junrao,2017-09-21T18:40:08Z,": what you suggested is simpler. my concerns are the following: (1) it can't truly protect the case when the same partition shows up in more than one log dir (say by human mistakes). (2) the approach of using leaderepoch only works when the message format has been upgraded. however, users may not upgrade the message format immediately after upgrading the code. picking the replica based on just the offset is less reliable.",0,0.9784755706787109
140330274,3874,lindong28,2017-09-21T18:54:37Z,"regarding (1), if the same partition appears on multiple log directories due to human either, i think log manager can still choose the one with the highest epoch (or nextoffset if epoch is the same) to address the problem. is my understanding right? regarding (2), i am wondering if it is reasonable to support intra-broker replica movement only if message format has been increased to support leader epoch. i personally think it is a good tradeoff to keep the kafka implementation simpler in the long term. it seems reasonable for a new feature to rely on a message format that has come before it. btw, in my solution to another issue you raised, i.e. inconsistency between the current and the future replica, i also used this trick of leader epoch to address the problem. the solution to that problem will probably be less clean if we can not reply on leader epoch. i will need to think more about how to address these two problems if we want to allow user to move replica within broker with older message format.",0,0.9667259454727173
140330487,3874,lindong28,2017-09-21T18:55:28Z,also note that kip-112 is only enabled if inter-broker-protocol is 1.0 or higher. i am wondering if the similar logic can be applied to determine whether kip-113 is fully supported.,0,0.9867845177650452
140347295,3874,junrao,2017-09-21T20:13:39Z,": for (1), if there is human error, the 2 replicas could correspond to the same topic created at different times. so, their leader epoch may not be directly comparable. it just feels safer if we have a more direct way to detect errors like this. for (2), note that inter-broker-protocol is separate from the message format. even when the message format is set, leader epoch only applies to newly produced messages.",0,0.9886093139648438
140361789,3874,junrao,2017-09-21T21:18:44Z,"hmm, i am not sure if we should lock the writes to the current replica while writing to the future replica. what you said earlier makes sense: we want the writes to the current and the future replica to be independent. another concern is that we are duplicating the logic for epoch checking in replicaalterdirsthread here. i was thinking that another way to do this is in partition.truncateto(), if the truncation is on a current replica, we simply remove it and add it back to the replicaalterdirmanager if it's there. the newly added partition will go through the initialization phase to do the truncation that's needed. this way, the writes to current and the future replica can still be independent.",0,0.8118361830711365
140364258,3874,junrao,2017-09-21T21:30:09Z,could we replace replicamgr.getpartition(topicpartition).get with partition?,0,0.9950606226921082
140365688,3874,junrao,2017-09-21T21:36:34Z,it's not very clear what's being deleted from the name. would it be better to name this replacecurrentwithfuturelog?,0,0.8435520529747009
140366268,3874,junrao,2017-09-21T21:39:25Z,it seems that we need to call replicaalterdirmanager.shutdownidlefetcherthreads() after a partition is removed?,0,0.9948728680610657
140369569,3874,junrao,2017-09-21T21:55:51Z,"there are various error loggings like that in line 220 with text ""error to broker .."". those lines are now shared between the replicafetcherthread and the replicaalterdirthread. so, we probably want to make the logging clearer.",0,0.9911174774169922
140370782,3874,junrao,2017-09-21T22:02:02Z,the reference to leader is not accurate here.,0,0.8315192461013794
140371771,3874,junrao,2017-09-21T22:07:07Z,"hmm, shouldn't we get the startoffset from the future replica?",0,0.9734135270118713
140375054,3874,junrao,2017-09-21T22:29:05Z,should we make this volatile now that it's updatable?,0,0.9936512112617493
140377631,3874,junrao,2017-09-21T22:47:03Z,we probably want to have a separate window size and window samples config for the intrabroker quota?,0,0.9951545000076294
140377671,3874,junrao,2017-09-21T22:47:19Z,intrabroker => logdirsbalancing?,0,0.9917164444923401
140379049,3874,junrao,2017-09-21T22:57:49Z,"to be consistent with the new throttling name, perhaps name this num.log.dirs.balancing.threads? if so, we want to change variable names, comments, and documentations accordingly.",0,0.9940522313117981
140379353,3874,junrao,2017-09-21T23:00:10Z,this is now unused.,0,0.9552958011627197
140380696,3874,junrao,2017-09-21T23:09:43Z,"hmm, leaderepochcache is maintained when records are appended to the log. so, not sure if we need to call initializeleaderepochcache() when renaming.",0,0.924064040184021
140380952,3874,junrao,2017-09-21T23:11:40Z,"if the dir name doesn't change, could we skip the steps below?",0,0.9906328916549683
140383875,3874,junrao,2017-09-21T23:34:10Z,could we add topicpartition too?,0,0.993838369846344
140385799,3874,junrao,2017-09-21T23:51:11Z,we probably want to rename intra-broker-throttle to log-dirs-balancing-throttle?,0,0.9952501058578491
140385990,3874,junrao,2017-09-21T23:53:02Z,should we make it volatile?,0,0.9893414974212646
140387569,3874,junrao,2017-09-22T00:07:08Z,unused import,0,0.9524969458580017
140389918,3874,junrao,2017-09-22T00:26:11Z,is the comment still valid?,0,0.9911167621612549
140389959,3874,junrao,2017-09-22T00:26:37Z,should we do the assert in a waituntil loop?,0,0.9926747679710388
140390517,3874,junrao,2017-09-22T00:32:46Z,"the replica on broker 100 is just changing the log dir. waitforreassignmenttocomplete() only checks for the completion of cross broker replica movement, but not of cross log dirs movement. perhaps we should do this in a waituntil() loop?",0,0.9926832318305969
140595813,3874,lindong28,2017-09-22T21:01:15Z,"regarding (2), i am thinking that it may be reasonable to say we only support inter-broker replica movement only if message format is supports epoch. this is similar to saying that we only support time-based query if message format supports time index, and we only kafkaheader if the message format support kafka header. this may be worth doing if it can keep the kafka implementation simpler in the long term. also regarding (2), my understanding is that we can use leader epoch to choose the newer log directory in this case after message format has been upgraded to support leader epoch, even if there is still old messages in the log that doesn't have leader epoch. this is because the trick here only look at the epoch of the latest message for each log directory. if this is not true then my approach would not work. regarding (1), i realized the following shortcomings of the suggested approach while trying to implement it. let me compare the suggested approach with my approach in more detail below. to clarify, my approach is the following: 1) rename futurelog to be the current log 2) rename currentlog to be deleted. the approach you suggested is the following: 1) rename futurelog to log.completed. 2) rename currentlog to log.deleted. 3) rename log.completed to log. pros of the suggested approach: - it allows user to move replica between log directories of the same broker before user has upgraded to the message format that support leader epoch. (a short term benefit) - it matches how we do swapping in log cleaner (i am not very sure the benefit of following the existing swapping logic in log cleaner in this case though. can you explain a bit more?) - it can help us detect human error if the user mistakenly copied a directory with old data to a broker which already has directory for this partition on another log directory. cons of the suggested approach: - if we fail at the step 2 (rename currentlog to log.deleted), we will mark the partition offline even if we can use the partition in the destination log directory. this reduces availability of the partition. - if we fail at step 3 (rename log.completed to log), we will still delete the replica in the source log directory because it has been successfully renamed for deletion. this reduces the persistence of the partition. - extra logic is needed to keep completable logs in a separate map in logmanager so that we can include its size in the describelogdirsresponse. we also need extra metric tag for log whose directory has be renamed to log.completed. this adds complexity to kafka implementation in the long term. - it doesn't protect against more complicated errors, e.g. if user deletes new log directory before copying the old log directory, or if user deletes specific segment for the partition. overall i think the ability to detect some human error is nice to have. but human error detection is generally hard to do and we don't have a good definition for the scope of human error that can be detected. i am not sure if this is worth the cost in availability and code complexity. actually, if we do want to detect this specific human error, we can also modify the my approach to have broker refuse to start if the same partition appears in more than one directory. this will generate false positive only if source log directory fails exactly at the time the destination partition has caught up with the source partition, which should be pretty. since user knows the log directory that was offline, he/she can manually delete the partition in the source log directory correctly and restart the broker. the reply is a bit long. thanks for taking time to read and discuss this issue.",0,0.9655525088310242
140636915,3874,junrao,2017-09-23T16:22:58Z,": i like the modified version of your approach. basically fail the broker if we detect duplicated logs during restart. this makes the logic simpler. with this, we probably don't need to have the constraint on message format.",1,0.9745765328407288
140643683,3874,lindong28,2017-09-23T23:16:22Z,"ah, i didn't realize you have replied to this thread. yeah i have considered this option. my concern with this approach is that truncation usually happens at the partition level or log level, but the management of replicaalterdirmanager and replicafetchermanager ideally should happen at the replicamanager level, which is higher than the level of partition and log. usually the level of caller should be higher than the level of caller to avoid deadlock and to make the code logic simpler to maintain and develop in the long term. in this specific case, if we add/remove partition from replicaalterdirmanager, a replicafetcherthread may need to get the following lock if truncation happens: abstractfetcherthread.partitionmaplock, partition.leaderisrupdatelock, replicamanager.replicastatechangelock, replicaalterdirmanager.maplock and replicaalterdirthread.maplock. this may cause deadlock if another kafkarequesthandler attempts to get the replicamanager.replicastatechangelock and then partition.leaderisrupdatelock. do you think the approach i suggested previously would work? do you have concern with having this approach depend on the leader epoch and thus the message format?",0,0.9064603447914124
140645077,3874,lindong28,2017-09-24T01:25:35Z,"yeah i have considered this option. my concern with this approach is that truncation usually happens at the partition level or log level, but the management of replicaalterdirmanager and replicafetchermanager ideally should happen at the replicamanager level, which is higher than the level of partition and log. usually the level of caller should be higher than the level of caller to avoid deadlock and to make the code logic simpler to maintain and develop in the long term. in this specific case, if we add/remove partition from replicaalterdirmanager, a replicafetcherthread may need to get the following lock if truncation happens: abstractfetcherthread.partitionmaplock, partition.leaderisrupdatelock, replicamanager.replicastatechangelock, replicaalterdirmanager.maplock and replicaalterdirthread.maplock. this may cause deadlock if another kafkarequesthandler attempts to get the replicamanager.replicastatechangelock and then partition.leaderisrupdatelock. regarding your concern with ""lock the writes to the current replica while writing to the future replica"", i think it probably won't hurt performance much. it will reduce the maximum throughput of writing to the current replica by at most half. but i assume that for most replica, the average throughput should be much less than 50% of the maximum throughput that a broker can write to a partition. furthermore, even if the throughput of this partition is very close to the maximum throughput, we actually want to reduce the throughput that a broker can write to the current replica before the future replica catches up. does this make sense? do you think the approach i suggested previously using leader epoch would work? do you have concern with having this approach depend on the leader epoch and thus the message format?",0,0.9845207333564758
140645086,3874,lindong28,2017-09-24T01:26:15Z,"regarding your concern with ""lock the writes to the current replica while writing to the future replica"", i think it probably won't hurt performance much. it will reduce the maximum throughput of writing to the current replica by at most half. but i assume that for most replica, the average throughput should be much less than 50% of the maximum throughput that a broker can write to a partition. furthermore, even if the throughput of this partition is very close to the maximum throughput, we actually want to reduce the throughput that a broker can write to the current replica before the future replica catches up. does this make sense? we can continue discussion under the new batch of comment you provided. thanks!",0,0.9489614963531494
140645139,3874,lindong28,2017-09-24T01:30:45Z,"my bad. previously i was very tight on the time and spent on most of the time on addressing the comments and have not spent enough time on reviewing the patch myself. now that i have time, i will review the patch myself twice and let you know once it is ready.",-1,0.9848174452781677
140645147,3874,lindong28,2017-09-24T01:31:10Z,the issue is fixed as suggested.,0,0.990813672542572
140645440,3874,lindong28,2017-09-24T02:02:10Z,"i understand that ideally we want to shutdown idle threads. my concern with this approach is that it will let replicaalterdirthread depend on replicaalterdirmanager which introduce circular dependency and make it easier to have deadlock in the future. the only drawback of the current approach is that, there may be idle replicaalterdirthread until the broker receives the next leaderandisrrequest. during this period this replicaalterdirthread will call dowork() once every 1 second by default, which doesn't seem like a problem. thus i think the little performance overhead is better than complicating the kafka implementation. what do you think?",0,0.9333515167236328
140645451,3874,lindong28,2017-09-24T02:03:35Z,my bad. it is fixed now.,-1,0.9912278652191162
140645510,3874,lindong28,2017-09-24T02:06:24Z,previously i thought it is always more accurate to simply read the logstartoffset (and similarly hw) from the current replica. i forgot to go over the patch and correct this after your previous comment regarding the use of hw. i will go over the patch twice to make sure all these are corrected. it is fixed as suggested.,0,0.9880363941192627
140648350,3874,lindong28,2017-09-24T06:20:07Z,it is fixed now. i should be able to fix missing parameters like this in the next update.,0,0.9903850555419922
140651820,3874,lindong28,2017-09-24T09:39:56Z,good point. i have updated the name as suggested. thanks!,1,0.9956395626068115
140653814,3874,lindong28,2017-09-24T11:24:16Z,"i am not sure i understand the problem here. it seems that current error logging in abstractfetcherthread is technically correct. for example, the `error to broker` in line 220 is correct because `sourcebroker.id` still refers to the broker from which the data is fetched, for both replicafetcherthread and replicaalterdirthread. furthermore, the log4j error logging already identifies the class (either replicafetcherthread or replicaalterdirthread) for those log statements in the abstractfetcherthread, thus there is probably no need to identify in the logging message whether it is for replicafetcherthread or replicaalterdirthread. does this make sense?",0,0.9869142174720764
140653857,3874,lindong28,2017-09-24T11:25:59Z,good point! i have updated the patch to make it volatile.,1,0.9881630539894104
140653887,3874,lindong28,2017-09-24T11:27:44Z,it is fixed now. i will review the patch myself twice and try to catch all these things.,0,0.9814742207527161
140654025,3874,lindong28,2017-09-24T11:34:18Z,"i don't have a good reason for adding a separate window size and window samples. i think the main difference between interbroker and logdirsbalancing quota is the throttle rate which can already be configured differently for these two quotas. is there any scenario where user may want to use different window size and window samples for interbroker and logdirsbalancing quota? if not, maybe we can do it when we need it in the future?",0,0.9216848611831665
140654292,3874,lindong28,2017-09-24T11:48:32Z,"replicaalterdir describes the action of these threads and classes, whereas logdirsbalancing identifies the purpose of this action of moving replica. i think replicaalterdir* is more useful and explicit for kafka developer to understand the what these replicaalterdirthread is doing. on the other hand, logdirsbalancing is probably more useful for user to understand the purpose of this new quota. if we were to unify the name, i think it is better to use replace logdirsbalancing with replicaalterdir. the reason is that it is a bit weird and vague to have method like adminclient.logdirsbalancing(map ). and both developer and user probably needs to translate logdirsbalancing to replicaalterdir in order to understand what the new thread, thread manager and request is doing. what do you think?",0,0.9547332525253296
140654314,3874,lindong28,2017-09-24T11:49:27Z,sorry.. it is fixed now.,-1,0.9928386807441711
140654337,3874,lindong28,2017-09-24T11:50:30Z,good point. i have updated the patch as suggested.,1,0.8782106041908264
140654392,3874,lindong28,2017-09-24T11:53:26Z,"i think we need to call initializeleaderepochcache() because the leaderepochcheckpointfile.checkpoint.file is determined and fixed in initializeleaderepochcache(). thus if we don't call initializeleaderepochcache() after the log directory is renamed, leaderepochcheckpointfile.write() will still try to write to a file in the old log directory which no longer exists.",0,0.9921994805335999
140654406,3874,lindong28,2017-09-24T11:54:17Z,"yes, you are right. i will rename these.",0,0.8225971460342407
140654424,3874,lindong28,2017-09-24T11:54:59Z,ah.. fixed now.,0,0.9456441402435303
140654487,3874,lindong28,2017-09-24T11:57:27Z,thanks. i have updated the comment to the following. i will review the patch end-to-end twice to try to make comments and the code consistent after the previous changes. `// when we execute an assignment that moves an existing replica to another log directory on the same broker`,1,0.9287765622138977
140654577,3874,lindong28,2017-09-24T12:02:24Z,you are right. it is fixed now.,0,0.5901312828063965
140654729,3874,lindong28,2017-09-24T12:10:00Z,you are right. strictly speaking we should use waituntil() here. i have updated the patch accordingly.,0,0.9359237551689148
140683628,3874,junrao,2017-09-25T03:34:28Z,": your suggested approach probably works in the common case. my concerns are the following. (1) log truncation is a relatively rare event. your approach tries to solve the problem by requiring writes to future log to hold on to the lock to the current log on every write. so, we add overhead in the common path to solve a rare event. intuitively, to solve a rare event, we also want to add overhead in the rare path. (2) your approach won't be able to distinguish leader epoch inconsistency due to log truncation or bugs in kafka. in the latter case, we probably want to error out instead of continuing. (3) the dealing with leader epoch is tricky to reason about and is already done during replica initialization in the replicaalterdirthread. if possible, it would be useful to limit the places that we deal with leader epoch directly. (4) in theory, even if a topic has the new message format, a truncation may bring the log to the point where there is only old message. (5) intuitively, the disk balancing feature seems independent of message format. so, it feels a bit weird to require that. as for the concerns that you mentioned on the suggested approach. i am not sure we need to hold partition.leaderisrupdatelock. that lock is only needed when the replica set changes. truncating an existing future replica doesn't change replica set though. we do want to make sure that the reinitialization in the future replica is synchronized properly with potential concurrent alterlogdir requests, as you pointed out. so, the following is a slightly modified approach. after the replicafetchthread truncates the log, it will do the following: (1) call a new method in replicaalterdirthread.addpartitionswithtruncation that takes a partition and a truncating offset. this method won't directly do truncation in the future replica. it simply sets the partition state to be truncating if the partition is still present in the partition map. when replicaalterdirthread sees this new state, it ignores any pending fetch response and truncates the future log to the truncating offset, and then resumes fetching. addpartitionswithtruncation() needs to hold partitionmaplock. however, since only replicafetchthread.truncation can call replicaalterdirthread.addpartitionswithtruncation, but not vice versa. there is no cycle to form a deadlock. this approach seems to address all the above concerns: (1) no additional overhead in the write path, which is common, (2), (3) no additional logic for dealing with leader epoch, (4) and (5) doesn't require new message format. neither approach deals with the case when a truncation only happens on the current replica, but not the future replica, and the broker dies. this can still lead to the case when the future replica's log can be ahead of the current replica. if the message format doesn't have the leader epoch, this may not be dealt with cleanly during future replica initialization. we could potentially just truncate the future replica to the log end offset of the current replica in that case during recovery.",0,0.9652783870697021
140683654,3874,junrao,2017-09-25T03:34:53Z,could we just add a scheduler thread that calls replicaalterdirmanager.shutdownidlefetcherthreads() periodically?,0,0.9950002431869507
140683674,3874,junrao,2017-09-25T03:35:14Z,"my point is that for replicaalterdirthread, the logging ""to broker"" doesn't convey much info since it always moves data within the same broker. when there is an error, it's more useful to know the source log dir from which the future replica is copying.",0,0.9889155626296997
140683704,3874,junrao,2017-09-25T03:35:49Z,"the window size and window samples impact how much load can be put during initialization. during initialization, we give a full window worth of quota. so, the larger the window, the more bytes can be put in initially. since interbroker quota may be configured based on network capacity whereas logdirsbalancing quota is mostly based on disk capacity, having separate window sizes between the two quotas allows the admin to control the initial load separately.",0,0.9914622902870178
140683719,3874,junrao,2017-09-25T03:36:06Z,"hmm, it seems that both the num.threads config and the disk movement quota will be set by the admin. so, it seems it makes sense to make them consistent. naming them both after replica alter dir will be fine too.",0,0.969437301158905
140683728,3874,junrao,2017-09-25T03:36:14Z,"ah, makes sense. could you add a comment about this?",0,0.9068998694419861
140683945,3874,junrao,2017-09-25T03:39:55Z,"a related concern here is that we are paying the sort overhead on every fetch request. if there are lots of partitions, this could add non-trivial overhead. the queue approach where the replicaalterdirthread takes one partition at a time from the queue obviates the need for that. it's fine to optimize this in a followup patch though.",0,0.984067440032959
140922489,3874,lindong28,2017-09-25T23:09:34Z,"i think your points 1-5 makes sense. my concern with the modified approach is that it requires replicafetcherthread to depend on the replicaalterdirthread in order to call fetching. addpartitionswithtruncation(). it seems a bit clumsy. i have another way of doing that by passing the truncation signal from replicafetcherthread to replicaalterdirthread via the affected partition. here is my modified approach: 1) partition.truncateto() and partition.truncatefullyandstartat() will grab write lock of leaderisrupdatelock. and partition.appendrecordstofuturereplica() will grab read lock of leaderisrupdatelock. thus we still ensure that the truncation of the current replica and the append operation of the future replica will be executed in order. 2) when the current replica of a partition is truncated, it will set partition.futurereplicaneedtruncation to true. 3) partition.appendrecordstofuturereplica() will first check whether partition.futurereplicaneedtruncation is true. if the flag is true, the method will set the flag to false and throw offsetoutofrangeexception. 4) if abstractfetcherthread.processfetchrequest() catches an ooor exception from processpartitiondata(), it will update partitionstate for this partition to set truncatinglog to true. then the future replica will be truncated based on the leader epoch later. this approach also seems to address all the above concerns: (1) no additional overhead in the write path, which is common, (2), (3) no additional logic for dealing with leader epoch, (4) and (5) doesn't require new message format. in comparison to the previous modified approach, the class dependency graph will be simpler and more intuitive. what do you think?",0,0.7141816020011902
140923612,3874,lindong28,2017-09-25T23:17:24Z,great! i will implement this version in the updated patch.,1,0.9936777949333191
140928340,3874,lindong28,2017-09-25T23:53:27Z,thanks for catching this. i have updated it patch to fix it.,1,0.8103963732719421
140928991,3874,lindong28,2017-09-25T23:57:55Z,good point. i have updated the patch to call replicaalterdirmanager.shutdownidlefetcherthreads() every 2.5 seconds.,1,0.8716881275177002
140931539,3874,lindong28,2017-09-26T00:19:55Z,"i see. currently abstractfetcherthread can not get the log directory for partition in general because consumerfetcherthread, which also extends abstractfetcherthread, does not have log directory for partition. i think the existing implementation probably already provides log directory of the partition in the error log when this information is needed. the idea is that we need to know the log directory of the partition in the error log only if this is a log directory failure. but if this is the case, the original exception should have specified the log directory of the partition. does this sound reasonable?",0,0.9828438758850098
140931968,3874,lindong28,2017-09-26T00:23:48Z,i see. the default size of the full window is 11 seconds. i think the replica movement typically lasts much longer than 11 seconds and in general it is not a big deal to have a slow start. i am not sure it is worth two additional configs to optimize the initial performance of intra-broker replica movement. i don't have a strong opinion on this. do you prefer me to add two configs for this new quota?,0,0.6093838810920715
140932270,3874,lindong28,2017-09-26T00:26:57Z,sure. i added this comment: `re-initialize leader epoch cache so that leaderepochcheckpointfile.checkpoint can correctly reference the checkpoint file in renamed log directory`,0,0.9932116270065308
140936761,3874,lindong28,2017-09-26T01:07:01Z,sure. i have updated the patch to use replica alter dir consistently.,0,0.9933807849884033
140938334,3874,lindong28,2017-09-26T01:22:16Z,"good point. i have updated the patch with the following code. the new implementation should require only one pass of the partitionmap with o(n) time complexity, which is same as the time complexity of replicafetcherthread.buildfetchrequest().",1,0.6701046228408813
140938438,3874,lindong28,2017-09-26T01:23:13Z,here is the code. the idea is that we only need the maximum partition in the filtered partitionmap. [code block],0,0.9909377098083496
140941543,3874,junrao,2017-09-26T01:55:06Z,": the modified approach sounds good overall. a few more questions on this. (a) do we need the leaderisrupdatelock in step 1? if we truncate the current replica first and then insert the truncation point in the future replica, eventually the future replica will be able to truncate to the right offset, right? (b) for step 2 and 3, we can set the truncation state through partition. but we could also just directly set the state in replicaalterdirthread, which seems simpler since it avoids a level of indirection. (c) not sure why we need to turn the truncation state to ooor exception. the handling of ooor may truncate to a different offset than the truncation offset. it seems it's clearer if we handle the truncation state directly.",0,0.735720694065094
140942158,3874,junrao,2017-09-26T02:01:26Z,"yes, i'd prefer to add two new configs for the new quota since we already have separate window configs for the client and the replication quota.",0,0.9881103038787842
140952243,3874,lindong28,2017-09-26T03:54:06Z,sure. i will update the patch to add these two new configs.,0,0.9887292385101318
140993990,3874,lindong28,2017-09-26T08:53:21Z,"good point regarding (a). indeed, truncateto() and truncatefullyandstartat() can simply use the readlock instead of the writelock. readlock is needed to avoid race condition with maybereplacecurrentwithfuturereplica(). regarding (b), can you explain a bit more how replicafetcherthread can set state in replicaalterdirthread after log truncation? are you suggesting that replicafetcherthread constructor should take `replicaalterdirmanger.fetcherthreadmap` as input. then when log truncation happens for partition, it derives the corresponding replicaalterdirthread from `replicaalterdirmanger.fetcherthreadmap` by hashing the topic and partition, before calling `replicaalterthread. addpartitionswithtruncation ()`? it seems a bit weird to put `replicaalterdirmanger.fetcherthreadmap` in the constructor of each replicafetcherthread. what do you think? regarding (c), i agree we don't need to throw ooor if we can directly set the truncation state. i am just not sure how we can directly set the truncation state due the concern with (b) described above. also, in my suggested approach, the handling of this ooor will not reset offset using handleoffsetoutofrange. instead it will set partitionstate.truncatinglog to true so that the partition will be truncated based on the leader epoch later. i am going to update the patch soon so that you can see it.",0,0.9610726237297058
141366056,3874,junrao,2017-09-27T14:44:59Z,": i was thinking of adding a truncatepartition(map[topicpartition, long]) method in abstractfetcherthread and abstractfetchermanager. the latter will call the former. the method takes a truncation offset for each partition in the map. replicafetcherthread will have access to replicaalterdirmanager to call truncatepartition() when the current log is truncated. currently, abstractfetcherthread maintains partitionfetchstate for each partition, if the state is truncatinglog, it will issue leaderepochrequest, followed by log truncation. we can probably introduce a separate leaderepochstate. during initialization, a partition will go through leaderepoch state (where leader epoch request is issued) and then truncatinglog state (where log will be truncated). when truncatepartition() is called, abstractfetcherthread just sets the partition state to truncatinglog state. when abstractfetcherthread sees a partition in that state, it will just truncate the log to the specified truncating offset and then transition to the fetch state. for (a), i am not sure we even need a read lock on leaderisrupdatelock. in the case when a partition is already removed when abstractfetcherthread.truncatepartition() is called, we can simply ignore that partition.",0,0.9913425445556641
141389315,3874,lindong28,2017-09-27T15:57:01Z,"regarding (b), it seems that leaderepochstate is not used in the suggested approach? i think the suggested approach would work. my only concern with this approach is that his approach will have replicafetcherthread depend on replicaalterdirthread, which is a bit unintuitive. on the other hand, my current approach is more complicated because it requires a new flag in parition, ooor exception from partition.truncateto(...), and handling of this ooor exception thrown from processpartitiondata(). i will implement the suggested approach if you think it is ok to have replicafetcherthread depend on replicaalterdirthread. can you confirm this? regarding (a), i think readlock is needed by truncateto() and truncatefullyandstartat() to avoid race condition with maybereplacecurrentwithfuturereplica(). for example, if truncateto() does not grab the read lock, it is possible that maybereplacecurrentwithfuturereplica() finds the leo of the future replica equals leo of the current replica, truncateto() truncates the current replica, and then maybereplacecurrentwithfuturereplica() replaces the current replica with the future replica, and the future replica has data that should have been truncated. does this make sense?",0,0.8835164904594421
141399349,3874,junrao,2017-09-27T16:33:14Z,": in comparison, the approach that lets replicafetcherthread reference replicaalterdirmanager seems a bit better. your explanation on the locking requirement makes sense. we are abusing the intent of leaderisrupdatelock now. so, we probably want to add some comments on that.",0,0.9799466729164124
141768963,3874,lindong28,2017-09-29T00:49:23Z,thanks for all the comments! i have updated the patch as suggested.,1,0.9781031608581543
142055101,3874,tedyu,2017-10-02T03:57:10Z,should we check whether getreplica(request.futurelocalreplicaid).get.log is none (in case we get read lock immediately after write lock is released) ? see code at line 197 above.,0,0.9950215816497803
142070001,3874,lindong28,2017-10-02T07:34:43Z,maybereplacecurrentwithfuturereplica() will not cause nosuchelementexception here because there the thread that calls maybereplacecurrentwithfuturereplica() for a given partition is guaranteed to be the same replicaalterdirthread that appends record to the future replica of this partition.,0,0.9903524518013
142263275,3874,junrao,2017-10-02T21:41:00Z,unused import offsetoutofrangeexception.,0,0.97270667552948
142266788,3874,junrao,2017-10-02T21:58:47Z,"hmm, not sure why we need to check partitionstates.contains() here since we already have the check in line 179.",0,0.9538962841033936
142267378,3874,junrao,2017-10-02T22:01:30Z,indentation,0,0.822169840335846
142278626,3874,junrao,2017-10-02T23:08:27Z,"hmm, i am not sure that we should always let a partition go through the leader epoch logic when a partition is marked for truncation. there are two cases here. (1) if a partition is not in the fetching mode, we should let the replica go through the leader epoch logic and truncate based on the epoch response. after that, we will truncate again based on the marked truncation offset. (2) if a partition is in the fetching mode, we should just do the truncation based on the marked truncation offset w/o going through the leader epoch logic. we probably want to add some comments to document this. also, given this new method, the existing includelogtruncation flag can be a bit confusing. perhaps it's clearer to rename it to isrecovering?",0,0.9318834543228149
142283836,3874,junrao,2017-10-02T23:46:58Z,"the name appendtofollower is now a bit mis-leading since it can be used to append records for future replicas, which is not really a follower. perhaps it's better to rename the methods here and those in log as appendwithoffsetassignment() and appendwithoutoffsetassignment().",0,0.9648695588111877
142294260,3874,ijuma,2017-10-03T01:17:04Z,"we can use this in `logfuturedirname` and `logdeletedirname`. we can maybe add a `suffix` parameter and have `""""` as the default.",0,0.9948595762252808
142294466,3874,ijuma,2017-10-03T01:19:17Z,it seems like `if/else` could be about appending the third tag instead of duplicating all the logic.,0,0.9906837940216064
142294684,3874,lindong28,2017-10-03T01:21:36Z,"previously i had a method called `appendrecordstofuturereplica`. i merged it with `appendrecordstofollower` to reduce the number of methods. since this is misleading, i think it may be better to add method `appendrecordstofuturereplica`, which is more intuitive and more consistent with the name `appendrecordstoleader`. what do you think?",0,0.9907212257385254
142294773,3874,ijuma,2017-10-03T01:22:21Z,"we typically use dash-separated names for kafka metrics. should it be `is-future` then? also, i wonder if this name will be clear to people. i'll think a bit more, don't have any concrete suggestions, right now.",0,0.8541139364242554
142294900,3874,lindong28,2017-10-03T01:23:46Z,"the reason is that replicadiralterthread may have removed topicpartition from the partitionstates in `processpartitiondata()` if the future replica has caught up with the current replica. in this case if we call `partitionstates.updateandmovetoend()`, this partition will be added back to the `partitionstates` by mistake.",0,0.9903278946876526
142294964,3874,lindong28,2017-10-03T01:24:06Z,my bad.. it is fixed now.,-1,0.9909855127334595
142295005,3874,lindong28,2017-10-03T01:24:24Z,thanks much for the detailed review. it is fixed now.,1,0.8416497111320496
142295483,3874,ijuma,2017-10-03T01:28:49Z,"does this not need to be `volatile`? also, now that it's a `var`, we may want to make it private and only provide a public accessor.",0,0.9933104515075684
142295625,3874,ijuma,2017-10-03T01:30:23Z,we should probably use `utils.atomicmovewithfallback`.,0,0.9941195249557495
142295728,3874,ijuma,2017-10-03T01:31:36Z,"seems like we should extract a method that just takes the suffix and generates the `uniqueid`, etc.",0,0.9940231442451477
142421245,3874,lindong28,2017-10-03T14:37:39Z,"one reason to let a partition go through leader epoch is that, if the leader replica is truncated to offset 10, append data up to offset 20, and truncated again to offset 15, first truncation offset 10 will be overwritten by the second truncation offset 20. in reality the window for this happening is probably small and we expect the truncation to happen almost immediately on the future replica after the leader is truncated. but ideally we would probably want to stay on the safe side and use leader epoch to make sure this does not cause any problem. another reason to apply leader epoch is to mimic what we are currently doing with the follower replica. currently whenever leader replica is truncated, it is guaranteed that there is leadership transfer, and the replica will be removed from the replicafetchermanager and added back in the follower. thus the follower will always apply leader epoch if leader is truncated. so it seems to make sense to always truncate the future replica using leader epoch whenever the current replica is truncated. does this make sense? also, is there any correct or performance concern if we always use leader epoch to truncate the future replica?",0,0.9827575087547302
142422846,3874,lindong28,2017-10-03T14:42:59Z,"good point. you are right, it should be volatile. i have updated the patch to make it private and added a public accessor for it.",1,0.9422631859779358
142423254,3874,lindong28,2017-10-03T14:44:26Z,yeah it should be is-future. i have updated the patch as suggested. thanks!,1,0.9925137162208557
142424683,3874,lindong28,2017-10-03T14:49:18Z,sure. i updated the patch with the following code: [code block],0,0.9916861653327942
142427674,3874,lindong28,2017-10-03T14:59:18Z,"i have considered this api. `utils.atomicmovewithfallback` calls `files.move`. and according to the java doc of `files.move`, this method will fail if the target file exists, which is the case here when we replace the current replica with the future replica.",0,0.9939836859703064
142429205,3874,lindong28,2017-10-03T15:04:25Z,"sure. i have updated the patch to add a private method `logdirname(topicpartition: topicpartition, suffix: string)`. i still keep the method `logfuturedirname` and `logdeletedirname` because it seems easy to use by the caller. i can remove these two methods if you prefer.",0,0.9900269508361816
142429272,3874,ijuma,2017-10-03T15:04:36Z,"`files.move` does not fail if the target file already exists given the right `copyoptions`, which `atomicmovewithfallback` uses.",0,0.9929106831550598
142429768,3874,ijuma,2017-10-03T15:06:22Z,"in particular, `atomic_move` should work on linux. and on windows, we fallback to `replace_existing`.",0,0.9935542345046997
142430102,3874,ijuma,2017-10-03T15:07:34Z,"although, this is a directory, so not sure. maybe we should write a test to verify. either way, if `atomic_move` doesn't work, we should use `files.move` with `replace_existing`, which should work, i believe.",0,0.978484034538269
142431419,3874,lindong28,2017-10-03T15:12:09Z,sure. i have updated the patch to use this method in the newly-added private method.,0,0.9919432401657104
142432032,3874,lindong28,2017-10-03T15:14:15Z,i made a mistake previously. the `renamedir` will rename a directory but the destination direction does not exist. thanks for the explanation. i will try and test this approach.,1,0.5912414193153381
142433208,3874,ijuma,2017-10-03T15:18:11Z,sounds good. the main advantage of the `files` apis when compared to the legacy ones is that they provide error messages when things go wrong. that can be quite helpful.,1,0.9898557662963867
142482694,3874,lindong28,2017-10-03T18:24:12Z,i have updated the patch as suggested.,0,0.9791624546051025
142558743,3874,junrao,2017-10-04T00:34:06Z,good point. could you add a comment for that?,1,0.8716713190078735
142559035,3874,junrao,2017-10-04T00:37:14Z,: very good point on double truncation. one way to get around this is to maintain the smallest truncation offset if the partition is marked for truncation multiple times. my concern of depending on leader epoch is that it won't apply if the message format is old.,1,0.9539088606834412
142704994,3874,lindong28,2017-10-04T15:27:09Z,sure. actually the comment is already in the patch.,0,0.9913423657417297
142707839,3874,lindong28,2017-10-04T15:37:00Z,"good point. i have update the patch to use the smallest truncation offset. even if we use the smallest truncation offset, i think it is still safer to use leader epoch to truncate the future replica if leader epoch is available. this is because truncation offset is only recorded in the memory which may be lost if broker restarts. does this make sense?",0,0.5883140563964844
142721548,3874,lindong28,2017-10-04T16:24:54Z,i have rebased patch onto trunk. i will go through this patch end-to-end after we agree on how to truncate the future replica.,0,0.9792628288269043
142831425,3874,junrao,2017-10-05T01:26:53Z,": thinking a bit more. we can use leader epoch to handle truncation since if the leader epoch doesn't exist, we fall back to hw and the truncation point should always be no lower than that. so, this should be safe.",0,0.9767668843269348
142933529,3874,lindong28,2017-10-05T13:17:04Z,"great. thanks for taking time to think through this. since it is safe to use leader epoch and there is not performance concern with doing it, to simplify the implementation, i am going to update the patch to use only leader epoch or high watermark to truncate the future replica without recording the truncation offset. does this sound ok?",1,0.9945360422134399
143042586,3874,junrao,2017-10-05T20:04:43Z,extra empty line,0,0.9794193506240845
143044343,3874,junrao,2017-10-05T20:12:27Z,"in the common case, partitionandoffsets will have less entries than partitionstates. so, it will be more efficient to iterate partitionstates and do lookups in partitionandoffsets.",0,0.9932162165641785
143052139,3874,junrao,2017-10-05T20:45:12Z,"since this method is only called only by replicaalterdirmanager, perhaps it should be defined there?",0,0.9956908822059631
143060422,3874,junrao,2017-10-05T21:21:00Z,"in this case, the current replica won't have an leader epoch info after truncation. to deal with this better, it seems that it's better for a follower replica or a future replica to fall back to the initialized offset in the partitionstate in abstractfetcherthread, instead of hw, when leader epoch can't be found. we can initialize the offset in partitionstate to the truncation point in this case. in other cases, we can pass in hw to initialize the offset in partitionstate.",0,0.9946882724761963
143061641,3874,junrao,2017-10-05T21:27:09Z,"it maybe possible that the log end offset in the partition is less than leaderendoffset. in that case, we really want to start fetching from the log end offset instead of leaderendoffset. so, it seems it's safer for truncateto() to return the current log end offset after truncation and use that as the starting offset for fetching. ditto in replicaalterlogdirsthread.",0,0.9941850304603577
143065376,3874,junrao,2017-10-05T21:45:46Z,do we need the lock here? it seems that we just need to make sure the current replica is not being updated when maybedeleteandswapfuturereplica() is called.,0,0.9911752939224243
143067860,3874,junrao,2017-10-05T21:59:13Z,getreplicaorexception can throw an exception. we don't want to kill the replicaalterlogdirsthread because of this. it seems that we need to return resultwithpartitions?,0,0.9109967947006226
143068459,3874,junrao,2017-10-05T22:02:31Z,it seems lastpartitionopt is better than maxpartitionopt?,0,0.9926720857620239
143071316,3874,junrao,2017-10-05T22:19:12Z,alterlogdirs => alterreplicalogdirs ?,0,0.9938828945159912
143071753,3874,junrao,2017-10-05T22:21:21Z,"numalterlogdirsreplicationquotasamples => numalterreplicalogdirsquotasamples ? ditto for alterlogdirsreplicationquotawindowsizeseconds. in general, it would be useful to make the naming consistent.",0,0.9934278130531311
143072002,3874,junrao,2017-10-05T22:22:44Z,num.replica.alter.log.dirs.threads => num.alter.replica.log.dirs.threads ?,0,0.9927099943161011
143072168,3874,junrao,2017-10-05T22:23:44Z,alter.log.dirs.replication.quota.window.num => alter.replica.log.dirs.quota.window.num? ditto for alter.log.dirs.replication.quota.window.size.seconds.,0,0.9933381080627441
143073815,3874,junrao,2017-10-05T22:33:36Z,shutdownidlereplicaalterlogdirsthread => shutdownidlealterreplicalogdirsthread ?,0,0.9937644004821777
143073900,3874,junrao,2017-10-05T22:33:58Z,replicaalterlogdirsmanager => alterreplicalogdirsmanager?,0,0.9946966171264648
143074047,3874,junrao,2017-10-05T22:34:43Z,"shutdown-idle-replica-alter-log-dirs-thread => shutdown-idle-alter-replica-log-dirs-thread? also, 2500l could probably just be 10000l since the idle threads don't have to be closed that quickly.",0,0.9939569234848022
143079118,3874,junrao,2017-10-05T23:09:46Z,"it seems that we if the source dir is offline, we want to avoid adding the partition to replicaalterlogdirsmanager?",0,0.9904496073722839
143084972,3874,junrao,2017-10-05T23:57:02Z,"since we are calling sourcelog.close() later, could we just call it here instead calling sourcelog.closehandlers()?",0,0.9941900968551636
143091621,3874,lindong28,2017-10-06T01:01:45Z,thanks. it is removed now.,1,0.8781322836875916
143091979,3874,lindong28,2017-10-06T01:05:13Z,"sorry, i missed the exception here. instead of returning resultwithpartitions, how about we keep it consistent with replicafetcherthread.fetchepochsfromleader(), which returns `tp -> new epochendoffset(errors.forexception(t), undefined_epoch_offset)` in the resulting map if the current replica for this topic partition is offline?",-1,0.9751424193382263
143092370,3874,lindong28,2017-10-06T01:09:14Z,it is called maxpartitionopt because this is the toipcpartition with largest topic (in alphabetical order) or the largest partition (if topic string is the same). this topic partition is not selected based on its order in partitionstates. `lastpartitionopt` seems to suggest it is the last partition that is put into the partitionstates. that is why i used `maxpartitionopt`. do you still prefer `lastpartitionopt`?,0,0.9939559102058411
143092809,3874,lindong28,2017-10-06T01:13:48Z,"i intentionally used alterlogdirs to reduce the length of the variable name and related config key name in other places. i think ""replica"" can be removed from the name because its type is `replicationquotamanager`, which already includes the word ""replication"". i will change it to `altereplicalogdirs` if you prefer. what do you think?",0,0.9926244616508484
143092968,3874,lindong28,2017-10-06T01:15:23Z,"i just think that ""numalterreplicalogdirsquotasamples"" is a bit verbose by having both ""replica"" and ""replication"". thus i removed ""replica"" from the name. i will change it to ""numalterreplicalogdirsquotasamples"" if you prefer.",0,0.9461808800697327
143093247,3874,lindong28,2017-10-06T01:18:38Z,"though the request is named ""alterreplicalogdirsrequest"", the thread is `replicaalterlogdirsthread`, which is more consistent with `replicafetcherthread`. because this config is used to determine the thread number, it seems more intuitive to name it `num.replica.alter.log.dirs.threads`. what do you think?",0,0.9942975640296936
143093359,3874,lindong28,2017-10-06T01:19:51Z,"i just think that ""alter.log.dirs.replication.quota.window.num"" is more consistent with the existing config ""replication.quota.window.num"". what do you think?",0,0.9908547401428223
143093452,3874,lindong28,2017-10-06T01:20:49Z,i think it is because the thread class is named `replicaalterlogdirsthread`. i can change it if you still prefer `shutdownidlealterreplicalogdirsthread`.,0,0.992409348487854
143093676,3874,lindong28,2017-10-06T01:23:06Z,do you prefer to rename the manager class from `replicaalterlogdirsmanager` to `alterreplicalogdirsmanager`? previously i think `replicaalterlogdirsmanager` is more consistent with the existing class `replicafetcherthreadmanager`. same for the `replicaalterlogdirsthread`.,0,0.9941146969795227
143174644,3874,lindong28,2017-10-06T12:11:34Z,"the reason this is defined in abstractfetchermanager is that, this method currently uses `fetcherthreadmap`, `maplock` and `getfetcherid`, which are currently private in abstractfetchermanager. i thought it is better to keep them private and only uses these variables in `abstractfetchermanager`. another reason is that we already have methods such as `abstractfetcherthread.fetchepochsfromleader()`, which are defined in `abstractfetcherthread` but only used in `replicafetcherthread`. i am not strong on this. do you prefer to change variables above to protected and move `markpartitionsfortruncation` to `replicaalterdirmanager`?",0,0.9382959604263306
143176721,3874,lindong28,2017-10-06T12:24:02Z,"i am not sure i fully understand your suggestion. i checked the current implementation of replicafetcherthread.handleoffsetoutofrange(). if log end offset in the partition is less than leaderendoffset, the current implementation will start fectching from `math.max(leaderstartoffset, replica.logendoffset.messageoffset)`. so it already does what you suggested, right?",0,0.9709649682044983
143178096,3874,lindong28,2017-10-06T12:32:43Z,"good point. it is not needed. in addition to the reason you mentioned, another reason is that appendrecordstofuturereplica() will be called by the same replicaalterlogdirsthread that calls maybedeleteandswapfuturereplica() for this partition. i will update the patch to remove this lock. thanks!",1,0.9950461387634277
143178280,3874,lindong28,2017-10-06T12:33:55Z,"it is named `shutdown-idle-replica-alter-log-dirs-thread` because the thread class is replicaalterlogdirsthread. do you think we should change the name of the thread class and thread manger class? sure, i will update the patch to use 10000l as interval.",0,0.9944381713867188
143178857,3874,lindong28,2017-10-06T12:36:56Z,"yeah i think the current implementation already avoids adding the partition to replicaalterlogdirsmanager if the source dir is offline. if the source dir is offline, the `val replica = getreplicaorexception(topicpartition)` at line 604 will throw kafkastorageexception and this method will not call `replicaalterlogdirsmanager.addfetcherforpartitions` for this partition.",0,0.9900584816932678
143179842,3874,lindong28,2017-10-06T12:42:37Z,"i think we need to call sourcelog.closehandlers() instead of sourcelog.close(). if we call sourcelog.close() and if source log directory is offline, this method will throw kafkastorageexception without closing handler for this sourcelog. later when logmanager.handlelogdirfailure() is called for this source log directory, the handles of this sourcelog will not be closed because sourcelog has already been removed from `currentlogs`. on the other hand, if we sourcelog.closehandlers() and if the source log directory is offline, the handler of sourcelog will be closed before sourcelog.renamedir() throws kafkastorageexception. all handlers in the source log directory will be properly closed in this case. does this make sense?",0,0.9908449053764343
143179997,3874,lindong28,2017-10-06T12:43:33Z,good point. this makes sense. let me think more about how to handle this case properly.,1,0.9518731832504272
143258114,3874,junrao,2017-10-06T17:59:55Z,"the case that i am worried about is the following. suppose the follower replica has logendoffset of 5 and truncateto(10) is called. after that, we will be fetching from offset 10, which could be in the offset range of the leader. this means that we will be missing messages from offset 5 to 10 in the follower. fetching from offset 5 in this case will be safer.",0,0.9603566527366638
143258987,3874,junrao,2017-10-06T18:03:26Z,"yes, that covers the common case. the case that i was concerned about is when the source replica is taken offline after getreplicaorexception() but before getpartition(topicpartition).get.getorcreatereplica(request.futurelocalreplicaid). in this case, are we creating a future replica on an offline partition?",0,0.9916719794273376
143320042,3874,lindong28,2017-10-07T02:11:34Z,"replicamanager.handlelogdirfailure() is the only method that will take a replica offline. this method is synchronized with replicamanager.alterreplicalogdirs() using replicastatechangelock. thus if the handelogdirfailure() is executed after alterreplicalogdirs(), the future replica will be created first, and then both the current replica and the future replica will be taken offline. if the handelogdirfailure() is executed before alterreplicalogdirs(), the future replica will not be created on the offline partition. so the current implementation seems correct, right?",0,0.9931679964065552
143320196,3874,lindong28,2017-10-07T02:18:44Z,"in replicafetcherthread.handleoffsetoutofrange(), we will first check whether `leaderendoffset < replica.logendoffset.messageoffset`. the code block which you mentioned here is only executed if `leaderendoffset < replica.logendoffset.messageoffset`. in the case ""the follower replica has logendoffset of 5 and truncateto(10) is called"", i assume you are saying that `replica.logendoffset.messageoffset` is 5 and `leaderendoffset` is 10, then the code block here won't be executed. instead, the code block in the `else` branch will truncate the follower replica to offset `math.max(leaderstartoffset, replica.logendoffset.messageoffset)`, which will be offset 5 if the leaderstartoffset is smaller than the follower's leo. later replicafetcherthread will actually fetch starting from offset 5, which seems correct. did i miss something here?",0,0.9927384257316589
143355895,3874,lindong28,2017-10-08T14:15:27Z,"sorry for late reply on this issue. now i think about this more, i think the current patch handles this case well. i understand that if truncatefullyandstartat() is called for the current replica, the current patch will truncate the future replica to high watermark which does not have any effect. but truncatefullyandstartat() will also be called for the future replica later. if truncatefullyandstartat() is called for the current replica, then we know that futurereplica's logendoffset < ""currentreplica's logendoffset before truncation"" < ""currentreplica's logstartoffset after truncation"". this means that replicaalterdirthread will see offsetoutofrangeexception for futurereplica and call handleoffsetoutofrange for future replica. later truncatefullyandstartat() will be called for the future replica as well, which makes the result correct. do you think this make sense? if not, can you explain a bit more what will go wrong?",-1,0.9909805655479431
143356250,3874,lindong28,2017-10-08T14:29:43Z,this lock is removed.,0,0.9862890243530273
143356393,3874,lindong28,2017-10-08T14:36:43Z,"i have updated the patch to return `tp -> new epochendoffset(errors.forexception(t), undefined_epoch_offset)` if the replica is offline. hw will be used to truncate the future replica before the future replica is removed from replicaalterdirthread later.",0,0.9949327111244202
143356469,3874,lindong28,2017-10-08T14:40:19Z,thanks. i realized that the signature of this method could be simplified to `markpartitionsfortruncation(topicpartition: topicpartition)`. i have updated the patch to do the following to optimize the performance of this method. [code block],1,0.8193536996841431
143529807,3874,junrao,2017-10-09T17:22:58Z,": yes, it doesn't seem that this can happen here. so we can leave this as it is.",0,0.9868091344833374
143530433,3874,junrao,2017-10-09T17:25:52Z,": good point that we can rely on truncatefullyandstartat() being called on the future replica later since its offset will be out of range too. in that case, it seems that replicamgr.replicaalterlogdirsmanager.markpartitionsfortruncation() is a no op. do we need to call it here? however, the same issue may happen on truncateto(). consider the following case. the current replica needs to call partition.truncateto(leaderendoffset) since its logendoffset is > leaderendoffset, which can happen when an unclean leader election is triggered. we then call replicamgr.replicaalterlogdirsmanager.markpartitionsfortruncation(). if there is no leader epoch info (e.g., message format is still old), the future replica will default to truncating to its hw, which could be > the leaderendoffset of the current replica. by the time the future replica fetches again, more data could have been accumulated in the current replica and the future replica's offset could still be in range. however, some of the data in the future replica now are different from the current replica. in this case, it's better if the future replica defaults to the leaderendoffset of the current replica during truncation.",0,0.9761261940002441
143530570,3874,junrao,2017-10-09T17:26:26Z,"hmm, do we need to truncate based on hw for those partitions that are already marked as offline? it seems that it's simpler to just let handlepartitionswitherrors() deals with them before they are removed from replicaalterdirthread.",0,0.9880270957946777
143545091,3874,lindong28,2017-10-09T18:31:56Z,"yeah you are right, markpartitionsfortruncation() is not needed if currentreplica. truncatefullyandstartat() is called. i will remove the markpartitionsfortruncation() here. regarding the second issue, i agree that the inconsistency between the current and the future replica can happen if the remaining message's format is old. but it seems to me that the same inconsistency can happen between follower and leader as well if the message format is old. thus the inconsistency between the future and the current replica does not increase the problem we already have. and in the long term, all messages will have the new format and this won't be an issue. thus i am not sure the reduced change of inconsistency is worth additional code complexity. but i will update the patch as suggested if you think this is worth doing. what do you think?",0,0.9472920894622803
143546055,3874,lindong28,2017-10-09T18:36:29Z,"strictly speaking, we don't have to truncate the future replica is the current replica is offline. but it is probably more intuitive to return `epochendoffset(errors.forexception(t), undefined_epoch_offset)` here because the purpose of this method is `fetchepochsfromleader()`. the caller of this method, in this case abstractfetcherthread.maybetruncate(), should decide which to handlepartitionswitherror or truncate the replica. does this make sense?",0,0.988434910774231
143592973,3874,junrao,2017-10-09T22:36:40Z,"ok, this is fine then.",0,0.8976935744285583
143592989,3874,junrao,2017-10-09T22:36:48Z,": i agree that the same issue may happen between the leader and the follower, which we can improve separately in the future. we probably don't want to introduce new issues here between the current and the future replica. i am not sure if my suggestion will add more complexity though. we already store the initial offset in abstractfetcherthread.partitionstates, but ignore it in maybetruncate(). it seems that it's more natural to fall back to this initial offset instead of hw. then, we just need to set the initial offset in markpartitionsfortruncation().",0,0.978499174118042
143783274,3874,lindong28,2017-10-10T16:33:23Z,"the reason i think they are the same problem (not new issue) is that, the future replica is conceptually very similar to the follower replica. replicaalterlogdirsthread works in a very similar way as the replicafetcherthread. they currently share the same problem regarding the inconsistency. and if we have a solution for the follower replica, the solution should be applicable to the future replica as well. i personally think the future replica is just another follower replica on the same broker as leader. let's say we think the inconsistency in the future replica is a new problem and we want to fix it. i think re-using the offset in `abstractfetcherthread.partitionstates` for truncation will make the code a bit more complicated for the following reasons: - if we allow markpartitionsfortruncation() to change the offset in `partitionstates`, then replicafetcherthread (and replicaalterlogdirsthread) will need to handle this properly in processpartitiondata(). currently only one thread will update the offset in `partitionstates` and `fetchoffset` should always equals `replica.logendoffset.messageoffset` in `processpartitiondata()`. - as of now, the offset in `partitionstates` is always the leo of the follower (and future) replica. thus it is no-op if we truncate the follower replica to this offset in maybetruncate(). re-using this offset to store the truncation offset may make the code harder to maintain. it may be better to store the truncationoffsets in a separate map and use it in maybetruncate(...) as shown in [a link] thanks for all the discussion. given my explanation above, can you let me know which solution you prefer? besides, do you want me to change the name of configs and classes as you raised in the other comments?",0,0.9537988305091858
143793959,3874,junrao,2017-10-10T17:14:38Z,": a couple of things. first, when markpartitionsfortruncation(), the replica is now transitioning to a maybe truncating state (not ready for fetching). if there is a pending fetch response, we should just ignore it. i have a separate pr ([a link] that tries to tighten this up. second, once we have that. the implementation that i was thinking is the following. markpartitionsfortruncation() just marks the partition as maybe truncating and puts the initial offset in partitionstates. from that point on, the replica won't be used for fetching data until it transitions to the ready for fetch state. during the handling of maybetruncate() logic, we will try to decide the truncation point based on leader epoch if possible. otherwise, we will just fall back to the initial offset. so, implementation wise, i am not sure we really need a separate truncationoffsets map. so, my thinking is that such a change seems relatively small and safer than the current approach. as for the naming, i don't want have a strong preference. it's up to you to pick sth consistent.",0,0.9837153553962708
143807179,3874,lindong28,2017-10-10T18:03:08Z,this solution makes sense. i have updated the patch as suggested. it seems that all comments have been addressed. i will rebase the patch onto trunk and review it myself tomorrow. thanks!,1,0.993881344795227
143874421,3874,junrao,2017-10-10T22:55:11Z,if we tighten the check in abstractfetcherthread like in [a link] we can still throw an exception here since it shouldn't be possible. that seems a more general fix since it covers the replicafetcherthread too.,0,0.9909959435462952
143876603,3874,junrao,2017-10-10T23:08:56Z,we probably want to throw an illegalstateexception if includelogtruncation is false since markpartitionsfortruncation() is not meant to be called in that case.,0,0.9859965443611145
143882150,3874,junrao,2017-10-10T23:52:27Z,partitionstoalterlogdirwithlogendoffset =>futurereplicasandinitialoffset ?,0,0.993743360042572
143898257,3874,lindong28,2017-10-11T02:20:26Z,"good point. i have updated the patch as suggested, i.e. still throw exception here and check `isreadyforfetch` in `processfetchrequest()`. i can rebase the patch after your patch is committed.",1,0.6253892779350281
143899061,3874,lindong28,2017-10-11T02:28:59Z,thanks for catching this. i have updated the patch as suggested.,1,0.6871450543403625
143900496,3874,lindong28,2017-10-11T02:43:07Z,"actually, since that state is not possible, i have updated the patch to replace runtimeexception with illegalstateexception.",0,0.9844607710838318
143900528,3874,lindong28,2017-10-11T02:43:31Z,sure. i have updated the patch to check for this illegal state.,0,0.9880087375640869
144160448,3874,junrao,2017-10-11T23:14:38Z,"how about we change the comment to the following? ""it's possible that a partition is removed and re-added or truncated when there is a pending fetch request. in this case, we only want to process the fetch response if the partition state is ready for fetch and the current offset is the same as the offset requested.""",0,0.9943945407867432
144160911,3874,junrao,2017-10-11T23:17:52Z,"we should throw the exception, right?",0,0.9655678272247314
144162641,3874,junrao,2017-10-11T23:30:32Z,"how about changing the comment slightly to the following? ""the read lock is needed to prevent the follower replica from being updated while replicaalterdirthread is executing maybedeleteandswapfuturereplica() to replace follower replica with the future replica.""",0,0.9936743974685669
144162836,3874,junrao,2017-10-11T23:32:12Z,"how about changing the comment slightly to the following? ""the read lock is needed to prevent the follower replica from being truncated while replicaalterdirthread is executing maybedeleteandswapfuturereplica() to replace follower replica with the future replica.""",0,0.9937119483947754
144162863,3874,junrao,2017-10-11T23:32:26Z,"how about changing the comment slightly to the following? ""the read lock is needed to prevent the follower replica from being truncated while replicaalterdirthread is executing maybedeleteandswapfuturereplica() to replace follower replica with the future replica.""",0,0.9937119483947754
144168236,3874,lindong28,2017-10-12T00:15:17Z,sure. i have updated the comment as suggested.,0,0.9905271530151367
144168256,3874,lindong28,2017-10-12T00:15:22Z,sure. i have updated the comment as suggested.,0,0.9905271530151367
144168262,3874,lindong28,2017-10-12T00:15:26Z,sure. i have updated the comment as suggested.,0,0.9905271530151367
144168272,3874,lindong28,2017-10-12T00:15:29Z,sure. i have updated the comment as suggested.,0,0.9905271530151367
144168299,3874,lindong28,2017-10-12T00:15:46Z,ah... my bad. thanks much for catching this.,-1,0.9937916398048401
144629332,3874,junrao,2017-10-13T18:40:47Z,"earlier, you had assertequals(nummessages, consumerrecords.size), which seems useful. is there a reason to remove this?",0,0.9918850660324097
144632221,3874,junrao,2017-10-13T18:54:22Z,"hmm, do we need the read lock here? replica/log can only be changed by leaderandisrrequest, stopreplicarequest, and alterreplicalogdirs, all of which are already protected under replicastatechangelock.",0,0.9921370148658752
144632346,3874,junrao,2017-10-13T18:54:57Z,"it seems that this case should never happen. so, should we throw illegalstateexception?",0,0.9693161249160767
144632596,3874,junrao,2017-10-13T18:56:03Z,should performed => should be performed,0,0.984263002872467
144665825,3874,junrao,2017-10-13T22:01:56Z,"hmm, it seems that sourcelog.close() can only throw kafkastorageexception because closehandlers() has already been called due to offline log dir. so, not sure why closehandlers() needs to be called again.",0,0.8598484396934509
144666248,3874,junrao,2017-10-13T22:05:13Z,is this comment correct? it seems that logsegment.close() does a superset of logsegment.closehandlers().,0,0.9931689500808716
144680990,3874,lindong28,2017-10-14T00:49:04Z,"thanks for the review. i think we need readlock here is that the log directory of the current replica is not changed by replicaaltherlogdirsthread when the kafkarequesthandler thread is checking whether it needs to create future replica (when it handles alterreplicalogdirsrequest). if we don't use read lock here, the following scenario can happen: 1) broker receives alterreplicalogdirsrequest 2) kafkarequesthandler calls maybecreatefuturereplica(). it finds that the log directory of the current replica is different from the user-specified destination log directory. so it creates future replica and will later try to add this partition replicaalterlogdirsmanager 3) replicaaltherlogdirsthread calls maybereplacecurrentwithfuturereplica(), updated the log directory of the current replica, removed the future replica from allreplicasmap, and removed this partition from replicaalterlogdirsmanager. 4) kafkarequesthandler will now add this partition to replicaalterlogdirsmanager. 5) now we have an inconsistent state where replicaalterlogdirsmanager has this partition but this partition does not have future replica. the replicaalterlogdirsthread will see replicanotavailableexception and fail. does this make sense?",1,0.7911720275878906
144681216,3874,lindong28,2017-10-14T00:54:15Z,"on a double thought, i realized that this could actually happen if the broker receives the same alterreplicalogdirsrequest multiple times, which could happen because reassignpartitionscommand will re-send alterreplicalogdirsrequest. does this make sense?",0,0.954937219619751
144681244,3874,lindong28,2017-10-14T00:54:59Z,thanks. i will update the patch to fix it.,1,0.677332878112793
144681370,3874,lindong28,2017-10-14T00:57:22Z,i think it is correct. i verified that close() does not set abstractindex.mmap to null. note that close() can not set mmap to null so that abstractindex.delete() can be executed by the scheduler thread.,0,0.971086323261261
144681629,3874,lindong28,2017-10-14T01:03:50Z,"i think log.close() also does disk io operation, e.g. when it calls producerstatemanager.takesnapshot() or filerecords.flush(). therefore it could throw kafkastorageexception() if the ioexception occurs. i realized that we need maybehandleioexception() for log.close() to catch e.g. ioexception from producerstatemanager.takesnapshot(). i have updated the patch to do this.",0,0.9923117756843567
144681763,3874,lindong28,2017-10-14T01:06:46Z,"the reason is that testutils.consumetopicrecords() will throw exception if the consumerecords.size() is not exactly the nummessages(). do you prefer me to add back assertequals(nummessages, consumerrecords.size) so that this check is more explicit in the test?",0,0.9935120940208435
144913957,3874,junrao,2017-10-16T17:30:53Z,thanks for the explanation. this is fine then.,1,0.7001026272773743
144913975,3874,junrao,2017-10-16T17:30:58Z,"thanks, sound goods.",1,0.9543246030807495
144913998,3874,junrao,2017-10-16T17:31:04Z,"ok. then ""file handlers"" can be a bit confusing since we do close the channel associated with the log segment. how about changing the comment to the following? ""the memory mapped buffer for index files of this log will be left open until the log is deleted""",-1,0.6606991291046143
144914073,3874,junrao,2017-10-16T17:31:23Z,"hmm, this is the case that the future replica exists, but not in the specified log dir. resending the same alterreplicalogdirsrequest won't lead to this case, right?",0,0.9697787761688232
144914169,3874,junrao,2017-10-16T17:31:52Z,"i guess the scenario that you are describing is that there is already an ongoing replica movement across disks at step 2. however, in that case, it seems that we will remove the partition from replicaalterlogdirsmanager and the future replica in line 591 and 592. after that point, replicaalterlogdirsthread can't call maybereplacecurrentwithfuturereplica() any more because the additional partition state check that we added in abstractfetcherthread, right?",0,0.9928105473518372
144995830,3874,lindong28,2017-10-16T23:30:42Z,"not sure i explained my thought clearly. i think here the case is that the future replica already exists in the specified log dir. more specifically, when the broker receives the same alterreplicalogdirsrequest again, it calls replicamanager.alterreplicalogdirs(). alterreplicalogdirs() should only add this partition to replicaalterlogdirsmanager if this future replica has not already been created. so alterreplicalogdirs() calls maybecreatefuturereplica(), and maybecreatefuturereplica() should return true iff the future replica is newly created. because it is possible that future replica already exists, we should not throw illegalstateexception. does this sound ok?",0,0.9914606809616089
144995860,3874,lindong28,2017-10-16T23:30:59Z,sure. i have updated the comment and related method names as suggested.,0,0.9918507933616638
144996257,3874,lindong28,2017-10-16T23:34:00Z,"the scenario is that there is already an ongoing replica movement for this same partition to the same destination log directory, which can happen if broker receives the same alterreplicalogdirsrequest again. because the requested destination log directory of the alterreplicalogdirsrequest is same as the destination log directory of the ongoing movement, we will not remove the partition from replicaalterlogdirsmanager. does this make sense?",0,0.9918728470802307
144999197,3874,lindong28,2017-10-16T23:56:36Z,"actually, in the scenario that there is already an ongoing replica movement to a different destination log directory, the following may happen: - replicaaltherlogdirsthread calls maybereplacecurrentwithfuturereplica(), updated the log directory of the current replica and removed the future replica from allreplicasmap() - kafkarequesthandler calls alterreplicalogdirs(). because future replica has been removed, it will not remove this partition from replicaalterlogdirsmanager. then it will create the future replica for this partition and add fetcher for this partition. - then replicaaltherlogdirsthread will remove fetcher for this partition. this leads to an inconsistent state where we have future replica for this partition but this partition is not in replicaalterlogdirsmanager. the main issue is that, we do not have a lock that makes it an atomic operation to 1) add/remove partition from replicaalterlogdirsmanager and 2) add/remove future replica for the partition. protect maybecreatefuturereplica() with `leaderisrupdatelock` could reduce the chance of this race condition.",0,0.9938274025917053
145007121,3874,junrao,2017-10-17T01:06:10Z,": thanks for the info. makes sense. perhaps we should throw an illegalstateexception if future replica exists, but is on a log dir different from the input?",1,0.8791140913963318
145007148,3874,junrao,2017-10-17T01:06:34Z,": in the scenario that there is already an ongoing replica movement to a different destination log directory, i am not sure what you described can happen. maybereplacecurrentwithfuturereplica() is called inside processpartitiondata() and is protected by the abstractfetcherthread.partitionmaplock. so, while this is ongoing, no new partitions can be added to the fetcher. the other scenario that there is already an ongoing replica movement for this same partition to the same destination log directory does make sense. so, we can keep the readlock there.",0,0.9802390933036804
145007951,3874,lindong28,2017-10-17T01:14:41Z,sure. i have updated the code to throw illegalstateexception if the current log dir of the future replica is different from the requested log dir. thanks!,1,0.9782293438911438
145008087,3874,lindong28,2017-10-17T01:16:16Z,thanks much for the discussion!,1,0.9162716269493103
1400867677,3874,Hongten,2023-11-21T16:32:47Z,"i have a question about the previous var. if the log dir name doesn't end with ""-future"", the `currentlogs` will put the topic partition as key and log as value, and return log. the simple logic like the below: [code block] if the `previous` is not null, then there is an `illegalstateexception` to be thrown. right?",0,0.9870113134384155
59305175,1215,becketqin,2016-04-12T00:37:28Z,"i have a question regarding the code here. on line 199 of this patch (line 192 of the original code), we check if the index file exists or not. however, right before this, we have already created the log segment which will create the index file if it does not exist. so it seems the test here will never be false?",0,0.9824668169021606
59380790,1215,ijuma,2016-04-12T14:02:16Z,was it intentional to remove the volatile annotation from this var?,0,0.993709921836853
59381324,1215,ijuma,2016-04-12T14:05:03Z,"also, do we actually need to mutate the vars above in the subclasses? if not, they should remain `private[this]` as they were before. we have accessor methods (without the underscore).",0,0.9948817491531372
59381969,1215,ijuma,2016-04-12T14:08:30Z,"a tuple of 3 elements is not great for readability, i think it's time to introduce a case class for the method result.",0,0.757362961769104
59382177,1215,ijuma,2016-04-12T14:09:43Z,unintentional indent.,-1,0.7793291211128235
59425499,1215,becketqin,2016-04-12T18:13:02Z,i was actually wondering why we need these variables? they are just a derived value based on `mmap.limit` and `mmap.position`. shouldn't we just define them as methods?,0,0.9751760959625244
59429145,1215,ijuma,2016-04-12T18:33:05Z,"it's a good question. i assumed they were there for performance reasons, but i haven't checked.",1,0.9419035315513611
59433036,1215,becketqin,2016-04-12T18:54:25Z,thought about this again. having the variables makes sense because we do not lock the mmap on read. that means the read can happen when the writing of an index entry is half-done. i'll keep the variables.,0,0.9887442588806152
60862080,1215,junrao,2016-04-25T04:38:00Z,typo abastract,0,0.9658104777336121
60862083,1215,junrao,2016-04-25T04:38:04Z,key/value combination => key or value,0,0.9832799434661865
60862084,1215,junrao,2016-04-25T04:38:10Z,should we assert that exactly one of targetkey and targetkey is not empty?,0,0.9934537410736084
60862100,1215,junrao,2016-04-25T04:38:40Z,"when searching for offset, the passed in value is the absolute offset whereas the offsets in the index are relative. so, we use to translate the absolute offset to the relative one in indexslotfor(). that logic seems to be lost in the new code.",0,0.9892751574516296
60862105,1215,junrao,2016-04-25T04:38:48Z,the description starting from line 155 seems redundant. the description in line 150 and 151 explains this method pretty well.,0,0.9782842993736267
60862107,1215,junrao,2016-04-25T04:38:53Z,it seems it's more natural to return none in this case.,0,0.9836476445198059
60862130,1215,junrao,2016-04-25T04:39:07Z,passing in handleandmaybestop seems a bit more complicated than necessary. i am wondering if we can just reuse the iterator() code to be able to iterate messageandoffset from an arbitrary position. the caller can decide what to do.,0,0.9063898324966431
60862136,1215,junrao,2016-04-25T04:39:22Z,typo: mappying and timestamp,0,0.9818370938301086
60862140,1215,junrao,2016-04-25T04:39:26Z,unused imports.,0,0.9113456606864929
60862143,1215,junrao,2016-04-25T04:39:33Z,the comment on line 172 is now outdated. perhaps we can just say all index files.,0,0.9810104966163635
60862149,1215,junrao,2016-04-25T04:39:45Z,that's a good point. it seems that we should check the existence of the index file before creating logsegment.,1,0.7218965888023376
60862151,1215,junrao,2016-04-25T04:39:56Z,"the warning log in line 205 always refers to indexfile, which is not necessarily correct now.",0,0.9736663699150085
60862158,1215,junrao,2016-04-25T04:40:12Z,"hmm, it seems that we should insert the offset in segment i that has the largest timestamp. not sure why we want to insert the offset in the next segment.",0,0.6023998856544495
60862171,1215,junrao,2016-04-25T04:40:34Z,"hmm, does the seg.largesttimestamp always correspond to logendoffset?",0,0.9901500940322876
60862192,1215,junrao,2016-04-25T04:41:35Z,"the current getoffsetbefore() api is a bit awkward to use since it's tightly coupled with how we use the last modified time in each log segment. for example, it doesn't seem to make sense to return a sequence of offsets now that we have message level timestamp. so, it's probably simpler and better to leave the current implementation of getoffsetbefore() as it is. in log, logsegment, and timeindex, we expose a simple api that takes a timestamp and returns a single offset whose timestamp is >= than the input. in the future, we can design a new request that exposes this capability to the client.",0,0.7884738445281982
60862196,1215,junrao,2016-04-25T04:41:44Z,"hmm, i think we want to show both the actual size and the max size, not the ratio.",0,0.9015727639198303
60862197,1215,junrao,2016-04-25T04:41:50Z,could we just call entry.getvalue once?,0,0.9938845038414001
60862201,1215,junrao,2016-04-25T04:41:58Z,"hmm, is this right? the offset associated with the largest timestamp may not be the last offset in the time index.",0,0.9854704141616821
60862203,1215,junrao,2016-04-25T04:42:02Z,is lastoffset ever used?,0,0.991574227809906
60862208,1215,junrao,2016-04-25T04:42:09Z,should we compute maxtimestampsofar before appending to the timeindex?,0,0.9936214089393616
60862210,1215,junrao,2016-04-25T04:42:13Z,typo retrun,0,0.9586837887763977
60862213,1215,junrao,2016-04-25T04:42:21Z,not sure why we need max here since we should always be able to find a timestamp >= lasttimeindexentry.timestamp.,0,0.986214816570282
60862216,1215,junrao,2016-04-25T04:42:32Z,"not sure why we need ""the timestamp is the max timestamp before that offset.""",0,0.923547089099884
60862218,1215,junrao,2016-04-25T04:42:34Z,typo timestmaps,0,0.9829570055007935
60862221,1215,junrao,2016-04-25T04:42:38Z,larger than => larger than or equal to,0,0.9715155959129333
60862225,1215,junrao,2016-04-25T04:42:45Z,store => stored,0,0.9584681391716003
60862228,1215,junrao,2016-04-25T04:42:46Z,typo monitonically,0,0.978731632232666
60862233,1215,junrao,2016-04-25T04:43:05Z,is it worth maintaining _lasttimestamp and _lastoffset since they can be obtained from lastentry?,0,0.9950705766677856
60862237,1215,junrao,2016-04-25T04:43:17Z,"if there is no return value, the convention is not to use =. so, it will be def maybeappend() { }",0,0.9941741824150085
60862243,1215,junrao,2016-04-25T04:43:25Z,"do you mean ""timestamp can't be"" instead ""timestamp can be""?",0,0.9906226992607117
60862249,1215,junrao,2016-04-25T04:43:33Z,"timestampoffset(timestamp, offset) != lastentry seems a more expensive check. could we just check timestamp and _lasttimestamp?",0,0.9911097288131714
60862253,1215,junrao,2016-04-25T04:43:41Z,this check seems useless since _entries is calculated from mmap.position.,0,0.912542998790741
60862264,1215,junrao,2016-04-25T04:44:04Z,"hmm, not sure why this logic here is different from that in offsetindex.truncateto. if we find an index entry that matches offset exactly, it seem that we should delete that slot from the time index too.",0,0.9461238980293274
60862266,1215,junrao,2016-04-25T04:44:11Z,"the error message is only for timestamp, but the failure could be due to offset.",0,0.988819420337677
60862269,1215,junrao,2016-04-25T04:44:15Z,should 35% be 33%?,0,0.9907896518707275
60862271,1215,junrao,2016-04-25T04:44:16Z,the each => each,0,0.9387723803520203
60923190,1215,junrao,2016-04-25T14:36:11Z,"we should insert the offset corresponding to maxtimestampsofar, right?",0,0.9918729662895203
60952050,1215,becketqin,2016-04-25T17:22:10Z,this logic has been moved to `parseindexentry()` in offsetindex and timeindex. this is to make `indexslotfor()` entry format agnostic.,0,0.9954861998558044
60956589,1215,becketqin,2016-04-25T17:50:02Z,good point. i think we can use the iterator for timestamp search. we probably still need to keep a separate scan function for offset search because the iterator does not give the position. but this will be only used by offset search so there is no function argument passed in.,1,0.6926164031028748
60967454,1215,becketqin,2016-04-25T18:52:36Z,"if we check the existence of the index files before creating log segment, would it be a little difficult to distinguish between 1) the upgrade case and 2) time index file is really missing? in (1), we want to just create an empty time index without rebuilding the time index. in (2), we want to rebuild the entire time index. i am wondering in which case will we miss a index? is it only when the index is deleted manually?",0,0.9130911827087402
60968317,1215,becketqin,2016-04-25T18:57:47Z,"hmm, if we return none, what timestamp and offset response should we return to the user? we cannot simply use the log end offset or hw because it is possible the log end offset or hw has grown after the search. so it seems we should tell the caller that up until which offset we have searched?",0,0.9819552302360535
60974231,1215,becketqin,2016-04-25T19:35:42Z,"the way we index the timestamp changed a little since the original proposal. the original proposal was that a timestamp entry `(t, offset)` means the message with timestamp `t` is at `offset`. now it means that before `offset`, the largest timestmap we have seen is `t`. so the offset does not point to the message with the largest timestamp any more. the benefit of the current way is that it is a little easier to build and maintain. so in this case, we are treating the entire log segment as a big message set and assuming the last modification time is the largest timestamp in this segment. so that means before the base offset of the next segment, the largest timestamp we see in this segment is the last modification time of the segment. that is why the last time index entry in each inactive segment always points to the base offset of the next segment.",0,0.9872140884399414
60974567,1215,becketqin,2016-04-25T19:37:52Z,there is no real logic change here. i just changed the printing code format to a shorter pattern.,0,0.9748640656471252
60981807,1215,becketqin,2016-04-25T20:23:08Z,please see the previous reply. the offsets is no longer the offset of the message with maxtimestampsofar now.,0,0.9903523325920105
60982883,1215,becketqin,2016-04-25T20:29:09Z,"if the starting position is the position from the last time index entry, it is not guaranteed that we can find a timestamp >= lasttimeindexentry.timestamp.",0,0.9893032312393188
60995200,1215,becketqin,2016-04-25T21:45:14Z,"i was trying to say that when the log segment tries to append a time index entry, it is not guaranteed the timestamp of that entry is strictly larger than the timestamp of previous entries. but the offset has to be strictly larger. we probably should also check the timestamp as well.",0,0.986409604549408
60996355,1215,becketqin,2016-04-25T21:53:24Z,"this check is to avoid throwing exception in cases when we insert the last entry to the time index when the log segment is closed or rolled. in those cases, we may see attempt to insert a duplicate a time index entry whose offset is the same as the previous one. we can probably split it into two if statement.",0,0.9915137887001038
60996692,1215,becketqin,2016-04-25T21:55:58Z,actually the last check won't even be evaluated unless the previous two statement are true. not sure if performance is a concern here.,0,0.8203550577163696
60996885,1215,becketqin,2016-04-25T21:57:13Z,"_entries is a variable loaded from mmap.position when then index is created, but after that it is maintained separately. the original offset index has the check so i just left it unchanged.",0,0.9917213320732117
61005130,1215,becketqin,2016-04-25T23:04:06Z,"this is also related the to semantic meaning of the time index. because the offset in the index entry is the ""next"" offset. so if the truncated to index is the same offset in the index entry, we should keep the entry because the max timestamp corresponding to that time index entry are not truncated.",0,0.9916342496871948
61006403,1215,becketqin,2016-04-25T23:16:09Z,"if we compute the maxtimestampsofar before appending to the timeindex, we will require the lastoffset of the messages. if we do it in this way we only need the firstoffset.",0,0.9927389025688171
61188911,1215,Ishiihara,2016-04-27T00:49:44Z,the parentheses may not be needed here as this function does not have side effect. correct me if i am wrong.,0,0.8924139142036438
61188922,1215,Ishiihara,2016-04-27T00:49:50Z,maybe add another log after the file is successfully deleted.,0,0.9926024079322815
61188929,1215,Ishiihara,2016-04-27T00:49:56Z,are we always rounding up or rounding down? it would be nice to reflect that in the function name.,0,0.9821650385856628
61188934,1215,Ishiihara,2016-04-27T00:50:01Z,assume all entries are valid and set the position to the last entry,0,0.9912791848182678
61188942,1215,Ishiihara,2016-04-27T00:50:05Z,how about using a different error message? e.g. entry size exceeds max index size.,0,0.9683988690376282
61189019,1215,Ishiihara,2016-04-27T00:51:03Z,may be remove forcefully?,0,0.9932792782783508
61189107,1215,Ishiihara,2016-04-27T00:52:21Z,how bout log in the error level?,0,0.9868365526199341
61326011,1215,Ishiihara,2016-04-27T20:03:02Z,the comments of the return value are inconsistent. largest_timestamp_checked_before_target_timestamp and largest_timestamp_checked.,0,0.9912170171737671
61326015,1215,Ishiihara,2016-04-27T20:03:04Z,this equivalent as -> this is equivalent to,0,0.9688997268676758
61674500,1215,becketqin,2016-04-30T20:20:34Z,"it seems this message is warning about a wrong maxindexsize argument, but not because there are too many entries. so the error message seems right. but we can probably add the current index size in the log.",0,0.9825839400291443
61674869,1215,becketqin,2016-04-30T20:48:16Z,"this is a pre-existing comments. i am not sure if it is really a ""forceful"" free. so i just leave it as is.",0,0.726272702217102
61674895,1215,becketqin,2016-04-30T20:50:28Z,"not sure if it is needed. if something wrong happened, an exception should be thrown and we will see that in the log. otherwise it is removed successfully. so no exception = success?",0,0.9849503040313721
61676699,1215,Ishiihara,2016-04-30T23:10:43Z,it seems a bit nicer if we use string interpolation.,0,0.7356368899345398
61676701,1215,Ishiihara,2016-04-30T23:10:47Z,"again not a big deal, but we can use pattern matching to be more scala-like. [code block]",0,0.9462703466415405
61676704,1215,Ishiihara,2016-04-30T23:10:54Z,nit: comment is not aligned with code below.,0,0.9621781706809998
61676705,1215,Ishiihara,2016-04-30T23:10:57Z,"not a bit deal, but we need to import `ioexception` to make the ide happy.",0,0.6718727946281433
61684116,1215,ijuma,2016-05-01T09:09:56Z,it is true that pattern matching is a more scala-like. the suggested code is missing a case entry if the first case doesn't match though.,0,0.9915307760238647
64971303,1215,junrao,2016-05-27T21:53:50Z,unused import ioexception,0,0.9689543843269348
64971332,1215,junrao,2016-05-27T21:54:10Z,"this interface is a bit awkward. since we expect either key or value to be set, another option is to have sth like the following. protected def indexslotfor(idx: bytebuffer, target: k, boolean istargetforkey):",-1,0.850199818611145
64971340,1215,junrao,2016-05-27T21:54:17Z,the comment on return value is duplicated as the one in line 170.,0,0.989264726638794
64971410,1215,junrao,2016-05-27T21:54:58Z,could we just return the base offset in this case?,0,0.993842601776123
64971431,1215,junrao,2016-05-27T21:55:10Z,typo timestmap,0,0.9877769947052002
64971444,1215,junrao,2016-05-27T21:55:19Z,perhaps it's better to do the try/catch for each index file so that we know which one is corrupted?,0,0.9915462136268616
64971523,1215,junrao,2016-05-27T21:56:00Z,"hmm, for those segments w/o time index because they were created in 0.9, we will update the index with the last modified time. however, it seems that we didn't change maxtimestampsofar in the log segment after that since logsegmentsseq(i).loadlargesttimestamp() is called before updating the index?",0,0.9932388067245483
64971535,1215,junrao,2016-05-27T21:56:11Z,"hmm, it seems that if assignoffsets is false, we won't set maxtimestampinmessageset properly? perhaps we should initialize maxtimestampinmessageset in analyzeandvalidatemessageset()?",0,0.9657460451126099
64971545,1215,junrao,2016-05-27T21:56:15Z,returnoffsets is unused,0,0.8947256803512573
64971577,1215,junrao,2016-05-27T21:56:30Z,does the timestamp in the last message necessarily have the largest timestamp?,0,0.9925290942192078
64971583,1215,junrao,2016-05-27T21:56:33Z,no need for unit.,0,0.9737380146980286
64971598,1215,junrao,2016-05-27T21:56:37Z,no need to have unit =. there are a few other places like that.,0,0.981419563293457
64971603,1215,junrao,2016-05-27T21:56:39Z,typo retrun,0,0.9586837887763977
64971625,1215,junrao,2016-05-27T21:56:50Z,"hmm, in this case, should we return lastoffset + 1 in the segment and perhaps with a max timestamp?",0,0.9922953844070435
64971644,1215,junrao,2016-05-27T21:56:58Z,"intuitively, if there is no message, should largesttimestamp be maxlong?",0,0.911251425743103
64971662,1215,junrao,2016-05-27T21:57:06Z,perhaps we should move this comment to before line 125?,0,0.9931991696357727
64971685,1215,junrao,2016-05-27T21:57:18Z,"since there is no close() method in timeindex, we probably want to clarify that the logic of adding the last timestamp index entry is in logsegment.onbecomingactivesegment().",0,0.9948496222496033
64971723,1215,junrao,2016-05-27T21:57:40Z,typo validatd,0,0.9655337929725647
64971763,1215,junrao,2016-05-27T21:58:00Z,it seems that maxtimestamp won't be set properly if messagetimestamptype is log_append_time?,0,0.9870636463165283
64971776,1215,junrao,2016-05-27T21:58:05Z,could we update the comment with respect to the return type?,0,0.9932026863098145
64971791,1215,junrao,2016-05-27T21:58:11Z,it would be useful to add a comment explaining the return type before the method.,0,0.984399676322937
64971800,1215,junrao,2016-05-27T21:58:16Z,log timestamp => offset,0,0.9653268456459045
64971805,1215,junrao,2016-05-27T21:58:19Z,"hmm, not sure what this is for.",-1,0.8197853565216064
64972732,1215,Ishiihara,2016-05-27T22:10:04Z,the ioexception is used in scaladoc.,0,0.9894009232521057
64998112,1215,becketqin,2016-05-29T06:05:53Z,"hmm, but the key and value type might be different, so only defining the target to be the type of key seems not enough. maybe it is less awkward if have sth like: `protected def indexslotfor(idx: bytebuffer, target: indexentry[k, v], searchbyentity: indexsearchentity):` the indexsearchentity is an enumeration that is either searchbykey or searchbyvalue.",0,0.8572209477424622
64998229,1215,becketqin,2016-05-29T06:20:56Z,"actually never mind. since we only search by key, so having key is probably good enough.",0,0.7472667694091797
64998294,1215,becketqin,2016-05-29T06:29:16Z,we do search by value when truncating the time index... so maybe we still need to pass in the index entry.,0,0.9884328246116638
64998628,1215,becketqin,2016-05-29T07:16:57Z,"if there is no message after the starting point, it means we have reached the log end. ideally we should return the offset that we started to search with, but we only have position in this method. so we return none here to let the caller know that we have reached the log end and the caller will return the offset corresponding to the physical starting position.",0,0.9899554252624512
64999284,1215,becketqin,2016-05-29T08:12:38Z,i added that according to the scala coding style guide. maybe we can do a refactoring separately if we want to. [a link],0,0.9809166789054871
64999465,1215,ijuma,2016-05-29T08:27:13Z,"yeah, kafka currently deviates from that convention. i prefer the scala coding style guide way, but there isn't a strong reason either way (one way is a little more consistent, but is more verbose). so, it probably makes sense to stick with kafka's way for now as it would create a lot of diffs to change.",0,0.9370179176330566
65019054,1215,becketqin,2016-05-30T02:53:53Z,"if `log.searchfortimestamp()` returns none, that means there is no message at or after the position we started to search with. it could happen when: 1. the log segment is empty 2. the log segment is truncated after we got the position from the offset index. for case (1) maybe we should just return (notimestamp, baseoffset). for case (2) maybe we should propagate the none to the caller so the caller can retry the search. this does not completely solve the problem that we may return an offset to the user that is later truncated, but would avoid it as much as possible. does that sound reasonable?",0,0.9922283291816711
65019819,1215,becketqin,2016-05-30T03:10:57Z,"previously we don't have a concept of largest timestamp for a log segment. implicitly the largest timestamp is the last modification time. so all the logic around timestamp is built based on last modification time. with kip-33 supposedly most of the previous logic that are depending on `lastmodified()` should now be using largest timestamp. maxtimestampsofar is only updated when it sees actual timestamp in a message (except for old inactive log segments where maxtimestampsofar is always the same as last modification time and does not change). i am thinking to leave `lastmodified()` as it is but replace the external usage of `lastmodified()` with `largesttimestamp()`. `largesttimestamp()` prefers to use the maxtimestampsofar if it exists, but falls back to lastmodified if no message has a timestamp, such that the external logic would be the same for all segments no matter whether they contains timestamp or not. i may have missed some usages of `lastmodified()` in the current patch. i will fix that in the coming patch.",0,0.984616219997406
65023366,1215,becketqin,2016-05-30T04:55:32Z,"this is printing out the mismatches. the first timestamp is the timestamp in the index, and the second timestamp is the mismatch timestamp in the log. so the printed string seems correct?",0,0.9931228756904602
65023563,1215,becketqin,2016-05-30T05:01:36Z,"i was trying to list the offsets of the mismatch timestamp index entry. but the format seems wrong, i am thinking of something like the following: when timestamp does not match. `timestamp: 1000 (log timestamp: 2000) offset: 100` when timestamp and offset both do not match `timestamp: 1000 (log timestamp: 2000) offset: 100 (log offset: 200)`",0,0.9361365437507629
65999852,1215,junrao,2016-06-07T02:00:58Z,would it be better to name this searchtype?,0,0.9926605224609375
65999868,1215,junrao,2016-06-07T02:01:09Z,"hmm, this may not be reliable. could we just compare this to (long) int.max?",0,0.8440612554550171
65999871,1215,junrao,2016-06-07T02:01:13Z,unused import,0,0.9524969458580017
65999886,1215,junrao,2016-06-07T02:01:27Z,"to be consistent with the code, maxtimestamp should be before timestamp. also, timestamp is too generic and it's not clear what it really means. how about rename it to logappendtime?",0,0.9394727945327759
65999931,1215,junrao,2016-06-07T02:02:11Z,"hmm, this means that when upgrading, we are forced to scan all existing log segments since they won't have the timeindex. could we just create an empty timeindex file in this case? see my other comment in logsegment on whether it's useful to always have a non-empty timeindex.",0,0.9339543581008911
65999965,1215,junrao,2016-06-07T02:02:42Z,"hmm, we should be checking timeindex.entries instead of maxentries, right?",0,0.9821891188621521
65999990,1215,junrao,2016-06-07T02:03:12Z,"hmm, is the while loop necessary? it seems that if foundoffset is none, we can just return baseoffset of next segment or nextoffset if the search is on the active segment. also, if we have an empty log, do we loop forever?",0,0.9604488015174866
66000164,1215,junrao,2016-06-07T02:05:21Z,"in the proposal of kip-33, we changed the behavior of log rolling to be that if the largesttimestamp in the segment hasn't changed for the log rolling time, we will roll another log segment. thinking about this a bit more, i am wondering if it's better to preserve the current log rolling logic based on the log segment create time. the current behavior provides a nice property that a log segment is guaranteed to be rolled within certain amount of time. this is useful since there are use cases where people may have some sensitive data that has to be deleted or cleaned after certain amount of time. the new behavior will make this harder to enforce since the active segment is never deleted or cleaned and there is no time bound on when the new segment can be rolled. the log deletion policy can still be based on the timestamp in the message.",0,0.9621110558509827
66000207,1215,junrao,2016-06-07T02:06:06Z,extra space before *,0,0.9754075407981873
66000218,1215,junrao,2016-06-07T02:06:19Z,extra space before *,0,0.9754075407981873
66000237,1215,junrao,2016-06-07T02:06:33Z,should we append nextoffset or baseoffset here?,0,0.9935008883476257
66000245,1215,junrao,2016-06-07T02:06:39Z,extra space before *,0,0.9754075407981873
66000271,1215,junrao,2016-06-07T02:06:58Z,"hmm, if none of the message has timestamp, should we include the offset of the first message in the segment?",0,0.9489371180534363
66000275,1215,junrao,2016-06-07T02:07:04Z,we should document when we return none.,0,0.979401707649231
66000282,1215,junrao,2016-06-07T02:07:08Z,foundtimestampoffsetopt is unused.,0,0.9806066155433655
66000320,1215,junrao,2016-06-07T02:07:44Z,"currently, we have the logic to force adding an index entry (with last modified timestamp) if none of the message has timestamp. i am wondering why this is necessary. it seems that we can just leave the timeindex empty in that case and largesttimestamp() can still return lastmodified? that may make the log recovery logic a bit simpler.",0,0.9667240977287292
66000326,1215,junrao,2016-06-07T02:07:49Z,unused import,0,0.9524969458580017
66000354,1215,junrao,2016-06-07T02:08:10Z,"the comment here says insert a time index entry with the last modified time and the base offset. however, in logsegment.onbecomeinactivesegment(), we insert the next offset, not the base offset. it seems that inserting the base offset makes sense.",0,0.9945914149284363
66000366,1215,junrao,2016-06-07T02:08:23Z,is the comment accurate? maybeappend() may see the same timestamp as long as no new messages have a larger timestamp.,0,0.991219699382782
66000386,1215,junrao,2016-06-07T02:08:43Z,"the comment is not accurate. we don't return a number of entries. also, we are trying to find an entry with timestamp >= than targettimestamp",0,0.8009141087532043
66000434,1215,junrao,2016-06-07T02:09:22Z,"we will need to explain the output better. perhaps when we print ""mismatches in :"" , we can say these are cases where the timestamp in the wrapper message doesn't match the inner. also, it would also be useful to capture errors in which the timestamps are not increasing in the index.",0,0.9853206276893616
66187001,1215,becketqin,2016-06-08T03:13:26Z,"the assumption here is that `this.start + position` is a positive integer, and `size` is also a positive integer. when you say not reliable, do you mean `this.start + position` can also overflow?",0,0.9909713268280029
66188197,1215,becketqin,2016-06-08T03:34:23Z,"the current code actually creates the time index file in line 195 when it instantiate the logsegment. so the else branch seems never be called. i asked that question earlier and you suggested that we can check the index existence before we instantiate the logsegment. but the problem of that is we are not able to distinguish between 1) upgrade case and 2) the time index is missing. we want to create an empty index in case 1) and want to rebuild the time index in case 2). i thought case 2) only occurs when the time index is manually deleted, which is rare. therefore i left the code as it is, i.e. always create an empty time index when it is missing. this is essentially assuming that when a time index is missing it is the upgrade case.",0,0.9821721911430359
66188736,1215,becketqin,2016-06-08T03:46:00Z,"this is to make sure the time index file is not resized to zero so it can hold at least one time index entry. but putting the check here is a little confusing, i will move it into ensurenonemptytimeindex().",0,0.9467839598655701
66296450,1215,becketqin,2016-06-08T17:06:48Z,"i am not sure if we have the same guarantee even if we still let the log rolling based on the log segment create time. there are a few issues, 1. when the timestamp type is createtime, the messages in the segment may have older timestamp than the create time of the log segment. so the log rolling may still be delayed from the application perspective. 2. in some linux system, the create time of a file is not available. so based on segment file create time may not always work. i am thinking that maybe we can just let the log rolling based on the timestamp of the first time index entry. we can always insert an index entry when the first message is appended to the log segment. this provides similar guarantee of the previous log rolling and does not have the above two issues. what do you think?",0,0.8008919358253479
66299695,1215,becketqin,2016-06-08T17:25:05Z,"the main idea behind this while loop is to make sure we give user a good offset to our best effort. `targetseg.findoffsetbytimestamp()` only returns none when log truncation occurred after we find the physical position by looking up the offset index. in that case, the may be no message after the physical position because it could have been truncated. we cannot return the nextoffset in that case because it is possible that some new messages have been appended after `targetseg.findoffsetbytimestamp()` returns. we haven't checked the timestamp of those messages, so returning nextoffset in this case might result in skipping messages with larger timestamp. that said, this case should be very rare because truncation usually only occurs on the followers, so they should not server offset request. however, if we have a fast leadership fail over and failback, it could still happen. when the log segment is empty, baseoffset is returned by `targetseg.findoffsetbytimestamp()`.",0,0.9874733686447144
66301258,1215,becketqin,2016-06-08T17:32:07Z,"i was thinking the semantic meaning of this is that the timestamp of the last message in the segment is lastmodified. but you are right that during a search by timestamp, we would want to start from the base offset.",0,0.9752576947212219
66302572,1215,becketqin,2016-06-08T17:39:05Z,i think we do return the offset of the first message if none of the messages has timestmap.,0,0.9857977032661438
66318868,1215,junrao,2016-06-08T19:04:05Z,"right, could this.start + position overflow to a negative value and then + size bring it to positive again?",0,0.9846200942993164
66319046,1215,junrao,2016-06-08T19:05:03Z,"interesting. then, in the code, perhaps we should just get rid of the check of the existence of the offset and the time index files since they are guaranteed to be present after logsegment is created? i agree the case that people manually delete the index files is rare.",0,0.910923421382904
66319077,1215,junrao,2016-06-08T19:05:14Z,"ok, perhaps we can add this in the javadoc.",0,0.9923813939094543
66319260,1215,junrao,2016-06-08T19:06:23Z,"ok, perhaps we can add some comments to make it clear why we need to do the loop. a related question is what happens when there is no offset whose timestamp is >= than the target timestamp? should we return the log end offset or sth like -1? if it's the former, the user may not know the fact that there is no offset with a larger or equal timestamp.",0,0.9907693266868591
66319334,1215,junrao,2016-06-08T19:06:48Z,"yes, what you suggested sounds like a good idea. i would just modify that slightly to do the time-based rolling based on the timestamp of the first message in the segment. we probably want to update the kip wiki and bring this up in the mailing list to see if people have any concern about the change.",0,0.9211633205413818
66376458,1215,becketqin,2016-06-09T03:05:27Z,"theoretically it is possible. but if it is a log segment it seems not possible because the `this.start` would be 0, so it is essentially `position + size`. i don't know if we ever call `read()` on a sliced filemessageset.",0,0.9858981370925903
66377571,1215,becketqin,2016-06-09T03:22:58Z,"thought about this a little more, it seems that it would be better to append the nextoffset - 1. the offset is essentially used in two cases: 1) search by timestamp 2) log truncation. for case 1, the previous behavior was that if the target timestamp is greater than the lastmodified, we will simply start from the next segment. this behavior will be changed if we append the baseoffset here. i.e. user needs to start consume from the beginning of this segment instead of the beginning of next segment. for case 2, if an inactive log is truncated and becomes the active log segment again, we will want to truncate the time index entry as well, if we append the nextoffset -1 here, the time index will also be truncated. but if we append baseoffset here, the time index entry won't be truncated.",0,0.9896492958068848
66479759,1215,becketqin,2016-06-09T16:58:29Z,"the patch currently returns log end offset if there is no offset whose timestamp is greater than the target timestamp. i am wondering in which case user would want to know there is no timestamp greater or equals to the target timestamp? currently, user can always start consuming from the returned offset and it is guaranteed that no message with larger timestamp will be missed. if we return -1, what user would do in that case? they can not seek to the end because after we return -1, some messages with larger timestamp could have been appended so consuming from log end offset will miss those messages.",0,0.9616660475730896
66480437,1215,becketqin,2016-06-09T17:02:43Z,"yes based on the timestamp of the first message sounds good. more precisely the time based log rolling will be based on the first message that has a timestamp if there is at least one such message. if there is no message that has a timestamp, the time based log rolling will be based on the create time, which is the same as previous behavior.",0,0.970829427242279
66536970,1215,junrao,2016-06-09T23:00:02Z,"yes, that sounds reasonable.",0,0.9470524787902832
66540277,1215,junrao,2016-06-09T23:33:48Z,"i looked at the commit history on this class a bit more. it seems that the existing logic is because of a bug introduced in kafka-2012. we should check the existence of the offset index file before instantiating a logsegment, not after. then, if the offset index is missing, we will rebuild the index. so, perhaps we can fix the logic here as the following. (1) if offset index is missing, rebuild both indexes. (2) if only the timeindex is missing, create an empty timeindex file (i.e., assuming that it's an old segment from pre-v10).",0,0.9937788844108582
66561253,1215,becketqin,2016-06-10T04:45:37Z,"that is a good point. i think it should work. there is a slight difference. the current patch essentially takes a snapshot of the timestamp when last message is appended to the log segment. so even if user touched the segments later and changed the modification time, it does not affect the log retention. if we change the behavior to only use lastmodified of the file, it could change if user touch the file later. i remember our sre used to do touch the file for some reasons, but i am not sure if this is an important difference.",0,0.6213626265525818
66561646,1215,becketqin,2016-06-10T04:54:58Z,i see. that sounds reasonable to me.,0,0.9724356532096863
66696679,1215,junrao,2016-06-11T00:21:04Z,"yes, after the producer upgrades to 0.10, all new messages will have a timestamp and the time-based retention will be more accurate. for the old messages, the current behavior is to use the current last modified time for retention. we don't really have to improve it if that makes the new code simpler.",0,0.9912031888961792
67100177,1215,junrao,2016-06-15T05:05:33Z,"this iterator actually copies the key and value from the file channel to the buffer. for searching timestamp, we could do a special iteration that just copies the header part (like how we do in search by offset). we need to think through whether it's worth specializing.",0,0.9891566038131714
67100215,1215,junrao,2016-06-15T05:06:14Z,"hmm, is that true? the segment could have messages with and w/o timestamp. stopping early may prevent us from finding the offset with the timestamp that we want.",0,0.8045017123222351
67100246,1215,junrao,2016-06-15T05:06:25Z,"in this case, should we really maxtimestampchecked since it is not really associated with lastoffsetchecked + 1?",0,0.9930423498153687
67100351,1215,junrao,2016-06-15T05:06:48Z,"do we need to duplicate the code for index and timeindex? since both indexes are of abstractindex, perhaps we can just iterate two abstractindex in a loop and do the sanitycheck and recover in the loop (we may need to add a absolutepath() method in abstractindex).",0,0.99381422996521
67100430,1215,junrao,2016-06-15T05:07:17Z,it's a bit awkward to have to create logsegment here and in line 196. we can avoid that by just doing sth like the following val indexexist = indexfile.exists() segment = new logsegment(...) if (indexexist) else,-1,0.9254373908042908
67100453,1215,junrao,2016-06-15T05:07:40Z,"for segments where no message has timestamp, should we really use last modified time?",0,0.9931499361991882
67100460,1215,junrao,2016-06-15T05:07:43Z,typo timestaamp,0,0.9788845777511597
67100462,1215,junrao,2016-06-15T05:07:47Z,an => a,0,0.8990496397018433
67100482,1215,junrao,2016-06-15T05:08:04Z,"it seems that we can retain the tombstone using the message timestamp, instead of segment time. we can file a separate jira to track that.",0,0.993030846118927
67100485,1215,junrao,2016-06-15T05:08:09Z,no need for extra space before startms,0,0.9841585159301758
67100491,1215,junrao,2016-06-15T05:08:13Z,maxtimestampsofarbeforeappend is never used.,0,0.9787623286247253
67100692,1215,junrao,2016-06-15T05:10:25Z,"do we have to append the timestamp for the first message to the index? if so, we are not doing that consistently in recover(). for log rolling, it seems that we can just track the timestamp of the first message (if notimestamp, just use the create time) during startup or append w/o needing the index entry.",0,0.9942402839660645
67100718,1215,junrao,2016-06-15T05:10:48Z,"if we update offsetofmaxtimestamp, don't we need to update offsetofmaxtimestamp accordingly?",0,0.9945802092552185
67100724,1215,junrao,2016-06-15T05:10:55Z,could we improve the text to make it clearer how the index is corrupted?,0,0.9789257049560547
67100745,1215,junrao,2016-06-15T05:11:19Z,"there is inconsistency in the caller of maybeappend(). some of them does [code block] and some others don't do the check. it would be better if we can do this consistently. it seems if maybeappend() just ignores negative timestamp, the caller doesn't have to do the check anymore.",0,0.9908738136291504
67100751,1215,junrao,2016-06-15T05:11:26Z,this comment is a bit weird in that it tries to explain things that we don't do. is it useful?,-1,0.9632745385169983
67100757,1215,junrao,2016-06-15T05:11:31Z,could we improve the text to make it clearer how the index is corrupted?,0,0.9789257049560547
67100764,1215,junrao,2016-06-15T05:11:34Z,on => one,0,0.9484579563140869
67100776,1215,junrao,2016-06-15T05:11:44Z,"hmm, not sure why we need to have the while loop here. aren't we just loop the same wrappermessageopt over and over?",-1,0.7305881977081299
67100784,1215,junrao,2016-06-15T05:11:51Z,this should probably go to stderr as those mismatches.,0,0.9518280625343323
67398599,1215,becketqin,2016-06-16T18:26:01Z,"hmm, i actually did that in my first patch. `searchforoffset()` and `searchfortimestamp` were sharing a `scanandhandlemessages()` function that does a special iteration by only looking at the headers. you suggested maybe we can just use the iterator in the comments and i thought it was a good suggestion because of the following reasons: 1. search by timestamp is a very infrequent call. 2. unlike searching by offset, searching by timestamp do need to look into the payload if the message is a compressed message. so copy the value into the buffer seems reasonable. 3. because we have the index, the number of bytes we read from the disk should be relatively small assuming the timestamps are not abnormal. so it seems not worth duplicating the code of the iterator here?",0,0.9538949131965637
67426111,1215,becketqin,2016-06-16T21:20:15Z,"yes, stopping early means we may not find the exact offset with a timestamp that we want. but it will not miss that message. in reality, a log segment may have messages w/ and w/o timestamp because some of the producers have been upgraded and others have not. what concerns me of not stopping when see old message is that if we don't have any message w/ a timestamp (or the timestamp we wanted locates close to the end of the log segment), we may end up with scanning the entire log segment. that will pollute the memory and impact the performance. since we are not appending a time index entry to the time index for the first message with a timestamp in a segment. can we do the following? 1. in `timeindex.lookup()`, when slotfor() returns -1 in the timeindex, we can just return the offset of the first entry instead of baseoffset (the offset will be baseoffset if the first message has a timestamp). this will essentially skip all the earlier messages w/o a timestamp in the log segment. if the time index is empty, we still return baseoffset. 2. in `searchfortimestamp()` we keep searching when we see message w/o a timestamp until we find the timestamp. the only risk is that if two indexed offset in the time index are far away, we may still be scanning the entire log. for example, if message 0 has a timestamp 100, message 100000 has timestamp 200. when people are searching for timestamp 150, we will scan the message from 0 to 100000. but this should be rare.",0,0.8413712978363037
67427456,1215,becketqin,2016-06-16T21:28:46Z,"currently this method returns the `maxtimestampchecked` and the `nextoffsettoread`, so it is not the exact timestamp to offset mapping. do you think it would be better to return a tuple `(timestamp, offset)` instead of a `timestampoffset`?",0,0.9937963485717773
67445751,1215,becketqin,2016-06-17T00:17:41Z,it seems reasonable to use the last modification time as the biggest timestamp of the segment. do you have any specific concern?,0,0.9874745607376099
67449438,1215,junrao,2016-06-17T01:12:15Z,"ok, sounds good. we can leave this as it is. sorry for going back/forth on this.",-1,0.9813258647918701
67449469,1215,junrao,2016-06-17T01:12:49Z,"1. slotfor returns -1 only when the timeindex is empty. in the case, the largest timestamp of the segment is notimestamp. so, this segment shouldn't need to be search since notimestamp is smaller than any target timestamp, right 2. yes, not sure how common the case you described can happen. given that search by timestamp is infrequent, perhaps scanning more is ok?",0,0.980668306350708
67449480,1215,junrao,2016-06-17T01:12:56Z,it doesn't seem timestamp is used by the caller. could we just return option[long]?,0,0.9899215698242188
67449925,1215,becketqin,2016-06-17T01:19:39Z,"if a log segment has messages w/ and w/o timestamp, the first message in a log segment may not always have the timestamp. so it seems we still need to store the timestamp of the first message that w/ a timestamp somewhere, right? or do you mean we only look at the timestamp of the first message to determine whether to use the message timestamp or segment create time?",0,0.9894484281539917
67454855,1215,becketqin,2016-06-17T02:48:30Z,i am not sure how to make the text clearer. it seems we have already specifically stated the problem?,-1,0.7526592016220093
67455183,1215,becketqin,2016-06-17T02:55:00Z,i added this because offset index will throw exception if we attempt to insert an offset index entry whose offset equals to the previous offset. i am trying to avoid confusing future contributors here by adding these comments.,0,0.9889454245567322
67455678,1215,becketqin,2016-06-17T03:04:39Z,"the wrappermessageopt will be updated in line 206. we need to do this because if user is producing uncompressed messages, a ""batch"" would actually be multiple messages. the first message in the batch may not always have the the largest timestamp. so we need to scan a little. we should be able to find the indexed timestamp before the next indexed offset in the time index or the log end, whichever comes first.",0,0.9898994565010071
67554576,1215,becketqin,2016-06-17T18:25:35Z,"1. slotfor also returns -1 if the timestamp is smaller than the first indexed timestamp. so the case i described is something like the following: say we have 1 gb log segment, the first message w/ a timestamp is offset 1234567 at position 900mb. and the timestamp is 1000. so the first time index entry will be (1000, 1234567) in this case. now if user come and search for timestamp 100, `indexslotfor` will return -1, and currently we will return baseoffset if `indexslotfor` returns -1. so we will scan the log from base offset and page 900 mb into memory. if we return the offset in the first time index entry. we don't need to scan the previous 900 mb in that segment. because we know that there is no timestamp before the offset of the first indexed offset in the time index, there is no need to scan that. in another scenario, if the time index is empty, that means there is no timestamp in the segment. but in that case `logsegment.largesttimestamp()` will return the last modification time. so `log.fetchoffsetsbytimestamp()` will not skip the segment but treat it the same way as the segments that have timestamps. this essentially means at log level, we people search for we do not distinguish between the largesttimestamp from the message timestamp or the largesttimestamp from last modification time. they provides a unified experience to the users. are you suggesting that we always ignore the old messages completely in the new way of searching for timestamp. i am worried about the transition period regarding that approach. for example, say some user is now using the timestamp search at segment granularity. if they want to consume all the data after 8:00 am, they can start to consume the data after the segment whose last modification time is before 8:00 am. there may be duplicates but it works. now the users upgraded to new consumer which search for timestamp based on message timestamp, suddenly we skip all the old segments and they always get log end offsets. that was also why i am not sure if we should skip the old messages or we should just stop on seeing old messages. 1. i agree the case i described would be rare, so scanning until we find timestamp should be fine.",0,0.9884850978851318
67583237,1215,junrao,2016-06-17T22:21:08Z,"thanks for the explanation. 1. yes, i agree that it's better to use last modified time for segments with no timestamp. so, if all messages have notimestamp, the semantic is that the search will return the offset of the first message in the segment whose last modified time is >= the target timestamp. 2. if a segment has messages with and w/o timestamp, to find the message matching the precise timestamp may require us scan most the segment, but is probably ok since it's rare. it would be useful to document the semantics in the comment above log.fetchoffsetsbytimestamp() on those corner cases.",1,0.7921364903450012
67583244,1215,junrao,2016-06-17T22:21:13Z,"ok, this is fine then.",0,0.8976935744285583
67583312,1215,junrao,2016-06-17T22:21:47Z,"yes, i was thinking of just looking at the timestamp of the first message. if it doesn't have timestamp, we use create time. this is probably simpler than having to force an index entry on first message with timestamp. for those segments with a mix of valid timestamp and notimestamp, we can decide whether the rolling will be based on the old or the new behavior. either is fine, but we probably want to pick one that's easier to implement.",0,0.9888206124305725
67583331,1215,junrao,2016-06-17T22:21:59Z,"corrupt index found, index file (%s) has non-zero size and the last offset is %d is not larger than the base offset is %d",0,0.9783840179443359
67583348,1215,junrao,2016-06-17T22:22:18Z,"got it. then, is it enough to read only maxmessagesize from the log? it seems that we may need to scan to the end of the log to find the message that we are looking for.",0,0.9922502636909485
67591522,1215,becketqin,2016-06-18T00:40:28Z,"yes, you are right. we do need to read till the end of the log.",0,0.9399430155754089
67594888,1215,becketqin,2016-06-18T03:53:16Z,"just want to make sure i understand the behavior we want here. it seems that sometimes we want to skip the messages w/o timestamps, and sometimes we don't skip. for example, if we have two log segments: segment 0: baseoffset=0, no message has timestamp, last offset 99, last modified=1000. segment 1: baseoffset=100, the first message with a timestamp is at offset 105, and the timestamp is 2000. the second message with a timestamp is at offset 150, and the timestamp is 3000. now if we search for timestamp 1500, it looks that we should return offset 100, i.e. we should not ignore messages 100 - 104 that do not have timestamps, even though the timestamp we wanted is at offset 105. on the other hand if we search for timestamp 2500, it seems that we will skip the messages 106 - 149 because they don't have timestamps. it seems a little weird that we treat the messages w/o timestamps differently depending on where the messages are. do you think that is the behavior we want or it would be better if we have a consistent behavior regarding messages w/o timestamps? previously i am taking the approach that we always don't skip the messages w/o timestamps. but that does mean we may not able to return the exact message with the timestamp we wanted. what do you think?",0,0.9881299734115601
67604184,1215,junrao,2016-06-18T17:46:39Z,"hmm, i was thinking that if you search for timestamp 1500, we will return offset 105 since that's the first message whose timestamp is >= 1500. similarly, if you search for timestamp 2500, we will return offset 150. in the case where a segment has no timestamp (we know that from largesttimestamp), we can optimize by not scanning the whole segment and just return the offset of the first message in the segment. otherwise, we will just scan the segment as much as needed.",0,0.982539176940918
67605816,1215,becketqin,2016-06-18T19:57:05Z,"if we return 105 when search for 1500, would that cause problem for the transitional period? previously user will consume from 100, which may be the messages they actually wanted. once they switch to new timestamp search, the user will not see message 100 - 104 any more. in our example there are only 5 messages, but in real world there could be more. it looks there is a trade-off we need to make between backward compatibility and accuracy of search. i am not sure how critical the backward compatibility here is. personally i feel that when there are mixture of messages with and w/o timestamps, backward compatibility seems more important. because the accuracy will increase when more and more messages contains timestamp. and we will have the full accuracy once the users have fully rolled out the new message format.",0,0.6858127117156982
67625139,1215,junrao,2016-06-19T22:34:37Z,"to me, it seems that we just need to preserve compatibility when things are comparable. for example, if a segment has no message with timestamp, it makes sense to use the old behavior, i.e., treating all messages in the segment as if they have the last modified time. if a segment has messages with and w/o timestamp, it's not directly comparable with the old behavior. it seems to me that simply finding the first message with a timestamp >= than the target is easy to understand. stopping at the first message with notimestamp seems harder to explain since it depends on where those messages are and what the indexing interval is. in any case, we probably need a separate kip to expose the timestamp search in an api. we can discuss more and finalize the decision then.",0,0.9545459747314453
67625332,1215,becketqin,2016-06-19T22:51:54Z,"i see. i will create another kip then. the concern i have is that from user's perspective, they don't really care or know which segment the messages go into. they only want to make sure that all the messages produced after a certain timestamp **t** will be consumed. previously the offsets we return to the user are based on last modification time at segment level. it seems that now when we have old messages without timestamps, we should still keep the previous behavior.",0,0.9425032734870911
67796773,1215,junrao,2016-06-21T01:49:35Z,the previous indentation seems correct?,0,0.9902458190917969
67796777,1215,junrao,2016-06-21T01:49:41Z,do we need loadedsegment at all? it seems that loadedsegment is always segment.,0,0.9932982325553894
67796798,1215,junrao,2016-06-21T01:49:54Z,"could we get rid of indexortimeindex and change warn to log ""found corrupted index due to e.getmessage() ...""? the message in the exception tells us the file name, which should be good enough.",0,0.9939915537834167
67796809,1215,junrao,2016-06-21T01:50:01Z,the comment is not accurate. the rolling is now based on the timestamp of the first message.,0,0.975609540939331
67796815,1215,junrao,2016-06-21T01:50:05Z,do we need the extra new line?,0,0.9884954690933228
67796820,1215,junrao,2016-06-21T01:50:09Z,do we need the extra space before startms?,0,0.9888167381286621
67796828,1215,junrao,2016-06-21T01:50:16Z,the comment seems in the wrong location.,0,0.7445826530456543
67796839,1215,junrao,2016-06-21T01:50:24Z,unused val maxtimestampsofarbeforeappend,0,0.9783911108970642
67796844,1215,junrao,2016-06-21T01:50:28Z,this comment seems in the wrong location now.,0,0.6860643625259399
67796889,1215,junrao,2016-06-21T01:50:59Z,"this forces us to read one message from every log segment during clean startup, which may incur additional i/os. another way is to calculate rollingbasetimestamp lazily when timewaitedforroll() is first called and then remember it. this will avoid the potential extra i/os.",0,0.9828265905380249
67796907,1215,junrao,2016-06-21T01:51:14Z,"if we update maxtimestampsofar, don't we need to update offsetofmaxtimestamp accordingly? otherwise, the next time we add an entry to the time index, the offset may not match maxtimestampsofar.",0,0.9944103360176086
67796913,1215,junrao,2016-06-21T01:51:20Z,"to be more precise, we are not adding the last, but the largest time index entry.",0,0.9873600602149963
67796920,1215,junrao,2016-06-21T01:51:23Z,the comment seems inaccurate.,-1,0.9242519736289978
67796925,1215,junrao,2016-06-21T01:51:29Z,the comment is no longer accurate now that we only return offset.,0,0.9847308397293091
67796958,1215,junrao,2016-06-21T01:51:46Z,"more precisely, the comment should be ""get the index entry with a timestamp less than or equal to the target timestamp"".",0,0.9922232031822205
67796971,1215,junrao,2016-06-21T01:51:55Z,could we use file.getabsolutepath instead file.getname here to make it consistent?,0,0.9950574636459351
67796980,1215,junrao,2016-06-21T01:52:01Z,that means the we => that means we,0,0.9211532473564148
67796995,1215,junrao,2016-06-21T01:52:12Z,"is the comment still accurate? we don't insert the last modification time of the file to the time index, right?",0,0.9893513321876526
67797002,1215,junrao,2016-06-21T01:52:19Z,we want to find the time index entry whose timestamp is less than or equal to the given timestamp.,0,0.9867919683456421
67797008,1215,junrao,2016-06-21T01:52:24Z,could we use file.getabsolutepath instead file.getname here to make it consistent?,0,0.9950574636459351
67797017,1215,junrao,2016-06-21T01:52:33Z,that may require a large heap for the tool. could we read messages in chunks up to maxmessagesize?,0,0.9719378352165222
67797065,1215,junrao,2016-06-21T01:53:06Z,"it seems that we just need to print timestamp and offset in the index. not sure why we need to print s""(log timestamp: $maxtimestamp)"" and s""(log offset: ${partialfilemessageset.head.offset})"".",0,0.9801422357559204
67797070,1215,junrao,2016-06-21T01:53:09Z,typo indexs,0,0.9829057455062866
67797073,1215,junrao,2016-06-21T01:53:11Z,typo indexs,0,0.9829057455062866
67968372,1215,junrao,2016-06-21T23:03:13Z,"hmm, is that right? the rolling check happens before the append. so, the first message in the segment is ""set"", which has notimestamp. then, we will be using the creation time of the segment. so, it seems that in the case, we should roll another segment after calling append() in line 94.",0,0.9914127588272095
67968389,1215,junrao,2016-06-21T23:03:19Z,"hmm, do we need the if test since the baseoffset is 0?",0,0.9797183275222778
67968395,1215,junrao,2016-06-21T23:03:22Z,the comment is no longer accurate.,0,0.7255185842514038
67968397,1215,junrao,2016-06-21T23:03:25Z,unused val msgperseg,0,0.9567977786064148
67968464,1215,junrao,2016-06-21T23:04:08Z,"hmm, shouldn't we populate messages of format 0.9.0 here since we want to set message format to 0.9.0 later?",0,0.9801872372627258
67968484,1215,junrao,2016-06-21T23:04:20Z,"to trigger the rebuild of the index, don't we need to set recoverypoint to 0?",0,0.9948722720146179
67968492,1215,junrao,2016-06-21T23:04:24Z,unused import,0,0.9524969458580017
67968503,1215,junrao,2016-06-21T23:04:31Z,"hmm, why will the append hit the exception here? the timestamp seems larger than the ones in the index.",0,0.6766135096549988
67968517,1215,junrao,2016-06-21T23:04:37Z,"hmm, not sure why we will hit the exception since the offset to be appended is larger than the ones in the index.",0,0.515781581401825
67968523,1215,junrao,2016-06-21T23:04:41Z,this is no longer accurate.,0,0.5845196843147278
67968533,1215,junrao,2016-06-21T23:04:48Z,"is ""might"" accurate? it seems it should be ""will"".",0,0.990426778793335
67968542,1215,junrao,2016-06-21T23:04:52Z,offset index => offset index entry,0,0.9810283780097961
67968550,1215,junrao,2016-06-21T23:04:55Z,this is no longer true.,0,0.9678940176963806
68103620,1215,becketqin,2016-06-22T18:02:49Z,"not sure i fully understand this. it seems we need to read the first message from the file anyway, whether at the startup time or when the first message is appended after startup. if the first message received after startup and the first message in the segment resides in the same disk block, we only page in once. otherwise we still need to page in two blocks. so it seems the disk i/os are the same? do you mean we can save the disk i/o if there is no message appended to a partition after startup?",0,0.9493124485015869
68108307,1215,becketqin,2016-06-22T18:28:10Z,"hmm, i think filemessageset.read() only set a start position and end position. it does not really read anything into the heap, right? this is just allow the iterator to iterate until the end of the segment. it seems not creating any additional memory pressure.",0,0.9447833895683289
68109192,1215,becketqin,2016-06-22T18:32:30Z,"i was thinking this easier for user to find out what when wrong. when i run this command, i found it is a little ugly that we have to switch between the dumped errors and the printed index entries.",-1,0.9464187622070312
68109601,1215,becketqin,2016-06-22T18:34:34Z,"ah... sorry for the confusion, i changed the assertion expected value but forgot to change the assertion message.",-1,0.9903557300567627
68111083,1215,becketqin,2016-06-22T18:42:13Z,"logically the first message appended to a log segment does not cause the insertion of index entries, so searching for the timestamp of the first message should give base offset. but in our case the base offset happened to be the same as the offset of our first message.",0,0.9922101497650146
68111692,1215,becketqin,2016-06-22T18:45:29Z,it does not really matter whether we append message in 0.9.0 or 0.10.0 format because the log segment will do down conversion when the message is appended if the format is 0.10.0,0,0.9922584891319275
68112128,1215,becketqin,2016-06-22T18:47:50Z,"in our case, we will have corrupted log index, so no matter what recovery point it is, the index will be deleted and rebuilt.",0,0.9682044982910156
68112512,1215,becketqin,2016-06-22T18:49:59Z,this is because the time index entry is already full. we only allow maxentries - 1 entries to be appended if skip full check is set to false (which is the default value).,0,0.9936445951461792
68113246,1215,becketqin,2016-06-22T18:54:01Z,"our base offset is 45l, max entries = 30l. the offset of the last time index entry is (30 - 1) \* 10 + 45 = 335. we are appending an entry with offset (30 - 2) \* 10 = 280. so it is smaller.",0,0.9916195869445801
68166110,1215,junrao,2016-06-23T02:06:26Z,"mayberoll() is only called on the active segment. so, if we get first message on demand when mayberoll() is called, we can avoid reading the first message on all old segments.",0,0.9936948418617249
68166173,1215,junrao,2016-06-23T02:07:29Z,"good point. so, this is not an issue then.",1,0.9323834180831909
68166576,1215,junrao,2016-06-23T02:14:25Z,"but the log is not configured with 0.9.0 message format when the append happens, right?",0,0.9831063747406006
68167173,1215,junrao,2016-06-23T02:24:51Z,"got it. sorry, i thought the first field is the offset.",-1,0.9920374155044556
68244074,1215,becketqin,2016-06-23T14:26:12Z,got it. thanks for the explanation. that makes sense.,1,0.8002085089683533
68244889,1215,becketqin,2016-06-23T14:30:19Z,"ah, you are right. sorry i was reading the lines below this, which is recovering the log.",-1,0.9931856393814087
68306815,1215,ijuma,2016-06-23T20:16:47Z,doing this means that `comparekey` and `comparevalue` will cause boxing to take place. two ways to fix this: - use `` although it's a bit hard to know when the optimisation is not applied - use `long` everywhere when doing the comparisons,0,0.9749206304550171
68307091,1215,ijuma,2016-06-23T20:18:40Z,`java.util.long.compare`?,0,0.9927803874015808
68307419,1215,ijuma,2016-06-23T20:20:40Z,how can we say it is fully compatible and then say that there are `potential breaking changes`?,0,0.9886701107025146
68307613,1215,ijuma,2016-06-23T20:21:50Z,"for the two above, it would probably be useful to say what the previous behaviour was as well.",0,0.976764976978302
68308726,1215,ijuma,2016-06-23T20:28:32Z,`asinstanceof` and `anyval` are generally avoided in scala as there is usually a cleaner and safer way to do things. maybe `indexslotfor` should take a function that does the comparison?,0,0.9945723414421082
68313140,1215,ijuma,2016-06-23T20:54:35Z,"this is a bit odd, why not the standard `int mid = (low + high) >>> 1`?",-1,0.8149696588516235
68313919,1215,ijuma,2016-06-23T20:58:58Z,"a micro-optimisation is to leave this as the last `else` as we return once it succeeds. statistically, we are more likely to hit the other branches more times.",0,0.9895306825637817
70016160,1215,junrao,2016-07-08T01:51:20Z,timebased => time-based,0,0.9812657237052917
70016179,1215,junrao,2016-07-08T01:51:40Z,"on the leader, during append, we actually use the first offset in the messageset when adding the time index entry. to be consistent, we probably should do it here as well.",0,0.9936820268630981
70016194,1215,junrao,2016-07-08T01:51:52Z,"we need to set skipfullcheck to true when calling maybeappend here, right?",0,0.9934374690055847
70016202,1215,junrao,2016-07-08T01:51:57Z,would it be better to rename this to loadlargesttimestamp()?,0,0.9951581358909607
70016219,1215,junrao,2016-07-08T01:52:15Z,it's kind of verbose to have to do the assignment here and in line 256. perhaps we can move these two lines after line 241. then we can get rid of the two else clauses.,0,0.5459980368614197
70016230,1215,junrao,2016-07-08T01:52:24Z,"we need to set skipfullcheck to true when calling maybeappend, right?",0,0.9931291937828064
70016242,1215,junrao,2016-07-08T01:52:35Z,the error message is a bit hard to understand. could we improve that?,-1,0.6668459177017212
70145743,1215,junrao,2016-07-08T21:45:34Z,"ran into an issue while testing dumplogsegments (details can be found in the jira since pr comment doesn't support attachment). it seems that if the producer sends a batch of non-compressed messages, in logsegment.append(), we always pass in the offset of the first message, but the offset of the largest message may not be the first. this seems to be what's failing the check in the tool. not sure if this is the behavior that we want. if yes, we will need to document this properly, i.e., the index may point to an offset before the message that has the corresponding timestamp. but then, we have to think through other implications such as how this affects truncation.",0,0.8980842232704163
70380300,1215,becketqin,2016-07-12T05:48:19Z,"i meant it was compatible api wise, however there are potential breaking changes in resource footprint. i agree we should be clearer on this. i'll update the doc.",0,0.9709181785583496
70680191,1215,junrao,2016-07-13T18:19:59Z,could we add offsetofmaxtimestamp?,0,0.9946410655975342
70680203,1215,junrao,2016-07-13T18:20:03Z,could we rename this to validateandoffsetassignresult?,0,0.994941771030426
70680256,1215,junrao,2016-07-13T18:20:19Z,"we changed the logic to only use the wrapper message offset in time index in append(). so, perhaps we should do the same during recovery? also, it would be good to avoid calling entry.firstoffset twice since decompression is needed each time.",0,0.9936800003051758
70680297,1215,junrao,2016-07-13T18:20:33Z,"in line 460, do we still need the test messageformatversion > message.magicvalue_v0? it seems it's already covered by line 458.",0,0.9946520328521729
70680342,1215,junrao,2016-07-13T18:20:43Z,"hmm, in this case, if the targetcodec is nocompression, we should return the offset of the first message, right?",0,0.9906336069107056
70680368,1215,junrao,2016-07-13T18:20:52Z,"for the code btw 484 and 491, if messagetimestamptype and timestamp != maxtimestamp, don't we need to change the timestamp in the wrapper message?",0,0.9952923059463501
70680433,1215,junrao,2016-07-13T18:21:11Z,"typo firxst also, the next line of the comment seems to talk about the same thing.",0,0.9914458990097046
70680461,1215,junrao,2016-07-13T18:21:20Z,"when i ran the following command, i got an exception. bin/kafka-run-class.sh kafka.tools.dumplogsegments --files 00000000000000113931.timeindex dumping /users/junrao/downloads/00000000000000113931.timeindex exception in thread ""main"" java.lang.illegalargumentexception: invalid max index size: -1 at kafka.log.abstractindex. (abstractindex.scala:54) at kafka.log.offsetindex. (offsetindex.scala:51) at kafka.tools.dumplogsegments$.kafka$tools$dumplogsegments$$dumptimeindex(dumplogsegments.scala:185) at kafka.tools.dumplogsegments$$anonfun$main$1.apply(dumplogsegments.scala:101) at kafka.tools.dumplogsegments$$anonfun$main$1.apply(dumplogsegments.scala:91) at scala.collection.indexedseqoptimized$class.foreach(indexedseqoptimized.scala:33) at scala.collection.mutable.arrayops$ofref.foreach(arrayops.scala:108) at kafka.tools.dumplogsegments$.main(dumplogsegments.scala:91) at kafka.tools.dumplogsegments.main(dumplogsegments.scala)",0,0.9766291975975037
70684786,1215,junrao,2016-07-13T18:44:25Z,"since we changed the logic, so for compressed messages, we need the offset of the wrapper message for the timeindex. also, could we save the last messageandoffset to avoid calling retainedmessages.last (since it requires iteration)?",0,0.9943146109580994
70926518,1215,becketqin,2016-07-15T06:19:26Z,i was not able to reproduce this issue. it seems that the exception would only happen if the time index file does not exist.,0,0.614915132522583
72359859,1215,junrao,2016-07-26T23:57:16Z,is removing the above code correct? it doesn't seem there is code to compute the largest timestamp lazily.,0,0.9802268743515015
72360736,1215,becketqin,2016-07-27T00:06:07Z,the maxtimestampsofar and offsetofmaxtimestamp are loaded when the log segment is constructed. so it seems that we don't need to load it again.,0,0.9923447966575623
72363721,1215,junrao,2016-07-27T00:39:52Z,got it. then the changes look good.,1,0.6752414107322693
75409338,1215,junrao,2016-08-18T23:50:45Z,typo timestmp,0,0.9683358073234558
75409364,1215,junrao,2016-08-18T23:51:01Z,could we just set appendinfo.maxtimestamp here and get rid of maxtimestampinmessageset?,0,0.9957630634307861
75409371,1215,junrao,2016-08-18T23:51:04Z,rollingbasetimestamp => rollingbasedtimestamp ?,0,0.9945347309112549
75409380,1215,junrao,2016-08-18T23:51:14Z,perhaps it would be safer for the callers to use named params since the first three params are of the same type.,0,0.9930087327957153
75409406,1215,junrao,2016-08-18T23:51:27Z,perhaps we should add largesttimestamp and offsetoflargesttimestamp to the trace logging too?,0,0.9946657419204712
75409414,1215,junrao,2016-08-18T23:51:31Z,typo messsage,-1,0.5924453139305115
75409417,1215,junrao,2016-08-18T23:51:34Z,shouldn't we used created instead of 0 here?,0,0.9923865795135498
75409433,1215,junrao,2016-08-18T23:51:47Z,"we probably shouldn't eat the exception here. if there is an error when appending to the time index, we should probably just halt the jvm so that we can run recover on restart.",0,0.9695026278495789
75409443,1215,junrao,2016-08-18T23:51:54Z,that means the we => that means we,0,0.9211532473564148
75409460,1215,junrao,2016-08-18T23:52:06Z,"is the following comment still accurate? we don't insert the last modification time of the file to the time index, right?",0,0.9909759163856506
75409490,1215,junrao,2016-08-18T23:52:23Z,the name wrappermessagetimestamp seems inaccurate since the message set is not always compressed?,0,0.9581867456436157
75409524,1215,junrao,2016-08-18T23:52:45Z,"in both this line and line 472, it seems that we should be using offsetofmaxtimestamp instead of the offset of the last message since validatedmessages may not be compressed when adding to the log. also, could we make wrappermessagetimestamp a non-option field since all possible values are some.",0,0.9956913590431213
75409563,1215,junrao,2016-08-18T23:52:59Z,"it seems that the ordering of the 2nd and the 3rd params is reversed? to avoid this, perhaps it will be clearer to use named parameters since timestamp and offset are of the same type.",0,0.9940415024757385
75410546,1215,junrao,2016-08-19T00:04:46Z,could we not print this if there is no error?,0,0.9827749133110046
75422544,1215,becketqin,2016-08-19T03:14:55Z,"i am thinking that if there is no message in the segment, the log segment would not have been waiting for rolling, so returning 0 seems reasonable. the return value here does not matter much because we check the segment size in log.mayberoll(). but it is probably better to return (now - created) since we have a trace level logging in log.mayberoll().",0,0.9888779520988464
75424163,1215,becketqin,2016-08-19T03:45:08Z,"hmm, if the message is not compressed, the offset should be the exact offset of the message that has the largest timestamp. when using create_time (line 472), that message would be offsetofmaxtimestamp. but when using log_append_time, it seems the offset should be the offset of the first message in the message set because all the messages in the validatedmessages will have the same timestamp. (on line 474, offsetcounter has not been incremented yet. so offsetcounter.value is still the offset of first message). i thought about making wrappermessagetimestamp non-option, but we actually will pass in none in the constructor in line 272.",0,0.9902287721633911
75424189,1215,becketqin,2016-08-19T03:45:45Z,good catch! i'll add a unit test for this. can't believe it is not caught in the unit tests.,1,0.986228346824646
75425328,1215,junrao,2016-08-19T04:06:50Z,thanks for the explanation. that makes sense. the current logic is correct then.,1,0.9552013874053955
75517403,1215,junrao,2016-08-19T17:08:21Z,the comment is no longer valid. we can probably just remove it.,0,0.9757328033447266
75517610,1215,junrao,2016-08-19T17:09:30Z,"it seems that timeindex.maybeappend() won't throw ioexception. so, swallowing the exception here is actually fine.",0,0.9850555658340454
210999572,5527,Kaiserchen,2018-08-17T18:41:38Z,serialized wrapper?,0,0.9896084666252136
211006524,5527,Kaiserchen,2018-08-17T19:08:05Z,"can skip the second length, its known anyway.",0,0.9916822910308838
211006693,5527,Kaiserchen,2018-08-17T19:08:55Z,treating the whole thing as buffer?,0,0.9837396740913391
211008763,5527,Kaiserchen,2018-08-17T19:17:47Z,i think the step here an optimizer _could potentially_ exploit is the repartitioning. so one could try to only factor out the repartitioning,0,0.9854990243911743
211009275,5527,Kaiserchen,2018-08-17T19:20:07Z,probably need to wrap into delegatingpeekingkeyvalueiterator,0,0.9911549091339111
211347575,5527,bellemare,2018-08-20T17:38:36Z,"true, i could just do it as the remainder. thanks",1,0.945995032787323
211347916,5527,bellemare,2018-08-20T17:39:41Z,"i'll have to look more into the optimizer. tbh i built this originally in 1.0 and just did a functional port, not necessarily a best practices one. thanks",1,0.9507694244384766
211390368,5527,bellemare,2018-08-20T20:05:51Z,"i don't understand your question, can you elaborate?",0,0.5558519959449768
211396540,5527,bellemare,2018-08-20T20:27:36Z,will do.,0,0.9864637851715088
211399371,5527,bellemare,2018-08-20T20:37:52Z,"i notice that in 2.x that i may be able to rework this to allow for enabled cache using a `prefixscan` function similar to `threadcache.range`. i will have to look into this a bit more, though i don't think it will affect performance much since i anticipate rocksdb prefixscan to take the longest overall.",0,0.9754067063331604
211510890,5527,Kaiserchen,2018-08-21T07:57:50Z,"might be, its one of the places i got stuck once. from experience i can tell that its working sufficiently well w/o cache. i think rocks does a pretty good job in not seeking around to randomly on the disk",0,0.7505108714103699
211511167,5527,Kaiserchen,2018-08-21T07:58:50Z,i would not recommend to spend to much energy. at the moment i really don't expect the optimizer to be able to exploit any of this. probably also not in the future. was just a though popping into my head,-1,0.7704243063926697
211511539,5527,Kaiserchen,2018-08-21T08:00:21Z,i think the whole section could look nicer if you would start with bytebuffer.allocate(totallength).asintbuffer(keylength).asbytebuffer.put(key).put(key)... something,0,0.9868153929710388
214673257,5527,Kaiserchen,2018-09-03T12:23:37Z,would need to forward `null` here?,0,0.9928629994392395
214674662,5527,Kaiserchen,2018-09-03T12:29:31Z,would remove this class and avoid protected final here. doesn't seem like a convincing java programming style.,0,0.735840380191803
214715526,5527,bellemare,2018-09-03T15:01:58Z,"i'll leave it out for now. if someone else thinks otherwise, they can speak up or it can be done in a subsequent pr.",0,0.9820377826690674
214744117,5527,bellemare,2018-09-03T18:30:42Z,"yes, cleaner to do so. the value is not relevant. i have fixed that and added a clarification comment (i can remove all comments if required before final submission).",0,0.9678226709365845
214744281,5527,bellemare,2018-09-03T18:32:41Z,"i will change this - but i do appreciate any advice on how i should changee that. i'll post my updated code and we can determine if it's any better, or if there is a more specific approach i should follow.",1,0.7054758071899414
275888898,5527,adaniline-traderev,2019-04-16T16:34:03Z,"why is the topic passed as null? it causes issues with genericrecord avro serializer, since it tries to register schemas under ""null-value"" subject, and the schema registry responds with ""version not compatible"" error",0,0.9724975228309631
275899695,5527,bellemare,2019-04-16T17:00:50Z,"the issue is actually with the confluent implementation of the serde, as they incorrectly attempt to register when null topics are passed in. read [a link] for more details. that being said, it has been extremely quiet in that git repo, i am not sure how much effort confluent puts into supporting work on that product.",-1,0.6148118376731873
275904020,5527,adaniline-traderev,2019-04-16T17:11:42Z,"if this does not gets fixed either way, this pr will be unusable for most of the practical use cases. what is the downside of passing the topic name to the serializer? i tried it, and it seemed to work as expected. is there a workaround if confluentinc/schema-registry#1061 is not fixed?",0,0.9805667996406555
275908240,5527,bellemare,2019-04-16T17:22:45Z,"i think the main issue would be the large amount of internal topic schemas registered to the schema registry. this, combined with any breaking changes to the schema (due to normal business requirement changes) would make it such that you are now needing to manually delete schema registry entries made to internal topics. this is a workflow that i do not believe was ever intended to be done with the confluent serde. as it stands right now, there are allegedly other functionalities that require null serialization (""there are several places in streams where we need to serialize a value for purposes other than sending it to a topic (ktablesuppressprocessor comes to mind), and using `null` for the topic is the convention we have.""). these too will not work with the confluent serde. if they do not fix it, then the next best thing to do would be wrap it in your own implementation and intercept null-topic values to avoid registration. i do not see why it wouldn't be fixed since the current behaviour of registering ""null-topic"" is fundamentally useless. anyways, with all that being said, for this particular line i can certainly pass in the topic since it's fairly well-defined. if you wish to have your internal topics registered to the schema registry, no big deal. for other parts, such as [a link] there is no solution using the current confluent serde.",0,0.6912367939949036
275924688,5527,adaniline-traderev,2019-04-16T18:02:56Z,"confluent serde needs a schema id, and looks like it is not stored in genericdata.record instance - it may not be trivial to fix confluentinc/schema-registry#1061...",0,0.9903305768966675
275926845,5527,bellemare,2019-04-16T18:08:30Z,"that is a fair point. : it may not be as easy to get the hash value as we thought if we rely on the value serde, namely because of the interactions with the schema registry to serialize the data. though this is technically a confluent issue, it may be sufficient to put a blocker on this pr since, as adaniline demonstrates, many users of this use the confluent serde. any thoughts on a way forward are welcome.",1,0.9746925830841064
275978323,5527,vvcephei,2019-04-16T20:28:13Z,"hmm. this does seem like an impediment. the serializer interface doesn't specifically state whether the topic is nullable or non-nullable. what it does say is ` topic topic associated with data`. getting fully into armchair lawyer mode, it seems like this statement implies non-nullability, since `null` is not a valid topic name. if it could be null, it should say something like ""the topic associated with the data, or null if there is none."" also, backing up to a higher level, the serializer interface is specifically for serializing data for use with kafka topics. so, it's probably not appropriate to use it for general serialization. if we want to do that, maybe we should add a new interface that doesn't imply we're sending data to a topic. then again, this is in support of an optimization. perhaps we should just drop the optimization for now and go back to storing only the foreign key reference for the correctness check. for bonus points, we could design a message and storage format that leaves the door open for future optimizations like this, without an awkward upgrade procedure. wdyt, ?",0,0.8881902694702148
276022142,5527,guozhangwang,2019-04-16T22:48:53Z,"on the high-level, i think this should be fixed at confluent sr, rather than letting an ak feature blocked on it -- i.e. users should still be able to pass in not-null topic names while non-schema required typed data will not be registered. reading on the source code of avro-serializer, i think the root cause is that today we treat all primitive typed data as a simple avro-schema as well when serializing, hence still registering it. details are here: [a link] and [a link] we could, instead, fix sr to let it just use primitive serdes directly for primitive types. in this way users can still provide topic names.",0,0.9908391833305359
276026299,5527,pgwhalen,2019-04-16T23:08:22Z,"fwiw , as a user of the sr/serdes, i would consider ""fix sr to let it just use primitive serdes directly for primitive type"" to be a regression. registering primitive schemas with the schema registry is a feature, because it allows other applications (support tooling, etc.) to understand the data in a topic without any context whatsoever.",0,0.9913038015365601
276236590,5527,bellemare,2019-04-17T13:20:57Z,"i think to answer the question of if confluent needs to change their sr and serde, or if we need to take a different approach requires us to address john's first paragraph: ""the serializer interface doesn't specifically state whether the topic is nullable or non-nullable."" if the topic must be non-nullable, then the current approach with the hash code wont work, since the output topic is unknown by the ktablerepartitionerprocessorsupplier.java. if the topic must be nullable (and still provide a serialized output), then the confluent serde/sr needs to change to support this. this isn't clear from the contract and so it probably does need to be resolved. lastly, i do agree with pgwhalen on the usage of primitive schemas in support tooling. we use this functionality all the time with schema registry lookups, as opposed to having our team guess as to what it may have been serialized in. one last thought - for the confluent serde, if the topic is null and the type is a primitive, we can avoid registration and do as outlined. if the type is not a primitive, it can throw an exception (as it effectively does now, upon trying to register to topic-null). this does seem a bit hacky and perhaps a bit complicated, but it may work.",0,0.9858264327049255
276244207,5527,adaniline-traderev,2019-04-17T13:36:43Z,"can the solution be to have a separate interface to calculate data hash (hashsupplier, etc), and have confluent avro serializer implement it? looks like it is a separate concern from kafka data serialization this way ktablerepartitionerprocessorsupplier could do something like [code block]",0,0.9945059418678284
276324353,5527,guozhangwang,2019-04-17T16:17:04Z,"i see. that's a valid point. after a second thought i feel that instead of all / never (i.e. always register a simple avro schema, v.s. never register for primitive types) we should give users options to choose from the two. -traderev that should also work, in fact, we can just let streams to use a special serde other than whatever registered serde for this repartition topic's value, instead of asking the registered serde to provide a hashserde function: note that, the current serde precedence is, from high to low: 1) user overridden value at the dsl. 2) streams library hard-coded value internally (think: longserde for `count`). 3) default registered serde value. but i'm a bit concerned about adding more special handling of serdes at the streams side, i.e. add more scenarios of case 2) above: today streams try to reason about the resulted stream key/value type out of an operator in a best effort and try to use the serde correspondingly event if user does not specify any overrides. the goal is to try to be as adherent to case 1) as possible. although we do have special hard-coded serdes as case 2), e.g. in `count` operator, we hard-coded the serde as longserde unless user overrides it, we still want to keep such cases as small as possible, since having streams to special-handle, e.g. a `ktablerepartitionerprocessor` opens the door for more complexity, as this handling logic would be scattered across the classes and error-prone: note that besides the sink node, at the source node of the downstream sub-topology, streams then should also remember to use a special serde instead of the registered one to deserialize it as well. that being said, if people feels it is worth to add this complexity in streams for good reasons, i can be convinced as well ---------------- philosophically, i'd still argue that, the ak code should not yield to a single vendor's dependency when considering its logic (disclaimer: i'm currently employed at confluent). we should consider what's the best approach for ak streams here, and then if it affects the eco-system dependency we should fix it on the other side.",0,0.8424183130264282
276332348,5527,bellemare,2019-04-17T16:36:42Z,"i don't disagree with your stand on ak first. i do, however, agree with john that the contract is not quite clear on if topic should always be non-null or if topic can be nullable. this is pivotal for determining the way forward. i believe that a precedent has been set by the suppress functionality ( [a link] ), and if we wish to be consistent we should make clear that serializers need to handle null topics (though that handling could simply be throwing an exception.. as is effectively the case with the confluent serde / sr ).",0,0.9510260224342346
276340194,5527,guozhangwang,2019-04-17T16:56:51Z,"for this aspect, my personal take is streams should pass in the topic name whenever it knows -- for the example you brought up, currently it's because the operator does not know the topic name i believe, for which we could refactor internal code to fix it (would like to chime in here whether that is really doable) -- and not relying on any assumptions of the serdes itself, whether the topic is nullable or not.",0,0.975837767124176
276340707,5527,vvcephei,2019-04-17T16:58:10Z,"hah! well, now i'm really in the middle of it ;) it's worth noting that there's plenty of precedent on both sides of the issue. i don't think the suppress implementation constitutes a contract. it could just as easily be argued that l95 there is a bug. actually, i still feel the way i did toward the beginning of the thread, that it makes more sense to say it's non-nullable (given the javadoc and the origin/ownership of the interface in `kafka-clients`). i'm happy to fix that bug in suppress, since we actually do send the serialized result there to a changelog topic, we should just provide the cl topic name to the serializer. this case is more of a bind because i'm not aware of anywhere else in streams where we legitimately serialize something we have no intention of sending to any topic.",1,0.9953199028968811
276375010,5527,mjsax,2019-04-17T18:24:46Z,"i think for suppress() it's a bug -- and it seems to break sr integration: on restore the schema needs to be fetches from the sr if avro is used, but with `null` topic on serialization the schema would never have be registered correctly and restore would fail with schema not found error. for passing in `null` in general, i think it should be allowed, but i also think it's not really necessary. we can pass in the repartition topic name here, too. with regard to the concern about writing something different into the topic compared to a registered schema: we do this already for windowed changelog topics (note that only the user-data-key is serialized as avro for this case, and we add one or two additional longs and maybe a unique counter before writing into the changelog). if we believe this is an issue, we can fix it, but i would not block this pr for it. it's orthogonal and if we think we need to fix it, we need to fix it for all topics. however, it was not an issue in practice so far, thus, my personal take it, that we should move forward with this pr and pass in the repartition topic name.",0,0.9723553657531738
276391436,5527,bellemare,2019-04-17T19:07:18Z,"i can certainly pass in the repartition topic name for the serializer without any issue for both the serializer and deserializer here. [a link] at that point, it's up to the confluent serde users to complain about their sr being populated with internal topic schemas (an issue we have run into at my company), though it's not a deal breaker. that being said, i am not aware of how to obtain the destination topic in [a link] this processor creates the hash code for the current event from the value serde (ie: confluent's), but has no knowledge of the downstream repartition topic, and thus cannot provide a topic. it is my understanding that this would require information not available to the processor, and so will not work as currently structured. this is the real issue that hasn't been adequately addressed yet, aside from the suggestion from john to drop the hash code optimization. this would skip the whole issue, though it may be sub-optimal in terms of developer experience.",0,0.9725245833396912
276433024,5527,adaniline-traderev,2019-04-17T21:04:07Z,here is another instance where a serializer is called with null topic. i was just wondering if it is possible to pass [code block] as topic name - seemed to worked in my testing scenario...,0,0.9808775186538696
276456917,5527,vvcephei,2019-04-17T22:24:43Z,"at the risk of being annoying, the processor _could_ just make up a topic name to use. this would also fix your problem. right now, i think we have three viable solutions (in order of my preference): 1. generate a topic name for the processor to pass to the serializer 2. pass null to the serializer, forcing confluent's sr and any other serializer/sr to handle nulls gracefully. 3. drop the optimization option 2 is a little unfriendly to confluent sr (and other serializer) implementations, but pragmatically, we _are_ upstream, so we have this leverage we can apply to force them to change.",-1,0.5463807582855225
276716731,5527,vvcephei,2019-04-18T15:30:20Z,"further in support of making up a topic name to give the serializer, this is what we're currently doing with state stores, when change-logging is disabled. we unconditionally generate the topic name to pass, given only the appid and storename: [code block] when change-logging is disabled for a store, there is no such topic; i.e., it's a made-up topic name. it's not immediately clear how this is different from something like: `applicationid + ""-"" + processorname + ""-recordhash""`",0,0.993719220161438
276720367,5527,vvcephei,2019-04-18T15:38:47Z,(tangential: i've just submitted [a link] to fix the suppression serde handling. please feel free to review it!),0,0.8979315757751465
277324985,5527,bellemare,2019-04-22T15:24:41Z,"john, i do indeed like that option of `applicationid + ""-"" + processorname + ""-recordhash""` because of the existing precedence with the made-up changelog topic. i believe a decision like this would further align us with the statement ""topic should always be non-null in serialize/deserialize"". so it comes down to 3 options: 1) punt any question on the serde topic nullability by removing the optimization. 2) require that serde topic parameter be nullable by setting topic to null as i have already done in this pr. 3) require that serde topic parameter be non-nullable by creating a fake topic name. in order of preference, i believe 3 is most reasonable, followed by 1. i think 2 is actually fairly reasonable, but least likely to provide a productive way forward because of the existing ambiguous contract. nullability would require that the loosest form of string be used. if no one else objects, i'll go about using a `applicationid + ""-"" + processorname + ""-recordhash""` and post an update shortly.",0,0.9695683121681213
277394421,5527,bellemare,2019-04-22T18:55:23Z,"small change. wasn't able to figure out a clean way to get processorname, but since it's a dummy anyways, i went with context().topic() instead of processorname",0,0.9102683663368225
278785940,5527,guozhangwang,2019-04-26T01:44:10Z,"back to the sr / avro-serde issue we discussed above: after thinking about that a bit more, i'm wondering if we should just fix it by hard coding a serde for the hash value. since our current serde precedence is: 1) user specified serde at the dsl control object. 2) streams hard-coded serde on some special operator (e.g. at `count` operator we hard-code longserde). 3) globally registered serde via config. for the hashvalue, we can treat it as case 2) above and hard-code a serde internally that override the registered serde. and for this foreign key join operation we would not expose control objects for serde overrides case 1), hence this way we should be safe. wdyt?",0,0.9910659193992615
278872345,5527,mjsax,2019-04-26T09:25:08Z,"from my understanding, the design was to first serializer the data, and afterwards compute a hashvalue based on the `byte[]` array. however, for the first step, we don't know the type and thus cannot hard code a serializer. is my understanding incorrect?",0,0.9432150721549988
278953143,5527,bellemare,2019-04-26T13:41:49Z,"this is my understanding as well, which is why i do not see another way forward at the moment.",0,0.9593777060508728
279118475,5527,guozhangwang,2019-04-26T22:14:28Z,"ah okay, i think i was the culprit for the misunderstanding here: i was thinking that we will 1) compute the hash code first, and then 2) serialize that hash code, and hence the issue is that sr also register for a primitive type which i thought should be addressed at streams. now i realize that we are 1) serializing first, and then 2) compute the hash value based on the bytes. this actually makes much more sense since we cannot guarantee all typed objects have a consistent implementation of the `hashcode` interface. in this way though, the bottom line is that we are calling the serializer for getting the bytes, but we are not actually sending the bytes over the wire. and there are serializers like confluent avroserde out there which tries to remember which topics are serialized with which schema, which will then break since streams are not actually using the serialized bytes actually. given that scenario (hopefully i got it right this time :p), i think although it is indeed fixable on confluent avroserde to not register schema given `null` topic name, it is still only one serde and we cannot tell there are no other serdes in the wild that relies on the passed in topic name parameters to bookkeep some mappings, and therefore i think we still need to consider this issue at the streams layer. on this regard my preference is that, at the moment, we just pass in the actual topic name than using a consistent dummy topic name, and my reasoning is that repartition topics are really internal ones specific to the streams app itself, and not supposed to be exposed outside the app (though for changelog topics there may be some exceptions like other apps / consumers may want to read that topic directly, for repartition topics like this one i do feel that they should be really `transient` and not be leveraged by any external clients), and hence protecting such mis-usages sounds like an overkill to me. in the long run, we should consider adding extra apis in the general serde interface which does not take extra parameters (for this purpose i think neither `topic` name or `iskey` boolean should be included) but just object -> bytes and vice versa, to leave no space for any serdes have semantical business logic around those fields. at that time we can then be on the safer side by choose the new apis.",0,0.8510145545005798
279160285,5527,bellemare,2019-04-27T16:22:52Z,"- sounds very reasonable to me. my question is, do i now simply use `context().topic()`? i believe that is correct, since it'll be the topic that we're sourcing the data from, but i just want to verify.",1,0.5232028961181641
279167678,5527,mjsax,2019-04-27T20:37:59Z,"i discussed this with some other people, and somebody mentioned, that for the value we serialize, this value is actually also store in rocksdb (input `ktable`). we also know, that the corresponding `byte[]` are written into the store changelog topic. hence, instead of using the repartition topic, using the changelog topic should be a better option, as it does not leak anything into sr (or whatever other serdes might do with the topic name). even if there is not changelog topic for the input ktable (we do some optimizations and sometimes don't create one (eg, the store might actual be a logical view and is not materialized). but even for this case, using the changelog topic name seems to be save.",0,0.9921086430549622
279514920,5527,bellemare,2019-04-29T19:58:05Z,"`context().topic()` gives the repartition topic name in the serializer, which is what i want. in the processor sections, where i use null, `context().topic()` gives me the input-topic name for the ktable... which is also fine, since the serializer will check against the input topic schema, which must be valid by definition of the data being within the topic... so i suspect this issue can be laid to rest, in line with adaniline-traderev's suggestion. this removes any requirement for the upstream serializer to have to do special work for null values.",0,0.9695855379104614
279749459,5527,bellemare,2019-04-30T13:20:15Z,"after a long discussion, yes, this is what i think is currently the best option. thanks for the suggestion in the first place!",1,0.97645503282547
280145412,5527,guozhangwang,2019-05-01T17:26:43Z,"i'm not sure i can fully follow the suggestion of using changelog topic v.s. the repartition topic here: are you suggesting to do it universally or just for this case? if it is the latter case, i felt it a bit awkward due to inconsistency with other source `ktable` cases where we will just follow the `sourcenode / recorddeserializer` path to deserialize using the source topic; it if it the first case, that also has some drawbacks since with today's topology generation not all source `ktable`s will need to be materialized to a store and hence not necessary having a changelog topic. i still feel that using the source topic name (and i.e. in this case, the repartition topic) admittedly exposed to sr but is philosophically the right thing to do, and we should consider fixing it on serde apis in the future. wdyt",0,0.6052942872047424
280147603,5527,vvcephei,2019-05-01T17:33:38Z,might as well just remove it. i think murmur3 is fine.,0,0.9574325084686279
280147762,5527,vvcephei,2019-05-01T17:34:10Z,wouldn't hurt to have some tests for this. maybe copy those from hive as well.,0,0.9367576837539673
280158927,5527,vvcephei,2019-05-01T18:07:46Z,"recommend making this final as well, and just moving the null initialization to the fk constructor.",0,0.9940605759620667
280159330,5527,vvcephei,2019-05-01T18:08:52Z,[code block] we try to avoid unnecessary qualifiers. also applies elsewhere. i won't call them out further at this time.,0,0.9924812316894531
280187466,5527,mjsax,2019-05-01T19:34:29Z,"i was just talking about the foreign-key case (not sure why you thought it might be anything else?). my understanding is the following: the contract is that we should pass a topic name into the serializer of which we want to write the data into. this contract breaks if we pass in the repartition topic name, because we write something different into the repartition topic. you are right that the changelog topic might not exist, however, my personal take is, that registering for a non-existing topic, is a smaller violation of the contract that passing in the ""wrong"" repartition topic name. note, that the changelog topic name is conceptually the ""right"" topic name. however, this case would not happen very often anyway (compare examples below). your comment trigger one more thought: the optimization framework could actually check for different cases, and if there is an upstream topic (either changelog or source topic that has the same schema), we could actually use this name. some examples (does not cover all cases): [code block] for this case we need to materialize the base table (that is also the join-table), and the schema is registered on `table-topic` already, so we can pass in `table-topic` to avoid leaking anything. [code block] for this case we materialize the derived table from the filter() and we get a proper `filter-changelog-topic` and we can pass this one. [code block] for this case, the agg result ktable is materialized and we can pass the `agg-changelog-topic` as name. [code block] for this case, the agg result ktable is materialized and we can pass the `agg-changelog-topic` as name, because the filter() does not change the schema. thus, even if the join-input ktable is not materialized, we can avoid to leak anything by ""borrowing"" the upstream changelog topic name of the filter input ktable. [code block] for this case, we need to materialize the result of `mapvalues()` and get a proper changelog topic for the join-input table. [code block] this might be a weird case, for which the base table is materialized, while the input join-table would not be materialized, and also the type changes via mapvalues(). hence, the `table-topic` schema is not the same as the join schema and we also don't have a changelog topic for the join-input ktable. we still use the changelog-topic name of the non-existent changelog topic (of the mapvalues() result ktable). as you can see, we can cover a large scope of cases for which we don't leak anything and can always use a topic name that contains data corresponding to the schema. does this explain my thoughts?",0,0.9762988686561584
280187571,5527,vvcephei,2019-05-01T19:34:49Z,"[code block] in general, we try to retrict visibility to the minimum required. i won't call these out further at this time.",0,0.9875707030296326
280188086,5527,vvcephei,2019-05-01T19:36:37Z,"might be a good idea to throw an exception here, to make sure we don't modify the code later and falsify this assumption.",0,0.9806519746780396
280188308,5527,vvcephei,2019-05-01T19:37:30Z,"also, i'm not sure about the fact that configure is called outside of this chain, but close is part of this chain... seems like an ambiguous ownership situation.",-1,0.5600159168243408
280189461,5527,vvcephei,2019-05-01T19:41:36Z,[code block] i personally prefer this any time you're specifically referencing the size of an int or long.,0,0.9810479879379272
280189627,5527,vvcephei,2019-05-01T19:42:09Z,unused,0,0.9426007866859436
280190516,5527,vvcephei,2019-05-01T19:44:58Z,"take this with a grain of salt if you don't like it, but you could save a fair bit of code if you just implement all the `serde`, `serializer`, and `deserializer` interfaces in this one class. (the `serializer()` and `deserializer()` getters can just return `this` in that case). personally, i kind of like this because it puts the serialization and deserialization logic right next to each other, which seems easier to maintain their symmetry.",0,0.5137093663215637
280191410,5527,vvcephei,2019-05-01T19:47:53Z,not sure what this means...,-1,0.8707724213600159
280192430,5527,vvcephei,2019-05-01T19:51:02Z,"my immediate reaction is that it's a little surprising that `byprimarykey := false` means ""use _only_ the foreign key"". boolean flags like this generally contribute to code complexity/obscurity. what do you think about just making separate partitioners for the primary and foreign keys?",0,0.8048002123832703
280193830,5527,vvcephei,2019-05-01T19:55:29Z,it's a little surprising that the store's name is the same as the topic name,-1,0.9244779944419861
280194501,5527,vvcephei,2019-05-01T19:57:36Z,"generally, we forbid null keys in ktable apis for this reason. feel free to just drop the record, log a message, and increment the right metric (look around for other null-key checks in the ktable processors).",0,0.9857097864151001
280195544,5527,vvcephei,2019-05-01T20:00:35Z,"just dropping this in before i forget, following kip-307, we need to provide a mechanism to name these operators and internal states.",0,0.9835184812545776
280258689,5527,guozhangwang,2019-05-02T00:07:58Z,"i understand your reasoning now, but still i felt streams should not fix it trying to piggy-back on another topic that happens to be of the same schema that this serde is used for; or rather, i'd prefer to use a non-exist dummy topic than an existing topic if we do not like repartition topics (again, i agree that repartition topic is not ideal, since we are, in fact, not sending the bytes serialized in that way to the topic).",0,0.9441512227058411
281378147,5527,vvcephei,2019-05-06T21:53:40Z,"this reads a little funny to me. can we just say that it's a many:1 join with the other table, and the foreignkeyextractor selects the key in the other table to join with?",-1,0.9787701368331909
281378332,5527,vvcephei,2019-05-06T21:54:17Z,missing ``,0,0.9794673323631287
281378589,5527,vvcephei,2019-05-06T21:55:13Z,feels like this deserves a comment.,0,0.7846795916557312
283745078,5527,bellemare,2019-05-14T11:12:12Z,done.,0,0.9640594124794006
283746677,5527,bellemare,2019-05-14T11:17:24Z,roger that. will review code + apply.,0,0.9328543543815613
283748861,5527,bellemare,2019-05-14T11:24:01Z,done.,0,0.9640594124794006
283756936,5527,bellemare,2019-05-14T11:49:18Z,"done. i copied the tests over. they depend on guava so i added that as a test dependency for the kafka common package. it's also apache-2.0 license so i don't think there's a problem with this, but if there is please let me know.",0,0.8869205117225647
283758235,5527,bellemare,2019-05-14T11:52:54Z,"i'm not sure i follow on this point. is it that the serdes may be closed multiple times, once by my combinedkey(ser/de)erializer and also outside of it?",0,0.6795218586921692
283758342,5527,bellemare,2019-05-14T11:53:12Z,"haha yes, programming 101. fixed. :)",1,0.995834469795227
283759023,5527,bellemare,2019-05-14T11:55:15Z,thanks - removed.,1,0.7975412011146545
283759466,5527,bellemare,2019-05-14T11:56:34Z,deprecated comment. should have been removed. fixed.,0,0.9841377139091492
283760279,5527,bellemare,2019-05-14T11:59:01Z,"good point. i think you are correct and that it will be clearer. the irony here is that i never use it with byprimarykey=true... i think i abandoned that part of the code and forgot to clean it up. so, no more boolean, and i will clean up the name.",1,0.9459525346755981
283766444,5527,bellemare,2019-05-14T12:16:09Z,"i think this makes sense. i did spend time tabbing back and forth while writing it, so having them together sounds like a better idea to me. done.",0,0.7963684797286987
283769402,5527,bellemare,2019-05-14T12:24:13Z,done.,0,0.9640594124794006
283779807,5527,bellemare,2019-05-14T12:49:23Z,bit of a typo there. it should be the state store name. this state store is materializing the combinedkey and so should not be associated with any particular topic name. i will clear this up.,0,0.9742528200149536
283816226,5527,bellemare,2019-05-14T14:06:20Z,done. let me know if it's still unclear.,0,0.8686472177505493
283816527,5527,bellemare,2019-05-14T14:06:58Z,done.,0,0.9640594124794006
283830915,5527,bellemare,2019-05-14T14:34:01Z,done.,0,0.9640594124794006
283833355,5527,bellemare,2019-05-14T14:38:09Z,the wiki says it's currently under discussion - has it already been accepted? just curious as to if this work needs to be done for 2.3 if it's not going to be a part of it.,0,0.948652982711792
284348335,5527,vvcephei,2019-05-15T16:39:07Z,"i think this is fine, but of course i'm not a lawyer. :)",1,0.9949508905410767
284349058,5527,vvcephei,2019-05-15T16:40:44Z,"i haven't reviewed the most recent state, so this might not be relevant anymore, but i just meant that this class is *not* responsible for calling configure, but it *is* responsible for calling close. ideally, the same class should be responsible for both.",0,0.9824151396751404
284349463,5527,vvcephei,2019-05-15T16:41:40Z,"heh, i wouldn't say it's so basic. we use literals all over the code base for this; i've just recently started promoting the use of the constant field instead.",0,0.6529447436332703
284350221,5527,vvcephei,2019-05-15T16:43:25Z,"woah, it looks like the contributor forgot to update the kip. it was accepted. i'll update the wiki.",0,0.8911016583442688
284853800,5527,bellemare,2019-05-16T19:02:00Z,"i put this in its own interface for now because it's not immediately clear where it should live. it needs to be part of statestore, given how all of the various wrapper classes, like the metered, caching and logging ones work. however, i do not want it to be in the readonlykeyvaluestore as it shouldn't be exposed to the outside world.",0,0.9876547455787659
284854252,5527,bellemare,2019-05-16T19:03:19Z,one of the effects of prefixscan needing to be attached to statestore,0,0.9893323183059692
284854473,5527,bellemare,2019-05-16T19:03:57Z,"i'm not really sure how the timestamped statestores work, nor if i even need to support this (since my intention is to only use the non-timestamped versions).",0,0.6512472033500671
284854893,5527,bellemare,2019-05-16T19:05:12Z,"this is a weird one. i end up with a stack overflow error as the above function calls just go back and forth. it seems like it's getting some weird scope problem. this works around it, but i am not sure if i stumbled on an existing bug or if it's something i introduced. i'm just not really sure how what i did could have caused this.",-1,0.982684314250946
284855494,5527,bellemare,2019-05-16T19:06:52Z,all the above will be cleaned up.,0,0.9870033860206604
284856271,5527,bellemare,2019-05-16T19:09:16Z,"i'm required to supply a materialized store with a name, otherwise the internals of ktableimpl cannot get the name for the state store, and therefore the subscriptionresolverjoinprocessorsupplier cannot access it (fails with npe). this is related to the aforementioned changes to the ktableimpl constructor dropping the `isqueryable` boolean.",0,0.9883654117584229
284857540,5527,bellemare,2019-05-16T19:13:03Z,"am i going to need to handle all of these statestore types? i suspect i'll need to handle both `timestampedkeyvaluestore` and regular `keyvaluestore`, but given that `context.getstatestore` can return any of them, i don't know if i should expect to handle the remainder.",0,0.8953791856765747
287059994,5527,bellemare,2019-05-23T17:44:50Z,"hi guozhang - i noticed that in this pull ( [a link] ) you made it such that the non-queryable store name is no longer obtainable in ktableimpl. i need access to the materializedinternal.storename, but cannot get it anymore (that i know of). do you have any suggestions of what i should do to get it? my only other options appear to be rewriting the ktableimpl constructors back to what they were before, but since you made this change i would like your input. basically, i am now being given materializerinternal.queryablestorename, but i need materializerinternal.storename for when the user does not specify the materialized store (which is frequently). please advise - thanks",0,0.8815822005271912
289081888,5527,guozhangwang,2019-05-30T17:06:36Z,"sorry i've just seen this now. the main motivation of that pr is to avoid materializing state stores unnecessarily and the queryable-name refacotring is sort of a by-product. i was thinking that the parent store names (user-specified or internal) can be accessed from `ktablevaluegettersupplier#storenames`, would that be a possible work-around for you?",-1,0.9876603484153748
289094679,5527,bellemare,2019-05-30T17:38:45Z,"edit: i may have something. i am leaving this here for now to show where i am stuck, but i will update it if i figure out how to properly use your suggestion... - thanks for the reply. basically `ktablea.dojoinonforeignkey(....) ` needs to be able to access `ktablea's` own internal state store to compare the hash values for the workflow we established in kip-213. when `ktablea` is not materialized (internally or by user-specified queryable-name), then i do not think we can query the parents directly since they are by definition different data stores. i do not see how they can slot in as a replacement for the following section (originalsource is what used to be the always-populated statestore, user-specified or internally materialized, represented by queryablestorename) [a link] based on my understanding, it appears i need to have tablea materialized, otherwise i am not sure how to proceed with this ticket. this is basically where i am stuck. i admit i don't know enough about this part of kafka streams to speak with certainty on this.",1,0.619442343711853
289108628,5527,guozhangwang,2019-05-30T18:13:10Z,"i see. i think the protocol should be that when a join operator requires to access its parents (the joining ktables, for example in this case) it will quire from its parent's `valuegetter`, which would chase up until it finds some processor with associated state stores, or it would go all the way up and require the source ktable to be materialized (see `ktableimpl#valuegettersupplier` --- actually you can find the related materials i got from kafka summit this year, [a link] around slide 56 :) so back to your example, even if the source ktable is materialized without a name, calling a join later should cause its `ktablesource#materialize()` be triggered, where its internal `storename` which is always not-null since it would be auto-generated as `nameprovider.newstorename(generatedstoreprefix)` if not specified, would be assigned to its exposable `queryablename`. and then this name can be accessed by its descent processors in the topology if necessary. hope this would help for you to figure it out.",1,0.9936018586158752
289109055,5527,guozhangwang,2019-05-30T18:14:22Z,"note the logic `should cause its ktablesource#materialize() be triggered` may need to be added by you, i.e. the `subscriptionresolverjoinprocessorsupplier` should require to get its parent's valuegetter, which eventually would trigger this function.",0,0.9945439100265503
289121346,5527,bellemare,2019-05-30T18:45:39Z,"i think i solved it with your original recommendation, though by getting the valuegettersupplier as you recommended and not the storenames directly. your follow up message is exactly what i did, so i am glad to have that confirmation. it's passing my tests now and appears to work with and without user-specified queryablestorenames, so i believe this did the trick! thanks for your help! :thumbs_up: now i just need to work on the remaining highlighted issues.",1,0.9959362745285034
289122840,5527,bellemare,2019-05-30T18:49:23Z,overcome by events. no longer relevant :thumbs_up:,0,0.6951274871826172
289124387,5527,guozhangwang,2019-05-30T18:53:10Z,great!,1,0.9883756637573242
296021873,5527,vvcephei,2019-06-20T21:31:11Z,this should get reverted before merging. also with the other commented-out stuff below.,0,0.993263840675354
296022446,5527,vvcephei,2019-06-20T21:33:08Z,unused,0,0.9426007866859436
296022680,5527,vvcephei,2019-06-20T21:34:01Z,"please attribute the source, along with noting the commit hash, as you did for the main code.",0,0.9907802939414978
296023510,5527,vvcephei,2019-06-20T21:36:54Z,"i've always felt that this was a weird use of the `valuemapper` class, elsewhere. what do you think about using `java.util.function.function ` instead?(just now having this thought)",-1,0.7939308881759644
296023880,5527,vvcephei,2019-06-20T21:38:09Z,"thanks! you can ""resolve"" this comment to clean up the pr.",1,0.9512132406234741
296025422,5527,vvcephei,2019-06-20T21:43:18Z,"documentation nit. since this is such a complicated operation, i think we might want some more verbose comments here. something like:",0,0.925518810749054
296025600,5527,vvcephei,2019-06-20T21:43:54Z,"as mentioned in the ktablerepartitionerprocessorsupplier, i'm wondering if we can do without this partitioner by using combinedkey only in the prefix-scan store, and not over the wire?.",0,0.9924250841140747
296026278,5527,vvcephei,2019-06-20T21:46:07Z,"""thisstatestorename"" is a little esoteric :) can we try to make this more self-documenting? i'm assuming that you're copying this convention over from the other join, where we say ""this"" and ""other"", but there's a lot going on here. maybe you can establish a different convention, like ""primary key table"" and ""foreign key table"", or ""left side"" and ""right side"", etc..",1,0.9916192293167114
296026592,5527,vvcephei,2019-06-20T21:47:06Z,"as i understand it, the value getter interface is mainly to support looking up values in another ktable. it's fine (and more direct) for you to just wire the same state store in to both processors. then, you won't need a ""prefix value getter"" interface anymore.",0,0.9846957325935364
296026762,5527,vvcephei,2019-06-20T21:47:34Z,"this doesn't seem quite right... i expected to see a *this* joiner handling updates from this table, and and *other* joiner handling updates from the other table (the subscriptionresolverjoinprocessorsupplier), followed by a merge node, but it looks like we're doing something else here?",0,0.9537357687950134
296026938,5527,vvcephei,2019-06-20T21:47:58Z,"didn't totally follow this todo... the pk-side ktable needs to be copartitioned with the input to the ""subcriptionresolverjoinprocessor"" the fk-side ktable needs to be copartitioned with the output of the ""ktablerepartitionerprocessorsupplier"" in both cases, there's one pre-determined topic and one repartition topic we control, so the co-partitioning should be trivial, unless i'm missing something...",0,0.9759578108787537
296027875,5527,vvcephei,2019-06-20T21:50:58Z,"can we assume both keys are not null (i.e., can we add a condition to skip any null-key updates in both processors so that we can rely everywhere on the fact that keys can never be null? other stateful operators already do something similar (see aggregations, for example), and there are metrics and logs for it. edit: i later figured out that this is part of the prefix-search magic.",0,0.9901944994926453
296028126,5527,vvcephei,2019-06-20T21:51:55Z,"not sure i follow what this case means edit: i later figured out that is a ""magic"" case for creating search prefixes...",0,0.8438084721565247
296028311,5527,vvcephei,2019-06-20T21:52:35Z,"can we name the type parameters pk and fk here and elsewhere, just so we don't have to remember which is which?",0,0.9935013651847839
296028562,5527,vvcephei,2019-06-20T21:53:35Z,"regarding `&& foreignvalueandtime.value() != null`, is this because we're only doing an inner join?",0,0.9932581186294556
296028691,5527,vvcephei,2019-06-20T21:54:08Z,there's a protocol for handling cases like this. check out the aggregate processors.,0,0.9929607510566711
296028773,5527,vvcephei,2019-06-20T21:54:26Z,"not sure if identity is sufficient here, since these objects come from deserializers (i.e., this condition may _never_ be true) also not sure if we can rely on `equals` to be any better than identity. i'm wondering, rather than checking inside this processor, we should ask the upstream table to suppress such no-ops, similar to how we request `sendoldvalues`. then, the upstream processor can perform this check on the serialized form of the data and save a bunch of work downstream (aka, right here).",0,0.9830585718154907
296028913,5527,vvcephei,2019-06-20T21:55:02Z,"oooh... for reference, i just spent 30 minutes trying to figure out how the prefix scan is correct, only to realize that you have created a special ""search key"" that just happens to produce a prefix of the ""stored key"" when used in conjunction with your combinedkeyserde. this seems like a _very_ mysterious implicit coupling relationship among 4 different classes. there's got to be a better way...",-1,0.9537228941917419
296028980,5527,vvcephei,2019-06-20T21:55:17Z,we'd better close this iterator.,0,0.9400293827056885
296029149,5527,vvcephei,2019-06-20T21:55:53Z,"maybe a nit, this sentinel is constant and small, so caching it in a static field is probably valuable.",0,0.9650307297706604
296029321,5527,vvcephei,2019-06-20T21:56:30Z,"can the key actually be an empty array? if so, it's not a safe sentinel value for null. the hashed value of an empty array is `[-7122613646888064702, -8341524471658347240]`. it seems like we could do better by actually using an empty array as the sentinel-hash representing a null value. then, we don't have to send any bytes over the wire to represent null, or store any bytes for that matter.",0,0.9930667877197266
296029499,5527,vvcephei,2019-06-20T21:57:20Z,"alternatively, does this mean there's no need to notify the other side at all, and we can just proceed to recompute the join result? might break semantics, though...",0,0.9611201882362366
296029644,5527,vvcephei,2019-06-20T21:57:52Z,"if we move the primary key into the value and just forward to the foreign key, we can drop the extra partitioner and also extra serde from the wire protocol",0,0.9915773868560791
296030000,5527,vvcephei,2019-06-20T21:59:09Z,"this hash _must_ match the one we produce in ktablerepartitionerprocessorsupplier. if we _ever_ produce a different hash for the same value, we will _lose data_. in light of this, it seems like both locations really need to reference the same logic somewhere, either in a static method somewhere, or passed in as a ""hash function"" over the values. as an illustration of the legitimacy of the concern, you're using a different topic here than in the other location, which could result in a different serial form of the same data.",0,0.9819148778915405
296030317,5527,vvcephei,2019-06-20T22:00:19Z,"maybe a nit... maybe move this byte to the front and make it a bit field, so that we have a straightforward path to pack more boolean flags into the value in the future.",0,0.9689827561378479
296031064,5527,vvcephei,2019-06-20T22:03:10Z,"adding this new interface to keyvaluestore may have some serious implications for implementers. are we sure we have to? at least, we need to add a default implementation.",0,0.9570928812026978
296031167,5527,vvcephei,2019-06-20T22:03:33Z,"note this isn't a byte[], but a k. not actually sure if this api makes sense. for example, what would this api mean if my key type is uuid or mycustomrecord? in other words, only some key types even have prefixes.",0,0.8685865998268127
296033792,5527,vvcephei,2019-06-20T22:13:07Z,"sorry, feeling a bit dense... is this right? it seems like it would cut off some results that should be at the end of the range. in particular, it seems like it cuts off keys like `[prefix]ff01`, since that key is strictly greater than `[prefix]ff`. you might want to take a look at the function that rocksdb uses to compute the range-end for range queries.",-1,0.9835207462310791
296034425,5527,vvcephei,2019-06-20T22:15:38Z,"just a thought, does rocks return in sorted order? if so, we can probably do better by comparing backwards from the end of the prefix. then again, that might screw up cache locality, not sure...",0,0.5055882930755615
296034482,5527,vvcephei,2019-06-20T22:15:50Z,probably should be illegalstateexception,0,0.9540162086486816
296034728,5527,vvcephei,2019-06-20T22:16:47Z,"huh, neat... as i read it, the serial format for our combinedkeys is [fk length][fk bytes][pk bytes] this means that all the records with same-length foreign keys are sorted together, a prefix scan won't suffer any ambiguity between fk and prefixes of the pk. this seems to avoid a problem we face in the session window store. putting it in terms of this key if we have two records with r1.fk=aa r1.pk=b and r2.fk=a and r2.pk=ab, they are both serialized as aab, and in particular, a prefix scan would get pseudomatches that are out of the range and have to handle it by decomposing the serial form and then double-checking the prefix. but since you prefix by the size of the fk, there's no ambiguity, even if the fks are variably sized! but it is worth noting that this depends on the exact serialization format.",1,0.6951895356178284
296034895,5527,vvcephei,2019-06-20T22:17:23Z,"this is due to the subclassing. if you instead wrap and delegate, this won't be a problem.",0,0.9908217191696167
296857031,5527,bellemare,2019-06-24T18:29:39Z,"yep, this is the intended design. it definitely is sensitive to how the serialization is handled, but i think that it's okay as it currently stands.",0,0.6082369089126587
296858048,5527,bellemare,2019-06-24T18:31:57Z,"yep. i'm taking a look at this now and i don't know what i was thinking. i have tested some of the submap logic and it indeed seems that i am cutting off some values. thank you for catching this, ugh. range is a bit different because it specifies the entire key, whereas with prefix we're only concerned with the first n bytes of the key. i will think on this some more. i am wondering if it's best to just wrap the entire thing in an iterator that compares the prefix on each ""next()"" call, and only returns those that meet the full prefix, much like i already have established in the rocksdbdualcfprefixiterator.",-1,0.9770316481590271
296898877,5527,bellemare,2019-06-24T20:22:38Z,"okay, so i believe that i have figured out what i was doing wrong... i needed to do: `map.submap(fromkey, true, tokey, false);` and set tokey to be fromkey + 1 as a byte array. i am currently testing it and it seems to be working, but i want to test further in case i am misunderstanding the submap results.",0,0.9186072945594788
296908737,5527,vvcephei,2019-06-24T20:48:08Z,"yeah, that last thing sounds like what i had in mind. the rocksdb function i had in mind is one that basically computes `+1` for an array of bytes (i.e., iterate backwards from the end to find the first byte that isn't already `0xff` and add `1` to it).",0,0.9677607417106628
298135494,5527,bellemare,2019-06-27T11:45:43Z,:thumbs_up:,0,0.9771975874900818
298136127,5527,bellemare,2019-06-27T11:47:36Z,cleaned.,0,0.9780460596084595
298137597,5527,bellemare,2019-06-27T11:52:05Z,"done. hash included, along with link to file in github.",0,0.9611318707466125
298138716,5527,bellemare,2019-06-27T11:55:17Z,"to me it felt natural as i wanted to apply a mapping function to a value and obtain a result. semantically they feel the same though, so i don't really care one way or another. if you think it's more appropriate to go with `java.util.function.function ` i will make the change.",0,0.765856921672821
298143733,5527,bellemare,2019-06-27T12:10:41Z,"according to their wiki ( [a link] ) it does provide a sorted iterator. the range function operates on this principle too, which confirms this to be the case in the code. we have to validate the entire prefix for each event either way, forwards or backwards. as soon as we run into an event which does not have the full prefix, we terminate and hasnext() will from then on return false. i don't think there's anything in terms of efficiency to be done here, but let me know if i misunderstood.",0,0.8030275702476501
298143789,5527,bellemare,2019-06-27T12:10:51Z,yup. thanks!,1,0.9948152899742126
298198372,5527,bellemare,2019-06-27T14:11:53Z,will be adding this in shortly.,0,0.9852837324142456
298669556,5527,bellemare,2019-06-28T16:45:02Z,i'll do my best to clarify the entire operation in the next commit.,0,0.9751604199409485
298670452,5527,bellemare,2019-06-28T16:47:50Z,"i'm fine with using the ""primary key table"" and ""foreign key table"" lingo, but given that this was stripped out of the function name somewhere previously in the review, i wasn't sure it was ""allowed"". to be frank, _i_ find it confusing to talk about this as if it's _not_ a `foreignkeyinnerjoin` and `foreignkeyleftjoin`, but instead some sort of special-case normal `join` and `leftjoin`. i'm just going to go ahead and call it what i want internally, and then we can all bicker about the bike-shed name afterwards. :)",-1,0.4911459684371948
298799471,5527,bellemare,2019-06-29T13:20:55Z,"it just means the fk is the same - the hash may have changed. we need to update the hash in the subscription state store on the rhs, otherwise valid updates coming from the rhs table will join on a stale hash, and be discarded during the resolver phase (oldhash != currenthash).",0,0.993889331817627
298799689,5527,bellemare,2019-06-29T13:30:26Z,"yep, you're correct. i believe this is an artifact left over from the initial design, when i used to send (combinedkey , v) as the event, and it was either put the fk in the key or in the value. i'll adjust the code accordingly.",0,0.9763259291648865
298801769,5527,bellemare,2019-06-29T14:52:45Z,"okay, while i took it out from over-the-wire, but we still need the serde for the `prefixscanstorebuilder`, since combinedkeys are stored to the changelog topic. the end result is that the only thing that is removed is the custom partitioner, which i like as i we no longer rely on a copied + pasted + slightly-edited partitioner.",0,0.9809373021125793
298802096,5527,bellemare,2019-06-29T15:03:53Z,"while it could go into a static method, it will always need a topic name unique between all topologies because of the weak interface definition of `serialization`. it is ambiguous as to whether topic can be null in `serialize(topic,data)`. from experience, the confluent avro serde _will_ register once with a null topic, but then will forever give already-registered exceptions for all remaining registrations. this means that we will forever need some unique dummy topic per foreignkeyjoin schema, and it will need to live in some common place. i can create a dummy topic name in the `ktableimpl.doforeignkeyjoin()` and pass in the necessary common reference to both `subscriptionresolverjoinprocessorsupplier` and `ktablerepartitionerprocessorsupplier`. this will ensure that `serialize(topic,data)` is consistent, since the topic will not rely on the topology (outside of uniqueness).",0,0.9880468845367432
298802436,5527,bellemare,2019-06-29T15:16:43Z,"changed to instructions, no longer relevant",0,0.9638402462005615
298802801,5527,bellemare,2019-06-29T15:31:05Z,"i am not sure we have to add this to all keyvaluestores. i had previously tried to limit it to the rocksdb instance only, but previously-given feedback suggested that it should support both caching and logging for performance related reasons. what we have now is due partially to a snowballing of inclusion of caching, logging and rocksdb store, and partially due to my thinking that ""if range can work in all tables, why not prefixscan since it's basically the same operation?"" the prefixscankeyvaluestore needs to support both get() (for lhs->rhs lookup) and prefixscan() (rhs->lhs lookup), and get() is tied to readonlykeyvaluestore. i also didn't want to expose prefixscan to the outside world via readonlykeyvaluestore. if you (or anyone else) feels strongly about removing it, please direct me on how you would see best to limit it to rocksdb + caching + logging. i am not confident in messing with the existing structure too much, so guidance / direction on it would be preferred than leaving it strictly up to me. :thumbs_up:",0,0.9526598453521729
298803316,5527,bellemare,2019-06-29T15:49:33Z,"the key can be anything. the issue is that murmur3 cannot hash a null to a unique sentinel that wouldn't also be available by hashing another value. so any value we choose will not work. that being said, i could do something like (you mentioned using a bit in another comment): hash is null: `{1-bit nullhash = true}{remaining-serialized-data}`. hash is notnull: `{1-bit nullhash = false}{2-bytes hash}{remaining-serialized-data}`. the only thing i am rusty on is how the bit is handled in over-the-wire communication. would it not simply end up being stored as a full byte anyways? in this case, we're adding a full byte to each message just to indicate if the hash is actually null, and this is in both directions. however, for correctness sake i believe we should do this as i don't think there is any safe sentinel we can use. if we want to save space, we have two more options. 1) fold this in with the version byte, and only give version 7-bits. {1-bit-nullhash}{7-bit-version} 2) can also switch to hash64 (50% chance of collision in ~4 billion events) instead of hash128 (50% chance of collision in ~1.844674407e19). for the sake of moving this along, i will just include a single-bit of isnullhash and take it from the version byte. this should satisfy our needs.",0,0.9019116163253784
298808164,5527,bellemare,2019-06-29T18:48:06Z,"i folded all this in, the 7-bit version and the 1-bit and the 1 bit ""isnull"". i'll resolve this one now and if it's no good for whatever reason then just open another.",0,0.9764625430107117
298808919,5527,bellemare,2019-06-29T19:20:22Z,overcome by events.,0,0.9788522124290466
298809600,5527,bellemare,2019-06-29T19:50:15Z,removed in latest version.,0,0.9873346090316772
298809661,5527,bellemare,2019-06-29T19:52:20Z,"all joins are being executed in the subscriptionresolverjoinprocessorsupplier. everything comes in from the subscriptionresponsewrapper topic, so there is no this/other.",0,0.9938522577285767
298809878,5527,bellemare,2019-06-29T20:03:23Z,"sorry, my comment was not very clear. currently what you described does work for a single `lefttable.joinonforeignkey(righttable, ...)`. however, i was concerned how it would work when we start chaining them together. i currently have a (somewhat complexly written) integration test (`ktablektableforeignkeyinnerjoinmultiintegrationtest`) where i do: [code block] and then: `table_1.joinonforeignkey(table_2, ... ).joinonforeignkey(table_3, ...)` the test does not pass (times-out after 60s of waiting) when `table_1_size != table_3_size` , using the co-partitioning as you suggested above. i'm not familiar enough with what's going on under the hood to explain it, nor have i spent much time digging deeper, but it seems that the partition distribution for chained `joinonforeignkey` needs some attention.",-1,0.9841996431350708
298810060,5527,bellemare,2019-06-29T20:12:27Z,it would make it inconsistent with the types in ktableimpl. i standardized them across all the code in this pr because once learned it's consistent everywhere you look. i am hesitant to change them because the next comment will be someone asking to make them consistent with ktableimpl...,-1,0.8622639179229736
298864664,5527,bellemare,2019-07-01T02:18:54Z,"i will remove this. i am not sure how to go about asking the processor to not send no-ops, but unless it's built in i'd like to limit the scope. this pr is big enough that i don't want to add more than necessary.",0,0.7811771631240845
298865371,5527,bellemare,2019-07-01T02:26:44Z,"i will add more comments to make it clearer. the coupling is indeed tight because it's based strictly on the byte ordering of the key. i couldn't think of a better way, so if you think this is a deal-breaker please let me know and we'll throw it back on the mailing list.",0,0.9235457181930542
298866241,5527,bellemare,2019-07-01T02:35:21Z,"corrected the comments - this is probably also related to your question about where should the prefixscan even go. the only real requirements are rocksdb, logging and caching stores. since they're so intertwined, it's hard for me to give you a good answer on if this should be here or not. if we have to ask, probably not, but tbh i'm really looking for guidance on this since i'm a bit over my head on where it should go. i have asked for feedback on this previously, but so far you're the only one to take not.",-1,0.5018596649169922
299600884,5527,bellemare,2019-07-02T17:34:00Z,"can't handle multiple input partition counts if we chain foreignkeyjoins together. i did a few hours of investigation into this and it appears it's related to a combination of: a) multiple topicgroups ( [a link] ) b) creating sinks (for both the subscription and subscriptionresponse topics) c) how sinks are handled with copartitioning and a per-topic-group way: => the result is that sink topics are assigned the maximum number of partitions in the topicgroup (as all sink topics are treated - [a link] ""if this topic is one of the sink topics of this topology, use the maximum of all its source topic partitions as the number of partitions"" the result is that we end up with the wrong (ie: a maximum) number of partitions for some but not all of the internal repartition topics. for instance, if i have the following: `left.joinonforeignkey(rightonetable, named.as(""join1""), ...).joinonforeignkey(righttwotable, named.as(""join2""), ...)` [code block] i would expect to have the following topics with partitions: [code block] instead, due to the aforementioned dynamics, i get: [code block] as a result, i will not be supporting variable partition counts in this pr, but will put it off until after this one is comitted and roll it in its own pr. the scope on this pr is large enough.",0,0.9887834191322327
299612961,5527,bellemare,2019-07-02T18:01:42Z,"true - the unfortunate part is that wiring it in and getting it via `processorcontextimpl.getstatestore(..)` ( [a link] ) is that it does not match any of the store types, and so cannot be accessed that way. i can modify that further, but this is all due to the same original question - where in the interface definitions should `prefixscankeyvaluestore.prefixscan()` live?",0,0.9124961495399475
307344539,5527,vvcephei,2019-07-25T15:01:25Z,"hey , i think your feeling is reasonable, but to me it actually supports using a function more than using a valuemapper. what i mean is, you just want to run a _function_ on the value and obtain a result. the valuemapper implies you're mapping the value to a new value to produce a new ktable with the result value. in other words, it only makes sense in a `mapvalues()` operation. the valuemapper interface was introduced for the `mapvalues()` operator, and we abused (along with others of our functional interfaces) by using it other places where we just want a unary function (because java had no stdlib functions at that point). now that java has function, we can clean this mess up. right now, though, i'm just proposing not to create more mess that we have to clean up later. if people disagree with using function (for some reason), then we should make a new semantically correct interface instead of using valuemapper.",0,0.8904505968093872
307349571,5527,vvcephei,2019-07-25T15:10:40Z,"ok, just for the record, i think we have to fix this before merging... i'll see if i can figure it out.",0,0.9683724641799927
307394163,5527,bellemare,2019-07-25T16:39:15Z,i had researched it more extensively a few weeks ago but just realized now i forgot to post the findings. they were pending publishing in my own review...,0,0.7596748471260071
307394639,5527,bellemare,2019-07-25T16:40:15Z,i've just posted the findings. i am concerned about scope creep if we tinker with the copartitioner. as it stands right now i think the size of this pr is intimidating enough.,0,0.7927995324134827
307397528,5527,bellemare,2019-07-25T16:47:19Z,function it is. your perspective on the misuse of valuemapper makes sense.,0,0.9220485687255859
311715968,5527,abbccdda,2019-08-07T19:05:58Z,nit: newline,0,0.9064050316810608
318776174,5527,cpettitt-confluent,2019-08-28T20:26:53Z,"it might be better to throw if there is overflow. otherwise the return prefixed key does not follow the protocol in combinedkeyschema. i don't think it would happen in practice, but if we're going to address it one way or the other i would probably lean toward explicitly failing on overflow. otherwise we should at least doc that this widens the array of bytes in the case of overflow.",0,0.9823312759399414
318778418,5527,cpettitt-confluent,2019-08-28T20:32:27Z,"as this is public documentation, it would be nice to explain what named is used for.",0,0.8807052969932556
318778654,5527,cpettitt-confluent,2019-08-28T20:33:05Z,as this is public documentation it would be nice to have documentation on it. it looks like it would be the same as the previous sans named.,0,0.8624172210693359
318778736,5527,cpettitt-confluent,2019-08-28T20:33:18Z,same comment as above.,0,0.9899691939353943
318802475,5527,cpettitt-confluent,2019-08-28T21:32:47Z,do we need to be careful here about getting dos'd by an extreme length either due to malice or accident? do we have a key limit anywhere else that we could use to assert that `foreignkeylength` is within acceptable limit?,0,0.9473904371261597
318803831,5527,cpettitt-confluent,2019-08-28T21:36:44Z,"it seems given this that we can at least assert that foreignkeylength is less than or equal to 2147483643 bytes. though a better bound, if there is one, would be nice.",0,0.9790952205657959
318813557,5527,cpettitt-confluent,2019-08-28T22:07:33Z,should this be sent only when the old and new key do not match?,0,0.9923392534255981
318814883,5527,cpettitt-confluent,2019-08-28T22:12:16Z,looks like dead code that can be removed?,0,0.979973554611206
318816694,5527,cpettitt-confluent,2019-08-28T22:19:04Z,`value.getforeignvalue() == null && (!leftjoin || currentvaluewithtimestamp == null)` ?,0,0.9900790452957153
318817354,5527,cpettitt-confluent,2019-08-28T22:21:28Z,minor: order of visibility keywords in field declarations are reversed here vs. other places in the code.,0,0.9928774237632751
318819397,5527,cpettitt-confluent,2019-08-28T22:30:04Z,"maybe worth an assert here that version fits in 7-bits? not that we're going to hit it any time soon, but if we set the 8th bit then given the semantics below we are considered to have a null hash.",0,0.9906978011131287
318820465,5527,cpettitt-confluent,2019-08-28T22:34:09Z,same comment re. version as above.,0,0.9923380017280579
318821811,5527,cpettitt-confluent,2019-08-28T22:39:37Z,`cache.isempty()` seems sufficient? curious why you needed to change this.,0,0.9773180484771729
318822498,5527,cpettitt-confluent,2019-08-28T22:42:21Z,curious: is there any functional change by moving this code?,0,0.9638919234275818
318822822,5527,cpettitt-confluent,2019-08-28T22:43:38Z,i think we can revert this for cleanliness.,0,0.9403582811355591
318822997,5527,cpettitt-confluent,2019-08-28T22:44:19Z,"given the size of this commit, it seems worth reverting non functional changes like this.",0,0.9843839406967163
318823102,5527,cpettitt-confluent,2019-08-28T22:44:43Z,same as last few comments :),1,0.9854488968849182
318823246,5527,cpettitt-confluent,2019-08-28T22:45:17Z,same as above.,0,0.9857698678970337
318824005,5527,cpettitt-confluent,2019-08-28T22:48:25Z,minor: you could get away with keeping this mutable if you initialize it here and do `addall` with `topicstocopartitiongroup.get` below. just check `copartitiongroup.isempty` to determine if you can break.,0,0.993105947971344
318824758,5527,cpettitt-confluent,2019-08-28T22:51:26Z,is it? :d,1,0.9834633469581604
319131058,5527,bellemare,2019-08-29T15:23:00Z,"my understanding is that if the foreign key is too large it couldn't have been written as a message to kafka (exceeds maximum batch/message size). accordingly, the maximum size of the foreignkey is limited to the maximum allowable batch/message size. is this incorrect?",0,0.9715359807014465
319136512,5527,bellemare,2019-08-29T15:33:33Z,"i believe we chose this because with a regular join we propagate the same output value for each event sent in. if there are n events with the same old and new state, we output n joined events, even if they are the same. if we do not send when oldkey == newkey, then we swallow + hide the event.",0,0.9897866249084473
319136649,5527,bellemare,2019-08-29T15:33:50Z,yep. i'll go through and try to clean it up. lots of stuff changed and got reverted unsuccessfully.,-1,0.9035395979881287
319137563,5527,bellemare,2019-08-29T15:35:36Z,"haha, good eye. i didn't notice the repeated logic at the end... sigh... thanks.",1,0.9945592284202576
319138304,5527,bellemare,2019-08-29T15:37:01Z,:thumbs_up:,0,0.9771975874900818
319139534,5527,bellemare,2019-08-29T15:39:27Z,i can put some validation in the serializer since it's the one that's forcing a byte into 7-bits.,0,0.9915128350257874
319142830,5527,bellemare,2019-08-29T15:45:25Z,same solution - will validate in serialization since it's the serializer that is limiting it to 7 bits.,0,0.9932429194450378
319144549,5527,bellemare,2019-08-29T15:48:52Z,"this is an artifact of a broken trunk that i needed to fix to get this to compile a few weeks back. currently in trunk it seems to be fixed ( [a link] ) , so i'll resolve this when i make a new pr rebasing this off of the murmur3hash pr that needs to be resolved prior....",0,0.9557889699935913
319150616,5527,cpettitt-confluent,2019-08-29T16:02:01Z,"my bad! i thought this was coming from a topic, but this is just for the prefix matching in the store. this can be closed out.",-1,0.9917580485343933
319153538,5527,cpettitt-confluent,2019-08-29T16:08:32Z,":thumbs_up:makes sense. my understanding is that sending an output even for each input is best effort, e.g. the output event is not emitted if the hash changes more quickly than the updates get through the rhs.",0,0.5563176274299622
319153674,5527,cpettitt-confluent,2019-08-29T16:08:49Z,:thumbs_up:,0,0.9771975874900818
319172463,5527,bellemare,2019-08-29T16:53:53Z,"there was at one point - i believe i was using the storebuilder to build the store, then i had to connect it afterwards. it would throw an exception if i tried to connect a store that was not built yet. the work that john r did to fix up the topology seems to have remedied it, so i'll revert the order back to the original order.",0,0.9791638255119324
319174179,5527,bellemare,2019-08-29T16:58:03Z,"yes, i will do so. this was an artifact of my ide organizing the imports i believe.",0,0.9441277384757996
319195586,5527,bellemare,2019-08-29T17:50:08Z,deftly overcome by events! will remove the whole thing.,-1,0.9579907059669495
319198127,5527,bellemare,2019-08-29T17:56:13Z,"i'll leave that up to to comment on, as he is the one who made these changes... . actually, now i'm not sure why this change is in here, i think this was supposed to be in its own pr? john?",0,0.593572199344635
319261222,5527,bellemare,2019-08-29T20:38:03Z,"i see what you're saying, but i am not sure it's proper to put the exception in the bytes.increment as it's doing what it says it should do (ie: increment the byte array by 1). john and i noticed this before, but since combinedkeyschema always starts with a positive integer, wrap-around won't affect us in either case. as john noticed 22 days ago: [code block] we're implicitly protected as long as the maximum of positive integers are always 0x7fff ffff.",0,0.9498859643936157
319263781,5527,bellemare,2019-08-29T20:45:03Z,:thumbs_up:,0,0.9771975874900818
319275297,5527,cpettitt-confluent,2019-08-29T21:16:08Z,good point. that seems to support an assertion / exception vs. adding behavior we don't expect to run though? if we overflow clearly there is a logic error somewhere in the callee and it would be better to find out directly vs. as a side effect of behavior we don't expect to exercise?,0,0.9234496355056763
320388724,5527,bellemare,2019-09-03T17:24:51Z,"yep, fair enough. i'll make it such that it'll throw an error if it would result in a wrap around. the caller will have to allocate additional room if they want it to roll over.",0,0.8133683204650879
320395570,5527,bellemare,2019-09-03T17:40:50Z,indexarrayoutofbounds? or do you have something else in mind? i can't seem to find a reasonable choice from the list...,0,0.6482434272766113
320401139,5527,cpettitt-confluent,2019-09-03T17:53:34Z,"i don't have a strong opinion. i suppose `illegalargumentexception(""overflow"")` would be fine. that seems most appropriate, especially if we document that increment only works for inputs up to max int - 1.",0,0.9445496797561646
320401556,5527,cpettitt-confluent,2019-09-03T17:54:35Z,"btw, this is not a blocker to me. i think if we get the one change we discussed above (exception on overflow) that things are looking pretty good from my perspective. i'll do a pass on the tests too.",0,0.8541677594184875
321287361,5527,bbejeck,2019-09-05T14:09:51Z,nit: `prefix_scan_processor` and `join_on_foreign_key_name` names are unused.,0,0.9936823844909668
321398773,5527,vvcephei,2019-09-05T17:49:17Z,"thanks, -confluent . i think we're better off favoring immutability unless there's a significant readability or performance advantage to mutable state.",1,0.9752272367477417
321400745,5527,vvcephei,2019-09-05T17:53:29Z,"using `size()` was actually identified as a performance regression. trunk is now using `isempty()`: [a link] regardless, this line should not appear in your diff at all. i'd just smash it with whatever is in trunk.",0,0.9891725778579712
322342024,5527,bbejeck,2019-09-09T16:40:07Z,"although this class is in an `internals` package, some brief javadoc would be helpful. the overall flow is complex, and a short description will help grok the functionality and where the class fits in the flow of things. same thing for all other classes in `internals.foreignkeyjoin` so i won't repeat the comment.",0,0.9727363586425781
322368963,5527,bbejeck,2019-09-09T17:42:07Z,this is unrelated to this pr but i'm wondering the `processorgraphnode` _always_ used as the node name we could simplify this class. but let's just leave it as is for now.,0,0.9393667578697205
322376681,5527,bbejeck,2019-09-09T17:59:31Z,"nit: the test doesn't cover `prefixbytes` method. i'm not a proponent of 100% test coverage always, but imho that method is a main factor in the ""other->this"" join so it should have coverage in this case.",0,0.9542083740234375
322855625,5527,bellemare,2019-09-10T16:55:24Z,"according to the commits i made, this should be removed by now... not sure why it's still showing up in the review...",0,0.7790542840957642
322918610,5527,bbejeck,2019-09-10T19:20:26Z,"i think it _may_ be possible to implement the integration tests using the `topologytestdriver`, the benefit of which would be that we could get coverage reports and the tests run faster without the embedded broker. the test cases look complete to me, but without coverage reports, we could be missing something.",0,0.9769902229309082
322919371,5527,bbejeck,2019-09-10T19:22:00Z,leftover debugging?,0,0.9557427763938904
323413934,5527,bellemare,2019-09-11T19:15:44Z,"i'm not familiar enough with this myself. if it's problematic i would be willing to address it in another pr, as i'm experiencing some fatigue on this one.",-1,0.9053784012794495
323413988,5527,bellemare,2019-09-11T19:15:53Z,very much so. thanks!,1,0.9948818683624268
323985652,5527,mjsax,2019-09-12T23:12:49Z,"seems we need to update `streamsresetter` to delete those topics, too?",0,0.9944040775299072
323985742,5527,mjsax,2019-09-12T23:13:15Z,as above.,0,0.9878018498420715
325438742,5527,vvcephei,2019-09-18T00:27:57Z,"yes, we do. good catch!",1,0.9952319264411926
326269999,5527,bbejeck,2019-09-19T16:30:05Z,"nit: enabling optimizations is a two-step process. in addition to setting the `optimize` flag in the configs, we also need pass in the configs to the overloaded `streambuilder#build(properties)` method here.",0,0.9926292896270752
326272813,5527,bellemare,2019-09-19T16:36:36Z,"whoops! that's not a nit, that's just a miss on my part. thanks!",1,0.9301614761352539
426783396,8680,abbccdda,2020-05-18T17:25:17Z,nit: we could use { versionrangetype} to reference to the classes.,0,0.994126558303833
426783652,8680,abbccdda,2020-05-18T17:25:44Z,could be simplified as new features<>,0,0.986140251159668
426783720,8680,abbccdda,2020-05-18T17:25:51Z,same here,0,0.9628711938858032
426805425,8680,abbccdda,2020-05-18T18:06:33Z,nit: extra line,0,0.950958788394928
426806321,8680,abbccdda,2020-05-18T18:08:17Z,is this function only used in unit test?,0,0.9929764866828918
426806671,8680,abbccdda,2020-05-18T18:09:02Z,we should ensure `features` is not null,0,0.9911187291145325
426807646,8680,abbccdda,2020-05-18T18:10:58Z,"nit: just a personal preference, but getting one less internal reference to a public function `all` makes the code usage check easier, like `features.get(feature)`.",0,0.9897547364234924
426808456,8680,abbccdda,2020-05-18T18:12:36Z,"also if we could potentially have a not-found feature, we should either fail with illegal state, or make the return type `optional `",0,0.9933527708053589
426808879,8680,abbccdda,2020-05-18T18:13:21Z,maybe rephrase as `a map with the underlying features serialized`,0,0.9947487711906433
426809504,8680,abbccdda,2020-05-18T18:14:35Z,s/deserializes/deserialize,0,0.9865949153900146
426810909,8680,abbccdda,2020-05-18T18:17:09Z,we should check `null` for other.,0,0.9891427159309387
426829453,8680,abbccdda,2020-05-18T18:53:37Z,nit: might make sense to build meta comment for parameters: [code block],0,0.9914402961730957
426836963,8680,abbccdda,2020-05-18T19:07:57Z,s/ !featuresandepoch.isempty / featuresandepoch.isdefined,0,0.9758371114730835
426838064,8680,abbccdda,2020-05-18T19:10:06Z,this is because the write path has not been implemented?,0,0.9911865592002869
426865773,8680,abbccdda,2020-05-18T20:07:15Z,nit: add a line,0,0.953488290309906
426873359,8680,abbccdda,2020-05-18T20:23:39Z,i think we need to bump the schema version to 4? same with `apiversionsrequest.json`,0,0.9950448274612427
426875434,8680,abbccdda,2020-05-18T20:28:01Z,"looks like we have some gaps for unit testing `apiversionsresponse`. could we add unit tests for this class, since the logic `createapiversionsresponse` becomes non-trivial now?",0,0.9888618588447571
426875879,8680,abbccdda,2020-05-18T20:28:59Z,s/allapi/getallfeatures,0,0.9770312905311584
426876134,8680,abbccdda,2020-05-18T20:29:35Z,we need the apache license title,0,0.9919593930244446
426876793,8680,abbccdda,2020-05-18T20:30:54Z,we could use `org.apache.kafka.common.utils.utils#mkmap` here,0,0.9951307773590088
426876852,8680,abbccdda,2020-05-18T20:31:01Z,same here,0,0.9628711938858032
426877891,8680,abbccdda,2020-05-18T20:33:12Z,nit: new line,0,0.930640459060669
426884892,8680,abbccdda,2020-05-18T20:47:45Z,"in terms of naming, do you think `finalizedversionrange` is more explicit? also when i look closer at the class hierarchy, i feel the sharing point between finalized version range and supported version range should be extracted to avoid weird inheritance. what i'm proposing is to have `versionrange` as a super class with two subclasses: `supportedversionrange` and `finalizedversionrange`, and make `minkeylabel` and `maxkeylabel` abstract functions, wdyt?",0,0.968565046787262
426890390,8680,abbccdda,2020-05-18T21:00:09Z,"note this function is public, which suggests there could be external dependency that we need to take care of. the safer approach is to keep this static function and create a separate one with augmented parameters. cc for validation.",0,0.9913255572319031
426931875,8680,abbccdda,2020-05-18T22:44:55Z,i think we could delay the addition for these helpers until we actually need them.,0,0.9793187975883484
426933479,8680,abbccdda,2020-05-18T22:49:35Z,"i gave it more thought, and wonder whether we could just call this function `features` to be more consistent with our convention for getters.",0,0.9843422770500183
426933776,8680,abbccdda,2020-05-18T22:50:20Z,need to check null,0,0.9219598770141602
426934551,8680,abbccdda,2020-05-18T22:52:20Z,is there a difference between `objects.equals` and `this.minkeylabel.equals(that.minkeylabel)`?,0,0.9938299059867859
426935082,8680,abbccdda,2020-05-18T22:53:54Z,"nit: testminmax, and we could reuse the same `new versionrange(1, 2)` by only creating it once.",0,0.9931447505950928
426936469,8680,abbccdda,2020-05-18T22:57:45Z,does l17-23 really necessary for testing?,0,0.9928327798843384
426936751,8680,abbccdda,2020-05-18T22:58:34Z,could we add a reference to the class?,0,0.9926069974899292
426937532,8680,abbccdda,2020-05-18T23:00:50Z,it seems that we don't have the handling logic for this featurecacheupdateexception. do we think this is fatal?,0,0.8621285557746887
426937944,8680,abbccdda,2020-05-18T23:02:01Z,is this function being used?,0,0.9898198246955872
426940597,8680,abbccdda,2020-05-18T23:10:12Z,do you expect these helper functions actually to be used in production logic with subsequent prs?,0,0.9937160611152649
426940830,8680,abbccdda,2020-05-18T23:10:56Z,i don't think we need a nested if-else: [code block],0,0.9538959860801697
426942377,8680,abbccdda,2020-05-18T23:16:03Z,could we make feature extraction as a helper function?,0,0.994126558303833
426942842,8680,abbccdda,2020-05-18T23:17:26Z,could we make this parameter configurable?,0,0.993614673614502
426976264,8680,abbccdda,2020-05-19T01:19:38Z,what would happen if we are dealing with a v4 json map containing features?,0,0.9935957789421082
426976396,8680,abbccdda,2020-05-19T01:20:02Z,nit: this test could move closer to testfromjsonv4withnorack,0,0.9919518232345581
426976932,8680,abbccdda,2020-05-19T01:22:05Z,should we test `isdefined` before calling `get`?,0,0.9941933751106262
426977978,8680,abbccdda,2020-05-19T01:26:17Z,s/existingstr/oldfeatureandepoch,0,0.9850296378135681
426978090,8680,abbccdda,2020-05-19T01:26:43Z,this val seems redundant.,-1,0.5921202301979065
426978267,8680,abbccdda,2020-05-19T01:27:25Z,nit: this errormsg val seems redundant.,-1,0.800727367401123
426979984,8680,abbccdda,2020-05-19T01:34:31Z,"this is only used on l53, maybe we could just use supportedfeatures instead",0,0.9927777647972107
426980855,8680,abbccdda,2020-05-19T01:37:40Z,"this comment is a bit vague to me, what are you referring by `incompatibilities`?",-1,0.6277873516082764
426990007,8680,abbccdda,2020-05-19T02:12:55Z,nit: maybe rename to `incompatiblewith` and flip the boolean,0,0.992691695690155
426990716,8680,abbccdda,2020-05-19T02:15:41Z,"might worth getting a ticket to define the handling strategy for such exception, and in general how `updateorthrow` will be used.",0,0.9916736483573914
426997108,8680,abbccdda,2020-05-19T02:39:40Z,does this event actually happen? will we hit illegal state exception in `updatelatestorthrow`?,0,0.9862313866615295
427022316,8680,kowshik,2020-05-19T04:25:04Z,done.,0,0.9640594124794006
427023280,8680,kowshik,2020-05-19T04:29:23Z,"do you feel strongly about this? the reasons why i ask the question is: 1. caller is unlikely to pass `null`. 2. i looked over a number of other existing classes in kafka, and there aren't any null checks for most constructor parameters. it will help me if you could share couple examples from existing code where the `null` check convention is followed in kafka.",0,0.9843511581420898
427023377,8680,kowshik,2020-05-19T04:29:55Z,done. good point!,1,0.9948235750198364
427023394,8680,kowshik,2020-05-19T04:30:00Z,done.,0,0.9640594124794006
427023705,8680,kowshik,2020-05-19T04:31:11Z,"done. yes, i've changed it to default visibility now.",0,0.9496510624885559
427023770,8680,kowshik,2020-05-19T04:31:31Z,done. removed it.,0,0.9659409523010254
427024341,8680,kowshik,2020-05-19T04:34:02Z,done. good point!,1,0.9948235750198364
427024379,8680,kowshik,2020-05-19T04:34:12Z,done. good point!,1,0.9948235750198364
427025378,8680,kowshik,2020-05-19T04:38:08Z,"the underlying data structure is a `map`. it would be simpler if this method just returns `null` if the feature doesn't exist. for example, that is how java's `map.get` works, here is the javadoc: [a link] also, i've documented this method now (doc was previously absent).",0,0.9906912446022034
427025539,8680,kowshik,2020-05-19T04:38:51Z,done.,0,0.9640594124794006
427025597,8680,kowshik,2020-05-19T04:39:05Z,done.,0,0.9640594124794006
427025866,8680,kowshik,2020-05-19T04:40:04Z,done. good point! added test as well.,1,0.9912649989128113
427027670,8680,kowshik,2020-05-19T04:47:29Z,it provides slightly better convenience: `object.equals` will also take care of the `null` checks for you. also it turned out it was overkill to use `objects.equals` for primitive type checks for `minvalue` and `maxvalue`. so i've simplified the code to use `==` those attributes. good point!,1,0.9946932196617126
427027909,8680,kowshik,2020-05-19T04:48:28Z,done.,0,0.9640594124794006
427033616,8680,kowshik,2020-05-19T05:10:37Z,done. also added a test. good catch!,1,0.9954515099525452
427034499,8680,kowshik,2020-05-19T05:13:51Z,done. good point!,1,0.9948235750198364
427034758,8680,kowshik,2020-05-19T05:14:57Z,"are you sure? all newly added fields are tagged (i.e. optional). going by [a link] in kip-482, it is not required to change the schema version whenever tagged fields are introduced.",0,0.990633487701416
427035290,8680,kowshik,2020-05-19T05:16:58Z,done.,0,0.9640594124794006
427035380,8680,kowshik,2020-05-19T05:17:19Z,done.,0,0.9640594124794006
427042310,8680,kowshik,2020-05-19T05:42:26Z,done.,0,0.9640594124794006
427042434,8680,kowshik,2020-05-19T05:42:49Z,done.,0,0.9640594124794006
427043245,8680,kowshik,2020-05-19T05:45:33Z,"done. some of it is not required. good point, i have removed the unnecessary testing now. we still need to check if exception is thrown in these 4 basic tests: min < 1, max < 1, min & max < 1 and max > min.",1,0.5525991320610046
427043710,8680,kowshik,2020-05-19T05:47:05Z,done.,0,0.9640594124794006
427044348,8680,kowshik,2020-05-19T05:49:07Z,"no, this constructor overload was simply created to avoid a churn of test code at number of places adding the additional `supportedfeatures` parameter. how do you feel about keeping it?",0,0.983232319355011
427045136,8680,kowshik,2020-05-19T05:51:37Z,done. good point!,1,0.9948235750198364
427045338,8680,kowshik,2020-05-19T05:52:15Z,done. it was unused and i have eliminated it now.,0,0.9527587294578552
427045754,8680,kowshik,2020-05-19T05:53:30Z,done.,0,0.9640594124794006
427045906,8680,kowshik,2020-05-19T05:54:00Z,done.,0,0.9640594124794006
427046004,8680,kowshik,2020-05-19T05:54:19Z,done.,0,0.9640594124794006
427046331,8680,kowshik,2020-05-19T05:55:17Z,it is used intentionally to split the log message into 2 lines (for ~100-char readability limit per line). otherwise the string will be huge and all in the same line.,0,0.9319535493850708
427046353,8680,kowshik,2020-05-19T05:55:21Z,it is used intentionally to split the log message into 2 lines (for ~100-char readability limit per line). otherwise the string will be huge and all in the same line.,0,0.9319535493850708
427047251,8680,kowshik,2020-05-19T05:58:04Z,"i have added comments now to the code. the idea i had was that this event may happen, rarely (ex: operational error). in such a case, we do not want to kill the brokers, so we just log a warning and treat the case as if the node is absent, and populate the cache with empty features. so, this case is actually handled inside `featurecacheupdater.updatelatestorthrow()`. the call to read zk node will return `zkversion.unknownversion` whenever the node does not exist in zk, and i've explicitly handled this returned version.",0,0.9917934536933899
427047400,8680,kowshik,2020-05-19T05:58:32Z,done.,0,0.9640594124794006
427048695,8680,kowshik,2020-05-19T06:02:19Z,good point. i have improved the doc now. let me know how you feel about it.,1,0.9861873388290405
427049093,8680,kowshik,2020-05-19T06:03:24Z,done.,0,0.9640594124794006
427049831,8680,kowshik,2020-05-19T06:05:39Z,done.,0,0.9640594124794006
427050030,8680,kowshik,2020-05-19T06:06:13Z,"yes, this will get used in the future. for example the write path will use it.",0,0.9887068271636963
427050597,8680,kowshik,2020-05-19T06:07:55Z,done. good point!,1,0.9948235750198364
427057916,8680,kowshik,2020-05-19T06:27:29Z,done.,0,0.9640594124794006
427060765,8680,kowshik,2020-05-19T06:34:31Z,"the tests have been already added. pls check out the tests added in `apiversionsresponsetest.java`, particularly: `shouldreturnfeaturekeyswhenmagiciscurrentvalueandthrottlemsisdefaultthrottle`. let me know if this test does not look sufficient.",0,0.9940550327301025
427063053,8680,kowshik,2020-05-19T06:39:32Z,done.,0,0.9640594124794006
427063724,8680,kowshik,2020-05-19T06:40:58Z,done.,0,0.9640594124794006
427064271,8680,kowshik,2020-05-19T06:42:10Z,"in my understanding, this is an impossible case. because, we always write features into the json only in v5 or above. that is why, there is no test for it. let me know how you feel about it.",0,0.9156864285469055
427064923,8680,kowshik,2020-05-19T06:43:33Z,done.,0,0.9640594124794006
427827018,8680,kowshik,2020-05-20T08:21:37Z,"as we discussed offline today, this exception is already handled in `changenotificationprocessorthread.dowork()` method defined in `finalizedfeaturechangelistener.scala`. basically, the zk change notification processor thread exits the broker with a fatal error (non-zero exit code) when this exception (or any exception) is caught while trying to update `finalizedfeaturecache`.",0,0.994530975818634
427884165,8680,kowshik,2020-05-20T09:51:49Z,done.,0,0.9640594124794006
427885025,8680,kowshik,2020-05-20T09:53:14Z,"done. good point! - i have now created 3 classes as you proposed. `baseversionrange` is the base class, and, `supportedversionrange` & `finalizedversionrange` are it's child classes. - the key labels couldn't be made into abstract functions since these constants are needed within `deserialize()` which is a static method defined in the child classes.",1,0.9915580749511719
428080079,8680,abbccdda,2020-05-20T14:55:57Z,"yea, the reasoning is that we have `get` call blindly look up inside `features` which in this case null is not valid. and i don't feel passing `null` makes sense for the caller, correct?",0,0.9053564071655273
428367400,8680,abbccdda,2020-05-20T23:39:32Z,`deserialize()`? i think the second sentence is redundant.,0,0.9838579297065735
428370254,8680,abbccdda,2020-05-20T23:48:46Z,do we want to get a unit test class for `baseversionrange`?,0,0.9944720268249512
428370905,8680,abbccdda,2020-05-20T23:51:04Z,should be `supportedversionrange`,0,0.9934723377227783
428371260,8680,abbccdda,2020-05-20T23:52:20Z,"just for the sake of argument, i feel we could remove this method and just test: [code block] for incompatibility.",0,0.9853470325469971
428392754,8680,abbccdda,2020-05-21T01:13:18Z,nit: supportedversionrange,0,0.9848031997680664
428392936,8680,abbccdda,2020-05-21T01:14:10Z,why this is a `note`? could we just comment like: [code block],0,0.9913289546966553
428402864,8680,abbccdda,2020-05-21T01:54:32Z,"maybe i'm a bit too obsessive about code duplication, but after i made an attempt i thought we could actually have the internal deserialization logic shared between `deserializefinalizedfeatures` and `deserializesupportedfeatures` by making a template [code block]",0,0.6047729253768921
428403904,8680,abbccdda,2020-05-21T01:58:35Z,missing header,0,0.9673138856887817
428404068,8680,abbccdda,2020-05-21T01:59:14Z,seems we didn't trigger style check on this new class.,0,0.9902614951133728
428404491,8680,abbccdda,2020-05-21T02:00:52Z,what's the difference between this test class and its super class test case? same question for `supportedversionrangetest`,0,0.9940279722213745
428418517,8680,abbccdda,2020-05-21T02:58:16Z,could we move this logic as part of inner else? like: [code block] it makes the if-else logic more tight.,0,0.9926071166992188
428419538,8680,abbccdda,2020-05-21T03:02:18Z,"i think we don't need to talk about future work inside the comment, just making it clear that the read path for serving apiversionsrequest is the only reader as of now.",0,0.9710803031921387
428420141,8680,abbccdda,2020-05-21T03:04:59Z,nit: provide,0,0.9641706943511963
428421713,8680,abbccdda,2020-05-21T03:11:58Z,do we need the comment to be on info level?,0,0.9935261011123657
428422280,8680,abbccdda,2020-05-21T03:14:25Z,nit: don't feel strong about having this parameter,-1,0.9570797681808472
428422483,8680,abbccdda,2020-05-21T03:15:18Z,feel neutral about this helper function,-1,0.9367417097091675
428422966,8680,abbccdda,2020-05-21T03:17:24Z,"i don't think this is scala accepted comment style to add `-`, do you see a warning?",0,0.9022693037986755
428424395,8680,abbccdda,2020-05-21T03:23:53Z,`feature cache update gets interrupted`,0,0.9887186288833618
428426189,8680,abbccdda,2020-05-21T03:31:57Z,"does the version field existence guarantee there is a valid feature data node or not? in fact, `getdataandversion` returns an optional data. i checked the getdataandversion caller `produceridmanager`, there is a handling for empty data which i feel we should have as well. additionally, i think since we haven't implemented the write path yet, could we get a ticket to write down a short description on how the write path shall look like, by defining the different cases like: [code block] if that makes sense, so that we could keep track of the design decisions we made in the read path pr when implementing the write path.",0,0.9807206988334656
428426448,8680,abbccdda,2020-05-21T03:33:03Z,"could we summary the possible thrown error code in the comment as well? for example, does a json deserialization error should be treated as fatal?",0,0.9928972721099854
428429013,8680,abbccdda,2020-05-21T03:44:51Z,"is it possible to have no enqueued updater, and cause this function block the thread indefinitely?",0,0.9638203978538513
428429615,8680,abbccdda,2020-05-21T03:47:38Z,"for an educational question, does the zkclient have a separate thread to do the node change monitoring?",0,0.9933520555496216
428430093,8680,abbccdda,2020-05-21T03:49:45Z,does the order matter here? i was wondering if there is any concurrent issue if we unregister before the queue and thread get cleaned up.,0,0.9371200799942017
428430356,8680,abbccdda,2020-05-21T03:50:57Z,we could just comment `for testing only`,0,0.993665874004364
428430553,8680,abbccdda,2020-05-21T03:51:55Z,`wait time for the first feature cache update upon initialization`,0,0.9915332198143005
428430779,8680,abbccdda,2020-05-21T03:52:57Z,"i think the comment is not necessary, since we have already commented on `kafka_2_6_iv1`",0,0.9860504269599915
428431584,8680,abbccdda,2020-05-21T03:56:16Z,nit: returns a reference to the latest features supported by the broker.,0,0.9881861209869385
428432424,8680,abbccdda,2020-05-21T04:00:05Z,this logging is duplicate,0,0.933893620967865
428432727,8680,abbccdda,2020-05-21T04:01:36Z,"i'm slightly inclined to return a set of features instead of just strings, and make the string conversion as a helper. but i leave this up to you to decide, and we could always adapt the function to make it more useful in other scenarios as needed.",0,0.9068710207939148
428432904,8680,abbccdda,2020-05-21T04:02:25Z,"if that's the case, i feel we could remove the testing only comment.",0,0.9814082980155945
428433279,8680,abbccdda,2020-05-21T04:04:10Z,"aha, the order is wrong for `kafka_0_10_0_iv1` and `kafka_2_6_iv1`",0,0.9727079272270203
428433517,8680,abbccdda,2020-05-21T04:05:31Z,"i think even if this is an operational error, the cluster is at risk of violating the feature semantics previously enabled, which is different from an unknown feature version from the beginning. i feel we should just exit in fatal error for this case, but would open for discussion.",0,0.8504036664962769
428434151,8680,abbccdda,2020-05-21T04:08:21Z,s/asjavamap/featuresasjavamap,0,0.9920761585235596
428434945,8680,abbccdda,2020-05-21T04:11:27Z,could we log statusint here as well? also i feel the exception should be thrown from `featureznodestatus.withnameopt`,0,0.994174063205719
428435694,8680,abbccdda,2020-05-21T04:15:15Z,is there a more dedicated exception code for deserialization error? i feel the kafkaexception is a bit too general compared with illegalargument,0,0.7869442701339722
428436046,8680,abbccdda,2020-05-21T04:16:59Z,could we name it v0 for simplicity?,0,0.994040310382843
428436573,8680,abbccdda,2020-05-21T04:19:58Z,"i feel we might worth creating a separate thread discussing whether we could get some benefit of the automated protocol generation framework here, as i think this could be easily represented as json if we define it in the common package like other rpc data. the difficulty right now is mostly on the serialization and deserialization for feature itself, but these could have workarounds if we want to do so.",0,0.9836034774780273
428437318,8680,abbccdda,2020-05-21T04:23:22Z,"i'm a bit surprised, do we want to support feature znode deletion in long term?",-1,0.9228475093841553
428437571,8680,abbccdda,2020-05-21T04:24:39Z,could we extract some common initialization logic for the tests to reduce duplication?,0,0.9925726652145386
428437659,8680,abbccdda,2020-05-21T04:24:58Z,nit: space,0,0.8302400708198547
428438063,8680,abbccdda,2020-05-21T04:27:00Z,"if we are not validating the features by extracting them, i think we do not need to pass in a non-empty feature list?",0,0.9896548986434937
428573407,8680,kowshik,2020-05-21T10:32:12Z,"it is thoroughly tested in it's child class test suite: `supportedversionrangetest`. personally i feel it is good enough this way, because, anyway to test this class we need to inherit into a sub-class (since constructor is `protected`). and by testing via `supportedversionrangetest`, we achieve exactly the same. i have now added top-level documentation in the test suite of `supportedversionrangetest`, explaining the above.",0,0.7700850367546082
428576410,8680,kowshik,2020-05-21T10:39:55Z,done. i'm raising an exception now if it is `null`. i see your point. will be good to learn what is the convention in kafka for constructor param null checks.,0,0.6139294505119324
428577156,8680,kowshik,2020-05-21T10:41:42Z,done.,0,0.9640594124794006
428578424,8680,kowshik,2020-05-21T10:44:59Z,done.,0,0.9640594124794006
428578472,8680,kowshik,2020-05-21T10:45:04Z,done. good point!,1,0.9948235750198364
428578829,8680,kowshik,2020-05-21T10:45:53Z,done.,0,0.9640594124794006
428579070,8680,kowshik,2020-05-21T10:46:29Z,done. good point!,1,0.9948235750198364
428579884,8680,kowshik,2020-05-21T10:48:19Z,done.,0,0.9640594124794006
428580337,8680,kowshik,2020-05-21T10:49:28Z,done.,0,0.9640594124794006
428581013,8680,kowshik,2020-05-21T10:51:04Z,done. good point!,1,0.9948235750198364
428581253,8680,kowshik,2020-05-21T10:51:45Z,done.,0,0.9640594124794006
429069672,8680,kowshik,2020-05-22T06:41:44Z,done.,0,0.9640594124794006
429071500,8680,kowshik,2020-05-22T06:47:02Z,"done. i have simplified this test suite eliminating the redundant tests, and only keeping the ones specific to `finalizedversionrange`. also i have added documentation to both test suites explaining their purpose.",0,0.9551530480384827
429074215,8680,kowshik,2020-05-22T06:55:11Z,done. changed to `illegalargumentexception`. good point!,1,0.9917717576026917
429076303,8680,kowshik,2020-05-22T07:01:08Z,"done. for the other point, i don't feel strongly for it. i feel it is ok to have an api that doesn't throw and just lets the caller decide (based on the context) if an empty returned value is incorrect.",0,0.7732954025268555
429076742,8680,kowshik,2020-05-22T07:02:23Z,no. but we want to test the behavior about what happens during a deletion (ex: operational error).,0,0.974151074886322
429077064,8680,kowshik,2020-05-22T07:03:13Z,done.,0,0.9640594124794006
429077469,8680,kowshik,2020-05-22T07:04:23Z,done.,0,0.9640594124794006
429078661,8680,kowshik,2020-05-22T07:07:36Z,"as far as i can see, no zk node class defined in this file is defined in such a way. every class in this file encodes/decodes json by itself, and manages its own attributes. should we break the norm?",0,0.9620934128761292
429086184,8680,kowshik,2020-05-22T07:27:10Z,done.,0,0.9640594124794006
429087972,8680,kowshik,2020-05-22T07:31:25Z,"see l848 below where it is validated. the call to `zkclient. getallbrokersincluster` decodes each `brokeridznode` content from json to `brokerinfo` object. then, we check whether the call returns exactly the same `brokerinfo` objects defined here, and, along the way features are checked too.",0,0.9906594753265381
429089245,8680,kowshik,2020-05-22T07:34:40Z,done.,0,0.9640594124794006
429089574,8680,kowshik,2020-05-22T07:35:30Z,done. good catch!,1,0.9958080053329468
429089817,8680,kowshik,2020-05-22T07:36:05Z,done.,0,0.9640594124794006
429090026,8680,kowshik,2020-05-22T07:36:42Z,done.,0,0.9640594124794006
429093727,8680,kowshik,2020-05-22T07:45:18Z,done. good point!,1,0.9948235750198364
429096612,8680,kowshik,2020-05-22T07:51:42Z,done. removed extra logging in the caller of this method (see `finalizedfeaturecache`).,0,0.9922871589660645
429101010,8680,kowshik,2020-05-22T08:01:36Z,"done. yes, i feel json deserialization should be treated as fatal. it should never happen, and, can indicate corruption.",0,0.9530530571937561
429107026,8680,kowshik,2020-05-22T08:14:57Z,done. removed.,0,0.9667683243751526
429107347,8680,kowshik,2020-05-22T08:15:43Z,"done. but it's actually ""change notification queue interrupted"".",0,0.909151017665863
429109170,8680,kowshik,2020-05-22T08:19:43Z,"the function blocks indefinitely - yes. but this shouldn't cause a problem or lead to deadlock/limbo situation. even if this thread is waiting for an item to become available in the queue, the waiting thread can always get interrupted by the `finalizedfeaturechangelistener.close()` call which calls `shutdownablethread.shutdown()`. note that the `shutdownablethread.shutdown()` method interrupts the thread, which should unblock any waiting `queue.take()` operation and makes it raise an `interruptedexception`: [a link] [a link]",0,0.9840282797813416
429110087,8680,kowshik,2020-05-22T08:21:36Z,done. removed.,0,0.9667683243751526
429111103,8680,kowshik,2020-05-22T08:23:51Z,"i didn't understand the question. are you saying the logging severity should be lower or higher? this is a rare case anyway as the feature node doesn't get created often, so, `info` logging seems fine to me.",0,0.8760056495666504
429113491,8680,kowshik,2020-05-22T08:28:40Z,"you bring up a good point. my main concern is availability. if we exit the broker here, then, whenever the feature zk node gets deleted (accidentally), it could crash all brokers in the fleet all at once leading to an availability problem. with regards to violating feature semantics, good point. i'm in 2 minds here, and perhaps we can also hear 's thoughts on this topic.",1,0.64341801404953
429117278,8680,kowshik,2020-05-22T08:36:30Z,yes. here is the documentation explaining the same: [a link],0,0.9760111570358276
429117918,8680,kowshik,2020-05-22T08:37:53Z,done. removed.,0,0.9667683243751526
429120585,8680,kowshik,2020-05-22T08:43:40Z,the order probably doesn't matter in this case. but logically i decided to follow the below order since i could reason about it better: 1. stop the inflow of new events 2. clear pending events 3. stop the processing of all events,0,0.9870928525924683
429120739,8680,kowshik,2020-05-22T08:44:04Z,done.,0,0.9640594124794006
429123988,8680,kowshik,2020-05-22T08:50:49Z,"i have added documentation here in this method describing all the cases. the empty data case should never happen and can indicate a corruption. the reason is that we always return non-empty data in `featureznode.encode`, so the zk node content should never empty. yes, i can add some more info to kafka-10028 or in the write path pr summary.",0,0.9908181428909302
429126751,8680,kowshik,2020-05-22T08:56:54Z,done.,0,0.9640594124794006
429126867,8680,kowshik,2020-05-22T08:57:07Z,done.,0,0.9640594124794006
429128812,8680,kowshik,2020-05-22T09:01:12Z,done.,0,0.9640594124794006
429474760,8680,abbccdda,2020-05-22T22:08:39Z,we could have multiple here,0,0.9853559136390686
429476928,8680,abbccdda,2020-05-22T22:19:31Z,"i didn't look thoroughly enough, but the only illegalargumentexception i found is [code block] which should never happen as we always use `matchanyversion` in `retryrequestsuntilconnected`. are we trying to catch some other exceptions here?",0,0.9610002636909485
429480603,8680,abbccdda,2020-05-22T22:38:14Z,"my feeling is that this could be on debug level, but no strong perference.",0,0.6019495725631714
429494635,8680,abbccdda,2020-05-23T00:13:07Z,nit: minkeylabel,0,0.9805732369422913
429495765,8680,abbccdda,2020-05-23T00:22:36Z,"i see, makes sense.",0,0.9320074915885925
429496037,8680,abbccdda,2020-05-23T00:24:54Z,nit: we could test `emptysupportedfeatures.features().isempty()`,0,0.9943600296974182
429497749,8680,abbccdda,2020-05-23T00:40:54Z,nit: could you elaborate why this helper function and `finalizedfeaturesandepoch` struct is useful in this context? just for easier message printing?,0,0.9940258264541626
429498395,8680,abbccdda,2020-05-23T00:48:10Z,so here we will directly throw nosuchelementexception if `maybefeatureznodebytes` is empty? do we want to check this case and throw a customized exception instead?,0,0.9917464256286621
429498408,8680,abbccdda,2020-05-23T00:48:17Z,nit: space,0,0.8302400708198547
429499008,8680,abbccdda,2020-05-23T00:54:28Z,"this leads to a more general question: is there a way to cleanup all the zk feature path? reading from the kip, i don't see we have any admin api to do so, which makes me wonder how could this case happen in reality. in terms of severity, i think crushing the entire cluster seems to be an overkill as well, maybe we should have some blocking mechanism in place for any feature extraction call here, until we see `handlecreation` gets triggered again?",0,0.8713071346282959
429509179,8680,abbccdda,2020-05-23T03:18:11Z,"nit: one liner: `this.features = objects.requirenonnull(features, ""provided features can not be null."");`",0,0.9919843077659607
429509941,8680,abbccdda,2020-05-23T03:30:12Z,nit: remove `only`,0,0.9903426170349121
429510099,8680,abbccdda,2020-05-23T03:32:02Z,"this comment should be frequent and the `featurezknodepath` is staying constant, could we just make it for debugging level?",0,0.9894471168518066
429510224,8680,abbccdda,2020-05-23T03:34:25Z,"i don't think this note is necessary, maybe just merge with the first line as: [code block]",0,0.9875883460044861
429510520,8680,abbccdda,2020-05-23T03:39:24Z,"do you think we should add this config as part of the kip since it is public? i think it would just be a minor update, but let's wait and see others thoughts on this.",0,0.9827629327774048
429510746,8680,abbccdda,2020-05-23T03:43:32Z,remove semi-colon,0,0.9779518842697144
429511091,8680,abbccdda,2020-05-23T03:50:12Z,s/it's/its,0,0.9123643636703491
429511146,8680,abbccdda,2020-05-23T03:51:19Z,`a kafka cluster exists already and the ibp config is less than kafka_2_6_iv1` to `an existing kafka cluster with ibp config less than kafka_2_6_iv1`,0,0.9949232935905457
429511236,8680,abbccdda,2020-05-23T03:52:57Z,"i think the norm exists because we don't have automated framework by then, and doing hand-written json serialization and deserialization is a bit wasting. cc as this is a major direction discussion.",0,0.8444727659225464
429589291,8680,kowshik,2020-05-24T00:51:52Z,done.,0,0.9640594124794006
429589607,8680,kowshik,2020-05-24T01:00:30Z,done. also added doc.,0,0.9305221438407898
429590012,8680,kowshik,2020-05-24T01:12:17Z,done.,0,0.9640594124794006
429590179,8680,kowshik,2020-05-24T01:16:53Z,"actually i've eliminated the helper method now, and, there is only 1 method: `updateorthrow(...)`.",0,0.9902588129043579
429590200,8680,kowshik,2020-05-24T01:17:20Z,done.,0,0.9640594124794006
429590218,8680,kowshik,2020-05-24T01:17:45Z,done.,0,0.9640594124794006
429590248,8680,kowshik,2020-05-24T01:18:15Z,done.,0,0.9640594124794006
429590426,8680,kowshik,2020-05-24T01:23:07Z,"fixed now. good point. actually the code was incorrect. i meant to wrap `featureznode.decode` call with the `try-catch`, since, it throws `illegalargumentexception`. i have fixed the code now to do the same.",1,0.6689053177833557
429590504,8680,kowshik,2020-05-24T01:25:20Z,done.,0,0.9640594124794006
429590532,8680,kowshik,2020-05-24T01:25:46Z,done.,0,0.9640594124794006
429590593,8680,kowshik,2020-05-24T01:27:36Z,"sounds good. yeah, it is minor and feels like an implementation detail to me. but we can wait to see what others say.",1,0.9527556896209717
429590614,8680,kowshik,2020-05-24T01:27:57Z,done.,0,0.9640594124794006
429590626,8680,kowshik,2020-05-24T01:28:30Z,done.,0,0.9640594124794006
429590656,8680,kowshik,2020-05-24T01:29:04Z,done.,0,0.9640594124794006
429591914,8680,kowshik,2020-05-24T01:59:16Z,done.,0,0.9640594124794006
429593151,8680,kowshik,2020-05-24T02:26:04Z,"the deletion of znode is a rare case, it should never happen in reality unless it is zk corruption, or rarely an operational error that deletes some zk nodes. it's not easy to prevent damage in such a case. from a correctness standpoint, imagine what would happen if the feature znode gets deleted, and, afterwards a broker restarts. it will start with empty cache, so the damage is done. therefore, it seems that even if we add a special logic here, we can not prevent damage if the source of truth is lost. two things to note here: 1. the client should anyway ignore older stale epoch responses, if it had seen newer epochs that are greater. in that spirit, the client can be also made to treat the absence of finalized features in an `apiversionsresponse` just like a stale epoch case, if, it had seen at least one valid `apiversionsresponse` earlier (i.e. at least one response with some valid epoch). 2. deletion of individual finalized feature is actually supported in [a link], but not deletion of the entire znode. search for the word 'deletion' in the kip write-up. if needed, this deletion functionality could be extended to provide the ability to delete all features too.",0,0.921920895576477
430737606,8680,abbccdda,2020-05-26T22:15:42Z,"thanks, i don't think we need to be super paranoid with this rare scenario, but we should also be indicating this error state to the client suggesting that some manual fix is necessary. my proposed idea above is to add such an error state to the feature cache to refuse any further updates until we have: 1. a node creation event 2. restart of the broker (once the issue gets fixed), so this blocking behavior shall be ephemeral and recoverable from broker perspective. we don't have to implement this logic in the current pr, as we don't have a write path yet, just get a jira to track it sounds fine. make sense to cc and as well.",0,0.7062536478042603
432781217,8680,junrao,2020-05-29T23:29:07Z,"this won't make 2.6.0 release. so, perhaps we should use kafka_2_7 or whatever the next release is?",0,0.9895260334014893
432782068,8680,junrao,2020-05-29T23:33:18Z,"i missed this in the kip, but it seems that long is overkilling for version. the version in request is short and the version in zk data is int. so, perhaps this should just be short?",0,0.851454496383667
432782926,8680,junrao,2020-05-29T23:37:35Z,"minvalue > 1, maxvalue > 1 => minvalue >= 1, maxvalue >= 1",0,0.969600260257721
432783145,8680,junrao,2020-05-29T23:38:43Z,should we include the label too?,0,0.9936431646347046
432783472,8680,junrao,2020-05-29T23:40:25Z,serialize typically means generating binary data. perhaps this is better called tomap()?,0,0.9935558438301086
433327328,8680,junrao,2020-06-01T15:53:29Z,missing license header,0,0.9875472784042358
433337829,8680,junrao,2020-06-01T16:10:17Z,empty => isempty ?,0,0.9853425025939941
433347401,8680,junrao,2020-06-01T16:27:29Z,"could we use map {case(feature, versionlevel, _) => ...} to avoid unnamed references like _1?",0,0.9936830997467041
433359805,8680,junrao,2020-06-01T16:50:36Z,the kip doesn't seems to include this field. could we add it to the kip wiki?,0,0.9856359958648682
433366871,8680,junrao,2020-06-01T17:03:47Z,"interruptedexception can be thrown if the thread is shut down explicitly. in this case, we probably don't want to throw runtimeexception to the caller.",0,0.9698909521102905
433373309,8680,junrao,2020-06-01T17:16:17Z,"hmm, could we just use config.zkconnectiontimeoutms for this, instead of introducing a new config?",0,0.99139004945755
433375459,8680,junrao,2020-06-01T17:20:23Z,"hmm, is waitonceforcacheupdatems <=0 supported? in that case, it seems that we still need to read the /features path in zk?",0,0.9919596314430237
433382257,8680,junrao,2020-06-01T17:32:58Z,"if this thread is being closed, the interruptedexception is expected and we don't need to log this.",0,0.9860664010047913
433384475,8680,junrao,2020-06-01T17:37:12Z,"hmm, this just kills the thread, but not the broker as the comment says. also, not sure about killing the broker. we probably should just log an error and continue since this is not necessarily fatal.",-1,0.723537266254425
433395727,8680,junrao,2020-06-01T17:58:03Z,"hmm, the epoch returned from zk is int32. does finalizedfeaturesepoch need to be int64?",0,0.9918015599250793
433399575,8680,junrao,2020-06-01T18:05:16Z,"hmm, why is finalizedfeaturesepoch an optional but latestsupportedfeatures is not?",0,0.9606757164001465
433400012,8680,junrao,2020-06-01T18:06:06Z,should we add public methods for accessing those fields?,0,0.9934715032577515
433402784,8680,junrao,2020-06-01T18:11:26Z,it doesn't seem we store security protocol map in the broker registration.,0,0.9846571087837219
433403260,8680,junrao,2020-06-01T18:12:25Z,should we include the new field in tostring()?,0,0.9930197596549988
433409944,8680,junrao,2020-06-01T18:25:22Z,the existing comments seem incorrect since we don't store listener_security_protocol_map in zk.,0,0.9755324125289917
434343065,8680,kowshik,2020-06-03T06:47:41Z,done. made it kafka_2_7_iv0.,0,0.9784113168716431
434344257,8680,kowshik,2020-06-03T06:50:32Z,done. i have made it `int16` now. great point.,1,0.9866053462028503
434345400,8680,kowshik,2020-06-03T06:53:05Z,done.,0,0.9640594124794006
434346281,8680,kowshik,2020-06-03T06:55:08Z,done.,0,0.9640594124794006
434417020,8680,kowshik,2020-06-03T09:01:38Z,done.,0,0.9640594124794006
434428173,8680,kowshik,2020-06-03T09:20:02Z,"it's because non-existing supported features _can_ be represented by an empty map (i.e. broker does not advertise any features). but on the other hand, non-existing finalized features can not be represented by empty map alone, as we need a suitable epoch value that indicates the absence of finalized features. to address this case, i saw 2 ways: 1) provide a negative epoch value indicating absence of finalized features, or 2) represent using an empty `optional` for both finalized features and epoch. i chose the latter approach. please, let me know if you have concerns.",0,0.9861735105514526
434431330,8680,kowshik,2020-06-03T09:25:27Z,"i had added such apis previously. but wanted these removed, as they are not currently unused. please refer to this comment: [a link] please, let me know, and i can add them back if you prefer.",0,0.9555396437644958
434431880,8680,kowshik,2020-06-03T09:26:20Z,done. changed to `int32` now. great point!,1,0.9957900643348694
434434381,8680,kowshik,2020-06-03T09:30:30Z,done.,0,0.9640594124794006
434434804,8680,kowshik,2020-06-03T09:31:10Z,done. nice catch!,1,0.9960498213768005
434435193,8680,kowshik,2020-06-03T09:31:48Z,done.,0,0.9640594124794006
434435824,8680,kowshik,2020-06-03T09:32:53Z,done.,0,0.9640594124794006
434438288,8680,kowshik,2020-06-03T09:36:50Z,done. removed the catch clause and exception wrapping.,0,0.9873931407928467
434441200,8680,kowshik,2020-06-03T09:41:16Z,done.,0,0.9640594124794006
434443007,8680,kowshik,2020-06-03T09:44:10Z,"it kills the broker because `shutdownablethread` catches `fatalexiterror` and triggers exit sequence: [a link] i have updated the comment to use the word ""eventually"". regarding logging fatal and continuing -- the exception caught here almost always indicates a feature incompatibility, and, that means the broker can cause damage if it sticks around. that is why i felt it is better to kill the broker in such a rare incompatibility case. please, let me know your thoughts.",0,0.94756680727005
434444716,8680,kowshik,2020-06-03T09:46:55Z,done. i have changed the code disallowing values <= 0.,0,0.9602656364440918
434444848,8680,kowshik,2020-06-03T09:47:11Z,done. great point!,1,0.9958512783050537
434445428,8680,kowshik,2020-06-03T09:48:14Z,done.,0,0.9640594124794006
434448455,8680,kowshik,2020-06-03T09:53:30Z,done. removed. great catch!,1,0.9959730505943298
434450195,8680,kowshik,2020-06-03T09:56:30Z,sure. i will be happy to follow up on this. trying to understand the process -- should i update the kip and send an email as fyi to `dev.apache.org` ?,1,0.9905271530151367
435543865,8680,junrao,2020-06-04T20:56:15Z,"to handle zk session expiration, we need to register a statechangehandler. that way, we can read the /features path from zk when the new session is established since the feature could have changed btw the old and the new zk sessions. see object zkstatechangehandler as an example.",0,0.9939305782318115
435558683,8680,junrao,2020-06-04T21:20:35Z,could we pass in `optional ` instead of two separate optional?,0,0.9944466352462769
435560941,8680,junrao,2020-06-04T21:23:29Z,"if finalizedfeaturesepoch is not present, we probably want to set the field to sth like -1 instead of leaving it as the default value of 0.",0,0.9926977753639221
435562341,8680,junrao,2020-06-04T21:26:15Z,the comment can be a bit misleading since features is not optional.,0,0.8464420437812805
435567942,8680,junrao,2020-06-04T21:39:10Z,it's probably better to close this before zkclient since the close call unregister from zkclient.,0,0.9942165613174438
435595571,8680,junrao,2020-06-04T22:53:02Z,the name of the method probably should include failure?,0,0.9902474284172058
435595915,8680,junrao,2020-06-04T22:54:00Z,missing license header,0,0.9875472784042358
435596401,8680,junrao,2020-06-04T22:55:36Z,"could we just assertequals(featureznode, decoded)?",0,0.9950904846191406
435597745,8680,junrao,2020-06-04T22:59:39Z,`version > currentversion` means that we can't downgrade the broker. we will need to relax this check.,0,0.9837146401405334
435598956,8680,junrao,2020-06-04T23:03:22Z,missing license header,0,0.9875472784042358
435601124,8680,junrao,2020-06-04T23:10:31Z,missing license header,0,0.9875472784042358
435604964,8680,junrao,2020-06-04T23:23:22Z,"hmm, if the feature is disabled, it seems that updatedfinalizedfeatures shouldn't be reflected in the cache, right?",0,0.9178804159164429
435606223,8680,junrao,2020-06-04T23:27:47Z,do we want to throw an exception here?,0,0.9846611618995667
435607391,8680,junrao,2020-06-04T23:31:54Z,missing license header,0,0.9875472784042358
436493426,8680,kowshik,2020-06-08T07:04:45Z,done.,0,0.9640594124794006
436493633,8680,kowshik,2020-06-08T07:05:14Z,done.,0,0.9640594124794006
436494049,8680,kowshik,2020-06-08T07:06:16Z,done.,0,0.9640594124794006
436495007,8680,kowshik,2020-06-08T07:08:46Z,done. great point!,1,0.9958512783050537
436495405,8680,kowshik,2020-06-08T07:09:48Z,done.,0,0.9640594124794006
436495661,8680,kowshik,2020-06-08T07:10:28Z,done.,0,0.9640594124794006
436496035,8680,kowshik,2020-06-08T07:11:21Z,done.,0,0.9640594124794006
436496254,8680,kowshik,2020-06-08T07:11:54Z,done.,0,0.9640594124794006
436515190,8680,kowshik,2020-06-08T07:53:52Z,done. i have modified the code such that `featurecacheupdater.updatelatestorthrow` will now clear the cache whenever it sees that the feature zk node is disabled. great point!,1,0.9948040843009949
436524414,8680,kowshik,2020-06-08T08:11:36Z,done. changed it to use a latch that gets notified when the exit procedure is called. great point!,1,0.9950512051582336
436527003,8680,kowshik,2020-06-08T08:16:56Z,done.,0,0.9640594124794006
436532143,8680,kowshik,2020-06-08T08:26:36Z,done.,0,0.9640594124794006
436543251,8680,kowshik,2020-06-08T08:47:05Z,done.,0,0.9640594124794006
436544409,8680,kowshik,2020-06-08T08:49:14Z,"done. i'm no longer passing 2 optionals, since, we decided (below) that epoch can be set as -1 whenever it is absent.",0,0.9739113450050354
436607402,8680,kowshik,2020-06-08T10:44:45Z,this config has been eliminated now.,0,0.9867693185806274
437045081,8680,junrao,2020-06-08T22:54:43Z,"this is not really ""change-notification"". so, the name can just be featureznode.path.",0,0.9887338876724243
437049072,8680,junrao,2020-06-08T23:06:49Z,2.6.x => 2.7.x,0,0.9908018708229065
437049227,8680,junrao,2020-06-08T23:07:19Z,2.6.x => 2.7.x,0,0.9908018708229065
437123822,8680,kowshik,2020-06-09T03:56:53Z,done.,0,0.9640594124794006
437123965,8680,kowshik,2020-06-09T03:57:29Z,done.,0,0.9640594124794006
437124061,8680,kowshik,2020-06-09T03:57:53Z,done.,0,0.9640594124794006
437140900,8680,abbccdda,2020-06-09T05:10:27Z,nit: we could use utils.mkmap here,0,0.991081953048706
437141678,8680,abbccdda,2020-06-09T05:13:44Z,"we don't need to check `other == null` here, the next condition check covers it.",0,0.9902542233467102
437143331,8680,abbccdda,2020-06-09T05:19:56Z,"nit: should all the parameters be final here, not just minmagic?",0,0.9838575124740601
437145250,8680,abbccdda,2020-06-09T05:26:56Z,"i overlooked this case, let's maintain this static constructor without renaming it, since it is public.",0,0.9843803644180298
437146576,8680,abbccdda,2020-06-09T05:31:25Z,"nit: instead of using comments, better to build this into the test name, for example: `testinvalidsuppportedfeatureswithmissingmaxversion`",0,0.9947234392166138
437153379,8680,abbccdda,2020-06-09T05:53:27Z,nit: {} not necessary,0,0.9006558656692505
437580565,8680,abbccdda,2020-06-09T16:57:16Z,nit: use `introduced` to align with previous comment?,0,0.9953917264938354
437582007,8680,abbccdda,2020-06-09T16:59:26Z,it's -> its,0,0.7586807608604431
437582948,8680,abbccdda,2020-06-09T17:00:59Z,could be simplified as `the latest known finalizedfeaturesandepoch or empty if not defined in the cache`,0,0.9955173134803772
437584758,8680,abbccdda,2020-06-09T17:04:11Z,"i think we could remove `if the cache update is not successful, then, a suitable exception is raised...` which is pretty obvious.",0,0.9714656472206116
437586235,8680,abbccdda,2020-06-09T17:06:41Z,"sorry it's been a while since my last review, but have we discussed the recovery path when we hit a data corruption exception for the cluster? is there a way to turn off the feature versioning completely to unblock, or we have a mechanism to wipe out zk data?",-1,0.9824081063270569
437592050,8680,abbccdda,2020-06-09T17:16:33Z,"being a bit paranoid here, would it be possible to have out-of-order updates from zk, such that the version number is not monotonically increasing? i'm thinking even we could throw in finalizedfeaturecache, do we really want to kill the broker, or we should just log a warning and proceed.",0,0.7642549276351929
437598721,8680,abbccdda,2020-06-09T17:27:52Z,"i think i'm no longer insisting on this point, as we could make this as a follow-up work. filed jira here: [a link]",0,0.9455620646476746
437604015,8680,abbccdda,2020-06-09T17:36:59Z,nit: space,0,0.8302400708198547
437605413,8680,abbccdda,2020-06-09T17:39:17Z,v4 doesn't have feature right? what's the purpose of this test?,0,0.9226179122924805
437606748,8680,abbccdda,2020-06-09T17:41:34Z,add the space back,0,0.987253725528717
437607867,8680,abbccdda,2020-06-09T17:43:22Z,nit: we could add a minor test to verify a negative `waitonceforcacheupdatems` will throw,0,0.990345299243927
437851289,8680,kowshik,2020-06-10T04:20:38Z,done.,0,0.9640594124794006
437851622,8680,kowshik,2020-06-10T04:21:57Z,done. good point.,1,0.9524728059768677
437855643,8680,kowshik,2020-06-10T04:38:46Z,done.,0,0.9640594124794006
437855789,8680,kowshik,2020-06-10T04:39:31Z,done.,0,0.9640594124794006
437856190,8680,kowshik,2020-06-10T04:41:11Z,done.,0,0.9640594124794006
437856298,8680,kowshik,2020-06-10T04:41:37Z,done.,0,0.9640594124794006
437856385,8680,kowshik,2020-06-10T04:41:59Z,done.,0,0.9640594124794006
437856510,8680,kowshik,2020-06-10T04:42:29Z,done.,0,0.9640594124794006
437857795,8680,kowshik,2020-06-10T04:47:48Z,done.,0,0.9640594124794006
437858130,8680,kowshik,2020-06-10T04:49:06Z,it's a 2-line block.,0,0.9900025129318237
437874395,8680,kowshik,2020-06-10T05:50:01Z,"1. re: out-of-order updates from zk: i don't understand. when a watch fires from zk, we react by issuing a zk read operation to obtain the latest value of the zk node (see l75). it is impossible that we get a stale read from zk after watch fires on the client side. 2. re: broker death: the exception thrown here almost always indicates a feature incompatibility, and, that means the broker can cause damage if it sticks around (because feature bumps are breaking changes and you can not allow an incompatible broker to stick around in the cluster). that is why i felt it is better to kill the broker in such a rare incompatibility case. note that after the controller has finalized features, there should be no brokers in the cluster with incompatibilites, so death here makes sense. note: i have also explained point #2 in this comment: [a link]",0,0.9742770195007324
437875708,8680,kowshik,2020-06-10T05:54:19Z,thanks. good idea to leave a jira. i have linked it to kafka-9755.,1,0.9944171905517578
437875864,8680,kowshik,2020-06-10T05:54:45Z,done.,0,0.9640594124794006
437876419,8680,kowshik,2020-06-10T05:56:21Z,it checks backwards compatibility i.e. it checks whether the deserialization code (v5-based) can correctly deserialize v4 such that features are assigned empty value by default..,0,0.995205819606781
437877179,8680,kowshik,2020-06-10T05:58:47Z,done.,0,0.9640594124794006
437877390,8680,kowshik,2020-06-10T05:59:31Z,done.,0,0.9640594124794006
437883374,8680,kowshik,2020-06-10T06:17:37Z,it's very rare especially when controller is the only entity writing to the zk node. i have now modified the code to handle this case and clear the cache. perhaps that's better than crashing the broker in such a case. remediation will need human intervention in fixing the zk node. we can provide tooling if required.,0,0.9842945337295532
1333345949,14406,philipnee,2023-09-21T16:40:02Z,is the extra line intentional?,0,0.9836241006851196
1333349057,14406,philipnee,2023-09-21T16:42:59Z,kafkaexception?,0,0.9720531702041626
1333353029,14406,philipnee,2023-09-21T16:46:45Z,it is handled in the error event handler - which means the user should get the exception upon invoking poll. i wonder if we could just log info or at a different level. or even no logging.,0,0.9720016121864319
1333353596,14406,philipnee,2023-09-21T16:47:22Z,extra line :grinning_face_with_sweat:,0,0.9921833872795105
1333355626,14406,philipnee,2023-09-21T16:49:19Z,ditto : as the error is log here - we might not need the extra logging,0,0.9879229664802551
1333393941,14406,junrao,2023-09-21T17:28:22Z,"just to understand this. if the consumer gets a fenced_leader_epoch, a metadata update is triggered. once the new metadata is received, the validatepositionsapplicationevent will trigger the offsetforleaderepoch request to validate the fetch position. until the new metadata is received, the consumer will just continuously fetch from the old leader and receiving the same fenced_leader_epoch error?",0,0.9905753135681152
1333594757,14406,junrao,2023-09-21T20:54:51Z,"i guess the purpose of this code is when there is no pending records, we block until some new records are fetched. however, i am wondering if it achieves the purpose. when processing a fetchevent, applicationprocessor just calls requestmanagers.fetchrequestmanager.drain(). if there is nothing to drain, an empty queue is returned immediately. this will unblock fetchevent to return immediately without waiting for the poll time?",0,0.9846946597099304
1333599432,14406,lianetm,2023-09-21T21:00:26Z,is this an old comment i guess?,0,0.9730172157287598
1333605133,14406,lianetm,2023-09-21T21:07:38Z,i find this name combination closer+assertopen kind of confusing. i even think it would it be easier to follow if we just had the explicit check `if(isclose()) throw` here,0,0.7220764756202698
1333613388,14406,lianetm,2023-09-21T21:17:24Z,do we expect to have nulls here even if these come from the blockingqueue that does not accept nulls?,0,0.9908577799797058
1333616692,14406,philipnee,2023-09-21T21:21:51Z,have you ran into a scenario that the module is null?,0,0.9863255620002747
1333617066,14406,lianetm,2023-09-21T21:22:23Z,"need ""to"" throw",0,0.9564487338066101
1333620613,14406,lianetm,2023-09-21T21:27:18Z,debug level better? (same for all other log lines in this func),0,0.9893195629119873
1333698259,14406,junrao,2023-09-21T23:36:53Z,is this request guaranteed to be sent when the consumer is closed? do we need this guarantee?,0,0.9940516352653503
1333708126,14406,junrao,2023-09-21T23:55:37Z,is the rebalance callback called here?,0,0.9939974546432495
1333739561,14406,philipnee,2023-09-22T00:36:53Z,"current log is at trace level: `log.trace(""closing the kafka consumer"");`",0,0.9926853179931641
1333760307,14406,junrao,2023-09-22T01:07:10Z,"this logic is a bit weird. applicationeventprocessor handles fetchevent by draining all completefetches from fetchbuffer, but here we are just adding them back to fetchbuffer again.",-1,0.9714807271957397
1334577989,14406,junrao,2023-09-22T16:08:24Z,could we describe what this class does? it's a bit weird the `backgroundeventprocessor.process` is called from `prototypeasyncconsumer` in the foreground.,-1,0.950370728969574
1334591301,14406,junrao,2023-09-22T16:20:46Z,this causes an exception to be thrown in the application thread. it seems that we should avoid doing that for at least the retriable exceptions? ditto below.,0,0.9486145377159119
1334595965,14406,junrao,2023-09-22T16:25:38Z,it seems that timer.currenttimems() doesn't change btw poll start and poll end because of the way that timer is constructed?,0,0.9883537292480469
1334596869,14406,junrao,2023-09-22T16:26:33Z,is that todo still needed since we implemented `poll` now?,0,0.9949716329574585
1334617225,14406,junrao,2023-09-22T16:47:30Z,should we wait for the time here like what we did in `refreshcommittedoffsetsifneeded`?,0,0.9942103624343872
1334630287,14406,junrao,2023-09-22T17:01:40Z,"this is an existing issue, but i don't quite understand this comment. in other places, we just use `time` directly assuming it's never null.",0,0.90534907579422
1334636045,14406,junrao,2023-09-22T17:08:20Z,do we need this since closetimer is already bounded by requesttimeoutms?,0,0.9910673499107361
1334639334,14406,junrao,2023-09-22T17:11:53Z,we are not really passing in closetimer below.,0,0.9829036593437195
1334651469,14406,junrao,2023-09-22T17:25:40Z,could we remove `this` for better consistency?,0,0.9933724403381348
1334655265,14406,junrao,2023-09-22T17:29:54Z,"we haven't implemented the group subscription logic in prototypeasyncconsumer, right? ditto for the pattern subscribe below.",0,0.9834685325622559
1334668882,14406,junrao,2023-09-22T17:45:36Z,"`fetchposition` is updated in the background thread, right? so, it could change anytime during the `poll` call in the consumer. do we need the info on `fetchposition` to be accurately reflected here?",0,0.9916204214096069
1334677351,14406,junrao,2023-09-22T17:55:10Z,the comment is a bit confusing. the code doesn't seem to do anything related to offsets and rebalance.,-1,0.9414035677909851
1334678608,14406,junrao,2023-09-22T17:56:44Z,no partitions are provided to this method.,0,0.9850940704345703
1334719457,14406,junrao,2023-09-22T18:48:26Z,"this is an existing issue, but i am not sure why the comment mentions `fetchrecords`.",0,0.9559227228164673
1334720342,14406,junrao,2023-09-22T18:49:38Z,could we update the javadoc?,0,0.9934460520744324
1334733479,14406,junrao,2023-09-22T19:06:57Z,there is still a mention of `deserializers` above.,0,0.9922698736190796
1334734342,14406,junrao,2023-09-22T19:08:09Z,extra new line,0,0.9711894392967224
1334738863,14406,junrao,2023-09-22T19:14:25Z,it seems that none of the request managers implements `close`. does this need to be `closeable`?,0,0.9895290732383728
1334740555,14406,junrao,2023-09-22T19:16:49Z,`requestmanagers` doesn't take .,0,0.9785872101783752
1334821243,14406,junrao,2023-09-22T21:13:33Z,the noid part is a bit confusing. assignfromusersingletopic?,-1,0.8038387298583984
1334829050,14406,junrao,2023-09-22T21:27:55Z,"`client.updatemetadata `eventually calls `metadata.updatewithcurrentrequestversion`. so, not sure why we are updating cluster metadata twice with different values.",0,0.9752835631370544
1334857621,14406,junrao,2023-09-22T22:25:49Z,could we be consistent with the use of `this`?,0,0.9946459531784058
1334860526,14406,junrao,2023-09-22T22:31:22Z,consumerclient => networkclientdelegate?,0,0.9933007955551147
1334869446,14406,kirktrue,2023-09-22T22:52:25Z,"yes, just to set off the child `subpackage` element more cleanly. but i can remove it if you'd like.",0,0.9883983731269836
1334870059,14406,kirktrue,2023-09-22T22:54:15Z,"are you saying that the incoming error (`t`) is already logged before the callback is invoked? if so, then yeah, it makes sense to remove it here.",0,0.9901628494262695
1334870549,14406,kirktrue,2023-09-22T22:55:37Z,"sorry, can you elaborate? where is the error logged other than this?",-1,0.9873235821723938
1334870694,14406,kirktrue,2023-09-22T22:56:06Z,yep. i'll remove it.,0,0.8813685178756714
1334870735,14406,kirktrue,2023-09-22T22:56:12Z,will remove.,0,0.9741621017456055
1334870782,14406,kirktrue,2023-09-22T22:56:20Z,ok. i'll change it. thanks.,1,0.9734435677528381
1334871262,14406,kirktrue,2023-09-22T22:57:46Z,"hmm... i can see your point. the naming is definitely confusing :grinning_squinting_face: it used to be named `maybethrowillegalstateexception()`, so it could be worse.",-1,0.8522380590438843
1334871627,14406,kirktrue,2023-09-22T22:59:03Z,i found the occasional `null` event in the past. the collections didn't prevent it. maybe it's an extra level of paranoia that has outlived its purpose?,0,0.9071229100227356
1334872019,14406,kirktrue,2023-09-22T23:00:22Z,do you mean if `networkclientdelegate` is still `null`? yes. that can happen if the object is constructed and then used without calling `initializeresources` beforehand. perhaps a comment or a restructuring of the code could be made.,0,0.9945059418678284
1334872655,14406,kirktrue,2023-09-22T23:02:24Z,"i need ""to"" proofread my comments more thoroughly :grinning_face_with_smiling_eyes:",0,0.9619700908660889
1334873271,14406,kirktrue,2023-09-22T23:04:12Z,"i'll change the log line at the start of the method from `info` to `trace` and leave the log line at the end of the method as `debug`. in so doing, both will match the levels in `kafkaconsumer.close()`.",0,0.9929607510566711
1334876767,14406,kirktrue,2023-09-22T23:16:05Z,"not yet, no. i'll remove the comment because we haven't implemented the callback mechanism here. it's in a draft pr #14357. we do have the _general_ mechanism for how we'll end up calling them, which is via the `backgroundeventprocessor`. i did notice a difference between `kafkaconsumer` and `prototypeasyncconsumer`the former is potentially invoking the rebalance callback on each iteration of the loop inside `poll()` whereas the latter implementation is only calling it once at the top of `poll()`. i'll change ours to work in a similar fashion.",0,0.9888408780097961
1334878210,14406,kirktrue,2023-09-22T23:21:07Z,"yes, this is ugly and ripe for reworking. there are two buffers to store `completedfetch`es: one for the background thread and one for the application thread. this way the background thread can write to _its_ buffer and the application thread can read from _its_ buffer without them stepping on each other's toes.",-1,0.976373553276062
1334878765,14406,kirktrue,2023-09-22T23:23:21Z,"yeah, that is a bit weird. it's the same with `applicationeventprocessor.process()` being called from the background thread. each thread ""processes"" the events it received from the other thread.",-1,0.9840468764305115
1334878800,14406,kirktrue,2023-09-22T23:23:31Z,"but yes, i'll definitely add some comments here.",0,0.9655498266220093
1334879279,14406,kirktrue,2023-09-22T23:25:15Z,my understanding was that the failure is only propagated to this callback once the retries have been exhausted. am i misunderstanding?,0,0.8065352439880371
1334881403,14406,kirktrue,2023-09-22T23:32:36Z,"the `timer` is created inside `poll()` is passed into the other methods. the only one that updates it directly is `pollforfetches` which updates it only in the `finally` block at the end: [code block] i double-checked our implementation against `kafkaconsumer` and they seem to match in that regard. `kafkaconsumer` passes the `timer` into the methods related to the consumer coordinator, but since we don't have that functionality just yet, we don't.",0,0.9930956959724426
1334881860,14406,kirktrue,2023-09-22T23:34:21Z,good question. do we need to update our `poll` implementation to include the wakeup mechanism?,1,0.9364510774612427
1334882482,14406,kirktrue,2023-09-22T23:37:13Z,do you remember why we opted for a non-blocking event here?,0,0.9897856712341309
1334882689,14406,kirktrue,2023-09-22T23:38:10Z,`offsetfetcher.resetpositionsifneeded()` is used in the `kafkaconsumer` and it appears to send off the reset positions request asynchronously :thinking_face:,0,0.9905768632888794
1334884022,14406,kirktrue,2023-09-22T23:43:15Z,"`createtimerforrequest` appears to only be called from `close()`. some of the constructors' contents are wrapped in a `try-catch` block that attempts to close the consumer on initialization failure. so if the constructor fails before we initialize the `time` instance variable, it would be `null` when we attempt to `close()` up any resources. i'm assuming based on that comment that only `close()` has that concern about using `time`.",0,0.9934200644493103
1334885217,14406,kirktrue,2023-09-22T23:48:32Z,true. there doesn't appear to be any blocking calls made from the `fetchbuffer.close()` path. i'll dig around some more.,0,0.9873817563056946
1334885226,14406,kirktrue,2023-09-22T23:48:34Z,true. we don't have to account for time it takes for the coordinator to close because we don't have a coordinator :grinning_face_with_smiling_eyes:. i'll remove that.,0,0.9800283908843994
1334885719,14406,kirktrue,2023-09-22T23:50:42Z,"the inclusion of `this` here is, in fact, to be more consistent... with the code in `kafkaconsumer.subscribe()`. at one point we took as much of the code from `kafkaconsumer` as we could, warts and all. i'll remove this `this`, though.",0,0.9916332960128784
1334885895,14406,kirktrue,2023-09-22T23:51:38Z,"there are several other places in the `prototypeasyncconsumer` that we do things sub-optimally, just to match `kafkaconsumer`.",0,0.9891124367713928
1334886142,14406,kirktrue,2023-09-22T23:52:47Z,i'll dig in on this a little deeper.,0,0.9656856656074524
1334886595,14406,kirktrue,2023-09-22T23:54:45Z,this is another case of grabbing the code verbatim from `kafkaconsumer`. does the code comment make sense to you?,0,0.9938442707061768
1334886820,14406,kirktrue,2023-09-22T23:55:41Z,good catch. old comments :frowning_face_with_open_mouth:,1,0.9861673712730408
1334888478,14406,kirktrue,2023-09-23T00:03:26Z,"i think i wrote the initial comment :grimacing_face: i was trying to explain that `drain()`-ing a `completedfetch` is like `close()`-ing it, in that we free its resources. but it's _unlike_ `close()` because we can technically still call `fetchrecords()` on it without throwing some sort of `illegalstateexception` or anything. is this better? or should i just scrap the whole comment altogether?",0,0.5742665529251099
1334892999,14406,kirktrue,2023-09-23T00:28:08Z,will do.,0,0.9864637851715088
1334893011,14406,kirktrue,2023-09-23T00:28:13Z,will exorcise them.,0,0.9753746390342712
1334893046,14406,kirktrue,2023-09-23T00:28:28Z,i'll remove it.,0,0.9830724000930786
1334893631,14406,kirktrue,2023-09-23T00:32:19Z,"the `fetchrequestmanager` does by virtue of extending from `abstractfetch`. the sole reason for that it is so that it can prepare to send requests to the brokers to close their fetch sessions. it's kind of kludgey the way it's done, so i'll take another look to see if it can be done more cleanly.",0,0.9745611548423767
1334894116,14406,kirktrue,2023-09-23T00:35:10Z,thanks for the catch!,1,0.9198203682899475
1334896241,14406,kirktrue,2023-09-23T00:49:26Z,removed the extra line.,0,0.9819137454032898
1335942472,14406,lianetm,2023-09-25T14:07:00Z,"my understanding is that in that case it won't continuously fetch from the old leader because of the partition subscription state, which will transition to `awaiting_validation` (not a valid state for fetching). the moment a new metadata is discovered, [a link], so the [a link] will not fetch from them. to complete the validation picture, once the `offsetforleaderepoch` response is received, the subscription state will transition to `fetching` again and fetch requests should resume for that partition. my thoughts but please correct me if i'm missing something from the fetching story.",0,0.9533161520957947
1336253362,14406,junrao,2023-09-25T18:31:51Z,: thanks for the reply. that's my understanding too. my question was what happens before the new metadata is received. will the consumer continuously fetch from the older leader?,1,0.8676521182060242
1336273549,14406,junrao,2023-09-25T18:52:21Z,should this comment be moved to above the `client.prepareresponse` below?,0,0.995355486869812
1337443244,14406,kirktrue,2023-09-26T15:54:24Z,i reverted the change to the comment. i don't remember changing it :man_shrugging:,-1,0.7759660482406616
1337444033,14406,kirktrue,2023-09-26T15:55:02Z,i've updated this so that the `close()` method is a lot cleaner.,0,0.9828677177429199
1337444456,14406,kirktrue,2023-09-26T15:55:21Z,removed the unnecessary timer.,0,0.9381629228591919
1337444877,14406,kirktrue,2023-09-26T15:55:43Z,"`createtimerforrequest()` is no longer used, so marking this as resolved.",0,0.9942383766174316
1337660657,14406,kirktrue,2023-09-26T19:02:44Z,i've changed the mechanism to handle the responses from fetch such that we should now properly block until results are available.,0,0.9885572195053101
1337661714,14406,kirktrue,2023-09-26T19:03:54Z,"this has been reworked as part of a recent change. not only are there are still two `fetchbuffer`s, but i've _added_ a blocking queue between them since the `fetchbuffer` should not be updated on the `future` callback, since that is updated on another thread and `fetchbuffer` is not thread safe.",0,0.986751914024353
1337662384,14406,kirktrue,2023-09-26T19:04:41Z,"it is currently being worked on for the kip-848 work, so its development is running in parallel.",0,0.9894198179244995
1337849711,14406,kirktrue,2023-09-26T22:39:41Z,it looks like the other call sites that add error events to the handler also log them :man_shrugging:,0,0.8721342086791992
1337881130,14406,kirktrue,2023-09-26T23:43:17Z,"in the refactored version, the logging is not as verbose.",0,0.9422042965888977
1337881557,14406,kirktrue,2023-09-26T23:44:08Z,"this code has been refactored, but it still has the check, just to be paranoid.",0,0.9610795378684998
1337882369,14406,kirktrue,2023-09-26T23:45:52Z,added a brief comment to explain this case.,0,0.9791347980499268
1338972414,14406,philipnee,2023-09-27T17:35:33Z,"i am actually not sure if we need this as networkclientdelegate is already doing the connection checking. if the node is unavailable for reconnection, then it would fail the unsentrequest and presumably trigger a retry. the original code does the connection checking because the request is sent right after its creation; however, there's a time gap between the creation and the actual network io. i think it is harmless to leave it here but it would be great if we could clean them up later.",0,0.9551103115081787
1338973379,14406,philipnee,2023-09-27T17:36:21Z,"per previous comment - if we actually clean up the code, we should only care if there's a fetchtarget or not.",0,0.9910874962806702
1339157715,14406,philipnee,2023-09-27T20:13:48Z,we are logging debug for the request manager but info here. just want to make sure we are consistent with the logging level.,0,0.9732310175895691
1339158103,14406,philipnee,2023-09-27T20:14:09Z,thanks for removing the boolean.,0,0.8558413982391357
1339158811,14406,philipnee,2023-09-27T20:14:54Z,my only fear is that this could spam the trace log,-1,0.9207135438919067
1340402407,14406,philipnee,2023-09-28T16:26:40Z,should we use ( ) instead of { } ?,0,0.9940158128738403
1340690791,14406,philipnee,2023-09-28T21:36:39Z,"since we also need to send offsetcommit upon closing, maybe it is best to poll the networkclientdelegate upon closing.",0,0.9931220412254333
1342913561,14406,junrao,2023-10-02T16:29:31Z,could we describe what `poll` does?,0,0.9921385645866394
1342950743,14406,junrao,2023-10-02T17:11:23Z,the above comment that this class is only used from a single thread seems incorrect. the background thread adds fetched data into `completedfetches` and `prototypeasyncconsumer` drains `completedfetches` through `fetchcollector.collectfetch(fetchbuffer)`. there is actually very subtle synchronization between the two threads. could we document the correct way of using this class and how we achieve synchronization so that future developers don't break it?,0,0.9708277583122253
1342984775,14406,junrao,2023-10-02T17:50:15Z,"hmm, with this logic, there is a short window between `completedfetch` in `fetchresults` and `completedfetch` be added to back to `fetchbuffer`. during this window, `backgroundthread` could make a `poll` call, see no buffered data in `fetchbuffer` and fetch the same offset again? then the consumer could see duplicated data because of this.",0,0.9882767796516418
1343046752,14406,junrao,2023-10-02T18:58:21Z,"earlier, we have ""do not have a valid position and are not awaiting reset"". the reset there and the reset here mean different things. the former refers to resetting the offset based on offsetforleaderepoch and the latter refers to resetting the offset to either the earliest or latest. it would be useful to make this clear.",0,0.9892070293426514
1343059742,14406,junrao,2023-10-02T19:11:22Z,"it still seems weird that we only use the timer for `refreshcommittedoffsetsifneeded`, but not for other cases where we don't have valid fetch positions. for example, if all partitions are in await_validation state, it seems that prototypeasyncconsumer.poll() will just go in a busy loop, which is not efficient.",0,0.5657455325126648
1343061015,14406,junrao,2023-10-02T19:12:57Z,"if `initializingpartitions` is empty, do we still send the offsetfetch request? i didn't see the logic for short-circuiting.",0,0.9891538023948669
1343147889,14406,junrao,2023-10-02T20:46:12Z,is `this` needed?,0,0.9919894337654114
1343150605,14406,junrao,2023-10-02T20:49:09Z,"to be consistent with other places, it seems that we want to combine this with the previous line. ditto below.",0,0.9188413619995117
1343163505,14406,junrao,2023-10-02T21:04:40Z,where is the callback handler?,0,0.9922314882278442
1343232059,14406,junrao,2023-10-02T22:44:17Z,"at this stage, we are just propagating connection level errors like disconnectexception, which is retriable. so, it seems that we shouldn't throw this error back to the application. ditto in `pollonclose`.",0,0.9837471842765808
1343246844,14406,junrao,2023-10-02T23:12:14Z,"if the background thread dies, should we throw an exception to the user thread on the next `poll` call?",0,0.9891039133071899
1343251934,14406,junrao,2023-10-02T23:21:55Z,"instead of using `currenttimems`, we need to use `timer.currenttimems` to pick up the latest time, right?",0,0.9938297867774963
1343259817,14406,junrao,2023-10-02T23:40:32Z,is this comment addressed?,0,0.9921022057533264
1343265294,14406,junrao,2023-10-02T23:52:58Z,fetchposition is updated in the user thread.,0,0.9899423122406006
1343266219,14406,junrao,2023-10-02T23:54:58Z,was this comment addressed?,0,0.9915623068809509
1344756235,14406,kirktrue,2023-10-03T21:21:19Z,"it is now run as part of the `consumer.close()` process, yes.",0,0.9921941757202148
1344758105,14406,kirktrue,2023-10-03T21:22:10Z,"no, not yet. do we want to add something for wakeup here, or should i remove the comment? thanks.",0,0.6759726405143738
1344762836,14406,kirktrue,2023-10-03T21:26:43Z,can you look at the new `defaultbackgroundthread.runatclose()` method i added? do we need to update the `commitrequestmanager` to implement the `pollonclose()` api i added?,0,0.9938794374465942
1344780023,14406,kirktrue,2023-10-03T21:47:18Z,updated to overload the `assignfromuser` method name with a single `topicpartition`. then that single partition is used to return the topic name to reduce the number of times `noid` appears in that code.,0,0.9949163198471069
1344786987,14406,kirktrue,2023-10-03T21:54:37Z,"good question. as a test, i made this change locally: [code block] i ran the tests and they all passed, so i don't know why it was written like that :man_shrugging: this code in `fetchrequestmanagertest` is copied from `fetchertest`; as much as we could was left verbatim.",1,0.9686552882194519
1344795530,14406,kirktrue,2023-10-03T22:03:44Z,done.,0,0.9640594124794006
1344799794,14406,kirktrue,2023-10-03T22:08:14Z,done.,0,0.9640594124794006
1344801112,14406,kirktrue,2023-10-03T22:09:55Z,fixed in both original `fetchertest` and the copied `fetchrequestmanagertest`.,0,0.9943460822105408
1344822614,14406,kirktrue,2023-10-03T22:34:18Z,i added documentation to the `requestmanager` interface with pointers to it from the methods in `fetchrequestmanager`.,0,0.9931139349937439
1344897098,14406,kirktrue,2023-10-04T00:05:17Z,"yes, the process is a bit convoluted... to perform the process of moving the fetched records from the background thread to the application thread and then on to the user, `prototypeasyncconsumer` has these three instance variables: 1. `fetchresults` 2. `fetchbuffer` 3. `fetchcollector` all three of those objects are created in the application thread when the `prototypeasyncconsumer` is created. `fetchbuffer` and `fetchcollector` are only ever referenced by the application thread; `fetchresults`, however, is used by **both** threads. `fetchresults` is referenced in the background thread when it is used in the `fetchevent` callback in the `sendfetches()` method: [code block] since the `whencomplete()` method is executed when the background thread ""completes"" the `future`, `fetchresults` is thus modified on the background thread. the rest of the process should occur on the application thread. during calls to `poll()` on the application thread, data from `fetchresults` is moved to `fetchbuffer` in `pollforfetches()`: [code block] the data in `fetchbuffer` is later extracted in `fetchcollector` during the `poll()` process, but this again is on the application thread. this roundabout way of getting the data is specifically done so that we don't write to the `fetchbuffer` inadvertently from the background thread. hence these javadoc comment for `fetchresults`: [code block] this is a rough idea of what happens on the background thread: then later in the application thread during `poll()`: let me know if that makes sense or if there is still a gap that i'm not seeing. i can write the above up (with any changes you'd like) in code comments.",0,0.8818503022193909
1344899034,14406,kirktrue,2023-10-04T00:09:08Z,i've removed the qualifiers where they're not needed.,0,0.985268771648407
1344900260,14406,kirktrue,2023-10-04T00:11:31Z,fixed.,0,0.979083240032196
1344900777,14406,kirktrue,2023-10-04T00:12:12Z,fixed.,0,0.979083240032196
1346179200,14406,junrao,2023-10-04T16:45:53Z,": thanks for the explanation. two followup questions. 1. the background thread has the following path` fetchrequestmanager.poll -> handlefetchresponse -> fetchbuffer.add(completedfetch)`. so, it seems that the background thread also writes the fetched data to `fetchbuffer`. 2. this is related to my other [a link]. the background thread has the following path `fetchrequestmanager.poll -> abstractfetch.preparefetchrequests -> abstractfetch.fetchablepartitions -> reads fetchbuffer.bufferedpartitions()`. since fetchbuffer is written by the application thread, how do we coordinate the synchronization btw the two threads?",1,0.7992891669273376
1346234546,14406,kirktrue,2023-10-04T17:33:01Z,you're right. thanks for catching that! changed.,1,0.995250940322876
1346270372,14406,kirktrue,2023-10-04T18:05:36Z,yes. i added a check that it's not closed at the top of `runonce()`.,0,0.9923579096794128
1346278813,14406,kirktrue,2023-10-04T18:13:15Z,this was an outdated comment. fixed.,0,0.8669449687004089
1346451911,14406,junrao,2023-10-04T20:54:01Z,background network thread => network thread ?,0,0.9908251166343689
1346463369,14406,junrao,2023-10-04T21:05:03Z,"this will cause a logging of error during normal shutting down of the consumer, right? it would be useful to avoid that.",0,0.9826375842094421
1346493970,14406,philipnee,2023-10-04T21:35:27Z,thanks - i think we will need to do that. i created kafka-15548 to handle the closing task.,1,0.7141912579536438
1346504058,14406,kirktrue,2023-10-04T21:47:38Z,i removed the error propagation (and logging).,0,0.9817352890968323
1346508562,14406,kirktrue,2023-10-04T21:51:54Z,any reason we don't check if `initializingpartitions` is non-empty before creating the `offsetfetchapplicationevent`?,0,0.9946427345275879
1346517075,14406,kirktrue,2023-10-04T21:59:23Z,"regardless of the return value of `updatefetchpositions()`, `poll()` will still go on to call `pollforfetches()` which will block for data availability or timeout expiration.",0,0.9939129948616028
1346545044,14406,kirktrue,2023-10-04T22:32:56Z,"for point #1, the background thread has a _separate_ fetch buffer. it doesn't write to the same object. the application thread `fetchbuffer` is created in `prototypeasyncconsumer` and the background thread `fetchbuffer` is created in `abstractfetch`. for point #2, i think your [a link] is correct. i'm not yet sure how to maintain those two fetch buffers separately without running into that race condition.",0,0.9172766804695129
1346546088,14406,kirktrue,2023-10-04T22:34:22Z,"yes, i can see that now. given that there are two separate `fetchbuffer`s and the way they're populated, i think the window is actually a bit bigger. i need to noodle on this for a bit.",0,0.9041969776153564
1346562666,14406,junrao,2023-10-04T22:58:01Z,`fetcher` is a `testablefetchrequestmanager`. could we just do `poll` instead of `fetcher.poll`?,0,0.9949047565460205
1346567694,14406,junrao,2023-10-04T23:06:49Z,"where is the callback? also,` networkclient#send` happens in the caller, not here, right?",0,0.9941760301589966
1346572630,14406,junrao,2023-10-04T23:15:53Z,it's very confusing that the above two `handlefetchresponse` refer to different methods. could we name them differently?,-1,0.9513272643089294
1346604856,14406,kirktrue,2023-10-05T00:00:01Z,"yes, it would, but what do you expect when you're logging at `trace`? :face_with_tongue:",0,0.9800866842269897
1346606768,14406,kirktrue,2023-10-05T00:02:48Z,changed to debug,0,0.9861841797828674
1346607807,14406,kirktrue,2023-10-05T00:04:39Z,i've removed the logging and error forwarding as it is handled in the `networkclientdelegate` layer.,0,0.99294114112854
1346612374,14406,kirktrue,2023-10-05T00:11:20Z,"at the beginning of the `kafkaconsumer.poll()` loop, it does this: [code block] do we support _disabling_ wake-ups? i don't see the analogue to `maybetriggerwakeup()`, `disablewakeups()`, etc. in `wakeuptrigger`. can we emulate what `kafkaconsumer` is doing in the `poll()` loop with our current implementation? if not, i'd prefer to a) remove the comment, and b) file a new jira. thoughts?",0,0.9937098026275635
1346613925,14406,kirktrue,2023-10-05T00:12:42Z,i'll review with .,0,0.9819949269294739
1346615044,14406,kirktrue,2023-10-05T00:14:29Z,`abstractfetch` is used by both the current `fetcher` as well as the `fetchrequestmanager`. i'd have to refactor the code to rid ourselves of it. what do you think about filing a new jira to track a follow-up change for this?,0,0.9923192858695984
1346616102,14406,kirktrue,2023-10-05T00:16:29Z,"i'd like to file a separate jira for this, only because it's been this way for a while. i need more time to understand it before changing it, and would love to get the integration tests and perhaps even system tests online before changing it. thoughts?",1,0.595810055732727
1346616646,14406,kirktrue,2023-10-05T00:17:22Z,i think i need to circle back with to get her input on this as she's much closer to it than i am.,0,0.7402771711349487
1347629215,14406,junrao,2023-10-05T15:39:53Z,"yes, it's fine to have a separate jira to clean this up.",0,0.9845041036605835
1347692761,14406,junrao,2023-10-05T16:28:21Z,"this logic looks correct in the test. however, in the actual code, there could be unconsumed data in `prototypeasyncconsumer.fetchresults `and `prototypeasyncconsumer.fetchbuffer`. how do we prevent those data from being returned to the user? same question when partition is paused.",0,0.9930379986763
1347727982,14406,junrao,2023-10-05T16:57:13Z,"hmm, should the code be commented out? it doesn't match the comment above.",0,0.8922121524810791
1347742323,14406,junrao,2023-10-05T17:10:13Z,"i don't quite understand these 3 lines. why are we polling the fetcher again since typically this doesn't happen after pollonclose is called on the fetcher? also, for the test as it is, it seems that the first request is the one with the final epoch, not the second?",0,0.9026035666465759
1347748114,14406,junrao,2023-10-05T17:15:36Z,does this test subsume `testinflightfetchonpendingpartitions`?,0,0.9953001737594604
1347751320,14406,junrao,2023-10-05T17:18:29Z,should the comment be moved to just above `client.prepareresponse` below?,0,0.9954415559768677
1347752851,14406,lianetm,2023-10-05T17:19:55Z,"agree , i will update the comments to better explain. the bottom line is that positions may be reset in 2 different ways: - using the committed offsets (retrieved with `offsetfetch` sent to the group coordinator). this if committed offsets are in use. - using the partition offsets (retrieved with `listoffset` sent to the partition leader + reset strategy) the `offsetforleaderepoch` request is the one used to validate positions, basically retrieving epoch and end offsets from a leader, to validate the the current position held on the consumer side. makes sense? i will update the comments for each step.",0,0.9717446565628052
1347759469,14406,junrao,2023-10-05T17:26:00Z,should the comment be moved to just above client.prepareresponse below? ditto in a few other places.,0,0.9934960603713989
1347768459,14406,junrao,2023-10-05T17:34:57Z,is the upgrade on the server or the client side?,0,0.9935187697410583
1347777973,14406,lianetm,2023-10-05T17:43:31Z,i updated the comments in this other pr that i had just opened [a link],0,0.9843316078186035
1347791680,14406,junrao,2023-10-05T17:56:33Z,it would be useful to clarify that `fetchedrecords()` is called deep inside `fetcher.collectfetch()`. ditto in a few other places mentioning `fetchedrecords()`.,0,0.994256317615509
1347799078,14406,kirktrue,2023-10-05T18:03:41Z,i'm planning to remove the comments and create a new jira to track this change. cc,0,0.9671092629432678
1347806531,14406,junrao,2023-10-05T18:11:27Z,be consistent with usage of `this`.,0,0.9906615614891052
1347811905,14406,junrao,2023-10-05T18:17:09Z,where is the resizing?,0,0.9868202805519104
1347832688,14406,junrao,2023-10-05T18:40:09Z,its been => it has been,0,0.9643387198448181
1347834317,14406,junrao,2023-10-05T18:41:55Z,this seems unnecessary given the `assertemptyfetch` below?,0,0.9907687306404114
1347865054,14406,kirktrue,2023-10-05T19:14:43Z,todo: fix the comment in the code and explain about the applicationeventprocessor.,0,0.9898595213890076
1347874026,14406,kirktrue,2023-10-05T19:25:07Z,todo: find case where we _might_ be sending rpcs with empty sets.,0,0.9898527264595032
1347874693,14406,kirktrue,2023-10-05T19:25:55Z,todo: to create a separate ticket to review/fix.,0,0.9891603589057922
1347883272,14406,junrao,2023-10-05T19:35:43Z,could we write this as parameterized test to avoid duplicating the code in the next few tests?,0,0.9944038391113281
1347884952,14406,junrao,2023-10-05T19:37:30Z,should we assert there is no pending request after this?,0,0.9929793477058411
1347885711,14406,lianetm,2023-10-05T19:38:19Z,"i know for sure we skip empty lists and don't send requests for all the partition offsets related events (on the `offsetsrequestmanager` on [a link], [a link] and [a link]. that being said, here is about fetching the committed offsets, and i don't see a clear early return but maybe i'm missing how it happens so let's wait for to give it a closer look.",0,0.9661082625389099
1347894828,14406,junrao,2023-10-05T19:45:34Z,it would be useful to add a comment why offset is not reset yet on `offset_out_of_range`. this is because the error handling happens when new records are polled.,0,0.9944494962692261
1347906316,14406,junrao,2023-10-05T19:57:07Z,could this be replaced with `fetchrecordsinto`?,0,0.9949713945388794
1347908197,14406,junrao,2023-10-05T19:58:49Z,is this redundant given the test in 1811?,0,0.9880090951919556
1347910980,14406,junrao,2023-10-05T20:01:53Z,"hmm, why don't we return records from other partitions since maxrecords is maxint?",0,0.9519411325454712
1347913781,14406,junrao,2023-10-05T20:05:21Z,why don't we return records from tp1 since maxrecords is 2?,0,0.9903523325920105
1347914377,14406,junrao,2023-10-05T20:06:06Z,affect => effect,0,0.9878178238868713
1347923838,14406,junrao,2023-10-05T20:17:28Z,what's the purpose of this code? the receive is delayed and thus there is no throttledelayms received in the client.,0,0.9840494394302368
1347931744,14406,junrao,2023-10-05T20:26:15Z,why is `recordsfetchleadmin` different from `partitionlead` given there is only 1 assigned partition?,0,0.9941869974136353
1347936262,14406,junrao,2023-10-05T20:31:04Z,"`expectedbytes` is calculated as total, instead of avg. is this correct?",0,0.9920691251754761
1347938331,14406,junrao,2023-10-05T20:33:31Z,"the name is a bit mis-leading. we get a full response, but skipped an offset before the fetch position.",0,0.6413594484329224
1347960253,14406,junrao,2023-10-05T20:54:36Z,the expected and actual are reversed.,0,0.9853524565696716
1348009426,14406,kirktrue,2023-10-05T21:36:47Z,i filed kafka-15555 as a separate follow-up task to handle the wakeup mechanics.,0,0.9930049777030945
1348009622,14406,kirktrue,2023-10-05T21:37:03Z,i will remove the temporary comment in a bit.,0,0.9823800325393677
1348011353,14406,kirktrue,2023-10-05T21:39:43Z,removed.,0,0.9782117605209351
1348019537,14406,junrao,2023-10-05T21:45:42Z,capitalize in?,0,0.9859308004379272
1348029408,14406,kirktrue,2023-10-05T21:58:16Z,"i have filed kafka-15556 (_remove networkclientdelegate methods isunavailable, maybethrowauthfailure, and tryconnect_) to address this issue since it's affecting other `requestmanager` implementations.",0,0.9904223680496216
1348029671,14406,kirktrue,2023-10-05T21:58:45Z,true. we'll handle that in kafka-15556.,0,0.9920864701271057
1348047927,14406,kirktrue,2023-10-05T22:14:19Z,i filed kafka-15557 (_fix duplicate metadata update in fetcher tests_) to address this issue.,0,0.9943352341651917
1348055761,14406,kirktrue,2023-10-05T22:21:17Z,created kafka-15558 (_determine if timer should be used elsewhere in prototypeasyncconsumer.updatefetchpositions()_) to address separately as the given implementation is the same as the current implementation. perhaps fixes in both `consumer` implementations is warranted?,0,0.9956081509590149
1348062340,14406,junrao,2023-10-05T22:22:48Z,node => note?,0,0.9829413294792175
1348062596,14406,kirktrue,2023-10-05T22:22:55Z,filed kafka-15551 (_evaluate conditions for short circuiting consumer api calls_) to implement this consistently.,0,0.9945921301841736
1348083698,14406,kirktrue,2023-10-05T23:00:07Z,"yes, it appears that it will continue to attempt to fetch from the old leader. when a fetch response is received from the broker and we notice that it has an error, we call `fetchcollector.handleinitializeerrors()` to deal with the different error conditions. when it notices that the error is `fenced_leader_epoch`, it will execute these two statements (from the `fetchutils.requestmetadataupdate()` method): [code block] that's all it does. the logic doesn't update the `fetchstate` for that partition. it doesn't clear out the leader epoch. nothing. the next time the user calls the `consumer.poll()` method, the `fetcher`/`fetchrequestmanager` will determine for which partitions we should issue `fetch` rpcs. the first step is to call the `subscriptionstate.fetchablepartitions()` method which checks each partition: [code block] because we didn't change anything in the underlying state of the partition in `subscriptionstate` previously, when the `topicpartitionstate.isfetchable()` method is invoked, it returns `true`. thus it is included in the list for which to fetch, and we will likely hit the same error.",0,0.992073118686676
1348084921,14406,kirktrue,2023-10-05T23:02:32Z,the error message in `errors` for `fenced_leader_exception` states that this error is caused when...,0,0.9946847558021545
1348087535,14406,kirktrue,2023-10-05T23:07:55Z,"naively it seems like we want to clear/reset the partition's `metadata.leaderandepoch` value in the metadata cache locally. then in the fetch logic, that would allow us to skip that partition when we check for the presence of a leader: [code block]",0,0.9939693212509155
1348088801,14406,junrao,2023-10-05T23:10:38Z,should this comment be moved to just above `client.prepareresponse` below?,0,0.9951074123382568
1348091800,14406,junrao,2023-10-05T23:16:50Z,not sure what we are testing here. which handler is this referring to?,0,0.6571230292320251
1348107483,14406,junrao,2023-10-05T23:44:11Z,"hmm, the consumernetworkthread shouldn't die because of a topicauthorizationexception, right? ditto below.",0,0.9042781591415405
1348110728,14406,junrao,2023-10-05T23:51:45Z,which call is returning long.max_value?,0,0.9872631430625916
1348111165,14406,junrao,2023-10-05T23:52:48Z,does this test cover `testfindcoordinator`?,0,0.992870032787323
1348903678,14406,junrao,2023-10-06T15:51:45Z,be consistent with the use of `this`. ditto below.,0,0.9881114959716797
1348915254,14406,junrao,2023-10-06T16:02:18Z,should we fix `this.records` above too?,0,0.9950467348098755
1348955876,14406,junrao,2023-10-06T16:31:47Z,this will run the network i/o in the application thread and break the model that all network i/os should be done in the background thread? will this be safe since now there could be two threads driving a shared networkclient?,0,0.9915339350700378
1348962486,14406,junrao,2023-10-06T16:38:11Z,called from by => called by,0,0.9905455112457275
1349023459,14406,junrao,2023-10-06T17:13:46Z,the auto offset commit seems to happen asynchronously? do we guarantee that the new owner of the unsubscribed partitions could pick up the latest committed offset?,0,0.9934653639793396
1349173413,14406,junrao,2023-10-06T18:18:01Z,"there is a subtle difference between transitioning to reset from initializing and transitioning to reset from `offsetoutofrangeexception` during fetch. in the latter, the application thread will call `fetchcollector.handleinitializeerrors()`. if there is no default offset reset policy, an `offsetoutofrangeexception` will be thrown to the application thread during `poll`, which is what we want. however, for the former, if there is no default offset reset policy, we simply ignore that partition through `offsetfetcherutils.getoffsetresettimestamp`. it seems in that case, the partition will be forever in the reset state and the application thread won't get the `offsetoutofrangeexception`.",0,0.9927916526794434
1349184330,14406,junrao,2023-10-06T18:28:19Z,"thanks, kirk. does the old consumer have the same behavior too? should we file a followup jira to improve this?",1,0.8445847034454346
1349221937,14406,philipnee,2023-10-06T19:11:48Z,"hi jun - i think we mostly use ""background thread"" in lieu of network thread, so maybe just use background thread?",0,0.989024817943573
1349342751,14406,kirktrue,2023-10-06T21:44:50Z,"i will triple check, and if so, i will add a jira.",0,0.9865060448646545
1349343412,14406,kirktrue,2023-10-06T21:46:03Z,"i just pushed a proposed fix for this, which is basically to make the `fetchbuffer` thread safe. now there is only one fetch buffer for the consumer and is accessed by both threads.",0,0.9917120933532715
1349343753,14406,kirktrue,2023-10-06T21:46:49Z,you didn't see that i got fed up and changed the name of `defaultbackgroundthread` to `consumernetworkthread` :grinning_squinting_face:,0,0.9437054395675659
1349361459,14406,junrao,2023-10-06T22:15:08Z,"1. this is an existing issue. but the way we handle paused partitions in `collectfetch` seems problematic. the application thread first calls `fetchbuffer.setnextinlinefetch(null)` and then calls `fetchbuffer.addall(pausedcompletedfetches)`. this could leave a brief window where the paused partition is not included in either `nextinlinefetch` or `completedfetches`. if the background thread kicks in in that window, it could have fetched another chunk for that partition and added the response back to fetchbuffer. this would violate the assumption there is no more than one pending `completedfetch` per partition in fetchbuffer and could cause records returned not in offset order or duplicates to be returned. 2. the second existing issue is on the `fetchbuffer.setnextinlinefetch` call in `collectfetch`. the issue is that after all records are drained from `nextinlinefetch`. we only call `setnextinlinefetch` when there is a new `completedfetch`. however, until the drained `completedfetch` is removed from `nextinlinefetch`, the background thread can't fetch the next chunk. so, it seems that we will just be stuck here.",0,0.9517941474914551
1350689034,14406,junrao,2023-10-09T18:46:55Z,should we just remove this method?,0,0.9925352334976196
1350697908,14406,junrao,2023-10-09T18:54:59Z,the only useful part of this call is to wake up the consumernetworkthread so that it could prefetch the next data chunk. perhaps we could make that an explicit call like `applicationeventhandler.wakeup`?,0,0.9931429624557495
1350700366,14406,junrao,2023-10-09T18:57:04Z,this call seems unnecessary.,0,0.7266120910644531
1350703155,14406,junrao,2023-10-09T18:59:36Z,the comment seems obsolete since we are not fetching data below.,0,0.963672935962677
1350707142,14406,junrao,2023-10-09T19:03:50Z,"`notemptycondition.await` returns false if the waiting time detectably elapsed before return from the method. this seems to be case to break out of the while loop. so, it seems that the `if` test should be reversed.",0,0.992661714553833
1350773132,14406,junrao,2023-10-09T20:44:37Z,"currently, `fetchbuffer.setnextinlinefetch` and `fetchbuffer.poll` are separate operations and we expect the caller to call them in the right order to avoid a partition missing in fetchbuffer in the transition phase. it still leaves us with the situation that a partition could be in both completedfetches and nextinlinefetch at a particular time. it's not a problem for now, but it may be in the future. could we make them an atomic operation? if not, could we add a comment to document the correct usage of the api and the impact on partition being duplicated in completedfetches and nextinlinefetch?",0,0.9935232400894165
1351006437,14406,kirktrue,2023-10-09T23:58:22Z,removed.,0,0.9782117605209351
1351006470,14406,kirktrue,2023-10-09T23:58:29Z,done.,0,0.9640594124794006
1351011656,14406,kirktrue,2023-10-10T00:04:22Z,i removed the latter phrases to reduce confusion.,0,0.980404794216156
1351011802,14406,kirktrue,2023-10-10T00:04:32Z,agreed. i've updated the names.,0,0.9738485813140869
1351042141,14406,kirktrue,2023-10-10T00:15:32Z,you're right. i've changed the core logic and updated that test (and another one that is essentially the same thing).,0,0.8767269849777222
1351054656,14406,kirktrue,2023-10-10T00:19:07Z,"yeah, i don't see it either. i'm not exactly sure what this testing is exercising. , do you remember?",-1,0.9117513298988342
1351063405,14406,kirktrue,2023-10-10T00:24:28Z,yes. i've removed `testfindcoordinator()` as it's now superfluous.,0,0.9868196249008179
1351064502,14406,kirktrue,2023-10-10T00:26:59Z,"these are constructors, so even though it's not _strictly_ needed, i've been following the standard java convention.",0,0.9828790426254272
1352874538,14406,kirktrue,2023-10-10T16:28:35Z,removed check to avoid.,0,0.9885731935501099
1352874719,14406,kirktrue,2023-10-10T16:28:44Z,done.,0,0.9640594124794006
1352876631,14406,kirktrue,2023-10-10T16:30:05Z,i've refactored the code to run it in the background thread again.,0,0.9870700836181641
1352879009,14406,kirktrue,2023-10-10T16:31:35Z,fixed.,0,0.979083240032196
1357182316,14406,junrao,2023-10-12T17:43:47Z,not sure if this is a useful test since offsetsrequestmanager.resetpositionsifneeded() seems to never directly throw an exception?,0,0.9583670496940613
1357194942,14406,junrao,2023-10-12T17:55:19Z,"this needs to wait for the cleanup to be done until the timeout, right?",0,0.9670685529708862
1358651225,14406,kirktrue,2023-10-13T18:16:51Z,i removed the commented out code and explained why we need to use `runatclose()` instead of closing the fetcher directly.,0,0.9919669032096863
1358658187,14406,kirktrue,2023-10-13T18:19:15Z,"you are correct, sir. i removed those lines. thanks for the catch!",1,0.9942415952682495
1358665833,14406,kirktrue,2023-10-13T18:22:24Z,"the ordering and way they go about testing it is different. as this is an issue from the original `fetchertest`, i'll open a ticket to resolve separately. thanks!",1,0.9714476466178894
1358682245,14406,kirktrue,2023-10-13T18:33:16Z,"it looks like both. the test starts off mimicking a client that doesn't support topic ids. the test sets up the local subscriptions and metadata with a topic that has no id. then the test ""upgrades"" the client to a version that _does_ support topic ids. this is to validate that the fetch session (on the broker) should remove the topic without the id in favor of the topic with the id. and then the test ""downgrades"" the client again to ensure the opposite case. i haven't looked at the underlying code in any depth, however.",0,0.9811721444129944
1358693714,14406,kirktrue,2023-10-13T18:43:42Z,"`fetchedrecords()` calls `fetcher.collectfetch()`, so it's the other way around. i updated the call sites and changed `fetchedrecords()` to just `fetchrecords()` so that it's hopefully a little more clear.",0,0.992672860622406
1358701620,14406,kirktrue,2023-10-13T18:53:30Z,"i had removed most unnecessary uses of `this` in a previous round of updates, but left these because they were necessary. there are three tests that create a locally-scoped variable named `records` that masks the instance-scoped variable of the same name, hence the use of `this` to distinguish them. i've updated the tests to change the name of the local variable to `testrecords` so it's a) more clear that they're separate from `records`, and b) removes the use of `this`.",0,0.9943971633911133
1358712167,14406,kirktrue,2023-10-13T19:07:09Z,"the `testunauthorizedtopic()` test method was added to `fetchertest` almost eight years ago. here's what the test looked like when it was initially committed: [code block] the comment makes a little more sense when taken in its historical context. but it makes a little more sense still when you look at the test method that used to appear directly above `testunauthorizedtopic()`: [code block] my take is that the author copied the `testfetchrecordtoolarge()` to use as a starting point for the new `testunauthorizedtopic()` method. separately, although `testfetchrecordtoolarge()` is no longer around, we still test the 'record too large' case in `testfetchrequestwhenrecordtoolarge()`. i'm inclined to remove the comment because it's pretty clear that the intent of `testunauthorizedtopic()` is to validate that a `topicauthorizationexception` is thrown if the fetch response includes the `topic_authorization_failed` error. what do you think?",0,0.9862027168273926
1358713529,14406,kirktrue,2023-10-13T19:09:06Z,changed,0,0.9270829558372498
1358717315,14406,kirktrue,2023-10-13T19:14:04Z,correct. i've removed the unnecessary `fetchrecords()` call from `testpartialfetchwithpausedpartitions()` in both fetcher tests.,0,0.9942561984062195
1358758478,14406,kirktrue,2023-10-13T19:40:51Z,done.,0,0.9640594124794006
1358761112,14406,kirktrue,2023-10-13T19:43:39Z,done.,0,0.9640594124794006
1358764452,14406,kirktrue,2023-10-13T19:48:25Z,done.,0,0.9640594124794006
1358791361,14406,kirktrue,2023-10-13T20:21:36Z,"done. here's what i added: [code block] i'll admit, i don't know that i totally understand what i wrote or if it's correct :)",1,0.9921140670776367
1358832549,14406,junrao,2023-10-13T20:48:48Z,should the comment be moved to just above `consumernetworkthread.runatclose` below?,0,0.995790958404541
1358914146,14406,kirktrue,2023-10-13T22:24:45Z,"i may be misunderstanding your comment, but the code to denote partitions as being revoked (via `subscriptionstate.markpendingrevocation()` will be handled in kafka-15539.",0,0.9854646325111389
1358914547,14406,kirktrue,2023-10-13T22:25:46Z,done.,0,0.9640594124794006
1358914571,14406,kirktrue,2023-10-13T22:25:51Z,done.,0,0.9640594124794006
1358918492,14406,kirktrue,2023-10-13T22:36:04Z,yes. done.,0,0.819446325302124
1358949767,14406,kirktrue,2023-10-13T23:05:23Z,"i looked into this a bit, and it has to do with the records that are used for the different partitions, their counts, offsets, etc. i think it should be investigated and cleaned up for clarity and reassurance. i will open a new jira ticket since this is part of the existing `fetchertest` suite.",0,0.9838258624076843
1358952151,14406,kirktrue,2023-10-13T23:14:09Z,filed kafka-15606 to track.,0,0.9935423135757446
1358952187,14406,kirktrue,2023-10-13T23:14:15Z,added this to kafka-15606.,0,0.9937757253646851
1358953070,14406,kirktrue,2023-10-13T23:17:34Z,added a link to this question to kafka-15606.,0,0.9931881427764893
1358953131,14406,kirktrue,2023-10-13T23:17:49Z,fixed,0,0.9281549453735352
1358953536,14406,kirktrue,2023-10-13T23:19:06Z,i'll file a bug to investigate this question. thanks!,1,0.9848406910896301
1358953612,14406,kirktrue,2023-10-13T23:19:25Z,i'll file a bug to investigate this question. thanks!,1,0.9848406910896301
1358953637,14406,kirktrue,2023-10-13T23:19:31Z,i'll file a bug to investigate this question. thanks!,1,0.9848406910896301
1358954499,14406,kirktrue,2023-10-13T23:22:49Z,maybe `testfetchresponsemetricswithskippedoffset()`?,0,0.9950587749481201
1358955393,14406,kirktrue,2023-10-13T23:25:43Z,renamed and reversed.,0,0.9880380630493164
1358956176,14406,kirktrue,2023-10-13T23:28:19Z,changed `testreturnabortedtransactionsinuncommittedmode()` to `testreturnabortedtransactionsinuncommittedmode()`,0,0.9948168396949768
1358956462,14406,kirktrue,2023-10-13T23:29:46Z,fixed.,0,0.979083240032196
1358956804,14406,kirktrue,2023-10-13T23:31:02Z,fixed,0,0.9281549453735352
1358957417,14406,kirktrue,2023-10-13T23:32:34Z,i believe it is referring to the `runnable` that is passed into `setwakeuphook()`.,0,0.9924212098121643
1358990414,14406,kirktrue,2023-10-14T00:22:58Z,done.,0,0.9640594124794006
1358990445,14406,kirktrue,2023-10-14T00:23:03Z,done.,0,0.9640594124794006
1358990537,14406,kirktrue,2023-10-14T00:23:29Z,done. replaced with direct call to `applicationeventhandler.wakeup()`.,0,0.9900168776512146
1358990617,14406,kirktrue,2023-10-14T00:23:57Z,"we are not fetching, but we are waiting, so i reworded the comment. lmk if it still needs tweaking. thanks.",1,0.9552136659622192
1358990797,14406,kirktrue,2023-10-14T00:24:33Z,thanks for catching that. i fixed this but it's pretty clear now that i need unit tests to validate correctness.,1,0.9203099608421326
1360933149,14406,junrao,2023-10-16T16:27:06Z,"i made the comment when the code had a `fetchbuffer` in both `prototypeasyncconsumer` and `abstractfetch` since we need to apply the same check on `subscriptions.isfetchable` to both places. now, we only have a single fetchbuffer in `abstractfetch`. this is no longer an issue.",0,0.9937781095504761
1360942134,14406,junrao,2023-10-16T16:34:07Z,unsentrequest => lastunsentrequest ?,0,0.9896608591079712
1360995022,14406,junrao,2023-10-16T17:04:12Z,got it. this is referring to server side upgrade with topicid support.,0,0.9815987944602966
1360998263,14406,junrao,2023-10-16T17:07:32Z,fetchedrecords() => fetchrecords() ?,0,0.9911583065986633
1361004569,14406,junrao,2023-10-16T17:13:29Z,: thanks for the explanation. it makes sense to me to remove the comment here.,0,0.6803041696548462
1361103184,14406,junrao,2023-10-16T18:17:15Z,"thanks for updating the comment, kirk. the comment seems correct. it would be useful to further add that because the fetch position in the request is different from the one in fetch state, the fetched data, including the `offset_out_of_range` error is ignored in `fetchcollector.handleinitializeerrors` because of the following code. ` if (position == null || fetchoffset != position.offset) { ` it's a bit weird that the above check is only done for the `offset_out_of_range` error, instead of any error. it might be useful to file a jira to revisit this logic.",1,0.8762099742889404
1361109166,14406,junrao,2023-10-16T18:23:52Z,"yes, the proposed new name sounds good to me.",0,0.6748930215835571
1361131214,14406,junrao,2023-10-16T18:38:47Z,thanks for the reply. i still don't quite understand the test. why do we duplicate the following code both inside and outside of setwakeuphook? [code block] mockclient is only woken up through `networkclientdelegate.disconnectasync`.,1,0.7693060636520386
1361156117,14406,junrao,2023-10-16T19:05:33Z,the way the code is written. we will wake up `applicationeventhandler` whether fetch is empty or not. perhaps it's simpler to just always call `applicationeventhandler.wakeup()` after each `fetchcollector.collectfetch(fetchbuffer)` call?,0,0.9953782558441162
1361329379,14406,kirktrue,2023-10-16T22:36:19Z,i have filed kafka-15615 to resolve.,0,0.9902105331420898
1361329900,14406,kirktrue,2023-10-16T22:37:18Z,"this is one of the more serious and subtle issues, so i want to know you're ok with the new approach before i resolve this conversation in the pr. thanks!",1,0.9809237718582153
1361332784,14406,kirktrue,2023-10-16T22:42:39Z,filed kafka-15617,0,0.9915271401405334
1361345756,14406,kirktrue,2023-10-16T23:07:23Z,"references were changed to either `fetchrequests` or `collectfetch` as appropriate. some minor refactoring was also introduced to use `assertthrows` instead, where possible.",0,0.9947395920753479
1361346244,14406,kirktrue,2023-10-16T23:08:26Z,removed.,0,0.9782117605209351
1361346884,14406,kirktrue,2023-10-16T23:09:43Z,changed.,0,0.9758284687995911
1361353808,14406,junrao,2023-10-16T23:23:31Z,": yes, the fix lgtm.",0,0.979028046131134
1361355764,14406,kirktrue,2023-10-16T23:27:28Z,great :grinning_face_with_smiling_eyes: thanks!,1,0.994820237159729
1361357104,14406,junrao,2023-10-16T23:29:55Z,the comment is a bit mis-leading since the fetcher doesn't block. it throws an exception.,0,0.5212186574935913
1361357218,14406,kirktrue,2023-10-16T23:30:05Z,can you chime in on this question? thanks!,1,0.9759697318077087
1361357318,14406,kirktrue,2023-10-16T23:30:16Z,can you chime in on this question? thanks!,1,0.9759697318077087
1361357471,14406,kirktrue,2023-10-16T23:30:32Z,can you chime in on this question? thanks!,1,0.9759697318077087
1361358097,14406,kirktrue,2023-10-16T23:31:42Z,"i am not fond of this code as written, and have made at least two attempts to change it. it's a bit messy but i will take another pass to clean it up. ideally mostif not allof the logic would live in `fetchbuffer`.",-1,0.974719762802124
1361358254,14406,kirktrue,2023-10-16T23:32:03Z,"ok, i'll look at this again.",0,0.9748567342758179
1364694361,14406,kirktrue,2023-10-18T23:39:42Z,filed kafka-15634.,0,0.9931148886680603
1364696003,14406,kirktrue,2023-10-18T23:42:49Z,filed kafka-15635.,0,0.9928693175315857
1364698472,14406,kirktrue,2023-10-18T23:47:24Z,filed kafka-15636.,0,0.9928964972496033
1364699488,14406,kirktrue,2023-10-18T23:49:29Z,filed kafka-15637.,0,0.9931938648223877
1364700996,14406,kirktrue,2023-10-18T23:52:47Z,filed kafka-15638.,0,0.9932392835617065
1364704339,14406,kirktrue,2023-10-18T23:59:55Z,filed kafka-15639.,0,0.9931065440177917
1364706025,14406,kirktrue,2023-10-19T00:02:24Z,i removed the comment since there's a more explanatory comment below already.,0,0.9817001223564148
1364707771,14406,kirktrue,2023-10-19T00:04:26Z,done.,0,0.9640594124794006
1364712500,14406,kirktrue,2023-10-19T00:08:48Z,i've filed kafka-15640 to look into this in more detail.,0,0.9874666333198547
1364715414,14406,kirktrue,2023-10-19T00:13:45Z,i've added this to kafka-15640 for a dedicate effort to clean up the modifications to this data to make them atomic operations.,0,0.9895267486572266
1364758468,14406,kirktrue,2023-10-19T01:15:42Z,"i tried to update the comment, but ended up confused on how to explain it. because this looks like an existing issue that needs more investigation, i filed kafka-15641 to follow up.",-1,0.563657820224762
1366182334,14406,kirktrue,2023-10-19T21:59:35Z,both `kafkaconsumer` and `prototypeasyncconsumer` commit offsets asynchronously. i've filed kafka-15651 to review.,0,0.9936400055885315
1366237460,14406,kirktrue,2023-10-19T23:37:40Z,"the issue is with how `offsetsrequestmanager.resetpositionsifneeded()` handles the call to `offsetfetcherutils.getoffsetresettimestamp()`. since `getoffsetresettimestamp()` may throw an exception, `offsetsrequestmanager` should catch it and forward it to the application thread. but instead, `offsetsrequestmanager` allows the error to bubble up to the `applicationeventprocessor`, which will then bubble it up to `consumernetworkthread`, which handles it by logging the error and exiting its `run()` method. in fact, this appears to be the intended behavior since `offsetsrequestmanagertest.testresetpositionsthrowspreviousexception()` explicitly tests that `offsetsrequestmanager.resetpositionsifneeded()` will throw the error directly at the caller. what needs to change is for `offsetsrequestmanager.resetpositionsifneeded()` to catch the exception and enqueue an `errorbackgroundevent` on the background event queue. in this way, the error will be processed on the application thread as part of `poll()`.",0,0.9940029978752136
1366237944,14406,kirktrue,2023-10-19T23:38:52Z,i don't see any existing unit tests which track the specific case that mentioned. i'm currently looking at the integration tests to see if those cover this case.,0,0.9639567732810974
1366262621,14406,kirktrue,2023-10-20T00:00:34Z,"yes. i've made the change that on `close()`, the application thread will wait for the network thread to finish its cleanup, up to the given timeout.",0,0.989082932472229
1366266506,14406,kirktrue,2023-10-20T00:06:58Z,"unfortunately, there are no unit tests or integration tests which catch the offset reset case. i'll file a jira to have one concocted.",-1,0.5364401340484619
1366267515,14406,kirktrue,2023-10-20T00:09:25Z,i've made the following changes: 1. now `offsetsrequestmanager` correctly enqueues errors from `getoffsetresettimestamp()` onto the background event queue for use by the application thread 2. renamed `offsetfetchertest`'s `testrestoffsetsauthorizationfailure()` to `testresetoffsetsauthorizationfailure()` 3. renamed `offsetsrequestmanagertest`'s `testresetpositionsthrowspreviousexception()` to `testresetoffsetsauthorizationfailure()` and updated its logic to ensure the expected error is present in the queue for the application thread to check in `poll()`,0,0.9950413107872009
1367260539,14406,junrao,2023-10-20T16:53:42Z,could we just redirect the implement to the constructor above?,0,0.9947274327278137
1367369975,14406,junrao,2023-10-20T18:27:18Z,would it be clearer to rename refreshcommittedoffsetsifneeded to initwithcommittedoffsetsifneeded?,0,0.9957043528556824
1367383773,14406,junrao,2023-10-20T18:44:13Z,"in `offsetfetcherutils.getoffsetresettimestamp()`, if there is no offset reset policy, currently we just ignore it. it seems that we should throw an exception in that case?",0,0.9918831586837769
1367498133,14406,kirktrue,2023-10-20T21:30:10Z,filed kafka-15652 to ensure that we have tests that catch this case.,0,0.994134247303009
1367508455,14406,kirktrue,2023-10-20T21:49:59Z,fixed.,0,0.979083240032196
1367508628,14406,kirktrue,2023-10-20T21:50:19Z,done.,0,0.9640594124794006
1367510616,14406,kirktrue,2023-10-20T21:53:31Z,done.,0,0.9640594124794006
1367515674,14406,junrao,2023-10-20T22:03:20Z,"this doesn't seem quite right. it's possible for a fetchrequest to return no data. in that case, if we don't wake up the the network thread, it may not be able to send the next fetch request for a long time.",0,0.7047386169433594
1367516322,14406,junrao,2023-10-20T22:04:01Z,`wakeup` => `wakeupnetworkthread` ?,0,0.9939208030700684
1367517181,14406,kirktrue,2023-10-20T22:05:48Z,"there is a default offset reset strategy which is configured via `consumerconfig`, passed to the `kafkaconsumer`, and then to the `subscriptionstate`, right? why wouldn't we fall back to that if there's no overridden offset reset strategy for a particular partition?",0,0.9957506656646729
1367529409,14406,junrao,2023-10-20T22:33:26Z,"[a link] has 3 options: `latest`, `earliest`, `none`. it's possible for a user to choose `none`, which means ""throw exception to the consumer if no previous offset is found for the consumer's group"". but in that case, `offsetfetcherutils.getoffsetresettimestamp` just ignores that partition and won't reset it forever. we need to throw an exception so that the user knows. it's a bit of weird configuration since it means a consumer can't really consume for the very first time with this option. however, i tested it out with the existing consumer and it does throw an exception. [code block]",-1,0.5223653316497803
1367535648,14406,kirktrue,2023-10-20T22:51:18Z,"i changed the `return null` to `throw new nooffsetforpartitionexception(partition)`. i re-ran the tests and nothing failed, so there seems to be another gap in the tests.",0,0.9930181503295898
1367536108,14406,kirktrue,2023-10-20T22:52:38Z,"the enqueuing of other events will also call `wakeupnetworkthread`, so it shouldn't be a problem. but i went ahead and changed it as requested.",0,0.986774206161499
1367536128,14406,kirktrue,2023-10-20T22:52:43Z,done,0,0.8974218964576721
1367537583,14406,junrao,2023-10-20T22:56:48Z,could we just return empty here instead of calling collectfetch() again since the caller is in a loop and can call this method to collect fetch again?,0,0.9939566850662231
1367545811,14406,junrao,2023-10-20T23:12:39Z,would it be clearer to rename `refreshcommittedoffsetsifneeded` to `initwithcommittedoffsetsifneeded`?,0,0.9956046342849731
1367556045,14406,kirktrue,2023-10-20T23:25:15Z,"the `refreshcommittedoffsetsifneeded()` name is derived from existing code in `kafkaconsumer` that calls out to `consumercoordinator.refreshcommittedoffsetsifneeded()`. if we change the method name in `prototypeasyncconsumer`, should we change `consumercoordinator`'s corresponding method name too?",0,0.9951783418655396
1367557772,14406,junrao,2023-10-20T23:32:12Z,"yes, in both cases, the method sets offsets for partitions in initializing state.",0,0.9934321641921997
1367559124,14406,kirktrue,2023-10-20T23:37:47Z,"yes, we could update `pollforfetches()` to simply return `fetch.empty()` at the end. however, there's code that intentionally blocks (for a little bit) waiting for fetch data to arrive in the buffer: [code block] also, each loop through `poll()` executes `updateassignmentmetadataifneeded()` before checking the fetch buffer for any data. that method does a lot of work (network i/o) that we'd ideally skip if we already have the data. perhaps we could update `awaitnotempty()` with a return flag so that the tail end of `pollforfetches()` can look something like this: [code block]",0,0.992442786693573
1367562895,14406,junrao,2023-10-20T23:52:41Z,"thanks for the explanation, kirk. we can just leave the code as it is then.",1,0.8397734761238098
1367565477,14406,kirktrue,2023-10-21T00:03:02Z,updated and a bit of cleanup.,0,0.9769369959831238
1370389793,14406,lianetm,2023-10-24T15:20:23Z,"i had missed a detail here. we're only implementing this with the default timeout, but not the overloaded one below, that has the timeout provided by the user. is there a reason or is it just that we missed the latter one? (same for the `listtopics`)",0,0.9793872833251953
1370452938,14406,lianetm,2023-10-24T15:58:23Z,(i guess it will be all part of the integration with the metadata calls right?),0,0.9847882986068726
1370486899,14406,kirktrue,2023-10-24T16:21:12Z,good call out. i don't know that the necessary topic plumbing code was written at that time. would you mind filing a bug to resolve?,1,0.6062010526657104
751663483,11390,ccding,2021-11-17T21:48:45Z,why do we remove `false` from the third parameter? the default is `true`,0,0.9940273761749268
751670345,11390,ccding,2021-11-17T21:59:29Z,why do we remove the keyword `override` here?,0,0.9922096729278564
751673278,11390,ccding,2021-11-17T22:04:21Z,is this change intentional?,0,0.9819757342338562
754749020,11390,satishd,2021-11-23T01:26:46Z,"good catch, fixed it.",1,0.962594211101532
754749244,11390,satishd,2021-11-23T01:27:35Z,"intellij auto formatted, fixed it.",0,0.9892268180847168
755410314,11390,junrao,2021-11-23T18:38:36Z,is this change needed?,0,0.9904143810272217
755430690,11390,junrao,2021-11-23T19:08:52Z,"hmm, why do we want to eat the ioexception? ditto below.",0,0.8534613847732544
755446235,11390,junrao,2021-11-23T19:32:40Z,"does the parent cl have a super set of classpathes than the child? if so, is urls1 a subset of urls2?",0,0.9938925504684448
755523984,11390,junrao,2021-11-23T21:42:25Z,i the local log => in the local log,0,0.9549440741539001
755548648,11390,junrao,2021-11-23T22:22:25Z,listoffset returns the leaderepoch for the localstartoffset. could we just use that leaderepoch? it will simplify the code below.,0,0.9942627549171448
760490750,11390,junrao,2021-12-01T19:04:46Z,could we add remotelogmanager to the javadoc too?,0,0.9948416352272034
760491245,11390,junrao,2021-12-01T19:05:34Z,does this need to be volatile?,0,0.9890959858894348
760630665,11390,junrao,2021-12-01T22:49:37Z,indentation,0,0.822169840335846
760661057,11390,junrao,2021-12-01T23:54:44Z,could this case just be handled below for earliest_local_timestamp?,0,0.9952030181884766
760671044,11390,junrao,2021-12-02T00:20:02Z,could this be private?,0,0.9903441071510315
761506462,11390,junrao,2021-12-02T22:15:31Z,"we need to find the first segment matching the timestamp from the remote segments, then the local segments.",0,0.9907364249229431
761524592,11390,junrao,2021-12-02T22:50:20Z,fetchremoteindex() can take time. could we call this asynchronously so that we don't block the request handler thread?,0,0.992901086807251
762123788,11390,junrao,2021-12-03T17:33:27Z,this may not matter for now. but it's probably better to use config.maxindexsize as the max index size.,0,0.9911830425262451
762126153,11390,junrao,2021-12-03T17:37:24Z,should >= be > ?,0,0.9878260493278503
762129356,11390,junrao,2021-12-03T17:42:27Z,could we add a description for this class?,0,0.9911763668060303
762138449,11390,junrao,2021-12-03T17:57:18Z,should we close inputstream when done?,0,0.9925984144210815
762171200,11390,junrao,2021-12-03T18:53:08Z,should we use a shutdownablethread?,0,0.991853654384613
762176132,11390,junrao,2021-12-03T19:01:36Z,"the abort marker for offsets within the fetch range could be in subsequent log segments. so, we need to collect aborted transactions beyond the segment that the fetch offset resides.",0,0.9865939617156982
762183906,11390,junrao,2021-12-03T19:15:33Z,could we just call loadclass() once as in createremotestoragemanager()?,0,0.9950777292251587
762188249,11390,junrao,2021-12-03T19:23:09Z,could we add topicids to javadoc?,0,0.9944114089012146
762189948,11390,junrao,2021-12-03T19:26:06Z,could we reuse the method unifiedlog.remotelogenabled()?,0,0.994696855545044
762191856,11390,junrao,2021-12-03T19:29:25Z,should we just add remote_log_metadata_topic_name to topic.internal_topics?,0,0.9954094290733337
762193670,11390,junrao,2021-12-03T19:32:32Z,could we just get rid of filteredleaderpartitions as we have for followertopicpartitions?,0,0.9948847889900208
762195818,11390,junrao,2021-12-03T19:36:31Z,"hmm, it seems that we only want to remove topicid when all partitions in the topic are removed?",0,0.9855221509933472
762200473,11390,junrao,2021-12-03T19:44:52Z,does this need to be a concurrent map since there is no synchronization on access?,0,0.991600751876831
762202911,11390,junrao,2021-12-03T19:49:17Z,"similar here, since fetch from remove storage can block, it would be better to do this asynchronously so that it doesn't block a request handler thread.",0,0.9928425550460815
762206303,11390,junrao,2021-12-03T19:55:19Z,should we also close all opened files in entries?,0,0.9944133162498474
762325936,11390,junrao,2021-12-03T22:36:03Z,"to use array(), we have to first check hasarray(). it's probably simpler to do buffer.put(logheaderbuffer).",0,0.9940876960754395
762355278,11390,junrao,2021-12-04T00:22:04Z,the code doesn't seem to check topicid.,0,0.8653420805931091
762355609,11390,junrao,2021-12-04T00:23:48Z,which request?,0,0.9652830362319946
762357821,11390,junrao,2021-12-04T00:34:25Z,"when receiving offset_moved_to_tiered_storage, we know the follower's offset is below leader's local start offset. it seems that we could directly ask for leader's local start offset instead of calling fetchlatestoffsetfromleader().",0,0.9932327270507812
762359179,11390,junrao,2021-12-04T00:41:01Z,it's less verbose to do [code block],0,0.9715509414672852
762362355,11390,junrao,2021-12-04T00:58:51Z,reloadsegments => reloadsnapshots ?,0,0.9932603240013123
762362423,11390,junrao,2021-12-04T00:59:17Z,is this needed since the caller calls this already?,0,0.9930850267410278
762364294,11390,junrao,2021-12-04T01:11:13Z,where is the logic to rebuild remotelogmetadatasnapshotfile?,0,0.9952507019042969
762366976,11390,junrao,2021-12-04T01:29:24Z,loading from remote storage could be expensive. it would be useful to do this asynchronously so that the replication thread can make faster progress on other partitions.,0,0.9888862371444702
762367379,11390,junrao,2021-12-04T01:32:13Z,do we want to include the change in fetchrequest too?,0,0.9933423399925232
762367939,11390,junrao,2021-12-04T01:36:36Z,"it's not really ""by local timestamp"". it's localstartoffset.",0,0.973128616809845
767417471,11390,satishd,2021-12-13T05:14:43Z,this is added to exclude any generated files by the tiered storage test runs.,0,0.9872398972511292
767425395,11390,satishd,2021-12-13T05:41:05Z,"it checks if the given resource exists within this class loader first, it delegates to the parent classloader if it is not found in this class loader.",0,0.9934931397438049
767426396,11390,satishd,2021-12-13T05:44:05Z,it is a `val` for now and it is not needed to be declared as volatile and the compiler does not allow too. this will be updated in the upcoming changes to `var` and then it can be declared as volatile.,0,0.9942864775657654
767427042,11390,satishd,2021-12-13T05:45:48Z,updated with shutdownablethread.,0,0.9914980530738831
767427379,11390,satishd,2021-12-13T05:46:46Z,this is an unused method. remotelogmanager handles going through subsequent segments and collect all aborted transactions. these changes will be added in the next pr. i will remove this unused method for now.,0,0.9889013767242432
767427546,11390,satishd,2021-12-13T05:47:16Z,"actually, that can still be improved. updated with the changes to avoid creating `classloaderawareremotestoragemanager` unnecessarily and calls going through classloader switching.",0,0.9881261587142944
767427717,11390,satishd,2021-12-13T05:47:50Z,i plan to do that later. it requires the metadata topic configs to be built and auto topic creation manager needs to handle this topic creation etc.,0,0.9907802939414978
767428241,11390,satishd,2021-12-13T05:49:29Z,good point. changed it to use topicpartition instead of topic as we need to maintain a different data structure for all the partitions and need to synchronize between them. having concurrentmap of topicpartion with topicid is simpler to manage here.,0,0.5582959651947021
767428501,11390,satishd,2021-12-13T05:50:15Z,i will address in a followup pr.,0,0.9860363006591797
767428782,11390,satishd,2021-12-13T05:51:13Z,this cleansup all the earlier loaded snapshots. it loads the newly created snapshot.,0,0.9911510348320007
767430230,11390,satishd,2021-12-13T05:55:41Z,"`rlsmetadata = rlm.fetchremotelogsegmentmetadata(partition, epoch.get, leaderlocallogstartoffset)` returns empty and this method throws an error back to the caller here. it retries again until the required `rlsmetadata` is available. `remotelogmetadatasnapshotfile` is loaded when assigning of partitions are done as part of `topicbasedremotelogmetadatamanager.assignpartitions()`.",0,0.994828999042511
767430483,11390,satishd,2021-12-13T05:56:24Z,i will address this in a followup pr.,0,0.9830334782600403
767434452,11390,satishd,2021-12-13T06:08:20Z,used `option.foreach` here. can you be more specific here?,0,0.9946098327636719
767435783,11390,satishd,2021-12-13T06:11:55Z,i will address this in a followup pr.,0,0.9830334782600403
767698400,11390,satishd,2021-12-13T12:08:40Z,updated the javadoc.,0,0.9908164739608765
768141997,11390,junrao,2021-12-13T21:38:33Z,should we remove this?,0,0.9898141026496887
772110652,11390,junrao,2021-12-20T06:38:21Z,was this comment addressed?,0,0.9915623068809509
772110800,11390,junrao,2021-12-20T06:38:43Z,the return value is not very intuitive. i'd expect a true return value to indicate that the request is handled successfully.,0,0.934842050075531
772110895,11390,junrao,2021-12-20T06:38:56Z,could we add a comment on what this method does?,0,0.9904578924179077
772110978,11390,junrao,2021-12-20T06:39:11Z,"in the else case, should we truncate all local log?",0,0.9929429888725281
772111057,11390,junrao,2021-12-20T06:39:21Z,change from ` replicamgr.remotelogmanager.foreach(rlm => { } ) ` to ` replicamgr.remotelogmanager.foreach{rlm => } ` ditto in a few other places.,0,0.9936800003051758
772111223,11390,junrao,2021-12-20T06:39:45Z,"hmm, the remote data could end at leaderlocallogstartoffset - 1. in that case, we won't find a corresponding rlsmetadata.",0,0.9307544827461243
772111916,11390,junrao,2021-12-20T06:41:23Z,"this is kind of awkward and inefficient. could we add a better api to avoid the trial and error approach? for example, we could have an api that waits for the remote log segment metadata up to offset leaderlocallogstartoffset - 1 becoming available with leader epoch less than or equal to currentleaderepoch.",-1,0.9231635332107544
772111987,11390,junrao,2021-12-20T06:41:35Z,it's awkward to stream into a temp file only to load it back in memory.,-1,0.9782149791717529
773121075,11390,satishd,2021-12-21T13:08:06Z,"updated the comment, we do not really need to have a check here. let me know if i am missing anything here.",0,0.976820707321167
773121400,11390,satishd,2021-12-21T13:08:36Z,addressed it in the latest commit.,0,0.9927680492401123
773121903,11390,satishd,2021-12-21T13:09:20Z,this is inline with `handleoutofrangeerror` contract. i am fine with the suggested change but it is good to have similar semantics to `handleoutofrangeerror` method too for uniformity.,0,0.7349393963813782
773122505,11390,satishd,2021-12-21T13:10:13Z,good point. i updated it to address this scenario too in the latest commit.,1,0.8960921168327332
773123927,11390,satishd,2021-12-21T13:12:13Z,changed it to use the leader epoch of leader's local-log-start-offset and find the respective earlier epoch for (leader's local-log-start-offset -1) from the leader.,0,0.9938070178031921
773143045,11390,satishd,2021-12-21T13:39:14Z,filed [a link] to add the suggested improvement.,0,0.9888816475868225
773499214,11390,wyuka,2021-12-21T23:16:35Z,shouldn't this method be called `setremotelogmanager(...)`?,0,0.9946224689483643
778990618,11390,ccding,2022-01-05T17:08:02Z,`local-log-start-timestamp` instead of `local-log-start-offset` in the comment?,0,0.9955874681472778
779060541,11390,junrao,2022-01-05T18:52:06Z,"when we hit offsetoutofrangeexception, it's possible that remote storage is enabled. in that case, we also need to rebuild the remote log metadata.",0,0.9915096759796143
779089066,11390,ccding,2022-01-05T19:40:31Z,is it possible to make `topic.isinternal(topicpartition.topic())` to return true if `topicbasedremotelogmetadatamanagerconfig.remote_log_metadata_topic_name.eq(topicpartition.topic()))`? then we can get rid of the `topicbasedremotelogmetadatamanagerconfig.remote_log_metadata_topic_name.eq(topicpartition.topic()))` check,0,0.9950652718544006
779142706,11390,ccding,2022-01-05T21:17:24Z,do we need to log if there are any exceptions? or throw the exception out?,0,0.9915497303009033
779158936,11390,ccding,2022-01-05T21:47:49Z,is there any reason for not using the existing suffixes? [a link],0,0.9917395114898682
779162870,11390,ccding,2022-01-05T21:55:20Z,should the error message be `cleaned up`?,0,0.9949982166290283
779166585,11390,ccding,2022-01-05T22:02:35Z,why do we use `coreutils.tryall` in one case and use `array().foreach( try catch )` in the other case?,0,0.9941312670707703
779169864,11390,ccding,2022-01-05T22:09:02Z,"we can use `val dirname = ""remote-log-index-cache""` here",0,0.9940029978752136
779171925,11390,ccding,2022-01-05T22:13:11Z,what is the trade-off between using a daemon thread and using kafka scheduler?,0,0.9929845333099365
779175283,11390,ccding,2022-01-05T22:20:08Z,[code block] i think we don't need to flush the parent dir. it doesn't matter if the cache file is not renamed during an unclean shutdown.,0,0.9819979071617126
779177001,11390,junrao,2022-01-05T22:23:44Z,space after if.,0,0.9859527349472046
779177082,11390,ccding,2022-01-05T22:23:57Z,do we need to log/handle exception caused by fetchandcreateindex,0,0.9894735217094421
779191474,11390,junrao,2022-01-05T22:55:27Z,"topicbasedremotelogmetadatamanager independently updates the metadata state from the tier topic. when we make the `rlm.fetchremotelogsegmentmetadata` call, how does it make sure that it has caught up enough records from the tier topic including the segment covering the requested offset?",0,0.9949836730957031
779191948,11390,ccding,2022-01-05T22:56:38Z,"wanted to double check you mean `log.remotelogenabled()` or `!log.remotelogenabled()` here, because it is `filternot`",0,0.9933887720108032
779192232,11390,ccding,2022-01-05T22:57:20Z,"`log.remotelogenabled()` already checks internal and equals remote_log_metadata_topic_name, do we need to check again here?",0,0.995547890663147
779196455,11390,junrao,2022-01-05T23:07:36Z,"endoffset is exclusive. so, we could just use leaderlogstartoffset.",0,0.9914711117744446
779199654,11390,junrao,2022-01-05T23:15:45Z,should we use foreach instead of map?,0,0.9931507110595703
779200299,11390,junrao,2022-01-05T23:17:30Z,should we flush the leader epoch file at the end?,0,0.9946029782295227
779213401,11390,junrao,2022-01-05T23:55:08Z,should we write the producer snapshot to a temp file first and then rename?,0,0.9945039749145508
779216639,11390,junrao,2022-01-06T00:05:34Z,"it possible that the endoffset in rlsmetadata is larger than leaderlocallogstartoffset. if we fetch the local log from leaderlocallogstartoffset, duplicated tnx could be added to producerstatemanager. it's better to start fetching from rlsmetadata.endoffset + 1.",0,0.9912481307983398
779223560,11390,junrao,2022-01-06T00:26:56Z,this is the top level error. unknown_topic_id and inconsistent_topic_id are partition level errors and don't need to be handled here.,0,0.9896851778030396
779233183,11390,junrao,2022-01-06T00:57:41Z,why does this method need to be protected instead of private? ditto for fetchoffsetandbuildremotelogauxstate.,0,0.9855577349662781
784750507,11390,satishd,2022-01-14T10:57:46Z,we have not yet made `topicbasedremotelogmetadatamanagerconfig.remote_log_metadata_topic_name` as internal topic. i plan to make this change once it is created as an internal topic.,0,0.9935184121131897
784751134,11390,satishd,2022-01-14T10:58:44Z,we do not want to log here. it should be handled by the invoker.,0,0.9710129499435425
784753702,11390,satishd,2022-01-14T11:02:40Z,there is no specific reason other than having a shorter suffix. i do not have a strong opinion on that. i am fine with eitherways.,0,0.8356772661209106
784764008,11390,satishd,2022-01-14T11:18:34Z,"in the earlier case, we want the exception to be thrown with the exception as mentioned in `coreutils.tryall`. but in this case, we want to catch each invocation and ignore it instead of collecting like coreutils.tryall.",0,0.989757776260376
784768268,11390,satishd,2022-01-14T11:25:20Z,"no, we want to throw it back so that invoker can handle it.",0,0.9813995957374573
784770314,11390,satishd,2022-01-14T11:28:57Z,nice catch!!,1,0.9947559833526611
784772939,11390,satishd,2022-01-14T11:33:21Z,"good point, i am making a simpler check here to use `filter`. [code block]",1,0.855899453163147
784793287,11390,satishd,2022-01-14T12:08:32Z,we do not need to flush it as`cache.assign` already flushes the entry.,0,0.9934723377227783
784793923,11390,satishd,2022-01-14T12:09:39Z,"sure, it is good to do that. addressed it in the latest commit.",0,0.948172390460968
784801502,11390,satishd,2022-01-14T12:22:42Z,"if it does not catchup then it returns `optional.empty`, and that we throw a remotestorageexception. as the caller receives remotestorageexception, it will be retried again.",0,0.9890521168708801
785875887,11390,satishd,2022-01-17T11:19:35Z,"in that case, i prefer to use '>' instead of '>=' like below. this is more clear and easy to read. i have also added a comment to talk about a case in leader epoch gap. [code block]",0,0.9681876301765442
786517360,11390,satishd,2022-01-18T08:36:13Z,"i refactored `assign` whether to flush or not with default as true for backward compatibility. in this case, i assign all the entries without flush, and flush to the file at the end.",0,0.9933973550796509
786518882,11390,satishd,2022-01-18T08:38:15Z,"we encounter `offsetoutofrangeexception` only when the offsets are beyond the range of [logstartoffset, logendoffset]. why do we need to build remote log metadata in that case? i may be missing something here.",0,0.9531764984130859
786736586,11390,satishd,2022-01-18T13:01:15Z,good point! made the respective changes in the latest commit.,1,0.9850472211837769
788215466,11390,junrao,2022-01-19T22:58:55Z,space after if,0,0.9853398203849792
788253183,11390,junrao,2022-01-20T00:23:47Z,"if we hit offsetoutofrangeexception, we call fetchearliestoffsetfromleader() inside fetchoffsetandapplyfun(), which fetches the localstartoffset. we then truncate the whole log and start fetching from localstartoffset. if the leader has data in remote storage, the follower won't have the remote log metadata for consumer fetch and won't have the same state (e.g. producer state) as the leader.",0,0.9805831909179688
788269196,11390,junrao,2022-01-20T01:02:58Z,fetchearlierepochendoffset(3) => fetchearlierepochendoffset(2) ?,0,0.9937992691993713
788270782,11390,junrao,2022-01-20T01:07:16Z,"it's possible for the local data to overlap a bit with what's in the remote storage. so, leaderlocallogstartoffset - 1 is not necessarily the highest offset in remote storage. could we name highestoffsetinremotefromleader more properly?",0,0.9886041879653931
788279027,11390,junrao,2022-01-20T01:29:23Z,we need to return nextoffset to the caller so that fetchoffsetandapplyfun() could set the next fetch offset to this.,0,0.9940506815910339
789307564,11390,wyuka,2022-01-21T02:46:58Z,we can use [code block] instead,0,0.9913800358772278
789308168,11390,wyuka,2022-01-21T02:48:04Z,we can use [code block] instead,0,0.9913800358772278
791322611,11390,satishd,2022-01-25T03:10:39Z,"sure, as we discussed offline, i added the approach to keep offsetoutofrange like earlier, which is to fetch the log-start-offset and it may get a response of offsetmovedtotieredstorage if it tries to fetch from log-start-offset and it is moved to tiered storage.",0,0.9897890686988831
791957579,11390,yyang48,2022-01-25T17:28:55Z,"just curious, why we need to read this value from the buffer and discard it immediately?",0,0.8928395509719849
791968984,11390,yyang48,2022-01-25T17:42:00Z,"i'm not sure whether this buffer is big enough or not? from the line 58: the size of the buffer is the record content size + 12. however, from the line 34, the logheaderbuffer is: 17. in the line 59, if we put the entire logheaderbuffer to this buffer, in the worse case, we need 5 bytes more space in the capacity. is this correct?",0,0.9469681978225708
796465473,11390,satishd,2022-02-01T10:40:54Z,good point. it is not really needed. looks like it was added earlier to log offset but the log was removed.,1,0.8366478085517883
796479255,11390,satishd,2022-02-01T10:58:08Z,"no, we do not really need more space here. i updated with more comments in the code on how it works. this is aligned with the existing code in other places like `filechannelrecordbatch`. payload : log_overhead + 4 + 1 (magic:byte) + reocrd-content log_overhead = 8(offset:long) + 4(size:int) = 12 `size` = 4 + 1(magic) + record-content-size. `logheaderbuffer` is read until magic. that is why the complete buffer-size is 12(log_overhead) + size. we do not count ""4 + 1(magic)"" here as it is already taken into account with size_read_from_header",0,0.9890825748443604
804020896,11390,junrao,2022-02-10T19:07:26Z,should we complete the javadoc? ditto for fetchearliestoffsetfromleader().,0,0.9920303821563721
804023336,11390,junrao,2022-02-10T19:10:45Z,could we add the javadoc for this one?,0,0.9924229979515076
804025075,11390,junrao,2022-02-10T19:13:07Z,"is ""related to offsets out of rage"" true? also, since we explained this error, do we need the error code?",0,0.9671014547348022
804026471,11390,junrao,2022-02-10T19:15:03Z,"is ""handle the offset out of range error"" true?",0,0.9925127029418945
804030400,11390,junrao,2022-02-10T19:20:34Z,"could we make it clear that the reason that we don't need to backoff and retry is because we move the partition to a failed state? also, could we put true in a separate line? ditto for handleoutofrangeerror().",0,0.9932836294174194
804042686,11390,junrao,2022-02-10T19:37:27Z,"the above long comment doesn't quite fit into remote storage. we could make it more general that covers both cases. if that's too complicated, perhaps have a separate method just for handling remote storage.",0,0.9750390648841858
804145767,11390,junrao,2022-02-10T21:59:14Z,could we change earliestorlatest to sth more generic now that it can have 3 values?,0,0.9933544397354126
804149120,11390,junrao,2022-02-10T22:00:51Z,there is no leader epoch before 0.10. so the leader epoch can just be -1.,0,0.9855040907859802
804186063,11390,junrao,2022-02-10T22:32:48Z,"this call writes another snapshot, which is unnecessary. perhaps we could just do producerstatemanager.truncateandreload()?",0,0.9917759895324707
804191359,11390,junrao,2022-02-10T22:38:43Z,"if we get here, it means the leader has started tiering the data but the follower hasn't received the remotestorageenable config yet. it seems that we should backoff and retry the same offset instead of just fetching from leaderlocallogstartoffset?",0,0.9856523275375366
804196978,11390,junrao,2022-02-10T22:45:04Z,this is not just an offset index.,0,0.9803637862205505
804200819,11390,junrao,2022-02-10T22:49:26Z,why is this called cleanableindex? it's bit confusing given log cleaner. maybe sth like baseindex?,-1,0.841288149356842
804201757,11390,junrao,2022-02-10T22:50:32Z,time stamp => timestamp,0,0.9667389988899231
804203296,11390,junrao,2022-02-10T22:52:28Z,space after if,0,0.9853398203849792
804223128,11390,junrao,2022-02-10T23:14:55Z,"hmm, it's kind of weird to set the class loader on each call. is this needed? do other remote storage classes just use the classloader for rlm and rlmm?",-1,0.9854936003684998
804234045,11390,junrao,2022-02-10T23:27:08Z,the original configs in config may contain implementation specific properties. how do we pass those to rlmm and rlm through remotelogmanager?,0,0.9933332800865173
804239401,11390,junrao,2022-02-10T23:33:20Z,it seems that we never add to topicpartitionids?,0,0.9816754460334778
804245130,11390,junrao,2022-02-10T23:43:38Z,"in the local case, if all the messages in the remote storage have larger timestamps, it seems that we return the timestamp of the first message.",0,0.9909600019454956
804245833,11390,junrao,2022-02-10T23:45:16Z,could we call maybeepoch.get() once in the loop?,0,0.993860125541687
804250739,11390,junrao,2022-02-10T23:56:46Z,previousepoch?,0,0.99216628074646
804250861,11390,junrao,2022-02-10T23:57:03Z,nextepoch?,0,0.9837180972099304
804250995,11390,junrao,2022-02-10T23:57:19Z,epochentry?,0,0.9052865505218506
804251574,11390,junrao,2022-02-10T23:58:41Z,should previousepoch be initialize to none?,0,0.9927816987037659
804252215,11390,junrao,2022-02-11T00:00:12Z,this seems unused?,0,0.824500560760498
804252997,11390,junrao,2022-02-11T00:02:09Z,it's not really local timestamp.,0,0.6987239718437195
804265970,11390,junrao,2022-02-11T00:35:38Z,"should we load up existing files to entries during init()? otherwise, it's not clear when they will be cleaned up.",0,0.9732970595359802
804266325,11390,junrao,2022-02-11T00:36:47Z,should we close the indexes too?,0,0.9938668608665466
804266637,11390,junrao,2022-02-11T00:37:38Z,this is never read?,0,0.9772647619247437
804267665,11390,junrao,2022-02-11T00:40:18Z,is this safe? the entry could be cleaned immediately after this check.,0,0.9923537969589233
804268708,11390,junrao,2022-02-11T00:43:07Z,rewind() is typically used after the buffer is written. should we use clear()?,0,0.9951651096343994
804270391,11390,junrao,2022-02-11T00:47:41Z,was this comment addressed?,0,0.9915623068809509
804274827,11390,junrao,2022-02-11T01:00:19Z,"this is not supported yet, right? should we throw an exception?",0,0.9009775519371033
804275488,11390,junrao,2022-02-11T01:02:03Z,should we just throw unsupportedexception?,0,0.9772722721099854
804277844,11390,junrao,2022-02-11T01:09:06Z,no need to pass in reloadfromcleanshutdown since it's always false?,0,0.994743824005127
804280439,11390,junrao,2022-02-11T01:16:55Z,this seems an indirect way to check message version. should we just check that explicitly?,0,0.9408820271492004
804281396,11390,junrao,2022-02-11T01:19:46Z,"hmm, locallogstartoffset could change after the call the remotelogmanager.",0,0.9833690524101257
804843541,11390,junrao,2022-02-11T17:03:42Z,"for other broker side plugins (e.g. authorizer), we never needed a special class loader. why do we need this for the remote storage plugin?",0,0.9921512603759766
812537683,11390,satishd,2022-02-23T03:44:29Z,"this is to avoid library conflicts directly or indirectly with the existing libraries in the system classpath. this classloader loads the libraries in the given paths. whenever a class needs to be loaded, it delegates to the system classloader only when it is not found in the configured paths. rsm or rlmm providers can have all the required libraries in given directories and add them as classpath for rsm or rlmm. this provides isolation with the libraries in the system classpath.",0,0.9949561953544617
813156759,11390,junrao,2022-02-23T17:48:17Z,"yes, i understand the intent. however, there are quite a few pluggable components on the broker side right now. sorting out the classpath dependencies among all of them seems quite complicated. another way to solve the issue is through shading. a potential conflicting library could be renamed to a different package.",0,0.9450709819793701
814028646,11390,satishd,2022-02-24T16:00:43Z,updated the statement and the error code is removed.,0,0.9924282431602478
814031095,11390,satishd,2022-02-24T16:03:07Z,"sure, i also updated the method to return true if it was able to handle it.",0,0.9862226843833923
814036592,11390,satishd,2022-02-24T16:09:03Z,`responsepartition.leaderepoch` returns -1 with <= kafka_0_10_1_iv2 version. no need to explicitly set it as -1.,0,0.9952042102813721
814039902,11390,satishd,2022-02-24T16:12:30Z,`remotelogmanagerconfig#remotestoragemanagerprops()` and `remotelogmanagerconfig#remotelogmetadatamanagerprops()` return respective properties which are used while configuring rsm and rlmm in `remotelogmanager#configurersm()` and `remotelogmanager#configurerlmm()`.,0,0.9936792254447937
814041397,11390,satishd,2022-02-24T16:13:59Z,this code missed while merging other changes. addressed with the latest commit.,0,0.9843780398368835
814045120,11390,satishd,2022-02-24T16:17:57Z,changed it to `version 8 enables listing offsets by local log start offset.`,0,0.9940122961997986
814046367,11390,satishd,2022-02-24T16:19:15Z,we do not need to explicitly close them as they are already closed inside `deleteifexists()` method.,0,0.9937288761138916
814050149,11390,satishd,2022-02-24T16:23:14Z,"this is used in dowork(), updated with the latest commit.",0,0.9935843348503113
814127632,11390,satishd,2022-02-24T17:53:23Z,good catch!! i will address it.,1,0.9949422478675842
814640948,11390,kowshik,2022-02-25T10:10:57Z,"this class is slim in functionality, and i don't feel there is any real benefit for introducing this. also for the future, it is not clear to me what operations can be included in this class, and which ones can't be. i feel that the earlier design without this base class was simpler. are we planning to add new functionality in the future into this class?",-1,0.768947184085846
814642656,11390,kowshik,2022-02-25T10:13:11Z,"lets rename `x` to something more readable, ex: `index`.",0,0.9944540858268738
814658812,11390,kowshik,2022-02-25T10:35:11Z,s/related to offset moved to tiered storage/offset_moved_to_tiered_storage can we also log the topicpartition?,0,0.9950317144393921
814660162,11390,kowshik,2022-02-25T10:37:09Z,"this method `fetchoffsetandapplytruncateandbuild` is currently doing a number of things, which is clear from the method name. it will be hard to cover all test cases in unit test. so, it is better if its simplified.",0,0.9904866814613342
814668927,11390,kowshik,2022-02-25T10:50:08Z,"here to build the remote log aux state we only need the leader local log start offset, right? in such a case, i think it gets complicated if we try to repurpose `fetchoffsetandapplytruncateandbuild` here. can we just introduce a separate method that would just attempt to get the leader's local log start offset, and pass it into `buildremotelogauxstate`?",0,0.9883843660354614
814678429,11390,kowshik,2022-02-25T11:04:36Z,"this method is doing a lot of things, and it is worthwhile thinking about how to simplify it. in its current form, it is going to be hard to test it.",0,0.686264157295227
814981129,11390,junrao,2022-02-25T18:00:33Z,"i was referring to ""the timestamp will be message.notimestamp"". it should be the timestamp of the first message.",0,0.9899359345436096
818028561,11390,junrao,2022-03-02T19:29:10Z,"the purpose of a special class loader is to address potential class conflicts. if the same class exists btw the plugin and kafka, by switching the class loader, it seems that we don't know deterministically which version of the class will be loaded, which can be confusing.",0,0.9014027118682861
898097965,11390,divijvaidya,2022-06-15T15:02:56Z,the comment does not match the functionality for the function here. this implementation only performs delete.,0,0.9901988506317139
981140295,11390,divijvaidya,2022-09-27T11:51:53Z,nit i would suggest to move `testutils.resource` to `utils` and use that to mimic java's try-with-resource in scala.,0,0.9926716089248657
981150239,11390,divijvaidya,2022-09-27T12:02:42Z,"this could be refactored into a method in leaderepochcache, perhaps with signature `assign(seq(epochentry))`",0,0.9952953457832336
981152254,11390,divijvaidya,2022-09-27T12:04:55Z,"do we want to clear the existing cache first using `cache.clearandflush()`? asking because (and correct me if i am wrong) in the case of uncleanleaderelection, this follower may have log lineage belonging to previous leader. the new leader may have a different log lineage which doesn't contain epochs present in old lineage. those epochs absent missing in new lineage need to be removed from the cache.",0,0.9878498911857605
983849860,11390,divijvaidya,2022-09-29T17:39:05Z,this offset is the `last-tiered-offset + 1` and not the `local-log-start-offset`. please correct me if i am wrong but this is inconsistent with what is described in the kip-405 where we say:,0,0.9695627093315125
985706396,11390,satishd,2022-10-03T12:06:00Z,this offset is not `last-tiered-offset + 1` but `previousoffsettoleaderlocallogstartoffset` which is `leaderlocallogstartoffset - 1`. this is aligned with what we mentioned in kip-405. you can take a look at the usage of `mayberlsm` which is [code block],0,0.9952014684677124
1025959204,11390,showuon,2022-11-18T03:46:54Z,nit: add a space before `new rcordheader`,0,0.9931029081344604
1026063322,11390,showuon,2022-11-18T06:18:22Z,nit: remotestoragesystemenable -> remotestoragesystemenable[d],0,0.993489146232605
1026064974,11390,showuon,2022-11-18T06:22:09Z,nit: remote logging -> remote log,0,0.9884273409843445
1026065351,11390,showuon,2022-11-18T06:22:57Z,should we also check `__cluster_metadata` topic? it isn't checked in `isinternal`,0,0.9952998161315918
1026079869,11390,showuon,2022-11-18T06:48:22Z,nit: remotestoragesystemenable -> remotestoragesystemenable[d],0,0.993489146232605
1026086446,11390,showuon,2022-11-18T07:01:21Z,"there will be background thread to delete them later, right? i don't think this is necessary.",0,0.9564822912216187
1026087680,11390,showuon,2022-11-18T07:03:42Z,where's the implementation?,0,0.986208438873291
1026095589,11390,showuon,2022-11-18T07:18:10Z,"this `computifabsent` method might do 3 `fetchandcreateindex` for all 3 indexes, which will take many time, inside the lock. could we fetch them before we lock the `entries`?",0,0.994235098361969
1026097879,11390,showuon,2022-11-18T07:21:53Z,forgot to add javadoc for 3 parameters,0,0.979540228843689
1026112608,11390,showuon,2022-11-18T07:44:38Z,"the implementation of `lookuptimestamp` above is also returning the `the timestamp of the first message.`. so, only javadoc needs to be updated",0,0.9947997331619263
1026121749,11390,showuon,2022-11-18T07:57:35Z,nit: additional comma at the end,0,0.9831894636154175
1026133917,11390,showuon,2022-11-18T08:14:42Z,updated partition fetch state,0,0.9841009974479675
1026146723,11390,showuon,2022-11-18T08:28:16Z,agree. there must be something wrong here. error log is also necessary.,0,0.9718319177627563
1026150319,11390,showuon,2022-11-18T08:32:22Z,nit: the indent is not quite right here,-1,0.7302283048629761
1026173480,11390,showuon,2022-11-18T08:57:36Z,nit: give a change -> chance?,0,0.9530133008956909
1026175979,11390,showuon,2022-11-18T09:00:20Z,ditto,0,0.9222367405891418
1026242726,11390,showuon,2022-11-18T10:02:31Z,"i think it should `mock the segment of offset 0-4 moved to remote store.`, right?",0,0.9945079684257507
1026243503,11390,showuon,2022-11-18T10:03:18Z,ditto,0,0.9222367405891418
1032869910,11390,satishd,2022-11-27T05:35:05Z,we were doing that earlier but you suggested to do normal truncation until local-log-start-offset as mentioned [a link].,0,0.9946678876876831
1032869957,11390,satishd,2022-11-27T05:36:00Z,this is addressed with the latest changes.,0,0.9902011752128601
1032870167,11390,satishd,2022-11-27T05:38:00Z,we can keep it simple for now as you suggested. removed baseindex for now but we may add it later if needed.,0,0.9927889704704285
1032870377,11390,satishd,2022-11-27T05:39:57Z,adding space fails with style-check.,0,0.9237594604492188
1032870521,11390,satishd,2022-11-27T05:41:05Z,this is the existing convention used in other properties like unclean.leader.election.enable etc,0,0.994398295879364
1032870562,11390,satishd,2022-11-27T05:41:34Z,this is the existing convention used in other properties like unclean.leader.election.enable etc,0,0.994398295879364
1032870593,11390,satishd,2022-11-27T05:42:27Z,these are not loaded as entries marked for deletion. it is good to delete them any pending deletions when a broker is started.,0,0.9532263278961182
1032870604,11390,satishd,2022-11-27T05:42:41Z,it is addressed with the latest set of commits.,0,0.9877787232398987
1032871126,11390,satishd,2022-11-27T05:49:04Z,changed the text to make it more clear.,0,0.970767080783844
1032871130,11390,satishd,2022-11-27T05:49:09Z,changed the text to make it more clear.,0,0.970767080783844
1032944075,11390,satishd,2022-11-27T14:45:54Z,leaderepochcache is already cleaned up by the earlier `truncatefullyandstartat` call.,0,0.9918069243431091
1032945780,11390,satishd,2022-11-27T14:57:26Z,i will address in the next commit.,0,0.9887678027153015
1033092123,11390,showuon,2022-11-28T03:31:34Z,any reason why we don't want to `extends closeable` here?,0,0.9767564535140991
1033093221,11390,showuon,2022-11-28T03:34:54Z,"i saw we already updated the `_locallogstartoffset` in `maybeincrementlogstartoffset` method. if you know there are some other places we also need to update it, maybe you can make it much clear in the comment.",0,0.9932243227958679
1033097357,11390,showuon,2022-11-28T03:45:59Z,fair enough,0,0.8143565058708191
1033136878,11390,showuon,2022-11-28T05:22:04Z,should we lock it?,0,0.9908197522163391
1033141283,11390,showuon,2022-11-28T05:32:56Z,"thanks for the update, but i think we still lock for the period of loading 3 index files. how about this: [code block] wdyt?",1,0.7960928082466125
1033492033,11390,satishd,2022-11-28T12:38:45Z,"added closeable as part of this pr, and we do not really need it with the latest changes..",0,0.9849690198898315
1033493533,11390,satishd,2022-11-28T12:40:19Z,locking is not really needed here as `init` method is invoked only when remoteindexcache instance is getting initialized.,0,0.9928020238876343
1033515905,11390,satishd,2022-11-28T13:02:53Z,"this creates race between writers and readers of these files which may fail readers with io errors. for ex: the race can occur in 3 ways 1. multiple writers writing those indexes concurrently 2. one of them will update the entry with the existing file but that file could have been over written in step-1 3. when readers start reading, those file might have been overwritten in step-1.",0,0.9790273904800415
1033516642,11390,satishd,2022-11-28T13:03:35Z,"please ignore the stale comment, removed with the latest commit.",0,0.9873056411743164
1034340498,11390,satishd,2022-11-29T06:20:02Z,"[a link] covers to get indexes or data in async manner for critical paths, we can cover as part of that jira. wdyt?",0,0.9890648126602173
1034345625,11390,showuon,2022-11-29T06:29:16Z,sounds good to me! i'll resolve this comment.,1,0.9887813329696655
1034345639,11390,satishd,2022-11-29T06:29:18Z,good point. this is clarified in later comments.,1,0.9170762896537781
1041219212,11390,satishd,2022-12-06T16:50:10Z,"it does not really create another snapshot as it has the below check in producerstatemanager#takesnapshot. also, it is good to use `log.loadproducerstate` as any extra logic that may be added does not need to be added separately here. [code block]",0,0.9928553700447083
1041821188,11390,showuon,2022-12-07T06:52:56Z,nit: javadoc doesn't include all params,0,0.938969075679779
1041842874,11390,showuon,2022-12-07T07:22:48Z,"nit: i know we don't test them, but could we add some comments here? thanks.",1,0.7083967924118042
1042140948,11390,divijvaidya,2022-12-07T12:24:53Z,"consider the following scenario: 1. leader is archiving to tiered storage and has a follower. 2. follower has caught up to offset x (exclusive). 3. while follower is offline, leader moves x to tiered storage and expires data locally till y, such that, leaderlocallogstartoffset > x and y = leaderlocallogstartoffset. meanwhile, x has been expired from tiered storage as well. hence, x < globallogstartoffset as well. now, there could be a scenario where globallogstartoffset > leaderlocallogstartoffset because segments has been expired from remote but not from local. 3. follower comes online and tries to fetch x from leader, leader throws moved to tiered storage exception. 4. follower moves to buildaux state and tries to fetch the metadata. the metadata may not exist since the segment has been deleted in remote storage and we will get an error. this could be addressed at replica manager where it could detect if the remote segments have been deleted and accordingly throw an out of bound instead of move to tiered storage exception, but we should also add a defensive handling check here. in the above scenario, we should directly move to truncation instead of build aux state. the defensive check could be `&& leaderlocallogstartoffset > leaderlogstartoffset` over here. also, please add a test for this scenario.",0,0.9924207329750061
1043330520,11390,satishd,2022-12-08T13:04:03Z,this is addressed with the latest commit.,0,0.9903546571731567
1043330573,11390,satishd,2022-12-08T13:04:07Z,this is addressed with the latest commit.,0,0.9903546571731567
1043981337,11390,junrao,2022-12-09T01:39:11Z,the comment is a bit confusing since 4 bytes + magic doesn't add up to log_overhead.,-1,0.8292829394340515
1043981867,11390,junrao,2022-12-09T01:40:03Z,same question here. it seems that it's better to make it clear that abstractindex is closable?,0,0.9918603301048279
1043982291,11390,junrao,2022-12-09T01:41:10Z,does this need to be volatile?,0,0.9890959858894348
1043982526,11390,junrao,2022-12-09T01:41:43Z,should we reset hwm too?,0,0.9929240942001343
1043982906,11390,junrao,2022-12-09T01:42:42Z,should this be in the storage module like classloaderawareremotelogmetadatamanager?,0,0.9954631924629211
1043983132,11390,junrao,2022-12-09T01:43:19Z,i guess we will add the logic to delete the remote data later?,0,0.9879491329193115
1043983263,11390,junrao,2022-12-09T01:43:42Z,target offset => start offset?,0,0.9919746518135071
1043983592,11390,junrao,2022-12-09T01:44:31Z,"do we need to make ""all the messages in the remote storage have larger timestamps"" a special case here? it seems the last option covers that case already.",0,0.9936655163764954
1043983792,11390,junrao,2022-12-09T01:45:04Z,could we just assign to maybeepoch directly and get rid of startingoffsetepoch?,0,0.9943870306015015
1043984064,11390,junrao,2022-12-09T01:45:35Z,"if no message has timestamp, we will fall to here. this doesn't seem to implement what the comment says.",0,0.8810775279998779
1043984353,11390,junrao,2022-12-09T01:46:29Z,"it would be useful to make logging a complete sentence, so sth like debug(s""received error ${errors.offset_moved_to_tiered_storage} at "" + s""fetch offset: ${currentfetchstate.fetchoffset} for "" + s""topic-partition: $topicpartition"")",0,0.9917473793029785
1043984841,11390,junrao,2022-12-09T01:47:46Z,haven't => hasn't,0,0.5932610630989075
1043985073,11390,junrao,2022-12-09T01:48:20Z,"we already stopped processing requests at this point, right?",0,0.9807561039924622
1043985230,11390,junrao,2022-12-09T01:48:41Z,this seems unused?,0,0.824500560760498
1043985494,11390,junrao,2022-12-09T01:49:22Z,could this be private?,0,0.9903441071510315
1043985686,11390,junrao,2022-12-09T01:49:51Z,should fetchearlierepochendoffset(2) be fetchearlierepochendoffset(90)?,0,0.9948924779891968
1043985886,11390,junrao,2022-12-09T01:50:14Z,"could we use complete sentence? e.g. s""active producers with size of ${log.producerstatemanager.activeproducers.size}, "" s""logstartoffset is $leaderlogstartoffset and logendoffset is $nextoffset"")",0,0.992546021938324
1043986046,11390,junrao,2022-12-09T01:50:34Z,"yes, thinking about this more. i am not sure that truncating all local logs is the right thing to do. if we do that, the replica's log may not give a complete view of the data. we could get into this situation when (1) the topic level remote storage flag propagation is delayed; (2) incorrect configuration by the user (e.g. remotestoragesystemenable not enabled on all brokers). in both cases, it seems a better strategy is to error out and keep retrying. in the case (1), the issue will be resolved automatically when the topic level flag is propagated to this broker. in the case (2), this issue will be resolve after the user fixes the configuration.",0,0.9359105229377747
1043987311,11390,junrao,2022-12-09T01:51:30Z,it seems no non-test caller sets flushtofile to false?,0,0.9912533164024353
1043989048,11390,junrao,2022-12-09T01:52:25Z,truncateonfetch is always true?,0,0.9930605888366699
1043989337,11390,junrao,2022-12-09T01:52:47Z,add newline after,0,0.9792097806930542
1043989757,11390,junrao,2022-12-09T01:53:22Z,could this be private?,0,0.9903441071510315
1043990559,11390,junrao,2022-12-09T01:54:23Z,could we add a description of the class?,0,0.9912192225456238
1044740416,11390,junrao,2022-12-09T18:47:37Z,could we use case statement to avoid using unnamed references?,0,0.9928620457649231
1044741168,11390,junrao,2022-12-09T18:48:41Z,"hmm, i am not sure that i understand the test. the snapshot corresponding to offset 5 should still be there, right? where did we delete it?",-1,0.589289665222168
1044757469,11390,junrao,2022-12-09T19:11:36Z,why are we calling the same thing a second time?,0,0.9285479187965393
1044758640,11390,junrao,2022-12-09T19:13:28Z,why are we calling the same thing a second time? ditto in two other places below.,0,0.954757809638977
1044791351,11390,junrao,2022-12-09T19:42:37Z,"hmm, the log segment only has 1 record with timestamp and startoffset. why do we return timestamp + 1 here?",0,0.9621054530143738
1044796318,11390,junrao,2022-12-09T19:48:50Z,add a new line above,0,0.9815390706062317
1044806867,11390,junrao,2022-12-09T20:05:41Z,_locallogstartoffset could change after we find out the epoch. perhaps we could save it as a local val and use it in the return value.,0,0.9921321272850037
1046991743,11390,satishd,2022-12-13T10:58:07Z,comment does not say that magic+4 bytes adds upto log_overhead. updated the comment to make it more clear about the size used in the below code. `int buffersize = log_overhead + size;`,0,0.9941163063049316
1047001228,11390,satishd,2022-12-13T11:04:58Z,i will address it in a followup pr. filed [a link],0,0.9746226072311401
1047001890,11390,satishd,2022-12-13T11:05:34Z,right. added the respective delete part for now which is about removing the partitions. more on that will be added respectively when we add handling partition deletes with respect to remote storage also.,0,0.9918642044067383
1047002015,11390,satishd,2022-12-13T11:05:45Z,done,0,0.8974218964576721
1047002223,11390,satishd,2022-12-13T11:05:58Z,done,0,0.8974218964576721
1047003879,11390,satishd,2022-12-13T11:07:40Z,"that case is taken care in `lookuptimestamp`. let me know if i am missing anything here. `val timestampoffset = lookuptimestamp(rlsmetadata, timestamp, startingoffset)`",0,0.9931447505950928
1047004756,11390,satishd,2022-12-13T11:08:10Z,done,0,0.8974218964576721
1047005713,11390,satishd,2022-12-13T11:08:41Z,updated it with the right text.,0,0.9912930130958557
1047007959,11390,satishd,2022-12-13T11:09:51Z,nice catch! this is moved to `metadataversion`.,1,0.9795387387275696
1047008633,11390,satishd,2022-12-13T11:10:15Z,"no, fetchearlierepochendoffset(2) is right. argument here is the leader epoch.",0,0.9886367917060852
1047008950,11390,satishd,2022-12-13T11:10:25Z,done,0,0.8974218964576721
1047009169,11390,satishd,2022-12-13T11:10:31Z,done,0,0.8974218964576721
1047014746,11390,satishd,2022-12-13T11:14:32Z,right.,0,0.9793882369995117
1047015681,11390,satishd,2022-12-13T11:15:31Z,`truncateonfetch` is the existing code. it is not added by this pr.,0,0.9945517182350159
1047016127,11390,satishd,2022-12-13T11:15:58Z,done,0,0.8974218964576721
1047017673,11390,satishd,2022-12-13T11:17:33Z,this is overridden by `listoffsetsrequestwithremotestoretest`,0,0.9944233298301697
1047018234,11390,satishd,2022-12-13T11:17:46Z,done,0,0.8974218964576721
1047018559,11390,satishd,2022-12-13T11:17:55Z,done,0,0.8974218964576721
1047019754,11390,satishd,2022-12-13T11:18:35Z,updated with javadoc to explain the testcases with the latest commits.,0,0.9899294972419739
1047020063,11390,satishd,2022-12-13T11:18:44Z,updated with javadoc to explain the testcases with the latest commits.,0,0.9899294972419739
1047020508,11390,satishd,2022-12-13T11:18:57Z,done,0,0.8974218964576721
1047020836,11390,satishd,2022-12-13T11:19:07Z,done,0,0.8974218964576721
1047024290,11390,satishd,2022-12-13T11:21:03Z,+1 on this approach. this is aligned with our initial proposal in this pr also. latest commit is updated with this change.,0,0.6401220560073853
1047369687,11390,satishd,2022-12-13T16:07:36Z,added more documentation about the test for better clarity with the latest commit. statemanager.reloadsnapshots() deletes the existing snapshots.,0,0.9896206855773926
1049205016,11390,satishd,2022-12-15T04:33:13Z,"as discussed offline, the current follower fetch retries when it receives an error while building aurxiliary state. it will eventually gets the auxiliary data from remote storage for the available leader-log-start-offset.",0,0.9892767667770386
1049392445,11390,showuon,2022-12-15T09:20:23Z,maybe we should have an assertion before and between the 1st and 2nd call to `getindexentry`? like this: [code block],0,0.9949952363967896
1049393028,11390,showuon,2022-12-15T09:20:56Z,typo: sis -> is,0,0.9822522401809692
1049396894,11390,showuon,2022-12-15T09:23:45Z,i saw there are many places have this assertion. i've created a jira to address it: [a link] . you can ignore it for this pr. thanks.,1,0.9678865671157837
1049993923,11390,junrao,2022-12-15T18:15:54Z,"this is still not very precise since size includes other fields like crc, attributes, etc. so, we could probably just omit it and say the total size of a batch is log_overhead + the size of the rest of the content.",0,0.9855729937553406
1050008020,11390,junrao,2022-12-15T18:31:58Z,it's better to use locallog.logendoffsetmetadata since it has the log metadata in addition to the offset.,0,0.9937731623649597
1050013671,11390,junrao,2022-12-15T18:39:10Z,"it seems that the ""no message in the remote storage has the given timestamp"" case is covered in the otherwise clause too?",0,0.9947651624679565
1050017122,11390,junrao,2022-12-15T18:43:27Z,it seems that both offsetforleaderepochrequestversion and listoffsetrequestversion are moved to metadataversion and can be removed here?,0,0.9957564473152161
1050029710,11390,junrao,2022-12-15T18:57:17Z,"then, could we just remove this param?",0,0.9928687214851379
1050033092,11390,junrao,2022-12-15T19:01:07Z,inmemory => in memory,0,0.949959397315979
1050035787,11390,junrao,2022-12-15T19:04:29Z,could we add a similar comment as in line 125?,0,0.9939170479774475
1050039191,11390,junrao,2022-12-15T19:09:04Z,change to curlocallogstartoffset = locallogstartoffset ?,0,0.9891108870506287
1050045012,11390,junrao,2022-12-15T19:16:40Z,should we add a test that explicitly tests the producer state after handling offset_moved_to_tiered_storage error? this can be done in a separate pr.,0,0.9950313568115234
1050536097,11390,satishd,2022-12-16T09:28:23Z,updated with what you suggested to make it more clear.,0,0.9809746146202087
1050536434,11390,satishd,2022-12-16T09:28:47Z,done,0,0.8974218964576721
1050536942,11390,satishd,2022-12-16T09:29:21Z,done,0,0.8974218964576721
1050537018,11390,satishd,2022-12-16T09:29:26Z,done,0,0.8974218964576721
1050537960,11390,satishd,2022-12-16T09:30:25Z,"as you suggested earlier, i created a [a link] for that and mentioned it in my earlier [a link].",0,0.9870188236236572
1051118349,11390,junrao,2022-12-16T20:06:38Z,logendoffset still uses offset. we want to use logendoffsetmetadata.,0,0.9903786182403564
1051439769,11390,ijuma,2022-12-17T18:26:58Z,+1,0,0.7702900171279907
263150141,6363,kkonstantine,2019-03-06T21:47:30Z,please skip this file and review: [a link] instead. thanks!,1,0.9935164451599121
263150256,6363,kkonstantine,2019-03-06T21:47:51Z,please skip this file and review: [a link] instead. thanks!,1,0.9935164451599121
263151738,6363,kkonstantine,2019-03-06T21:52:09Z,please skip this file and review: [a link] instead. thanks!,1,0.9935164451599121
263151859,6363,kkonstantine,2019-03-06T21:52:30Z,please skip this file and review: [a link] instead. thanks!,1,0.9935164451599121
263151902,6363,kkonstantine,2019-03-06T21:52:37Z,please skip this file and review: [a link] instead. thanks!,1,0.9935164451599121
263151960,6363,kkonstantine,2019-03-06T21:52:46Z,please skip this file and review: [a link] instead. thanks!,1,0.9935164451599121
263152009,6363,kkonstantine,2019-03-06T21:52:55Z,please skip this file and review: [a link] instead. thanks!,1,0.9935164451599121
263152049,6363,kkonstantine,2019-03-06T21:53:03Z,please skip this file and review: [a link] instead. thanks!,1,0.9935164451599121
263152103,6363,kkonstantine,2019-03-06T21:53:11Z,please skip this file and review: [a link] instead. thanks!,1,0.9935164451599121
263152397,6363,kkonstantine,2019-03-06T21:54:01Z,please skip this file and review: [a link] instead. thanks!,1,0.9935164451599121
263152448,6363,kkonstantine,2019-03-06T21:54:08Z,please skip this file and review: [a link] instead. thanks!,1,0.9935164451599121
263152502,6363,kkonstantine,2019-03-06T21:54:17Z,please skip this file and review: [a link] instead. thanks!,1,0.9935164451599121
263242755,6363,kkonstantine,2019-03-07T05:31:22Z,"this file changes can be omitted, although it'd be nice to consider whether we want to enable a few log messages in connect integration tests. this is something that manually needs to be enabled when someone debugs a failure at an integration test.",0,0.9916753768920898
268807968,6363,rhauch,2019-03-25T19:10:32Z,missing the `` for most of the parameters.,0,0.9857881665229797
268809353,6363,rhauch,2019-03-25T19:14:31Z,"nit: might this be null, or will it only be empty?",0,0.9811357855796814
268809411,6363,rhauch,2019-03-25T19:14:38Z,"nit: might this be null, or will it only be empty?",0,0.9811357855796814
268845523,6363,rhauch,2019-03-25T20:51:45Z,nit: should the header be in a ` ` section so it's easier to read given it uses constant-width formatting?,0,0.9944685697555542
268846278,6363,rhauch,2019-03-25T20:53:50Z,"the [a link] that `compatible` is the default. also, why is the protocol string for eager ""`default`""?",0,0.9950404763221741
268847672,6363,rhauch,2019-03-25T20:57:16Z,"why not define a new field in the enum and assign via a constructor, rather than define an abstract method and override in the definitions? see [a link] for an example.",0,0.9930834770202637
268847927,6363,rhauch,2019-03-25T20:57:50Z,the [a link] mentions that `compatible` is the default.,0,0.992771327495575
268848356,6363,rhauch,2019-03-25T20:58:40Z,nit: maybe use `timeunit.seconds.tomillis(300)` for the value? that seems to be more in line with how we're doing time-related constants now.,0,0.9936175346374512
268848881,6363,rhauch,2019-03-25T21:00:06Z,can this be final? can it also be private? (i don't see it's used anywhere else in the code.),0,0.9917716383934021
268849865,6363,rhauch,2019-03-25T21:02:40Z,"doesn't each process only have a single distributedworker instance? if so, then would `connect_client_id_sequence.getandincrement()` ever return something other than 1?",0,0.9939289093017578
268868053,6363,rhauch,2019-03-25T21:53:33Z,"did you consider having a single log message that output all of these in one message? would that make it easier to follow what is being decided, especially if there are lots of interjected messages from currently-running connectors and tasks?",0,0.985564112663269
268869092,6363,rhauch,2019-03-25T21:56:44Z,add javadoc,0,0.9799273014068604
268882992,6363,rhauch,2019-03-25T22:43:19Z,is this method used anymore?,0,0.991060197353363
268911175,6363,rhauch,2019-03-26T01:06:41Z,"the logic of these methods is not trivial, and while connectassignortest has unit tests that exercise some of these methods, what do you think about writing unit tests for these. they really don't use state, so they would seem straightforward to test and it would help any future work by preventing regressions.",0,0.9751307368278503
268911374,6363,rhauch,2019-03-26T01:08:03Z,this combination of javadoc and line comments is unusual. is there a reason this isn't in the javadoc?,0,0.8000891804695129
268912546,6363,rhauch,2019-03-26T01:16:43Z,nit: seems odd to have statics after member fields.,-1,0.9744881987571716
268913739,6363,rhauch,2019-03-26T01:24:46Z,how about a validator to ensure that worker configs are valid before the distributedworker starts instantiating its components and throwing illegalargumentexceptions?,0,0.9928014278411865
268913846,6363,rhauch,2019-03-26T01:25:27Z,"what happens if name is not lowercase? there's no validator for this, so it's possible to get an exception at a strange point.",0,0.7776625156402588
268914485,6363,rhauch,2019-03-26T01:29:39Z,i don't think this is used anywhere except for tests. is that intentional?,0,0.7849543690681458
268914753,6363,rhauch,2019-03-26T01:31:27Z,"i think these fields will never be null based upon how it is currently used, but there are no asserts or checks to ensure there are no npes here. is this intentional?",0,0.9782521724700928
268915078,6363,rhauch,2019-03-26T01:33:33Z,"it took me a while to find this class. would it make more sense if there were named `incrementalcooperativeassignortest` instead, since that's all that's being tested?",0,0.9838111996650696
268916477,6363,rhauch,2019-03-26T01:43:03Z,do you think it's easier to understand the test to simply do: [code block],0,0.9881851673126221
268916806,6363,rhauch,2019-03-26T01:45:25Z,"is this all that we can assert here? it doesn't really seem to validate much of the logic by just checking the sizes, does it?",0,0.9865140318870544
271858376,6363,kkonstantine,2019-04-03T17:46:44Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9913869500160217
271858438,6363,kkonstantine,2019-04-03T17:46:52Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9913869500160217
271858506,6363,kkonstantine,2019-04-03T17:47:02Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9913869500160217
271858588,6363,kkonstantine,2019-04-03T17:47:16Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9913869500160217
271858640,6363,kkonstantine,2019-04-03T17:47:23Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9913869500160217
271858676,6363,kkonstantine,2019-04-03T17:47:29Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9913869500160217
271858830,6363,kkonstantine,2019-04-03T17:47:41Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9913869500160217
271858905,6363,kkonstantine,2019-04-03T17:47:54Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9913869500160217
271908729,6363,rayokota,2019-04-03T20:01:15Z,"wouldn't it be better to return an empty map? then it would be consistent with the code in the rest of the method body that also returns an empty map if both are `null`. and it would also be consistent with `asmap` that never returns `null` as well as a few other methods in this class that return `collections.emptylist` instead of `null`, and also remove a bunch of `null` checks.",0,0.9948931932449341
271909677,6363,rayokota,2019-04-03T20:03:53Z,"if `taskassignments` never returns `null`, you can simplify these checks.",0,0.9923831820487976
271910018,6363,rayokota,2019-04-03T20:04:51Z,"if `taskassignments` never receives `null`, you can simplify this so that it also never returns `null`.",0,0.9914999604225159
271910748,6363,rayokota,2019-04-03T20:06:58Z,`asmap()` never returns `null`; that's why it would be nice if `asrevokedmap` also never returns `null`.,0,0.9913305044174194
271911651,6363,rayokota,2019-04-03T20:09:34Z,yay!,1,0.9786435961723328
271911745,6363,rayokota,2019-04-03T20:09:53Z,yay!,1,0.9786435961723328
271912716,6363,rayokota,2019-04-03T20:12:39Z,wouldn't it be better to have something like `public static connectprotocolcompatibility default = eager;`,0,0.9939725995063782
271913903,6363,rayokota,2019-04-03T20:16:03Z,"why can't this just be `name().tolowercase(locale.root)`. otherwise if `protocol()` is allowed to differ from `name()`, then how do i go from a `protocol()` to the enum (since there is only a way to go from `name()` to enum).",0,0.9907484650611877
271916281,6363,rayokota,2019-04-03T20:22:40Z,should we check that `update` is `null`? it's confusing if `running` is allowed to be `null` but `update` is assumed not to be.,0,0.8885897397994995
271917878,6363,rayokota,2019-04-03T20:27:21Z,nit: can be replaced with `computeifabsent`,0,0.9938675761222839
271918316,6363,rayokota,2019-04-03T20:28:35Z,nit: can be replaced with `computeifabsent`,0,0.9938675761222839
271918654,6363,rayokota,2019-04-03T20:29:29Z,nit: can be replaced with `getordefault`,0,0.9933751225471497
271918689,6363,rayokota,2019-04-03T20:29:35Z,nit: can be replaced with `getordefault`,0,0.9933751225471497
271919947,6363,rayokota,2019-04-03T20:33:02Z,do we need an `assert` that the `memberconfigs` is never empty? otherwise `return maxoffset` will throw npe.,0,0.990345299243927
271920454,6363,rayokota,2019-04-03T20:34:20Z,"nit: this can be simplified to `maxoffset = math.max(maxoffset, memberrootoffset)` if we initialize `maxoffset` with `long maxoffset = long.min_value`.",0,0.9945161938667297
271923960,6363,rayokota,2019-04-03T20:43:37Z,"there is an `equals` call here, but i don't see `equals` and `hashcode` methods for `connectassignment`. if you are assuming reference equality, perhaps use `==`?",0,0.9943325519561768
271927037,6363,rayokota,2019-04-03T20:51:08Z,"why not return `connectassignment.empty()`? i found 2 callers to this method: `incrementalcooperativeconnectprotocol.derserializemetadata` sends the result to the `extendedworkerstate` constructor, which replaces null with `connectassignment.empty()`. the other caller, `workercoordinator.onjoincomplete()`, tries to call `version()` and would get an npe.",0,0.9914354681968689
271928754,6363,rayokota,2019-04-03T20:55:39Z,nit: could add `throws schemaexception` to the method declaration if you want,0,0.9927287101745605
271930819,6363,rayokota,2019-04-03T21:01:10Z,do we need an `assert` that `allmembermetadata` is not empty? otherwise an npe would result here i think,0,0.9921392798423767
271933574,6363,rayokota,2019-04-03T21:08:51Z,should this return an empty `bytebuffer`? i think one of the callers will get a npe otherwise.,0,0.9651609063148499
271933845,6363,rayokota,2019-04-03T21:09:40Z,nit: `.stream().foreachordered()` can be replaced with `.foreach()`,0,0.9929918050765991
271934088,6363,rayokota,2019-04-03T21:10:24Z,nit: `.stream().foreachordered()` can be replaced with `.foreach()`,0,0.9929918050765991
271934289,6363,rayokota,2019-04-03T21:10:57Z,nit: `.stream().foreachordered()` can be replaced with `.foreach()`,0,0.9929918050765991
271979425,6363,kkonstantine,2019-04-04T00:16:31Z,"unfortunately this value has to stay as is, called `default`, otherwise we won't be able to have live rolling upgrades. in all the versions up to now, the `workercoordinator` sets the name of the embedded protocol in the joingrouprequest (aka metadata request) as `default`. small price to pay i think, because it's internal info. we can deprecate the term `default` eventually",0,0.9822695851325989
271979799,6363,kkonstantine,2019-04-04T00:18:57Z,in the `reverse` map we put both values lowercase and uppercase (values are matching the enum name which is upper case). they can be used either way then. i don't think i was the first to introduce this. but i have found useful that we don't strictly accept only uppercase values. i don't see much downside to it.,0,0.9427535533905029
271980517,6363,kkonstantine,2019-04-04T00:23:32Z,"i find the two ways equivalent, with minor pros and cons in edge cases.",0,0.6670922636985779
271980846,6363,kkonstantine,2019-04-04T00:25:39Z,correct. i didn't get to the removal of `cooperative` as well as the switch of default yet. will update in a bigger commit without other cleanup comments.,0,0.9857304096221924
271982564,6363,kkonstantine,2019-04-04T00:36:45Z,"the sets are many. i'd still like to take a final look on what is printed before we merge. but seems not printing as soon as possible, might hide issues, even during integration tests. but i see your point. let's get back to that.",0,0.8716392517089844
272760693,6363,kkonstantine,2019-04-05T22:24:34Z,i believe they are there now.,0,0.9399486184120178
272761166,6363,kkonstantine,2019-04-05T22:27:38Z,let me know if that's what you had in mind.,0,0.9808444976806641
274026037,6363,mumrah,2019-04-10T15:36:25Z,"`objects#requirenonnull` can be used during assignment as well, e.g. [code block]",0,0.9948023557662964
274068757,6363,mumrah,2019-04-10T17:13:39Z,"minor: since there are so few values to consider, maybe prefer a brute force approach? e.g., `values().stream().findfirst(mode -> mode.name().equalsignorecase(querymode)`",0,0.9936001300811768
275537294,6363,kkonstantine,2019-04-15T20:44:49Z,"this file contains the old code in `workercoordinator` _as-is_. i would prefer not to introduce changes at all, no matter how small the changes. in a pr that big, it's simply a matter of discipline not to try to change multiple execution paths at once. this and the optimizations below are small. additionally, this code is not expected to run if the new rebalancing policy is chosen. i'm happy to return to this code, that is know encapsulated in a separate and well defined class for a similar clean once the the code has been released.",1,0.9550126791000366
275537397,6363,kkonstantine,2019-04-15T20:45:07Z,same as above.,0,0.9857698678970337
275537442,6363,kkonstantine,2019-04-15T20:45:16Z,same as above,0,0.965356171131134
275537487,6363,kkonstantine,2019-04-15T20:45:21Z,same as above,0,0.965356171131134
275537527,6363,kkonstantine,2019-04-15T20:45:30Z,same as above,0,0.965356171131134
275537593,6363,kkonstantine,2019-04-15T20:45:41Z,same as above,0,0.965356171131134
275538726,6363,kkonstantine,2019-04-15T20:48:59Z,"it's not a checked exception. we don't add unchecked exception to the signature. only in javadoc. this method is `private`, so i'm adding the javadoc mention on the `public` methods that check version.",0,0.9881112575531006
275549911,6363,kkonstantine,2019-04-15T21:22:22Z,fixed. with a note to improve logging and log messages in this class.,0,0.9808176755905151
275560677,6363,kkonstantine,2019-04-15T21:57:44Z,"the distinction i want to reflect here is that, task assignments have always been a required field of the connect protocol (v0 and therefore v1) and this can not change in a backwards compatible way. to the contrary, the revoked assignments correspond to a new field, which is also `nullable` which here means also optional. deprecating such a field if we need to might be easier in the future (although not completely transparent since we don't selectively unpack fields in the protocol schema). that's why `asmap` does not return `null` while `asrevokemap` might return `null`. i'll comment below too.",0,0.9937570095062256
275562433,6363,kkonstantine,2019-04-15T22:04:33Z,see previous comment.,0,0.9873520135879517
275563850,6363,kkonstantine,2019-04-15T22:10:28Z,"this is different. this takes you from on-the-wire representation to the in-memory representation. also, it's meant to be used both for assignments and revocations. of course, for this protocol it doesn't make sense to keep `null` in the in-memory representation of `connectassignment`. see another take on compatibility between v0 and v1 in `connectprotocolcompatibilitytest`",0,0.9937227368354797
275563890,6363,kkonstantine,2019-04-15T22:10:39Z,see comment above,0,0.9702662825584412
275567590,6363,kkonstantine,2019-04-15T22:25:40Z,"enums in java are more expressive. we don't have to restrict ourselves to what `name()` represents. here we have a good example, where the protocol has to stay as `default` for backwards compatibility but we don't have to call the enum literal `default`. giving the literal a more accurate name, while keeping compatibility is one of the reasons enums in java are more powerful than elsewhere.",0,0.9767052531242371
275567702,6363,kkonstantine,2019-04-15T22:26:14Z,let's revisit when we reduce the enum values to reflect the voted version of the kip,0,0.9909580945968628
275571648,6363,kkonstantine,2019-04-15T22:43:44Z,this is not meant to be a general method. i removed the `null` check because assignment collections should not be `null`. if we see fit later on we could factor out this logic to a more general diff method in `connectassignment` itself.,0,0.9938061237335205
275575635,6363,kkonstantine,2019-04-15T23:02:18Z,"with api generator has become a bit harder to argue about, but both current and new code depend on members this list (`allmembermetadata`) not being `null`. any gaps of api generator with `final` member fields and when arrays are allowed to be set to `null` instead of an empty array should not be addressed as part of this pr imo. i think it's safe to depend on the previous assumption, that `allmembermetadata` can not be `null`.",0,0.9790757894515991
275576977,6363,kkonstantine,2019-04-15T23:08:48Z,but if we were to introduce these methods on `connectassignment` this code would still work right? while reference equality would be harder to track in this case.,0,0.9912558794021606
275585786,6363,kkonstantine,2019-04-15T23:55:41Z,"currently this doesn't seem possible because we never send a `connectassignment.empty()` intentionally unless this is called in a metadata request. we might send an assignment that is practically empty on an error, but in this case equality here is not true. however, i'll tighten the checks and will increase coverage. we might end up diverging, depending on who's using this call. however, again for metadata we need `null` because this goes to a nullable field.",0,0.9735865592956543
275586823,6363,kkonstantine,2019-04-16T00:01:33Z,"see explanation above. this ties back to what we send over the wire. a `connectassignment.empty` assignment is never sent over the wire (you'll always have the leader and the leader url fields for instance, even if you receive an empty assignment).",0,0.9944105744361877
275587099,6363,kkonstantine,2019-04-16T00:03:19Z,"see answer in the other comment about `asmap`. the two methods are not symmetric to this respect, because one field is required and the other one is optional.",0,0.9925658702850342
275587135,6363,kkonstantine,2019-04-16T00:03:30Z,fixed,0,0.9281549453735352
275587191,6363,kkonstantine,2019-04-16T00:03:50Z,"as mentioned above, these fields in `v1` protocol are `nullable`. therefore, instead of going back and forth from empty list to `null` and vice versa, i prefer to have `taskassignments` handle `null` and potentially return `null`, because `null` is what needs to be used when these optional fields are empty.",0,0.9934417009353638
275588182,6363,kkonstantine,2019-04-16T00:09:40Z,"changed, although with the need to convert `long` to `int` it's less brief than ideal. though still safer, i agree.",0,0.925467848777771
275588691,6363,kkonstantine,2019-04-16T00:12:39Z,fixed. i must have had plans for parameterizing it in unit tests that i didn't follow after all.,0,0.9781346321105957
275588918,6363,kkonstantine,2019-04-16T00:13:49Z,this is older code which i chose not to change here. one place where you can see the counter making a difference is in integration tests with multiple workers at the moment.,0,0.9672072529792786
275589318,6363,kkonstantine,2019-04-16T00:16:11Z,i'm keeping the old comment from `connectprotocol`. not sure it belongs to the javadoc. wdyt?,0,0.8938553333282471
275589829,6363,kkonstantine,2019-04-16T00:19:14Z,"in general, i'm not sure our checkstyle is very opinionated w.r.t to this order. changed to bring empty first.",-1,0.535527765750885
275590343,6363,kkonstantine,2019-04-16T00:22:13Z,"this class has some overlap with other classes such as `connectorsandtasks` and even `leaderstate`. i agree and i would also like to consolidate, but maybe when we are near the end of the pr review.",0,0.9834913611412048
275590597,6363,kkonstantine,2019-04-16T00:23:38Z,i'll add a requirement in the constructor rather than here.,0,0.9885559678077698
275592326,6363,kkonstantine,2019-04-16T00:34:24Z,fixed,0,0.9281549453735352
275592693,6363,kkonstantine,2019-04-16T00:36:30Z,"also, to comment, java allows us to not have strict binding to enum names. i'm inclined to use this functionality here.",0,0.9122732281684875
275593431,6363,kkonstantine,2019-04-16T00:41:13Z,javadoc fixed with reference to `null`,0,0.9930499792098999
275593446,6363,kkonstantine,2019-04-16T00:41:19Z,javadoc fixed with reference to `null`,0,0.9930499792098999
275893903,6363,mumrah,2019-04-16T16:46:38Z,does connect use the `time` utility class? my understanding is that it makes instrumenting time-based logic easier in the test code.,0,0.9922295212745667
275900247,6363,mumrah,2019-04-16T17:02:14Z,"i was wondering about the thread safety of this assignment, but i see that calls to this method are protected by upstream synchronization in abstractcoordinator. maybe we should include a note about thread safety in the class javadoc?",0,0.9676580429077148
275903378,6363,mumrah,2019-04-16T17:10:05Z,"maybe consider exposing only what is needed from workercoordinator rather than depending on the whole class here? instead, you could pass in a clusterconfigstate supplier and a leaderstate consumer. this would also make unit testing this method more straightforward. just a thought.",0,0.9901644587516785
275904303,6363,mumrah,2019-04-16T17:12:29Z,"how is error handling done for this method? it mutates its own state (previousassignment) as well as the workercoordinator. if we fail half way through the assignment procedure, how do we ensure a valid overall state?",0,0.9876573085784912
275905898,6363,mumrah,2019-04-16T17:16:39Z,why the explicit check for log level here?,0,0.9789507985115051
275908713,6363,mumrah,2019-04-16T17:23:57Z,"nit: a method reference can be used here e.g., `foreach(workerload::assign)`",0,0.993650496006012
275912009,6363,mumrah,2019-04-16T17:32:06Z,why iterator here instead of stream?,0,0.9897065162658691
275944942,6363,kkonstantine,2019-04-16T18:54:49Z,"we seem to follow this pattern in other enums elsewhere too, so i'm more inclined to keep it the same here too. i agree with your point. but also the footprint of a hashmap here is not an issue too i'd say. thus this is more stylistic than anything else i believe. wdyt?",1,0.8109350204467773
275945434,6363,kkonstantine,2019-04-16T18:56:08Z,"yes, i'm a big proponent of mocking time and `time` util specifically. i missed its use here. will add!",1,0.7394634485244751
275946661,6363,kkonstantine,2019-04-16T18:59:28Z,good point. in general we don't assume multi-threading for the code that is run by the herder and this has simplified things. i'll add a mention,1,0.9426934123039246
275953129,6363,kkonstantine,2019-04-16T19:18:02Z,to avoid the `foreach` loop if the log level is not at least debug (the methods called on `wl` don't compute anything indeed),0,0.9850664138793945
275955774,6363,kkonstantine,2019-04-16T19:25:52Z,"the `numtorevoke` that is used to exit the `for` loops (potentially early) is not effectively final. i could work around it, but i'm not sure the result would be more readable.",0,0.9441482424736023
275956315,6363,kkonstantine,2019-04-16T19:27:18Z,til. thanks!,1,0.9860846996307373
276076567,6363,kkonstantine,2019-04-17T04:39:04Z,added guard in the constructor,0,0.9807517528533936
276076869,6363,kkonstantine,2019-04-17T04:41:28Z,done,0,0.8974218964576721
276079316,6363,kkonstantine,2019-04-17T04:58:31Z,done,0,0.8974218964576721
276861923,6363,rayokota,2019-04-18T23:04:07Z,perhaps either 1) add `equals` and `hashcode` to `connectassignment` or 2) add a comment here stating that the `equals` method is relying on reference equality since `equals` is not overridden in `connectassignment`. wdyt?,0,0.9949342608451843
277123841,6363,kkonstantine,2019-04-20T04:49:03Z,"sure! added a comment for now, and i'll revisit method implementation if we need it for general comparisons between assignments (i don't see a reason yet).",0,0.8591746687889099
277124243,6363,kkonstantine,2019-04-20T05:14:41Z,done,0,0.8974218964576721
277799701,6363,kkonstantine,2019-04-23T17:54:02Z,"the changes to the enum that reflect the latest kip version have been pushed. again, using ""default"" is required in order to be backwards compatible and support older workers.",0,0.9940497875213623
277800822,6363,kkonstantine,2019-04-23T17:56:56Z,"again, i'd prefer to support both: `eager` and `eager` as well as `compatible` and `compatible`. are we ok with that?",0,0.9917450547218323
277933842,6363,ewencp,2019-04-24T02:14:52Z,"why this particular setup with a new class? the naming seems like it's going to be confusing since there's no obvious differentiation in naming. its been awhile since i looked at the code, but i think the general pattern expected (from both `consumerprotocol` and `connectprotocol` when we generalized) is that we'd maintain the different version schemas alongside each other, much as we do for lower level message types (e.g. check what `metadatarequest` code looks like). this means we have mostly reuse and just a bit of delta for various parsing/serialization since lots of the code overlaps. at a minimum, i'd suggest renaming this class to something clearly tied to the updated code, whether similar to the `incrementalcooperativeconnectprotocol` class or some variant that is perhaps more general that would apply even with further extensions.",0,0.8864024877548218
277934191,6363,ewencp,2019-04-24T02:17:07Z,"currently with only 1 version we just do validation inline, but given this is common state between this class and the base class, why not make it a field and any necessary accessors on the base class? seems like ideally this class would only add new fields that are truly unique to it (and lack of stored state in one case vs the other seems weird).",-1,0.7076748609542847
277938290,6363,ewencp,2019-04-24T02:45:57Z,"at some length of fields, `stringbuilder` probably makes sense. not sure how frequently we're logging this, which i assume is main use case here",0,0.9058985710144043
277939161,6363,ewencp,2019-04-24T02:52:28Z,"why do we need distinct here but not on the subsequent task list? why would there be dups here but not there? i think its fine to include this if we want to be defensive, but seems like it should be used in both cases if that's the goal.",0,0.9861083626747131
277945505,6363,ewencp,2019-04-24T03:40:16Z,these methods could validate the `key` is in the expected set to be more defensive against coding errors,0,0.991543173789978
277945625,6363,ewencp,2019-04-24T03:41:08Z,nit: you're doing a redundant lookup here after already assigning to `connectors` to do the `null` check,0,0.9649927020072937
277946373,6363,ewencp,2019-04-24T03:47:35Z,"why are we documenting v1 subscription here? it's also identical to v0, but even if it weren't, this code deals with v0, right?",0,0.9791879057884216
277946470,6363,ewencp,2019-04-24T03:48:27Z,"i guess this kind of explains my above question re: v1 docs here since this doesn't include everything for v0, but again, why re-document this here?",0,0.9615368247032166
277947459,6363,ewencp,2019-04-24T03:56:30Z,"if anything, it seems even better to just generalize to case insensitivity (which i am not a fan of in many cases, but in the context of enum configs should be harmless unless we make some pretty bad decisions). tbh, i'm not sure why elsewhere we're optimizing the string -> enum lookup unless it is in a hot path, which it doesn't seem like it should be here",0,0.5155494809150696
277947904,6363,ewencp,2019-04-24T04:00:14Z,"not sure if this was intended to apply to both connect protocol and scheduled rebalance max delay, but validator on the delay would make sense as well -- at a minimum to ensure non-negative",0,0.9899105429649353
277948672,6363,ewencp,2019-04-24T04:06:36Z,"hmm, so this is a potentially interesting change. client.id can be used for some things like quotas. since this is for workers, i'm not sure we're actually changing behavior in any interesting way here, but we should consider what the possible fallout in behavior could be by changing the default client.id behavior here.",0,0.9570289850234985
277950243,6363,ewencp,2019-04-24T04:18:49Z,"we use normal logging elsewhere in this file, i assume this is stray debugging code?",0,0.9840440154075623
278276834,6363,ewencp,2019-04-24T19:11:50Z,what's the reason for removing this? if anything i would think we should have more logging around these operations rather than less.,0,0.9633803963661194
278278502,6363,ewencp,2019-04-24T19:16:38Z,"it seems like most of the other logic around the protocol versions is cleanly factored into the protocol classes. could we refactor this logic as well, e.g. to get this from `assignment`?",0,0.9918447136878967
278371438,6363,ewencp,2019-04-25T01:29:36Z,"why are we clearing these here? i would think the key thing in this class would just be to force the rejoin when tasks are revoked and it doesn't look like we use this anywhere else in this class that this would cause a problem. is there some sharing with code elsewhere that relies on this? (and if so, could we just hand this class a copy instead?)",0,0.9856621623039246
278372255,6363,ewencp,2019-04-25T01:36:27Z,"this might be worth a comment as well, or actually even restructuring a bit. it seems confusing that the `runningassignment` after starting all the connectors and tasks would be `empty()`. i *suspect* this is being done because on the subsequent round, this forces the `assignmentdifference` to be the full set of connectors/tasks in `assignment`. but it might be more intuitive to reset `runningassignment` to `empty()` in the `onrevoked` (where they actually stop running, and given that it's just based on the parameters, it might be more implicit based on what was passed in than based on the protocol version). i *think* that also handles my above comment because the check for protocol version is no longer necessary -- it should just work out.",0,0.9810246229171753
278374311,6363,ewencp,2019-04-25T01:54:11Z,"seems like copy paste? and a bunch of the utilities would be. aside from the diff to make protected, did you consider having this inherit from eager and override the key functionality but reuse the rest (which perhaps is better structured as utilities elsewhere, but your inclination to not change the existing implementation too much seems reasonable to me at least for awhile for maintenance reasons, although even there that code hasn't changed in a long time)?",0,0.980369508266449
278732876,6363,kkonstantine,2019-04-25T21:09:29Z,"added a validation and a validator class that can allow anyone to write a validator in place. i think this is useful and will help with easy addition of validations, that currently are missing from several places. i believe this part belongs to a separate pr with a jira ticket that informs for the addition of what i called `lambdavalidator`. but before i create this i'd like to get some feedback here. wdyt ?",1,0.5675223469734192
278733160,6363,kkonstantine,2019-04-25T21:10:18Z,"given that i've added several integration tests that bring up several workers, i think it makes sense to leave this here.",0,0.9793426990509033
278741717,6363,kkonstantine,2019-04-25T21:36:44Z,"i'm using an assignment via `leaderset` to the coordinator itself though. i'm inclined to say that encapsulation makes sense for now. i feel it doesn't pose a big trade-off. i'd suggest leaving it for now, since it's an easy future refactoring.",0,0.8689406514167786
278751495,6363,kkonstantine,2019-04-25T22:12:31Z,that's a good question. we might need to reset this under certain errors. i'll get back to that.,1,0.8940629959106445
278752888,6363,ewencp,2019-04-25T22:18:41Z,this is getting a bit confusing -- this seems the same as `currentworkerassignment`. what mutates that causes this to be different?,-1,0.8130274415016174
278755759,6363,kkonstantine,2019-04-25T22:31:50Z,added a note at the class level for both `eagerassignor` and `incrementalcooperativeassignor`. we could potentially add a more detailed note such as the one in `abstractcoordinator` on locking.,0,0.9937315583229065
278758021,6363,ewencp,2019-04-25T22:42:40Z,normally `time` would be injected for testing?,0,0.9943002462387085
278765522,6363,kkonstantine,2019-04-25T23:21:58Z,i like to keep the programmatic way of defining test cases. but you are right in that the workers here won't scale significantlly. changed.,0,0.5460674166679382
278766008,6363,kkonstantine,2019-04-25T23:24:35Z,the goal of this test is to validate balanced assignment. thus asserting the size is deterministic and probably sufficient. if we agree on the scheduling algorithms additional unit tests will be added (possibly here) and in `workercoordinatorincrementaltest`,0,0.9939674139022827
278772408,6363,ewencp,2019-04-26T00:01:36Z,it feels like we're getting inconsistent with the naming. `connectassignment` and `connectprotocol.assignment` vs `incrementalcooperativeconnectprotocol.extendedworkerstate` vs `connectprotocol.workerstate`.,0,0.9071909785270691
278785956,6363,ewencp,2019-04-26T01:44:19Z,"i realize we can get the value via `protocolcompatibility.protocol()` here, but might be clearer to just be explicit anyway. definitely in this case it feels like it makes it harder to parse what's going on here (to me at least)",0,0.9788870811462402
278786168,6363,ewencp,2019-04-26T01:46:02Z,what about `cooperative` here?,0,0.9933704137802124
278786302,6363,ewencp,2019-04-26T01:47:04Z,"seems we are missing `cooperative` case here? seems like if we don't handle it here, that setting won't work and having that mode doesn't serve much purpose (even if we encourage people to just leave it in `compatible` given expected low overhead generally)",0,0.9781107902526855
278787756,6363,ewencp,2019-04-26T01:59:34Z,"would any of this be better handled by dynamic dispatch rather than switch statements (for further extensibility)? not a huge deal, but given (at least in this case) it seems like we could dispatch to one of the `[x]connectprotocol` classes, i'm wondering if it avoids switch case hell and keeps the logic for each closer to related protocols and outside of otherwise more general logic. (this admittedly could have been done initially but not nearly as valuable with just one case...)",0,0.6368111968040466
278788073,6363,ewencp,2019-04-26T02:02:07Z,"i'm still working through updated code and all the classes, but this feels a bit messy. admittedly we just dumped the `connectprotocol` here initially when we only had one type. but now it seems confusing when i use the new protocol directly vs having to switch on compatibility, etc. not sure i have a concrete suggestion yet, but i worry about the more general classes here ending up with both explicit (compat mode) and implicit (this case where we always use `incrementalcooperativeconnectprotocol`) decisions about how to handle logic of different versions. i'll think more about how we can refactor...",-1,0.9532648921012878
278788840,6363,ewencp,2019-04-26T02:08:42Z,"we should move this log *above* any actions taken, even if for some reason we only want it in this conditional instead of immediately after the deserialization. since something in onrevoked code could log, ordering of events would be confusing with this where it currently is.",0,0.9767945408821106
278789848,6363,ewencp,2019-04-26T02:17:05Z,"this approach seems interesting -- we previously had this class handle this as immutable (the entire snapshot was left unchanged or entirely replaced). do we actually need to mutate like we do here? a few lines down we do [code block] so main value here seems to be for the log statement a couple lines below. the other value in mutating things in this block seems to be for `newassignment`. but it's taking anything *left* in the old assignment and adding it to `newassignment`. but i thought in the kip we still reiterate to the member all assigned resources, so adding the old leftover ones seems redundant. shouldn't the `newassignment` already contain exactly what we want to update `assignmentsnapshot` with before we attempt any of these mutations?",0,0.9783995747566223
278790323,6363,ewencp,2019-04-26T02:21:21Z,this is another location where i wonder if we just maintain one assignor and update *it* when we see protocol version change rather than maintaining `currentconnectprotocol` and switching on it could refactor some of this logic to be more general,0,0.9844319224357605
278791412,6363,ewencp,2019-04-26T02:30:58Z,didn't notice earlier in review that we're making previously internal state mutable. seems to be used primarily by the assignors for identical logic. can we keep this internal state by pushing that logic into this class? i.e. some sort of `tryupdatesnapshot(maxoffset)`?,0,0.9931675791740417
278791963,6363,ewencp,2019-04-26T02:35:24Z,"i haven't worked through all of them, but i think at least `leaderstate()` and `currentprotocolversion()` can be private. with ^^ suggested update, i think some of the `config[x]snapshot()` methods could be as well. we should try to be conservative about what internal state we're exposing. `configstate` and `leaderstate` in particular worry me more since making that mutable by other classes makes this code a lot harder to reason about.",0,0.9165307283401489
278792696,6363,ewencp,2019-04-26T02:41:45Z,"nit: i found this terminology a bit weird. do we (or something else) use `embed` like this normally? if not using a builder pattern but wanting a static method instead of public constructor to build it (which, tbh, seems like a fine solution to me...), i would expect `build(..., ...)` or similar.",-1,0.9671042561531067
278795951,6363,ewencp,2019-04-26T03:07:44Z,appears to be unused?,0,0.9861102104187012
278796064,6363,ewencp,2019-04-26T03:08:38Z,sigh... one day this class will either disappear or become more than a mostly useless pass-through that is mostly here just for the constructor and fields...,-1,0.9703611135482788
278796757,6363,ewencp,2019-04-26T03:14:29Z,"might want to extend this comment to explain updated conditions, i.e. that in original mode all connectors and tasks are revoked, but in newer modes it may be a partial list. this is internal, so not critical, but if you're updating some of the other todo javadocs, this would be another nice improvement",0,0.8545645475387573
278798597,6363,ewencp,2019-04-26T03:28:13Z,"nit: just naming, but there's only one `clusterconfigstate` in this test... extra number not necessary",0,0.9745098352432251
278805479,6363,ewencp,2019-04-26T04:29:09Z,same question about `cooperative` enum option as before,0,0.9927248954772949
278806121,6363,ewencp,2019-04-26T04:34:43Z,"we should enable this for sure, at least at some level. they get stored in truncated logs if successful, and (as of recently) we store full logs for debugging purposes if the test fails. tbh, still not sure how we ended up in a log-free state by default -- it just results in having to turn this on manually, and if test failures are not reproducible locally and only in jenkins, this is a huge pain. in fact, i'd happily merge this as a separate pr even before this pr :) aside from performance or excessive logging, for tests there isn't much downside in ratcheting up the log level",1,0.9878458380699158
278806552,6363,ewencp,2019-04-26T04:38:52Z,"i think nm on this, pretty sure it was moved from other code. just hard to see without loading the full hidden diffs in github review",0,0.9133221507072449
278806717,6363,ewencp,2019-04-26T04:40:29Z,"primary question here is what coverage looks like. `distributedherder.java` now has paths that consider both protocol versions, but looks like these tests are only using `v0` paths. is that ok? based on herder changes, i think loc coverage may not have changed too much, but critical differences might not be well tested now?",0,0.9878764152526855
278807647,6363,ewencp,2019-04-26T04:49:36Z,are we missing other parameterizations? only have one here... `cooperative`?,0,0.9931595325469971
278807823,6363,ewencp,2019-04-26T04:51:38Z,logger or remove?,0,0.9901973009109497
278809207,6363,ewencp,2019-04-26T05:04:48Z,this is never a good sign in a test like this. what does this accomplish?,-1,0.8421391844749451
278810850,6363,ewencp,2019-04-26T05:18:23Z,"might want to highlight the `balanced` pieces below here, that's ultimately the critical bit beyond just running what we expect (which tbh, makes the most important part of these tests hard to find)",0,0.9571017026901245
278812987,6363,ewencp,2019-04-26T05:36:38Z,"just be wary that this entire loop capturing state is a bit dangerous. of course you don't expect it to happen, but it's possible there is a rebalance (unintentionally due to timeouts) and you get some inconsistent set of results wrt connector state/location. at a bare minimum, tons of repeated tests locally and many repeated tests on jenkins would be warranted here to avoid any potential flakiness, especially given ak jenkins' penchant for unexpected timing issues.",-1,0.6558251976966858
278816564,6363,ewencp,2019-04-26T06:00:17Z,this is the kind of assertion that could become flaky given incremental population of `connectors`.,0,0.9624890685081482
279022852,6363,kkonstantine,2019-04-26T16:40:18Z,"you are right, this used to be bad, but for a few java versions now, the compiler is able to substitute [a link] to `stringbuilder` on the bytecode. for this class, what i get from: `javap -c connectassignment.class | less` is: [code block] based on that i avoid `+` in loops but in constant expression as this one i keep using `+` for readability. i'm inclined to leave it here, since i'd expect this transformation will be common among java compilers but i can also hardcode `stringbuilder`. wdyt?",0,0.7219130396842957
279027503,6363,kkonstantine,2019-04-26T16:54:39Z,"chose to be on the safe side and map to what we've been doing already in `connectprotocol#asmap`: [a link] and [a link] if we feel confident to diverge on the new protocol (slightly here), i'm happy to do that.",1,0.9687022566795349
279086507,6363,kkonstantine,2019-04-26T20:04:33Z,"since we use `assert` in a few places already, i'll use `assert` here too. let me know if you had something else in mind.",0,0.9890611171722412
279086549,6363,kkonstantine,2019-04-26T20:04:40Z,done here and below,0,0.9903836846351624
279087129,6363,kkonstantine,2019-04-26T20:06:37Z,typo since this was added after v1 javadocs. however the descriptions are correct. nothing should be v1 in this class.,0,0.9918161034584045
279087208,6363,kkonstantine,2019-04-26T20:06:56Z,same typo as above. format is correct,0,0.9805716276168823
279088293,6363,kkonstantine,2019-04-26T20:11:01Z,"if i understand correctly, you are suggesting something similar to what suggested. keep case insensitivity but remove the map. i'll apply this change.",0,0.9738776087760925
279088613,6363,kkonstantine,2019-04-26T20:12:09Z,comments are not in chronological order :) i hope you find inline validations useful and we can keep this. should i submit another pr with some unit tests?,1,0.9946148991584778
279089415,6363,kkonstantine,2019-04-26T20:14:45Z,"indeed, this code is not an addition. it's moved from `workergroupmember` _as-is_ to your point, here, every time i reload i search for ""load diff"" and i load the hidden files. thankfully only 5 or 6 so far :)",1,0.9837320446968079
279100216,6363,kkonstantine,2019-04-26T20:52:48Z,got a second comment on that. changed to runtime check.,0,0.9746628403663635
279135611,6363,kkonstantine,2019-04-27T00:28:05Z,"it was moved inside `onjoinprepare`. that's because now `onrevoked` might also be called in `onjoincomplete`. but this wouldn't mean that a ""rebalance started"".",0,0.9953057169914246
279136107,6363,kkonstantine,2019-04-27T00:36:22Z,"i did inject it elsewhere, especially after 's comment. but this was somehow missed even though i thought i grepped. fixed",0,0.8510928153991699
279136319,6363,kkonstantine,2019-04-27T00:39:55Z,"you are bringing up a good point. i considered `connectassignment` more involed and worthy of factoring out to its own class, but not `workerstate`. we haven't decided what we'll do yet, but i'm more inclined to suggest `connectassignment` and `connectworkerstate` as separate classes. wdyt?",0,0.6883320808410645
279136441,6363,kkonstantine,2019-04-27T00:41:59Z,`cooperative` was removed as per the latest comments on the kip (the point was brought up by ). there's was a missed javadoc reference which i've just removed. only `eager` and `compatible` atm.,0,0.9927018880844116
279136636,6363,kkonstantine,2019-04-27T00:45:28Z,i agree,0,0.8392824530601501
279136696,6363,kkonstantine,2019-04-27T00:46:30Z,"maybe you started reviewing when it hadn't been removed. as mentioned in a comment above, `cooperative` has been removed to reflect the kip.",0,0.9948108196258545
279136963,6363,kkonstantine,2019-04-27T00:51:25Z,i thought i had a use of it :) removed now.,1,0.9958245754241943
279137024,6363,kkonstantine,2019-04-27T00:52:32Z,:) if i understand correctly this is not actionable immediately,0,0.8405019044876099
279586499,6363,kkonstantine,2019-04-30T00:33:51Z,make sense. updated!,1,0.6805877089500427
279587083,6363,kkonstantine,2019-04-30T00:38:25Z,i'm also hugely in favor of tests that don't depend on `sleep`. probably this was left here since earlier stages of manual debugging with these tests. removed from all tests. if needed the assertions will be improved.,0,0.9427419304847717
279587559,6363,kkonstantine,2019-04-30T00:41:53Z,"indeed. i'm saving this comment of yours for better verification of flakiness. given that reviews are in progress still, i haven't run integration tests in repeated mode, but i'll definitely do so before merging and will tighten the assertions if needed.",0,0.9455476999282837
279587997,6363,kkonstantine,2019-04-30T00:45:04Z,maybe you are referring to the assertion for imbalanced assignment? because the assignment being unique should be a strong deterministic requirement. but i agree with a holistic review of the assertions here.,0,0.9824514985084534
279588163,6363,kkonstantine,2019-04-30T00:46:18Z,fixed!,0,0.7785738706588745
279588578,6363,kkonstantine,2019-04-30T00:49:31Z,"indeed, the unit testing gaps currently are found here here and in `workercoordinatorincrementaltest`. these will be filled asap. but wanted to first get a round of reviews on the protocol, because these tests will pin the checks on the proposed functionality tbh (as opposed to integration tests for example). definitely a known gap atm.",0,0.9890646934509277
279588748,6363,kkonstantine,2019-04-30T00:50:41Z,"so, `cooperative` was removed, but i left the parameterization just in case we go back and for between `eager` and `compatible` still here (or the original `workercoordinatortest`). i might as well remove it if not.",0,0.9941585063934326
279588838,6363,kkonstantine,2019-04-30T00:51:20Z,debugging leftover probably.,0,0.8469335436820984
279589061,6363,kkonstantine,2019-04-30T00:53:14Z,"as mentioned above, `cooperative` was removed. left, in case some common tests are covered by both (although the assertions might be affected - hence the 1 failure i've left hanging around still so we don't have the impression that we are done with those unit tests).",0,0.9890081882476807
279589343,6363,kkonstantine,2019-04-30T00:55:29Z,"removed, thanks!",1,0.975879430770874
279590175,6363,kkonstantine,2019-04-30T01:02:09Z,"totally agree too. this is indeed weird given that the two commits that refer to this file, don't show evidence of when this change happened. i'll submit another pr that can backported. thanks!",1,0.9293137788772583
280291175,6363,rhauch,2019-05-02T05:20:11Z,"okay, that makes sense. but it might be nice to denote that requirement with a short comment.",0,0.906955361366272
280291571,6363,rhauch,2019-05-02T05:24:51Z,i agree with (on a [a link] that a validator on the scheduled rebalance max delay is probably pretty beneficial to ensure non-negative values.,0,0.8804782032966614
280292191,6363,rhauch,2019-05-02T05:30:53Z,+1,0,0.7702900171279907
280292897,6363,rhauch,2019-05-02T05:36:54Z,"wouldn't it be helpful here to have more debug or trace logs in this method? i worry that without them, it's going to be hard to track what this logic is doing. it may makes sense to refactor a bit to have a single return preceded by a log message, rather than having multiple log messages for each of the returns.",0,0.5091460347175598
280292977,6363,rhauch,2019-05-02T05:37:44Z,same comment hear about adding more debug/trace logging for most of the branches.,0,0.9838287830352783
280294446,6363,rhauch,2019-05-02T05:51:26Z,"and given ewen's [a link], if `completeworkerassignment` is not different than `currentworkerassignment`, then will `connectorassignments` be any different than before, and `taskassignments` be any different than before?",0,0.9949619770050049
280294974,6363,rhauch,2019-05-02T05:56:18Z,"it'd be really great to have unit tests for many of these methods. the `performtaskassignment(...)` method is already pretty lengthy, and there are just a few unit tests whereas there seem to be lots of permutations and branches. not only would they help with confidence, but they'd help with regression testing if/when we have to get back into this code.",0,0.8473914861679077
280295034,6363,rhauch,2019-05-02T05:56:45Z,ping,0,0.9308286309242249
280295298,6363,rhauch,2019-05-02T05:58:58Z,"right, but everything in the for loop starting on line 335 (except for the return on line 347) is dealing with debug logging, right? if so, then line 336 could be moved into this debug-only block.",0,0.9906855225563049
280295967,6363,rhauch,2019-05-02T06:04:40Z,isn't it possible that some of these are 0 due to integer division truncating? seems like all 4 of these lines could be replaced with something like: [code block],0,0.9903008937835693
280296761,6363,rhauch,2019-05-02T06:10:52Z,"+1. the value of logging in this whole class is not really going to be knowing the final end state, but being able to track the logic in this class to figure out why the end state doesn't match an expected state on some user's connect cluster, and hopefully being able to learn enough to understand what paths are taken so that we can reproduce the case. the other approach is to log all of the initial state up front and all of the new state at the end, such that with that information we could reproduce any logged scenario with a unit test that we can then debug to trace the logic.",0,0.9803192019462585
280296881,6363,rhauch,2019-05-02T06:11:51Z,ping,0,0.9308286309242249
280297070,6363,rhauch,2019-05-02T06:13:38Z,i think it'd be useful to have just one style of javadoc.,0,0.9663335084915161
280297285,6363,rhauch,2019-05-02T06:15:29Z,+1 on the separate classes.,0,0.9250925779342651
280297897,6363,rhauch,2019-05-02T06:20:00Z,"right, and that would be easier to unit test, too.",0,0.9650761485099792
283517005,6363,kkonstantine,2019-05-13T20:15:26Z,"as mentioned this was an insightful observation. returning to this after i added several tests on the assignor code. we have the following two cases: 1) the assignment is computed by the assignor, it contains only revocations and it fails to be delivered. in the next round of rebalancing this failure to change the state of revoked tasks is detected by the assignor, and instead of skipping revocation according to its policy that mandates that there's no consecutive revocations, it re-applies revocation of tasks. this should happen until the assignment containing the revoked tasks succeeds. 2) the assignment is computed by the assignor, it contains only assignments and it fails to be delivered. distinguishing this case from the case that active assignments are detected as lost, would result in a more complicated logic of the assignor's state machine. instead of doing that, the current code, selects to interpret the failed assignment as referring to lost tasks and therefore it enters the deferred rebalancing period, with the specified delay. i believe this keeps things simpler. in a sense whether a worker goes down, or an assignment fails to be delivered, are both considered failures that takes us to the deferred rebalancing logic. the current unit tests currently confirm this behavior. wdyt ?",0,0.9398141503334045
283518084,6363,kkonstantine,2019-05-13T20:18:05Z,"my rule of thumb is that i include in a if statement only the debug statements that would result in eager (and potential wasteful) computation of print arguments. the rest of the debug logging is kept outside the if branch, which will allow us to remove the if branch altogether if the line that requires it is removed. otherwise, we risk keeping redundant `if`s around.",0,0.9767376780509949
283528795,6363,kkonstantine,2019-05-13T20:44:26Z,"this test class, now called `incrementalcooperativeassignortest` has been significantly extended to include a big set of tests for the new assignor. resolving this comment and will follow up on other test additions.",0,0.9893051385879517
283529644,6363,kkonstantine,2019-05-13T20:46:37Z,changed to an explicit call to `compatible.protocol()`. resolving this comment. thanks,1,0.890778124332428
283530355,6363,mumrah,2019-05-13T20:48:19Z,i think that sounds reasonable. thanks for the follow-up !,1,0.9680482745170593
283530780,6363,kkonstantine,2019-05-13T20:49:28Z,`sleep` statements have been removed.,0,0.9916799664497375
283553403,6363,kkonstantine,2019-05-13T21:54:32Z,fixed,0,0.9281549453735352
283555350,6363,kkonstantine,2019-05-13T22:00:53Z,removed,0,0.9801433682441711
283557138,6363,kkonstantine,2019-05-13T22:07:18Z,i see your point. when i initially imported this comment _as-is_ i considered it non-javadoc comment and then i added javadoc. upgraded as javadoc now.,0,0.9451779127120972
283557471,6363,kkonstantine,2019-05-13T22:08:34Z,fixed. `stream` is used now instead of a static map.,0,0.9929530024528503
283558392,6363,kkonstantine,2019-05-13T22:11:56Z,"given the generated bytecode, i'll keep the current form of `tostring` if you don't mind. resolving here, but feel free to comment if you feel otherwise.",0,0.9810197949409485
283562360,6363,kkonstantine,2019-05-13T22:27:52Z,"added `between(0, integer.max_value)`",0,0.9921610951423645
284026277,6363,rhauch,2019-05-14T22:34:22Z,"i see what ewen is suggesting - it definitely could be confusing. concretely, at a minimum, rename `connectassignment` -> `incrementalcooperativeassignment` to tie it more closely with the `incrementalcooperativeconnectprotocol`. (even if we think it *might* be useful in a future protocol, we can refactor if/when that happens.) the design in this pr doesn't follow the `consumerprotocol` and `consumerassignor` model too closely. there, the assignor methods dealt with `subscription` and `assignment` types, and so those were defined in the `consumerassigner` class. the `consumerprotocol` just serialized those types. in the current design, the `connectassignor` doesn't deal with the `assignment` and `workerstate` types, and so defining those types in the `connectassignor` class doesn't make much sense. instead, the different `connectassignor` subclasses use their respective protocol in their implementation of `performassignment(...)`. given this difference, i suggest that we simply rename all of the classes that go with the incremental cooperative protocol / assignor to begin with `incrementalcooperative`.",0,0.9762639999389648
284026633,6363,rhauch,2019-05-14T22:35:33Z,+1,0,0.7702900171279907
284035771,6363,rhauch,2019-05-14T23:15:43Z,"when a user has this in their logs, what do they do? maybe add a bit more detail to this log message that lets them know what action they could/should perform, if any. when would the member configs be empty?",0,0.9921683669090271
284037825,6363,rhauch,2019-05-14T23:25:06Z,thoughts on this now that you've been running this a while in tests and in soak?,0,0.9658150672912598
284066405,6363,rhauch,2019-05-15T02:25:31Z,"is there _any_ chance we might have `totalworkersnum` might be 0, resulting in termination of the worker?",0,0.9910452961921692
284067290,6363,rhauch,2019-05-15T02:31:49Z,"`connectorsandtasks.embed(new arraylist<>(), new arraylist<>())` is called 5 places in non-test code. wdyt about adding a `connectorsandtasks.create()` method to reduce the code a bit?",0,0.990588903427124
284067493,6363,rhauch,2019-05-15T02:33:14Z,"if you believe debug logging is sufficient at this point to be able to track behavior based only on logs, then go ahead and resolve this conversation. if not, maybe consider adding more in key places.",0,0.9902291297912598
284067892,6363,kkonstantine,2019-05-15T02:35:47Z,"actually, the current form, that prints each assignment set separately has been working out nicely in the logs even with lots of connectors. what i think is key, is to use `assignments: ` suffix (or similar) in the end. this way you can grep/collect these lines all together focusing on the logger of this class as well (either via log4j or again by grepping). the fact that these assignments (every set) are printed in a separate line makes the lineage of the assignment process easy to follow. i'll review their final message but again, i'm inclined to retain a common substring and have each one in their own line. rebalancing is happening in certain moments, so there's no significant issue with verbosity here.",0,0.9523613452911377
284068513,6363,rhauch,2019-05-15T02:39:42Z,these methods will sort `completeworkerassignment` -- is that worth a comment above these two lines?,0,0.9931603670120239
284068845,6363,rhauch,2019-05-15T02:42:03Z,i guess i'm a bit surprised that this method modifies `workerassignments`. maybe mention in the `` description here and in `assignconnectors(...)`?,0,0.7368402481079102
284069392,6363,rhauch,2019-05-15T02:45:59Z,"these assign methods are pretty boilerplate, with i think just 2 lines in each that is distinct (the log line and the worker.assign call). did you consider pulling into a method and supplying a bi-function that takes the connectortaskid and the worker?",0,0.9082565307617188
284069861,6363,kkonstantine,2019-05-15T02:49:38Z,it's mutated by: [code block] i see your point and we might be able to consolidate. but i feel that this is higher risk low value optimization at this point. i'm more inclined to leave a comment for a future refactoring.,0,0.9411557912826538
284070224,6363,rhauch,2019-05-15T02:52:11Z,"one thing that would be nice to have: what are the characteristics of the parameters and returned map? for example, is it possible that the returned map contain null `bytebuffer` reference, and if so what does that mean?",0,0.9795684814453125
284070727,6363,rhauch,2019-05-15T02:55:39Z,"but at least on the first line of this method, wouldn't it make sense to use an `connectassignment.isempty()` method here, rather than relying upon instance equality? same behavior, but that would seem less brittle.",0,0.9909370541572571
284071019,6363,rhauch,2019-05-15T02:57:18Z,"i added a comment regarding this regarding the `connectassignor.performassignment(...)` method's javadoc. iiuc, it's possible that the returned `map ` can contain a null byte buffer reference. is null allowed / handled everywhere this method (and others) are used?",0,0.9951045513153076
284071662,6363,rhauch,2019-05-15T03:01:55Z,though wouldn't it be helpful to have the names of the classes related to the incremental protocol all start with `incrementalcooperative`? this is related to my earlier comment (previous review).,0,0.9937396049499512
284072023,6363,rhauch,2019-05-15T03:04:32Z,+1,0,0.7702900171279907
284072326,6363,kkonstantine,2019-05-15T03:06:58Z,these are now specifically tested in `incrementalcooperativeassignortest` alone and as part of the tests cases for `performtaskassignment`. also tested in `workercoordinatorincrementaltest`,0,0.9944340586662292
284072920,6363,rhauch,2019-05-15T03:10:59Z,"we're starting 4 connectors, so should we check that all 4 are running?",0,0.9926774501800537
284072977,6363,rhauch,2019-05-15T03:11:28Z,"we're starting 4 connectors, so should we check that all 4 are running?",0,0.9926774501800537
284073066,6363,rhauch,2019-05-15T03:12:15Z,", can you provide an update?",0,0.9918193817138672
284073384,6363,rhauch,2019-05-15T03:14:30Z,can you provide an update?,0,0.9916853904724121
284074000,6363,rhauch,2019-05-15T03:18:48Z,what is the status of these tests that are commented out?,0,0.9883534908294678
284365134,6363,kkonstantine,2019-05-15T17:22:13Z,"indeed, when a `joingroupresponse` is received with no errors (`errors.none` in errors field) the response will have at least the leader itself as a member. removed this warning because it's a no-op.",0,0.994178056716919
284366320,6363,kkonstantine,2019-05-15T17:25:18Z,"true. i'd like as part of this pr to apply minimal or no changes to v0 (now eager) protocol. also, as opposed to `connectprotocol` the overlap between the two assignor implementations is quite small, so i think subclassing is not worth it here. i suggest we consider a refactoring (including any helper methods in utils classes) in a subsequent iteration/cleanup.",0,0.9726309180259705
284366792,6363,kkonstantine,2019-05-15T17:26:35Z,good point. moved to builder pattern,1,0.8569678664207458
284367865,6363,kkonstantine,2019-05-15T17:29:02Z,we need the aggregated result of the assignment and creating a new list that we return as a result doesn't worth it i think. i'll update the javadoc to make it more clear. the signature of the method without a return type should also be a hint.,0,0.9811386466026306
284370260,6363,kkonstantine,2019-05-15T17:34:35Z,i see your point. but given that currently we provide only reference equality i wouldn't like to hide this fact within an `isempty` method that would implement this reference equality check. i wouldn't like this to be confused with an assignment that it just has no assigned or revoked resources at the moment.,-1,0.7703136801719666
284374327,6363,kkonstantine,2019-05-15T17:45:05Z,fixed and improved all the logs in this method,0,0.9556625485420227
284375015,6363,kkonstantine,2019-05-15T17:46:44Z,fixed by introducing builders for both inner classes here.,0,0.9900571703910828
284375778,6363,kkonstantine,2019-05-15T17:48:22Z,"this remains the case. but for reasons of symmetry with `connectorsandtasks` which is similar i'm inclined to retain this for now, if that's ok.",0,0.9680348634719849
284381964,6363,kkonstantine,2019-05-15T18:02:28Z,i'll add a temp edit to `jenkins.sh` and will run the connect tests (unit and integration) in repeat today. locally i have not noticed flakiness after several runs.,0,0.9858551621437073
284388778,6363,kkonstantine,2019-05-15T18:19:34Z,leftovers of an early import of tests. removed.,0,0.9837589263916016
284539491,6363,kkonstantine,2019-05-16T05:00:16Z,"as discussed briefly offline, the new classes are now both separate public classes and are called `extendedassignment` and `extendedworkerstate`. one of the primary intentions is to leave the current protocol version (v0) with minimal changes. a subsequent refactoring in one of the next version could consolidate the two classes (maybe with a better name).",0,0.9946305751800537
284539787,6363,kkonstantine,2019-05-16T05:02:43Z,"dynamic dispatch is not very easy or elegant here, because the protocol classes are effectively static classes (have only static methods) and we can't hold on to a reference on their instance and use inheritance effectively. i've moved the creation of `joingrouprequestprotocolcollection` in the protocols though, and now the `switch` block (which i also dislike compared to dynamic dispatch) is small.",-1,0.7474209070205688
284541423,6363,kkonstantine,2019-05-16T05:14:14Z,the above pr is merged. i removed this temp commit. thanks for reviewing!,1,0.9930257797241211
284542971,6363,kkonstantine,2019-05-16T05:25:34Z,"as mentioned in another thread, the classes are now named `extendedassignment` and `extendedworkerstate` respectively",0,0.9944392442703247
284544064,6363,kkonstantine,2019-05-16T05:32:48Z,i have now added tests related to the new rebalancing protocol in this class too. (also the worker coordinator tests as well).,0,0.9890080690383911
284834540,6363,kkonstantine,2019-05-16T18:13:23Z,added: ` // we have at least one worker assignment (the leader itself) so totalworkersnum can't be 0`,0,0.9855350255966187
284834759,6363,kkonstantine,2019-05-16T18:13:54Z,same reason why we removed a warning about empty `memberconfigs` above,0,0.9940398931503296
284835203,6363,kkonstantine,2019-05-16T18:15:00Z,this block now reads: [code block] we shouldn't mind these averages being 0. this means there's not much to revoke.,0,0.986057460308075
284843672,6363,kkonstantine,2019-05-16T18:36:05Z,added,0,0.9267084002494812
284845286,6363,kkonstantine,2019-05-16T18:39:52Z,this sorting should not matter in any decision. it does it to apply weighted round-robin internally. but the order in the list of assignments does not matter.,0,0.988860547542572
284845721,6363,kkonstantine,2019-05-16T18:40:50Z,"i've added and improved debug logs. if during additional testing we consider that some info logs are warranted, we could return here.",0,0.9788275361061096
284846327,6363,kkonstantine,2019-05-16T18:42:15Z,add clarification.,0,0.977479875087738
284846980,6363,kkonstantine,2019-05-16T18:43:45Z,i'll create a ticket for future refactoring to address this.,0,0.9849379062652588
284847996,6363,kkonstantine,2019-05-16T18:46:11Z,made `leaderstate` private. but `currentprotocolversion` is used by `workergroupmember`,0,0.994953453540802
284849064,6363,kkonstantine,2019-05-16T18:48:59Z,`null` value for the `bytebuffer` value of this map is not allowed. every member should have an assignment even if it's empty.,0,0.9912837743759155
284849278,6363,kkonstantine,2019-05-16T18:49:35Z,at this point i will clear this if needed in a subsequent cleanup/refactoring after more testing is applied.,0,0.9889175891876221
284849517,6363,kkonstantine,2019-05-16T18:50:12Z,this is also candidate for subsequent refactoring. will create a jira ticket.,0,0.9923729300498962
284849946,6363,kkonstantine,2019-05-16T18:51:18Z,"i'll leave the old method unchanged, but we can also consider enhancement during the refactoring described in other comments that will follow-up.",0,0.9900795221328735
284850119,6363,kkonstantine,2019-05-16T18:51:48Z,"also, leaving as-is since it's the old code. but will revisit",0,0.984272837638855
284850476,6363,kkonstantine,2019-05-16T18:52:51Z,at this point i will avoid the risk of optimizations and will include this in the ticket that will revisit tuning of the new rebalancing code. thanks!,1,0.9859550595283508
284853764,6363,kkonstantine,2019-05-16T19:01:54Z,i'm disabling the assertion at the moment because it results in flaky runs on jenkins. will return to it in a separate pr. thanks!,1,0.9890899062156677
284876254,6363,ryannedolan,2019-05-16T20:06:57Z,"instead of biconsumer here, and relying on exceptions to pass validation errors back to the caller, maybe this should be `(k, v) -> error`?",0,0.9937149882316589
284879355,6363,ryannedolan,2019-05-16T20:15:45Z,"would be nice to roll up this re-throw into ensurevalid(), i.e. catch the exception and format a general error message there.",0,0.9911353588104248
284879788,6363,ryannedolan,2019-05-16T20:16:54Z,it's strange to rely on runtimeexceptions for validation like this. maybe narrow to configexceptions at least.,-1,0.9129380583763123
284882011,6363,kkonstantine,2019-05-16T20:22:55Z,i think the current pattern works. i'll resolve this comment.,0,0.9087706208229065
284882177,6363,ryannedolan,2019-05-16T20:23:22Z,:party_popper:,0,0.9849576950073242
284882599,6363,kkonstantine,2019-05-16T20:24:25Z,good points. let's revisit in a follow up cleanup/refactoring since this is not critical atm.,1,0.8457828760147095
284883108,6363,kkonstantine,2019-05-16T20:25:43Z,"again here the difficulty is part due to protocol classes being effectively static. since it's not critical for the initial version of the new rebalancing, let's revisit in a follow-up.",0,0.9608500599861145
284883316,6363,kkonstantine,2019-05-16T20:26:08Z,see comment above about protocol classes being effectively static.,0,0.9896954298019409
284884565,6363,kkonstantine,2019-05-16T20:29:30Z,made `protected` and added several tests in `incrementalcooperativeassignortest`,0,0.9941326975822449
284886129,6363,ryannedolan,2019-05-16T20:33:54Z,i think this is a lot of gymnastics to avoid writing a couple `if`s and `for`s.,0,0.9414120316505432
284886324,6363,kkonstantine,2019-05-16T20:34:28Z,"since this doesn't influence the actual schemas of the protocols, i'd also suggest to punt to the next refactoring/cleanup of the protocol classes.",0,0.9908856749534607
284919786,6363,kkonstantine,2019-05-16T22:20:49Z,the current form maps exactly to `ensurevalid` in the validator interface. this addition here is minor. i'd suggest discussion any improvements on config defs in a separate pr/jira issue.,0,0.9876425266265869
284920523,6363,kkonstantine,2019-05-16T22:24:05Z,"again, this is added for convenience. it's not implementing the validation as other validators do in this class. what developers chooses to throw here, is their own responsibility, as when they implement the `validator` interface.",0,0.9922806620597839
284920787,6363,kkonstantine,2019-05-16T22:25:25Z,"not a bad idea. but at the moment, i'd suggest taking improvements on this code in a separate pr",-1,0.8419193029403687
284921328,6363,kkonstantine,2019-05-16T22:27:32Z,this is a two line lambda still and straightforward. still not in any critical path of this pr.,0,0.8868280649185181
284921479,6363,kkonstantine,2019-05-16T22:28:18Z,i've kept uniqueness requirement but have removed assertion around balancing atm.,0,0.9890472292900085
284952509,6363,kkonstantine,2019-05-17T01:34:30Z,10 successful consecutive runs of all the connect tests (including integration tests). [a link],0,0.9781479835510254
284952789,6363,kkonstantine,2019-05-17T01:36:30Z,here just confirming that they've started to go to the next phase (which is to remove a worker). not an assertion of the connectors per se. but i agree we could tighten it in a subsequent iteration.,0,0.9891996383666992
220729441,5582,rajinisivaram,2018-09-26T21:27:38Z,i remember i had `supportsclientreauth` and `supportsserverreauth` in my commit. it may be worth checking if we can have a single `supportsreauth` method and have the caller track mode.,0,0.9860427975654602
220729477,5582,rajinisivaram,2018-09-26T21:27:44Z,confusing to have `supportsclientreauth` and `clientsupportsreauthentication`. perhaps `supportsreauth` instead of `supportsclientreauth` and `remotesupportsreauth` instead of `clientsupportsreauthentication` (or something along those lines)?,0,0.9942025542259216
220730428,5582,rajinisivaram,2018-09-26T21:31:36Z,"can't all this be done in the authenticator? we can move it to some shared class later if we need it in two places, but for now we just need this in `saslclientauthenticator`?",0,0.9955925345420837
220732429,5582,rajinisivaram,2018-09-26T21:39:59Z,i thought we weren't supporting re-authentication or connection termination for ssl. why do we need time?,0,0.845666229724884
220732576,5582,rajinisivaram,2018-09-26T21:40:38Z,"as before with ssl, can we avoid tracking time unless it is actually used?",0,0.9931007623672485
220735918,5582,rajinisivaram,2018-09-26T21:54:37Z,we have to avoid invoking an extra `time.milliseconds()` for every request. actual time should get propagated from the caller.,0,0.991066038608551
220736421,5582,rajinisivaram,2018-09-26T21:56:25Z,"`kafkachannel` is a network-layer class, not a security-related class, so this should perhaps say `authenticationsession` or something like that to make it more obvious.",0,0.9939671754837036
220736573,5582,rajinisivaram,2018-09-26T21:57:12Z,why do we need this?,0,0.9448511004447937
220740223,5582,rajinisivaram,2018-09-26T22:14:17Z,"seeing it here, the metric name doesn't look right. `v0` refers to saslauthenticaterequest version. perhaps `sasl-authentication` with tag `version=0` or something similar to our request metrics which has apikey and version would be better?",0,0.9909928441047668
220740427,5582,rajinisivaram,2018-09-26T22:15:20Z,why are we tracking time here?,0,0.9707372188568115
220741020,5582,rajinisivaram,2018-09-26T22:18:09Z,should this be `session_lifetime_ms`?,0,0.9940659999847412
220741102,5582,rajinisivaram,2018-09-26T22:18:29Z,as before `sessionlifetimems`?,0,0.9940534234046936
220742581,5582,rajinisivaram,2018-09-26T22:25:48Z,"do we need to track `interestedinwritingimmediatelyafterreauthentication`? aren't we starting reauthentication during write, so this would always be true?",0,0.9946659803390503
220745052,5582,rajinisivaram,2018-09-26T22:38:53Z,the comment is now incomplete. don't we still throttle in some cases?,0,0.9145386815071106
220745279,5582,rajinisivaram,2018-09-26T22:40:03Z,this code looks totally out of place here.,-1,0.6544802188873291
220786458,5582,rondagostino,2018-09-27T03:49:07Z,":thumbs_up: i eliminated these two methods by adding `long clientsessionreauthenticationtimems()` and `long serversessionexpirationtimenanos()`. these new methods only ever return non-null on the client and server, respectively. `clientsessionreauthenticationtimems()` now contains the 85%-95% calculation that was in `kafkachannel` and you asked if it could be moved into the authenticator.",0,0.9690080881118774
220786477,5582,rondagostino,2018-09-27T03:49:21Z,:thumbs_up: i've renamed this to be `boolean connectedclientsupportsreauthentication()` which is clear and no longer is close to any other method names since i eliminated the other two that were close as described above.,0,0.9490581154823303
220786498,5582,rondagostino,2018-09-27T03:49:30Z,:thumbs_up: i moved this into `saslclientauthenticator` -- the percentage calculation is now factored into the return value of `clientsessionreauthenticationtimems()`,0,0.9439709186553955
220786511,5582,rondagostino,2018-09-27T03:49:40Z,":thumbs_up: we don't need time. i added it in order to support the `long sessionbegintimems()` method i had added to `authenticator`, but now that the percentage calculation is moved into `saslclientauthenticator` we don't need the `sessionbegintimems()` method on `authenticator` anymore. this file is now untouched.",0,0.942779004573822
220786528,5582,rondagostino,2018-09-27T03:49:47Z,":thumbs_up: agreed, same as above: i added it in order to support the `long sessionbegintimems()` method i had added to `authenticator`, but now that the percentage calculation is moved into `saslclientauthenticator` we don't need the `sessionbegintimems()` method on `authenticator` anymore. this file is now untouched.",0,0.84212726354599
220786549,5582,rondagostino,2018-09-27T03:49:59Z,:thumbs_up: i moved the server-side-kill check from `kafkaapis` to `kafkarequesthandler` and now i pass in the nanos time that was already calculated.,0,0.9612345099449158
220786564,5582,rondagostino,2018-09-27T03:50:08Z,:thumbs_up: it is now `boolean serverauthenticationsessionexpired(long nanos)`,0,0.98319411277771
220786574,5582,rondagostino,2018-09-27T03:50:12Z,":thumbs_up: we don't need this. i added it in order to support the `long sessionbegintimems()` method i had added to `authenticator`, but now that the percentage calculation is moved into `saslclientauthenticator` we don't need the `sessionbegintimems()` method on `authenticator` anymore. this file is now untouched.",0,0.9645160436630249
220786590,5582,rondagostino,2018-09-27T03:50:19Z,":thumbs_up: we don't need this. i added it in order to support the `long sessionbegintimems()` method i had added to `authenticator`, but now that the percentage calculation is moved into `saslclientauthenticator` we don't need the `sessionbegintimems()` method on `authenticator` anymore. this file is now untouched.",0,0.9645160436630249
220786604,5582,rondagostino,2018-09-27T03:50:30Z,":thumbs_up: yes, it is always true -- i removed it.",0,0.9430480003356934
220786622,5582,rondagostino,2018-09-27T03:50:40Z,":thumbs_up: i moved it to `kafkarequesthandler` which also has the side-effect of making a nanosecond time value available for the comparison, which means we can eliminate the call to `time.milliseconds()` on every request that you had flagged as problematic.",0,0.938079297542572
220789008,5582,rondagostino,2018-09-27T04:13:55Z,"i realized today that we also have to count the connections from older clients that do not send sasl_authenticate. so it might be good to not refer to ""version"" at all. maybe it is best to not refer to ""sasl"" either? how about `successful-authentication-no-reauth` as the metric name? then maybe we don't need a special tag? if we still do need a tag then maybe `reauthsupport=false` to avoid referring to ""version""?",0,0.9938550591468811
220789699,5582,rondagostino,2018-09-27T04:21:00Z,"not sure. i changed the names of the methods on `authenticator` so that we now have `serversessionexpirationtimenanos()` and `clientsessionreauthenticationtimems()`. this value is communicating the expiration time, and then the `saslclientauthenticator` applies the 85%-95% factor to get a re-authentication time. based on this, it probably shouldn't have ""reauth"" in the name since that implies the factor has been applied -- which it has not at this point. so i think yes, it should be session_lifetime_ms. do you agree? if so i will change -- just confirm or suggest otherwise.",0,0.9915869235992432
220791745,5582,rondagostino,2018-09-27T04:41:24Z,:thumbs_up: i adjusted the javadoc. let me know if it is now more accurate.,0,0.9393168091773987
220917846,5582,rondagostino,2018-09-27T13:15:36Z,"oops, the file is not untouched -- just the sections related to ssl and plaintext are untouched.",-1,0.6477612257003784
220917981,5582,rondagostino,2018-09-27T13:15:59Z,"again, oops, the file is not untouched -- just the sections related to ssl and plaintext are untouched.",0,0.709516704082489
220919003,5582,rondagostino,2018-09-27T13:19:09Z,"oops, the file is not untouched because it still needs to send in a `supplier ` rather than `authenticator` when it creates a `kafkachannel` -- but the reference to `time` is now gone.",-1,0.5201919674873352
220919332,5582,rondagostino,2018-09-27T13:20:07Z,"again, oops, the file is not untouched because it still needs to send in a `supplier ` rather than `authenticator` when it creates a `kafkachannel` -- but the reference to `time` is now gone.",0,0.9501201510429382
221238033,5582,rondagostino,2018-09-28T12:37:26Z,:thumbs_up: changing to session_lifetime_ms,0,0.9864632487297058
221238079,5582,rondagostino,2018-09-28T12:37:35Z,:thumbs_up: changing to sessionlifetimems,0,0.972111165523529
221241246,5582,rondagostino,2018-09-28T12:49:59Z,changing to `successful-authentication-no-reauth-total` without extra tags.,0,0.993707537651062
221574183,5582,rajinisivaram,2018-10-01T11:23:19Z,using a combination of nanos and millis in the reauthentication logic is very error-prone.,0,0.5726050734519958
221575447,5582,rajinisivaram,2018-10-01T11:28:04Z,propagate time since we have tests that use mocktime.,0,0.9886325001716614
221576245,5582,rajinisivaram,2018-10-01T11:31:42Z,this is either a local client connection (on a client or inter-broker connection) or a remote client connection (on a broker).,0,0.9938145875930786
221576504,5582,rajinisivaram,2018-10-01T11:32:58Z,can we move this below the `final` fields?,0,0.994193971157074
221580005,5582,rajinisivaram,2018-10-01T11:47:25Z,should this be under the `channel.successfulauthentications() == 1`? presumably a client can use v0 authenticate request and still reauthenticate.,0,0.9952677488327026
221580843,5582,rajinisivaram,2018-10-01T11:50:51Z,`responsesreceivedduringreauthentication.foreach`? also null check looks unnecessary since we guarantee it is never null?,0,0.9940810799598694
221581167,5582,rajinisivaram,2018-10-01T11:52:23Z,could just be part of the previous `if` statement?,0,0.9948970675468445
221581375,5582,rajinisivaram,2018-10-01T11:53:24Z,add `-ms` to the metric names?,0,0.9936204552650452
221581926,5582,rajinisivaram,2018-10-01T11:55:42Z,typo: `lifetime`,0,0.9909288287162781
221582659,5582,rajinisivaram,2018-10-01T11:58:42Z,need to either change the name of this constant or where it is defined. negotiated configs dont come from jaas.,0,0.9929002523422241
221583408,5582,rajinisivaram,2018-10-01T12:02:03Z,also set state to `send_handshake_request`,0,0.99226975440979
221583541,5582,rajinisivaram,2018-10-01T12:02:42Z,this check is not needed if we set initial state during reauthentication to `send_handshake_request`,0,0.9951583743095398
221583677,5582,rajinisivaram,2018-10-01T12:03:17Z,"same as before, we dont need this if initial state is set for reauthentication,",0,0.9897558093070984
221584414,5582,rajinisivaram,2018-10-01T12:06:25Z,"this should only be done for re-authentication. otherwise it will end up with tight poll loop after authentication if there is nothing to be sent. in general, we need to make sure that we don't change any behaviour for the initial authentication.",0,0.9851881265640259
221585462,5582,rajinisivaram,2018-10-01T12:10:56Z,"on the broker-side, i think we need a minimum re-authentication interval as well to restrict the rate at which clients re-authenticate. this is particularly important since we dont apply any quotas for authentication. without imposing a re-authentication rate limit, a client that enters a re-authentication loop (due to a bug or intentionally) would effectively stop the broker from doing anything useful.",0,0.9798592329025269
221587034,5582,rajinisivaram,2018-10-01T12:16:57Z,we have an exception that is going to result in the connection being closed. seems unnecessary to re-authenticate before closing connection.,-1,0.5115911364555359
221587359,5582,rajinisivaram,2018-10-01T12:18:29Z,initiaize in the constructor similar to other fields?,0,0.9942227005958557
221588748,5582,rajinisivaram,2018-10-01T12:23:34Z,"can't we set buffers to a good state from `reauthenticate()` so that this method doesn't have to do anything special for re-authentication? we have received a handshake request, we just need to continue just as with authentication?",0,0.9934304356575012
221589195,5582,rajinisivaram,2018-10-01T12:25:18Z,nit: can we reduce the length of the method name?,0,0.9893969297409058
221591025,5582,rajinisivaram,2018-10-01T12:32:01Z,"in each of the tests, we could check metrics (expired-and-killed in some tests and re-authenticated where expected)",0,0.9934622049331665
221592475,5582,rajinisivaram,2018-10-01T12:37:22Z,this results in errors logged in the broker with stack trace. i don't think we want that.,-1,0.5856225490570068
221824499,5582,rondagostino,2018-10-02T04:47:12Z,":thumbs_up: changed so that both use nanos. we need to use nanoseconds on the server side to avoid a call to time.milliseconds() on each request as per previous review comments, so i changed the client side to use nanos as well.",0,0.9857526421546936
221824522,5582,rondagostino,2018-10-02T04:47:24Z,"this class uses the time variable in multiple places already, so i simply replicated the same solution. if we wish to fix all of them then perhaps it can be resolved via a separate ticket as opposed to this kip?",0,0.9912410974502563
221824530,5582,rondagostino,2018-10-02T04:47:31Z,:thumbs_up: definitely; fixed.,0,0.6239023804664612
221824536,5582,rondagostino,2018-10-02T04:47:36Z,:thumbs_up: moved,0,0.98967045545578
221824549,5582,rondagostino,2018-10-02T04:47:46Z,"we do not record latency for authentication, which is the case where `channel.successfulauthentications() == 1 ` -- the value `channel.reauthenticationlatencyms()` will be null in that case.",0,0.9930918216705322
221824558,5582,rondagostino,2018-10-02T04:47:54Z,"converted to `.foreach`, but we do have to check for null since that is the default (javadoc says null is possible, which it is)",0,0.9940968751907349
221824568,5582,rondagostino,2018-10-02T04:48:00Z,:thumbs_up: fixed,0,0.976753830909729
221824578,5582,rondagostino,2018-10-02T04:48:06Z,"`request-latency-avg` and `request-latency-max` don't have it (neither do `commit-latency`, `poll-latency`, and `process-latency` metrics). assume this means it should remain as-is.",0,0.9940074682235718
221824588,5582,rondagostino,2018-10-02T04:48:11Z,:thumbs_up: fixed,0,0.976753830909729
221824625,5582,rondagostino,2018-10-02T04:48:16Z,:thumbs_up: created `org.apache.kafka.common.security.authenticator.saslutils` to hold this constant.,0,0.9775328040122986
221824632,5582,rondagostino,2018-10-02T04:48:23Z,:thumbs_up: i created a `process_apiversions_response` state where we process the response we got -- either from the server in the auth case or from the previous authenticator in the re-auth case. this will be the initial state when re-authenticating. i think this makes it clear what is going on.,0,0.922314465045929
221824639,5582,rondagostino,2018-10-02T04:48:29Z,:thumbs_up: removed,0,0.9899410605430603
221824664,5582,rondagostino,2018-10-02T04:48:45Z,":thumbs_up: agreed, no longer needed -- the initial state for client-side re-authentication is now `process_apiversions_response`.",0,0.9817096590995789
221824673,5582,rondagostino,2018-10-02T04:48:51Z,":thumbs_up: fixed. i think maybe the original code had kept track of whether we we needed to immediately write something or not, and perhaps it was handled there? can't remember, but regardless, it is fixed now -- we remove write interest as before when we are not in a ""re-authentication"" scenario.",0,0.8471611142158508
221824682,5582,rondagostino,2018-10-02T04:48:59Z,":thumbs_up: i defined a 1-second requirement that applies to the second and subsequent re-authentications. so the first re-authentication can happen immediately after authentication if desired, but the second re-authentication must then happen at least 1 second later (and so on), otherwise the sasl handshake is passed through without beginning the re-authentication process (and that would mean the connection is closed, which also results in the client experience the newly-implemented ddos delay). there are two reasons i set it for the second re-auth. one is is because `saslauthenticatortest` would end up running longer if we had to set the interval that much longer. the other is that we don't have a time value that we can use to set the start time until `kafkachannel.maybebeginserverreauthentication()` is invoked. i think this is reasonable -- is it okay with you?",0,0.979804277420044
221824691,5582,rondagostino,2018-10-02T04:49:06Z,"actually, my understanding of this is that we received something that had been sent prior to the re-authentication process beginning -- it doesn't match what we were expecting back, so we didn't send it, so it must have come from before -- so we have to save it so it can be processed later. does that make sense? if so, then i think this code is correct.",0,0.9784345030784607
221824708,5582,rondagostino,2018-10-02T04:49:11Z,:thumbs_up: fixed,0,0.976753830909729
221824720,5582,rondagostino,2018-10-02T04:49:20Z,":thumbs_up: good point. i split out the `processpayload()` method to address a cyclomatic complexity issue, and i did not see the simplification at that time. done.",1,0.9558932781219482
221824731,5582,rondagostino,2018-10-02T04:49:24Z,:thumbs_up: fixed,0,0.976753830909729
221824759,5582,rondagostino,2018-10-02T04:49:41Z,:thumbs_up: removed,0,0.9899410605430603
221824978,5582,rondagostino,2018-10-02T04:52:09Z,"was unable to get this working, and it is almost 1am here at this point. will look again asap.",0,0.9359214901924133
221852361,5582,rondagostino,2018-10-02T07:50:04Z,"actually, i just got it working.",0,0.9227144122123718
221980284,5582,mk6i,2018-10-02T14:43:37Z,"i am confused by what this part of this sentence, can you elaborate? [code block]",-1,0.7181935906410217
221988637,5582,rondagostino,2018-10-02T15:02:55Z,here's the quote from the kip related to this: does that clarify it?,0,0.9932587146759033
222097603,5582,rajinisivaram,2018-10-02T20:20:08Z,`listener.name.sasl_ssl.oauthbearer.connection.max.expired.ms`?,0,0.9936845898628235
222103261,5582,rajinisivaram,2018-10-02T20:38:38Z,do you mean in a different class? because `channelbuilders` didn't have `time` before this pr.,0,0.9905135631561279
222104230,5582,rajinisivaram,2018-10-02T20:41:42Z,"nit: we initialize all other instance variables in the constructor, can we do the same here? i dont think we need the initialzations, especially nulls.",0,0.9849712252616882
222105405,5582,rajinisivaram,2018-10-02T20:45:20Z,"don't think we close the connection on processing saslhandshakerequest, we simply fail the request. do we want to close the connection for this case?",0,0.9193500876426697
222106188,5582,rajinisivaram,2018-10-02T20:48:04Z,`!ready()` here is an `illegalstateexception` since we never expect to here with with an not-ready channel?,0,0.9888517260551453
222106589,5582,rajinisivaram,2018-10-02T20:49:10Z,"since this is used only as the minimum reauthentication interval, can give it a name that indicates its usage?",0,0.9934391379356384
222108202,5582,rajinisivaram,2018-10-02T20:54:05Z,we could use the same name `reauthenticationlatencyms` for the method in authenticator as well? or use `reauthenticationelapsedtimems` in both cases?,0,0.9953271150588989
222111763,5582,rajinisivaram,2018-10-02T21:05:26Z,do we really need this method - test could just create one using hard-coded params?,0,0.9891080856323242
222115747,5582,rajinisivaram,2018-10-02T21:18:41Z,"now that we dont support java 7, we can use lambdas for these conditions (and the ones below).",0,0.9928677082061768
222116790,5582,rajinisivaram,2018-10-02T21:22:30Z,is this used?,0,0.9839692115783691
222117341,5582,rajinisivaram,2018-10-02T21:24:36Z,nit: `else if`?,0,0.9918597340583801
222118885,5582,rajinisivaram,2018-10-02T21:30:08Z,these two method use names that are not consistent with the config name.,0,0.9645277857780457
222119990,5582,rajinisivaram,2018-10-02T21:34:35Z,"so many tests with these two calls, couldn't we just have additional parameters to `verifyauthenticationmetrics` that optionally verify reauthentication and no-reauth metrics?",0,0.9944827556610107
222121974,5582,rajinisivaram,2018-10-02T21:42:18Z,"as before, can we move initializations to the constructor and remove unnecessary null iniitializations?",0,0.9950141310691833
222122932,5582,rajinisivaram,2018-10-02T21:46:03Z,"yes, this code is fine.",0,0.8697172999382019
222123268,5582,rajinisivaram,2018-10-02T21:47:24Z,"same as before, null initializations unnecessary.",0,0.9847255349159241
222124202,5582,rajinisivaram,2018-10-02T21:51:04Z,can we create an inner class to store the re-authentication state? there are just too many of these relevant only for re-authentication.,0,0.9877614974975586
222125964,5582,rajinisivaram,2018-10-02T21:58:50Z,"why is this code here? `reauthenticate()` has the sasl request, so it can do this check specific to reauthentication.",0,0.9953497648239136
222127047,5582,rajinisivaram,2018-10-02T22:03:34Z,we should be able to set up the state and call `authenticate` without separating out the methods.,0,0.9943060278892517
222144498,5582,harshach,2018-10-02T23:40:10Z,"is it going to be used for sasl only if so can you make it ""sasl.connection.max.reauth.ms""",0,0.9949232935905457
222161863,5582,rondagostino,2018-10-03T01:51:29Z,i think `listener.name.sasl_ssl.oauthbearer.connections.max.reauth.ms`?,0,0.9943589568138123
222164887,5582,rondagostino,2018-10-03T02:18:47Z,"oops, sorry, you are correct. fixed.",-1,0.9911640882492065
222358775,5582,rondagostino,2018-10-03T15:33:28Z,:thumbs_up:,0,0.9771975874900818
222359402,5582,rondagostino,2018-10-03T15:35:11Z,"ah, you are correct, we fail the request in kafkaapis and the connection is nor closed. doc adjusted accordingly here.",0,0.9490054845809937
222360598,5582,rondagostino,2018-10-03T15:38:22Z,:thumbs_up: `min_reauth_interval_one_second_nanos`,0,0.9920920133590698
222361705,5582,rondagostino,2018-10-03T15:41:08Z,:thumbs_up: renamed `authenticator` method to match this one: `reauthenticationlatencyms`,0,0.9897140264511108
222390337,5582,rondagostino,2018-10-03T17:04:46Z,:thumbs_up: we now throw `illegalstateexception` if that occurs,0,0.9863365888595581
222452923,5582,rondagostino,2018-10-03T20:18:01Z,:thumbs_up: removed it.,0,0.9764297008514404
222476244,5582,rondagostino,2018-10-03T21:37:07Z,:thumbs_up: added `` annotation to `testcondition` and implemented lambdas here. did not adjust any other uses of `testcondition` anywhere else unrelated to this pr.,0,0.9600381851196289
222477179,5582,rondagostino,2018-10-03T21:41:11Z,:thumbs_up: removed. this file is no longer affected by this pr.,0,0.9789382219314575
222477623,5582,rondagostino,2018-10-03T21:42:51Z,:thumbs_up: done,0,0.9480166435241699
222478232,5582,rondagostino,2018-10-03T21:45:26Z,:thumbs_up: fixed,0,0.976753830909729
222478999,5582,rondagostino,2018-10-03T21:48:38Z,i believe there was a desire to keep our options open in this regard and not mention sasl explicitly -- thoughts?,0,0.9775068759918213
222479519,5582,rondagostino,2018-10-03T21:50:49Z,:thumbs_up: done,0,0.9480166435241699
222480744,5582,rondagostino,2018-10-03T21:55:41Z,just want to confirm that this is acceptable.,0,0.9683920741081238
222486198,5582,rondagostino,2018-10-03T22:19:53Z,":thumbs_up: done. also shortened the max session reauth ms value from 500 ms to 100 ms, which shaved 20 seconds off of the test runtime (85 seconds dropped to 65 seconds locally). i'm interested to see if this exposes any errors when run on the build farm.",0,0.6318268179893494
222500340,5582,rondagostino,2018-10-03T23:39:47Z,:thumbs_up: fixed,0,0.976753830909729
222501837,5582,rondagostino,2018-10-03T23:49:12Z,"the `reauthenticate()` method has the `networkreceive` instance. we don't parse that and extract the `saslhandshakerequest` that it contains until later in the flow, at this point in the code. is it okay to keep the changed mechanism check here, as-is?",0,0.9943335056304932
222509254,5582,rondagostino,2018-10-04T00:39:49Z,:thumbs_up: created a `private static class reauthinfo` that has three public final fields: eliminated the `private boolean reauthenticating;` field with `private reauthinfo reauthinfo;`,0,0.8840981721878052
222901371,5582,rondagostino,2018-10-05T06:19:47Z,:thumbs_up: i added a new `reauth_process_handshake` state and that is where re-authentication starts.,0,0.9759305119514465
223997295,5582,rajinisivaram,2018-10-10T09:16:02Z,"yes, since this config is used by the broker to force reauthentication using connection termination as well, there is no reason why we can't apply it for ssl as well in future. so it makes sense to keep it neutral.",0,0.9933011531829834
224002046,5582,rajinisivaram,2018-10-10T09:29:31Z,dont think we need the `mutestate` check on the server-side since we are processing a received packet when we invoke this.,0,0.9894163012504578
224005987,5582,rajinisivaram,2018-10-10T09:39:25Z,is there a reason why this is passing in `time.milliseconds` while the others don't? there is some scope to use a common time value in all of these records to avoid multiple calls to `time.milliseconds()`.,0,0.9926788806915283
224007360,5582,rajinisivaram,2018-10-10T09:42:49Z,could this just use `currenttimenanos`?,0,0.9942319989204407
224008571,5582,rajinisivaram,2018-10-10T09:46:24Z,"move this to the end of the class? we tend to have enum definitions at the start, but typically other inner classes at the end.",0,0.9917364716529846
224009396,5582,rajinisivaram,2018-10-10T09:48:26Z,just return `pendingauthenticatedreceives` and remove the check for `null` in selector?,0,0.995525062084198
224009880,5582,rajinisivaram,2018-10-10T09:49:51Z,update comment since reauth starts in the state above?,0,0.9953835606575012
224010118,5582,rajinisivaram,2018-10-10T09:50:36Z,include `reauth` in the state name?,0,0.9945367574691772
224010735,5582,rajinisivaram,2018-10-10T09:52:28Z,"isn't this the same as `initial`? from this state onwards, we could use common states? perhaps you have them separate to make it easy to fall through rather than loop back to the start of `authenticate()` when handshake response is received. if it is hard to keep a common state, it is fine to leave as-is.",0,0.9938675761222839
224012583,5582,rajinisivaram,2018-10-10T09:58:35Z,"couldn't we move all four of these (or some of these) into `reauthinfo`? we could create `reauthinfo` early on and populate reauthentication metadata into it. if we really need to separate out fields related to next reauth from the fields related to current reauth, perhaps we could have a separate class with these fields.",0,0.9945666790008545
224014312,5582,rajinisivaram,2018-10-10T10:04:18Z,move `math.min` to `saslauthenticateversion()` to avoid duplication?,0,0.9953582882881165
224017228,5582,rajinisivaram,2018-10-10T10:14:56Z,"this comment is odd because that is not quite what we would do. if we can't fall through, we would put `authenticate` in a loop to process the next state.",-1,0.8980685472488403
224017388,5582,rajinisivaram,2018-10-10T10:15:26Z,"if we need to keep `initial` and `reauth_initial`, we should have. a method to use common code for this state.",0,0.9945932030677795
224018091,5582,rajinisivaram,2018-10-10T10:17:43Z,"do we need this check at all? if it isn't, it is a bug in the implementation and we would see a classcastexception with the class names.",0,0.9752780199050903
224018434,5582,rajinisivaram,2018-10-10T10:18:55Z,"if we always stored `apiversionsresponsefromoriginalauthentication` in `reauthinfo`, we can avoid this check.",0,0.9952312111854553
224021054,5582,rajinisivaram,2018-10-10T10:28:24Z,"looks like we are getting `time.milliseconds()` just for logging. log entries contain date and time anyway, so we could just log the intervals we actually use instead of computing new ones just for logging.",0,0.991614818572998
224021468,5582,rajinisivaram,2018-10-10T10:30:00Z,nit: unnecessary `long.valueof`,0,0.9419689178466797
224023926,5582,rajinisivaram,2018-10-10T10:39:22Z,move this class to the end to be consistent with other classes?,0,0.9944315552711487
224024097,5582,rajinisivaram,2018-10-10T10:39:54Z,can we move these three fields into `reauthinfo`?,0,0.9951425790786743
224024425,5582,rajinisivaram,2018-10-10T10:41:11Z,"add checkstyle suppression instead for this file, rather than split the method with a checkstyle comment.",0,0.9940202236175537
224025199,5582,rajinisivaram,2018-10-10T10:44:19Z,"nit: this is not a `utils` class, more like `configs`?",0,0.9896277189254761
224026269,5582,rajinisivaram,2018-10-10T10:48:29Z,"nit: too many boolean params, making it hard to know what this is doing.",-1,0.9274507164955139
224027337,5582,rajinisivaram,2018-10-10T10:52:17Z,why do we need this boolean?,0,0.9756231904029846
224028035,5582,rajinisivaram,2018-10-10T10:55:07Z,i can't tell from the method name what the function returned is.,0,0.7803785800933838
224028525,5582,rajinisivaram,2018-10-10T10:56:47Z,why?,0,0.8699262738227844
224029495,5582,rajinisivaram,2018-10-10T10:59:26Z,why is this in `testutils`?,0,0.9913899302482605
224031032,5582,rajinisivaram,2018-10-10T11:05:24Z,"we are doing at least two `time.nanoseconds` calls per channel, can we get the value at the start and use it in the three usages here.",0,0.9923720359802246
224031497,5582,rajinisivaram,2018-10-10T11:07:25Z,"not sure this matches the actual implementation,",0,0.80032879114151
224033627,5582,rajinisivaram,2018-10-10T11:16:04Z,"i think parameterization was useful at the start, but not sure we want to commit that. there are several tests where this parameter is not used at all, causing the same tests to be run twice. it feels like we should add some extra reauthentication tests and perhaps update some existing tests to also verify reauthentication. i think a new test which waits for multiple reauthentications while sending and receiving data continuously is sufficient (run with sasl_plaintext and sasl_ssl). it could run with a mechanism where reauthentication latency is higher and the test could run in a loop until latency > 0 to avoid timing errors in the test. all existing tests can stay as-is and use the existing `server.verifyauthenticationmetrics()` that just checks that there are no reauthentications. a new version of that with reauthentication count as arg could check for reauthentication metrics as well. what do you think?",0,0.9826152324676514
224035834,5582,rajinisivaram,2018-10-10T11:24:51Z,do we need a boolean here? are there tests where it is guaranteed to be > 0?,0,0.9912731051445007
224041831,5582,rajinisivaram,2018-10-10T11:47:25Z,same as in saslclientauthenticator - unnecessary check since classcastexception gives all the information required in case there is a bug in the code.,0,0.9903072118759155
224042409,5582,rajinisivaram,2018-10-10T11:49:16Z,do we need this method?,0,0.9872057437896729
224042825,5582,rajinisivaram,2018-10-10T11:50:51Z,"why is this conditional, can't we always set it?",0,0.8885796666145325
224043656,5582,rajinisivaram,2018-10-10T11:53:15Z,need `ms` in the method name since it is returning millis.,0,0.9920082092285156
224044350,5582,rajinisivaram,2018-10-10T11:55:17Z,just `credentialexpirationms` is sufficient since this is not the server's credential?,0,0.9948105812072754
224045454,5582,rajinisivaram,2018-10-10T11:59:08Z,can we move this into `reauthinfo` (rename that class if required)?,0,0.994686484336853
224045546,5582,rajinisivaram,2018-10-10T11:59:27Z,"same as above, move to `reauthinfo`?",0,0.995122492313385
224045843,5582,rajinisivaram,2018-10-10T12:00:34Z,this can be in `reauthinfo` as well. and `reauthinfo` can have a method `authenticating()` or `reauthenticating()` to avoid all the checks for `null`. same for clientauthenticator as well.,0,0.9952127933502197
224162804,5582,rondagostino,2018-10-10T17:04:57Z,:thumbs_up: fixed,0,0.976753830909729
224165591,5582,rondagostino,2018-10-10T17:13:46Z,:thumbs_up: now define `long readytimems = time.milliseconds()` at the top and use that time value for all metric `record()` calls.,0,0.9908377528190613
224189017,5582,rondagostino,2018-10-10T18:20:58Z,"i don't think we can use `currenttimenanos` because it represents the time when `poll()` was invoked, and that could be as far back in time as the timeout value (i.e. a large timeout value could in theory result in `java.nio.channels.selector.select()` blocking for quite a while). if we use a time to far in the past it increases the chance of the reauth decision yielding `false` when in fact it should yield `true` -- and in that case we could end up with our connection being killed. what we can do is reuse the `channelstarttimenanos` if it is available (i.e. `channelstarttimenanos != 0 ? channelstarttimenanos : time.nanoseconds()`) since it is a very recent value. furthermore, we can delay actually getting the time as long as possible -- and therefore maybe we don't need to calculate it at all -- by making `kafkachannel` accept a `supplier ` rather than a `long`. i've made both of these changes.",0,0.9765657782554626
224209301,5582,rondagostino,2018-10-10T19:21:42Z,:thumbs_up: moved.,0,0.9877530336380005
224210770,5582,rondagostino,2018-10-10T19:26:35Z,:thumbs_up: return value is now always non-null.,0,0.9910975694656372
224211024,5582,rondagostino,2018-10-10T19:27:28Z,:thumbs_up: fixed,0,0.976753830909729
224250048,5582,rondagostino,2018-10-10T21:35:37Z,:thumbs_up: now include `reauth_` prefix for all re-authentication states.,0,0.9880850911140442
224250994,5582,rondagostino,2018-10-10T21:39:12Z,"yeah, it is a fall-through issue. will keep code as-is given that the duplicated code is only two lines: [code block] however, in light of the comment below, i will refactor this out into a common method.",0,0.9540185928344727
224252644,5582,rondagostino,2018-10-10T21:45:34Z,:thumbs_up: created `private static class authinfoforreauth` to hold all of these in one place.,0,0.9862063527107239
224270430,5582,rondagostino,2018-10-10T23:11:04Z,":thumbs_up: done, we now send in the `apiversionsresponse` instance.",0,0.7611215710639954
224271563,5582,rondagostino,2018-10-10T23:17:28Z,:thumbs_up: fixed the comment -- it now states that we won't add the loop to minimize changes.,0,0.966164231300354
224271904,5582,rondagostino,2018-10-10T23:19:29Z,:thumbs_up: added method `sendinitialtokenandsetintermediatestate()`,0,0.9778928160667419
224272371,5582,rondagostino,2018-10-10T23:22:31Z,:thumbs_up: removed.,0,0.989620566368103
224273014,5582,rondagostino,2018-10-10T23:26:45Z,`reauthinfo` will be null for the `saslclientauthenticator` instance associated with the initial authentication; that instance will have an instance of `authinfoforreauth` to hold the `apiversionsresponse` received from the broker. this check is therefore necessary under these conditions.,0,0.9945847392082214
224276026,5582,rondagostino,2018-10-10T23:46:27Z,:thumbs_up: done,0,0.9480166435241699
224276273,5582,rondagostino,2018-10-10T23:47:58Z,:thumbs_up: removed,0,0.9899410605430603
224436894,5582,rondagostino,2018-10-11T12:58:25Z,:thumbs_up: moved,0,0.98967045545578
224439886,5582,rondagostino,2018-10-11T13:07:00Z,created `private static class authinfoforreauth`,0,0.9945344924926758
224442030,5582,rondagostino,2018-10-11T13:13:28Z,:thumbs_up: done,0,0.9480166435241699
224444370,5582,rondagostino,2018-10-11T13:19:45Z,"renamed it `saslinternalconfigs` (there is already a `org.apache.kafka.common.config.saslconfigs` class, and it is part of the public api, so it is not an appropriate place to put this internal constant).",0,0.9950097799301147
224506417,5582,rondagostino,2018-10-11T15:57:43Z,":thumbs_up: created `public enum metrictype` and the method `public void waitformetrics(string nameprefix, final double expectedvalue, set metrictypes)`. this method now looks like this: [code block]",0,0.9843789935112
224508051,5582,rondagostino,2018-10-11T16:02:15Z,":thumbs_up: this is now removed, and the expected/actual values are now included as part of the assertion error message.",0,0.9746165871620178
224509330,5582,rondagostino,2018-10-11T16:05:44Z,":thumbs_up: true that it is not really reusable; `nioechoserver` needs that functionality, so now it's a `private static boolean` method on that class rather than a `public static boolean` method on `testutils`.",0,0.9690831899642944
224514170,5582,rondagostino,2018-10-11T16:20:30Z,"the above change resulted in a disallowed import error, so i refactored out the following method and put it back into `testutils`. this is better than having the whole `maybebeginserverreauthentication()` method there. [code block]",0,0.9938068389892578
224523568,5582,rondagostino,2018-10-11T16:49:37Z,"good question! there was a comment above that method that stated: [code block] i didn't think about it much; i just read that comment and figured that since i'm making a change to `saslauthenticaterequest` and `saslauthenticateresponse` and they don't contain a `hashmap` i could -- and should -- test for equality and hashcode. but now that you ask, and i do spend the time to think about it, it seems that testing equality and hashcode doesn't provide the value i thought it would (and that the comment seemed to imply that it would except for the annoying tendency of a hashmap to screw up the results)! all we would be testing for is to make sure the result of serializing a request to a `struct` can be deserialized back to a request and then serialized again to an equivalent `struct`. in other words, it doesn't actually test that the serialization code (i.e. `saslauthenticateresponse.tostruct()`) is working perfectly -- the equality and hashcode tests will still succeed even if that code serializes a field incorrectly because the same field will be serialized incorrectly both times (for example). note that incorrect serialization would presumably be caught indirectly via failure of other unit or integration tests. what maybe has to change here is the original comment. should i adjusted it?",1,0.9436400532722473
224526490,5582,rondagostino,2018-10-11T16:59:07Z,"ok, it's now just a single call to `time.nanoseconds()` under all circumstances except for when `sasl_handshake_request` is sent and either 1) re-authentication is not enabled; or 2) re-authentication is enabled but it occurred less than a second ago. in these two cases `time.nanoseconds()` will be invoked twice, but it probably doesn't matter since this is a rare occurrence and we are going to send an error back to the client if/when it happens.",0,0.9921888113021851
224600485,5582,rondagostino,2018-10-11T20:52:28Z,"fixed. there is now a processor-level metric `expired-connections-killed-count` that tracks the value on a per-(listener,processor) basis as well as an aggregated sum of these to provide a broker-wide metric. the aggregated sum metric is called `expiredconnectionskilledcount`. the `ops.html` doc is also updated to reflect this.",0,0.9930927753448486
224643320,5582,rondagostino,2018-10-12T00:36:27Z,:thumbs_up: removed,0,0.9899410605430603
224643550,5582,rondagostino,2018-10-12T00:38:09Z,no -- removed.,0,0.9656237363815308
224644898,5582,rondagostino,2018-10-12T00:49:37Z,:thumbs_up: changed.,0,0.9869951605796814
224645195,5582,rondagostino,2018-10-12T00:52:07Z,:thumbs_up: renamed,0,0.9868964552879333
224645547,5582,rondagostino,2018-10-12T00:54:51Z,:thumbs_up: moved,0,0.98967045545578
224645875,5582,rondagostino,2018-10-12T00:57:22Z,:thumbs_up: moved,0,0.98967045545578
224646884,5582,rondagostino,2018-10-12T01:06:23Z,:thumbs_up: i moved `authenticationorreauthenticationtext()` into `authinfoforreauth` and added a `private boolean reauthenticating()` method to `saslserverauthenticator`.,0,0.9829718470573425
224647371,5582,rondagostino,2018-10-12T01:11:20Z,did the same thing for `saslclientauthenticator`.,0,0.993596076965332
224650731,5582,rondagostino,2018-10-12T01:42:13Z,"actually, after seeing some other review comments, i decided to do what you said: there is now a `reauthinfo` class only -- no additional `authinfoforreauth` class -- and we add the re-authentication data to it.",0,0.9824620485305786
224652056,5582,rondagostino,2018-10-12T01:53:43Z,now that i decided to get rid of the `authinfoforreauth` the code looks like this: [code block],0,0.9935157299041748
224652317,5582,rondagostino,2018-10-12T01:56:07Z,i decided to get rid of `authinfoforreauth` and keep everything in a single `reauthinfo` instance as you originally suggested.,0,0.991848349571228
224888052,5582,rondagostino,2018-10-12T19:09:14Z,"the client sends multiple `sasl_authenticate` requests, and i was thinking the client is known to support the latest version if it sends at least one of them with the required version. i realize it is unlikely to send different versions each time, but technically if it sends the required version just once then we know it supports that version. so i was trying to take that (admittedly rare) possibility into account. another way to do it would be: [code block] i figured the way i did it was better than that since it avoids the write when the value is already true. i can always set it if you feel that is more appropriate -- just let me know, otherwise i'll leave it as-is.",0,0.880270779132843
224890138,5582,rondagostino,2018-10-12T19:17:38Z,"sasl plain authenticates so quickly in the test case that the latency is 0, so if i check to make sure there is a non-zero latency in that case the test fails. i know you have a comment below about adjusting the unit tests to not be so wasteful. i may be able to get rid of this as i do that.",0,0.9580987691879272
224907777,5582,rondagostino,2018-10-12T20:34:55Z,"in the meantime, i added a comment describing the reasoning.",0,0.9851793646812439
225389120,5582,rondagostino,2018-10-16T03:52:30Z,"i eliminated this problem by always recording a latency of at least 1 ms when there is a non-zero latency to record. so now 100,000 nanoseconds of latency is recorded as 1 ms, for example.",0,0.9914807081222534
225389599,5582,rondagostino,2018-10-16T03:56:59Z,i just added a new `reauth_bad_mechanism` state on the `saslserverauthenticator` because a change in the mechanism wasn't being recorded as a failed re-authentication in the metrics. now it is being recorded correctly.,0,0.9949904084205627
225389740,5582,rondagostino,2018-10-16T03:58:28Z,resolved. i now record a latency of at least 1 ms when there is any non-zero latency.,0,0.988650918006897
225389970,5582,rondagostino,2018-10-16T04:00:32Z,"latest commit attempts to resolve this. all mechanisms include at least 1 re-authentication test. there is a multiple mechanism re-authentication test; there are tests for changing the principal, changing the mechanism, and re-authenticating too fast; and there is a test that continually sends data over the connection until the number of re-authentications is 5.",0,0.986997127532959
227157687,5582,rajinisivaram,2018-10-22T22:16:49Z,do we need these two fields `clientsessionreauthenticationtimenanos` and `serversessionexpirationtimenanos`? couldn't we just use `authenticator.clientsessionreauthenticationtimenanos()` and `authenticator.serversessionexpirationtimenanos()`?,0,0.9944518208503723
227158301,5582,rajinisivaram,2018-10-22T22:19:31Z,reword exception message since channel is not ready on receiving first handshake?,0,0.9856751561164856
227159398,5582,rajinisivaram,2018-10-22T22:24:42Z,can we move this into `authenticator`?,0,0.9941508173942566
227159491,5582,rajinisivaram,2018-10-22T22:25:04Z,can we move this into `authenticator`?,0,0.9941508173942566
227160254,5582,rajinisivaram,2018-10-22T22:28:35Z,"there are so many methods in kafkachannel that simply call a method in `authenticator`. i wonder if it would be better to add an `authenticator()` method and let callers directly use `authenticator`, reducing the amount of code in `kafkachannel`.",0,0.9903226494789124
227162913,5582,rajinisivaram,2018-10-22T22:40:48Z,not sure why this needs to be a suppiler of time rather than the value itself. the code would be more readable with just a value.,0,0.9600161910057068
227164081,5582,rajinisivaram,2018-10-22T22:46:25Z,"this no longer reflects the sequence of states, so it will be good to add javadoc for `saslstate` showing the two sequences for initial auth and reauth. i would probably move the reauth states to the end so that initial flows through to complete.",0,0.9911208748817444
227164773,5582,rajinisivaram,2018-10-22T22:49:51Z,leave `setsaslstate(saslstate.intermediate)` here similar to other cases?,0,0.9957166314125061
227165780,5582,rajinisivaram,2018-10-22T22:54:21Z,"as with client `saslstate`, since states don't flow through, we should have comment for `saslstate` showing the two sequences for initial auth and reauth. again, i would move reauth to the end so that `initial_request` flows through to `complete`.",0,0.9947368502616882
227166408,5582,rajinisivaram,2018-10-22T22:57:10Z,not sure we need this state. we can set state to failed and throw the appropriate exception.,0,0.8735367059707642
227168000,5582,rajinisivaram,2018-10-22T23:04:47Z,"looking at just this code, it looks like we record this for auth and reauth, even though it actually happens only once as expected. it would be more readable to move this code under the `if (channel.successfulauthentications() == 1)`.",0,0.9907357096672058
227168301,5582,rajinisivaram,2018-10-22T23:06:23Z,why can't we just throw `saslauthenticationexception` here?,0,0.9913671612739563
227168794,5582,rajinisivaram,2018-10-22T23:09:04Z,not used?,0,0.9285135269165039
227168816,5582,rajinisivaram,2018-10-22T23:09:12Z,not used?,0,0.9285135269165039
227169229,5582,rajinisivaram,2018-10-22T23:11:14Z,"not sure whether these methods add any value since you could just use `enumset.of` instead of `metrictype.setof`? and actually looking at `waitformetrics`, it would be even better to use varargs.",0,0.9936392903327942
227170791,5582,rajinisivaram,2018-10-22T23:19:42Z,we don't need a try-finally block when teardown does the cleanup.,0,0.9882780909538269
227170823,5582,rajinisivaram,2018-10-22T23:19:53Z,we don't need a try-finally block when teardown does the cleanup.,0,0.9882780909538269
227170844,5582,rajinisivaram,2018-10-22T23:20:00Z,we don't need a try-finally block when teardown does the cleanup.,0,0.9882780909538269
227170925,5582,rajinisivaram,2018-10-22T23:20:23Z,we don't need a try-finally block when teardown does the cleanup.,0,0.9882780909538269
227170945,5582,rajinisivaram,2018-10-22T23:20:30Z,we don't need a try-finally block when teardown does the cleanup. lots of these changes in this file are unnecessary (and the test is more readable without the try-finally.,0,0.9876343011856079
227393856,5582,rondagostino,2018-10-23T13:37:45Z,:thumbs_up: done,0,0.9480166435241699
227397762,5582,rondagostino,2018-10-23T13:46:33Z,"here's what i changed it to. not sure if this is what you were getting at. let me know if there is something else it should say. i also fixed the javadoc -- it was still referring to ""not muted"" when we got rid of that check based on a review comment. [code block]",0,0.9497737884521484
227401789,5582,rondagostino,2018-10-23T13:54:48Z,"i don't think so, no. for one, if we did, then `kafka.network.processor` would have to be able to get to the `authenticator` instance, and currently `kafkachannel` does not expose that publicly. the guts of this method also refers to state within `kafkachannel` as well (specifically, `lastreauthenticationstartnanos`), and while we could pass that in instead, fundamentally the `kafkachannel` instance also has to swap out its `authenticator` instances. so i think this method really has to belong in `kafkachannel`.",0,0.989107072353363
227402058,5582,rondagostino,2018-10-23T13:55:19Z,"similar to above: i don't think so, no, for the same reasons.",0,0.9541393518447876
227408464,5582,rondagostino,2018-10-23T14:07:56Z,"not sure. my gut says the benefit would be minimal and the downside to exposing the `authenticator` (adding complexity to code that now simply asks the `kafkachannel` to do stuff) would outweigh any benefit, but regardless, if you decide it is something you would like to do maybe it can be addressed as a separate ticket?",-1,0.6767012476921082
227409726,5582,rondagostino,2018-10-23T14:10:29Z,"there was a desire to not call `time.nanoseconds()` unnecessarily. we had a time value already, but it wasn't guaranteed to be current, so we have to get it again; making it a `supplier` meands we can delay getting it for as long as possible and avoid it completely if the logic is short-circuited first.",0,0.9740508794784546
227414037,5582,rondagostino,2018-10-23T14:18:22Z,:thumbs_up: javadoc added/declarations re-ordered,0,0.9693198204040527
227418118,5582,rondagostino,2018-10-23T14:26:33Z,"lol. i changed this based on a previous review comment: `if we need to keep initial and reauth_initial, we should have. a method to use common code for this state.` . it didn't seem worthwhile to make a method with just `sendsaslclienttoken(new byte[0], true)` in it, so i put both that and `setsaslstate(saslstate.intermediate) ` in there and named it accordingly. i'm good whichever way you want to go -- just let me know if you decide it should be different than what it currently is (i.e. maybe put it back to the way it was?). will leave as-is otherwise.",1,0.9904046058654785
227421513,5582,rondagostino,2018-10-23T14:34:05Z,:thumbs_up: javadoc added/declarations re-ordered,0,0.9693198204040527
227426184,5582,rondagostino,2018-10-23T14:43:53Z,:thumbs_up: moved,0,0.98967045545578
227450301,5582,rondagostino,2018-10-23T15:37:53Z,see comment below.,0,0.9845473170280457
227451106,5582,rondagostino,2018-10-23T15:39:43Z,"i added this state because without it the attempt to change the mechanism isn't recorded as a failed re-authentication in the metrics. if we simply throw the exception then it is caught either by `nioechoserver.maybebeginserverreauthentication()` (in the case of a unit test) or by `kafka.network.processor.processcompletedreceives()` (in real-world use). in the unit test case the exception is simply ignored, and eventually the channel is closed while we are waiting in vain for the metric to update. in real-world use the channel would end up being closed -- but again no metric update occurs because the server-side `selector` never sees the channel as being ""`!channel.ready()`"" -- it needs to see this in order to call `channel.prepare()`, catch the `authenticationexception`, and record the failed re-authentication in the metric. i realize it is a bit odd to have to create this extra state, and we can avoid it if we are willing to not record the attempt as a failed re-authentication in the metrics, but i figured we would want to to record it.",0,0.9934523105621338
227451806,5582,rondagostino,2018-10-23T15:41:21Z,:thumbs_up: removed,0,0.9899410605430603
227451895,5582,rondagostino,2018-10-23T15:41:36Z,:thumbs_up: removed,0,0.9899410605430603
227453157,5582,rondagostino,2018-10-23T15:44:39Z,":thumbs_up: agreed, eliminated all the methods and now invoke `enumset.of()` directly.",0,0.8953720331192017
227458546,5582,rondagostino,2018-10-23T15:57:23Z,"oops, didn't see that cleanup code. :thumbs_up: removed (everywhere)",-1,0.4934009611606598
227458722,5582,rondagostino,2018-10-23T15:57:48Z,:thumbs_up: removed,0,0.9899410605430603
227458807,5582,rondagostino,2018-10-23T15:57:59Z,:thumbs_up: removed,0,0.9899410605430603
227458896,5582,rondagostino,2018-10-23T15:58:11Z,:thumbs_up: removed,0,0.9899410605430603
227458997,5582,rondagostino,2018-10-23T15:58:27Z,:thumbs_up: removed (everywhere),0,0.9865488409996033
227798966,5582,rajinisivaram,2018-10-24T13:56:03Z,"yes, let's leave it as is for now.",0,0.9875034689903259
227799411,5582,rajinisivaram,2018-10-24T13:57:04Z,does it really need to be that uptodate? couldn't we just use the time that we have?,0,0.985627293586731
227800879,5582,rajinisivaram,2018-10-24T14:00:27Z,"looking at the rest of the code, i think it will be good to set the state here like in the rest of the code. perhaps: [code block]",0,0.9741548299789429
227801592,5582,rajinisivaram,2018-10-24T14:02:09Z,"thanks for the explanation. yes, we do want to record it, so let's keep the state.",1,0.8105015158653259
228162494,5582,rondagostino,2018-10-25T13:01:00Z,done,0,0.8974218964576721
228247041,5582,rondagostino,2018-10-25T16:32:54Z,"actually, i just realized that `currenttimenanos` does not represent the time when `poll()` was invoked -- it actually represents the moment after the `select()` returns. so we can use that value if necessary.",0,0.9915771484375
228248803,5582,rondagostino,2018-10-25T16:37:41Z,"yeah, we can. i mistakenly thought `currenttimenanos` represented the time when `poll()` was called, but it is actually the moment when the `select()` call returns, so it is relatively recent. so now i use the most recent value we have if there is one, otherwise we use `currenttimenanos`. i kept it as a `supplier<>` though -- for symmetry with `kafkachannel.maybebeginserverreauthentication()`. i can pass the long value in directly if you prefer, otherwise i think we're good here now.",0,0.9634057283401489
423906760,8657,chia7712,2020-05-12T17:25:21Z,"it collects the ""key"" used to complete delayed requests. the completion is execute out of group lock.",0,0.9940680265426636
423907638,8657,chia7712,2020-05-12T17:26:53Z,this is the main change of this pr (address [a link],0,0.9890806674957275
423908084,8657,chia7712,2020-05-12T17:27:34Z,new check for this pr. make sure it does not hold group lock,0,0.9868021607398987
423908468,8657,chia7712,2020-05-12T17:28:09Z,"this test case is for ""trylock"" so i just remove it.",0,0.9912028312683105
423913246,8657,chia7712,2020-05-12T17:35:42Z,"this is another case of deadlock. [code block] is in a **group lock** and it tries to complete other delayed joins which related to same **__consumer_offsets** partition. hence, this pr make it control the group lock manually in order to make sure it does not hold group lock when calling [code block]",0,0.9789164066314697
426943627,8657,hachikuji,2020-05-18T23:19:57Z,"currently we have a somewhat convoluted model where `replicamanager` creates delayed operations, but we depend on lower level components like `partition` to be aware of them and complete them. this breaks encapsulation. not something we should try to complete in this pr, but as an eventual goal, i think we can consider trying to factor delayed operations out of `partition` so that they can be managed by `replicamanager` exclusively. if you assume that is the end state, then we could drop `completedelayedrequests` and let `replicamanager` _always_ be responsible for checking delayed operations after appending to the log. other than `replicamanager`, the only caller of this method is `groupmetadatamanager` which uses it during offset expiration. i think the only reason we do this is because we didn't want to waste purgatory space. i don't think that's a good enough reason to go outside the normal flow. it would be simpler to follow the same path. potentially we could make the callback an `option` so that we still have a way to avoid polluting the purgatory.",0,0.9610475301742554
426944679,8657,hachikuji,2020-05-18T23:23:37Z,"hmm.. does the group purgatory suffer from the same deadlock potential? if we call `checkandcomplete` for a group ""foo,"" i don't think we would attempt completion for any other group.",0,0.7498043775558472
426960637,8657,hachikuji,2020-05-19T00:20:05Z,"for reference, here are links to two alternative approaches that i considered earlier this year: - async completion: [a link] - lock-safe offset cache: [a link] i think jun was not satisfied with the first approach because it called for another thread pool. its advantage though was a simpler and more intuitive api than what we have here. an idea which i never implemented was to let the request handlers also handle delayed operation completion so that we did not need another thread pool. basically rather than calling the callback in `delayedproduce` directly, we add a new operation to the request queues. obviously this has its own tradeoffs. the second commit tries to use lock-free data structures so that we do not need the lock when completing the callback. this was only a partial solution which handled offset commit appends, but not group metadata appends. i am not sure how to handle join group completion asynchronously, so i gave up on this idea. only posting in case it's useful to see how some of these alternatives might have looked. i'm ok with the approach here, but i do wish we could come up with a simpler api. one thought i had is whether we could make the need for external completion more explicit. for example, maybe `appendrecords` could return some kind of object which encapsulates purgatory completion. [code block] just a thought.",0,0.9591667652130127
427095614,8657,chia7712,2020-05-19T07:45:43Z,thanks for reviews! we are on the same page :) (my previous comment [a link] this style lgtm :),1,0.996044933795929
427102729,8657,chia7712,2020-05-19T07:57:45Z,"you are right. it requires lock for group ""foo"" only. but the potential deadlock i tried to avoid/describe is that the caller has held a lock of group_a and then it tried to complete delayed request for group_b. it is possible to cause deadlock as it requires the lock of group_b to completing delayed request for group_b. that way the comment says the caller should not hold any group lock.",0,0.9887330532073975
427114083,8657,chia7712,2020-05-19T08:16:25Z,pardon me. i fail to catch your point.,-1,0.9616345167160034
427430032,8657,hachikuji,2020-05-19T16:19:03Z,"the join/heartbeat purgatories are a little different from the produce purgatory. the key is based on the groupid, so when we complete an operation for group ""foo,"" we won't complete for group ""bar"" incidentally. at least that is my understanding. if you look at `delayedoperationpurgatory.checkandcomplete`, we only complete watchers for the passed key.",0,0.9899659156799316
427432140,8657,hachikuji,2020-05-19T16:22:06Z,"sorry, let me be clearer: 1. mainly i'm suggesting moving the delayed operation checking into `replicamanager` instead of `partition`. 2. we can change the call to `appendrecordstoleader` in `groupmetadatamanager` to go through `replicamanager` as well. 3. we could make the callback optional in `replicamanager.appendrecords` so that we do not have to add a callback (which appears to be the only reason we write directly to `partition` from `groupmetadatamanager`). anyway, just a suggestion. i thought it might let us keep the completion logic encapsulated in `replicamanager`.",-1,0.9459686875343323
427435780,8657,chia7712,2020-05-19T16:27:30Z,"you are totally right. my above comment is not clear. i added the comment to remind developers following code is dangerous. [code block] of course, the above code is nonexistent currently. i'm just worry that the deadlock is easy to produce in the future if we don't notice the lock issue.",0,0.4856938123703003
427723802,8657,chia7712,2020-05-20T03:40:48Z,"in fact, there is a example of deadlock in join purgatories. [code block] called by [code block] is possible to call [code block] to append records to __consumer_offsets-{**partitionfor(group.groupid)**}. if there are groups related to same partition, [code block] which is holding a group lock will require locks for other groups.",0,0.9931961297988892
428949769,8657,junrao,2020-05-21T22:28:41Z,"perhaps reword like the following? returning a map of successfully appended topic partitions and a flag indicting whether the hwm has been incremented. if the caller passes in completedelayedrequests as false, the caller is expected to complete delayed requests for those returned partitions.",0,0.9947481751441956
428950361,8657,junrao,2020-05-21T22:30:37Z,"could we do `localproduceresults.filter{ case (tp, logappendresult) => ... }` to avoid unnamed references?",0,0.9951019287109375
428956078,8657,junrao,2020-05-21T22:48:37Z,could we add a comment for the return value?,0,0.9902864694595337
428958530,8657,junrao,2020-05-21T22:56:39Z,could we add a comment for the return value?,0,0.9902864694595337
428972538,8657,junrao,2020-05-21T23:47:16Z,"this is bit tricky to untangle. it seems the original code holds the group lock for both the `group.hasallmembersjoined` check and the call to forcecomplete(). so, we probably want to keep doing that. i am thinking that we could do the following. 1. change `groupcoordinator.oncompletejoin()` so that (1) it checks group.hasallmembersjoined inside the group lock and returns whether hasallmembersjoined is true. 2. in `delayedjoin.trycomplete() `, we do [code block] in oncomplete(), we do nothing.",0,0.7696737051010132
430253921,8657,chia7712,2020-05-26T08:47:57Z,"could you take a look? i'd like to address comment but it produces a big change to this pr. hence, it would be better to have more reviews/suggestions before kicking off.",0,0.953609049320221
430748553,8657,junrao,2020-05-26T22:47:10Z,"i was trying to check if it's safe to do this. the intention for this is probably to avoid the deadlock between the group lock and the lock in delayedoperation. none of the caller of joinpurgatory.checkandcomplete holds a group lock now. the only other caller that can first hold a group lock and then the lock in delayedoperation is joinpurgatory.trycompleteelsewatch(). however, that's not an issue since that's when the delayedjoin operation is first added. so, this changes seems ok.",0,0.9848373532295227
430750020,8657,junrao,2020-05-26T22:51:20Z,"""as the lock is not free"" : do you mean ""when the lock is free""?",0,0.9478814601898193
430750723,8657,junrao,2020-05-26T22:53:22Z,a flag => a flag in replicamanager.appendrecords().,0,0.9920338988304138
430755656,8657,junrao,2020-05-26T23:08:08Z,could we add a comment to explain the return value?,0,0.9909886717796326
430756183,8657,junrao,2020-05-26T23:09:43Z,a map containing the topic partitions having new records and a flag indicating whether the hwm has been incremented.,0,0.9919871091842651
430757287,8657,junrao,2020-05-26T23:13:06Z,"i agree that it's simpler to let the caller in replicamanager to complete the delayed requests. this way, we don't need to pass completedelayedrequests in here.",0,0.9722055196762085
430761183,8657,junrao,2020-05-26T23:26:08Z,could we add a comment to explain the return value?,0,0.9909886717796326
431001869,8657,chia7712,2020-05-27T10:01:27Z,"it may produce deadlock if we hold the group lock for [code block]. [code block] is possible to append record to [code block] (see [a link] and hence it will try to complete other delayed joins which have groups belonging to same partition of [code block]. that is why i make [code block] control the group lock manually. for another, [code block] is used by [code block] only so it should be fine to change behavior of group lock in this case.",0,0.9907694458961487
431002494,8657,chia7712,2020-05-27T10:02:37Z,copy that.,0,0.9747872948646545
431003374,8657,chia7712,2020-05-27T10:04:13Z,"hmmm, i misunderstand your point. please ignore my first comment :)",-1,0.9512283802032471
431206147,8657,chia7712,2020-05-27T14:58:55Z,make sure [code block] does not cause deadlock,0,0.9792894124984741
431208549,8657,chia7712,2020-05-27T15:00:48Z,both methods are executed with lock,0,0.9893191456794739
431209368,8657,chia7712,2020-05-27T15:01:31Z,this is a workaround to deal with deadlock caused by taking multiples group locks,0,0.9667214155197144
431210497,8657,chia7712,2020-05-27T15:02:28Z,this enum type is more readable than [code block],0,0.9874215126037598
439543737,8657,junrao,2020-06-12T17:12:08Z,it's cleaner to not pass in completedelayedrequests here and let the caller (`replicamanager.appendrecords()`) check and complete purgatory instead.,0,0.9951077699661255
439549136,8657,junrao,2020-06-12T17:23:34Z,"could we use `map {case (tp, appendresult) => ...}` here to avoid using unamed references?",0,0.9941451549530029
439872747,8657,junrao,2020-06-14T22:15:38Z,"another way that doesn't require checking lock.isheldbycurrentthread is the following. but your approach seems simpler. override forcecomplete() to [code block] in oncomplete(), do nothing. in trycomplete(), do [code block] in onexpiration(), [code block]",0,0.9924579858779907
439872846,8657,junrao,2020-06-14T22:16:58Z,expire -> oncomplete -> completedelayedrequests,0,0.9850060343742371
439873175,8657,junrao,2020-06-14T22:21:43Z,"delyaedoperation.lockopt defaults to none. so, we don't have to specify it explicitly.",0,0.9899094104766846
439873441,8657,junrao,2020-06-14T22:25:23Z,"""groupcoordinator#oncompletejoin() tries to complete delayed requests"" => since the completion of the delayed request for partitions returned from groupcoordinator#oncompletejoin() need to be done outside of the group lock.",0,0.9947629570960999
439875801,8657,junrao,2020-06-14T22:54:00Z,typo whihc,0,0.9518983364105225
439875892,8657,junrao,2020-06-14T22:55:07Z,the caller no longer passed in completedelayedrequests.,0,0.9829492568969727
439876215,8657,junrao,2020-06-14T22:59:03Z,all callers pass in completedelayedrequests as false. could we remove this param?,0,0.9873493313789368
439876392,8657,junrao,2020-06-14T23:01:18Z,there was => there were,0,0.9692898988723755
439876493,8657,junrao,2020-06-14T23:02:54Z,"replicamanager.appendrecords()., => replicamanager.appendrecords(),",0,0.9897410869598389
439876557,8657,junrao,2020-06-14T23:04:08Z,may requires => may require,0,0.9162294864654541
439878341,8657,junrao,2020-06-14T23:27:03Z,"hmm, why do we need this logic now?",0,0.8803069591522217
439878736,8657,junrao,2020-06-14T23:31:46Z,"hmm, why do we need to mock this since replicamanager.getmagic() is only called through replicamanager.handlewritetxnmarkersrequest()?",0,0.9628024697303772
439878969,8657,junrao,2020-06-14T23:34:51Z,"hmm, this should only be called with leaderhwchange.leaderhwincremented, but the mock later returns leaderhwchange.none? ditto below.",0,0.9810648560523987
439914680,8657,chia7712,2020-06-15T03:35:28Z,testreplicamanager#appendrecords ([a link] always complete the delayedproduce immediately so the txn offset is append also. this pr tries to complete the delayedproduce after releasing the group lock so it is possible to cause following execution order. 1. txn prepare 1. txn completion (fail) 1. txn append (this is executed by delayedproduce),0,0.9908037185668945
439915438,8657,chia7712,2020-06-15T03:39:51Z,the caller of [code block] may hold the group lock so it could produce deadlock if [code block] tries to complete purgatory.,0,0.9870065450668335
439920019,8657,chia7712,2020-06-15T04:03:59Z,[code block] ([a link] also call [code block]. there are delayed ops are completed by [code block] so we have to mock the [code block]. the mock is same to [a link],0,0.9938641786575317
439923720,8657,chia7712,2020-06-15T04:23:45Z,read [a link] again. it is a nice idea to refactor [code block] and [code block] to simplify the behavior of checking delayed operations. could i address the refactor in another pr to avoid bigger patch?,1,0.712080180644989
440514740,8657,junrao,2020-06-16T00:14:56Z,"thanks. i am still not sure that i fully understand this. it seems that by not completing the delayedproduce within the group lock, we are hitting illegalstateexception. that seems a bug. do you know which code depends on that? it seems that we do hold a group lock when updating the txnoffset. [a link]",1,0.8658328056335449
440515043,8657,junrao,2020-06-16T00:15:55Z,"yes, we can refactor that in a separate pr. could you file a followup jira for that?",0,0.9930397272109985
440576071,8657,chia7712,2020-06-16T04:15:13Z,"the root cause (changed by this pr) is that the ""txn initialization"" and ""txn append"" are not executed within same lock. **the test story is shown below.** [code block] calls [code block] to add [code block] to [code block] (this is the link you attached). [code block] called by [code block] throws [code block] if [code block] is [code block] ([a link] **why it does not cause error before?** [code block] is updated by the callback [code block] ([a link] [code block] always create [code block] do handle the [code block] ([a link] the condition to complete the [code block] is [code block]. and the condition gets true when call both [code block] and [code block] since the former calls [code block] two times and another calls [code block] once. it means [code block] is always executed by [code block] and noted that [code block] is executed within a group lock ([a link] . in short, txn initialization ([a link] and txn append ([a link] are executed with same group lock. hence, the following execution order is impossible. 1. txn initialization 1. txn completion 1. txn append however, this pr disable to complete delayed requests within group lock held by caller. the [code block] which used to append txn needs to require group lock again.",0,0.9937241673469543
440585314,8657,chia7712,2020-06-16T04:53:54Z,nice caching. most methods don't need this flag. let me revert them :),1,0.9945790767669678
441175806,8657,junrao,2020-06-16T22:23:40Z,typo rebalacne,0,0.9759431481361389
441177055,8657,junrao,2020-06-16T22:27:14Z,the delayed requests may be completed as much as possible => the delayed requests may be completed inside the call with the expectation that no conflicting locks are held by the caller,0,0.9930453896522522
441177351,8657,junrao,2020-06-16T22:28:07Z,callers can complete the delayed requests manually => callers can complete the delayed requests after releasing any conflicting lock.,0,0.9934604167938232
441178418,8657,junrao,2020-06-16T22:31:00Z,"""if the caller no longer passed in completedelayedrequests"" the caller still passes this in, just as false.",0,0.9843296408653259
441180667,8657,junrao,2020-06-16T22:37:19Z,""" if the caller no longer passed in completedelayedrequests"" => there is no completedelayedrequests passed in.",0,0.9909524917602539
441182450,8657,junrao,2020-06-16T22:42:33Z,to to => to,0,0.9482661485671997
441186463,8657,junrao,2020-06-16T22:54:36Z,"thanks for the great explanation. i understand the issue now. essentially, this exposed a limitation of the existing test. the existing test happens to work because the producer callbacks are always completed in the same replicamanager.appendrecords() call under the group lock. however, this is not necessarily the general case. your fix works, but may hide other real problems. i was thinking that another way to fix this is to change the test a bit. for example, we expect completetxnoperation to happen after committxnoffsetsoperation. so, instead of letting them run in parallel, we can change the test to make sure that completetxnoperation only runs after committxnoffsetsoperation completes successfully. joingroupoperation and syncgroupoperation might need a similar consideration.",1,0.9897860288619995
441289689,8657,chia7712,2020-06-17T05:32:25Z,will roger that ! i didn't notice something interesting. could you share it with me?,-1,0.9821064472198486
441846005,8657,junrao,2020-06-17T21:31:23Z,if there is no completedelayedrequests passed in => if completedelayedrequests is false,0,0.9792559146881104
441846819,8657,junrao,2020-06-17T21:33:16Z,if there is no completedelayedrequests passed in => if completedelayedrequests is false,0,0.9792559146881104
441859110,8657,junrao,2020-06-17T22:02:38Z,i think the intention for the test is probably to use the same producerid since it tests more on transactional conflicts.,0,0.9869236350059509
441859824,8657,junrao,2020-06-17T22:04:30Z,"hmm, why don't we need the lock here since committxnoffsetsoperation and completetxnoperation could still run in parallel?",0,0.9854761958122253
441862013,8657,junrao,2020-06-17T22:10:14Z,"perhaps change the comment to sth like the following? ""setting to true to make completetxnoperation and committxnoffsetsoperation complete atomically since they don't typically overlap. otherwise completetxnoperation may see a pending offsetandmetadata without an appendedbatchoffset.""",0,0.9954326152801514
441938174,8657,chia7712,2020-06-18T02:48:30Z,"got it. however, the same producerid means the group completed by completetxnoperation is possible to be impacted by any committxnoffsetsoperation (since the partitions are same also). hence, the side-effect is that we need a single lock to control the happen-before of txn completion and commit so the test will get slower.",0,0.9905603528022766
441938393,8657,chia7712,2020-06-18T02:49:28Z,you are right,0,0.8688803315162659
442330606,8657,junrao,2020-06-18T15:53:30Z,"since creategroupmembers() is called in multiple tests, it seems we will be accumulating allgroupmembers across tests. that seems unexpected?",0,0.8905500173568726
442337184,8657,chia7712,2020-06-18T16:03:15Z,"junit, by default, creates a new instance for each test case so [code block] is always new one for each test case.",0,0.9938269257545471
452634516,8657,ijuma,2020-07-10T05:48:24Z,it's weird to have a method that invokes a callback and returns a result. do we need both? we have a number of other methods that do something similar. it would be good to reconsider that as it's difficult to reason about usage in such cases.,-1,0.9829354286193848
452635111,8657,ijuma,2020-07-10T05:50:38Z,"the usual naming convention is to only capitalize the first letter, eg leaderhwchange.",0,0.9900463223457336
452754165,8657,chia7712,2020-07-10T10:12:49Z,"thanks for your reviews. you are totally right and had given a great refactor idea ([a link] given that refactor will bring a lot of changes to this pr, i had filed a ticket to refactor related code (see [a link] in order to make this pr focus on bug fix.",1,0.9912173748016357
452755236,8657,chia7712,2020-07-10T10:15:19Z,will roger that!,-1,0.9121426939964294
463043040,8657,ijuma,2020-07-30T14:35:33Z,"i notice that we are including the `$` here and in a few other places, we should not do that.",0,0.9786490797996521
463044371,8657,ijuma,2020-07-30T14:37:19Z,i raised the point before that it's a bit unusual and unintuitive to have both a callback and a return value. any thoughts on this?,-1,0.8643313646316528
463066191,8657,chia7712,2020-07-30T15:07:03Z,"the response was [a link] in short, we should have a way of fetching delayed request from partition instead of using return value to carry them.",0,0.9916948676109314
463066323,8657,chia7712,2020-07-30T15:07:14Z,will copy that!,0,0.6217265129089355
463318346,8657,ijuma,2020-07-30T23:03:17Z,"thanks, i had missed that. will respond in that thread.",1,0.8304657936096191
464562972,8657,junrao,2020-08-03T17:39:30Z,"could we change the explanation to sth like the following? this method may trigger the completeness check for delayed requests in a few purgatories. occasionally, for serialization in the log, a caller may need to hold a lock while calling this method. to avoid deadlock, if the caller holds a conflicting lock while calling this method, the caller is expected to set completedelayedrequests to false to avoid checking the delayed operations during this call. the caller will then explicitly complete those delayed operations based on the return value, without holding the conflicting lock.",0,0.9928856492042542
464567219,8657,junrao,2020-08-03T17:45:18Z,group lock => conflicting lock,0,0.951158344745636
464567267,8657,junrao,2020-08-03T17:45:24Z,group lock => conflicting lock,0,0.951158344745636
464574837,8657,junrao,2020-08-03T18:00:13Z,"perhaps add ""but completes the delayed requests without holding the group lock"".",0,0.9932907819747925
464580388,8657,junrao,2020-08-03T18:11:18Z,a lot of group lock => multiple group locks,0,0.8561158180236816
464580891,8657,junrao,2020-08-03T18:12:15Z,"""this method may hold a lot of group lock"" : this is actually not true. unlike producer/fetch purgatory, which is keyed on partition, joinpurgatory is keyed on the group. so, when we complete a key, only a single group's lock will be held. the reason that we don't want the caller to hold a group lock is that delayedjoin itself uses a lock other than the group lock for delayedoperation.maybetrycomplete() and we want to avoid the deadlock between that lock and the group lock.",0,0.9710076451301575
464697840,8657,junrao,2020-08-03T22:36:59Z,this could be `completedelayedjoinrequests(groupstocomplete)` ?,0,0.9955756664276123
464715376,8657,junrao,2020-08-03T23:33:17Z,perhaps we could add a comment on what this method is intended to test?,0,0.9839143753051758
464791414,8657,chia7712,2020-08-04T04:25:52Z,thanks for explanation. i will revise the comment according to your comment.,0,0.5268052220344543
465179335,8657,junrao,2020-08-04T16:31:50Z,"hmm, it seems that we are now introducing a new potential deadlock. the conflicting paths are the following. path 1 hold group lock -> joinpurgatory.trycompleteelsewatch(delayedjoin) -> watchforoperation (now delayedjoin visible through other threads) -> operation.maybetrycomplete() -> hold delayedjoin.lock path 2 delayedjoin.maybetrycomplete -> hold hold delayedjoin.lock -> trycomplete() -> hold group lock",0,0.9341381192207336
465200508,8657,chia7712,2020-08-04T17:07:08Z,how about removing inner lock ([code block]) from [code block] ? it seems to me [code block] does not need the inner lock.,0,0.9905579090118408
465206257,8657,chia7712,2020-08-04T17:17:09Z,"another approach is that - we introduce an new method ""aftertrycomplete"" to [code block]. the new method is invoked by [code block] after lock is released. [code block] still pass group lock to [code block] and use ""aftertrycomplete"" to complete delayed requests",0,0.9954401254653931
465867406,8657,junrao,2020-08-05T16:53:02Z,": yes, that's a possibility. it adds some complexity to delayedoperation. another possibility is to have a special case to complete the delayed requests from groupmanager.storegroup() in groupcoordinator.oncompletejoin() in a separate thread.",0,0.9927241206169128
478599979,8657,junrao,2020-08-27T18:01:35Z,unneeded new line.,0,0.9502963423728943
478600507,8657,junrao,2020-08-27T18:02:36Z,we probably want to add a comment why this is needed.,0,0.9859581589698792
478603243,8657,junrao,2020-08-27T18:07:40Z,"hmm, why do we need to override this instead of using the one defined in delayedjoin?",0,0.9097915887832642
478603776,8657,junrao,2020-08-27T18:08:37Z,this probably should be included in the local time as before.,0,0.9891632795333862
478604292,8657,junrao,2020-08-27T18:09:33Z,could we add the new param to the javadoc?,0,0.9910531640052795
479379705,8657,junrao,2020-08-28T15:31:08Z,this can just be private.,0,0.9792063236236572
479381963,8657,junrao,2020-08-28T15:34:58Z,kafkaapis.handle() => kafkaapis.handle() and the expiration thread for certain delayed operations (e.g. delayedjoin),0,0.992457389831543
479382167,8657,junrao,2020-08-28T15:35:19Z,the above comment is outdated now.,0,0.9638450145721436
479382962,8657,junrao,2020-08-28T15:36:41Z,we probably should rename this to sth like safetrycomplete().,0,0.9928380846977234
479383807,8657,junrao,2020-08-28T15:38:11Z,the default value is none.,0,0.981803297996521
479389617,8657,junrao,2020-08-28T15:49:04Z,at the end of kafkaapis.handle() => at the end of kafkaapis.handle() and the expiration thread for certain delayed operations (e.g. delayedjoin),0,0.9933812618255615
479390056,8657,junrao,2020-08-28T15:49:47Z,in a queue => are stored in a queue,0,0.9747549891471863
479467548,8657,junrao,2020-08-28T18:24:30Z,the last sentence doesn't complete.,0,0.9061683416366577
479474904,8657,ijuma,2020-08-28T18:41:05Z,can we not use a `boolean` here? `false` until it's been incremented and then `true`. is there value in having the third state?,0,0.9931612014770508
479475681,8657,ijuma,2020-08-28T18:42:47Z,should we be guarding against exceptions here?,0,0.9869884252548218
479661386,8657,junrao,2020-08-29T15:40:22Z,a action => an action,0,0.929958701133728
479669354,8657,junrao,2020-08-29T17:05:19Z,"even if we hit an exception in handlexxx(), it would still be useful to complete the actionqueue.",0,0.9908218383789062
479670056,8657,junrao,2020-08-29T17:13:30Z,"it seems that we have to distinguish 3 states here: (1) records not appended due to an error; (2) records appended successfully and hwm advanced; (3) records appended successfully and hwm not advanced. in case (1), no purgatory needs to be checked.",0,0.9942060112953186
479670351,8657,junrao,2020-08-29T17:16:24Z,is this used?,0,0.9839692115783691
479670727,8657,junrao,2020-08-29T17:20:46Z,perhaps we could add a note at the top of delayedoperation so that people are aware of the need to complete actions for new delayedoperations in the future.,0,0.9920607805252075
479677889,8657,chia7712,2020-08-29T18:40:53Z,completing delayed actions may cause exception. should exception be swallowed and log if we move the completion to the final block?,0,0.9914488196372986
479678653,8657,chia7712,2020-08-29T18:50:10Z,you are right. i miss the exception in [code block]. let me revert this change,0,0.908731997013092
479678761,8657,ijuma,2020-08-29T18:51:18Z,what's the reasoning for taking just 1 item ? could this cause the queue to grow over time?,0,0.9721999764442444
479678812,8657,ijuma,2020-08-29T18:52:04Z,another approach would be for this queue to be per request thread instead of per server. that would simplify concurrency handling.,0,0.9926905035972595
479679930,8657,chia7712,2020-08-29T19:05:13Z,"it is dangerous to complete delayed actions by [code block] as most methods of [code block] are executed with locking. we, now, depend on [code block] to complete the delayed action produced by someone who can't complete delayed action due to locking. for example, [code block] can produce an new action and the new action can't be completed by [code block] itself due to group locking.",0,0.932675838470459
479680637,8657,chia7712,2020-08-29T19:13:19Z,the thread has to pass queue to method of replicmanager/groupcoordinator if queue is kept by thread. a lot of methods are included so that is a big patch. i prefer to keep small patch though it gets bigger now :(,-1,0.9910864233970642
479682849,8657,junrao,2020-08-29T19:37:54Z,good question. it's based on the assumption that each kafkaapis.handle() call only calls replicamanager. appendrecords() once. not sure if this is always true in the future. perhaps a safer approach is to have action.trycompleteaction() get the current size of the queue and complete all those actions.,1,0.7020936608314514
479683036,8657,chia7712,2020-08-29T19:40:00Z,it should be fine to let handler complete actions as much as possible since the response is created before handling delayed actions.,0,0.9879385828971863
479683212,8657,junrao,2020-08-29T19:42:24Z,"yes, if actionqueue.trycompleteaction() throws an exception, we can just catch it and log a warning in finally since the response has been sent by then.",0,0.9928858876228333
479683544,8657,junrao,2020-08-29T19:45:56Z,"i was thinking to add a comment so that if someone adds a future delayed operation that calls replicamanager.appendrecords() in oncomplete() like delayedjoin, he/she is aware that this operation's onexpiration() needs to call actionqueue.trycompleteaction().",0,0.9887866377830505
479684163,8657,junrao,2020-08-29T19:53:51Z,"perhaps we can make this a bit clearer. sth like the following. leaderhwincremented has 3 possible values: (1) if records are not appended due to an error, the value will be none; (2) if records are appended successfully and hwm is advanced, the value is some(true); (3) if records are appended successfully and hwm is not advanced, the value is some(false).",0,0.9834638237953186
479684353,8657,junrao,2020-08-29T19:55:43Z,"note that the action queue is not only called by requests threads, but also by the expiration thread for certain delayed operations.",0,0.9908729791641235
479686292,8657,ijuma,2020-08-29T20:17:33Z,good point .,1,0.9686352610588074
479686398,8657,ijuma,2020-08-29T20:19:12Z,i suggest using a sealed trait with 3 case objects to make this clearer. using `option[boolean]` as a tristate value is generally best avoided.,0,0.9924913048744202
479686517,8657,chia7712,2020-08-29T20:20:30Z,will copy that,0,0.9780444502830505
479689381,8657,chia7712,2020-08-29T20:55:45Z,please take a look at this method,0,0.9510564804077148
479689457,8657,ijuma,2020-08-29T20:56:53Z,"main thing to decide is what to do in case of exception, do we stop processing or do we continue?",0,0.9815177321434021
479689653,8657,ijuma,2020-08-29T20:59:38Z,why are we using a blocking queue? it doesn't seem like we ever need the blocking functionality. am i missing something?,0,0.7021753191947937
479689694,8657,chia7712,2020-08-29T20:59:55Z,i prefer to just catch it and log a warning as the response has been processed. wdyt?,0,0.9066269993782043
479689838,8657,chia7712,2020-08-29T21:01:42Z,you are right. how about using [code block] instead?,0,0.9666376113891602
479691180,8657,ijuma,2020-08-29T21:20:30Z,"yes, i think that's better. one thing i was wondering about is whether contention is going to be an issue for this `actionqueue`. multiple threads are adding items to it and then trying to consume from it. i haven't thought about all the details, but would a thread local work better? in that case, each thread would add and then drain. this works fine for the request threads, but i wasn't sure about the other case that pointed out.",0,0.9668309092521667
479692892,8657,chia7712,2020-08-29T21:44:06Z,handler (thread) can have local actionqueue and it is passed to each method to collect delayed actions. [code block] is specific case since the delayed actions are possible to be access by two thread (timeout thread and handler thread). a simple way to address thread local is that [code block] owns an actionqueue and the queue is passed to [code block] and then the queue is consumed by [code block]. both [code block] and [code block] are thread-safe so use a thread local queue is safe.,0,0.9946480393409729
479706182,8657,junrao,2020-08-30T00:59:37Z,"if we are unlucky, a single thread could be held up in this loop for a long time. perhaps we could let each thread only complete the number of actions that it sees when entering trycompleteactions().",0,0.8656500577926636
479706303,8657,junrao,2020-08-30T01:01:16Z,"perhaps we could do the try/catch of each action here instead of kafkaapis. this way, we are guaranteed that all pending actions are processed in time.",0,0.9939175844192505
479706407,8657,junrao,2020-08-30T01:02:56Z,"since we are draining more than 1 item now, this comment is no longer accurate.",0,0.9500932693481445
479716882,8657,ijuma,2020-08-30T03:41:47Z,maybe we can go with a single `actionqueue` in this pr. we can submit a separate pr for reducing the contention by having one per thread.,0,0.9943177103996277
479737358,8657,chia7712,2020-08-30T08:05:15Z,"sure. i will file a pr to follow the pattern in #9229 in order to simplify code base, i will revert the action queue in ""per server"" :)",1,0.9842543601989746
479802860,8657,junrao,2020-08-30T18:47:31Z,need => needs,0,0.9536541700363159
479802912,8657,junrao,2020-08-30T18:48:05Z,is failed => failed,0,0.5402750968933105
479803168,8657,junrao,2020-08-30T18:50:50Z,probably increased is clearer than incremental.,0,0.9869492650032043
479829275,8657,ijuma,2020-08-30T23:26:35Z,another nit: `leaderhwchange` adheres to the coding convention better.,0,0.9917744994163513
482743072,8657,chia7712,2020-09-03T06:50:50Z,"this change avoids deadlock in [code block]. if we update [code block] before [code block], the other threads can take the same key to complete delayed request. hence the deadlock happens due to following conditions. **thread_1** holds [code block] of transactionstatemanager to call [code block] and it requires lock of delayed request to call [code block]. **thread_2** holds lock of delayed request to call [code block] (updatecachecallback) and [code block] requires [code block] of transactionstatemanager.",0,0.9947593808174133
482753529,8657,chia7712,2020-09-03T07:06:44Z,"according to above case, there is a potential deadlock. [code block] [code block] is executed after updating [code block]. hence, it is possible that the lock of this request is held by **another thread**. the deadlock happens if this [code block] is holding the **lock** required by **another thread**. it seems to me the simple approach is to remove [code block]. that should be fine since we have called [code block] before.",0,0.9920297861099243
483276075,8657,junrao,2020-09-03T21:58:37Z,": 1. i think we still need `operation.safetrycomplete` in `delayedoperation.trycompleteelsewatch()`. the reason is that after the `operation.trycomplete()` call, but before we add the key to watch, the operation could have been completed by another thread. since that thread doesn't see the registered key, it won't complete the request. if we don't call `operation.safetrycomplete` after adding the key for watch, we could have missed the only chance for completing this operation. 2. i am not sure if there is a deadlock caused by transactionstatemanager. i don't see updatecachecallback hold any lock on statelock. the following locking sequence is possible through transactionstatemanager. thread 1 : hold readlock of statelock, call replicamanager.appendrecords, call trycompleteelsewatch, hold lock on delayedoperation thread 2: hold lock on delayedoperation, call delayedoperation.oncomplete, call removefromcachecallback(), hold readlock of statelock. however, since both threads hold readlock of statelock, there shouldn't be a conflict. do you see the test fail due to a deadlock?",0,0.9855782389640808
483552275,8657,chia7712,2020-09-04T11:15:46Z,the following read/write lock is from[code block] of [code block] 1. thread_1: holding readlock and waiting for lock of delayed op (transactionstatemanager#appendtransactiontolog) 2. thread_2: waiting for writelock ([code block]) [code block] 3. thread_3: holding lock of delayed op and waiting for readlock (another thread is trying to complete delayed op) **deadlock** 1. thread_1 is waiting for thread_3 1. thread_3 is waiting for thread_2 1. thread_2 is waiting for thread_1,0,0.9932671785354614
483832980,8657,junrao,2020-09-04T20:33:01Z,": thanks for the explanation. `statelock` is created as an unfair reentrantreadwritelock. so, in that case, will thread_3's attempt for getting the readlock blocked after thread_2? did the test actually failed because of this?",0,0.8337796926498413
483897245,8657,chia7712,2020-09-05T01:53:31Z,"to the best of my knowledge, writers have preference over readers in order to avoid starvation. that behavior is not public and we can get some evidence from source code. for example: [code block] at any rate, the non-fair mode does not guarantee above situation does not happen. hence, it would be better to avoid potential deadlock caused by [code block]. how about using [code block] in trycompleteelsewatch? it avoids conflicting locking and still check completion of delayed operations after adding watches?",0,0.9860090613365173
483966128,8657,junrao,2020-09-05T16:31:58Z,": thanks for the explanation. i agree that it's a potential problem. does using `trylock` in `trycompleteelsewatch()` lead us back to the previous issue that we could miss the opportunity to to complete an operation (fixed with kafka-6653)? another possibly is that we hold the lock in delayed operation while adding the operation to watch list and do the final `safetrycomplete()` check. this way, when the delayed operation is exposed to another thread, every thread, including the caller, always first acquires the lock in delayed operation. this should avoid all potential deadlocks between `trycompleteelsewatch()` and `checkandcomplete()`. what do you think?",0,0.5093470811843872
484039528,8657,chia7712,2020-09-06T08:22:57Z,nice idea. i have addressed this approach.,1,0.9889087080955505
484090245,8657,junrao,2020-09-06T16:38:01Z,requiring => requires,0,0.966413676738739
484090563,8657,junrao,2020-09-06T16:41:37Z,it seems that we don't need the `if` here?,0,0.9874282479286194
484090694,8657,junrao,2020-09-06T16:43:11Z,we should return if `trycomplete()` returns true.,0,0.9926784038543701
484091466,8657,junrao,2020-09-06T16:51:33Z,"this is an existing issue. i am not sure if calling `trycomplete()` without holding the operation's lock guarantees visibility to another thread. for example, thread 1 changes the state in the operation in `trycomplete()`. it then calls `trycomplete()` holding the operations's lock but doesn't change the state in the operation. thread 2 calls `trycomplete()` holding the operations's lock. is thread 2 guaranteed to see the changes made by thread 1 since the update was made without crossing the memory boundary by subsequent readers? if this is an issue, we could extend to lock to do the first `trycomplete()` check.",0,0.9786022901535034
484092252,8657,junrao,2020-09-06T16:59:20Z,"this approach is fine but leaks operation.lock beyond tests. another way to package this is to add a new method in delayedoperation like trycompleteandmaybewatch(). if that's not very clean, we can keep the current approach.",0,0.9859269857406616
484092496,8657,junrao,2020-09-06T17:02:00Z,do we still need this change to avoid deadlocks?,0,0.9889494180679321
484092945,8657,junrao,2020-09-06T17:06:29Z,"with this change, `delayedoperations.checkandcompletefetch()` is only used in tests. i am wondering if it can be removed. it's fine if we want to do this in a followup pr. unrelated to this pr, `delayedoperations.checkandcompleteproduce` and `delayedoperations.checkandcompletedeleterecords` seem unused. we can probably remove them in a separate pr.",0,0.9913225173950195
484097161,8657,chia7712,2020-09-06T17:52:54Z,"pardon me, the latest commit does it. if the trycomplete return true, this method return true also. or you mean we can do return in the lambda function directly? if so, the reason i dont address it is the impl of return in lambda is to throws and then catch exception.that is anti-pattern in scala and we should avoid it from our hot methods.",0,0.9142817258834839
484097601,8657,chia7712,2020-09-06T17:57:55Z,there is an new test for this new behavior. in the delayedoperationtest.,0,0.9920154809951782
484097948,8657,chia7712,2020-09-06T18:01:29Z,"yep. if we add it to watch list too early, the concurrent issue happens as trycompleteelsewatch calls trycomplete without locking.",0,0.9361141920089722
484099709,8657,chia7712,2020-09-06T18:21:23Z,"it depends :) however, it should be fine to extend the lock to do it in this pr. will address it in next commit",1,0.9886614084243774
484101535,8657,junrao,2020-09-06T18:40:54Z,"yes, you are right. i missed the bracket alignment.",0,0.8497942686080933
484101769,8657,junrao,2020-09-06T18:43:34Z,"yes, it's just that if all non-testing usage of delayedoperation.lock is within delayedoperation itself, it makes it a bit easier to trace down all usage of lock.",0,0.985418438911438
484138649,8657,chia7712,2020-09-07T00:59:57Z,"this approach can not resolve all potential deadlock. for example: 1. thread_a gets lock of op 1. thread_a adds op to watch list 1. thread_a calls op#trycomplete (and it requires lock_b) 1. thread_b holds lock_b 1. thread_b sees op from watch list 1. thread_b needs lock of op hence, we are facing the following issues. 1. the last completion check can cause deadlock after the op is exposed to other threads (by watch list). 1. the last completion check can not be removed due to kafka-6653. how about using actionqueue to resolve it? we add completion check to actionqueue after adding op to watch list. all handlers are able to complete it even if they don't have same key.",0,0.9756538271903992
484163863,8657,chia7712,2020-09-07T03:20:48Z,"as the potential deadlock caused by holding lock in [code block], i don""t change the [code block] to [code block]. maybe we can deal with this issue when we meet such issue.",0,0.9889397025108337
484164627,8657,chia7712,2020-09-07T03:24:50Z,i will file a ticket after this pr is merged. this is small change. i will remove them in this pr,0,0.9864228367805481
484181930,8657,junrao,2020-09-07T04:52:58Z,": what you described is possible, but probably not an issue in practice. since trycomplete() always completes a delayed operation asynchronously, there is no reason for the caller of a delayed operation to hold any lock while calling trycomplete. therefore, in step 4 above, the first lock that thread_b (assuming it's well designed) can acquire should be the lock in delayed operation.",0,0.9936330318450928
484209068,8657,chia7712,2020-09-07T06:32:29Z,"you are right. however, not sure how to maintain that ""well designed"" code in the future as the deadlock is implicit. it seems to me avoiding multiples exclusive lockings can avoid the deadlock. i will keep current approach since the story i described may be overkill in practice.",0,0.9457666873931885
484519651,8657,junrao,2020-09-07T16:45:35Z,"since safetrycomplete() is no longer used in trycompleteelsewatch(), the above comment is not completely relevant. perhaps we could just explain what this method does ""thread-safe variant of trycomplete().""",0,0.9916490316390991
484521628,8657,junrao,2020-09-07T16:52:44Z,it requires lock_b => it tries to require lock_b,0,0.9848513007164001
484522816,8657,junrao,2020-09-07T16:57:32Z,"perhaps we could change this comment to sth like the following. to avoid the above scenario, we recommend delayedoperationpurgatory.checkandcomplete() be called without holding any lock. since delayedoperationpurgatory.checkandcomplete() completes delayed operations asynchronously, holding a lock to make the call is often unnecessary.",0,0.9933902025222778
484523257,8657,junrao,2020-09-07T16:59:24Z,there is a potential deadlock => there is a potential deadlock between the callers to trycompleteelsewatch() and checkandcomplete(),0,0.9717215895652771
484523534,8657,junrao,2020-09-07T17:00:21Z,thread_c holds lock of op => thread_c calls checkandcomplete () and holds lock of op,0,0.9907650947570801
484524545,8657,junrao,2020-09-07T17:04:35Z,is this change still necessary now that we always call trycomplete() with lock in trycompleteelsewatch?,0,0.9947569370269775
484543835,8657,chia7712,2020-09-07T18:44:50Z,will copy that,0,0.9780444502830505
484605576,8657,junrao,2020-09-08T01:37:51Z,safetrycompleteandelse => safetrycompleteorelse ?,0,0.9835284948348999
484606811,8657,junrao,2020-09-08T01:43:41Z,"the above comment is a bit out of context now. perhaps we could change ""we do the check in the following way"" to ""we do the check in the following way through safetrycompleteandelse()"".",0,0.9925523996353149
484607882,8657,junrao,2020-09-08T01:48:33Z,do we still need to change the ordering now that we always call trycomplete() with lock in trycompleteelsewatch?,0,0.9931047558784485
484609072,8657,junrao,2020-09-08T01:53:44Z,checkandcomplete () => checkandcomplete(),0,0.9857615232467651
484610866,8657,junrao,2020-09-08T02:01:32Z,"perhaps change the above to the following? we hold the operation's lock while adding the operation to watch list and doing the trycomplete() check. this is to avoid a potential deadlock between the callers to trycompleteelsewatch() and checkandcomplete(). for example, the following deadlock can happen if the lock is only held for the final trycomplete() check.",0,0.9941721558570862
484622290,8657,chia7712,2020-09-08T02:52:05Z,i will revert this change,0,0.9761219024658203
484638938,8657,junrao,2020-09-08T04:08:51Z,"i think we still want to keep the rest of the paragraph starting from ""call trycomplete()."".",0,0.9771156311035156
484639236,8657,junrao,2020-09-08T04:10:06Z,"we hold => through safetrycompleteorelse(), we hold",0,0.9900434017181396
484640168,8657,junrao,2020-09-08T04:14:27Z,thread_b holds lock_b => thread_b holds lock_b and calls checkandcomplete(),0,0.9926396608352661
484640862,8657,junrao,2020-09-08T04:17:41Z,"noted that current approach can't prevent all deadlock. => note that even with the current approach, deadlocks could still be introduced.",0,0.9653815031051636
484644802,8657,junrao,2020-09-08T04:35:49Z,"instead of introducing a global var, could we add a new param when constructing committxnoffsetsoperation and completetxnoperation?",0,0.9954738020896912
484645849,8657,junrao,2020-09-08T04:40:17Z,thread_a gets lock of op => thread_a calls trycompleteelsewatch() and gets lock of op,0,0.9812148809432983
485026583,8657,junrao,2020-09-08T15:52:56Z,to call safetrycomplete => to call the final trycomplete(),0,0.9893506169319153
485026799,8657,junrao,2020-09-08T15:53:16Z,trycompleteelsewatch => trycompleteelsewatch(),0,0.969226598739624
485034262,8657,junrao,2020-09-08T16:04:21Z,causes error => causes an error,0,0.9060537219047546
485034296,8657,junrao,2020-09-08T16:04:23Z,such error => such an error,0,0.9175669550895691
94801659,2264,ijuma,2017-01-05T16:36:06Z,it seems like this field is not used anywhere.,0,0.9782862663269043
95000465,2264,hachikuji,2017-01-06T19:05:19Z,i think we need to enforce a minimum version of 2 since older versions would expect an older version of the message format. this is also an easy way to detect that we're talking with a version of the broker older than 0.10. i'm wondering if it would make sense to raise an exception to the user immediately when we connect to such a broker instead of waiting until we send an incompatible request?,0,0.9737914800643921
95016586,2264,cmccabe,2017-01-06T20:43:03Z,"sure, we can enforce a minimum version of 2 here. brokers earlier than 0.10 will automatically disconnect our clients, since those brokers don't support apiversionsrequest, which is the first thing we send after kafka-3600.",0,0.9867351055145264
95197805,2264,ijuma,2017-01-09T17:01:03Z,"nit: in kafka, we don't use `get` prefix for accessors.",0,0.9856985211372375
95198122,2264,ijuma,2017-01-09T17:02:33Z,"this is not needed, `stringbuilder` appends `null` for you.",0,0.9927338361740112
95204211,2264,ijuma,2017-01-09T17:35:24Z,nit: it may make sense to move the requestbuilder to the end as it's likely to be bigger and make it harder to read the other fields.,0,0.9917187690734863
95204352,2264,ijuma,2017-01-09T17:36:01Z,"we have a method `requestbuilder` that is the same as this, so we can remove this one.",0,0.9915934801101685
95215232,2264,cmccabe,2017-01-09T18:28:11Z,"ok, i'll remove that here (and elsewhere)",0,0.9878987669944763
95215682,2264,cmccabe,2017-01-09T18:30:19Z,k,0,0.934664785861969
95239733,2264,cmccabe,2017-01-09T20:32:35Z,"this should be used any time that there is a version mismatch problem between the message we are trying to send and the message versions we can actually send to the desired broker. i fixed the fetcher to use this instead of doing its own thing to detect version problems. i also change the type of this to runtimeexception, so that the exact exception which the builder raised can be preserved here.",0,0.9899497032165527
95248631,2264,ijuma,2017-01-09T21:20:56Z,nit: should this be `newrequest` since it's a method in `kafkaclient`? or is it clearer how it is?,0,0.9950443506240845
95252239,2264,ijuma,2017-01-09T21:39:37Z,"nit: do we really need 3 lines for this? seems like we could do it in two. in kafka, we generally go for wider lines than the traditional 80 columns (100 to 120 is common).",0,0.9859071969985962
95252366,2264,ijuma,2017-01-09T21:40:22Z,can we expand on when this can happen?,0,0.9849948287010193
95261313,2264,hachikuji,2017-01-09T22:27:41Z,nit: this alignment is weird. are you using intellij defaults?,-1,0.9921244978904724
95262756,2264,hachikuji,2017-01-09T22:36:29Z,does it make sense to special case the apiversion request only instead of skipping the check for all internal requests?,0,0.9934050440788269
95263217,2264,hachikuji,2017-01-09T22:39:17Z,nit: we usually skip braces for one-line branches like this. a few more below.,0,0.977906346321106
95264033,2264,hachikuji,2017-01-09T22:44:20Z,"would it make sense to push this check into `getusableversion`? i wouldn't consider a negative version ""usable.""",0,0.9927559494972229
95264436,2264,hachikuji,2017-01-09T22:46:54Z,is this equivalent to this? [code block],0,0.9917768239974976
95264759,2264,hachikuji,2017-01-09T22:48:56Z,nit: indentation,0,0.5517857670783997
95265028,2264,hachikuji,2017-01-09T22:50:32Z,nit: use string interpolation,0,0.9903901815414429
95265544,2264,hachikuji,2017-01-09T22:53:41Z,"there's a bug in `processdisconnection` (not introduced in this patch) that we ought to fix here. the type of `node` here is a string, but `nodeapiversions` is keyed by integer. (the conversion between string and int all over this class always pains me.)",0,0.6364777088165283
95265740,2264,ijuma,2017-01-09T22:54:41Z,"unfortunately, 0.9.0.1 has a bug where it won't disconnect when it receives an unknown request. it will keep the connection open until the connection reaper comes along. a subsequent request can cause an immediate disconnection though.",-1,0.5064706802368164
95265836,2264,hachikuji,2017-01-09T22:55:18Z,i think `nodeid` is a more accurate name.,0,0.9792448282241821
95265980,2264,ijuma,2017-01-09T22:56:13Z,"nit: is it right to say it's an `obsolete` broker? seems a bit too strong, obsolete means `no longer produced or used; out of date` whereas it could be a broker that is just 4 months old given our current time-based release schedule.",0,0.9145345091819763
95266228,2264,ijuma,2017-01-09T22:57:44Z,do we really need to do this? i'd prefer if we didn't expose a static mutable array outside this class.,0,0.987854540348053
95266232,2264,hachikuji,2017-01-09T22:57:45Z,nit: seems like there's enough room on the previous line for this,0,0.9629097580909729
95266343,2264,ijuma,2017-01-09T22:58:27Z,nit: `version`?,0,0.9921252131462097
95266684,2264,hachikuji,2017-01-09T23:00:39Z,seems this was our last usage for the `now` parameter.,0,0.9918251037597656
95266777,2264,hachikuji,2017-01-09T23:01:13Z,nit: can this fit on the line above?,0,0.9905905723571777
95267609,2264,ijuma,2017-01-09T23:06:14Z,"these 3 lines can simply be `val version = apiversion.getorelse(protoutils.latestversion(apikey,id))`.",0,0.9940061569213867
95267715,2264,hachikuji,2017-01-09T23:06:56Z,seems we can turn this into an assertion when it is not an apiversion request.,0,0.9927781224250793
95267760,2264,ijuma,2017-01-09T23:07:12Z,"nit: it should be `val version: short` (space after the colon, not before).",0,0.9940252900123596
95268226,2264,hachikuji,2017-01-09T23:10:16Z,`now` is never used.,0,0.9748930931091309
95268276,2264,ijuma,2017-01-09T23:10:37Z,"looks like the code for both `builder(...)` is the same, so maybe we can just do the `livebrokers` bit in the `if/else`.",0,0.9940125346183777
95268361,2264,ijuma,2017-01-09T23:11:14Z,"nit: the map creation is usually done like `map(securityprotocol.plaintext -> new endpoint(node.host, node.port))`.",0,0.9933587908744812
95268422,2264,hachikuji,2017-01-09T23:11:38Z,nit: you can leave out the type on the right-hand side.,0,0.9894292950630188
95268671,2264,ijuma,2017-01-09T23:13:10Z,nit: is there a reason why you didn't chain this one too?,0,0.9596384763717651
95268734,2264,ijuma,2017-01-09T23:13:39Z,seems like the `()` introduced here are not needed.,0,0.9862711429595947
95271011,2264,hachikuji,2017-01-09T23:28:58Z,`api` no longer used. indentation needs fixing also.,0,0.9892739653587341
95271585,2264,hachikuji,2017-01-09T23:32:24Z,there are a few javadoc references that need fixing as well.,0,0.9879470467567444
95274471,2264,hachikuji,2017-01-09T23:54:45Z,"i think it might be better to move this check into `consumernetworkclient.requestfuturecompletionhandler` to ensure that we don't forget any checks. also `onfailure` seems like a more appropriate callback for that case,",0,0.9934483170509338
95275129,2264,hachikuji,2017-01-10T00:00:05Z,"nit: string interpolation is preferred. another one below. also, not sure about the convention of including the function name. wouldn't the logger do that for us?",0,0.9600822329521179
95276737,2264,hachikuji,2017-01-10T00:13:40Z,"in this case, we're using the presence of the `offsets` field to indirectly determine that the version that was used was 0. i'm not sure we'll always have something so convenient, so i've been wondering if we need a way to determine the version that was used more directly. for example, we could have `clientresponse` or even `abstractresponse` include a field for the version.",0,0.9379420876502991
95276915,2264,cmccabe,2017-01-10T00:15:26Z,"ok, i realigned it with the left paren",0,0.9798963069915771
95276973,2264,cmccabe,2017-01-10T00:15:53Z,k,0,0.934664785861969
95277223,2264,hachikuji,2017-01-10T00:18:28Z,why was this changed?,0,0.9839271903038025
95277345,2264,cmccabe,2017-01-10T00:19:36Z,"hmm. i haven't thought about it that hard, but i think special casing will probably get messy here. it also duplicates work done elsewhere to check if the message is sendable.",-1,0.9062561988830566
95277392,2264,hachikuji,2017-01-10T00:19:57Z,the `impl` suffix is a little unconventional. can we just use `getoffsetsbytimes`?,0,0.8559695482254028
95278127,2264,cmccabe,2017-01-10T00:26:26Z,k,0,0.934664785861969
95278471,2264,cmccabe,2017-01-10T00:29:17Z,ok,0,0.8787186145782471
95278543,2264,cmccabe,2017-01-10T00:29:57Z,removed,0,0.9801433682441711
95278678,2264,hachikuji,2017-01-10T00:30:54Z,i think we need to pass this exception to the future instead of raising. would be good to have a test case if we don't already.,0,0.9365750551223755
95278757,2264,cmccabe,2017-01-10T00:31:41Z,"yeah, let's just do that.",0,0.9670489430427551
95278815,2264,cmccabe,2017-01-10T00:32:16Z,k,0,0.934664785861969
95278891,2264,cmccabe,2017-01-10T00:33:00Z,yeah,0,0.9002789258956909
95279595,2264,hachikuji,2017-01-10T00:39:47Z,"we didn't have it before, but maybe we should add a null check here for more resilience in the future.",0,0.9911976456642151
95279607,2264,cmccabe,2017-01-10T00:39:56Z,"yeah, that is pretty nasty. i'll fix it. i wish there were some workaround for this, but it looks like java map still always supports put(object) to allow compatibility with the pre-generics days... we should start running findbugs to catch things like this",-1,0.9916240572929382
95279753,2264,hachikuji,2017-01-10T00:41:13Z,"i'm a little unclear on the pattern for which fields are included in the builder constructor and which are included through methods. i thought perhaps it would be the required arguments included in the constructor, but we didn't pass the timestamps to query in the `listoffsetrequest` above, which seems required.",0,0.8897843956947327
95280248,2264,cmccabe,2017-01-10T00:45:07Z,k,0,0.934664785861969
95280508,2264,cmccabe,2017-01-10T00:47:36Z,k,0,0.934664785861969
95280577,2264,cmccabe,2017-01-10T00:48:05Z,k,0,0.934664785861969
95280644,2264,cmccabe,2017-01-10T00:48:41Z,yeah,0,0.9002789258956909
95281013,2264,cmccabe,2017-01-10T00:51:28Z,k,0,0.934664785861969
95281567,2264,cmccabe,2017-01-10T00:56:07Z,i added a comment,0,0.9567638635635376
95282327,2264,hachikuji,2017-01-10T01:02:40Z,maybe `unsupportedbrokerexception`?,0,0.9873526096343994
95284742,2264,cmccabe,2017-01-10T01:26:27Z,"hmm, how would the 0.9.0.1 broker even know that it was getting another request? it doesn't know the size of the first request so it doesn't know where that request ends and a new one begins.",0,0.6523829102516174
95284792,2264,cmccabe,2017-01-10T01:26:58Z,k,0,0.934664785861969
95284826,2264,hachikuji,2017-01-10T01:27:24Z,nit: would be nice to be consistent on the use of braces or parenthesis. i think we are trying to encourage the latter.,0,0.9444476962089539
95286297,2264,junrao,2017-01-10T01:43:04Z,"when the transport is ssl, the client can't send requests immediately after the socket is connected. we have to wait for the ssl handshake to complete. so, perhaps the selector needs to further return the transport.ready() state in kafkachannel to networkclient.",0,0.990435779094696
95286337,2264,junrao,2017-01-10T01:43:30Z,"using the current version is ok for now since there is currently only one version of saslhandshakerequest. it would be useful to add a comment that when there are new versions of saslhandshakerequest, we need to select the version based on the result of apirequest accordingly.",0,0.9925984144210815
95290016,2264,hachikuji,2017-01-10T02:25:10Z,we seem to be missing the version mismatch check in `handleproduceresponse`.,0,0.9930083751678467
95303775,2264,cmccabe,2017-01-10T05:53:19Z,k,0,0.934664785861969
95304065,2264,cmccabe,2017-01-10T05:57:04Z,"setversion is a method on the base class, abstractrequest#builder. so it returns an instance of abstractrequest#builder rather than an instance of the derived class fetchrequest#builder, which is awkward for scala's type inference.",-1,0.5247451066970825
95304445,2264,cmccabe,2017-01-10T06:01:54Z,k,0,0.934664785861969
95304662,2264,cmccabe,2017-01-10T06:04:57Z,nice,1,0.9342552423477173
95304719,2264,cmccabe,2017-01-10T06:06:13Z,k,0,0.934664785861969
95304766,2264,cmccabe,2017-01-10T06:06:44Z,k,0,0.934664785861969
95304877,2264,cmccabe,2017-01-10T06:08:33Z,k,0,0.934664785861969
95305418,2264,cmccabe,2017-01-10T06:16:03Z,"ok, we can hide it",0,0.9507773518562317
95305559,2264,cmccabe,2017-01-10T06:17:31Z,"obsolete may be a little strong, but it's clear what it means and what the user should do if they want access to the feature. we could also go with something like ""outdatedbrokerexception""?",0,0.9180504679679871
95305659,2264,cmccabe,2017-01-10T06:18:44Z,"it sounds like we would be in the clear then, since we're sending an apiversionsrequest followed by a follow-on request?",0,0.9927111864089966
95305690,2264,cmccabe,2017-01-10T06:19:14Z,fixed,0,0.9281549453735352
95305695,2264,cmccabe,2017-01-10T06:19:19Z,k,0,0.934664785861969
95305967,2264,cmccabe,2017-01-10T06:22:42Z,k,0,0.934664785861969
95305976,2264,cmccabe,2017-01-10T06:22:50Z,sounds good,1,0.9683692455291748
95305989,2264,cmccabe,2017-01-10T06:22:56Z,removed,0,0.9801433682441711
95306011,2264,cmccabe,2017-01-10T06:23:05Z,"yes, let's replace it with that",0,0.9819114804267883
95306022,2264,cmccabe,2017-01-10T06:23:14Z,fixed,0,0.9281549453735352
95306030,2264,cmccabe,2017-01-10T06:23:21Z,k,0,0.934664785861969
95306063,2264,cmccabe,2017-01-10T06:23:48Z,ugh. that's a nasty one. i fixed it in the patch. we should run findbugs...,-1,0.9930106997489929
95306070,2264,cmccabe,2017-01-10T06:23:54Z,k,0,0.934664785861969
95306078,2264,cmccabe,2017-01-10T06:23:59Z,k,0,0.934664785861969
95306086,2264,cmccabe,2017-01-10T06:24:06Z,yeah,0,0.9002789258956909
95306094,2264,cmccabe,2017-01-10T06:24:11Z,ok,0,0.8787186145782471
95306102,2264,cmccabe,2017-01-10T06:24:17Z,yeah,0,0.9002789258956909
95306242,2264,cmccabe,2017-01-10T06:26:07Z,"hmm. i think if it were just newrequest, i would wonder whether it was a new abstractrequest or a new clientrequest. what do you think?",0,0.728606641292572
95306249,2264,cmccabe,2017-01-10T06:26:14Z,ok,0,0.8787186145782471
95306275,2264,cmccabe,2017-01-10T06:26:38Z,i added a comment,0,0.9567638635635376
95306664,2264,cmccabe,2017-01-10T06:32:08Z,k,0,0.934664785861969
95307070,2264,cmccabe,2017-01-10T06:37:05Z,"hmm, i didn't see any code path where the return value could be null, or the value of the future itself, or the keys or values of the map. maybe an npe is ok in that case?",0,0.9540945291519165
95307372,2264,cmccabe,2017-01-10T06:40:56Z,"i wanted to avoid confusion with the public api of that name. how about ""retrieveoffsetsbytimes""?",0,0.9024178385734558
95307500,2264,cmccabe,2017-01-10T06:42:28Z,"good catch. i made some other edits to the for loop, but they're no longer necessary now. reverted",1,0.959710419178009
95308523,2264,cmccabe,2017-01-10T06:54:58Z,"i think abstractresponse should have a version number in it, since the data it contains varies based on the version. sometimes the interpretation of the data varies based on version as well. it's a property of the response and it belongs in the response object. but hopefully we can hold off on that for now since this patch is kinda big as-is...",0,0.9659238457679749
95308701,2264,cmccabe,2017-01-10T06:57:14Z,"yeah, let's leave the function name out. will use string interpolation",0,0.9842445254325867
95309085,2264,cmccabe,2017-01-10T07:02:05Z,"you are right that the general pattern is that constructor arguments are required, other things are optional. ideally we would have listoffsetrequest#builder(map ) and listoffsetrequest#builder(map ), but we can't do that because of a java limitation... both constructors would have the same type once type erasure has been performed, which is not allowed.",0,0.9865887761116028
95309234,2264,cmccabe,2017-01-10T07:03:58Z,"braces seem a little more familiar to me because of json. but if parentheses are the way to go, i can change it. it's a big change though since all the builders have a tostring. are we sure we want the parens?",0,0.9381521940231323
95324930,2264,ijuma,2017-01-10T09:19:53Z,i was debating that myself before writing the comment. let's leave it as is then.,0,0.9228739738464355
95342279,2264,ijuma,2017-01-10T11:04:44Z,"oh, i see. the compiler is correct in not allowing that then. one way to fix that is to change the definition of `builder` to be: [code block] but this makes it more awkward to use the abstract builder directly due to the additional type parameter (in scala we could use type members instead). an alternative is to override `setbuilder` in each builder and use the more specific type there. it's a bit annoying, but builders are supposedly used more times than they are defined.",-1,0.9717410206794739
95342721,2264,ijuma,2017-01-10T11:07:32Z,"the broker assumes that all requests are consistent with regards to the common request header elements. if we set the minimum versions correctly, we should be in the clear, i think. it would be good to have a test for 0.9.0.1, but we can do that in a follow-up.",0,0.9913472533226013
95343648,2264,ijuma,2017-01-10T11:13:53Z,"i think i prefer `unsupportedbrokerversion`. but it's subjective and `obsolete`/`outdated` are more explicit with regards that you want a newer broker. another point: if we think of the protocol as something independent from kafka (i.e. there could be other implementations), which is something that jay thinks we should, then `unsupportedbrokerversion` also seems better.",0,0.9850081205368042
95344394,2264,ijuma,2017-01-10T11:19:23Z,"there are indeed a few ways to do this. we tend to follow the `foo(a=""a"",b=""b"")` model and this is what public classes like `producerrecord` and `consumerrecord` do. also, it's worth saying that, outside of loops, `stringbuilder` is no better than string concatenation with regards to performance. up to java 8, javac will do the stringbuilder thing itself. from java 9, invokedynamic will be used to allow the runtime to choose the best strategy ([a link] my suggestion is to clean this up in a subsequent pr. it can even be done after the feature freeze.",0,0.9789736866950989
95358669,2264,ijuma,2017-01-10T13:01:34Z,", there is a comment already a couple of lines above (i asked ashish to add it as part of kafka-3600): [code block] maybe we can move the comment so that it's closer to the request creation.",0,0.9944003224372864
95358836,2264,ijuma,2017-01-10T13:02:45Z,"it's a bit odd that we add a hardcoded prefix and suffix in a generic `join` method. typically, these would be parameters and the default case would be no prefix or suffix (consistent with `join` that takes a `collection`).",-1,0.5664560794830322
95359080,2264,ijuma,2017-01-10T13:04:29Z,nit: space missing before `:`.,0,0.9745855927467346
95359283,2264,ijuma,2017-01-10T13:05:52Z,", have we tested with ssl enabled?",0,0.9936327338218689
95363623,2264,ijuma,2017-01-10T13:33:37Z,nit: `1: short` is a little better because it will fail to compile if the conversion is not possible where `toshort` will happily overflow. doesn't make a difference in these particular cases though.,0,0.9595356583595276
95368726,2264,ijuma,2017-01-10T14:04:14Z,nit: `0: java.lang.long` is a tiny bit shorter.,0,0.9718866348266602
95369472,2264,ijuma,2017-01-10T14:08:50Z,i think it would be worth adding an overload without the `callback` as it's optional and many callers don't need it.,0,0.9880015254020691
95370437,2264,ijuma,2017-01-10T14:14:21Z,this is unused.,0,0.8475880026817322
95373680,2264,ijuma,2017-01-10T14:31:44Z,i think is thinking of the case where `ret.get(partition)` returns `null`. not sure if we are enforcing that elsewhere though.,0,0.9559130072593689
95376734,2264,ijuma,2017-01-10T14:46:19Z,"typo, `r` missing.",0,0.9766820669174194
95378574,2264,ijuma,2017-01-10T14:54:01Z,nit: i think this is harder to read by being split into 3 lines like this. looks like a staircase. ;) there's one other case like that.,1,0.9908043146133423
95379773,2264,ijuma,2017-01-10T14:59:28Z,change `versionid` to `short` like you did in other places?,0,0.9951503872871399
95394973,2264,ijuma,2017-01-10T16:01:54Z,it looks like we only need to support `2` and above: [a link],0,0.9909351468086243
95397340,2264,ijuma,2017-01-10T16:11:14Z,should we be validating that version is always `1`? version `0` would probably mean that something is wrong.,0,0.9908387064933777
95398519,2264,ijuma,2017-01-10T16:16:08Z,in other request classes we don't throw an exception in case the version is higher than expected. we should be consistent. i think this approach is good because it forces people to consider how to handle a new version when it's introduced.,0,0.9263521432876587
95399367,2264,ijuma,2017-01-10T16:19:57Z,i think we should set it to `-1` in this case to make it clear that it won't be used as we have the following: [code block],0,0.9928072690963745
95400451,2264,ijuma,2017-01-10T16:24:42Z,we have 3 `getversion` calls. one should be enough.,0,0.9889094233512878
95402987,2264,ijuma,2017-01-10T16:35:38Z,parenthesis are not needed here or the other branches since a single value is being returned now.,0,0.9878267645835876
95403350,2264,ijuma,2017-01-10T16:37:05Z,nit: should be `fetchdata()`.,0,0.9918332099914551
95403601,2264,ijuma,2017-01-10T16:38:06Z,nit: there should be a space before `:`.,0,0.9877651929855347
95403993,2264,ijuma,2017-01-10T16:39:51Z,"personally, i think `short` and `null` for no usable version is less error-prone (you'll get a npe if you accidentally try to use it instead of ending with a `-1` somewhere it should not be).",0,0.9499807357788086
95404122,2264,ijuma,2017-01-10T16:40:22Z,seems like this comment should be in the method documentation.,0,0.9890986680984497
95404878,2264,ijuma,2017-01-10T16:43:20Z,why not use `enummap `? it would be more readable imo.,0,0.9937049746513367
95405837,2264,ijuma,2017-01-10T16:47:11Z,can this ever be less than 0?,0,0.9794878363609314
95405971,2264,ijuma,2017-01-10T16:47:48Z,`math.min` and 4 lines become 1?,0,0.9937198162078857
95406464,2264,ijuma,2017-01-10T16:50:01Z,this `tostring` is quite long. :) it would be nice to break it down into smaller methods so that it's easier to understand.,1,0.9959254264831543
95407688,2264,ijuma,2017-01-10T16:55:15Z,"any reason we are using `linkedlist` instead of `arraylist`? we seem to be adding to the end, iterating and then clearing (after jason's suggestion), so `arraylist` seems like the better option.",0,0.9908987283706665
95409034,2264,ijuma,2017-01-10T17:01:28Z,"it would be good to include the most current version in this message as well. also, as jun said it may be a good to log at a higher level if we are downgrading a request. not sure what jun had in mind, but maybe `debug`?",0,0.9887287616729736
95410187,2264,ijuma,2017-01-10T17:06:45Z,we have the following code for failed metadata requests: [code block] should we be doing similarly for this case (since we now do `apiversionsrequest` before `metadatarequest`)?,0,0.994988203048706
95410941,2264,ijuma,2017-01-10T17:10:14Z,`now` is no longer used,0,0.9896014332771301
95411451,2264,ijuma,2017-01-10T17:12:49Z,"we are now doing `apiversions` unconditionally. this means that 0.10.2 brokers won't be able to talk to 0.9.0.x brokers, right? we shouldn't do that.",0,0.9656210541725159
95418264,2264,cmccabe,2017-01-10T17:45:59Z,"hmm. just to clarify, you think that throwing the exception when we see an unexpected version is the right way to go? i can add that to the other requests if so.",0,0.9571884274482727
95418858,2264,cmccabe,2017-01-10T17:48:52Z,the other versions are used in unit tests. the server also can handle them to support older clients.,0,0.9928373694419861
95419171,2264,cmccabe,2017-01-10T17:50:25Z,"i wanted to do this, but it got messy. the problem is that there are a bunch of unit tests that are using reflection to call these methods-- and also some scala code. i think we should have a follow-on jira for converting the parse() methods to use 'short' for version.",-1,0.6052398681640625
95419258,2264,cmccabe,2017-01-10T17:50:53Z,k,0,0.934664785861969
95419528,2264,cmccabe,2017-01-10T17:52:23Z,that's a good point. what do you suggest? one approach is to (re)add a constructor parameter to networkclient that will allow the brokers to bypass sending apiversions.,0,0.6279299259185791
95438375,2264,cmccabe,2017-01-10T19:27:44Z,k,0,0.934664785861969
95438824,2264,cmccabe,2017-01-10T19:29:50Z,i fixed it to be an exception instead,0,0.9771910905838013
95440180,2264,hachikuji,2017-01-10T19:36:18Z,i doubt it would add much to the size of this patch if you want to do it here. a follow-up would work as well. i'm anxious to have a good general approach in place so that we have clear patterns to follow going forward.,-1,0.9188820123672485
95442388,2264,cmccabe,2017-01-10T19:47:17Z,"from a user point of view, unsupportedbrokerversion is that it doesn't make it clear whether the broker version is too new or old. it also suggests that the whole broker is unsupported, whereas just this one api is unsupported. hmm. it seems like we could still have other implementations of the protocol even if we used outdatedbrokerexception / obsoletebrokerexception? i'm open to ideas on this. i would kind of like something that gives the user a clear hint that they need to upgrade...",0,0.6787661910057068
95443442,2264,cmccabe,2017-01-10T19:52:32Z,"ah, good point. let me add a check for that just to be safe. after all, this data is coming over the wire, so we should not unconditionally trust it.",1,0.8249741792678833
95445212,2264,hachikuji,2017-01-10T20:02:02Z,note there was a previous comment about using `arraylist` instead of `linkedlist`.,0,0.9932382106781006
95449880,2264,cmccabe,2017-01-10T20:27:07Z,k,0,0.934664785861969
95450837,2264,cmccabe,2017-01-10T20:32:37Z,"yeah, it would be good to have a clear pattern here. let's do it in a follow-on.",0,0.9478374719619751
95452015,2264,cmccabe,2017-01-10T20:39:34Z,"hmm. cansendrequest should be making sure that the ssl handshake is complete, right? call stack: [code block] kafkachannel#ready has: [code block]",0,0.9883973002433777
95452301,2264,cmccabe,2017-01-10T20:41:17Z,: i'll parameterize our ducktape tests for client compat with ssl,0,0.9871102571487427
95458316,2264,cmccabe,2017-01-10T21:13:47Z,renamed to utils#mkstring and made this optional with function overloads.,0,0.994610071182251
95463538,2264,ijuma,2017-01-10T21:40:30Z,this should be `setversion(version)` i think.,0,0.9935784339904785
95465642,2264,hachikuji,2017-01-10T21:50:26Z,sounds reasonable to me.,0,0.9698968529701233
95466268,2264,hachikuji,2017-01-10T21:53:37Z,nit: string interpolation,0,0.9807521104812622
95466619,2264,hachikuji,2017-01-10T21:55:35Z,probably more helpful to convert the error code to an instance of `errors` and use `message()`. even better would be to have `apiversionsresponse` use a field of type `errors` instead of a short.,0,0.9938575625419617
95468151,2264,hachikuji,2017-01-10T22:03:47Z,"nit: the `tostring()` is not needed, right?",0,0.9342831373214722
95468429,2264,hachikuji,2017-01-10T22:05:28Z,i was thinking about this a little more. i wonder if we could just change the key type to string to make it consistent with `nodesneedingapiversionsfetch`?,0,0.9292197823524475
95469545,2264,hachikuji,2017-01-10T22:11:46Z,could we have this accept an `apikeys` instance instead of short? then we wouldn't need the check for a negative api key. also would be nice to document what exactly this method is returning. is it the largest version supported by both the client and server?,0,0.9859225749969482
95471626,2264,hachikuji,2017-01-10T22:23:31Z,"typo: ""reponse""",0,0.9883239269256592
95471877,2264,hachikuji,2017-01-10T22:25:04Z,i think i had a comment before about moving this check into `consumernetworkclient.requestfuturecompletionhandler`.,0,0.988685131072998
95472157,2264,hachikuji,2017-01-10T22:26:54Z,"to be clear, if the broker doesn't support this then we'll raise `obsoletebrokerexception`? i wonder if that handling is consistent with the behavior when the broker is up to date, but has an old message format version. it seems our handling of the `unsupported_for_message_format` is to add a null entry to the result. maybe we should do the same?",0,0.987647294998169
95472929,2264,hachikuji,2017-01-10T22:31:10Z,would we ever return a negative offset to the user?,0,0.9864984750747681
95473004,2264,hachikuji,2017-01-10T22:31:35Z,nit: move to previous line,0,0.9383642077445984
95473512,2264,hachikuji,2017-01-10T22:34:31Z,another suggestion: `incompatibleprotocolversion`?,0,0.9904643297195435
95475950,2264,hachikuji,2017-01-10T22:49:21Z,seems the only usage is internal to `networkclient`. maybe we could just use the variable directly?,0,0.9930776357650757
95477354,2264,ijuma,2017-01-10T22:57:56Z,"also, is `discoverpeerversions` the right name? seems like it should be `discoverbrokerversions` as `networkclient` is also used by clients.",0,0.994140088558197
95477481,2264,cmccabe,2017-01-10T22:58:42Z,"ok, i added a constructor parameter and a unit test. thanks for catching this!",1,0.9786401987075806
95477659,2264,ijuma,2017-01-10T22:59:44Z,"are the comments inside the if/else adding anything over what the code does? to me, they seem to say exactly the same thing as the code.",0,0.9569805264472961
95479078,2264,cmccabe,2017-01-10T23:09:16Z,k,0,0.934664785861969
95479437,2264,cmccabe,2017-01-10T23:11:52Z,"for some reason, there is no math.min(short, short), only math.min(int, int). i could use the int version with a typecast, but i thought the cast was ugly.",-1,0.9340973496437073
95479552,2264,cmccabe,2017-01-10T23:12:44Z,k,0,0.934664785861969
95480087,2264,cmccabe,2017-01-10T23:16:37Z,k,0,0.934664785861969
95480896,2264,cmccabe,2017-01-10T23:22:12Z,k,0,0.934664785861969
95481038,2264,cmccabe,2017-01-10T23:23:07Z,ok. will leave it as toshort here since the typecast is kind of annoying visually (edit: it's an ascription) ;),1,0.7685297727584839
95481685,2264,cmccabe,2017-01-10T23:28:03Z,"not really, can remove",0,0.7978971004486084
95482457,2264,hachikuji,2017-01-10T23:33:37Z,seems this field could be final. might be worth a pass over the other request types to locate other fields that could be final.,0,0.97797691822052
95482720,2264,hachikuji,2017-01-10T23:35:25Z,this seems unneeded.,-1,0.5531189441680908
95483218,2264,hachikuji,2017-01-10T23:39:11Z,"it would be nice to be consistent about whether a field should be included in the constructor or whether it should have a setter. i don't know that we have any cases that call for mutating a field that was initialized in the constructor, so i would prefer to just leave off the setters in that case and make the field final.",0,0.9690199494361877
95483731,2264,cmccabe,2017-01-10T23:43:13Z,"oops, sorry, i meant to reply but i closed the browser window. arraylist seems like overkill here since we don't expect a lot of aborted sends to happen. also, the memory consumed by arraylist only grows and never shrinks (unless you call trimtosize), which seems like a bad choice here.",-1,0.9891101717948914
95483834,2264,cmccabe,2017-01-10T23:43:59Z,k,0,0.934664785861969
95484012,2264,cmccabe,2017-01-10T23:45:13Z,ok,0,0.8787186145782471
95484274,2264,cmccabe,2017-01-10T23:47:15Z,"yeah, let's use errors to get the error enum. can refactor further later",0,0.9786059260368347
95484396,2264,cmccabe,2017-01-10T23:48:10Z,"true, it should be called implicitly",0,0.9878128170967102
95484656,2264,cmccabe,2017-01-10T23:49:56Z,good ideas. done,1,0.9935710430145264
95484862,2264,cmccabe,2017-01-10T23:51:24Z,"i don't understand what you mean by ""the broker is up to date, but has an old message format version"".",0,0.6065220236778259
95484986,2264,cmccabe,2017-01-10T23:52:18Z,"right, i have been looking at that. thinking of doing it in a follow-on jira since i will need to take a deeper look at the rpc paths when doing that",0,0.9730650782585144
95485081,2264,cmccabe,2017-01-10T23:53:03Z,k,0,0.934664785861969
95485096,2264,cmccabe,2017-01-10T23:53:08Z,no,0,0.8846297860145569
95485142,2264,cmccabe,2017-01-10T23:53:26Z,k,0,0.934664785861969
95486629,2264,hachikuji,2017-01-11T00:05:59Z,"i'm thinking of the case where the broker doesn't support v1 of listoffsets. for this case, i think we currently raise `obsoletebrokerexception`. i am questioning whether it would be more consistent to return a null entry in this case in the result of `offsetsfortimes`. currently it is possible for the broker to support the new api version, but not the message format version which is needed to answer the query. in this case, we return a null entry.",0,0.9648969769477844
95488513,2264,ijuma,2017-01-11T00:20:08Z,"well, the `arraylist` array would expand to 10 elements the first time an aborted send is added. and then, it will probably never grow beyond that. linkedlist in java is just not a very good collection in general. each node has 3 references and there is a node instance per item. a funny tweet by joshua bloch: "" does anyone actually use linkedlist? i wrote it, and i never use it."" [a link]",1,0.9200413823127747
95489336,2264,ijuma,2017-01-11T00:26:51Z,i asked colin to add this point to the follow-up jira.,0,0.988287627696991
95490172,2264,ijuma,2017-01-11T00:33:36Z,we should not have it in the javadoc then as this is a class that is exposed to users.,0,0.9936874508857727
95504733,2264,junrao,2017-01-11T03:03:06Z,"in the patch, it seems that once a channel is connected, but is not necessarily ready, networkclient can start issuing apirequest. this can fail if transport is ssl and transportlayer.ready() is false. it's also too late to only start issuing apirequest after channel is ready since the apirequest should be sent before sasl handshake (sasl handshake completes when authenticator.complete() is true). what the networkclient is supposed to do is only start issuing apirequest after transportlayer.ready() is true. it's just that currently, this state is no propagated by selector.",0,0.9904288053512573
95506134,2264,ijuma,2017-01-11T03:23:02Z,"i'm not sure what you mean when you say that the patch starts issuing apiversions request before transport layer is ready: [code block] isn't that ok (we call `selector.ischannelready(node)`)? the point about sasl. the outcome of the discussion in the pr for kafka-3600 was that we don't have to send the api versions request before the sasl request for now since there's only one version of the saslhandshake request. if we ever introduce an additional version, we can change the client at the same time. it seems like there's no downside to this since brokers will have to keep supporting the old sasl handshake request anyway. do you feel differently?",0,0.976321280002594
95507893,2264,junrao,2017-01-11T03:50:34Z,": yes, i missed the selector.ischannelready(node) check. so, this is fine. about the sasl, that's reasonable. we can keep the changes in the pr as they are.",0,0.8459550738334656
95579492,2264,ijuma,2017-01-11T13:41:57Z,"i submitted a pr that removes unused setters, makes fields final and tries to make things a bit more regular. makes it a bit simpler, but more could be done probably.",0,0.9837733507156372
95579966,2264,ijuma,2017-01-11T13:44:52Z,", this one seems important to resolve before merging.",0,0.9863218069076538
95582701,2264,ijuma,2017-01-11T14:01:03Z,i've done this in my pr.,0,0.9835993051528931
95582725,2264,ijuma,2017-01-11T14:01:11Z,removed in my pr.,0,0.9858958125114441
95582772,2264,ijuma,2017-01-11T14:01:25Z,fixed in my pr.,0,0.9863627552986145
95582876,2264,ijuma,2017-01-11T14:02:06Z,the server doesn't use the builder so i think that would be ok. but let's leave it for now.,0,0.9663132429122925
95582919,2264,ijuma,2017-01-11T14:02:21Z,"yes, but let's consider that in a separate pr.",0,0.9906538128852844
95583125,2264,ijuma,2017-01-11T14:03:35Z,changed in my pr.,0,0.9872023463249207
95583846,2264,ijuma,2017-01-11T14:07:42Z,i did this for a bunch of builders in my pr.,0,0.9615304470062256
95638931,2264,hachikuji,2017-01-11T18:21:36Z,can you address this comment please?,0,0.9908499717712402
95641786,2264,cmccabe,2017-01-11T18:35:12Z,done,0,0.8974218964576721
95641982,2264,cmccabe,2017-01-11T18:36:01Z,sounds good,1,0.9683692455291748
1290585581,14182,jeffkbkim,2023-08-10T19:23:36Z,i would include the priorities when considering uniform vs. sticky vs. rack-aware,0,0.9933172464370728
1290588764,14182,jeffkbkim,2023-08-10T19:27:03Z,"is ""expected"" in the name bring necessary?",0,0.9937974810600281
1290589362,14182,jeffkbkim,2023-08-10T19:27:44Z,"is this ""remaining number of partitions""?",0,0.9891523122787476
1290591418,14182,jeffkbkim,2023-08-10T19:30:04Z,i don't think we need this comment,0,0.6053839325904846
1290591834,14182,jeffkbkim,2023-08-10T19:30:34Z,how's `previousowners`?,0,0.991740345954895
1290610215,14182,jeffkbkim,2023-08-10T19:49:17Z,why is all of this under the constructor?,0,0.9746406078338623
1290610669,14182,jeffkbkim,2023-08-10T19:49:49Z,nit: can we match the argument ordering?,0,0.9897375702857971
1290611774,14182,jeffkbkim,2023-08-10T19:51:09Z,"`buildassignment()` makes more sense. also, this should be an abstract method under `uniformassignor`",0,0.9944948554039001
1290636312,14182,jeffkbkim,2023-08-10T20:17:29Z,i'm noticing a pattern where we are using class variables when they can just be method variables. we should aim to use the smallest scope for all variables.,0,0.8305537700653076
1290763071,14182,rreddy-22,2023-08-10T23:12:48Z,including balance >rack>stickiness,0,0.9903864860534668
1290763624,14182,rreddy-22,2023-08-10T23:13:54Z,"yeah because the extra partitions haven't been assigned yet, i'm just taking a count of how many are expected to get the extra partition",0,0.9451566934585571
1290764909,14182,rreddy-22,2023-08-10T23:16:54Z,"i think this name makes it clear that its a map, if we just used previousowners, its not clear whose previous owner right. we would then have to name it previouspartitionowners, which is kinda the same as partitiontopreviousowner?",0,0.9795223474502563
1290765488,14182,rreddy-22,2023-08-10T23:18:12Z,"any computations required to initialise the global attributes are done in this constructor, similar to the other existing assignors",0,0.9935064315795898
1290766391,14182,rreddy-22,2023-08-10T23:20:13Z,done,0,0.8974218964576721
1290813322,14182,jeffkbkim,2023-08-11T01:14:50Z,"`nummemberswithextrapartition` : number of members to get the extra partition, no? there is no expected vs. actual though, we always distribute that number",0,0.990304172039032
1290813753,14182,jeffkbkim,2023-08-11T01:16:00Z,"it is implied by the type that the previous owners are keyed by topicidpartition. like how we are using `potentiallyunfilledmembers`, `unfilledmembers`, or `newassignment`",0,0.9939019680023193
1290880471,14182,rreddy-22,2023-08-11T04:25:37Z,"its typically called as assignor.build so i thought that makes it kinda clear that its building the assignment, and the return value also specifies the same",0,0.9674288034439087
1290880628,14182,rreddy-22,2023-08-11T04:25:58Z,"changed a few of them, rest we discussed on call",0,0.9827349781990051
1291715874,14182,jeffkbkim,2023-08-11T19:39:09Z,nit: `alltopicidpartitions` and newline each argument,0,0.9880875945091248
1291716306,14182,jeffkbkim,2023-08-11T19:39:46Z,nit: allsubscriptionsequal,0,0.9396674633026123
1291718703,14182,jeffkbkim,2023-08-11T19:43:22Z,"nit: ``` public groupassignment assign( assignmentspec assignmentspec, subscribedtopicdescriber subscribedtopicdescriber ) throws partitionassignorexception {",0,0.9933426976203918
1291718960,14182,jeffkbkim,2023-08-11T19:43:43Z,nit: new line each argument,0,0.9645821452140808
1291724906,14182,jeffkbkim,2023-08-11T19:52:45Z,this and `parttiionracks` can be initialized as empty collections. then we just handle the case where `!membersbyrack.isempty()`,0,0.9949144124984741
1291729367,14182,jeffkbkim,2023-08-11T19:59:06Z,can you explain why we need to create `membersbyrack` then transform it to `memberracks`? can't we just create `memberracks` from the start?,0,0.9948712587356567
1291731843,14182,rreddy-22,2023-08-11T20:02:51Z,yeah my point was that nummemberswithextrapartition sounds like the members already have the extra partition but its actually a number of how many members we expect to have an extra and this number keeps decreasing as we assign the partitions.,0,0.9645521640777588
1291732541,14182,rreddy-22,2023-08-11T20:03:44Z,okay i'll rename it,0,0.9811567068099976
1293887191,14182,jeffkbkim,2023-08-14T19:32:12Z,we can move this to l93 and remove the else block,0,0.9918027520179749
1293887893,14182,jeffkbkim,2023-08-14T19:33:01Z,"can we use `this.classvariable = ...` for all the class scoped variables in the constructor? also, don't we get a nosuchelementexception if the iterator is empty? (do we test this case) lastly, we can just use the first member's subscribed topic ids because we know all members are subscribed to the same topics right?",0,0.9933009147644043
1293888288,14182,jeffkbkim,2023-08-14T19:33:30Z,do we need this variable?,0,0.9897464513778687
1293889620,14182,jeffkbkim,2023-08-14T19:35:13Z,i think a debug log should suffice. logs will get flooded if a topic metadata changes,0,0.9846515655517578
1293893418,14182,jeffkbkim,2023-08-14T19:38:31Z,should we move this to the top of the method?,0,0.9938183426856995
1293898405,14182,jeffkbkim,2023-08-14T19:42:34Z,can we use `minquota = totalpartitionscount / numberofmembers;` and do we need to declare and initialize separately?,0,0.9955083131790161
1293910818,14182,jeffkbkim,2023-08-14T19:57:07Z,do we need this? we can iterate through a set,0,0.9757424592971802
1293913755,14182,jeffkbkim,2023-08-14T20:00:36Z,we can remove the parentheses,0,0.9849948287010193
1294009242,14182,jeffkbkim,2023-08-14T22:00:23Z,"this will iterate through the entire list. let's instead use a set to store subscriptions. also, if the subscription list does not contain the topic id, should we throw an illegal state exception? every topic id from the assigned partitions should exist in the subscription list right",0,0.991533100605011
1294021888,14182,jeffkbkim,2023-08-14T22:19:36Z,"how's `retainedcurrentassignment`? in kafka, we don't use `get` in method names.",0,0.9900216460227966
1294034638,14182,jeffkbkim,2023-08-14T22:42:29Z,`k` --> `__`,0,0.9901067614555359
1294037874,14182,jeffkbkim,2023-08-14T22:47:31Z,ditto,0,0.9222367405891418
1294047232,14182,jeffkbkim,2023-08-14T23:07:04Z,can we `continue` here instead of using `assigned` variable?,0,0.9947180151939392
1294051623,14182,jeffkbkim,2023-08-14T23:16:44Z,let's use streams api when possible [code block],0,0.9853429794311523
1294052212,14182,jeffkbkim,2023-08-14T23:18:06Z,"let's use streams api (foreach, intstream.foreach)",0,0.989467203617096
1294054650,14182,jeffkbkim,2023-08-14T23:23:29Z,"this is implying we will be assigning an extra partition for this member right? how come we don't ""assign"" it here?",0,0.9823431372642517
1294062365,14182,jeffkbkim,2023-08-14T23:40:50Z,why can't we just create a new arraylist and add the ones where count > 0?,0,0.9888488054275513
1294064001,14182,jeffkbkim,2023-08-14T23:44:19Z,you can use getordefault,0,0.9902217388153076
1294068788,14182,jeffkbkim,2023-08-14T23:55:16Z,assignpartitiontomemberandupdateunfilledmembers it's hard to assume the side effects when looking at the existing name,0,0.9897617697715759
1294068919,14182,jeffkbkim,2023-08-14T23:55:35Z,i think we can use map#compute here right,0,0.9768908023834229
1294069200,14182,jeffkbkim,2023-08-14T23:56:10Z,we can break out of the for loop instead of using assigned here,0,0.9924667477607727
1294076876,14182,jeffkbkim,2023-08-15T00:14:57Z,why do we need to remove here,0,0.962681233882904
1294086512,14182,jeffkbkim,2023-08-15T00:38:49Z,"what i don't like about this approach is that the reader needs to know 2 things: 1. unfilledmembers (member -> remaining partition count) only exists when the count is > 0. 2. assignpartitiontomember removes a member from unfilledmembers if the count is 0 after decrementing or else we don't know whether this for loop will end. also i have not seen a for loop where we add something to the original collection we are iterating through. i think `while (!queue.isempty())` should be more readable. also, if there is a bug somewhere and for some reason the sum of all unfilledmembers` partition counts is greater than sortedpartitions size then we could have an infinite loop since there will be a member that still needs partitions to be assigned. we should add this check somewhere",0,0.6548193097114563
1294086912,14182,jeffkbkim,2023-08-15T00:39:55Z,do we need this?,0,0.9819303154945374
1294086965,14182,jeffkbkim,2023-08-15T00:40:02Z,do we need this?,0,0.9819303154945374
1294087718,14182,jeffkbkim,2023-08-15T00:42:11Z,ditto on using continue,0,0.8267046809196472
1294087923,14182,jeffkbkim,2023-08-15T00:42:45Z,how come we iterate on unfilledmembers instead of roundrobinmembers as in `rackawarerounrobinassignment`? this looks like a bug; can we add a test that breaks this,0,0.9835233092308044
1294088129,14182,jeffkbkim,2023-08-15T00:43:19Z,ditto on using a while loop,0,0.9834064841270447
1295197016,14182,rreddy-22,2023-08-15T22:21:32Z,changed to something else,0,0.9732366800308228
1295198962,14182,rreddy-22,2023-08-15T22:22:32Z,this shouldn't even happen at all so that's why its a warning. this case is handled by the target assignment builder,0,0.9917435050010681
1296343128,14182,jeffkbkim,2023-08-16T19:31:45Z,"if a topic is deleted, how does the target assignment builder handle it?",0,0.9916118383407593
1300462035,14182,rreddy-22,2023-08-21T17:52:49Z,"collections.emptymap is immutable though right, ig a better option would be to initliaze them as new hashmaps",0,0.98350590467453
1300620312,14182,rreddy-22,2023-08-21T20:36:34Z,"we check if rack aware assignment is possible i.e if partition racks and member racks exist and whether there's any intersection between the two sets, only then we assign the memberracks which is final.",0,0.9944291114807129
1300622597,14182,rreddy-22,2023-08-21T20:39:02Z,the code actually does just use the first members subscribed topic ids,0,0.9910627603530884
1300627015,14182,rreddy-22,2023-08-21T20:44:16Z,"that depends if the members map can be empty i guess which i think is checked before, it definitely can't be null",0,0.9728947877883911
1300631692,14182,rreddy-22,2023-08-21T20:50:14Z,"if a topic is deleted then it's basically the case where the topic doesn't exist in the topic metadata, it is just simply left off the subscription list before its sent to the assignor.",0,0.9872455596923828
1300633100,14182,rreddy-22,2023-08-21T20:52:07Z,we can't cause we might remove topics from the list just in case there's members subscribed to topics that don't exist in the topic metadata,0,0.9751197695732117
1300633833,14182,rreddy-22,2023-08-21T20:53:05Z,i wanted to keep them in just to segregate the replicaracks parts,0,0.9765388369560242
1300637770,14182,rreddy-22,2023-08-21T20:58:04Z,"not necessarily, since there could be partitions belonging to old subscriptions or topics that don't exist anymore and we don't need them anymore aka they're not valid anymore which is fine. mentioned in the javadoc",0,0.9808897972106934
1300779466,14182,rreddy-22,2023-08-22T00:25:27Z,"its not retained cause we didn't decide if we wanna keep it yet, that's decided in assignstickypartitions. this is just getting the valid assignment in terms of if the partitions are still part of the subscription topics and also if the racks don't match then we just store the prev owner info for the future",0,0.9919795989990234
1300780584,14182,rreddy-22,2023-08-22T00:27:40Z,i don't understand what's the change?,0,0.5017666220664978
1303273451,14182,rreddy-22,2023-08-23T16:29:35Z,"so there's potentially unfilled members which includes members that have remaining number of partitions to receive as >=0, i.e there could be members that have met the quota but are eligible to receive an extra partition. what i'm doing in this step is increasing the remaining count if there's still a possibility that a member could receive an extra partition. if the remaining count is still > 0 after that we add it to the unfilled members list.",0,0.9822367429733276
1303299811,14182,rreddy-22,2023-08-23T16:54:38Z,"isn't it kinda expected that if i assign a partition to a member from the unfilled map and the remaining value is updated aka reduced by 1, and it's removed from the map if it isn't unfilled anymore.",0,0.9797627329826355
1303309866,14182,rreddy-22,2023-08-23T17:04:30Z,"i still have to update the rr members after assigning the partition, i can't break within this if statement right.",0,0.9563706517219543
1305945556,14182,rreddy-22,2023-08-25T17:26:18Z,discussed offline that this isn't possible,0,0.7094790935516357
1305948679,14182,rreddy-22,2023-08-25T17:29:41Z,we can't use continue cause there's multiple other steps after that which need to be executed before we exit the loop,0,0.9881411790847778
1305956396,14182,rreddy-22,2023-08-25T17:37:07Z,"we are iterating over the roundrobin members, we're just using the size of all the unfilled members so that we do at least n number of iterations",0,0.9855390787124634
1305957286,14182,rreddy-22,2023-08-25T17:37:44Z,discussed offline that this isn't possible,0,0.7094790935516357
1305998324,14182,rreddy-22,2023-08-25T18:13:40Z,while loop instead of for loop?,0,0.9882170557975769
1308056437,14182,jeffkbkim,2023-08-28T23:42:28Z,can we keep rangeassignor changes in a separate pr?,0,0.9942651391029358
1308059442,14182,jeffkbkim,2023-08-28T23:49:03Z,what if the collections are out of order? can we add a test case for this,0,0.9889840483665466
1308060754,14182,jeffkbkim,2023-08-28T23:51:42Z,javadocs,0,0.9833319187164307
1308061244,14182,jeffkbkim,2023-08-28T23:52:48Z,"let's add javadocs for all of the methods below. also, can there be a case where any of the parameters are null? collections#disjoint can throw npe",0,0.9931390881538391
1308061768,14182,jeffkbkim,2023-08-28T23:54:00Z,nit: totopicidpartitions,0,0.9846950173377991
1308061977,14182,jeffkbkim,2023-08-28T23:54:26Z,nit: topicidpartitions,0,0.979345440864563
1308062300,14182,jeffkbkim,2023-08-28T23:55:04Z,change k to __,0,0.988667905330658
1308062948,14182,jeffkbkim,2023-08-28T23:56:30Z,topics,0,0.9434093236923218
1308068063,14182,jeffkbkim,2023-08-29T00:08:19Z,how's [code block] this aligns with the parameters in userackawareassignment,0,0.9942315816879272
1308072483,14182,jeffkbkim,2023-08-29T00:18:02Z,"i think we can do the following here: when initializing membersbyrack in l152, also initialize memberracks. then only set memberracks to collections.emptymap if userackawareassignment is false. then we don't have to do this transformation",0,0.9912801384925842
1308073563,14182,jeffkbkim,2023-08-29T00:20:43Z,nit: memberrack,0,0.9590839743614197
1308074883,14182,jeffkbkim,2023-08-29T00:23:59Z,"can you help me understand which part is rack-aware manner? also, can we add a test case for this?",0,0.9924066662788391
1308075407,14182,jeffkbkim,2023-08-29T00:25:09Z,this looks to be an exact copy of clients/common. can we move that instead?,0,0.9919909834861755
1308077282,14182,jeffkbkim,2023-08-29T00:29:12Z,do we need this change in this pr?,0,0.9934026598930359
1308077407,14182,jeffkbkim,2023-08-29T00:29:30Z,what's this change for?,0,0.9893280863761902
1308077660,14182,jeffkbkim,2023-08-29T00:30:06Z,"nit: we can remove kafka also, can we move this to buildassignment() and direct the reader to the method to see the step by step?",0,0.9948042035102844
1308079903,14182,jeffkbkim,2023-08-29T00:35:27Z,"nit: track it ""as the partition's"" prior owner",0,0.9837116599082947
1308081089,14182,jeffkbkim,2023-08-29T00:38:29Z,i'm wondering whether to have a userackawarestrategy field in rackinfo instead so that we don't have to infer this information here.,0,0.9884994626045227
1308081761,14182,jeffkbkim,2023-08-29T00:39:56Z,"actually, i think we should throw an illegal state exception. since this is not expected to happen",0,0.925590991973877
1308082801,14182,jeffkbkim,2023-08-29T00:42:39Z,why can't we do `final int minquota = totalpartitionscount / numberofmembers;`?,0,0.9941351413726807
1308083274,14182,jeffkbkim,2023-08-29T00:43:51Z,`assignmentspec.members().keyset().foreach(memberid -> ...`,0,0.9927392601966858
1308085281,14182,jeffkbkim,2023-08-29T00:48:43Z,nit: assignedstickypartitions,0,0.8277536630630493
1308086816,14182,jeffkbkim,2023-08-29T00:52:39Z,should we add a debug log indicating that the topic no longer exists in the metadata?,0,0.9950807094573975
1308086969,14182,jeffkbkim,2023-08-29T00:53:04Z,we can move the parentheses around (partition),0,0.9920801520347595
1308087850,14182,jeffkbkim,2023-08-29T00:55:05Z,we don't need this since retainedpartitionscount will be 0 in l178,0,0.9929112792015076
1308088960,14182,jeffkbkim,2023-08-29T00:57:28Z,"""previous"" step might not even need this comment. perhaps ""assign the extra partition if possible"" or something along those lines",0,0.9938961863517761
1308089767,14182,jeffkbkim,2023-08-29T00:59:28Z,nit: assignedstickypartitions,0,0.8277536630630493
1308090172,14182,jeffkbkim,2023-08-29T01:00:20Z,"personally, the word ""all"" does not add much value to variable names. how's `sortedtopics` also, what's the benefit of sorting the topics?",0,0.9863806366920471
1308091012,14182,jeffkbkim,2023-08-29T01:02:22Z,nit: can remove parentheses around (topic),0,0.9886910915374756
1308091211,14182,jeffkbkim,2023-08-29T01:02:52Z,we can inline partitioncount in l377,0,0.9931755661964417
1308093254,14182,jeffkbkim,2023-08-29T01:08:18Z,how's unassignedpartitionssizeequalsremainingassignments,0,0.9784518480300903
1308095670,14182,jeffkbkim,2023-08-29T01:13:56Z,"nit: ""sort"" and ""potential members""",0,0.9920715689659119
1308097288,14182,jeffkbkim,2023-08-29T01:17:54Z,is this a linked list?,0,0.9920666217803955
1308098707,14182,jeffkbkim,2023-08-29T01:19:55Z,`while(!roundrobinmembers.isempty() && !assigned)` is more readable since most for loops do not change the size,0,0.9907614588737488
1308102973,14182,jeffkbkim,2023-08-29T01:28:55Z,ah right. that makes sense,0,0.636909544467926
1308137334,14182,rreddy-22,2023-08-29T02:48:14Z,"lets decide what to do here cause i've also asked david multiple times, i think he said a warning is enough let me double check",0,0.9500950574874878
1308140708,14182,rreddy-22,2023-08-29T02:55:31Z,i feel like a whole pr for minor changes which are kinda related to what i learn from doing the other assignors would be unnecessary especially cause even minor ones take time to go through the review process and stuff. they might just go undone,0,0.6895043253898621
1308143447,14182,rreddy-22,2023-08-29T03:01:34Z,"that's kinda why i used list/set before but i changed it to collections on receiving comments on the interface. but that's a good point, i'll make sure the order doesn't matter",0,0.7542036175727844
1308150557,14182,rreddy-22,2023-08-29T03:18:54Z,"no they can't be null, they are all initialized in rackinfo",0,0.9842979907989502
1308150974,14182,rreddy-22,2023-08-29T03:19:52Z,"i named the method alltopicidpartitions to emphasize that its not a subset, so i feel like we can leave this as alltopicidpartitions as well",0,0.9784372448921204
1308151486,14182,rreddy-22,2023-08-29T03:21:17Z,renamed to alltopicids,0,0.989404559135437
1308152462,14182,rreddy-22,2023-08-29T03:23:48Z,agreed but memberracks and partitionracks are more readable and concise i guess in my opinion so i would leave it like this,0,0.8757774233818054
1308155008,14182,rreddy-22,2023-08-29T03:30:00Z,its a final attribute that why can't assign it twice and i feel like what's the point of initializing it before hand if i'm doing it in an if else block later which guarantees initialization,0,0.9449852705001831
1308164291,14182,rreddy-22,2023-08-29T03:52:16Z,i don't think i understand the question,-1,0.6569968461990356
1308165291,14182,rreddy-22,2023-08-29T03:54:34Z,"it's not haha i would've used that otherwise, this has partition as an integer whereas that has topicpartition (another class) as the attribute in addition to topic id",0,0.5408924221992493
1308165924,14182,rreddy-22,2023-08-29T03:55:52Z,yes because we decided how we want to handle the non existent topic case in this pr and hence this is just a side effect of that,0,0.9915829300880432
1308166084,14182,rreddy-22,2023-08-29T03:56:13Z,"this just keeps happening idky, ignore this file we have to force push it in the end",-1,0.7323395013809204
1308167128,14182,rreddy-22,2023-08-29T03:58:46Z,"i feel like the code pattern has always been to explain what the assignor does at the top instead of at assign/build, and since this is basically the main function of the assignor, it shouldn't make a difference if its at the top explaining what the optimized uniform assignment builder does",0,0.9703570008277893
1308167658,14182,rreddy-22,2023-08-29T03:59:51Z,"since we mentioned partition's up front in the sentence it makes sense that from then onwards ""it"" always refers to the partition",0,0.9941028952598572
1308169146,14182,rreddy-22,2023-08-29T04:03:11Z,makes sense,0,0.9534063935279846
1308171085,14182,rreddy-22,2023-08-29T04:07:48Z,all is mentioned to emphasize that it's all of the members assigned sticky partitions,0,0.9849174618721008
1308172074,14182,rreddy-22,2023-08-29T04:10:08Z,it actually means that the topic is no longer subscribed to by the group but yes that also translates into not being in the topic metadata sometimes,0,0.9831427931785583
1308173102,14182,rreddy-22,2023-08-29T04:12:34Z,why will it be zero?,0,0.9555878639221191
1308173397,14182,rreddy-22,2023-08-29T04:13:20Z,"i feel like its very hard to understand without this comment, just for the sake of anyone trying to understand why i used that index for the extra partition i would leave it in",-1,0.955090343952179
1308174183,14182,rreddy-22,2023-08-29T04:15:04Z,replied before,0,0.9524620771408081
1308174694,14182,rreddy-22,2023-08-29T04:16:12Z,"all means every single topic right, if it was just sorted topics, which/whose topics?",0,0.9778175950050354
1308177084,14182,rreddy-22,2023-08-29T04:21:48Z,it makes sure that all the unassigned partitions are present topic wise and then when we do a rr distribution while assigning these partitions they are distributed more evenly by topic as well,0,0.9931727051734924
1308179490,14182,rreddy-22,2023-08-29T04:26:47Z,total again emphasizes that i'm talking about all the unassigned partitions and all the remaining assignments right? and also since it returns a boolean value doesn't is make sense still,0,0.9480558037757874
1308181709,14182,rreddy-22,2023-08-29T04:31:34Z,"i don't want the loop to run until the roundrobinmembers list is empty though, this could cause an infinite loop. i just want it to go through every member at the very least and then if it doesn't find a member that is suitable then we just move on and the partition might get assigned later",0,0.7821885943412781
1309478048,14182,jeffkbkim,2023-08-30T00:36:34Z,you can't change what's stored in an empty map but you can change which map the variable points to. though it seems fine in this case since we are using streams api and need a final variable,0,0.9872188568115234
1309478864,14182,jeffkbkim,2023-08-30T00:38:35Z,space after `this.`,0,0.9925708174705505
1309479632,14182,jeffkbkim,2023-08-30T00:40:16Z,this can get npe if the members is empty right?,0,0.9654176831245422
1309481820,14182,jeffkbkim,2023-08-30T00:45:47Z,that seems like a big assumption; let's at least add something to the javadocs,0,0.9660430550575256
1309482536,14182,jeffkbkim,2023-08-30T00:47:07Z,can you remind me again why we need to do at least n number of iterations?,0,0.9749031662940979
1309482922,14182,jeffkbkim,2023-08-30T00:48:08Z,ok,0,0.8787186145782471
1309487439,14182,jeffkbkim,2023-08-30T00:57:49Z,"on i don't see which part is ""in a rack-aware manner"" in the code. can we test that the sorting happens as expected",0,0.8936752676963806
1309488516,14182,jeffkbkim,2023-08-30T01:00:25Z,"ah i see. i'm still leaning towards reusing that one, but will leave it up for david to decide",-1,0.5232259035110474
1309488929,14182,jeffkbkim,2023-08-30T01:01:19Z,we should probably fix this..,0,0.9682593941688538
1309489359,14182,jeffkbkim,2023-08-30T01:02:29Z,we have the step by step details at `assign()` for the range assignor right,0,0.9925472140312195
1309492110,14182,jeffkbkim,2023-08-30T01:06:29Z,"i meant if currentassignmentsize is 0, then retainedpartitionscount will be 0 and hence we won't iterate anyways",0,0.9662967920303345
1309493644,14182,jeffkbkim,2023-08-30T01:08:40Z,"not sure why i left this comment, can disregard",0,0.5734884738922119
1309498804,14182,jeffkbkim,2023-08-30T01:16:13Z,"that would make sense if we are using collections that form a subset of all topics somewhere in the code. otherwise it seems redundant i'm not sure i follow. even if the topics weren't sorted, we would still ensure unassigned partitions are present, no? what makes them distribute more evenly?",0,0.8244219422340393
1309500746,14182,jeffkbkim,2023-08-30T01:19:20Z,"""is __ equals __"" is not grammatically correct. if we want to, we can do `is __ equal to __` but i felt that was too long. do we ever have a case where we handle a subset of unassigned partitions? even the variable is called unassignedpartitions",0,0.9322403073310852
1309503692,14182,jeffkbkim,2023-08-30T01:23:50Z,the while loop will still iterate through all members at the very least right? since we poll one every iteration can you help me understand why the while loop can be infinite whereas the for loop cannot?,0,0.9699731469154358
1309504407,14182,jeffkbkim,2023-08-30T01:24:47Z,can we add a test case?,0,0.9923672080039978
1309505394,14182,jeffkbkim,2023-08-30T01:26:18Z,seems like you've changed this to a set. is the comment above still valid?,0,0.992314875125885
1310726962,14182,jeffkbkim,2023-08-30T19:28:56Z,`if (unfilledmembers.containskey(memberid)`,0,0.9942514896392822
1310733452,14182,jeffkbkim,2023-08-30T19:35:51Z,"there are 2 cases i'm concerned about: 1. i == unfilledmembers.size() but roundrobinmembers is not empty. this means we still have members to distribute 2. roundrobinmembers.size() < unfilledmembers.size(): we'll get npe. these 2 cases may not happen in practice, but the code makes it seem they might. this makes it hard to read and reason about.",0,0.5925539135932922
1310797271,14182,jeffkbkim,2023-08-30T20:41:10Z,nit: (member -> ...,0,0.8966580033302307
1310803310,14182,jeffkbkim,2023-08-30T20:47:16Z,"this looks like overkill and i don't think this works. for instance, if `totalassignmentsizesofallmembers.get(i)` keeps increasing by 1, we can have first member start off with 1 then the last member end with 100 if monotonically increasing. can we do a single iteration and track the maximum and minimum size? then we can do `asserttrue((max - min) <= 1)` right for ""partition assigned at most one member"", we can have a map and increment it. then after looping we just check whether the number of topic id partitions equals number of members and that each value is 1 i also wonder if we can add this check to uniformassignor, and run this at the end of `buildassignment()`. then the general assignor can also use this to see if it needs to do another iteration. we will need to add test cases for this",0,0.8649514317512512
1310837682,14182,jeffkbkim,2023-08-30T21:19:41Z,"to confirm my understanding: 1. we assign t1p1 and t2p1 to memberb since they have rack info 2. roundrobin the rest (unassignedpartitions, starting with t1p0) is this correct?",0,0.9923049807548523
1310840406,14182,jeffkbkim,2023-08-30T21:22:35Z,"should we also check rack awareness? (if both partition and member rack exists, check they match)",0,0.9942266941070557
1310843247,14182,jeffkbkim,2023-08-30T21:25:49Z,we should assert computed assignment here,0,0.9920570254325867
1310843639,14182,rreddy-22,2023-08-30T21:26:13Z,"cause we want to iterate through/visit every member at least once, n is the number of members.",0,0.97911137342453
1310845118,14182,jeffkbkim,2023-08-30T21:27:42Z,"i think ""n members m topics"" is understandable and simple. i've noticed other tests follow ""n members subscribed to m topics"". can we unify the format?",0,0.9623432159423828
1310846978,14182,rreddy-22,2023-08-30T21:29:45Z,"its just different formatting and every time i push any changes this file gets modified, i'll change it directly in the end",0,0.9111776947975159
1310868257,14182,jeffkbkim,2023-08-30T21:51:30Z,"is membera assigned t1p0 and t2p0 because there is a replica for t1p0 and t2p0 that have ""rack1""? (from mkmapofpartitionracks) i'm just wondering what the assignment would be if we actually did a successful first assignment where a was in rack1 and b was in rack2.",0,0.9910604357719421
1310869571,14182,jeffkbkim,2023-08-30T21:53:06Z,"t1p0 and t2p0 technically have racks in ""rack1"" right? so they should be both assigned to member b but already met its quota?",0,0.9946164488792419
1310880384,14182,jeffkbkim,2023-08-30T22:04:57Z,"no, we could have removed members from unfilledmembers in the if block above. and if we do so, we would also remove them from roundrobinmembers. since they start with the same members, they will end up with the same members",0,0.9944283962249756
1310892402,14182,rreddy-22,2023-08-30T22:20:42Z,"yeah that's true sorry idr when i changed it, i'll move it",-1,0.9904001355171204
1310897847,14182,rreddy-22,2023-08-30T22:28:40Z,but this is for when currentassignmentsize is non zero,0,0.9914336204528809
1310903635,14182,rreddy-22,2023-08-30T22:36:50Z,"distribute evenly topic wise as well, as in if i distributed partitions in random order its possible that all the partitions from a single topic go to one member only, if i rr a list that goes topic wise i'm distributing each topics partitions evenly",0,0.9833114147186279
1310906983,14182,rreddy-22,2023-08-30T22:41:32Z,"got it, changed it",0,0.9621075391769409
1310919719,14182,rreddy-22,2023-08-30T22:55:28Z,"because we keep adding members back to the round robin queue until the remaining partitions to be received by the member hits 0. therefore, the roundrobinmembers queue will never be empty unless all the partitions are assigned/ all the quotas are met.",0,0.981920063495636
1310920650,14182,rreddy-22,2023-08-30T22:56:41Z,here we might assign all the partitions that have matching racks but there's gonna be other partitions that haven't been assigned yet and therefore the remaining number of partitions to be received by members may not have reached zero yet.,0,0.9887967109680176
1310923371,14182,rreddy-22,2023-08-30T23:00:26Z,can members be empty?,0,0.9928497076034546
1310930694,14182,rreddy-22,2023-08-30T23:11:59Z,the efficiency is the same right? this shows that remaining is greater than zero. i also feel like its safer just incase we have any members with negative or 0 value as remaining,0,0.88155597448349
1310941152,14182,rreddy-22,2023-08-30T23:28:53Z,its 300 partitions and 50 members xd,0,0.575626015663147
1310948792,14182,rreddy-22,2023-08-30T23:40:20Z,cools i'll double check,0,0.9771513938903809
1310952891,14182,rreddy-22,2023-08-30T23:49:29Z,"yes that's correct, a is rack1 and p0 belongs to rack1",0,0.9727423191070557
1310961579,14182,rreddy-22,2023-08-31T00:03:21Z,"i think i might have to redo this example, thanks for the catch!",1,0.9269458651542664
1312351774,14182,jeffkbkim,2023-08-31T22:33:16Z,"if there's no pattern, can we change the name to testvalidityandbalanceforlargesampleset?",0,0.9949440360069275
1312392393,14182,rreddy-22,2023-08-31T23:49:36Z,"the test is correct if we let go of the fact that the current assignment wasn't done by this assignor, but with whatever information the assignor got, the behavior was as expected",0,0.9845916032791138
1312392493,14182,rreddy-22,2023-08-31T23:49:50Z,changed the current assignment to what this assignor would've returned,0,0.9901060461997986
1312392605,14182,rreddy-22,2023-08-31T23:50:05Z,explained offline,0,0.981282114982605
1312609650,14182,rreddy-22,2023-09-01T06:07:33Z,"well since we check the exact assignment for each member, when i was writing the exact partitions i made sure that the racks are matching so i feel like that is checked there already. to write a check again we would have to do quite some steps since its not guaranteed that every partition assigned to a member has a matching rack even if both partition and member racks exist",0,0.9844520092010498
1312610747,14182,rreddy-22,2023-09-01T06:09:10Z,yes,0,0.9659429788589478
1312612036,14182,rreddy-22,2023-09-01T06:11:09Z,1) this part specifically was taken from the client assignor so we know it works. 2) this can't work for the general assignor cause the definition of balance will not remain the same. in general assignor the min and max could have a larger difference and it would still be the most balanced possible,0,0.9916384816169739
1312613499,14182,rreddy-22,2023-09-01T06:13:28Z,the total assignment size can't keep increasing by 1 ever xd total partitions divided by total members is how many they'll each have and at most some of them will get 1 extra partition,0,0.9480624198913574
1312619017,14182,rreddy-22,2023-09-01T06:22:01Z,"nummembersbypartition is a map that's part of the rack info which tracks how many members are in the same rack as the partition. the sum of those members is used to sort them right, that's the ""rack aware manner"". sorting happens as expected since i put in print statements to verify them but also without that the assignments wouldn't be as expected and we do a 1:1 check on every assignment in the test cases",0,0.9909173846244812
1312623868,14182,rreddy-22,2023-09-01T06:29:08Z,"1) it doesn't matter if round robin members is not empty, we're doing this by partition so it's very possible that after iterating through the list many members are yet to receive partitions. the only time round robin members will be empty/there's no more members that need partitions is for the last partition.",0,0.9855535626411438
1312624721,14182,rreddy-22,2023-09-01T06:30:23Z,"unless round robin members is empty how will we get a npe, we would keep polling and adding it back right even if its just one member",0,0.872376561164856
1312625110,14182,rreddy-22,2023-09-01T06:30:53Z,anyways i changed it to round robin members size just like the rack aware round robin,0,0.9824298620223999
1312625675,14182,rreddy-22,2023-09-01T06:31:40Z,it is in the javadoc,0,0.9914229512214661
1312625983,14182,rreddy-22,2023-09-01T06:32:03Z,"* if the member has met their allocation quota, the member is removed from the * tracking map of members with their remaining allocations. * otherwise, the count of remaining partitions that can be assigned to the member is updated.",0,0.9935194849967957
1313213976,14182,jeffkbkim,2023-09-01T15:59:03Z,can we just use subscriptionset instead of subscriptionlist? it doesn't seem like we need a list to do any of the other operations.,0,0.9899082183837891
1313281824,14182,jeffkbkim,2023-09-01T16:50:11Z,"the `&& !assigned` part would prevent the infinite loop, no?",0,0.9918683767318726
1313283639,14182,jeffkbkim,2023-09-01T16:52:33Z,"no, unless we have a bug. can we add a check in assign() and throw illegal argument exception if members is empty?",0,0.9769665598869324
1313292815,14182,jeffkbkim,2023-09-01T17:01:15Z,that makes sense,0,0.9720192551612854
1313294383,14182,jeffkbkim,2023-09-01T17:02:37Z,"thanks, that makes sense",1,0.9056052565574646
1313393423,14182,jeffkbkim,2023-09-01T18:41:47Z,discussed offline. makes sense,0,0.9052432775497437
1313408646,14182,jeffkbkim,2023-09-01T19:02:23Z,this can be resolved,0,0.9735966324806213
1313434102,14182,jeffkbkim,2023-09-01T19:33:18Z,"that makes sense -- i forgot we're checking each member. still, i think it's possible to check the balancedness without a nested for loop. not sure if that affects the validity part",0,0.9259043335914612
1313436894,14182,jeffkbkim,2023-09-01T19:36:10Z,nit: `foreach(partition -> {`,0,0.9791340827941895
1313437179,14182,jeffkbkim,2023-09-01T19:36:28Z,nit: foreach(partition ->,0,0.9511752724647522
1313439928,14182,jeffkbkim,2023-09-01T19:39:17Z,nit: javadocs,0,0.9871456623077393
1313441197,14182,jeffkbkim,2023-09-01T19:40:29Z,can we put the arguments into new lines?,0,0.9935197234153748
1313442250,14182,jeffkbkim,2023-09-01T19:41:29Z,nit: [code block],0,0.9847351312637329
1313442609,14182,jeffkbkim,2023-09-01T19:41:50Z,nit: [code block],0,0.9847351312637329
1313443677,14182,jeffkbkim,2023-09-01T19:43:00Z,indentation looks off. [code block],0,0.9895254373550415
1313444165,14182,jeffkbkim,2023-09-01T19:43:30Z,nit: [code block],0,0.9847351312637329
1313444928,14182,jeffkbkim,2023-09-01T19:44:18Z,indentation looks off. [code block],0,0.9895254373550415
1313445794,14182,jeffkbkim,2023-09-01T19:45:13Z,let's split this [code block],0,0.9781631827354431
1313448367,14182,jeffkbkim,2023-09-01T19:47:52Z,"makes sense, let's leave it as is",0,0.9835494756698608
1315178473,14182,rreddy-22,2023-09-04T19:46:52Z,"as discussed on call, i added a check in the assign method instead",0,0.9924538731575012
1315178560,14182,rreddy-22,2023-09-04T19:47:07Z,done,0,0.8974218964576721
1315178781,14182,rreddy-22,2023-09-04T19:47:52Z,added check but i don't think we need to throw an illegal state exception,0,0.9522536396980286
1315178928,14182,rreddy-22,2023-09-04T19:48:32Z,we could but since we're checking for validity anyways we can leave it,0,0.988186240196228
1315500509,14182,dajac,2023-09-05T07:41:53Z,nit: `log` -> `log` as this is a constant.,0,0.9928128123283386
1315500739,14182,dajac,2023-09-05T07:42:04Z,nit: we can remove this empty line.,0,0.9824963808059692
1315501863,14182,dajac,2023-09-05T07:42:59Z,nit: `log` -> `log`.,0,0.9900844097137451
1315502677,14182,dajac,2023-09-05T07:43:41Z,could we please add javadoc to all the attributes? we have been doing this for all the new code in this module so we should continue.,0,0.9919249415397644
1315507070,14182,dajac,2023-09-05T07:47:13Z,nit: do we need to define `userackawarestrategy` as an attribute if we can get it from `rackinfo.userackstrategy`? we could perhaps have a method instead.,0,0.9956682920455933
1315508408,14182,dajac,2023-09-05T07:48:17Z,nit: there is an space between the `*`.,0,0.9875141978263855
1315509745,14182,dajac,2023-09-05T07:49:20Z,i suppose that we assume that we cannot get here if members is empty. is this correct?,0,0.9619311094284058
1315511582,14182,dajac,2023-09-05T07:50:52Z,i think that we should directly throw the illegalstateexception. it is a bit weird to construct it to wrap it in another one right away.,-1,0.9817004799842834
1315512642,14182,dajac,2023-09-05T07:51:49Z,this comment is incorrect as the implementation fails if the topic does not exist.,0,0.6596773862838745
1315513303,14182,dajac,2023-09-05T07:52:22Z,could this be final as well?,0,0.9939159750938416
1315529530,14182,dajac,2023-09-05T08:04:38Z,nit: `log` -> `log`.,0,0.9900844097137451
1315531958,14182,dajac,2023-09-05T08:06:51Z,is using an hashset necessary here? we could perhaps use `firstsubscriptionset.containsall(memberspec.subscribedtopicids())`. would it work?,0,0.9954826831817627
1315558356,14182,dajac,2023-09-05T08:28:24Z,"is there a reason to have this abstract class here? personally, i find it a bit weird as the concrete classes are not defined in this class. how about extracting it?",-1,0.9631409645080566
1315560818,14182,dajac,2023-09-05T08:30:26Z,nit: javadoc.,0,0.9837453365325928
1315804029,14182,dajac,2023-09-05T12:09:33Z,nit: could this method be static?,0,0.9845083951950073
1315804175,14182,dajac,2023-09-05T12:09:42Z,ditto.,0,0.6705162525177002
1315805497,14182,dajac,2023-09-05T12:10:55Z,nit: do we really need to create the arraylist here?,0,0.9826918840408325
1315808858,14182,dajac,2023-09-05T12:14:13Z,we already have the very same class in the `metadata` module. i wonder if we should move that one to `server-common` module so that we could reuse it here. it could land in the `common` package over there. what do you think?,0,0.9837760329246521
1315811048,14182,dajac,2023-09-05T12:16:15Z,nit: could we keep the previous code and use `getordefault` instead of `get`? the code would be more concise...,0,0.9887087941169739
1315814176,14182,dajac,2023-09-05T12:19:10Z,nit: we should use `int` here.,0,0.9887125492095947
1315815939,14182,dajac,2023-09-05T12:20:48Z,nit: this code is duplicated. should we have an helper method for it?,0,0.7856308817863464
1315831564,14182,dajac,2023-09-05T12:34:20Z,nit: we can remove ` `.,0,0.986979603767395
1315836673,14182,dajac,2023-09-05T12:38:40Z,shouldn't we keep what we had here?,0,0.9887366890907288
1315836903,14182,dajac,2023-09-05T12:38:52Z,nit: `log` -> `log`.,0,0.9900844097137451
1316096433,14182,rreddy-22,2023-09-05T15:50:54Z,yep i'll raise a different pr for range assignor changes,0,0.9824450612068176
1316390836,14182,rreddy-22,2023-09-05T20:47:41Z,"its not the exact same, that one has topicid mapped to topicpartition here its just the partition number",0,0.9841660261154175
1316396258,14182,rreddy-22,2023-09-05T20:54:00Z,removing this,0,0.9803035259246826
1316406386,14182,rreddy-22,2023-09-05T21:05:56Z,"ack will remove it but we can ignore this file for now since the implementation isn't in yet, just needed the initial template for now to get the conditional implementation of the specific assignment builder based on the subscriptions.",0,0.9940647482872009
1316408646,14182,rreddy-22,2023-09-05T21:08:55Z,yeah correct i added a check in the assign method so its not possible anymore,0,0.9731603264808655
1316429235,14182,rreddy-22,2023-09-05T21:30:10Z,done,0,0.8974218964576721
1316439651,14182,rreddy-22,2023-09-05T21:40:09Z,"yep makes sense i removed it, i thought in the future if we wanted to have a flag in the assignor to switch it on or off",0,0.9720283150672913
1316456003,14182,rreddy-22,2023-09-05T21:55:51Z,i wanted to throw a partition assignor exception since the exception is related to the assignor? can we do that only? or do we have to do just an illegal state exception?,0,0.9830368161201477
1316792230,14182,rreddy-22,2023-09-06T06:24:50Z,which concrete classes? we made it abstract so that any builder that implements this class would need to implement buildassignment which is the main function called within assign,0,0.994906485080719
1316793219,14182,rreddy-22,2023-09-06T06:26:04Z,i believe it's easier to understand since alltopicidpartitions is a method that returns this list which is used later on no?,0,0.9650193452835083
1316806195,14182,rreddy-22,2023-09-06T06:41:06Z,will do,0,0.9571817517280579
1316955014,14182,dajac,2023-09-06T08:52:10Z,generaluniformassignmentbuilder and optimizeduniformassignmentbuilder. how about extracting abstractassignmentbuilder from uniformassignor and calling it abstractuniformassignmentbuilder?,0,0.9949093461036682
1316956874,14182,dajac,2023-09-06T08:53:30Z,i was referring to `new arraylist<>(topicids)`. is creating a new arraylist from the set necessary? alltopicidpartitions could take a collection for instance to avoid it.,0,0.9939404726028442
1316961213,14182,dajac,2023-09-06T08:56:03Z,i was referring to [a link] it is really bad to have two classes with the same name but slightly different. i wonder if we can do something about it...,-1,0.9899128079414368
1317663852,14182,rreddy-22,2023-09-06T18:17:32Z,ohh got it yeah that makes sense,0,0.5695567727088928
1317669213,14182,rreddy-22,2023-09-06T18:23:27Z,"ohh my bad i got this question before so i instinctively replied, i realized i was thinking of the kafka common topicidpartition class but yeah this seems usable, would we need a new pr to move the file though?",-1,0.9614964127540588
1317676113,14182,rreddy-22,2023-09-06T18:30:53Z,"discussed offline, going to throw only partitionassignorexception",0,0.9434472918510437
1319775413,14182,dajac,2023-09-08T11:53:49Z,nit: we usually add an empty line before the javadoc for attributes.,0,0.991166889667511
1319776220,14182,dajac,2023-09-08T11:54:38Z,nit: should we log at debug level here?,0,0.9863281846046448
1319779160,14182,dajac,2023-09-08T11:58:00Z,nit: empty line can be removed.,0,0.9869259595870972
1319810543,14182,dajac,2023-09-08T12:31:31Z,nit: int?,0,0.9647737145423889
1319811185,14182,dajac,2023-09-08T12:32:12Z,could we elaborate a bit more on why the sorting is important here?,0,0.984129786491394
1319812206,14182,dajac,2023-09-08T12:33:18Z,i wonder if we could reuse the linked list that we already used in rackawareroundrobinassignment instead of re-creating a new one from scratch. is there a reason why we need it?,0,0.9748639464378357
1319812750,14182,dajac,2023-09-08T12:33:54Z,nit: should this comment be right before `if (unfilledmembers.containskey(memberid)) {`?,0,0.994132936000824
1319814872,14182,dajac,2023-09-08T12:36:02Z,"is this really necessary? it is a tad annoying to have to compute the sum of all the unfilled members. if you really want to do this, we could perhaps maintain the total count as we update the unfilled members but i am not sure if it is worth it.",-1,0.9743010401725769
1319816047,14182,dajac,2023-09-08T12:36:57Z,i was wondering whether we could avoid the copy and just update `potentiallyunfilledmembers`. have you thought about this?,0,0.9874297976493835
1319820875,14182,dajac,2023-09-08T12:41:33Z,"yeah, we can have a separate pr to move that class (and add some javadoc to it). i am actually annoyed by the fact that we have two topicidpartition classes but with different content. one with (id, name, partition) and one with (id, partition). this is really misleading...",-1,0.9902764558792114
1319824362,14182,dajac,2023-09-08T12:45:18Z,nit: could we just keep everything on one line?,0,0.9689905047416687
1319824635,14182,dajac,2023-09-08T12:45:35Z,still there :),1,0.9883548021316528
1320217221,14182,rreddy-22,2023-09-08T18:39:21Z,"i added it as a check to ensure we don't have more partitions to assign and less total required assignments count, i.e. jic our calculations are wrong. its not completely necessary",0,0.968959391117096
1320220040,14182,rreddy-22,2023-09-08T18:42:10Z,in the comments? or should i explain it here,0,0.9871363639831543
1320220933,14182,rreddy-22,2023-09-08T18:42:58Z,we sort so that the partition with the least number of options for a matching rack member can receive the assignment first.,0,0.9900006055831909
1321023603,14182,rreddy-22,2023-09-11T05:54:15Z,added in the javadoc,0,0.9894737601280212
1321023849,14182,rreddy-22,2023-09-11T05:54:42Z,"rackaware round robin might not be called in every case, it is only called when userackaware strategy is true. i could make it a global attribute maybe but that seems odd since the queue is only used in these two methods.",0,0.9828813076019287
1321024671,14182,rreddy-22,2023-09-11T05:56:05Z,i remember getting comments to keep the comments at the beginning of the loop instead of inside,0,0.9746992588043213
1321033941,14182,rreddy-22,2023-09-11T06:08:17Z,"yeah you're right, it's an unnecessary extra map, i made it a local map, just wanna still keep it separate cause potentially unfilled members also has ones that have met the quota, but unfilled only has those that still need to be assigned partitions, might be hard to understand what types of members we have at each point. lmk if what i did makes sense or if we can optimize it more",0,0.852202296257019
1321035644,14182,rreddy-22,2023-09-11T06:10:51Z,"yeah that's true i agree, i wasn't sure what else to call this one, okay i will add a new pr for this.",0,0.8792054057121277
1325561675,14182,dajac,2023-09-14T08:17:15Z,"small nit: in such case, i usually prefer to put the mutated object first in the list of arguments. then, i would also put memberid, then topicid and finally partition to follow their hierarchy. i would also rename targetassignment to assignment because the method is not tight to a target assignment in the end. it could be any assignment map.",0,0.9872775673866272
1325563579,14182,dajac,2023-09-14T08:18:43Z,"bit: this parenthesis seems misplaced, no?",0,0.7274073362350464
1325598891,14182,dajac,2023-09-14T08:44:47Z,"i see... it is a bit annoying to copy the map here but i can live with it if you think that it is better like this. i have another question regarding this code. my understanding is that we basically decide here which members will get the extra partitions. basically, the first members while iterating over the map will get them. when the rack awareness is enabled, i wonder if we could get in a situation where the members with the extra partitions and the unassigned partitions are completely misaligned to due this. let's take an example. we have a group with 10 members (from 1 to 10) subscribed to topic a. topic a has 20 partitions so each member has 2 assigned partitions. all the partitions are available in a single rack. members 1 to 5 are in rack r1 and members 6 to 10 in rack r2. now let's say that we add 5 partitions to a. 3 are in r1 and 2 in r2. if we iterate from 1 to 10 to assign the extra partitions, it means that 1 to 5 will get an extra partitions even though two of the partitions are not in the same rack. is this a possible scenario? it is perhaps a bit too extreme...",-1,0.974922776222229
1325600664,14182,dajac,2023-09-14T08:46:06Z,how about creating the queue just before calling rackawareroundrobinassignment and unassignedpartitionsroundrobinassignment and passing it as a parameter?,0,0.9948093891143799
1325602326,14182,dajac,2023-09-14T08:47:19Z,"ah ah. you got me :). i actually raised this because in rackawareroundrobinassignment, your put it right before the if. that also works because the comment is really about that if.",1,0.8996601700782776
1325604357,14182,dajac,2023-09-14T08:48:52Z,nit: let's log before creating the builder to be consistent with the other branch.,0,0.9899623394012451
1325633887,14182,dajac,2023-09-14T09:07:37Z,nit: we have the same method in rangeassignortest. could we somehow share it for the two suites? we could perhaps introduce an assignortestutil class in this package and add it there.,0,0.9919079542160034
1326815225,14182,rreddy-22,2023-09-15T05:42:57Z,yessir done :),1,0.9939401149749756
1326817433,14182,rreddy-22,2023-09-15T05:46:40Z,i wasn't sure where it went tbh xd,-1,0.8883334398269653
1326818424,14182,rreddy-22,2023-09-15T05:48:25Z,"makes sense, i put the order based on the method name like add partition to assignment so first partition then which topic then whose assignment and then which assignment",0,0.982222318649292
1326819932,14182,rreddy-22,2023-09-15T05:50:52Z,i changed it now so we don't need the queue at all,0,0.9870829582214355
1326826466,14182,rreddy-22,2023-09-15T05:56:06Z,"yeah that's true i didn't think of how we're assigning the extra partitions, used the same logic as before, let me look into it. thanks for catching this!",1,0.9863671660423279
1326838235,14182,rreddy-22,2023-09-15T06:06:32Z,"i think one option would be to iterate through potentially unfilled members instead during the round robin process and if the member is a potential rack match plus can get an extra partition then we can assign it. we basically dynamically decide who gets the extra, instead of deciding before hand",0,0.9888090491294861
1326871177,14182,dajac,2023-09-15T06:48:03Z,"yeah, i was thinking about more or less the same. is it an small change?",0,0.7386473417282104
1326872198,14182,dajac,2023-09-15T06:49:18Z,"in this case, i would put it back on the previous line.",0,0.9837754368782043
1332072827,14182,rreddy-22,2023-09-20T19:15:32Z,wasn't sadly but its done now,-1,0.8147174715995789
50180928,764,hachikuji,2016-01-19T21:48:28Z,"typo in ""messge""?",0,0.9930439591407776
50183536,764,hachikuji,2016-01-19T22:06:29Z,unneeded import (message)?,0,0.973619818687439
50183902,764,hachikuji,2016-01-19T22:09:14Z,unneeded import (errormapping)?,0,0.9656859636306763
50186812,764,hachikuji,2016-01-19T22:32:18Z,"i wasn't clear from the kip, but is this a broker-wide setting or can it be overridden for each topic?",0,0.9888490438461304
50334745,764,apovzner,2016-01-20T22:57:35Z,"it would be useful to have a comment describing what this method does. especially because in one ""invalid"" case it throws exception, and in another case (when we need to overwrite timestamp) it returns true/false.",0,0.9892364144325256
50335106,764,apovzner,2016-01-20T23:00:58Z,"i am wondering if it would be better to pass 'now' as a parameter. we are calling this method for each message in a set, and getting current time every time. normally getting system time is an expensive call, so maybe better to get it once for a message set, and pass it to this method?",0,0.9834287762641907
50338001,764,apovzner,2016-01-20T23:27:22Z,"i see that in other places you did ""if (magicvalue > magicvalue_v0)"" comparison -- i think that one is better, since we would still want timestamp if we have magicvalue_v2 in the future, for example.",0,0.9857994318008423
50367205,764,becketqin,2016-01-21T07:16:24Z,"i was also thinking about that. currently whatever configurations in logconfig are per topic configurations. and the message timestamp type is a legitimate log config. so currently it is a per topic configuration. i can see some benefit of doing so from migration point of view. because most topics are owned by some applications. we can start to use the new format once all the client of that topic has migrated. and in the final state, we can choose to leave the topics whose owner are not able to migrate to use old format and still have zero-copy.",0,0.9543224573135376
50367268,764,becketqin,2016-01-21T07:17:55Z,good catch :) i remember i had this somewhere but did not find it before submit the pr.,1,0.9955486059188843
50442463,764,hachikuji,2016-01-21T18:36:26Z,"thanks for the explanation. makes sense to me. by the way, i've only done a quick pass on this patch so far, but i'm planning to spend a bit more time in the next couple days.",1,0.9477254748344421
50479362,764,apovzner,2016-01-21T23:04:46Z,"since we are adding timestamp field to producerrecord, i think we should add a comment to producerrecord class description about meaning of timestamp, what happens if user sets null, etc.",0,0.9905547499656677
50479481,764,apovzner,2016-01-21T23:06:04Z,"also would be good to add a comment to recordmetadata class description what timestamp is actually returned (either set by client, producer, or broker).",0,0.9890903830528259
50481259,764,apovzner,2016-01-21T23:23:53Z,"i understand that producer learns about the type of the timestamp after it gets first successful produce response. we are using the type of the timestamp in kafkaproducer.send() to set timestamp in producerrecord. i see that we default to handling timestamp as createtime timestamp if we don't know the type yet. what is the impact of doing this if the correct type turns out to be logappendtime? why don't we just always set timestamp on producer as if is createtime (basically, set local producer time if timestamp in producerrecord is null), and broker then overwrites it if the timestamp type is logappendtime. otherwise, looks like lots of added complexity just to decide whether set timestamp on the producer or not.",0,0.987793505191803
50484068,764,apovzner,2016-01-21T23:52:00Z,"related to my other comment about learning about timestamp type for topic. so, the first set of produce messages will not have timestamp == inherited_timestamp if timestamp type == logappendtime, right? if setting timestamp to inherited_timestamp is required for compressed messages to work, does it mean we have a bug?",0,0.9781903028488159
50501215,764,becketqin,2016-01-22T04:29:28Z,"the reason we want to set the timestamp to -1 in producer when logappendtime is used for the topic is to avoid broker side recompression. if producer send createtime to a topic setup for logappendtime, recompression will occur on the broker if the received message timestamp is not -1. avoid recompression on broker is the key motivation of kip-31 so we don't want people to lose this feature if they are using logappendtime.",0,0.9914441704750061
50501355,764,becketqin,2016-01-22T04:34:01Z,"it is not required to be inherited_timestamp, but it is good to be so. like i answered in your other comment, if a topic is using logappendtime and a broker receives a message whose timestamp is not inherited_timestamp, it will overwrite it and do the recompression. so the first batch of a new producer might cause recompression on broker side, but after that, no recompression should be needed. i will add some comments so it is more clear.",0,0.904966413974762
50597218,764,apovzner,2016-01-22T22:03:34Z,"i agree about avoiding broker side recompression. however, i still feel like we can achieve the same behavior with less changes. let me know if i am missing something, but couldn't we just do the following: 1. producer always sets timestamps (either producer client or kafkaproducer), as if timestamp type == createtime. for compressed message: timestamp of the outer message is set to the largest timestamp of the inner messages. 2. broker will overwrite timestamps if type == logappendtime. in case of compressed message, it will overwrite only outer message timestamp, and let inner messages have ""wrong"" timestamps. if message ever gets uncompressed on broker: set all inner timestamps to outer timestamp if type == logappendtime; 3. when messages get uncompressed on consumer (or any case when we don't have timestamp type info): we know that outer timestamp is either max of inner timestamps (if create time) or outer timestamp was overwritten (and so inner timestamps are not valid anymore). we check if outer (compressed message) timestamp == max of inner message timestamps, and if false, set all inner message timestamps to outer timestamp. if there is ever a case that overwriting timestamp results in a timestamp == max of inner message timestamps, this means that producer and broker times are in sync, and inner message timestamps should be close enough to outer timestamp to care overwriting it.",0,0.8418012857437134
50599954,764,becketqin,2016-01-22T22:29:40Z,"in your suggestion, how can we differentiate between the following two scenarios: 1. logappendtime is used, the inner message's largest timestamp happened to be the same as the logappendtime. 2. createtime is used. the compressed messages in both case are exactly the same, but one is using logappendtime and the other one is using createtime. how would the consumer decide which timestamp to use? please also notice that we always do decompression on broker side to verify the message. what we want to avoid is re-compression.",0,0.9919936656951904
50621173,764,dajac,2016-01-23T15:25:29Z,wouldn't it be better to put this conversion in kafkaapis or directly in messageset? i would prefer to keep fetchresponse and fetchresponsepartitiondata as simple as possible and focused on the serialization.,0,0.9940886497497559
50621383,764,dajac,2016-01-23T15:40:43Z,nitpick: indentation is not correct.,-1,0.7101081013679504
50645225,764,becketqin,2016-01-24T23:42:32Z,"i agree it makes sense to put the message set format conversion code block into messageset instead of here. however, i make the io threads to do the conversion on purpose because i want to share the workload between kafkaapis threads and io threads. typically, io threads are more light-weighted than kafkaapis threads. if we have to make conversion for some requests, i am trying to put the conversion load on io threads.",0,0.9867820143699646
50743872,764,apovzner,2016-01-25T19:35:46Z,"i should have said ""if message ever gets re-compressed on broker..."" in #2. so we don't over-write timestamp and re-compress just for timestamps. to answer your question and clarify my suggestions, i am basing my suggestion on the assumption that we don't need to be very exact about timestamp -- meaning +- 1 ms is ok. so my proposal above is assuming that if your scenario happen and the inner message's largest timestamp happened to be the same as the current time on broker and we are using logappendtime, this means that producer and broker are in sync, and we don't care whether it is logappendtime or createtime. one more argument against: what if client sets ""bad"" timestamp in one of the inner messages. i realized that in your scenario my suggestion does not work well. i propose the following: on broker, when messages get decompressed, if timestamp type == logapendtime, then set outer message timestamp == current time. check if max timestamp of inner messages also contains this timestamp, and if so, decrement outer message timestamp by 1 ms. in this case, we know that we don't have the scenario above. on consumer, if outer message timestamp != max of inner messages timestamps, we know that this is logappendtime and set all inner message timestamps to outer message timestamp. **summary** i think we either need a cleaner way to get topic's timestamp type on producer or simplify timestamp code by allowing timestamps be not super exact, but no more than +- 1 ms error. the former i think is better solved by getting timestamp type with topic metadata, but that requires another wire protocol change. the latter is proposed above, but here is updated version based on the scenario in the previous comment: 1. producer always sets timestamps (either producer client or kafkaproducer), as if timestamp type == createtime. for compressed message: timestamp of the outer message is set to the largest timestamp of the inner messages. 2. broker will overwrite timestamps if type == logappendtime. in case of compressed message: it will overwrite only outer message timestamp, and let inner messages have ""wrong"" timestamps. if broker happens to overwrite outer message timestamp with with same timestamp, it means that outer timestamp would be equal to max of inner message timestamps. to allow consumer to differentiate between overwritten and not overwritten timestamp, we want to void the case where outer message timestamp == max of inner message timestamps when type == logappendtime. so, when overwriting outer message timestamp with same timestamp, we will decrement (or increment) outer message timestamp by 1 ms. 3. when messages get uncompressed on consumer, we know that outer timestamp is either max of inner timestamps (if create time) or outer timestamp was overwritten (and so inner timestamps are not valid anymore). we check if outer (compressed message) timestamp == max of inner message timestamps, and if false, set all inner message timestamps to outer timestamp.",0,0.9700652360916138
50764320,764,becketqin,2016-01-25T22:09:16Z,"personally i think the timestamp should be accurate. modifying the timestamp sounds very hacky and creates extra complexity. please also notice that the timestamp index built by the followers will be purely depending on the timestamp in outer message of compressed messages. the followers will not even decompress the messages. if we play the trick here, the time index on follower will also be affected. if we want to make things right, then producer should be able to get the necessary topic configuration info from broker, either from topicmetadatarequest or some other requests. so the producer can set the timestamp correctly to avoid server side recompression. but like you said this is a bigger change and it is unnecessary to block on that change. i think the current solution is reasonably clean as of the moment. once the producer is able to get the topic configuration from broker, we can simply migrate to use that. since everything is purely internal, the migration is very simple and transparent to users.",0,0.5098015069961548
51080192,764,apovzner,2016-01-28T04:59:25Z,"if we are exposing timestamp type in consumerrecord, should we declare timestamptype outside of record?",0,0.995263934135437
51082542,764,becketqin,2016-01-28T05:50:14Z,it is in kafkaproducer line 437. we just need a one liner now.,0,0.9913866519927979
51165826,764,apovzner,2016-01-28T18:39:07Z,the comment above the method does not match implementation anymore -- we are now only checking acceptable range for createtime timestamps.,0,0.9925383925437927
51221001,764,junrao,2016-01-29T03:00:09Z,it seems that we only reserved 3 bits for compression codec?,0,0.9897422790527344
51221007,764,junrao,2016-01-29T03:00:14Z,it seems that checking lastinneroffset itself is enough.,0,0.9912932515144348
51221024,764,junrao,2016-01-29T03:00:32Z,"since this is always called on the inner records, we probably don't need shallow in the param?",0,0.9937348961830139
51221029,764,junrao,2016-01-29T03:00:36Z,would it be better to name this lastinnerrelativeoffset?,0,0.9937669038772583
51221037,764,junrao,2016-01-29T03:00:44Z,fetch response v2 is actually different from v1 since the message format is different.,0,0.9508098363876343
51221069,764,junrao,2016-01-29T03:00:57Z,could we add timestamp to ?,0,0.9928440451622009
51221090,764,junrao,2016-01-29T03:01:13Z,is it useful for user to specify a -1 timestamp? would that be the same as passing in a null timestamp?,0,0.9939310550689697
51221091,764,junrao,2016-01-29T03:01:18Z,"the record is still sent to a topic/partition, not timestamp.",0,0.9901684522628784
51221099,764,junrao,2016-01-29T03:01:23Z,typo: record.record,0,0.9885298609733582
51221100,764,junrao,2016-01-29T03:01:25Z,typo: record.record,0,0.9885298609733582
51235304,764,becketqin,2016-01-29T08:18:35Z,"currently the message format change is not reflected in the fetch response protocol. the change is in the record class when it parses the bytebuffer. so the fetchresponse fields actually does not change. but i agree that ideally we should define all the wire protocols in protocol. i was planning to do it in another patch because this patch is already big. the comment here is actually not accurate. in fetchresponse v2 we may also see message format v0, because the broker will try to avoid losing zero copy by assuming the client sending fetchrequest v2 knows how to parse message format v0.",0,0.9878656268119812
51301463,764,apovzner,2016-01-29T19:08:50Z,"why do we ever need to recompute crc for timestamp type == createtime? since createtime is default, we should set all right attributes with the timestamp on the producer, and we don't need to update crc or do any related changes to timestamp/attributes on the broker. i think we should be clear about when crc can change on the broker and when it will not.",0,0.9815074801445007
51325920,764,becketqin,2016-01-29T22:37:12Z,we need to verify both the timestamp attribute bit and the actual timestamp. if one of them is not set properly we need to update it and recompute crc.,0,0.9917665123939514
51326334,764,apovzner,2016-01-29T22:42:22Z,"i see, so this is only the migration case, right? upgraded producer will set both attributes and timestamp correctly for the createtime topics, right?",0,0.989287257194519
51329584,764,becketqin,2016-01-29T23:21:45Z,for migration case and for producers that is not setting the timestamp of outer message correctly somehow. it should be fine since we are not changing the actual timestamps of messages.,0,0.9919427633285522
51502629,764,apovzner,2016-02-02T00:07:14Z,"thanks, that makes sense.",1,0.8544086217880249
51516461,764,junrao,2016-02-02T02:52:44Z,"right, perhaps we can make this clearer in the comment. sth like the following: even though fetch response v2 has the same protocol as v1, the record set in the response is different. in v1, record set only includes messages of v0 (magic byte 0). in v2, record set can include messages of v0 and v1 (magic byte 0 and 1). for details, see ref{bytebuffermessageset}.",0,0.9929925203323364
51516607,764,junrao,2016-02-02T02:54:29Z,"would it be better to rename this to wrappertimestamptype? also, since the way to interpret the timestamp is a bit subtle, especially with respect to compressed messages, could you document this in a comment?",0,0.9878858327865601
51516616,764,junrao,2016-02-02T02:54:34Z,"the comment says this is the constructor for version 1, but the code uses the latest version.",0,0.9927234053611755
51516635,764,junrao,2016-02-02T02:54:46Z,"we check version here, but uses the new field name in line 127 as the way to check the version. we should probably use a consistent approach.",0,0.9921004176139832
51516646,764,junrao,2016-02-02T02:54:59Z,could we add a comment before line 95 that we expect the caller to pass in a struct with the latest schema?,0,0.9933549165725708
51516833,764,junrao,2016-02-02T02:57:34Z,"in addition to have the internal versions, we probably should always have an ""0.10.0"" version in trunk so that it's in a releasable state. i was thinking that we always have ""0.10.0"" map to the last case object. in this case, both ""0.10.0"" and ""0.10.0-dv0"" will be pointing to kafka_0_10_0_dv0. when we add kafka_0_10_0_dv1, ""0.10.0"" will be pointing to kafka_0_10_0_dv1 and we will add ""0.10.0-dv1"", but leave ""0.10.0-dv0"" unchanged. in the code, we can just reference the first internal version in which a format change is introduced. then, for people deploy from trunk, they can use the internal version. for people who want to try trunk, they can use ""0.10.0"". also, would it be better to use iv (internal version) instead of dv? finally, it may make sense to make the next major release 0.10 instead of 0.9.1 since we will be including kstream. do you want to poll the mailing list to see if people are ok with this?",0,0.9930790066719055
51516887,764,junrao,2016-02-02T02:58:28Z,"i agree that it's better to do the message conversion in kafkaapis. the reason is that a single network thread is used to handle many socket connections. if the sending of one response is slow (e.g., recompression when converting the message), it slows down the processing of all connections on this network thread. on the other hand, if the processing in a request handler thread is slow, it only slows down that request. other requests are unaffected.",0,0.9916704893112183
51516906,764,junrao,2016-02-02T02:58:52Z,this means that we are paying the overhead of checking hasmagicvalue even after the consumer is upgraded to support both message format v0 and v1.,0,0.9881336092948914
51516922,764,junrao,2016-02-02T02:59:10Z,"should this be a topic level config? the issue is that this has to match the api version that the broker uses. for example, if the broker is on 0.9.x, setting the format in a topic to v1 is invalid, but is hard to enforce.",0,0.9866148829460144
51516927,764,junrao,2016-02-02T02:59:13Z,typo writtern,0,0.9694209694862366
51516929,764,junrao,2016-02-02T02:59:16Z,it simply write => it simply writes,0,0.9479414820671082
51516941,764,junrao,2016-02-02T02:59:28Z,can use innermessageandoffsets instead of messageandoffsets.,0,0.993546187877655
51516961,764,junrao,2016-02-02T02:59:49Z,"if we don't need to re-compress, should we validate the crc of each of the inner message?",0,0.9907031059265137
51516975,764,junrao,2016-02-02T03:00:03Z,"it seems that we only need to convert message format on filemessageset. so, perhaps it's better to move this to filemessageset?",0,0.9923847913742065
51516977,764,junrao,2016-02-02T03:00:08Z,there are a few unused imports.,0,0.9304671287536621
51517004,764,junrao,2016-02-02T03:00:31Z,"this probably shouldn't be info level logging, right?",0,0.919994592666626
51517033,764,junrao,2016-02-02T03:00:56Z,could we document what the valid values are for message format? it seems that we are piggybacking on the apiversion number. it's probably clearer if just use v0 and v1 that matches the magic value since not every api version change implies a message format change.,0,0.9902651309967041
51525824,764,becketqin,2016-02-02T05:28:21Z,read the code again. that's true. apparently i had some wrong impression about how we process the requests...,-1,0.9418960213661194
51529150,764,becketqin,2016-02-02T06:30:05Z,good catch. we only need to do down convert for fetch request lower than v2.,1,0.8832417726516724
51530067,764,becketqin,2016-02-02T06:38:39Z,"that is indeed a caveat. the reason i make message.format.version a topic level config is because it helps to roll out the change. in many cases topics are owned by different applications, so once the application finishes upgrade we can turn on the new message format for them without waiting for others. one way to enforce this is to add sanity check in both kafkaconfig and topicconfighandler. we can check to make sure the message format version config is valid.",0,0.9911092519760132
51531865,764,becketqin,2016-02-02T07:08:00Z,had some comments on the kip about this. i feel fine either way. the good thing about piggybacking apiversion is it is easy to validate the config. and from user's perspective it may be easier to understand. e.g. during upgrade they can simply put their previous kafka version there and after upgrade they just need to change it to the upgraded version. so users don't need to remember the magic values to put.,1,0.882146418094635
51615655,764,junrao,2016-02-02T18:54:10Z,it's probably clearer to rename this to sth like magicvalueinallmessages().,0,0.9939060807228088
51615665,764,junrao,2016-02-02T18:54:14Z,indentation,0,0.822169840335846
51615681,764,junrao,2016-02-02T18:54:20Z,could you attach gwen's comment here?,0,0.9917159676551819
51615706,764,junrao,2016-02-02T18:54:26Z,could we include the valid property values in the doc?,0,0.9918252229690552
51615770,764,junrao,2016-02-02T18:54:47Z,"we should use the magic configured for this topic and convert each message to the right version if needed, right?",0,0.9903406500816345
51615946,764,junrao,2016-02-02T18:55:53Z,"could we put those comments in a more prominent place like the beginning of the class? with v1 message format, we are adding a timestamp, a timestamp type attribute, and are using a relative for inner message. it would be useful to document the format in a bit more details for both the outer and the inner message. for example, should the timestamp type attribute be set for inner messages?",0,0.9927049279212952
51634795,764,becketqin,2016-02-02T21:05:21Z,"gwen gave the following feedback on the voting thread. ""2. apiversion has real version numbers. message.format.version has sequence numbers. this makes us look pretty silly :)""",1,0.9954298734664917
51637287,764,becketqin,2016-02-02T21:23:12Z,"i was thinking only applying the new message format to the messages appended after the change, so the log has a clear cut-off offset where all the new format comes after that. it is probably not necessary. what do you think?",0,0.9681021571159363
51672466,764,junrao,2016-02-03T02:51:10Z,could we add a comment to explain what the timestamp is?,0,0.9920044541358948
51672513,764,junrao,2016-02-03T02:51:55Z,the comment still says using v1 format.,0,0.9916120767593384
51672525,764,junrao,2016-02-03T02:52:14Z,it's probably useful to use the message format v1 on the topic. this can avoid the recompression overhead when compression is enabled.,0,0.9868389964103699
51672530,764,junrao,2016-02-03T02:52:20Z,it's probably useful to use the message format v1 on the topic. this can avoid the recompression overhead when compression is enabled.,0,0.9868389964103699
51672563,764,junrao,2016-02-03T02:52:53Z,"the thing is that the way topicconfigcommand works is that it just writes the config in zk and then writes the config notification. topicconfighandler just follows the notification. if we add the check in topicconfighandler, we need to remove the config in zk, which makes things more complicated. we can probably just leave this as a topic level config with the caveat that the config may be ignored if the broker property doesn't match.",0,0.9934335947036743
51672667,764,junrao,2016-02-03T02:54:32Z,"the changes in this class is a bit complicated, makes the code a bit hard to read. this and the following are some suggestions on simplification. do we need convertnoncompressedmessages()? since we can't do things in place, could we just use the path that deals with recompression to handle it? this will save some duplicated code.",0,0.7206224799156189
51672737,764,junrao,2016-02-03T02:55:35Z,"requirerecompression is a bit confusing. for example, requirerecompression will be true if the source data is compressed and the broker requires no compression. perhaps we can rename it to sth like inplaceconversion and negate the test?",0,0.6014271378517151
51672760,764,junrao,2016-02-03T02:56:06Z,"passing in messagesettimestampassignor makes the code a bit harder to read. i was wondering if we can obviate that and always scan the messages to get the max timestamp. this will add a bit overhead of making another iteration of all messages, but will simplify the code. the overhead should be small.",0,0.8161766529083252
51672770,764,junrao,2016-02-03T02:56:15Z,"so far, we have been using case classes to represent enum in scala (see compressioncodec). could we follow the same convention?",0,0.9938854575157166
51672776,764,junrao,2016-02-03T02:56:24Z,"hmm, producer request v2 is supposed to send message of v1, right? actually, should we enforce that on the broker?",0,0.9783092141151428
51672781,764,junrao,2016-02-03T02:56:34Z,"hmm, what is %s for now? also, do we want to just log the text ""fetchrequest""?",0,0.9558253288269043
51672789,764,junrao,2016-02-03T02:56:43Z,would it be better to use the latest version of the message?,0,0.9938850998878479
51672844,764,junrao,2016-02-03T02:57:49Z,"right, we can use sth like v0, v1 to make it consistent.",0,0.9931324124336243
51682035,764,junrao,2016-02-03T06:06:48Z,"converting to message format v1 allows us to track timestamp at the message level, which will be useful for things like removing the tombstone.",0,0.9917460680007935
51768874,764,becketqin,2016-02-03T18:57:25Z,"hi jun, currently we always do re-compression when compacting the log, even if message format v1 is used. do you mean we should change that so if a compressed message set does not change after compaction we simply write the original message set back? if we do that (and we probably should), it seems it does not matter whether message format v0 or v1 is used, because it only depends on whether there is message in the message set got compacted out or not.",0,0.9920045733451843
51817003,764,hachikuji,2016-02-04T01:24:23Z,"took me a while to wrap my head around this line. it seems like the `lastinnerrelativeoffset` and `wrapperrecordoffset` are constants within the life of this instance, so i'm wondering if we could instead use a single constant (e.g. `absolutebaseoffset`) for this difference? then this line would just become: [code block] which is a lot more readable.",0,0.9749780893325806
51831822,764,junrao,2016-02-04T05:42:22Z,"that's not what i meant. since this message will be eventually appended to the log through log.append, if it's compressed and of format v0, we need to recompress it. if it's format v1, the recompression can be avoid. also, since v1 carries more metadata, it seems that we should always try to use message v1 if possible.",0,0.9921668767929077
51961629,764,becketqin,2016-02-05T00:39:38Z,"hi jun, do we also want the change in old producer request and old producer? it seems it will be deprecated pretty soon. so in the current patch i did not even change the scala producerrequest format, but i probably should just leave the scala producer version to 1. besides that, i realized that we have quite a few tools still using old consumer. i will update them.",0,0.9635043740272522
52074957,764,becketqin,2016-02-05T21:26:46Z,ack :),1,0.9894511103630066
52267507,764,junrao,2016-02-09T04:50:22Z,"reworded this a bit the default on-disk message format in 0.10.0 in v1. if a consumer client is on a version before 0.10.0, it only understands message format v0. in this case, the broker is able to convert messages of format v1 to v0 before sending a response to the consumer on an older version. however, the broker can't use zero-copy transfer in this case. to avoid such message conversion before consumers are upgraded to 0.10.0, one can set the message format to v0 after upgrading the broker to 0.10.0. this way, the broker can still use zero-copy transfer to send the data to the old consumers. once most consumers are upgraded, one can change the message format to v1 on the broker.",0,0.9929199814796448
52267511,764,junrao,2016-02-09T04:50:31Z,the comment is not accurate since the producer doesn't know the timestamp type.,0,0.840453028678894
52267516,764,junrao,2016-02-09T04:50:38Z,are these comments correct? the timestamp in producerrecord is always set by the producer.,0,0.9934495091438293
52267522,764,junrao,2016-02-09T04:50:44Z,could we add a comment on the timestamp field?,0,0.9926014542579651
52267534,764,junrao,2016-02-09T04:51:06Z,"typo dv also, could we leave some comments so that people know what to do when changing the protocol again before 0.10.0 is released?",0,0.9927577972412109
52267543,764,junrao,2016-02-09T04:51:13Z,we no longer need this since 0_10_0 will just point to the latest iv.,0,0.9930410385131836
52267549,764,junrao,2016-02-09T04:51:21Z,the changes in this file seem no longer needed.,0,0.9848529100418091
52267569,764,junrao,2016-02-09T04:51:50Z,"i had a comment on this in the previous round of review. it seems that during compaction, it would be better to write the message in the configured message format : (1) this reduces the message conversion during fetch. (2) converting to message format v1 allows us to track timestamp at the message level, which will be useful for things like removing the tombstone.",0,0.9905068874359131
52267574,764,junrao,2016-02-09T04:51:56Z,should we just represent this as a byte to be consistent with message.magic?,0,0.9944650530815125
52267583,764,junrao,2016-02-09T04:52:05Z,should we assert that wrappermessagetimestamp is only set if compression is on and timestamptype is logappend?,0,0.9950171113014221
52267592,764,junrao,2016-02-09T04:52:10Z,adjust => adjusts,0,0.9725326895713806
52267595,764,junrao,2016-02-09T04:52:18Z,"could we make put the message in the exception clearer? e.g., the payload is null.",0,0.9899978041648865
52267604,764,junrao,2016-02-09T04:52:27Z,the confusion is that torelativeoffset() doesn't really return the relative offset as defined in line 150. would it be better to rename it to toinneroffset()?,0,0.9760236740112305
52267612,764,junrao,2016-02-09T04:52:41Z,"for compressed messages, we don't really set the timestamptype for inner messages. so, we need to make this clear. also, the inner message offset is not really the relative offset.",0,0.9696605205535889
52267620,764,junrao,2016-02-09T04:52:58Z,"since the offset of the inner message is not really the relative offset, we can probably just talk about how to derive the ao from the inner offset.",0,0.9858846068382263
52267622,764,junrao,2016-02-09T04:53:03Z,io is defined but not used.,0,0.9868578910827637
52267631,764,junrao,2016-02-09T04:53:19Z,"i left this comment in the previous review. do we need convertnoncompressedmessages()? since we can't do things in place, could we just use the path that deals with recompression to handle it? this will save some duplicated code.",0,0.9856164455413818
52267646,764,junrao,2016-02-09T04:53:35Z,is this check needed since we can only do in-place if magic is > 0?,0,0.9920821189880371
52267649,764,junrao,2016-02-09T04:53:38Z,5th -> 4th?,0,0.9891902208328247
52267651,764,junrao,2016-02-09T04:53:42Z,should we change the description for attribute?,0,0.9927597045898438
52267666,764,junrao,2016-02-09T04:53:56Z,could we add a comment to explain when do we expect wrappermessagetimestamp and wrappermessagetimestamptype to be not none?,0,0.9942745566368103
52267675,764,junrao,2016-02-09T04:54:05Z,"in line 168, should we set timestamptype in attribute?",0,0.9952529668807983
52267679,764,junrao,2016-02-09T04:54:08Z,indentation,0,0.822169840335846
52267681,764,junrao,2016-02-09T04:54:12Z,there are unused imports.,0,0.9208723902702332
52267687,764,junrao,2016-02-09T04:54:19Z,we only return the max timestamp of the inner messages if timestamptype is createtime.,0,0.9931240677833557
52267690,764,junrao,2016-02-09T04:54:24Z,would it be better to change samplemagicvalue to firstmagicvalue?,0,0.9944713115692139
52267700,764,junrao,2016-02-09T04:54:32Z,the message in the exception can be mis-leading since validatemagicvaluesandgettimestamp may not be called on a set of uncompressed messages.,0,0.9625681042671204
52267706,764,junrao,2016-02-09T04:54:51Z,"the method only iterates shallow messages. so, perhaps changing the method to magicvalueinallwrappermessages and adjusting the comments?",0,0.9841591119766235
52267737,764,junrao,2016-02-09T04:55:43Z,we can probably just check if all messages are on v0 since not all existing messages necessarily match the message format config.,0,0.9930484294891357
52267746,764,junrao,2016-02-09T04:55:59Z,it's probably better to log the # of bytes in the messageset instead of # of messages. the later will invoke the iterator and is more expensive.,0,0.9917003512382507
52267748,764,junrao,2016-02-09T04:56:04Z,incorrect indentation since this is the parameter for responsesize().,0,0.9566606283187866
52267763,764,junrao,2016-02-09T04:56:17Z,"we want to make it clear that the performance impact is only during the upgrade period. once the clients are upgraded or if people are just starting to use 0.10, there is no performance impact.",0,0.9900505542755127
52356387,764,becketqin,2016-02-09T19:02:42Z,"hi jun, this patch is using the message format version configured for this topic when doing compaction. the configuration is passed in in line 373. do you mean something else?",0,0.9915953278541565
52380036,764,becketqin,2016-02-09T21:52:37Z,"having a separate `convertnoncompressedmessages()` saves one round of memory copy. in `convertnoncompressedmessages()` we read from the old format and write the converted format directly into the new byte buffer. so there is only one memory copy. if we let the path that deals with re-compression to handle it, we need to first convert messages to required format (first memory copy), then write them together to a new byte buffer (second memory copy).",0,0.9929307699203491
52387545,764,junrao,2016-02-09T22:48:26Z,"hmm, i don't see the logic of format conversion though. for example, if there are uncompressed messages of v0 and the format of the topic is configured with v1, we should write messages of v1 to the new log segment. currently, it seems that we just keep the original message format.",0,0.8699248433113098
52389495,764,becketqin,2016-02-09T23:03:43Z,we always return the max timestamp of the inner messages as long as they are in v1.,0,0.9933817386627197
52405180,764,becketqin,2016-02-10T01:44:59Z,"hi jun, the tests on the configuration here is trying to address the following problem. after people just upgrade to 0.10.0.0, most of the fetch request are still in v1. in this case, if we check whether all the messages are v0 or not, we are essentially iterating over the file message set. by checking the configuration, we can avoid that. after people set message format to v1, we will only do the iterative check for old consumers (hopefully there won't be many at that point). the caveat of this approach is mentioned in the comments. after user set the message format to v1, if they decide to change the message format back to v0. the old consumer may see message v1 because of the discrepancy between actual message format and the config as you pointed out. do you prefer to simply take the performance cost right after people finish upgrade? this cost will go away after all the clients are upgraded, but that could be an extended period.",0,0.986462414264679
52503273,764,becketqin,2016-02-10T18:41:47Z,"ah, you are right. i'll fix that.",0,0.8054516911506653
52550562,764,becketqin,2016-02-11T00:34:48Z,"hi jun, i actually hesitated a little here. it seems this constructor should only be used by producer, so the timestamp should always be createtime. i added the timestamp type to constructor pretty lately because checksummessageformatter also needs to construct message in order to compute checksum. currently checksummessageformatter only takes key and value and always assume the compression type to be nocompression. this works because all the messages, including inner messages of compressed messages, should not have compression codec. however, because timestamp type can be different from message to message, we need to include timestamp type when computing checksum. we also need compression type because for compressed messages, inner message timestamp type is always createtime even when the timestamp type of the message is logappendtime defined by wrapper message. i did not find any usage of checksummessageformatter. i asked joel about this class, and it looks we used to use it in system test, but now we are not using it anymore. do you think we can simply remove this class?",0,0.5852822661399841
52609487,764,junrao,2016-02-11T14:44:42Z,"thanks, got your point. so, setting the message version to 0 in the config not only implies that future messages will be written in version 0, but all existing messages are of version 0 too? we should at least document this, but i am not sure if this is enough to warn people about the impact of switching back and forth of the message format config. could you run some experiments about the performance impact of doing the message format check?",1,0.5848156213760376
52780786,764,becketqin,2016-02-12T18:46:05Z,"hi jun, i ran the following experiment with the configuration check removed. i.e. always verify messages for fetch request v1. 1. start a new broker with message.format.version=v0. 2. produce 3000000 messages to topic with 128 partition using console producer. 3. consume the messages using console consumer in this rb (sending v2 fetch request, so no message format verification needed.) 4. consume the messages using console consumer in current trunk (sending v1 fetch request, so message verification is needed) the log below prints out the time cost on the verification code block: [code block] the first 4 lines are from v2 requests. the fifth line is from v1 and v2 mixed. the last 4 lines are from v1 requests. time unit is nano seconds. it seems the traversal cost is expensive.",0,0.9915710687637329
52814031,764,junrao,2016-02-12T23:47:08Z,"ok, then we can keep the version check there. could we update the config/upgrade doc to make it clear that by setting the message version on a topic, the user is certifying that all existing data are on that version and if that's not the case, the consumer before 0.10 will break?",0,0.9924556016921997
52815492,764,junrao,2016-02-13T00:08:23Z,"hi, jiangjie, independent of checksummessageformatter, shouldn't we set the attribute based on the timestamptype passed in? the caller is responsible for setting the timestamptype.",0,0.9943698048591614
52838521,764,junrao,2016-02-14T06:25:35Z,could we add the doc for timestamptype?,0,0.9931894540786743
52838529,764,junrao,2016-02-14T06:26:33Z,"since this will be part of the java doc, could we explain what the timestamp will be?",0,0.9913562536239624
52838534,764,junrao,2016-02-14T06:27:44Z,timestam -> timestamp type?,0,0.9924991726875305
52838535,764,junrao,2016-02-14T06:27:46Z,do we need the createtime at the end? ditto for the logappendtime at the end of line 30.,0,0.9933677315711975
52838538,764,junrao,2016-02-14T06:28:26Z,"if createtime is used, are we returning -1 for timestamp?",0,0.9939743876457214
52838543,764,junrao,2016-02-14T06:29:13Z,create times => createtime,0,0.9757644534111023
52838565,764,junrao,2016-02-14T06:32:40Z,the message format => that message format,0,0.9902856945991516
52838575,764,junrao,2016-02-14T06:34:35Z,need to remove prinitln.,0,0.9843186736106873
52838577,764,junrao,2016-02-14T06:35:01Z,should we throw kafkaexception instead?,0,0.9920593500137329
52838580,764,junrao,2016-02-14T06:35:43Z,"since the inner offset is not really the relative offset, we can probably just refer to it as inner offset and point to the description in the later text.",0,0.9921557307243347
52838587,764,junrao,2016-02-14T06:36:03Z,producer -> the producer create => creates,0,0.9724031686782837
52838590,764,junrao,2016-02-14T06:36:36Z,followings situation => following situations,0,0.9294949173927307
52838592,764,junrao,2016-02-14T06:36:54Z,probably better to rename to expectedinneroffset?,0,0.9938510656356812
52838595,764,junrao,2016-02-14T06:37:24Z,"it doesn't seem that we need to valid the input message here since this is already done in log,analyzeandvalidatemessageset().",0,0.9925290942192078
52838598,764,junrao,2016-02-14T06:38:07Z,would it be better to return a magicandtimestamp so that the caller doesn't have to iterate the message set again to get the magic?,0,0.9922425746917725
52838602,764,junrao,2016-02-14T06:38:33Z,numfetch and totaltime are unused.,0,0.9757673144340515
52838603,764,junrao,2016-02-14T06:38:51Z,"the value is now in bytes, not messages.",0,0.9920151233673096
52838608,764,junrao,2016-02-14T06:40:00Z,the whether -> whether,0,0.9369899034500122
52839564,764,becketqin,2016-02-14T08:36:19Z,"it seems that if we do not have the creattime at the end, java doc will show the entire qualifier, i.e. org.apache.kafka.common.record.timestamptype#createtime. this works but seems a little verbose. alternatively we can import the timestamptype class so we don't need to have a display name for the ``. do we have a convention for java doc in kafka? it seems we have different styles in the code base.",0,0.9428375959396362
52839682,764,becketqin,2016-02-14T08:48:20Z,"if createtime is used, we are returning user provided timestamp if it exists or the time when the record was handed to the producer.",0,0.9931029081344604
52847115,764,junrao,2016-02-14T19:01:21Z,"it seems that we need to reset absolutebaseoffset when we are done iterating the inner records. otherwise, the next record could be uncompressed and we will set the offset incorrectly. could we add a unit test that covers this?",0,0.9748337268829346
52847119,764,junrao,2016-02-14T19:01:28Z,incomplete sentence,0,0.905308723449707
52847121,764,junrao,2016-02-14T19:01:36Z,"reworded this a bit. see if it's clearer. since the api protocol may change more than once within the same release, to facilitate people deploying code from trunk, we introduce internal versions since 0.10.0. for example, the first time that we introduce a version change in 0.10.0, we will add a config value ""0.10.0-iv0"" and a corresponding case object kafka_0_10_0-iv0. we will also add a config value ""0.10.0"" that will be mapped to the latest internal version object, which is kafka_0_10_0-iv0. when we change the protocol a second time while developing 0.10.0, we will add a new config value ""0.10.0-iv1"" and a corresponding case object kafka_0_10_0-iv1. we will change the config value ""0.10.0"" to map to the latest internal version object kafka_0_10_0-iv1. config value of ""0.10.0-iv0"" is still mapped to kafka_0_10_0-iv0. this way, if people are deploying from trunk, they can use ""0.10.0-iv0"" and ""0.10.0-iv1"" to upgrade one internal version at a time. for most people who just want to use released version, they can use ""0.10.0"" when upgrading to 0.10.0 release.",0,0.9939737915992737
52847126,764,junrao,2016-02-14T19:02:02Z,"we should use the message format specified for the internal topic. in addition, we have to be a bit careful here, during a rolling upgrade, if a broker's inter-broker protocol version is still before 0.10.0, even if the message format is for v1, we will still want to use message format v0. otherwise, if another broker is still on the pre 0.10.0 code, it can't read the v1 message in the internal topic. ditto to the magic value setting below.",0,0.9175161719322205
52847133,764,junrao,2016-02-14T19:02:21Z,"there is a similar issue here. during rolling upgrade to 0.10.0, if a broker's inter-broker protocol version is still before 0.10.0, even if the message format is for v1, we will still want to use message format v0. otherwise, if another broker is still on the pre 0.10.0 code, it can't read the v1 message in the internal topic for things like log cleaning.",0,0.9823692440986633
52847134,764,junrao,2016-02-14T19:02:33Z,"similar issue as before, we need to further guard the message format based on inter protocol version so that we only use message format ready for every broker.",0,0.9912204146385193
52847137,764,junrao,2016-02-14T19:02:50Z,it seems that we may need to change the message format when copying out uncompressed messages too.,0,0.984621524810791
52847141,764,junrao,2016-02-14T19:02:54Z,the inner message offset is not really relative.,0,0.8753699660301208
52847144,764,junrao,2016-02-14T19:02:57Z,the inner message offset is not really relative.,0,0.8753699660301208
52847146,764,junrao,2016-02-14T19:03:06Z,it seems that timestamptype can only be none if magic is 0?,0,0.9880486130714417
52847149,764,junrao,2016-02-14T19:03:19Z,could we also add the need for this to be consistent with inter broker protocol (otherwise the setting will be ignored)?,0,0.9952945113182068
52847150,764,junrao,2016-02-14T19:03:23Z,are the changes here needed?,0,0.9910404086112976
52847151,764,junrao,2016-02-14T19:03:32Z,"since the fail and assertions are in the callback and we eat the exceptions, we probably need to propagate the failure to the main test method?",0,0.9928029179573059
52847154,764,junrao,2016-02-14T19:03:40Z,can we get the cause and check the exact exception time? ditto below.,0,0.9863572120666504
52847180,764,junrao,2016-02-14T19:05:18Z,it seems that we need to call validatetimestamp() in this case as well?,0,0.9945945143699646
52847192,764,junrao,2016-02-14T19:06:14Z,invalidmessageexception is used for corrupted messages. could we use a different exception and error code?,0,0.9757980704307556
52847218,764,junrao,2016-02-14T19:08:19Z,"thinking about this again, since it's possible for us to change the message format more than once within the same release and we need to make sure message format is consistent with inter protocol version, it's probably better to just use the values in apiversion to specify the message format. we can probably extend each of the case object in apiversion to add a magic field to indicate the message version associated with each protocol version. sorry for going back and forth on this one.",-1,0.9872431755065918
52850892,764,becketqin,2016-02-14T23:16:33Z,"hmm, absolutebaseoffset is only non-negative for inner iterators. the outer iterators always have absolutebaseoffset=-1. because we create a separate independent inner iterator for each compressed message set, the same absolutebaseoffset should be used by all the messages in that compressed message set. after we finish iterating one compressed message set and return to the outer iterator, the absolutebaseoffset of inner iterator will not affect the outer iterator, i.e. the outer iterator absolutebaseoffset remains -1. so even the next record is an uncompressed record, it should not be affected.",0,0.9801021218299866
52851922,764,becketqin,2016-02-15T00:20:05Z,"hi jun, we are doing message format conversion, right? if another broker is on old code and sends fetchrequest v1, we will down convert the message to v0. so it should not break even if leader has message format v1 on disk and follower is fetching using inter-broker protocol version before 0.10.0. i am wondering if we should simply let the internal topic message format comply with inter-broker protocol version. the reason is this guarantees no message format conversion is needed for internal topic replication. and it avoids manually setting message format version config for the internal topic.",0,0.9812880754470825
52852265,764,becketqin,2016-02-15T00:36:02Z,regarding the message format check. currently we do validate both broker and topic level configuration to make sure message format version is on or below inter-broker protocol version. so is it sufficient to simply use the message format version in the config?,0,0.9947525262832642
52852401,764,becketqin,2016-02-15T00:43:01Z,"sorry for the confusion, ""timestamptype"" in the comments should actually be ""wrappermessagetimestamptype"".",-1,0.9879181981086731
52852569,764,becketqin,2016-02-15T00:52:19Z,good catch. this might cause the test to just hang. it looks that in other multi-threaded test we have timeout in main thread. maybe we can do the same thing here.,1,0.6710383892059326
52852973,764,becketqin,2016-02-15T01:14:15Z,"i was also thinking about this when creating kafka-3203. currently we are also throwing invalidmessageexception if we non-keyed message for compacted topic. should we add invalidmagicbyteexception, invalidcodecexception, invalidtimestampexception and corresponding error mapping?",0,0.9799158573150635
52861805,764,junrao,2016-02-15T06:01:37Z,"yes, perhaps we can just add invalidtimestampexception in this patch and add others in kafka-3203.",0,0.9947612881660461
52861828,764,junrao,2016-02-15T06:02:18Z,"well, it may not hang. it just that if the assertion fails, the test may not fail since it only causes an exception in the callback thread. we can probably do sth like maintaining a successcount and check that at the end of flush.",0,0.9875739216804504
52861864,764,junrao,2016-02-15T06:03:24Z,"yes, you are right. didn't see the message format check in kafkaconfig. i think it's still better and simpler to just use the message format specified for the internal topic. this way, one can wait until inter protocol is upgraded to 0.10.0 in all brokers and then upgrade the message format w/o any conversion overhead. if we rely upon inter-broker protocol, there will still be some conversion while changing the inter-broker protocol in all brokers.",0,0.9597148299217224
52861870,764,junrao,2016-02-15T06:03:36Z,"thanks for the explanation. yes, i think this is fine since absolutebaseoffset is final.",1,0.7960550785064697
52861920,764,junrao,2016-02-15T06:04:11Z,"ok, sounds good.",1,0.7017148733139038
52862221,764,junrao,2016-02-15T06:05:32Z,"could we also add sth like the following. in particular, after the message format is set to v1, one should not change it back to v0 since it may break the consumer on versions before 0.10.0.",0,0.9948216676712036
52862231,764,junrao,2016-02-15T06:05:39Z,"could we add the following breaking change in 0.10.0? messageformatter def writeto(key: array[byte], value: array[byte], timestamp: long, timestamptype: timestamptype, output: printstream)",0,0.9937025308609009
52862239,764,junrao,2016-02-15T06:05:55Z,indentation,0,0.822169840335846
52862242,764,junrao,2016-02-15T06:06:01Z,are the changes in this file needed?,0,0.9932971596717834
52862251,764,junrao,2016-02-15T06:06:09Z,should we use magic v1 in this test?,0,0.9944549202919006
52862254,764,junrao,2016-02-15T06:06:13Z,typo converion,0,0.969730019569397
52862293,764,junrao,2016-02-15T06:06:47Z,it's not clear why this is needed. isn't the default of message version v1?,0,0.9499053955078125
52862309,764,junrao,2016-02-15T06:06:56Z,could we put the block from 185 to 191 in a method and reuse it in the subsequent blocks?,0,0.9954126477241516
52862322,764,junrao,2016-02-15T06:07:02Z,should we generate message of v1?,0,0.9932212829589844
52862344,764,junrao,2016-02-15T06:07:12Z,could we avoid duplicating the code btw v0 and v1?,0,0.9919339418411255
52862367,764,junrao,2016-02-15T06:07:23Z,"should we use message v1? since v1 is the default message format, it seems that v1 should be the format that we use in most tests.",0,0.9946582913398743
52862383,764,junrao,2016-02-15T06:07:31Z,"hmm, the overhead in message v1 is larger than message.minmessageoverhead.",0,0.9816042184829712
52862396,764,junrao,2016-02-15T06:07:36Z,"this same process can be used to upgrade from 0.8.x to 0.10.0, right?",0,0.9938608407974243
52865660,764,becketqin,2016-02-15T07:05:21Z,"just to clarify, by ""there will still be some conversion while changing the inter-broker protocol"", you meant downgrading inter-broker protocol, right? if user are bumping up inter-broker protocol, there will be no conversion. if so, considering inter-broker protocol downgrading is relatively rare and the impact is only during inter-broker protocol downgrade, does it still worth requiring user to change internal topic configuration as an extra step?",0,0.9886009097099304
52865992,764,becketqin,2016-02-15T07:12:43Z,"right, we have already have successcount like check. the test hangs because we usually call flush() in main thread to ensure all the messages are sent. some callbacks won't fire if sender thread dies due to assertion failure, hence flush() blocks forever. i will instead use producer.close(timeout) in main thread so it does not wait forever for the callbacks.",0,0.984745442867279
52869635,764,becketqin,2016-02-15T08:16:10Z,"yes, so i subtracted the additional timestamp length.",0,0.991006076335907
52922474,764,junrao,2016-02-15T17:00:51Z,"if the message format is tied to the inter-broker protocol, the first broker that upgrades its inter-broker protocol to 0.10.0 will start to have v1 messages in its log. since the rest of the brokers' inter-broker protocol is still before 0.10.0, they can only send v1 fetch request. therefore, the first broker has to convert v1 messages down to v0 in the fetch response. if we decouple the message format from inter-broker protocol, we can first keep message format to be v0. after every broker upgrades inter-broker protocol to 0.10.0 and starts using v2 fetch request, we then change message format to v1. at that point, there is no message format conversion needed.",0,0.9900798797607422
52962132,764,ijuma,2016-02-16T02:14:23Z,`if user` would read better as `if the user`.,0,0.9880762100219727
52962884,764,ijuma,2016-02-16T02:29:30Z,`overwritten by broker with broker local time when broker append` would read better as `overwritten by the broker with the broker local time when it appends`,0,0.9918888211250305
52963204,764,ijuma,2016-02-16T02:35:41Z,"`in either of the cases above, the timestamp that has actually been used will be returned to the user in`",0,0.990088164806366
53015522,764,ijuma,2016-02-16T14:19:28Z,"shouldn't these be called `no_timestamp_type`, `create_time` and `log_append_time` since this is java code? i personally prefer the scala convention (which is what we are using here), but it is inconsistent with all the java enums i looked at.",0,0.9732681512832642
53017909,764,ijuma,2016-02-16T14:36:37Z,this doesn't seem to be used at the moment.,0,0.9448230862617493
53018211,764,ijuma,2016-02-16T14:38:50Z,"sorry if this has been mentioned elsewhere, but why don't we reuse the java `timestamptype` instead of introducing a duplicate instance in scala code?",-1,0.9809752702713013
53018917,764,ijuma,2016-02-16T14:44:21Z,"why are we using an atomiclong here? this code doesn't have to be thread-safe, right (we are adding to an arraylist a few lines below with no locking for example)?",0,0.9912775754928589
53035417,764,ijuma,2016-02-16T16:27:18Z,"why we are using a linkedlist here? it rarely makes sense to use it, even the person who wrote it says so ([a link]",0,0.9566817283630371
53036739,764,ijuma,2016-02-16T16:35:11Z,maybe `arraydeque` would be better?,0,0.9938942790031433
53040684,764,ijuma,2016-02-16T16:57:43Z,it would probably be good to mention that `inneriter` will always have at least one element (and hence why we can just call `next()` on it without calling `hasnext()` first).,0,0.9914205074310303
53040990,764,ijuma,2016-02-16T16:59:20Z,maybe reference `magic_value_v1` instead of hardcoding `1` here?,0,0.9942291975021362
53041472,764,bill-warshaw,2016-02-16T17:02:23Z,"how would you feel about adding a testing constructor for this class that matches the existing signature, and would just use dummy values for the timestamp and `timestamptype`? eliminating that constructor will break compilation for any unit tests that rely on building `consumerrecord`s",0,0.9935320615768433
53048549,764,ijuma,2016-02-16T17:47:32Z,case 1 and 2 are the same at the moment. we could fall-through from case 1 to case 2 instead of having the same statement twice.,0,0.9796704053878784
53056249,764,becketqin,2016-02-16T18:39:32Z,do you mean the unit tests in projects other than kafka?,0,0.9917094111442566
53056903,764,bill-warshaw,2016-02-16T18:44:02Z,"yes. it's a minor change to update anywhere these constructors are used in unit tests, but any test that instantiates a `consumerrecord` isn't going to compile as soon as a user upgrades past `0.9.0.0`. we've used the `` annotation in the past to denote certain constructors that are only there for unit-testing.",0,0.9941971302032471
53058002,764,becketqin,2016-02-16T18:50:05Z,that makes sense. originally client side and server side timestamptype have some different methods. and i was thinking to combine the java and scala timestamptype class when we migrate server from message to record. we can probably combine the two classes in this patch.,0,0.9775057435035706
53106467,764,becketqin,2016-02-17T00:54:53Z,"i am not sure if we should add the testing constructor for other projects. it is a little bit weird to have a testing constructor which never used by kafka but for some unknown external project. technically speaking consumerrecord should only be constructed by kafka, but not other projects. if we do so, arguably we should maintain the constructor backward compatibility for any public class, even though most of them are not supposed to be constructed by any user.",-1,0.9196613430976868
53110159,764,bill-warshaw,2016-02-17T01:39:29Z,"if `consumerrecord` is only intended to be instantiated by kafka, then i withdraw my comment. internal apis shouldn't be forced to remain backwards-compatible.",0,0.6769713163375854
53142209,764,ijuma,2016-02-17T09:58:29Z,"`consumerfetcherthread` and `simpleconsumer` still use this class. given that, are we sure that we don't need to add a mapping here?",0,0.9941365718841553
53143828,764,ijuma,2016-02-17T10:13:32Z,would this read better as `messagetimestampmaxdifferencems`?,0,0.9944899082183838
53144348,764,ijuma,2016-02-17T10:18:06Z,should we be catching `apiexception` instead of individual cases like this?,0,0.9889495372772217
53202790,764,becketqin,2016-02-17T17:52:22Z,only produce will see this error code. so i think we are fine here.,0,0.9499757885932922
53203160,764,becketqin,2016-02-17T17:54:35Z,"i agree that would read better (in fact i used to use that name), but it seems we have `""*maxms""` for other configurations, so i just followed the convention.",0,0.9845043420791626
53204217,764,becketqin,2016-02-17T18:00:52Z,i don't have strong opinion on this. one benefit of having individual cases is that it is clear what kind of api exceptions are expected since not all api exceptions can be thrown from replica manager.,0,0.518510639667511
53263334,764,junrao,2016-02-18T02:08:56Z,"this comment is a bit hard to understand. given the comments at the beginning, we probably don't need the comment here.",-1,0.6281976103782654
53263338,764,junrao,2016-02-18T02:09:02Z,relative => inner,0,0.9656192660331726
53263354,764,junrao,2016-02-18T02:09:15Z,the way timestamp set is following => the way that timestamp is set is the following,0,0.989621639251709
53263360,764,junrao,2016-02-18T02:09:21Z,is set => are set,0,0.981171727180481
53263365,764,junrao,2016-02-18T02:09:26Z,following => the following,0,0.9483075141906738
53263370,764,junrao,2016-02-18T02:09:35Z,note => note; in a stream compressing way => in a streaming way,0,0.9880450367927551
53263375,764,junrao,2016-02-18T02:09:38Z,avoids => avoid,0,0.9204586148262024
53263382,764,junrao,2016-02-18T02:09:43Z,do we still need this comment?,0,0.9884083867073059
53263386,764,junrao,2016-02-18T02:09:50Z,it seems that minheadersize is the same as minmessageoverhead. could we consolidate them?,0,0.9923656582832336
53263400,764,junrao,2016-02-18T02:10:02Z,"would it be better to rename this to magicandlargesttimestamp()? also, the comment is outdated since we now return the magic as well.",0,0.994032084941864
53263409,764,junrao,2016-02-18T02:10:07Z,could we use the constant variable instead of 0?,0,0.9945403933525085
53263420,764,junrao,2016-02-18T02:10:18Z,incorrect indentation. the original one is correct.,0,0.6171358823776245
53263431,764,junrao,2016-02-18T02:10:37Z,unused import here. could you check other classes too?,0,0.9857355952262878
53263446,764,junrao,2016-02-18T02:10:54Z,we probably shouldn't mention 0.10.0-iv0 since it's not intended for public usage.,0,0.988896369934082
53263518,764,junrao,2016-02-18T02:11:50Z,"reworded the text a bit below. see if it's better. the maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message, if message.timestamp.type=createtime. a message will be rejected if the difference in timestamp exceeds this threshold. this configuration is ignored if message.timestamp.type=logappendtime.",0,0.9922768473625183
53263527,764,junrao,2016-02-18T02:11:58Z,"just to be consistent with what's in writeto, perhaps we should write the timestamp before key?",0,0.9939612150192261
53263537,764,junrao,2016-02-18T02:12:07Z,"to avoid duplicating code, could we pull line 237 to 245 into a private method and then reuse?",0,0.9928045868873596
53263541,764,junrao,2016-02-18T02:12:11Z,invalid => invalid; ditto below.,0,0.861337423324585
53263556,764,junrao,2016-02-18T02:12:21Z,"message.format.version change is an optimization. so, it's not really required. we can probably just cover that in the section on performance impact.",0,0.9918319582939148
53263559,764,junrao,2016-02-18T02:12:25Z,is this any different from any other topic?,0,0.984312117099762
53263566,764,junrao,2016-02-18T02:12:33Z,"instead of using v1/v0 in the message format, it's probably easier to understand if we just use the api version.",0,0.9910643100738525
53263572,764,junrao,2016-02-18T02:12:40Z,"we can just say that ""for clients that are upgraded to 0.10.0.0, there is no performance impact.""",0,0.9919275045394897
53291250,764,ijuma,2016-02-18T09:44:46Z,fair enough.,0,0.9010565876960754
53291541,764,ijuma,2016-02-18T09:47:25Z,my concern is that it's easy to miss new `apiexception` instances that could be thrown by the code above since we don't get help by the compiler. but we can consider handling this in a separate pr as you are maintaining the existing approach.,0,0.9815277457237244
53322688,764,ijuma,2016-02-18T14:48:18Z,"is there a reason why we don't pass the timestamp as a parameter to `analyzeandvalidatemessageset`? that would mean that `timestamp` could be a `val` instead of `var`. it's a straightforward change, but it would mean that we read `config.messagetimestamptype` outside the synchronized block. is that a problem?",0,0.9941362142562866
53342228,764,ijuma,2016-02-18T16:43:31Z,do we really need to mention the same thing so many times? it seems to me that it would be enough to mention once that message format 0 does not have a timestamp field and message format 1 does.,0,0.9877288341522217
53345876,764,ijuma,2016-02-18T17:05:16Z,"do we need this overload with timestamp and no timestamptype? there are only 3 usages in tests, i think i'd remove it.",0,0.9839615821838379
53383523,764,becketqin,2016-02-18T21:15:23Z,"if we do that, it seems possible to cause inconsistency order of message offset and timestamp. for example, message a comes and is stamped t1 by the broker, but before it is appended to the log, message b comes and is stamped t2 (t2 > t1) and gets appended to the log. after that, message a is appended. in this case, message a will have a smaller timestamp but a larger offset than message b, which is a bit confusing. we can put everything in the synchronized block, but it seems not worth doing if we only want to change a var to a val.",0,0.7142860293388367
53387576,764,becketqin,2016-02-18T21:44:34Z,"i am ok either way. as far as i understand, the purpose of the pre-existing constructor is to hide the payloadoffset and payloadsize from caller.",0,0.8728213906288147
53390466,764,ijuma,2016-02-18T22:06:34Z,"makes sense, thanks.",1,0.7218227386474609
53390818,764,ijuma,2016-02-18T22:09:44Z,"ok. since it was already there, better to handle the excessive use of constructor overloading separately.",0,0.9895724654197693
53413279,764,junrao,2016-02-19T01:51:17Z,can this be private?,0,0.9889413714408875
53413289,764,junrao,2016-02-19T01:51:25Z,the following properties => the following property,0,0.9829282164573669
53413303,764,junrao,2016-02-19T01:51:33Z,message format 0.10.0 => the message format in 0.10.0,0,0.9922763705253601
53413305,764,junrao,2016-02-19T01:51:35Z,of format 0.10.0 to earlier format => of the format in 0.10.0 to an earlier format,0,0.989538311958313
53413325,764,junrao,2016-02-19T01:51:48Z,"could we add what the interface is changed from? also, def is scala specific. we just need to include the java interface.",0,0.9910407662391663
53413342,764,junrao,2016-02-19T01:52:02Z,indicate the client support quota => indicate that the client supports quota,0,0.9831845164299011
53413403,764,junrao,2016-02-19T01:53:09Z,reworded this a bit to the following. see if it's better. ditto in topiccommand. this configuration will be ignored if the value is on a version newer than that specified in inter.broker.protocol.version in the broker.,0,0.992901086807251
53413412,764,junrao,2016-02-19T01:53:16Z,is the above addressed?,0,0.9921519756317139
53415057,764,becketqin,2016-02-19T02:18:05Z,it seems we cannot add scope modifier to a code block. compiler gives the following error: [code block] `verifyconvertedmessageset` itself seems private by nature and only accessible in `testmessageformatconversion`.,0,0.9919400811195374
53417265,764,becketqin,2016-02-19T02:50:09Z,"hi jun, this comment seems not accurate based on the current code. what we actually check is the message format version, not kafka version. for example, the current code will allow the message.format.version to be set to 0.9.0 even if the inter.broker.protocol.version is 0.8.2, because the underlying message.format.versions of those two kafka versions are the same. at some point i thought there was a use case for this, but i cannot think of any now. it is probably better to enforce the check as you described. i will make this change in the updated patch.",0,0.9623669385910034
1235169801,13870,dajac,2023-06-20T12:07:23Z,nit: could we prefix all those attributes with `genericgroup`?,0,0.9926059246063232
1235170208,13870,dajac,2023-06-20T12:07:48Z,we can't use the same config both both the consumer and the generic group because we have two configs for each.,0,0.9816315770149231
1235171243,13870,dajac,2023-06-20T12:08:49Z,nit: we can remove this one as there is the same phrase in the javadoc.,0,0.9910674691200256
1235178394,13870,dajac,2023-06-20T12:15:13Z,i am not a fan of returning a `group` here because it means that the caller have to cast the returned value. is it possible to avoid it?,-1,0.9020293951034546
1235178804,13870,dajac,2023-06-20T12:15:34Z,should we move this to the request validation?,0,0.9942144751548767
1235179626,13870,dajac,2023-06-20T12:16:19Z,i would remove this because it will be outdated extremely quickly.,0,0.905655026435852
1235180677,13870,dajac,2023-06-20T12:17:16Z,should we have a method helper to validate the request?,0,0.9941655397415161
1235188456,13870,dajac,2023-06-20T12:24:19Z,nit: would it make sense to update `plainprotocolset` to take `request.protocols()`?,0,0.9953385591506958
1235190243,13870,dajac,2023-06-20T12:25:52Z,"when the group is created to the first time, i think that we need to write a record to the log; the group could be reverted in the timeline hash map otherwise.",0,0.9892109632492065
1235202608,13870,dajac,2023-06-20T12:36:20Z,we need to discuss whether we want to start the heartbeat timer here or not. see [a link].,0,0.9925516843795776
1235206095,13870,dajac,2023-06-20T12:39:01Z,"do we still need `hassatisfiedheartbeat` in the new model? if the timeout expires, it seems to me that it means that the member has failed to heartbeat in time; the timer would have been reset otherwise.",0,0.9928869605064392
1235232078,13870,dajac,2023-06-20T12:59:58Z,i wonder if we should use a different timer for this case. have you considered it?,0,0.9695121645927429
1235241285,13870,dajac,2023-06-20T13:07:13Z,"instead of storing the initial rebalance timeout and the initial rebalance delay in the group, could we imagine passing them as arguments to `trycompleteinitialrebalanceelseschedule`? that could simplify the logic as everything would be self contain here.",0,0.9949486255645752
1235274474,13870,dajac,2023-06-20T13:31:31Z,what happens if the group instance id is an empty string?,0,0.9857983589172363
1235276378,13870,dajac,2023-06-20T13:32:56Z,i suppose that being here means that group instance id is null.,0,0.9868349432945251
1235277768,13870,dajac,2023-06-20T13:33:58Z,i have seen this code in a few place. it would be great to avoid it if possible.,0,0.5108147263526917
1235310632,13870,dajac,2023-06-20T13:56:02Z,shouldn't we use `completablefuture ` and complete the future exceptionally with the exception corresponding to the error?,0,0.992923378944397
1235497178,13870,jeffkbkim,2023-06-20T16:11:16Z,i think we should store generic groups separately. the added benefit here is that we wouldn't have to create a new record when a new group was created as you have mentioned in the comment below. wdyt?,0,0.9528416395187378
1235653740,13870,jeffkbkim,2023-06-20T18:24:23Z,i removed this; we have request validation in groupcoordinatorservice#joingroup. what do you think of having all request validation there?,0,0.9934285283088684
1235733198,13870,jeffkbkim,2023-06-20T19:26:09Z,"i don't think this fits well because we may have other records to append in this method. as mentioned above, i will store the generic groups in a separate hash map to prevent this from happening.",0,0.9476960301399231
1235734010,13870,jeffkbkim,2023-06-20T19:26:49Z,see [a link],0,0.9869033098220825
1235752587,13870,jeffkbkim,2023-06-20T19:46:36Z,"so that i understand: during completing rebalance, we schedule both pending sync (rebalance timeout) and heartbeats (session timeout). in practice, session timeout << rebalance timeout so heartbeats would expire and remove members. with cooperative rebalancing members should still be able to fetch records during completing rebalance phase. we want to extend the heartbeat here to rebalance timeout so that members are not removed by session timeout. is this correct? if so, i agree removing the heartbeat schedule sounds like the best approach since members are removed when pending sync expires anyways.",0,0.9862463474273682
1235808438,13870,jeffkbkim,2023-06-20T20:44:35Z,if the member is awaiting on a join/sync response then we can't remove the member on hb expiration right?,0,0.9863778352737427
1235813521,13870,jeffkbkim,2023-06-20T20:50:21Z,are you suggesting a different key? what would be the benefit?,0,0.9895249605178833
1235818207,13870,jeffkbkim,2023-06-20T20:54:59Z,initial rebalances don't have check and complete as try complete always returns false so this works. thanks,1,0.8964291214942932
1235822238,13870,jeffkbkim,2023-06-20T20:58:34Z,the existing protocol allows empty group instance ids for static member,0,0.9930505752563477
1235823024,13870,jeffkbkim,2023-06-20T20:58:57Z,"you're right, removed.",0,0.6231644749641418
1238417804,13870,dajac,2023-06-22T11:51:17Z,"i am not convinced. the downside is that it will be harder to guarantee to uniqueness of the group id. it also means that we would have to check both maps for all other operations (e.g. list, delete, etc.). i think that it would be better to keep them in a single map. for this particular case, we could just have two methods: `getormaybecreateconsumergroup` and `getormaybecreategenericgroup`.",0,0.9065030813217163
1238418966,13870,dajac,2023-06-22T11:52:26Z,i think that static validation could be done in the group coordinator service; however we have to keep the validation which depends on internal values in the state machine.,0,0.9925389885902405
1238484735,13870,dajac,2023-06-22T12:52:04Z,"that's correct. however, it may be better to just cancel the previous one.",0,0.9920725226402283
1238491877,13870,dajac,2023-06-22T12:58:00Z,i think that the non-error case is actually incorrect based on the implementation in the runtime. the issue is that the future will be completed immediately after the records are written. this means that we would send the response before the record is committed. i think that the future should be completed only when the records are committed.,0,0.9875013828277588
1238494924,13870,dajac,2023-06-22T13:00:19Z,"what does happen when this exception is thrown? i mean, where is it handled?",0,0.9559659361839294
1238559395,13870,dajac,2023-06-22T13:48:16Z,did you consider using a switch here? it seems that it would fit nicely.,0,0.9833347201347351
1238565407,13870,dajac,2023-06-22T13:52:35Z,nit: should we have an method such as `hasassignment()` in member?,0,0.994269609451294
1238585947,13870,dajac,2023-06-22T14:06:54Z,this feels a bit like a hack. i was wondering if we could push that call to `completegenericgroupjoin(group)` into the `genericgroupjoinnewmember` and `genericgroupjoinexistingmember` paths instead of handling it here for all cases. is it something that you have considered?,-1,0.8053759932518005
1238591771,13870,dajac,2023-06-22T14:11:10Z,"this is correct. btw, if we remove it, i think that we need to ensure that the session timeout is cancelled when a member rejoins.",0,0.9826515316963196
1238593470,13870,dajac,2023-06-22T14:12:26Z,"correct. however i think that the fundamental issues is that we do not cancel the session timeout while doing a rebalance. this is why we have this condition here. if we fix this, we may be able to remove it.",0,0.9834005236625671
1238594022,13870,dajac,2023-06-22T14:12:53Z,right. separation of concerns would be the benefit.,0,0.9748930931091309
1238626957,13870,dajac,2023-06-22T14:37:10Z,it seems that the condition was `group.is(empty)` in scala. what's the reason for changing it?,0,0.9926993250846863
1238627417,13870,dajac,2023-06-22T14:37:28Z,nit: extra empty line.,0,0.8511092662811279
1238630708,13870,dajac,2023-06-22T14:39:46Z,"actually, it seems that `completegenericgroupjoin` is already called in a few places on those paths.",0,0.9926599860191345
1238633046,13870,dajac,2023-06-22T14:41:05Z,nit: should we have an overload of `supportsprotocols` which takes `request.protocols()`?,0,0.9953676462173462
1238643069,13870,dajac,2023-06-22T14:48:13Z,nit: could we move this to the test then?,0,0.9912051558494568
1238647097,13870,dajac,2023-06-22T14:51:16Z,nit: let's remove this one as well.,0,0.977760374546051
1238724392,13870,dajac,2023-06-22T15:49:12Z,"one issue here is that if `generaterecordsandappendfuture` thrown an exception (e.g. due to a bug), the request will never be completed because the future is not available yet. if we reuse `coordinatorwriteevent`, we could subscribe to the future returned by it and complete the response when an exception is raised.",0,0.9930425882339478
1238725344,13870,dajac,2023-06-22T15:49:57Z,we probably need to convert some of the exceptions like i did for the consumer group heartbeat request.,0,0.9863015413284302
1239316537,13870,jeffkbkim,2023-06-23T04:48:54Z,are you referring to any lingering heartbeats at this point? i think we can just cancel them here right,0,0.9803933501243591
1239318379,13870,jeffkbkim,2023-06-23T04:53:31Z,"i think we can cancel the existing heartbeat when a member rejoins during a rebalance. this will still expire if the member does not rejoin which is what we want. also, moving the new member join timeout to a different key will help remove this `hassatisfiedheartbeat`. is that what you had in mind?",0,0.9932990074157715
1239320095,13870,jeffkbkim,2023-06-23T04:57:15Z,i expected that kafkaapis#handlejoingrouprequest will handle them. is that not the case?,0,0.9933320879936218
1240399005,13870,jeffkbkim,2023-06-23T21:09:13Z,"this is now further worsened with the new records on creating a group. the only ""non-hacky"" approach i can think of is just returning `list , record>` which the runtime would append & commit then complete in order. but this adds a lot of complexity for something we actually won't use in practice. the other approach (which i have implemented) is to ignore the result from `completegenericgroupjoin` when invoked from the join group path. this works because `completegenericgroupjoin` only produces records when a member expires. also, when a new group is created we don't have any other records to append. however, this still feels a bit hacky. not sure how to resolve this.",0,0.933223307132721
1240415098,13870,jeffkbkim,2023-06-23T21:23:12Z,"i thought the ""initial"" rebalance only applied to when the group is first created from [a link] but according to [a link] it looks like we want this for an empty group as well so, i will revert this change. however, it's awkward because here we consider ""initial rebalance"" to be an empty group. but a different part of the code checks generation id == 0. maybe it's because we don't know the previous state from groupcoordinator#addmemberandrebalance: [code block] i think we need to revert the change and include `initialrebalancedelayms` to the genericgroup object and rely on that to check whether the group is undergoing an initial rebalance.",0,0.6102768182754517
1240441622,13870,jeffkbkim,2023-06-23T21:58:30Z,"i'm a bit confused, is the coordinator write operation future the result we wait for committing?",-1,0.8842617869377136
1243806647,13870,dajac,2023-06-27T14:04:01Z,"how about the following? we keep track whether the group was newly created in a boolean. when we get the result from those methods, we check if the group is new, if it is, we check if the result has at least one record. if it does not, we recreate it while adding an empty record for the group.",0,0.9922792911529541
1246778958,13870,dajac,2023-06-29T15:21:28Z,"yeah, it seems that the current implementation is inconsistent.",-1,0.7381008863449097
1246964799,13870,CalvinConfluent,2023-06-29T18:24:56Z,the timer is not used yet. is it a place holder here?,0,0.9871456623077393
1246972433,13870,CalvinConfluent,2023-06-29T18:33:21Z,"i guess i missed some of the previous discussions, but why it is always either stable or empty when we load a group? does it mean the rebalancing process will be reverted if the coordinator fails?",0,0.9733697772026062
1246984793,13870,CalvinConfluent,2023-06-29T18:46:27Z,"the genericgroupjoinmember can returns a result, why don't we use the return value?",0,0.9927145838737488
1246995181,13870,CalvinConfluent,2023-06-29T18:56:21Z,do we need to handle the illegalstateexception(when member id is not known) and complete the responsefuture here?,0,0.9920037388801575
1247810650,13870,dajac,2023-06-30T12:31:40Z,"sorry, i was not clear. i meant that we need to port this [a link] here.",-1,0.9908089637756348
1247812716,13870,dajac,2023-06-30T12:34:06Z,"nit: i am not a fan of this validation. i wonder if we should just have two helpers: `isgroupidnotnull` and `isgroupidnotempty`. in this pr, we would only need `isgroupidnotempty`. what do you think?",-1,0.8075764179229736
1247814090,13870,dajac,2023-06-30T12:35:49Z,"i wonder if we need to handle the future returned by `schedulewriteoperation` as well. at minimum, we may want to react to errors. this could for instance happen if something goes wrong before the join group handling is event triggered.",0,0.9762867093086243
1247815228,13870,dajac,2023-06-30T12:37:09Z,nit: `completionfuture` or smth similar may be a better name here because we could have an operation without any records.,0,0.9941043257713318
1247815765,13870,dajac,2023-06-30T12:37:47Z,how about adding a boolean `replayrecords` to the coordinatorresult?,0,0.9946334362030029
1247816731,13870,dajac,2023-06-30T12:38:40Z,"i wonder if we should complete both future here. as `schedulewriteoperation` returns a future, it may be missed used otherwise. what do you think?",0,0.9719582200050354
1247817889,13870,dajac,2023-06-30T12:39:56Z,nit: could we revert this?,0,0.971430778503418
1247820936,13870,dajac,2023-06-30T12:43:22Z,"`topicpartition` should also be required, i think.",0,0.993923008441925
1247822722,13870,dajac,2023-06-30T12:45:23Z,i think that the group should be deleted in this case.,0,0.9739230871200562
1247825718,13870,dajac,2023-06-30T12:48:37Z,i wonder if we could avoid passing the version to this method by adding `-1` as the default value of `rebalancetimeout` in `groupmetadatavalue`. it seems that we could rely on this to decide here. another way that i was thinking about would be to pass the `record` to the replay method as it contains all the available information. have you considered this?,0,0.9907435774803162
1247826747,13870,dajac,2023-06-30T12:49:45Z,"we only write a record when the rebalance completes. this implies that the record is always empty or has members. as you pointed out, a failure happening before the rebalance complete is lost.",0,0.9909495711326599
1247831310,13870,dajac,2023-06-30T12:54:40Z,have you considered checking if the group exists in the map instead of adding this field? using a field like this has the disadvantage that we must ensure that it is set to false. i think that your implementation already misses it.,0,0.9833531379699707
1247837102,13870,dajac,2023-06-30T13:00:46Z,don't we need to fail the future if the write fails? or is it done somewhere else?,0,0.9819197058677673
1247839533,13870,dajac,2023-06-30T13:03:09Z,i am not satisfied with this logic here. i think that other folks won't understand this... we need to come up with a better way. i will think about it. i don't recall if i already asked this but would it be possible to push `completegenericgroupjoin` into `genericgroupjoinnewmember` and `genericgroupjoinexistingmember` instead of having it here?,-1,0.5882068872451782
1247843963,13870,dajac,2023-06-30T13:07:41Z,"hum... those exceptions will be caught by the `coordinatorwriteevent` and used to complete the future there. so, i suppose that they will be propagated to the api layer via this mechanism. do i get this right?",0,0.8676881790161133
1247846953,13870,dajac,2023-06-30T13:10:13Z,could we remove this? `genericgroupnewmemberjointimeoutms` is very likely passed to this object by the test itself so i am not sure to understand why we need to expose it to the test. is there a reason?,0,0.9748393893241882
1253477738,13870,jeffkbkim,2023-07-05T18:25:13Z,"i don't think this is the right place; we need to add the logic inside group metadata manager. i have done so in the sync pr. the reason is that for generic group apis, the append future is what we want the logic for when handling log append/commit errors. whereas for the new protocol, the consumer group heartbeat waits to return the results from the append/commit.",0,0.9900423288345337
1253484339,13870,jeffkbkim,2023-07-05T18:32:34Z,i'll remove this for now and add it back if we decide to pass it in later.,0,0.9874078035354614
1253487385,13870,jeffkbkim,2023-07-05T18:36:08Z,the approach is hacky. will be thinking of a different approach to resolve this,-1,0.9876438975334167
1253522689,13870,jeffkbkim,2023-07-05T19:11:59Z,"i will take your suggestion for this pr. however, it does make more sense to have the logic in one place instead of using isgroupidnotnull/isgroupidnotempty based on the request.",0,0.9593681693077087
1253525703,13870,jeffkbkim,2023-07-05T19:15:48Z,this is only used when records are generated (and need to be appended to the log) so i think append future makes more sense. `completionfuture` will be confusing alongside coordinator event's `future` field. wdyt?,0,0.9857682585716248
1253814655,13870,jeffkbkim,2023-07-06T01:27:38Z,for 1) doesn't it require a bump in the group metadata value version to add the default value? 2) i don't see much value in this and it feels more different to handle it this way compared to other record types in replicatedgroupcoordinator#replay(record),0,0.9921879768371582
1253817939,13870,jeffkbkim,2023-07-06T01:33:42Z,will revisit this after refactoring the coordinatorresult return type / generate multiple records discussion. the reason that a field was set is because where we add the group to `groups` (and initialize the append future) and where we set it as a return type (l1265) are at different places. once the group is added we can't check via groups.get(groupid).,0,0.9950644373893738
1253948284,13870,jeffkbkim,2023-07-06T05:26:40Z,the write event will catch the exception and complete the event's future. i added a handler to groupcoordinatorservice.java for these unexpected exceptions.,0,0.989128053188324
1253948390,13870,jeffkbkim,2023-07-06T05:26:50Z,added a previousstate to genericgroup. we will rely on this instead to confirm that a group is undergoing an initial rebalance (previous state == empty),0,0.9946034550666809
1253948479,13870,jeffkbkim,2023-07-06T05:27:00Z,"yeah, i will log an error for this",0,0.5348223447799683
1254577233,13870,dajac,2023-07-06T15:07:30Z,i think that we can remove this and `metadataimage` as [a link] was merged.,0,0.9817428588867188
1254579000,13870,dajac,2023-07-06T15:08:56Z,why do we only handle `illegalstateexception` here? why if we get an unexpected npe for instance.,0,0.9750134348869324
1254579343,13870,dajac,2023-07-06T15:09:12Z,nit: this could be static.,0,0.9628223776817322
1254580740,13870,dajac,2023-07-06T15:10:16Z,nit: should we move those two back to where they where?,0,0.9809020757675171
1254582473,13870,dajac,2023-07-06T15:11:39Z,could we move this one back to where it was? it should stay together with the other `withconsumergroup*` methods.,0,0.9950425624847412
1254582995,13870,dajac,2023-07-06T15:12:04Z,why did we move this one?,0,0.9671566486358643
1254584209,13870,dajac,2023-07-06T15:13:07Z,nit: empty line could be removed.,0,0.9870886206626892
1254584535,13870,dajac,2023-07-06T15:13:21Z,nit: should we revert this change?,0,0.986498236656189
1254584801,13870,dajac,2023-07-06T15:13:33Z,nit: should we revert this change?,0,0.986498236656189
1254585208,13870,dajac,2023-07-06T15:13:52Z,nit: should we revert this change?,0,0.986498236656189
1254585768,13870,dajac,2023-07-06T15:14:19Z,nit: should we revert this change?,0,0.986498236656189
1254587698,13870,dajac,2023-07-06T15:15:51Z,1) good question. the schema remains the same so it should be ok. it only adds a default value to the field.,1,0.8971214890480042
1254612652,13870,dajac,2023-07-06T15:36:23Z,"i am not sure to follow. it seems to me that you could have a local boolean to track this. for instance, before calling `getormaybecreategenericgroup`, you could initialise a variable `groupexists` by checking the map.",0,0.9358099699020386
1254999681,13870,jeffkbkim,2023-07-06T22:53:31Z,"i misunderstood, moved to using a local variable",-1,0.5691132545471191
1255794837,13870,dajac,2023-07-07T13:05:30Z,would it make sense to move this block into the `if (isnewgroup && result == empty_result)`?,0,0.9956310987472534
1255797868,13870,dajac,2023-07-07T13:08:02Z,remember this [a link]? don't we need to convert the exception here as well? this is why i was suggesting to do it in the service to ensure that we do it in all cases.,0,0.9921636581420898
1255798698,13870,dajac,2023-07-07T13:08:41Z,nit: javadoc?,0,0.9874733686447144
1255799314,13870,dajac,2023-07-07T13:09:08Z,nit: empty line could be removed.,0,0.9870886206626892
1255799771,13870,dajac,2023-07-07T13:09:29Z,nit: empty line.,0,0.783897340297699
1255800519,13870,dajac,2023-07-07T13:10:02Z,nit: empty line.,0,0.783897340297699
1255803548,13870,dajac,2023-07-07T13:12:27Z,nit: incomplete javadoc.,0,0.5575715899467468
1255807406,13870,dajac,2023-07-07T13:15:14Z,nit: `containskey`?,0,0.9933618307113647
1255809962,13870,dajac,2023-07-07T13:17:08Z,nit: empty line.,0,0.783897340297699
1255812336,13870,dajac,2023-07-07T13:18:48Z,nit: do we need this as all the states are covered?,0,0.990139901638031
1255826174,13870,dajac,2023-07-07T13:28:59Z,nit: should we inline this condition and move the comment within the branch?,0,0.9926097989082336
1255827611,13870,dajac,2023-07-07T13:30:02Z,nit: should we name this variable `newmember`?,0,0.9937624335289001
1255828754,13870,dajac,2023-07-07T13:30:54Z,nit: this could be inlined.,0,0.9874969720840454
1255828976,13870,dajac,2023-07-07T13:31:03Z,nit: empty line.,0,0.783897340297699
1255830986,13870,dajac,2023-07-07T13:32:33Z,nit: how about using: `.setmembers(isleader ? group.currentgenericgroupmembers() : collections.emptylist())`?,0,0.9950318336486816
1255832177,13870,dajac,2023-07-07T13:33:23Z,nit: i think that the error code is zero by default so we don't have to set it.,0,0.9832388162612915
1255832458,13870,dajac,2023-07-07T13:33:35Z,nit: empty line.,0,0.783897340297699
1255833047,13870,dajac,2023-07-07T13:34:01Z,nit: empty line.,0,0.783897340297699
1255833259,13870,dajac,2023-07-07T13:34:11Z,nit: ditto about error code.,-1,0.9693333506584167
1255833655,13870,dajac,2023-07-07T13:34:27Z,nit: empty line.,0,0.783897340297699
1255836858,13870,dajac,2023-07-07T13:36:43Z,nit: empty line.,0,0.783897340297699
1255838176,13870,dajac,2023-07-07T13:37:41Z,nit: the code style is a bit inconsistent between this line and l2526. i don't have a preference but it would be great if we could use the same format everywhere.,0,0.655640721321106
1255839487,13870,dajac,2023-07-07T13:38:39Z,i think that we can remove those. it is clear that we do nothing for this state if it is not listed before. there are a few other cases.,0,0.9829332828521729
1255840000,13870,dajac,2023-07-07T13:39:00Z,is this used anywhere?,0,0.989799976348877
1255849529,13870,dajac,2023-07-07T13:45:55Z,nit: empty line.,0,0.783897340297699
1255851195,13870,dajac,2023-07-07T13:46:55Z,nit: empty line.,0,0.783897340297699
1255863985,13870,dajac,2023-07-07T13:56:07Z,we could inline this as suggested earlier.,0,0.9912102222442627
1255864318,13870,dajac,2023-07-07T13:56:20Z,we can omit setting the error code.,0,0.9854924082756042
1255865580,13870,dajac,2023-07-07T13:57:08Z,ditto.,0,0.6705162525177002
1255868223,13870,dajac,2023-07-07T13:58:55Z,we need to update the javadoc here. i also wonder if we could find a better name now as it may also complete the join phase.,0,0.9864720106124878
1255878155,13870,dajac,2023-07-07T14:05:34Z,nit: we usually use `maybe`. i understand that this comes from the old purgatories but it may be better to use the correct naming convention.,0,0.9927045106887817
1255881371,13870,dajac,2023-07-07T14:07:59Z,nit: empty line.,0,0.783897340297699
1255883963,13870,dajac,2023-07-07T14:09:59Z,nit: you can replace `{}-{}` with `{}` and directly pass the topicpartition.,0,0.9938274025917053
1255885261,13870,dajac,2023-07-07T14:10:54Z,nit: package private for testing.,0,0.9890003204345703
1255886494,13870,dajac,2023-07-07T14:11:43Z,nit: empty line.,0,0.783897340297699
1255889149,13870,dajac,2023-07-07T14:13:25Z,nit: empty line.,0,0.783897340297699
1255892012,13870,dajac,2023-07-07T14:15:01Z,why do we need a copy here?,0,0.9843370318412781
1255894010,13870,dajac,2023-07-07T14:16:12Z,could we expand this comment a little?,0,0.9904792904853821
1255894583,13870,dajac,2023-07-07T14:16:34Z,we can remove this now.,0,0.9844797253608704
1256037213,13870,jeffkbkim,2023-07-07T15:48:20Z,which illegal state exception are you referring to?,0,0.9711737036705017
1256038506,13870,jeffkbkim,2023-07-07T15:49:17Z,"as discussed offline, we will complete both futures. the append future will be completed first and the event future will complete the join response if it's not already completed.",0,0.9925841093063354
1256056130,13870,jeffkbkim,2023-07-07T16:02:32Z,updated to all errors.,0,0.9601728916168213
1256069184,13870,jeffkbkim,2023-07-07T16:08:58Z,reverted the ordering,0,0.9832248687744141
1256110776,13870,jeffkbkim,2023-07-07T16:37:10Z,the issue is that the records need to be generated while the group is empty. after performing `genericgroupjoinnewmember()` the group will have added the member metadata. the existing protocol only allows records for empty groups or groups that have a defined protocol. this only applies to join group requests with `requireknownmemberid = false` or group instance id.,0,0.994672954082489
1256152143,13870,jeffkbkim,2023-07-07T17:10:29Z,the main concern i had was completegenericgroupjoin() can be invoked by the timer which would miss this conversion but i guess it's not really an issue.,0,0.9740724563598633
1256157423,13870,jeffkbkim,2023-07-07T17:14:57Z,i added this in case we add a new state in the future. should i remove it?,0,0.9923192858695984
1256163265,13870,jeffkbkim,2023-07-07T17:19:38Z,isn't it more readable to keep it?,0,0.9718837141990662
1256180440,13870,jeffkbkim,2023-07-07T17:33:38Z,in `groupmetadatamanager#expirependingsync()` we remove members from the set while iterating,0,0.9934900999069214
1258225411,13870,dajac,2023-07-10T12:59:31Z,i wonder if we should remove this because it will log all errors now.,0,0.8500295877456665
1258226163,13870,dajac,2023-07-10T13:00:04Z,i am a bit confused here. don't we need to apply this conversion to `responsefuture` as well?,-1,0.5860332250595093
1258226528,13870,dajac,2023-07-10T13:00:20Z,you can remove this one because it can't happen now.,0,0.986743688583374
1258226646,13870,dajac,2023-07-10T13:00:26Z,ditto.,0,0.6705162525177002
1258228530,13870,dajac,2023-07-10T13:01:52Z,"it may be better to inline this code because the handling could be different depending on the request type. if i remember correctly, it is slightly different for offset commits for instance.",0,0.9868393540382385
1258228818,13870,dajac,2023-07-10T13:02:07Z,could we bring this back?,0,0.9907767176628113
1258229353,13870,dajac,2023-07-10T13:02:32Z,nit: should we add `throws groupidnotfoundexception`?,0,0.9934282898902893
1258230722,13870,dajac,2023-07-10T13:03:38Z,i think that we should rather add this to the `onloaded` method rather than here. the issue is that it will also log all the non-compacted records and that will be misleading.,0,0.9829421043395996
1258231101,13870,dajac,2023-07-10T13:03:55Z,nit: `data structure`?,0,0.9927318692207336
1258231284,13870,dajac,2023-07-10T13:04:03Z,nit: remove empty line.,0,0.9612911343574524
1258232766,13870,dajac,2023-07-10T13:05:13Z,"for my understanding, we don't fail the future here because the event future will do it. am i correct?",0,0.9608156681060791
1258235016,13870,dajac,2023-07-10T13:06:59Z,i see. i wonder if we could have a `newgroupemptymetadatarecord` which generate an empty record for the group in this case to avoid this issue. would this work? i am asking because i think that centralising would simplify the code.,0,0.972258448600769
1258236219,13870,dajac,2023-07-10T13:07:54Z,nit: `maybe...`?,0,0.9862333536148071
1258269899,13870,dajac,2023-07-10T13:30:30Z,nit: i was considering whether we should have an helper in the joinrequest class for this. it could be something like `joinrequest#requireknownmemberid(short version)`. that advantage is that it would centralize all the version handling in one place. we could do the same for the other similar cases. what do you think?,0,0.9868851900100708
1258278071,13870,dajac,2023-07-10T13:35:54Z,"we can keep it, i suppose.",0,0.9804736375808716
1258280008,13870,dajac,2023-07-10T13:37:15Z,"nit: could we expand this error a little? it would be great if it could capture that it failed to update the metadata for a static member, etc.",0,0.9719641804695129
1258280313,13870,dajac,2023-07-10T13:37:27Z,i would remove them.,0,0.9705713987350464
1258281079,13870,dajac,2023-07-10T13:37:58Z,"nit: `"" + ""` the `+` in this case is not needed.",0,0.967723548412323
1258287486,13870,dajac,2023-07-10T13:42:02Z,"i just noticed that whenever we use `joinreason`, we also have the `joingrouprequestdata`. how about adding a helper in `joinrequest` class to get the reason from `joingrouprequestdata`? then, we don't have to pass it anymore to all the methods and we can remove the logic to compute it in `genericgroupjoin`. what do you think?",0,0.9856112003326416
1258291357,13870,dajac,2023-07-10T13:44:19Z,nit: `replayrecords`?,0,0.9926809668540955
1258295996,13870,dajac,2023-07-10T13:47:02Z,i was wondering if the following is simpler: [code block] then [code block] i leave it up to you.,0,0.971405029296875
1258313403,13870,dajac,2023-07-10T13:57:05Z,why is this false?,0,0.8406454920768738
1258314600,13870,dajac,2023-07-10T13:57:49Z,it may be better to validate the full response here.,0,0.9870409965515137
1258314933,13870,dajac,2023-07-10T13:58:02Z,do we need to add tests for the errors convertion?,0,0.9935078620910645
1258319481,13870,dajac,2023-07-10T14:01:24Z,should we revert this?,0,0.9863643050193787
1258320244,13870,dajac,2023-07-10T14:02:02Z,could we revert this?,0,0.988563060760498
1258320551,13870,dajac,2023-07-10T14:02:16Z,why are we changing this?,0,0.9637394547462463
1258320790,13870,dajac,2023-07-10T14:02:26Z,nit: empty line.,0,0.783897340297699
1258356121,13870,dajac,2023-07-10T14:29:27Z,this feels weird.... you pass the expected result and you alter it here. i think that it would be better to separate concerns and to return records and future to the caller and to let it do the validation.,-1,0.990230143070221
1258356713,13870,dajac,2023-07-10T14:29:54Z,"do we need this? if we do, we should replace `e.printstacktrace();`.",0,0.9931053519248962
1258356890,13870,dajac,2023-07-10T14:30:03Z,ditto.,0,0.6705162525177002
1258362905,13870,dajac,2023-07-10T14:34:12Z,is this needed? i would have thought that the group should have been created by the first request.,0,0.990924060344696
1258367695,13870,dajac,2023-07-10T14:37:48Z,nit: empty line.,0,0.783897340297699
1258368278,13870,dajac,2023-07-10T14:38:12Z,is this needed as well?,0,0.9907124638557434
1258375164,13870,dajac,2023-07-10T14:43:18Z,"why do we need to handle the first request differently? is it because it may generate a record? if so, i would not do this in every tests but only in one test focused on this.",0,0.983849287033081
1258375867,13870,dajac,2023-07-10T14:43:48Z,"nit: `intstream.range(0, groupmaxsize + 1)` that you just used above is pretty nice. i wonder if we could use it here as well.",1,0.5221807360649109
1258376361,13870,dajac,2023-07-10T14:44:07Z,do we need this?,0,0.9819303154945374
1258378853,13870,dajac,2023-07-10T14:45:53Z,ditto.,0,0.6705162525177002
1258379838,13870,dajac,2023-07-10T14:46:31Z,nit: you should try to use the stream api more often.,0,0.9810555577278137
1258387036,13870,dajac,2023-07-10T14:51:10Z,"in scala, we had `unknown_member_id` here. is the change expected?",0,0.9934460520744324
1258391017,13870,dajac,2023-07-10T14:53:33Z,"in scala, this test runs with a dynamic member and a static member. we don't do the static part here. why?",0,0.9429756999015808
1258394371,13870,dajac,2023-07-10T14:55:54Z,we were asserting the leader here.,0,0.990803599357605
1258396521,13870,dajac,2023-07-10T14:57:25Z,there is a `+ 1` in scala. don't we need it here?,0,0.9934200644493103
1258398177,13870,dajac,2023-07-10T14:58:35Z,nit: you can do: `group.allmembers().iterator().next()`.,0,0.9870573878288269
1258400111,13870,dajac,2023-07-10T15:00:00Z,there is a + 1 in scala.,0,0.9851511120796204
1258406471,13870,dajac,2023-07-10T15:04:08Z,there is `unknown_member_id` in scala?,0,0.9948427081108093
1258410034,13870,dajac,2023-07-10T15:06:24Z,is this a new test?,0,0.9905387163162231
1258924230,13870,jeffkbkim,2023-07-10T21:17:10Z,this would log all errors while appending/committing and if `generaterecordsandresponse` throws an unexpected exception. shouldn't we log them? it doesn't seem like we do for `consumergroupheartbeat()` -- maybe just filter out the coordinator not available / not coordinator error codes?,0,0.983754575252533
1258933631,13870,jeffkbkim,2023-07-10T21:30:02Z,"the responsefuture if completed inside genericgroupjoin will have an error code corresponding to the join group business logic. basically, we have already completed with the appropriate error if the response future is already completed at this line. the append future error is from the append/commit process which needs to be converted if we complete the response error here.",0,0.9908416271209717
1258934915,13870,jeffkbkim,2023-07-10T21:31:46Z,where should i look to confirm/learn this?,0,0.9834940433502197
1258937169,13870,jeffkbkim,2023-07-10T21:35:02Z,"confirmed that `storegroup` and `storeoffsets` have different handling. this will still be shared amongst join/sync/leave group, so i'll rename this to `appendgroupmetadataerrortoresponseerror`, wdyt?",0,0.9948156476020813
1258999406,13870,jeffkbkim,2023-07-10T23:18:33Z,is your suggestion to iterate through all groups & members and log each member after loading a partition is complete?,0,0.9938773512840271
1259002211,13870,jeffkbkim,2023-07-10T23:23:59Z,that's correct,0,0.9750980734825134
1259029305,13870,jeffkbkim,2023-07-11T00:24:18Z,great suggestion. thanks,1,0.9888633489608765
1259030830,13870,jeffkbkim,2023-07-11T00:28:01Z,a successful join group request will store the response future into the member's `awaitingjoinfuture` (could also complete if the join phase completes),0,0.9899877905845642
1259040832,13870,jeffkbkim,2023-07-11T00:43:14Z,we get illegal state exception if it's not initialized and since it doesn't affect the old protocol i thought it best to initialize it here.,0,0.9514483213424683
1259047855,13870,jeffkbkim,2023-07-11T00:53:11Z,"this is not to create a new group (note the `createifnotexists=false` argument) but to retrieve the group to do more validations such as group state, generation id, group size, etc. added a helper method `genericgroup()` to simplify the calls.",0,0.994625985622406
1259049772,13870,jeffkbkim,2023-07-11T00:55:49Z,"for all tests, we always generate a new record. some tests hide this as it's called in `groupmetadatamanagercontext#joingenericgroupasdynamicmember()`. maybe we can simplify this and just manually create an empty group for all tests except 1 where we test the new record. wdyt?",0,0.9880390763282776
1259054321,13870,jeffkbkim,2023-07-11T01:01:57Z,addressed in above comment.,0,0.9900397658348083
1259059291,13870,jeffkbkim,2023-07-11T01:08:34Z,"for all places i use the old for each / for loops, there is an error `variable used in lambda expression should be final or effectively final` because i reuse variables (mainly joingrouprequestdata & responsefutures). i can use new variables instead, would that be better?",0,0.9857885241508484
1259062674,13870,jeffkbkim,2023-07-11T01:13:15Z,i was following the new protocol as it made more sense but i have changed to reflect the old behavior.,0,0.970764696598053
1259095013,13870,jeffkbkim,2023-07-11T02:11:36Z,thanks for the catch. will add it.,1,0.6496338844299316
1259096806,13870,jeffkbkim,2023-07-11T02:14:34Z,there's a +1 on all advance clocks in scala. i haven't actually looked but assumed that it's in place due to how the purgatory works. the java timer implementation does not require a +1,0,0.9850173592567444
1259097546,13870,jeffkbkim,2023-07-11T02:16:06Z,have replied to a thread above,0,0.9880799651145935
1259098122,13870,jeffkbkim,2023-07-11T02:17:16Z,related to when a group is not found. have reverted and updated the error code,0,0.9899644255638123
1259098972,13870,jeffkbkim,2023-07-11T02:19:19Z,"yes, that's correct.",0,0.9540864825248718
1259103526,13870,jeffkbkim,2023-07-11T02:28:15Z,simplified the code a bunch. thanks for the suggestion!,1,0.9819360375404358
1259115771,13870,jeffkbkim,2023-07-11T02:53:23Z,"i'll think a bit more on this as it will require a large change in this class. one of the reasons i had it like this is that we mostly care about the responsefuture in the tests and wanted to hide the record/append future validations. the timer could also produce records which require setting things in advance. i agree it is unclean, i'll address this in the next commit.",0,0.9374369978904724
1259765086,13870,dajac,2023-07-11T13:46:46Z,yes. i would actually create a special test to validate this case and simplify all the others.,0,0.9791654348373413
1259767721,13870,dajac,2023-07-11T13:48:47Z,nit: empty line.,0,0.783897340297699
1259774315,13870,dajac,2023-07-11T13:53:31Z,should we move `genericgroup` to the context?,0,0.9949028491973877
1259776117,13870,dajac,2023-07-11T13:54:42Z,nit: empty line.,0,0.783897340297699
1259776394,13870,dajac,2023-07-11T13:54:53Z,nit: empty line.,0,0.783897340297699
1259779633,13870,dajac,2023-07-11T13:57:09Z,i find the helpers a bit confusing. it is not clear what's the difference between `joingenericgroup` and `sendgenericgroupjoin` for instance. is it possible to simplify them?,-1,0.8698256611824036
1259789131,13870,dajac,2023-07-11T14:03:57Z,how do end up in this state here? is there some code to advance the timer to complete the prepare phase?,0,0.9919503927230835
1259793958,13870,dajac,2023-07-11T14:07:28Z,this is really surprising. `verify*` suggests that this method only verifies something but it also has side effects. i think that this should rather be done in the context like i did for the new protocol.,-1,0.9743073582649231
1259795334,13870,dajac,2023-07-11T14:08:23Z,we need to align on this one as i also have an implementation [a link]. they look pretty close but they are different.,0,0.9254476428031921
1259836068,13870,dajac,2023-07-11T14:35:58Z,do we need to add a test for this one?,0,0.991936206817627
1260282790,13870,jeffkbkim,2023-07-11T21:06:25Z,`sendgenericgroup...` methods send the request and return the future. `joingenericgroup...` methods invoke `sendgenericgroup` methods then advance the timer to move the group to completing rebalance state.,0,0.9942814111709595
1260298077,13870,jeffkbkim,2023-07-11T21:24:18Z,"yeah, i noticed. i don't mind using the other implementation. looks like java's priority queue does arbitrary ordering for the same priority so they should have the same behavior",0,0.5452343821525574
1260497268,13870,jeffkbkim,2023-07-12T02:39:33Z,"with the latest changes, i renamed `joingenericgroup...` to ``joingenericgroupasdynamicmemberandcompletejoin` and `joingenericgroupandcompletejoin` to make it more explicit. let me know if this is more readable.",0,0.9877661466598511
1260497352,13870,jeffkbkim,2023-07-12T02:39:42Z,replied to comment below.,0,0.9915754199028015
1260500922,13870,jeffkbkim,2023-07-12T02:46:27Z,"removed this method, and now individual tests do the validation. one exception is for timer operation expirations - as the majority of the cases will not result in any records, i have done the validation inside mockcoordinatortimer.",0,0.9952719807624817
1263424766,13870,dajac,2023-07-14T07:56:38Z,"yeah, i think that it depends on what we mean by unexpected. i would remove it for now given that we also log something when the append future fails. we can always bring it back later if needed.",0,0.9426140189170837
1263429592,13870,dajac,2023-07-14T08:01:29Z,that makes sense.,0,0.9798967242240906
1263430125,13870,dajac,2023-07-14T08:02:02Z,that seems reasonable. we can see later if we could also share this logic with the consumer group heartbeat handling.,0,0.9405528903007507
1263432212,13870,dajac,2023-07-14T08:04:12Z,extremely small nit: should you move `topicpartition` to the top? this is a common attribute.,0,0.884239912033081
1263432742,13870,dajac,2023-07-14T08:04:46Z,nit: could you also move this one to the top of the attributes?,0,0.9908968806266785
1263435000,13870,dajac,2023-07-14T08:07:27Z,"nit: i was wondering whether it would make sense to move this to `coordinatorresult`. we could have a static public constant called `empty`. then, we could use `coordinatorresult.empty` in the code. this is a pattern that we already use in a few other places. what do you think?",0,0.9843941330909729
1263435600,13870,dajac,2023-07-14T08:08:05Z,nit: could we revert this change?,0,0.9884264469146729
1263436098,13870,dajac,2023-07-14T08:08:37Z,nit: add javadoc for unknownmemberidexception.,0,0.9508565068244934
1263437064,13870,dajac,2023-07-14T08:09:38Z,nit: there is a constructor which does not take the response. we could use it and remove `null` here. there are a few other cases. i won't mention them again.,0,0.9021087288856506
1263437658,13870,dajac,2023-07-14T08:10:17Z,nit: the format of the javadoc in is incorrect here.,-1,0.6857342720031738
1263439020,13870,dajac,2023-07-14T08:11:42Z,correct. i think that you saw that in my other pr. the issue with logging here is that it will log state metadata as well and we don't want this.,0,0.8328517079353333
1263441311,13870,dajac,2023-07-14T08:14:13Z,is this one covered by a unit test?,0,0.9929317235946655
1263443960,13870,dajac,2023-07-14T08:16:52Z,i was wondering if it would be better to complete the future directly here as well in order to be consistent. i think that you did this in the sync handling if i understood you correctly. what do you think?,0,0.9795361161231995
1263446381,13870,dajac,2023-07-14T08:19:16Z,"note: we will have to also verify the number of member after the group is loaded, i think. this is something for another pr but to keep in mind.",0,0.9871757626533508
1263447316,13870,dajac,2023-07-14T08:20:21Z,nit: could we prefix this one and the two others with `genericgroup`?,0,0.9918333292007446
1263450237,13870,dajac,2023-07-14T08:22:52Z,would it make sense to make the copy on the other side? it is a bit weird to anticipate this here because we don't do this for other accessors. i am usually tempted to return unmodifiable collections in the case to prevent this kind of issue.,-1,0.9762547016143799
1263452425,13870,dajac,2023-07-14T08:25:00Z,nit: `testjoingroupappend...`?,0,0.993472695350647
1263454213,13870,dajac,2023-07-14T08:26:50Z,nit: could we move this next to the other final private attributes? could we also invest private final to be consistent with the others?,0,0.9931500554084778
1263454828,13870,dajac,2023-07-14T08:27:31Z,nit: could we move this one back to its original place?,0,0.9703676700592041
1263458200,13870,dajac,2023-07-14T08:30:58Z,"nit: what the reason for this? if you don't catch it, the test will also fail.",-1,0.6459423899650574
1263459890,13870,dajac,2023-07-14T08:32:34Z,nit: let's revert this.,0,0.6727333068847656
1263459980,13870,dajac,2023-07-14T08:32:39Z,nit: let's revert this.,0,0.6727333068847656
1263460377,13870,dajac,2023-07-14T08:33:01Z,nit: `null` could be removed.,0,0.9915465712547302
1263461288,13870,dajac,2023-07-14T08:33:57Z,nit: `null` could be removed.,0,0.9915465712547302
1263463518,13870,dajac,2023-07-14T08:36:11Z,"this catch is a bit suspicious here. i suppose that it would also catch the error thrown by `assertequals`, no?",-1,0.8777556419372559
1263465299,13870,dajac,2023-07-14T08:37:56Z,"nit: while we are here, would it make to normalize the name of all tests starting with `should`? they should ideally start with `test...` like the others.",0,0.9933077096939087
1263471443,13870,dajac,2023-07-14T08:44:23Z,"it seems based on the usages of this method that only one timeouts is expected all the time. should we enforce it as well? more generally, i was wondering if having a `assertemptytimeout` helper method and using `assertemptytimeout(context.sleep(...))` would have a better separation of concerns. i leave this up to you.",0,0.9897884130477905
1263905173,13870,jeffkbkim,2023-07-14T16:11:41Z,that forces the coordinatorresult class to become non-generic which i don't think we want.,0,0.8612104058265686
1263922655,13870,jeffkbkim,2023-07-14T16:30:21Z,then do you think we can move `appendgroupmetadataerrortoresponseerror` back to groupmetadatamanager?,0,0.9951802492141724
1263925546,13870,jeffkbkim,2023-07-14T16:33:50Z,"to confirm, you're saying we should call `acceptjoiningmember` while loading members?",0,0.9948476552963257
1264075041,13870,jeffkbkim,2023-07-14T19:22:59Z,will keep it as assertemptyresult as the timeout is not empty (can be) but we want to assert that the coordinator result is.,0,0.9935612678527832
1264953365,13870,dajac,2023-07-17T07:04:25Z,ah.. did not think about that.,-1,0.8680302500724792
1264954924,13870,dajac,2023-07-17T07:06:34Z,"yeah, possibly.",0,0.9702399373054504
1264955867,13870,dajac,2023-07-17T07:07:49Z,no. i think that the current coordinator triggers a rebalance if the number of members is higher than the max when a group is loaded.,0,0.9902547001838684
1264961072,13870,dajac,2023-07-17T07:13:31Z,do we really need to keep the try..catch?,0,0.9630182385444641
1264962406,13870,dajac,2023-07-17T07:14:49Z,nit: `assertnooremptyresult`?,0,0.9930526614189148
1264964347,13870,dajac,2023-07-17T07:17:13Z,this request timeout was coming from the delayed produce op in the purgatory. we don't have this anymore.,0,0.9825281500816345
1264965443,13870,dajac,2023-07-17T07:18:40Z,this was not addressed.,0,0.9377602934837341
1264967746,13870,dajac,2023-07-17T07:21:18Z,this was not addressed.,0,0.9377602934837341
1264968675,13870,dajac,2023-07-17T07:22:25Z,"yeah, we have to stick to the old one here.",0,0.878676176071167
1265547819,13870,jeffkbkim,2023-07-17T15:32:01Z,i was thinking about the illegal state exceptions. wouldn't we hide the issue then? maybe we can log only for non api exceptions. wdyt?,-1,0.5650001764297485
1265554449,13870,jeffkbkim,2023-07-17T15:37:23Z,this is required if we want to use the streams api. let me know if we should just use the for each loop,0,0.9896238446235657
1265574666,13870,jeffkbkim,2023-07-17T15:54:25Z,thought i addressed this. addressed it now,0,0.9798821210861206
1265577548,13870,jeffkbkim,2023-07-17T15:56:48Z,changed to logging only when the response future is not complete,0,0.9856922626495361
1265644331,13870,jeffkbkim,2023-07-17T16:51:05Z,updated and added a test case,0,0.9897811412811279
1265807220,13870,dajac,2023-07-17T19:25:12Z,"this would still log in expected cases, no? for instance, when the coordinator for the group is inactive, loading, etc. if you really want to log something, you could perhaps log only if `exception` is not a kafkaexception or only when it is a runtimeexception for instance.",0,0.9939731955528259
1265807612,13870,dajac,2023-07-17T19:25:41Z,gotcha. it is fine like this.,1,0.6764992475509644
1265816192,13870,jeffkbkim,2023-07-17T19:35:47Z,ah makes sense. logging only when it is not a kafka exception makes sense.,0,0.9820507764816284
1266079310,13870,jeffkbkim,2023-07-18T01:36:33Z,i think our last discussion was to also revert this to the existing behavior right? i.e. not implement [a link],0,0.9917761087417603
1266264686,13870,dajac,2023-07-18T05:59:19Z,that's correct.,0,0.9792349338531494
1266267667,13870,dajac,2023-07-18T06:00:53Z,should we replace this by a constant if we can't change it based on config?,0,0.9921157956123352
1266269140,13870,dajac,2023-07-18T06:02:42Z,"so we actually need to reschedule the timer here, right?",0,0.9905149936676025
1266270587,13870,dajac,2023-07-18T06:04:21Z,nit: could we say `joingroup request {} hit....`?,0,0.9914100766181946
1267070768,13870,jeffkbkim,2023-07-18T17:00:13Z,yes. updated,0,0.9654099345207214
565612146,9944,jolshan,2021-01-27T20:29:10Z,i think i may want to do this in a simpler way. i want to keep track if we have ids for all the topics and i'm not sure if there is a better way to figure out when a topic is no longer in a session besides checking all the topic partitions.,0,0.9603196382522583
566449639,9944,rajinisivaram,2021-01-28T22:26:23Z,we don't use `get` prefix for getters,0,0.9826313853263855
566449805,9944,rajinisivaram,2021-01-28T22:26:42Z,comment needs updating?,0,0.9892416596412659
566453611,9944,rajinisivaram,2021-01-28T22:34:18Z,"we can use integer::sum as the last arg, but do we even need to maintain `partitionspertopic`?",0,0.995283305644989
566458667,9944,rajinisivaram,2021-01-28T22:45:05Z,could just parameterize `findmissing`?,0,0.994269609451294
566464590,9944,rajinisivaram,2021-01-28T22:57:33Z,"there are several places where we use this combination of two maps, should we create a class that maintains a bidirectional map?",0,0.989688515663147
566465893,9944,rajinisivaram,2021-01-28T23:00:16Z,can we end up with cases with some topics with ids and some without?,0,0.9896194338798523
566466426,9944,rajinisivaram,2021-01-28T23:01:33Z,the fact that you are running this code implies `apikeys.fetch.latestversion() >= 13`?,0,0.9946710467338562
567146583,9944,jolshan,2021-01-29T23:21:36Z,some of these tests may be flaky so i'm going to keep an eye on them.,0,0.6032235622406006
567172089,9944,rajinisivaram,2021-01-30T01:12:02Z,the whole fetchrequest class is quite hard to follow without reading the kip and looking at multiple places. it will be good to add some comments at the class level.,0,0.9311258792877197
567172368,9944,rajinisivaram,2021-01-30T01:13:50Z,"since we have session ids and topic ids in the context of a fetch request, we should probably qualify `topicid`",0,0.9941052198410034
567172755,9944,rajinisivaram,2021-01-30T01:15:54Z,`this.partitions.addall(partitions)`?,0,0.9919344186782837
567173386,9944,rajinisivaram,2021-01-30T01:19:17Z,does one non-zero id mean we have all ids?,0,0.990264892578125
567173468,9944,rajinisivaram,2021-01-30T01:19:41Z,this suggests we can have a combination of zero and non-zero?,0,0.9878724813461304
567173993,9944,rajinisivaram,2021-01-30T01:22:18Z,it will be good to see if can separate out new and old forms of fetchrequest/response. it is not a big deal since it is just wrapping the protocol layer.,0,0.8697169423103333
567174143,9944,rajinisivaram,2021-01-30T01:23:34Z,shouldn't we be using versions and expect non-zero ids in new versions?,0,0.9930545687675476
567174731,9944,rajinisivaram,2021-01-30T01:27:08Z,we need to remember to set this based on which version this is being merge to.,0,0.9889383316040039
567175350,9944,rajinisivaram,2021-01-30T01:30:45Z,nit: indentation,0,0.5517857670783997
567175593,9944,rajinisivaram,2021-01-30T01:32:32Z,does an unresolved partition have all these fields populated? or do we have it here because the topic may be resolved later?,0,0.9952492713928223
567175893,9944,rajinisivaram,2021-01-30T01:34:49Z,is this part intentionally commented out?,0,0.9858368635177612
567188080,9944,jolshan,2021-01-30T03:13:51Z,no that should be removed :),1,0.9842648506164551
567188108,9944,jolshan,2021-01-30T03:14:14Z,we need to keep the data from the fetch request for when we resolve the partition.,0,0.9921340942382812
567188287,9944,jolshan,2021-01-30T03:16:00Z,the idea is that we should only be able to send this request version if we had an id for each topic. i do need to take a closer look at this,0,0.9789782166481018
567188652,9944,jolshan,2021-01-30T03:19:22Z,i had trouble getting the version into the response. the constructor is used in some places where we don't have access to the version.,0,0.910955548286438
567188957,9944,jolshan,2021-01-30T03:22:37Z,that's true,0,0.9175609946250916
567189013,9944,jolshan,2021-01-30T03:23:35Z,i think this was a mistake. i need to see why i wrote it this way.,0,0.5957581400871277
567189128,9944,jolshan,2021-01-30T03:24:54Z,i should also move that comment (and maybe simplify it) to the partitioniterator where i moved the code for removing partitions with stale ids.,0,0.9925611615180969
568033865,9944,jolshan,2021-02-01T18:10:10Z,"i remember why i did this. i wanted to not get a set of the zero id when the version was old. i think if we are able to get better versioning logic, this should be fixed easily.",0,0.9789862036705017
568034891,9944,jolshan,2021-02-01T18:11:54Z,abstractresponse does not maintain version like abstractrequest. so i'm not sure the best way to proceed with this.,-1,0.5737149715423584
568078414,9944,jolshan,2021-02-01T19:20:40Z,"i'm thinking it may be possible if we had a response from a broker that supported topic ids and then a response from one that did not. of course, this should eventually get resolved, but i didn't know if it was worth it to try to avoid fetches that are unsupported in a few more cases.",0,0.949522078037262
568140154,9944,junrao,2021-02-01T21:07:54Z,space after comma,0,0.9793954491615295
568196064,9944,junrao,2021-02-01T22:51:09Z,gettopicids => topicnamestoids?,0,0.9902316927909851
568196201,9944,junrao,2021-02-01T22:51:32Z,gettopicnames => topicidstonames?,0,0.9926131963729858
568201144,9944,junrao,2021-02-01T22:58:56Z,"hmm, why do we need to do collect() at the end? the returned value doesn't seem be be used.",0,0.8965901732444763
568201276,9944,junrao,2021-02-01T22:59:07Z,"hmm, why do we need to do collect() at the end?",0,0.8629416823387146
568216529,9944,junrao,2021-02-01T23:34:43Z,it's a bit weird to add a comment that breaks the if/else clause. perhaps we could put the comment inside the `else if`?,-1,0.9767829179763794
568222532,9944,junrao,2021-02-01T23:50:06Z,"it seems that the following code makes changes to unresolvedpartitions, not topic ids.",0,0.9715232849121094
568223807,9944,junrao,2021-02-01T23:53:42Z,should we change `hashcode() `and `equals()` to include topicid?,0,0.9946832060813904
568230940,9944,junrao,2021-02-02T00:12:40Z,what's the definition of 'interesting'?,0,0.9870864152908325
568231067,9944,junrao,2021-02-02T00:13:05Z,"should we add the new params to the javadoc above? in particular, could we explain the relationship between responsedata and iderrors? also, could we name the params clearer? for example, responsedata => partitionswithmatchingtopicid, iderrors => partitionswithoutmatchingtopicid.",0,0.992190420627594
568832800,9944,junrao,2021-02-02T18:26:24Z,"since we are adding some complexity, it would be useful to make the code a bit easier to understand for other people. for example, perhaps we could add comments to explain (1) what partitions will be included in unresolvedpartitions vs partitionmap? (2) are partitions mutually exclusive between unresolvedpartitions and partitionmap? (3) how are partitions in unresolvedpartitions and partitionmap handled different for fetch response?",0,0.9918330907821655
569824849,9944,junrao,2021-02-03T23:29:26Z,topicnames => topicidtonamemap?,0,0.9903565049171448
569829415,9944,junrao,2021-02-03T23:41:13Z,is there a reason to use 0 instead of the default capacity for the hashmap?,0,0.9938522577285767
569830803,9944,junrao,2021-02-03T23:45:03Z,we could probably just get rid of session since it's part of the session object. ditto below.,0,0.9915443658828735
569832071,9944,junrao,2021-02-03T23:48:16Z,"now that the constructor code is a bit more now, perhaps we could just forward `builder()` to `builder(int initialsize, boolean copysessionpartitions) `?",0,0.9937410950660706
569832450,9944,junrao,2021-02-03T23:49:14Z,id => topicid ?,0,0.9893732666969299
569834804,9944,junrao,2021-02-03T23:55:33Z,"hmm, we should be adding tp.partition() to the hashset and not using it for the initial capacity, right?",0,0.9845751523971558
569862273,9944,junrao,2021-02-04T00:49:57Z,it seems that topicnames is unused?,0,0.9791557192802429
570397481,9944,junrao,2021-02-04T17:11:52Z,"it seems this is about a topic. so, unresolvedpartitions is better named as unresolvedtopic?",0,0.9936517477035522
570588361,9944,junrao,2021-02-04T22:29:45Z,"hmm, not sure if we need to distinguish here. it seems that it's easier to just always send a unknown_topic_id since the propagation of all topic ids could be delayed?",0,0.7359241843223572
570596351,9944,junrao,2021-02-04T22:46:08Z,"now that we are changing the semantics for this method to only iterating resolved partitions, it would be useful to have a more appropriate method name to make it clear. also, it seems that some of the callers need to iterate all partitions including unresolved ones (e.g., those checking for cluster action permissions) while some others need to iterate resolved ones (e.g, those checking for topic level permissions).",0,0.9933525323867798
570606630,9944,junrao,2021-02-04T23:08:08Z,"this method is kind of weird. it's only used in kafkaapis where topic name has already been resolved. the only reason for this method is that fetchcontext.updateandgenerateresponsedata() generates fetchresponse, which is used in createresponse(). instead, could we have fetchcontext.updateandgenerateresponsedata() return a different class that includes the resolved partitions?",-1,0.9713142514228821
570607999,9944,junrao,2021-02-04T23:11:22Z,perhaps we could log both the resolved partitions' size and unresolved partitions' size.,0,0.9936461448669434
570648997,9944,junrao,2021-02-05T00:58:06Z,it's kind of weird to pass in a request into fetchsession.,-1,0.981361448764801
570650572,9944,junrao,2021-02-05T01:02:52Z,"hmm, do we need to check version here? fetchresponse.fetchdataanderror() already checked the version.",0,0.9926167130470276
570652174,9944,junrao,2021-02-05T01:07:51Z,"could we name the methods better to make it easier to understand? for example, createnewsession => generateresolvedpartitions createnewsessioniderrors => generateunresolvedpartitions",0,0.9947578310966492
572203478,9944,junrao,2021-02-08T16:52:18Z,the metadata cache could change between the two calls. could we have a single call to metadata cache that returns both topicnames and topicids?,0,0.991117000579834
572208853,9944,junrao,2021-02-08T16:58:58Z,"`topicids.getordefault(part.topic(), uuid.zero_uuid)` if we always expect the topic to be found in topicids, we should just throw an exception instead of using a default. if this is expected, we probably should convert it to an unresolved partition?",0,0.9931778907775879
572218700,9944,junrao,2021-02-08T17:12:09Z,it seems that toforgetids is intended for unresolved topicids. could we name it more clearly together with toforget and add some comment?,0,0.9903963804244995
572220577,9944,junrao,2021-02-08T17:14:48Z,"i am not sure that i follow the logic here. it seems that we always put the forgot topic into unresolvedids. it seems that we should check the partitions size? also, perhaps rename partitions to sth like unresolvedpartitions?",0,0.8658076524734497
572228756,9944,junrao,2021-02-08T17:24:43Z,should we use mustadd()?,0,0.9934549927711487
572235515,9944,junrao,2021-02-08T17:33:23Z,do we need this part of the logic? it seems that the same is already done through fetchreqeust.fetchdataanderror().,0,0.9945021867752075
572274967,9944,junrao,2021-02-08T18:31:40Z,"this excludes the partition in the response. however, it seems we need to send an error back for this partition?",0,0.9743700623512268
572281866,9944,junrao,2021-02-08T18:42:34Z,this seems unused?,0,0.824500560760498
572287008,9944,junrao,2021-02-08T18:50:42Z,could we add the new param to the javadoc?,0,0.9910531640052795
572308958,9944,junrao,2021-02-08T19:25:33Z,should we use the latest version or fetchrequestversion guarded by ibp?,0,0.9947465062141418
572350818,9944,jolshan,2021-02-08T20:31:46Z,sorry this was unclear. i meant changes involving topic ids. i will adjust this comment.,-1,0.9925324320793152
572351801,9944,jolshan,2021-02-08T20:33:35Z,'interesting' was the name of the map of partitiondata. i believe they are topic partitions that are authorized and exist.,0,0.88713139295578
572351945,9944,jolshan,2021-02-08T20:33:51Z,sounds good to me,1,0.9168725609779358
572354491,9944,jolshan,2021-02-08T20:37:24Z,i think i was just matching `sessionpartitions` above,0,0.9850851893424988
572355958,9944,jolshan,2021-02-08T20:39:51Z,yeah. good catch. i'm going to experiment with this code a bit to see if it's faster to maintain this set or just get a set of topics from the map of topic partitions in` fetchrequestdata`,1,0.927331268787384
572356813,9944,jolshan,2021-02-08T20:41:16Z,"the reason i name it this is we maintain such an object for each partition that was unresolved. if we simply have one object per topic, we would need a way to know all the partitions for the topic that were requested.",0,0.9878742098808289
572357857,9944,jolshan,2021-02-08T20:43:16Z,"i've gone back and forth on this. one one hand, you are right that this is confusing in the case where we are doing and upgrade and id propagation is delayed. on the other hand, in the non-upgrade case, returning an unknown_topic_id error when topic ids are not even supported might not be as informative.",0,0.6370663642883301
572363402,9944,jolshan,2021-02-08T20:52:25Z,"i agree. i think it stems from exactly what you said...that `fetchcontext.updateandgenerateresponsedata()` generates a response only for it to be generated again. currently ` fetchcontext.updateandgenerateresponsedata()` does include all partitions (resolved and unresolved). the issue is that the partitions need to be down-converted. the way this works is that the partitions are pulled from the fetchresponse object itself. however, the issue is that i've changed responsedata and since this is the newest version of the response, it will try to reconstruct the map instead of pulling the object `partitiondata`. (which is too slow) i thought about changing the method to always return the map when it is not null, but that caused some issues in some places as well. i can look into this again though.",0,0.9721847772598267
572367849,9944,jolshan,2021-02-08T20:59:54Z,this is for adding unresolved partitions in the session but not in the request. i can add comments to clarify what is happening.,0,0.9890516400337219
572370494,9944,jolshan,2021-02-08T21:04:38Z,"good point, it should probably be along the lines of `if (fetchrequestversion >= 13 && !fetchdata.canusetopicids) 12 else fetchrequestversion` to match how it is sent below.",0,0.9560030102729797
572373623,9944,jolshan,2021-02-08T21:09:56Z,"if we run into this scenario, does it make sense to always return with an unknown_topic_id error? sometimes partitions will be skipped over anyway when `mustrespond` is false, so should those also return unknown_topic_id?",0,0.9922463297843933
572377972,9944,jolshan,2021-02-08T21:13:56Z,i realize this is a bit confusing. addpartitions method takes a list what this line is doing is grabbing the iderror object and adding partitions to it.,-1,0.8624985814094543
572381787,9944,jolshan,2021-02-08T21:20:43Z,"ah. this is confusing due to how i named things. basically, i'm collecting a set of partitions `partitions` for a given topic where the id was not resolved. then i'm adding them to unresolvedids. this is a mapping from the topic id to all the partitions that should be forgotten. i can rename and add comments to clarify what is happening here.",-1,0.9721693396568298
572413017,9944,jolshan,2021-02-08T22:11:24Z,"i thought about this, but i was worried about some weirdness where we need to support partitions before and after they have an id. (the partitions are techincally equivalent, but equals wouldn't reflect that) this may also cause problems in cases where ids may change. consider the code ` val cachedpart = session.partitionmap.find(new cachedpartition(topicpart))` this is used in the path of deleting partitions with stale ids. we would need to know the topic id to find the partition here. i could see potential issues where we no longer have the id and would have trouble removing it.",-1,0.6000939607620239
572470829,9944,jolshan,2021-02-09T00:21:46Z,when you mention that some callers need to iterate over all partitions like cluster action -- i'm a little confused. i thought the request context was passed into authhelper for that.,-1,0.7350292205810547
572472724,9944,jolshan,2021-02-09T00:25:21Z,i think we do since this is looking at the partitions cached in the session. i'll take another look though.,0,0.9599860906600952
572475014,9944,jolshan,2021-02-09T00:27:59Z,i think this is used for handling the case of older request versions.,0,0.9846023321151733
572512463,9944,junrao,2021-02-09T02:00:07Z,i was referring to the following code. it seems to need to iterate every partition through fetchcontext so that the unknown_topic_or_partition error code can be added for each partition. [code block],0,0.9906904697418213
573033865,9944,jolshan,2021-02-09T16:28:11Z,ok. i understand now. i think in this case though the expected behavior is to return unknown_topic_id if the topic id is unresolved.,0,0.970869779586792
573046669,9944,jolshan,2021-02-09T16:43:18Z,"i just realized that fetchrequest.latestallowedversion is the version we use to build the request (latest and earliest are the same.) but this is a bit confusing, so i'll probably just use the logic mentioned above.",0,0.9587339758872986
573102028,9944,junrao,2021-02-09T17:53:19Z,"yes, we want to return unknown_topic_id for all partitions in this case. the unresolved partitions in this pr could also return the unsupported error code.",0,0.9643934965133667
574846728,9944,jolshan,2021-02-11T21:42:38Z,get rid of the word session in the variable name? i was following sessionpartitions as above. or get rid of this altogether?,0,0.9884383082389832
574909648,9944,jolshan,2021-02-11T23:57:11Z,i'm trying to think if we could have a situation where the partition already exists but without topic id. (like an older version of the request was sent previously?) maybe i could check if it was not already added like how it is done below for resolved partitions added to the session.,0,0.9875284433364868
592335738,9944,chia7712,2021-03-11T12:54:16Z,i don't find any usage of this method. is it essential to keep this map in `topicnames`?,0,0.9444136619567871
592360300,9944,chia7712,2021-03-11T13:30:13Z,"it seems this method is used by server only. is it possible to have empty topic name when `kafkaapis` calls it? if not, we can remove this empty check and replace this method by `toresponsedatamap`",0,0.9948726296424866
592520900,9944,jolshan,2021-03-11T16:41:47Z,"i think i added it for completeness, but perhaps we don't need it.",0,0.9627601504325867
592524660,9944,jolshan,2021-03-11T16:46:21Z,"yes. we may have topic ids that could not be resolved. these topics will not have a topic name. i agree that this isn't the cleanest solution, but it was the one that worked while keeping topicpartitions as keys for the map.",0,0.965498149394989
592530926,9944,chia7712,2021-03-11T16:53:36Z,maybe we should remove the usage of this method first. is it useful if we make all callers use auto-generated data (topic and partition) instead of this map (topicpartition)?,0,0.9943779110908508
592536126,9944,jolshan,2021-03-11T16:59:57Z,"i can remove it. i was keeping it as a placeholder for now. i was hoping to find a way to not regenerate the map that we just passed in to make the fetchresponse. i'm also not quite sure what you mean by ""auto-generated data""",0,0.8811287879943848
592542384,9944,chia7712,2021-03-11T17:08:03Z,"make all callers use fetchresponsedata instead of map[topicpartition, ...]. in other words, fetchresponse does not return topicpartition anymore.",0,0.9937040209770203
592546512,9944,jolshan,2021-03-11T17:13:17Z,ah i see. i'd have to take a look. i'm wondering if we would still need to convert to topic names for certain methods.,0,0.6414759755134583
592761061,9944,jolshan,2021-03-11T22:16:27Z,"yeah, so for example, `topicpartition`s are given to `replicamanager.fetchmessages` where it is used heavily. i think we still want the map for now. one thing i was confused about with this code is why we generate `unconvertedfetchresponse` with `updateandgenerateresponsedata`. we pass in the map to create `unconvertedfetchresponse`. with the optimization to lazily compute the map, recompute it a few lines of code later in `createresponse`. i'm hoping to avoid this somehow. (i think the optimization is great everywhere else though and i was heading in that direction originally with this pr)",0,0.6702883243560791
592885424,9944,chia7712,2021-03-12T03:27:47Z,"you are right. i feel it is the side-effect caused mixing `topicpartition` and generated code in production. the callers have to create a heavy copy to update some fields of passed data. btw, that is what [a link] want to resolve. the pr makes all code use auto-generated data so they can update fields of passed auto-generated data instead of creating a copy.",0,0.8620330095291138
593283525,9944,jolshan,2021-03-12T16:04:20Z,got it. i think the issue here then is that some of the information can not be auto-generated data. we need topic names for certain methods but names will not be in the auto-generated data.,0,0.9747080206871033
593293236,9944,jolshan,2021-03-12T16:17:49Z,"i suppose we could set them server side, but when we iterate though the topics, we would need to not include those whose topic ids could not be resolved.",0,0.9885392785072327
593737385,9944,chia7712,2021-03-13T11:08:59Z,"as we resolve all ids before check permission, does it produce `topic_authorization_failed` with topic name even if it has no read permission to such topic (line#717)?",0,0.9945974349975586
593738472,9944,chia7712,2021-03-13T11:20:21Z,remove those code?,0,0.9882595539093018
593739424,9944,chia7712,2021-03-13T11:29:33Z,not sure whether this idea is valid. could we resolve all ids to names and then keep using previous code to handle fetch requests? for example: the code of deleting topic resolve ids to names first and then process the deletion by names. that is a good pattern to me as we don't need to trace id/name everywhere.,0,0.9390485286712646
593771946,9944,jolshan,2021-03-13T16:35:08Z,"for the most part, this is what we do. but we also have to keep track of unresolved names right? fetchsession makes this more complicated. we may get a topic id that we can't resolve, but with a subsequent update we can. i'm not 100% sure of the logistics of fetch sessions, but it doesn't seem like a good practice to leave unresolved ids out of the session.",0,0.9260935187339783
593772326,9944,jolshan,2021-03-13T16:37:56Z,"i would think so? the goal was for when the ids are resolved, the path would be the same. and i think we decided that topic_authorization_failed is the correct error when we don't have read permissions?",0,0.9927747249603271
593842004,9944,chia7712,2021-03-14T04:48:57Z,sorry for my unclear comment. my point was that the topic name is included by the response even if there is no read permission to resolve the topic is. that looks like a security issue that we expose the topic name.,-1,0.991628885269165
593922148,9944,jolshan,2021-03-14T16:01:06Z,ah right. i will fix that.,0,0.8370309472084045
595284658,9944,jolshan,2021-03-16T15:31:23Z,i went to fix this but i realized something. correct me if i'm wrong. the newest version of fetch will only return topic ids (not topic names) so we won't expose topic names. the older version of fetch sends topic names so it will have to send topic names back. i don't think the name is ever incorrectly exposed.,0,0.6473919153213501
603506960,9944,jolshan,2021-03-29T18:09:58Z,removed this object,0,0.978717029094696
603507748,9944,jolshan,2021-03-29T18:11:16Z,i simplified this path as well.,0,0.9545134902000427
617932245,9944,junrao,2021-04-21T22:26:04Z,extra newline.,0,0.9612767100334167
622349780,9944,junrao,2021-04-28T16:32:41Z,id => topicid ?,0,0.9893732666969299
622349941,9944,junrao,2021-04-28T16:32:54Z,id => topicid ?,0,0.9893732666969299
625164696,9944,jolshan,2021-05-03T15:23:38Z,"with the top level error change, we are no longer marking the partitions as `partitionswitherror`. i'm wondering if this is something we still want to do somehow to allow the broker's metadata time to update.",0,0.9804505109786987
625372843,9944,junrao,2021-05-03T21:15:05Z,"when will topicresponse.topic() be """"?",0,0.9921552538871765
625422142,9944,junrao,2021-05-03T23:09:32Z,an situation => a situation,0,0.8682048916816711
625429072,9944,junrao,2021-05-03T23:30:12Z,"it's a bit weird for `forgottentopics()` to have a side effect that changes the internal data structure since requests are typically immutable. it's all not consistent with topartitiondatamap(). if we do want to modify the internal data structure, we probably want to name the method more properly. also, why do we return a list of forgottentopic instead of list of topicpartition? the latter is easier to understand and it doesn't seem that we need topicid in forgottentopic,",-1,0.8936029076576233
625431122,9944,junrao,2021-05-03T23:36:39Z,no need for extra new line.,0,0.9794226288795471
625432217,9944,junrao,2021-05-03T23:40:13Z,version seems unused?,0,0.9712703824043274
625433357,9944,junrao,2021-05-03T23:43:56Z,"hmm, it seems that we can't pass in an empty topicids since partition iterator is not empty?",0,0.9484119415283203
625440965,9944,junrao,2021-05-04T00:09:25Z,does topicid need to be a var?,0,0.990691602230072
625443921,9944,junrao,2021-05-04T00:19:34Z,"hmm, if the topicid has changed, it seems that we should send an error (e.g. invalidtopicid) back to indicate the topicid is no longer valid so that the client could refresh the metadata?",0,0.9607879519462585
625446144,9944,junrao,2021-05-04T00:27:26Z,could we explicitly define the type of topicnames ?,0,0.9940432906150818
625451257,9944,junrao,2021-05-04T00:46:05Z,the calculation of version is duplicated between here and replicafetcherthread. could we share them somehow?,0,0.9829044938087463
625454055,9944,junrao,2021-05-04T00:56:19Z,"since there is only a single tp, does topics need to be a set?",0,0.992190420627594
626749507,9944,jolshan,2021-05-05T17:09:36Z,i ended up deciding to end the session and throw a top level error when we have an unknown topic id.,0,0.6419541835784912
626894717,9944,junrao,2021-05-05T21:01:53Z,"since topartitiondatamap() handles all versions, could we just simply call topartitiondatamap()? then, i am not sure if we need to call topartitiondatamap() in the constructor.",0,0.9863083958625793
626897100,9944,junrao,2021-05-05T21:06:16Z,it seems it will be clearer if we put this in an else clause.,0,0.9918147921562195
626899596,9944,junrao,2021-05-05T21:11:05Z,it seems that we could share the code to populate this.data and this.metadata. we only use `this` in this method. should we just remove it?,0,0.9931514263153076
626906972,9944,junrao,2021-05-05T21:24:45Z,do we need this method? it seems it's the same as toresponsedatamap().,0,0.9918861389160156
626907992,9944,junrao,2021-05-05T21:26:38Z,could we add the new param to javadoc?,0,0.9921905398368835
626945454,9944,junrao,2021-05-05T21:55:31Z,it seems that this can just be a local val instead of an instance val?,0,0.9925619959831238
626947091,9944,junrao,2021-05-05T21:57:30Z,do the new fields need to be included in tostring()?,0,0.9937332272529602
626952683,9944,junrao,2021-05-05T22:09:42Z,could we build the full tosendtopicids and tosendtopicnames once and reuse in both full and incremental?,0,0.9946000576019287
626953162,9944,junrao,2021-05-05T22:10:50Z,the above comment needs to be changed accordingly.,0,0.987149178981781
626954746,9944,junrao,2021-05-05T22:14:32Z,perhaps extra and omitted should be extrapartition and omittedpartitions to make it clear?,0,0.9935693740844727
626958184,9944,junrao,2021-05-05T22:23:00Z,could we add the javadoc for the new param?,0,0.9922440648078918
627026623,9944,jolshan,2021-05-06T01:58:33Z,realized this was no longer the case and removed in the most recent commit.,0,0.992010235786438
627027261,9944,jolshan,2021-05-06T02:00:45Z,"i originally did this when dealing with unresolved partitions. i was wondering if it would be better to not create a second data structure. if creating another structure (as done before) is not a problem, we can go back to that.",0,0.9695079922676086
627027404,9944,jolshan,2021-05-06T02:01:20Z,ah good catch on this.,1,0.9838793873786926
627514050,9944,jolshan,2021-05-06T15:15:14Z,"this is a good point. in general, i think i need to go through the session logic for handling different scenarios. (what happens when we have a session with different version requests--should we allow that to happen, etc) depending on this, we may want topicid to be a var (to update the id when we change request versions). i'll write up a summary of the logic i'm thinking of when i get it worked out.",0,0.683927059173584
627516643,9944,jolshan,2021-05-06T15:18:19Z,the difference is that we already have the topic names here. i added it for the optimization when we build the response data map again in kafkaapis (so we don't have to look up the topic ids again). but it is a little silly. one option is just to put that logic in the one place it is used instead of having such a method.,-1,0.9718797206878662
627518693,9944,jolshan,2021-05-06T15:20:46Z,"yeah. that seems cleaner. so the idea is that the constructor, won't set fetchdata for either version.",0,0.769925594329834
627519381,9944,jolshan,2021-05-06T15:21:33Z,"as mentioned below, we can simply not set fetchdata here and use the other two assignments.",0,0.9929514527320862
627522339,9944,jolshan,2021-05-06T15:25:02Z,would this work if we added a new topic to the session? i would think that we would need to add the new topic's info and the map is unmodifiable. please correct me if this is not the case.,0,0.9837603569030762
627523117,9944,jolshan,2021-05-06T15:26:00Z,"i think the original idea was that i wanted to make sure that we don't go from request version 12 up to version 13 in the same session. but in general, i need to rethink this whole approach, so this will very likely change. as mentioned in another comment, i'll write up the logic i'm thinking about so we are on the same page.",0,0.9568105936050415
627523900,9944,jolshan,2021-05-06T15:26:58Z,"i wasn't sure on this, but i can add them. maybe it makes sense just to add topicids though? (not both maps)",0,0.9550869464874268
627723205,9944,jolshan,2021-05-06T19:56:00Z,ah another artifact from before. good catch.,1,0.9515213966369629
627724561,9944,jolshan,2021-05-06T19:58:26Z,ah wait. the iterator is empty here. we create a new one `(new fetchsession.resp_map).entryset.iterator` and do not use `updates`. this is because the session is an error one.,0,0.9250969290733337
627767360,9944,jolshan,2021-05-06T21:11:12Z,rewrote this comment to be more concise.,0,0.9839497804641724
627776011,9944,jolshan,2021-05-06T21:27:29Z,"ah i realize that since this is a single topic, we can change this logic.",0,0.9458345770835876
627840199,9944,jolshan,2021-05-07T00:05:48Z,decided that we can use either version throughout the course of a session. removed instance val,0,0.994305431842804
628405414,9944,jolshan,2021-05-07T17:55:55Z,"after running through some tests i realized why this didn't work. we can go from version 13 to version 12 within the session, but we can't go from 12 to 13. this is because we have may have topics without ids in the session. we will try to return them using version 13 and they are all zero uuid. (we also have this issue when we send a full request version 12 and the subsequent request is empty. we could try to send version 13 request since we vacuously have ids for all topics in the request, but if we do have responses for the topics, then we will try to send them back without topic ids) if we tried to resolve them, we may end up in a case where there is no valid id and also no way to communicate this (since we send back ids). so i think we do need to store the state of the previous request version in the session.",0,0.942693829536438
648811500,9944,jolshan,2021-06-10T02:49:34Z,"i noticed that i get topic ids from metadata here and in the replica fetcher thread, i get from the metadata cache. i don't think it is a big deal since we add to the fetchdata using the same source, but it might make sense to use fetchrequestdata's topicids() instead.",0,0.9797602295875549
649585182,9944,junrao,2021-06-10T23:00:31Z,space after foreach.,0,0.9880708456039429
649603470,9944,junrao,2021-06-10T23:57:50Z,from topic name for topic id => from topic name to topic id ?,0,0.9927436113357544
649607001,9944,junrao,2021-06-11T00:09:33Z,should we include topicid in hashcode() and equals()?,0,0.9945200085639954
650157796,9944,junrao,2021-06-11T17:31:30Z,do we need to handle unknown_topic_id here too?,0,0.9944313168525696
650161415,9944,junrao,2021-06-11T17:38:16Z,"since metadatasnapshot could change anytime, it's more consistent if we save a copy of metadatasnapshot and derive both maps from the same cached value.",0,0.9921777844429016
650163078,9944,junrao,2021-06-11T17:41:14Z,could we use case to avoid unnamed reference _._2 to make it easier to read?,0,0.9942272901535034
650165036,9944,junrao,2021-06-11T17:44:44Z,"since metadatache could change, it's probably slightly better to get topicidstonames and topicnamestoids once from metadatache so that they are consistent.",0,0.992440938949585
650166656,9944,junrao,2021-06-11T17:47:42Z,is the test apikeys.fetch.latestversion >= 13 necessary? this code is added when we introduce version 13 as the latest fetch version.,0,0.9950306415557861
650169478,9944,junrao,2021-06-11T17:52:40Z,is the test apikeys.fetch.latestversion >= 13 necessary? this code is added when we introduce version 13 as the latest fetch version.,0,0.9950306415557861
650612574,9944,jolshan,2021-06-14T01:59:16Z,734fd7f fixes this,0,0.943418025970459
651075127,9944,junrao,2021-06-14T15:55:51Z,the kip talks about bootstrapping the topicid for the metadata topic. is that part done already? i don't see it included in this pr.,0,0.9898523688316345
651086239,9944,junrao,2021-06-14T16:10:24Z,"if we get fetchsessiontopicidexception, the existing session is going to be invalid. so, it seems that we should start a new session? the same thing seems to apply to unknowntopicidexception",0,0.932233989238739
651096649,9944,junrao,2021-06-14T16:24:39Z,could we do the topicids part once after the if/else block to avoid duplication?,0,0.9947681427001953
651099635,9944,junrao,2021-06-14T16:28:37Z,does this work with topic recreation? will a client be stuck with the old topicid when topic is recreated?,0,0.9826931953430176
651124339,9944,junrao,2021-06-14T17:04:08Z,should we set sessiontopicids and sessiontopicnames to empty map if canusetopicids is false?,0,0.9949131011962891
651163378,9944,junrao,2021-06-14T18:03:14Z,"i am wondering if this solves the problem completely. the decision to use version 13 fetch request also depends on the kafka version on the broker. so, even if the client has all topic ids, the client may still send version 12 fetch requests to a broker. so, canusetopicids doesn't accurate capture the state whether a version 13 fetch request has been used. another possibility is to handle the switching from version 12 to 13 of the fetch requests on the server side in fetchsession. fetchsession already stores usestopicids. so, if usestopicids is false and a fetch request passes in topicid, we could send an error to the client to force the client to establish a new session. if we do this, we probably don't need to cache the canusetopicids in client fetch session. we can just calculated canusetopicids independently for each request. will this approach be better?",0,0.9791377782821655
651170786,9944,junrao,2021-06-14T18:15:00Z,it might be useful to include the topic name and topic id (old and new) for those inconsistent topic ids.,0,0.9907594919204712
651293905,9944,junrao,2021-06-14T21:35:11Z,"maxversion is not necessary the exact version used for fetch request. the exact version is determined in networkclient.dosend() based on the response of apiversions. so, here, it seems that we need to pass in the exact version number?",0,0.9920097589492798
651294705,9944,junrao,2021-06-14T21:36:47Z,should we force close the fetchsession in this case too?,0,0.9942130446434021
651309361,9944,junrao,2021-06-14T22:05:50Z,"since topartitiondatamap() is only called here, should we just inline it here?",0,0.9954673051834106
651310206,9944,junrao,2021-06-14T22:07:39Z,should we document fetch_session_topic_id_error too?,0,0.9944506883621216
651310982,9944,junrao,2021-06-14T22:09:16Z,should unknown_topic_id be fetch_session_topic_id_error now?,0,0.9946408271789551
651314171,9944,junrao,2021-06-14T22:16:16Z,should we just inline toresponsedatamap() here?,0,0.9952337145805359
651314503,9944,junrao,2021-06-14T22:17:04Z,we choose to cache responsedata here but not in fetchrequest. is there a particular reason for this inconsistency?,0,0.9865938425064087
651329577,9944,jolshan,2021-06-14T22:53:56Z,"are you referring to creating a new topic id for the metadata topic? for now, we are simply using the sentinel id.",0,0.9926813244819641
651331247,9944,jolshan,2021-06-14T22:58:05Z,this happens inside of `fetchsessionhandler.handleresponse`. we set the session to close upon the next request. the code path for fetcher is slightly different so it made sense for that code to have it there.,0,0.9938929080963135
651331636,9944,jolshan,2021-06-14T22:59:05Z,"this is no longer a partition level error. we can only get it as a top level error. if it is a top level error, i believe we return an empty map and do not go down this code path.",0,0.9720956683158875
651332118,9944,jolshan,2021-06-14T23:00:22Z,"if we try to put in a new topic id, the session should be closed.",0,0.9898485541343689
651332908,9944,jolshan,2021-06-14T23:02:23Z,ah i see what you are saying here. i think this will still close the session when we send the request. the other option is to set a boolean similar to `missingtopicid` (maybe just change to `inconsistenttopicid` that signals to close the session earlier (upon build),0,0.9754937291145325
651333015,9944,jolshan,2021-06-14T23:02:46Z,that makes sense to me.,0,0.9786012172698975
651334106,9944,jolshan,2021-06-14T23:05:39Z,"i think we already do something like this on the broker. we only get to the point of having a session if the broker had an id for all the topics in the request. i don't think we can calculate on a request basis since we may respond with topics that did not have ids associated. i may be misunderstanding what you are saying, but i'm very wary of trying to switch between versions 12 and 13 in the same session.",-1,0.6400609612464905
651335121,9944,jolshan,2021-06-14T23:08:31Z,i see what you mean. it is a little tricky to get the version from the fetchresponse itself. would `resp.requestheader().apiversion()` work?,0,0.5127238631248474
651335255,9944,jolshan,2021-06-14T23:08:49Z,this closes the session in handler.handlerresponse.,0,0.9931321740150452
651335666,9944,jolshan,2021-06-14T23:09:59Z,i think i just have the wrong things here completely. there should be inconsistent_topic_id here as well.,0,0.6780827641487122
651336157,9944,jolshan,2021-06-14T23:11:15Z,i think this inconsistency existed before i touched the code. :grinning_face_with_sweat:,0,0.9484114050865173
651373234,9944,junrao,2021-06-15T01:01:41Z,"got it. could we clean the existing code up a bit? since fetchsessionhandler.handleresponse() already handles the closing of the session on error, it seem that we could get rid of fetchsessionhandler.handleerror(t). also, it seems that if fetchresponse.error() != none, we want to throw the error as an exception. finally, if fetchsessionhandler.handleresponse() returns false, we probably want to throw an exception too?",0,0.9927688837051392
651933919,9944,junrao,2021-06-15T15:59:07Z,got it. we can keep the code as it is then.,0,0.972391664981842
651939380,9944,junrao,2021-06-15T16:06:10Z,"if we are switching from version 12 to version 13 for a session, prevsessiontopicid will be null. should we also populate inconsistenttopicids in this case to force a new session in the client?",0,0.9925917387008667
651943909,9944,junrao,2021-06-15T16:11:49Z,"i added another comment in fetchsession. if the session starts with no topicid and a fetch request switches to using topicid, could the server just return an error to force a new session? will this avoid the need to track canusetopicids as a state? overall, it's probably a bit better to add a bit complexity on the server to simplify the development on the client since we implement the client multiple times in different languages.",0,0.9925042390823364
651946576,9944,junrao,2021-06-15T16:15:00Z,"yes, i think that works.",0,0.9161049127578735
651947708,9944,junrao,2021-06-15T16:16:03Z,thanks. sounds good.,1,0.9902436137199402
651969184,9944,jolshan,2021-06-15T16:42:29Z,i think there are other errors that can occur when trying to send the request which is why we have fetchsessionhandler.handleerror(t). but this all can probably be cleaned up a bit/improved so i will take a look.,0,0.9780440926551819
651970044,9944,jolshan,2021-06-15T16:43:38Z,"if we switch from 12 to 13, we will not get to this point. we will throw a fetch_session_id_error before we get here.",0,0.9831878542900085
651971564,9944,jolshan,2021-06-15T16:45:41Z,this is something that we are doing in fetchsession. we close the session if the requests switch between 12 and 13 (or vice versa). is the idea that we will just send the request based on the topic ids provided to the builder (if we have an id for each topic) and let the session code on the server handle it?,0,0.9937660694122314
651976677,9944,junrao,2021-06-15T16:52:21Z,"yes, if that makes the client code simpler and more consistent. for example, in [a link] the client also chooses to let the server handle the closing of the session.",0,0.990094006061554
651977071,9944,junrao,2021-06-15T16:52:49Z,got it. make sense.,0,0.944227397441864
651985270,9944,jolshan,2021-06-15T17:03:49Z,"i thought about this, and originally we compared the topic ids in the session by grabbing cached partitions and comparing to the ids in the request. since we have a new mechanism (the topic id map) we may no longer need to do this and i can add the id to the hashcode and equals methods.",0,0.9857327342033386
652228425,9944,jolshan,2021-06-15T23:27:39Z,this one is slightly different as we are checking the ibp to get fetchrequestversion. we could have an ibp where the version is lower than 12.,0,0.9402354955673218
652250666,9944,jolshan,2021-06-15T23:53:46Z,i was just thinking about this and realized we may send new error types to clients that may not be able to handle them. i need to review this code again.,0,0.6843488216400146
652835907,9944,jolshan,2021-06-16T16:04:40Z,"ok. just went through logic for old clients 1. unknown_topic_id should not be returned since we won't ever use topic ids (version 12 requests and below)"" 2. fetch_session_topic_id_error should not be returned since we won't send version 13+ in a session and will always have zero uuids 3. inconsistent_topic_id should not be returned, as we won't have topic ids in the request/session. the only thing i can think of is downgrading a client while a session is open. i'm not sure if this can happen.",0,0.938446044921875
652838939,9944,jolshan,2021-06-16T16:08:28Z,"though in most cases, if we canusetopicids we likely have ibp 2.8, or are upgrading to it.",0,0.9932377338409424
652875100,9944,jolshan,2021-06-16T16:55:24Z,one option is to do what the raftmetadatacache does and simply create a copy of the maps themselves in topicnamestoids() and topicidstonames(),0,0.9950297474861145
653921888,9944,jolshan,2021-06-17T20:43:55Z,"i think the main reason we keep the state in the session for using topic ids is that some requests may not contain any new/updated partitions and we need to know which version to send. we don't want to close the session and simply send the version that was sent last time. i do think this code is quite confusing as is, so i think i can simply a lot of it.",-1,0.7547845840454102
654039106,9944,jolshan,2021-06-17T23:06:25Z,"ah, i found another use -- we lookup partitions toforget using the hashcode. right now, toforget is a list of topic partitions and we don't directly use the id provided in the request. we could look up the topic id from the topic id map and use it (we could also remove from the session map if we do remove the topic)",0,0.9914613962173462
654673513,9944,jolshan,2021-06-18T20:57:32Z,"this is causing build failures, will update to prevent this.",0,0.932272732257843
655561404,9944,junrao,2021-06-21T17:07:25Z,"the inconsistent_topic_id check in replicamanager is not very precise since the topicid could change immediately after the check. i am thinking that another way to do this is to validate the topicid in the session again when we are generating the fetch response. we could pass in the latest topicnametoid mapping from the metadata cache to updateandgenerateresponsedata(). if the topicid is different from those in the fetch session, we could generate a top level inconsistent_topic_id error. we could then get rid of the inconsistent_topic_id check in replicamanager.",0,0.9891062378883362
655565663,9944,junrao,2021-06-21T17:14:12Z,is there a benefit to have fetch_session_topic_id_error in addition to inconsistent_topic_id? could we just always use inconsistent_topic_id?,0,0.9947092533111572
655574477,9944,junrao,2021-06-21T17:28:11Z,"in the latest pr, it seems that canusetopicids is updated on every build() call and can be a local val?",0,0.994756817817688
655574856,9944,junrao,2021-06-21T17:28:40Z,could we do this once at the beginning of build()?,0,0.9944931268692017
655590483,9944,junrao,2021-06-21T17:52:19Z,should we add topicid in tostring()?,0,0.9935460686683655
655593298,9944,junrao,2021-06-21T17:56:38Z,i thought that inconsistent_topic_id is always a top level error now?,0,0.9894493222236633
655598054,9944,junrao,2021-06-21T18:04:11Z,could we first save metadatasnapshot to a local val and then derive both maps so that they can be consistent?,0,0.9938915967941284
655599428,9944,junrao,2021-06-21T18:06:40Z,could we first save _currentimage to a local val and derive both maps from it so that they are consistent?,0,0.9941217303276062
655603017,9944,junrao,2021-06-21T18:12:38Z,then could we try/catch just leaderendpoint.sendrequest and call fetchsessionhandler.handleerror(t) on exception? this will make the code easier to understand.,0,0.9912630319595337
655604345,9944,junrao,2021-06-21T18:14:53Z,could we just use errors.forcode() to translate errorcode to exception generically?,0,0.9932303428649902
655614034,9944,junrao,2021-06-21T18:30:41Z,"since we cache fetchdata before, perhaps we could cache it in the new implementation too? this will make it more consistent with fetchresponse. ditto for toforget().",0,0.9931299090385437
655614908,9944,junrao,2021-06-21T18:32:10Z,extra empty line.,0,0.9731570482254028
655621465,9944,junrao,2021-06-21T18:42:57Z,"since this tests non-existing topics, why do we pass in topicnames for fetch requests?",0,0.9894587993621826
655622855,9944,junrao,2021-06-21T18:45:21Z,"this is an existing issue, but could we use case to remove unnamed references _._1?",0,0.9939451813697815
655627698,9944,junrao,2021-06-21T18:53:31Z,could we share the common code btw testcontrollernewibp() and testcontrolleroldibp()?,0,0.9954029321670532
655629132,9944,junrao,2021-06-21T18:55:47Z,should we remove this line? ditto in a few other places in this file.,0,0.9906174540519714
655642933,9944,jolshan,2021-06-21T19:19:02Z,ah apologies i did not clean up as well as i should have.,-1,0.9842233061790466
655643270,9944,jolshan,2021-06-21T19:19:42Z,i can try to pick up all the changes i made that do this.,0,0.9739577770233154
655647688,9944,jolshan,2021-06-21T19:27:27Z,and i discussed this a bit. it seems that the metadata cache may be less accurate than the log itself and that is why we did away with the metadata check. i am also a little unsure (i'd have to check the code) but i'm not sure if the topicid can change. are we saying that the partition and/or the underlying log can change in this code block? i think we can say we will read from the partition with that id. [code block],0,0.9373154044151306
655648541,9944,jolshan,2021-06-21T19:28:56Z,"i think the main reason why i made the session id error was that the inconsistent topic id error's message was too specific for this use case. i suppose we could just make all the errors here session errors. i do like the inconsistent id error specifying the log (and being on the partition with the issue), but we can change this.",0,0.9669344425201416
655649094,9944,jolshan,2021-06-21T19:29:53Z,"it is both a top level and partition error here. i kind of like being able to identify the partition (kind of wish the other errors could do this in some cases), but we can change this.",0,0.9349334239959717
655649425,9944,jolshan,2021-06-21T19:30:29Z,ok. i see what you mean here.,0,0.9495492577552795
655649858,9944,jolshan,2021-06-21T19:31:17Z,ah good point. i can look into this.,1,0.9659723043441772
655810138,9944,jolshan,2021-06-22T01:27:11Z,"i think because we still want to build the request. my understanding is that the topic is non-existing on the receiving side, but we still want to receive and handle the response.",0,0.9817665219306946
660013467,9944,junrao,2021-06-28T18:14:42Z,"it seems that we should never change the topicid in sessiontopicids? perhaps we should use putifabsent. similarly, if the topicid changes, i am not sure if we should update partitionmap below.",0,0.9616607427597046
660016282,9944,junrao,2021-06-28T18:19:08Z,do we need to include the new fields in tostring()?,0,0.9923100471496582
660018415,9944,junrao,2021-06-28T18:22:37Z,should we use usetopicid instead of version?,0,0.994400680065155
660032238,9944,junrao,2021-06-28T18:45:23Z,should we rename error to toplevelerror to make it clearer?,0,0.9938861727714539
660032853,9944,junrao,2021-06-28T18:46:25Z,"typically, if there is a topic level error, we set the same error in every partition through fetchrequest.geterrorresponse(). should we do the same thing here? ditto for incrementalfetchcontext.updateandgenerateresponsedata().",0,0.9936874508857727
660034212,9944,junrao,2021-06-28T18:48:30Z,error => toplevelerror?,0,0.9882823824882507
660038680,9944,junrao,2021-06-28T18:55:42Z,"ok, this is fine. i was thinking that when topicid changes, a pending fetch request could still reference the outdated partition object and therefore miss the topicid change. this is unlikely and can be tighten up by clearing the segment list when a partition is deleted. regarding the metadata propagation, it's true that right now, we propagate the leaderandisrrequest before the updatemetadatarequest. with raft, the topicid will always flow through metadata update first, followed by the replicamanager. when we get there, maybe we could simplify the the logic a bit.",0,0.9769254922866821
660061129,9944,jolshan,2021-06-28T19:31:39Z,"if a topic id changes, the fetchsession will become a fetcherrorsession and close. i can change to putifabsent if it makes things clearer, but all this state will go away upon an error + session close.",0,0.9845209717750549
660061358,9944,jolshan,2021-06-28T19:32:04Z,i suppose it won't hurt :),1,0.9890453815460205
660061496,9944,jolshan,2021-06-28T19:32:18Z,we can do that to make things clearer.,0,0.9866575598716736
660062652,9944,jolshan,2021-06-28T19:34:17Z,"i think this goes back to the question of whether it is useful for us to have information on the specific partition that failed. if we do this, should we also return the error values for the other fields as we do in fetchrequest.geterrorresponse?",0,0.9907863140106201
660068452,9944,jolshan,2021-06-28T19:44:25Z,"i'm still not sure i follow ""pending fetch request could still reference the outdated partition object and therefore miss the topicid change"" my understanding is that the log is the source of truth and we will either read from the log if it matches and not read if it doesn't. i see we could get an error erroneously if the partition didn't update in time, but i don't see us being able to read from the log due to a stale partition. or are you referring to the getpartitionorexception(tp) call picking up a stale partition and both the request and the partition are stale? in this case, we will read from the log, but will identify it with its correct id. the client will handle based on this.",0,0.8659171462059021
660122565,9944,jolshan,2021-06-28T21:16:00Z,"i guess the only issue with using fetchrequest.geterrorresponse is that we may have different topics in the response than in the request. sessionerrorcontext deals with this by simply having an empty response besides the top level error. i'm wondering if we should do something like this. (likewise, with the unknown_topic_id error, should we also just send back an empty response?)",0,0.9687917828559875
660127887,9944,jolshan,2021-06-28T21:25:48Z,"taking a second look, seems like we just use partitionmap.size. not sure if it is useful to have sessiontopicids size (and if the whole map is too much). i'm thinking maybe just including the usestopicids boolean.",0,0.9732666015625
660199209,9944,jolshan,2021-06-29T00:33:08Z,"we need to do something like this to easily get the top level error with no partition response for unknown_topic_id. i think this works, but we may want a version check as well just to be safe.",0,0.9860255122184753
660206465,9944,junrao,2021-06-29T00:57:22Z,"this kind of special treatment for unknown_topic_id is a bit weird. if you look at the comment above, the reason for setting the same error code in all partitions is for backward compatibility when we don't have a top level error code. so, we probably can just check the request version. if version is >=13, we just always return a top level error code with no partitions.",-1,0.8537922501564026
660209346,9944,junrao,2021-06-29T01:06:54Z,"this can also cause a bit confusing that we are treating inconsistent_topic_id differently from other top-level errors. since the only possible top level error is inconsistent_topic_id, perhaps we can change toplevelerror to hasinconsistenttopicid. ditto in incrementalfetchcontext.",0,0.9373490214347839
660211602,9944,junrao,2021-06-29T01:14:20Z,"a fetch request may pass the topicid check in replicamanager and is about to call log.read(), when the topicid changes. i was wondering in that case, if log.read() could return data that corresponds to the old topicid. it seems that's not possible since log.close() closes all segments.",0,0.8670912981033325
660228129,9944,jolshan,2021-06-29T02:06:34Z,yeah. i agree it is a bit weird. we can update as you mentioned.,-1,0.9899308681488037
660228674,9944,jolshan,2021-06-29T02:08:16Z,"the topic id should not change in the log once it is set. i think what you said in the last sentence is correct. my understanding is that if the log is closed, it can not read from it anymore.",0,0.9858934879302979
661716207,9944,junrao,2021-06-30T18:27:18Z,"could we adjust the above comment on ""the error is indicated in two ways: by setting the same error code in all partitions, and by setting the top-level error code. the form where we set the same error code in all partitions is needed in order to maintain backwards compatibility with older versions of the protocol in which there was no top-level error code."" ?",0,0.9952284097671509
661716835,9944,junrao,2021-06-30T18:28:20Z,"if we can't merge this in 3.0, we will need to change the tag to 3.1.",0,0.9938725233078003
661788073,9944,jolshan,2021-06-30T20:26:49Z,we should adjust this to say we will no longer set on all partitions for versions 13+?,0,0.9936222434043884
661822644,9944,junrao,2021-06-30T21:27:16Z,right,0,0.8996442556381226
671728971,9944,chia7712,2021-07-17T18:30:04Z,"i noticed following warning message from our cluster (building on trunk). [code block] according to this code, changing the version in session is disallowed (please correct me if i misunderstood). should fetch thread keep version in session meta? or change the log level to `debug`?",0,0.9673585295677185
671730072,9944,chia7712,2021-07-17T18:40:57Z,"if there is a removing partition, the topic id is not added to this builder. the fetch request with version=13 will carry `topic='xxx'` and `id=aaa...`. however, the topic name get reset to empty string by kafka protocol. hence, the following error message is produced. [code block] if this is an expected behavior, should we change the log level from `error` to `debug`? or add more docs to say `this error may be returned transiently when xxx`?",0,0.9948207139968872
671754420,9944,jolshan,2021-07-17T23:12:32Z,hi i'm tracking this bug here and will work on the fix: [a link],0,0.9572694897651672
671754618,9944,jolshan,2021-07-17T23:14:47Z,"in general, we should not send a request without a valid name or id. we remove partitions from a session by not including them in the builder -- so theoretically, we should already have the topic id. the only case we don't is when we are in a session that doesn't use topic ids. i will fix this behavior to also check that the topics being removed have ids in the session, otherwise send a v12 request.",0,0.9934878349304199
671754732,9944,chia7712,2021-07-17T23:16:05Z,thanks for response and tracking! will watch the issue!,1,0.8667698502540588
671754759,9944,jolshan,2021-07-17T23:16:31Z,"changing the version is not allowed. i'm not sure i follow what you mean by keeping version. current usestopicids is set based on the version when the session is first created and maintained throughout the session. i think we will see this error transiently, but please let me know if you continue to see this issue after i fix the bug below.",-1,0.5759667754173279
671755992,9944,chia7712,2021-07-17T23:33:04Z,thanks for explanation. will test it after you fix the issue!,1,0.879532516002655
671773887,9944,jolshan,2021-07-18T03:16:33Z,this one too: [a link] i have an idea of how to fix this one as well and it should make a big difference based on the testing i've done so far.,0,0.9488618969917297
1146803694,13443,jeffkbkim,2023-03-23T20:35:42Z,this usually suggests that the code can be simplified. do we see this issue?,0,0.9883792400360107
1146805063,13443,jeffkbkim,2023-03-23T20:37:10Z,is it necessary to use list?,0,0.9921334981918335
1146877129,13443,philipnee,2023-03-23T21:23:46Z,hey do you want to move the document above the class definition?,0,0.9886199235916138
1148105873,13443,jeffkbkim,2023-03-24T22:19:19Z,do these methods need to be protected?,0,0.9912025928497314
1148110690,13443,jeffkbkim,2023-03-24T22:24:26Z,when should we throw partitionassignorexception? should we throw when topics are not co-partitioned?,0,0.9926490187644958
1148119606,13443,jeffkbkim,2023-03-24T22:36:05Z,can we just define this as minrequiredquota?,0,0.9944105744361877
1148125546,13443,jeffkbkim,2023-03-24T22:48:14Z,i might be missing something - is it possible to decrease the number of partitions? there seems to be a related kip: [a link] but i don't see the new record.,0,0.9786387085914612
1148129063,13443,jeffkbkim,2023-03-24T22:54:58Z,do we want to sort for every retainedpartitionscount?,0,0.984628438949585
1148132025,13443,jeffkbkim,2023-03-24T23:01:45Z,"can you help me understand why we're incrementing? remaining is the number of partitions remaining to meet the min required quota so if we're giving one of the extra partitions to this member, my intuition tells me that remaining should decremented here.",0,0.9877033233642578
1148134237,13443,jeffkbkim,2023-03-24T23:08:04Z,can we create a new arraylist and add it at the end instead of accessing the map each time to add a new partition in l131?,0,0.9947376847267151
1148141785,13443,jeffkbkim,2023-03-24T23:29:17Z,i think we can make this more efficient. removing all elements from one list with another will take o(n^2) assuming both have same size.,0,0.980995237827301
1148145596,13443,philipnee,2023-03-24T23:38:46Z,"i got pointed out several times to make the param final. i think it's a good practice, wdyt?",0,0.8736903667449951
1148146400,13443,philipnee,2023-03-24T23:41:25Z,"i don't think we need this comment, the intent is pretty obvious.",0,0.7754139304161072
1148149978,13443,philipnee,2023-03-24T23:51:23Z,is it possible to do? [code block],0,0.9931355714797974
1148150169,13443,philipnee,2023-03-24T23:52:05Z,"this and step 2 can be more descriptive. but we probably don't need to explicitly describe the step, i guess.",0,0.979151725769043
1149558270,13443,philipnee,2023-03-27T17:05:32Z,i wonder if we should put this in common - i assume there's a lot of common use case for pair,0,0.8796907663345337
1149567823,13443,philipnee,2023-03-27T17:15:08Z,i would refactor this into a separated function as it's kind of long.,0,0.9812095761299133
1149569835,13443,philipnee,2023-03-27T17:17:12Z,"you could avoid null check using getordefault(topicid, new hashset<>())",0,0.9923426508903503
1149570091,13443,philipnee,2023-03-27T17:17:29Z,"the comment is also not needed, null check here is pretty indicative.",0,0.9437968730926514
1149572710,13443,philipnee,2023-03-27T17:20:07Z,i'm not entirely clear about the point of conversion here: i think it is because of line 181. there couldn't use use the foreach/for( ... : ...) syntax?,0,0.6913238167762756
1149630814,13443,rreddy-22,2023-03-27T18:17:17Z,i tried to simplify it as much as possible but since we wanted to many properties the code is a little complex,-1,0.5923929810523987
1149644261,13443,rreddy-22,2023-03-27T18:28:14Z,"no its not necessary but it's easier to work with, is there a reason why we should use collection instead of list?",0,0.9894179701805115
1149647453,13443,rreddy-22,2023-03-27T18:31:26Z,"it's specific to the data structures we're using for the assignor so i made it protected so only classes that use the same maps can use it, to avoid confusion.",0,0.9895555377006531
1149648624,13443,rreddy-22,2023-03-27T18:32:36Z,"this was added by david in the kip, i'm not sure when he meant for this exception to be thrown.",0,0.7296735048294067
1149650468,13443,rreddy-22,2023-03-27T18:34:27Z,"it's easier to understand if it's first named as numpartitionsperconsumer, i also tried to keep as many original variable names as possible so it's simpler to compare it with the client side/ existing range assignor",0,0.9897475242614746
1149655641,13443,rreddy-22,2023-03-27T18:37:49Z,oh! i wasn't sure if it was possible but i just designed the algorithm for all sorts of metadata changes. we could remove it and maybe if/when the removal of partitions is possible we can add it back. removed the code and the test case for now,-1,0.6186033487319946
1149658306,13443,rreddy-22,2023-03-27T18:40:15Z,"my bad, moved it before the for loop",-1,0.9871606826782227
1149659044,13443,rreddy-22,2023-03-27T18:41:02Z,"remaining = minrequiredquota - completedquota in cases where there are extra partitions after equally dividing the partitions amongst the consumers they will receive more than the minimum required quota, we're essentially increasing the quota by 1 -> requiredquota = minreq + 1 newremaining = requiredquota - completedquota = minreq + 1 - completedquota = minreq - completed + 1 = remaining + 1",0,0.9814866185188293
1149666320,13443,rreddy-22,2023-03-27T18:48:32Z,"okay yeah makes sense, i'll try to do it with a counter",0,0.8890700340270996
1152197788,13443,jeffkbkim,2023-03-29T16:24:47Z,collection allows iterating over elements which is the only use i see with subscribedtopics. it makes it more generic there's no need to use list here,0,0.9843749403953552
1152198768,13443,jeffkbkim,2023-03-29T16:25:38Z,can we make these private?,0,0.9915444850921631
1152199939,13443,jeffkbkim,2023-03-29T16:26:38Z,"you should clarify that, we should be throwing the exception here if that's expected.",0,0.9877949953079224
1152204557,13443,jeffkbkim,2023-03-29T16:29:48Z,we don't use this variable at all except renaming to minrequiredquota. the comments in l170-171 already explain well what the variable represents,0,0.991569995880127
1152261139,13443,rreddy-22,2023-03-29T17:15:23Z,"yep clarified, we'll add those cases soon!",0,0.6481313109397888
1152265456,13443,rreddy-22,2023-03-29T17:19:13Z,cool i'll rename it,1,0.7474492788314819
1152272541,13443,rreddy-22,2023-03-29T17:26:17Z,yess thanks !,1,0.9915487170219421
1152275571,13443,rreddy-22,2023-03-29T17:29:21Z,"since its already private, its treated as a final param so prolly not necessary here",0,0.9841800928115845
1152276204,13443,rreddy-22,2023-03-29T17:29:59Z,"got it, removed",0,0.961118221282959
1152284259,13443,rreddy-22,2023-03-29T17:36:42Z,"we need the integers that are not in the range [0, numpartitions] on comparison with assignedpartitions i.e we're calculating the difference between the set of assignedpartitions and the total set of partitions for that topic",0,0.9931274652481079
1152285443,13443,rreddy-22,2023-03-29T17:37:50Z,i just figured it would be easier to follow/correlate the code with the steps mentioned in the java doc,0,0.956202507019043
1152306205,13443,rreddy-22,2023-03-29T17:58:36Z,ohh got it! thanks! changed it!,1,0.9955607652664185
1152313744,13443,rreddy-22,2023-03-29T18:05:48Z,"we need the order of the partitions to be guaranteed and sorted when we're retaining the prev assignment, that's why we had to convert it to a list first.",0,0.9920449256896973
1152314761,13443,rreddy-22,2023-03-29T18:06:51Z,okay i'll refactor it!,0,0.7333672046661377
1152318162,13443,rreddy-22,2023-03-29T18:10:19Z,changed it!,0,0.7849392890930176
1152434986,13443,philipnee,2023-03-29T20:14:32Z,i think the point is final makes the params unmodifiable.,0,0.958953320980072
1152440653,13443,philipnee,2023-03-29T20:21:08Z,wait why is it specific? this is just a generic tuple no?,0,0.9434184432029724
1153765068,13443,rreddy-22,2023-03-30T20:40:33Z,sry my bad! i was thtinking about the putlist and putset,-1,0.9920485615730286
1156050423,13443,jeffkbkim,2023-04-03T14:32:42Z,this can be removed,0,0.9869565963745117
1156090957,13443,jeffkbkim,2023-04-03T15:03:49Z,should this be topic2name?,0,0.993320107460022
1156091273,13443,jeffkbkim,2023-04-03T15:04:06Z,nit: consumer c,0,0.9625598192214966
1156108091,13443,jeffkbkim,2023-04-03T15:17:35Z,"for expectedassignment, can we add a layer for each memberid? this is blindly matching with any member's assignment which doesn't seem right. then we won't have to remove from the expectedassignment which is also not ideal",0,0.9463114142417908
1156116922,13443,jeffkbkim,2023-04-03T15:24:40Z,you can use map.values() instead of entryset() if you don't need the key.,0,0.9921786785125732
1156117116,13443,jeffkbkim,2023-04-03T15:24:49Z,same here,0,0.9628711938858032
1156125078,13443,jeffkbkim,2023-04-03T15:31:14Z,"how do we know [0, 1] went to the same member from the initial assignment?",0,0.9923602938652039
1156240340,13443,rreddy-22,2023-04-03T17:18:04Z,this is a method though so private is implicitly final right?,0,0.9825690984725952
1156241130,13443,rreddy-22,2023-04-03T17:18:52Z,no we want all the mappings to be with uuid,0,0.9915071129798889
1156251873,13443,jeffkbkim,2023-04-03T17:29:52Z,"no, i'm referring to `assignmenttopicmetadata(topic1name, 3)`",0,0.9918477535247803
1156255508,13443,rreddy-22,2023-04-03T17:32:34Z,"no, this was done because we don't know which member gets which assignment. the order of members is not guaranteed at the time of assignment since they are stored in a hash map. so we're testing if the sets are correct and not testing the exact 1:1 mapping",0,0.9829927086830139
1157238218,13443,Hangleton,2023-04-04T13:20:44Z,are you referring to adding the `final` modifier to the parameter `assignmentspec` or the method `consumerspertopic`?,0,0.9946079254150391
1160097876,13443,rreddy-22,2023-04-06T17:54:18Z,ohhh yess thanks!,1,0.9936034083366394
1160098997,13443,rreddy-22,2023-04-06T17:55:36Z,going to add another test for stickiness,0,0.9571754336357117
1160919328,13443,jeffkbkim,2023-04-07T19:34:00Z,"""map of assigned partitions by topicid"" is more readable to me. wdyt?",0,0.9095299243927002
1160920086,13443,jeffkbkim,2023-04-07T19:35:49Z,in kafka we typically name getters as the field itself. in this case it would be `members()`,0,0.9947972893714905
1160921964,13443,jeffkbkim,2023-04-07T19:39:58Z,same on getters,0,0.9826769232749939
1160923243,13443,jeffkbkim,2023-04-07T19:42:41Z,"this doesn't look right in the javadoc. also can we get rid of all of the hyphens after colons? "":-"" to "":"" also, i think [code block] is more readable",0,0.9849594235420227
1160925170,13443,jeffkbkim,2023-04-07T19:46:40Z,you can use for numbered lists,0,0.9860756993293762
1160925256,13443,jeffkbkim,2023-04-07T19:46:52Z,"same here for ordered list. also, ""generate a map of consumerspertopic with member subscriptions."" not sure we actually need this point",0,0.9907962083816528
1160927503,13443,jeffkbkim,2023-04-07T19:51:37Z,we need another layer of lists,0,0.9821661114692688
1160929729,13443,jeffkbkim,2023-04-07T19:56:12Z,nit: can we \ all variables \ ?,0,0.983734130859375
1160933184,13443,jeffkbkim,2023-04-07T20:00:32Z,i don't think quota = minquota... is very helpful. how's,1,0.7553461194038391
1160934110,13443,jeffkbkim,2023-04-07T20:02:31Z,how's,0,0.8922057747840881
1160937277,13443,jeffkbkim,2023-04-07T20:10:03Z,"was this comment actually addressed? also, i'm wondering if just creating `member` private class which contains [code block] fields. the current use of the pair class makes the code harder to read.",0,0.960759699344635
1160938321,13443,jeffkbkim,2023-04-07T20:12:17Z,"the method yes, but the param no. you can still modify assignmentspec inside the method",0,0.9919032454490662
1160939242,13443,jeffkbkim,2023-04-07T20:14:29Z,how's `consumersbytopic`?,0,0.9932969212532043
1160940413,13443,jeffkbkim,2023-04-07T20:17:16Z,nit: `members`,0,0.9910857081413269
1160941760,13443,jeffkbkim,2023-04-07T20:20:15Z,i think [code block] looks simpler. wdyt?,0,0.8885865211486816
1160948260,13443,jeffkbkim,2023-04-07T20:34:27Z,nit: per topicid,0,0.9588990211486816
1160952656,13443,jeffkbkim,2023-04-07T20:44:09Z,do we really need to extract putlist and putset out? it makes the code harder to read. i don't see much benefit from this.,0,0.5370056629180908
1160953630,13443,jeffkbkim,2023-04-07T20:46:16Z,we can use keyset() here. we're not using the value,0,0.9917325973510742
1160954169,13443,jeffkbkim,2023-04-07T20:47:26Z,nit: `unassignedpartitionspertopic`,0,0.9931687116622925
1160959103,13443,jeffkbkim,2023-04-07T20:55:25Z,we can remove this comment,0,0.9859763383865356
1160967563,13443,jeffkbkim,2023-04-07T21:13:02Z,nit: i.e.,0,0.9680798053741455
1160972155,13443,jeffkbkim,2023-04-07T21:20:08Z,"nit: there's 2 spaces after ""="". also, let's break down the line into 2 lines.",0,0.9576193690299988
1160977912,13443,jeffkbkim,2023-04-07T21:33:40Z,"nit: ""should get i.e. number of partitions per consumer""",0,0.9770470857620239
1160979189,13443,jeffkbkim,2023-04-07T21:37:41Z,"nit: i think we can remove "" = numpartitionsperconsumer"" also `int excesspartitioncount` is simpler and more readable to me. wdyt?",0,0.9566217064857483
1160980503,13443,jeffkbkim,2023-04-07T21:40:55Z,"the numbering is off and ""potentially unfilled consumer"" and l204 ""add to the potentially unfilled consumers""",0,0.994763195514679
1160982741,13443,jeffkbkim,2023-04-07T21:47:34Z,"we are not ""assigning"" here, we're just increasing the quota. ""after possibly increasing the remaining quota with an excess partition"" makes more sense to me.",0,0.985776960849762
1160987340,13443,jeffkbkim,2023-04-07T21:55:53Z,are we actually deleting here? we're moving the pointer and grabbing a subset of the unassigned partitions. let's update the comments if we changed the code,0,0.9891853332519531
1160992340,13443,jeffkbkim,2023-04-07T22:03:34Z,"nit: `list partitionstoassign`, `int unassignedpartitionpointer`",0,0.9937514662742615
1164463357,13443,rreddy-22,2023-04-12T17:51:48Z,changed in interface changes,0,0.9872943758964539
1164463758,13443,rreddy-22,2023-04-12T17:52:14Z,changed in interface changes pr,0,0.9914758205413818
1164463893,13443,rreddy-22,2023-04-12T17:52:21Z,changed in interface changes pr,0,0.9914758205413818
1164465796,13443,rreddy-22,2023-04-12T17:54:07Z,done,0,0.8974218964576721
1164469564,13443,rreddy-22,2023-04-12T17:57:55Z,sounds good thanks!,1,0.9940391778945923
1164470089,13443,rreddy-22,2023-04-12T17:58:28Z,done!,0,0.6890168786048889
1164884200,13443,rreddy-22,2023-04-13T02:03:12Z,changed to memberspertopic,0,0.9860097169876099
1164884866,13443,rreddy-22,2023-04-13T02:03:51Z,removed the whole comment cause unnecessary,0,0.8352797031402588
1164893597,13443,rreddy-22,2023-04-13T02:12:37Z,changed it,0,0.9369763731956482
1164894366,13443,rreddy-22,2023-04-13T02:13:41Z,removed,0,0.9801433682441711
1164894487,13443,rreddy-22,2023-04-13T02:13:50Z,done,0,0.8974218964576721
1164899524,13443,rreddy-22,2023-04-13T02:17:50Z,ok,0,0.8787186145782471
1164901673,13443,rreddy-22,2023-04-13T02:19:25Z,i edited it but i want to keep it in cause its important,0,0.9474772214889526
1164901770,13443,rreddy-22,2023-04-13T02:19:32Z,ok,0,0.8787186145782471
1164902619,13443,rreddy-22,2023-04-13T02:20:32Z,doesn't exist anymore,0,0.9500582814216614
1164905279,13443,rreddy-22,2023-04-13T02:23:32Z,removed comment,0,0.980672299861908
1164906229,13443,rreddy-22,2023-04-13T02:24:25Z,each consumer gets one extra partition and i think the current name clarifies that,0,0.9779451489448547
1164906996,13443,rreddy-22,2023-04-13T02:25:13Z,done mb with the numbers,0,0.9717434048652649
1164908245,13443,rreddy-22,2023-04-13T02:26:48Z,cool changed it,1,0.794571042060852
1164908509,13443,rreddy-22,2023-04-13T02:27:06Z,yeah sorry updated the comments,-1,0.9867609739303589
1164911085,13443,rreddy-22,2023-04-13T02:30:03Z,done,0,0.8974218964576721
1169925559,13443,dajac,2023-04-18T12:00:00Z,should we revert this change now?,0,0.9913799166679382
1169925666,13443,dajac,2023-04-18T12:00:06Z,should we revert this change now?,0,0.9913799166679382
1169925763,13443,dajac,2023-04-18T12:00:11Z,should we revert this change now?,0,0.9913799166679382
1169958192,13443,dajac,2023-04-18T12:25:56Z,all the html makes the text quite messy. should we just remove it?,-1,0.8887416124343872
1169959223,13443,dajac,2023-04-18T12:26:47Z,should this section go to the javadoc of `assign`? that would be closer to the implementation.,0,0.9947668313980103
1169966483,13443,dajac,2023-04-18T12:32:52Z,"nit: there is an extra space after `=`. moreover, it seems that we don't mutate `assignedpartitionsfortopic` so we could actually use `collections.emptyset()` instead of `new hashset<>()`.",0,0.9925118684768677
1169982137,13443,dajac,2023-04-18T12:45:18Z,nit: a small stylistic comment: it would be better to structure such line as follow: [code block] i find this more readable than those long lines.,0,0.7811169028282166
1170005574,13443,dajac,2023-04-18T13:00:45Z,"is there a reason why we don't do step 4 and 5 directly in the `memberspertopic.foreach((topicid, membersfortopic)` loop?",0,0.9941251277923584
1170007516,13443,dajac,2023-04-18T13:02:11Z,nit: i have noticed that you use `computeifabsent` in a few places where `put` would just work.,0,0.9900321960449219
1170010343,13443,dajac,2023-04-18T13:04:31Z,"nit: whenever possible, let's use `collections.singletonmap`, `collections.emptymap`, `collection.emptylist`, etc.",0,0.9915812611579895
1170013892,13443,dajac,2023-04-18T13:07:19Z,nit: let's format such line as follow: [code block],0,0.9767366647720337
1170014726,13443,dajac,2023-04-18T13:07:58Z,nit: is `new arraylist<>` necessary here? there are many other cases.,0,0.9932082295417786
1170017991,13443,dajac,2023-04-18T13:10:28Z,i have a few utils [a link]. we could reuse them here as well. they allow you to define as assignment as follow: [code block] it makes the code easier to read.,0,0.9764497876167297
1170021475,13443,dajac,2023-04-18T13:13:12Z,i wonder if it would be better to actually create the expected `groupassignment` and to compare the computed one against it. we could then just use `assertequals` and this would verify the full output.,0,0.9884898066520691
1170322124,13443,rreddy-22,2023-04-18T16:52:38Z,"we discussed this before when i was writing the tests, that is how i did it earlier but i realized that the order of members isn't guaranteed in the hashmap so we don't know exactly what order the assignor used to predict the expected assignment",0,0.9696521162986755
1170357303,13443,dajac,2023-04-18T17:23:07Z,"if two maps have the same content, they will be equal, no? the order of the members does not matter here.",0,0.9856195449829102
1170658513,13443,rreddy-22,2023-04-18T23:21:37Z,remove the whole thing or just the html tags,0,0.9695620536804199
1170658595,13443,rreddy-22,2023-04-18T23:21:47Z,cool,1,0.6269813776016235
1170659867,13443,rreddy-22,2023-04-18T23:24:20Z,done,0,0.8974218964576721
1170662644,13443,rreddy-22,2023-04-18T23:30:19Z,the order in which the consumers were assigned partitions is unknown to us since at the time of computing the coordinator accesses the members map (order not guaranteed) so we can't predict which member gets which partitions in the first place. it could result in flaky tests,0,0.9505404829978943
1170981380,13443,dajac,2023-04-19T08:13:23Z,gotcha. i understand what you meant now.,0,0.7423610091209412
1171070403,13443,dajac,2023-04-19T09:23:44Z,just the html tags. the explanation is useful.,0,0.9797097444534302
1171777998,13443,rreddy-22,2023-04-19T19:37:45Z,"you're right, i've removed them!",1,0.8990588188171387
1171778657,13443,rreddy-22,2023-04-19T19:38:30Z,"the formatting is really off without them, that's why we had to add them",0,0.8565770983695984
1171781883,13443,rreddy-22,2023-04-19T19:42:18Z,"i removed most of them and converted them to put before, i'll check again",0,0.981272280216217
1171782048,13443,rreddy-22,2023-04-19T19:42:27Z,got it,0,0.929606556892395
1171783796,13443,rreddy-22,2023-04-19T19:44:36Z,like calculate unassigned partitions and assign them at the same time?,0,0.9928554892539978
1171913729,13443,rreddy-22,2023-04-19T22:33:48Z,re-checked and computeifabsent is the best safe way to do it,0,0.9855517148971558
1172314693,13443,dajac,2023-04-20T09:18:19Z,it does not have to be at the same time. i was wondering if there a reason why we need to do step 4 and 5 afterwards with all the unfilled members vs doing it per topic right after step 3.,0,0.9655969142913818
1172321570,13443,dajac,2023-04-20T09:23:13Z,let's try at minimum to align/indent/format things correctly. it does not look good as it is.,0,0.8488022089004517
1172322335,13443,dajac,2023-04-20T09:23:53Z,nit: we usually indent with 4 spaces in this case.,0,0.9815942049026489
1172324109,13443,dajac,2023-04-20T09:25:26Z,this is not correctly indented. it should be as follow: [code block],0,0.9764310717582703
1172325053,13443,dajac,2023-04-20T09:26:15Z,"nit: could we use `collections.singletonmap(topic1uuid, new assignmenttopicmetadata(3))`?",0,0.9951540231704712
1172325341,13443,dajac,2023-04-20T09:26:30Z,`singletonlist`?,0,0.9927666187286377
1172824513,13443,rreddy-22,2023-04-20T16:20:00Z,"i had changed it in my ide and it looked good, idky the formatting changed in the pr :( will take a look at it thanks!",-1,0.9775381684303284
1173050527,13443,rreddy-22,2023-04-20T20:17:51Z,okay,0,0.7269688844680786
1173172297,13443,rreddy-22,2023-04-20T23:26:12Z,done,0,0.8974218964576721
1173174594,13443,rreddy-22,2023-04-20T23:31:42Z,we need a set of sets so i added something similar in my test so facilitate the needs of this test case,0,0.987626850605011
1173177108,13443,rreddy-22,2023-04-20T23:37:24Z,we could've computed if the partition is still unassigned in step 5 directly and assigned it but since this is a range assignor i need all the available partitions in in a sorted list and the list provided is sorted since we iterate through 0-n where n is the total partitions and only add it to unassigned list iff it doesn't exist in the sticky partitions list,0,0.9917755126953125
1173177198,13443,rreddy-22,2023-04-20T23:37:37Z,i hope i understood the question correctly,0,0.8039547204971313
1173179837,13443,rreddy-22,2023-04-20T23:43:38Z,also the entire unfilled members per topic list needs to be populated since the ranges depend on how many partitions were assigned to the prev member,0,0.9889345765113831
1175267055,13443,dajac,2023-04-24T13:14:17Z,would it be possible to directly use `memberassignment` instead of `map ` here? that would save allocating a hashmap at the end.,0,0.9908958077430725
1175273145,13443,dajac,2023-04-24T13:19:07Z,"i still wonder if we could combine steps 4 and 5 in this loop. for instance, could we do something like this? * we start by creating a sorted set with all the partitions of the topic. * then for each member, we do what is already done but instead of populating `assignedstickypartitionspertopic`, we remove assigned partitions from the sorted set. * then we go through the unfilled members and allocated the remaining partitions in the sorted set. this could potentially reduce the number of data structures.",0,0.9821287393569946
1175274363,13443,dajac,2023-04-24T13:20:01Z,should we break this loop when there are no more partitions left to be assigned?,0,0.9931231141090393
1175279644,13443,dajac,2023-04-24T13:24:14Z,nit: we need to close ` `.,0,0.9802512526512146
1175280542,13443,dajac,2023-04-24T13:24:54Z,nit: ` ` does not seem to be required.,0,0.9607612490653992
1175552910,13443,rreddy-22,2023-04-24T16:48:56Z,we need to able to modify the map > throughout the code as we assign partitions and since targetpartitions in memberassignment is private final we can't modify it once its initialized. this is why i had to do it this way.,0,0.9736877083778381
1175567311,13443,rreddy-22,2023-04-24T17:03:25Z,"theoretically the sum of all the ""remaining"" values in the unfilled members list for the topic will be equal to the total unassigned partitions so we don't need to break the loop cause it happens automatically. i could add a check to ensure this is the case, i've added a check in the uniform assignor anyways just for a correctness check.",0,0.9931786060333252
1175689958,13443,rreddy-22,2023-04-24T19:17:01Z,steps 3 & 4?,0,0.992448091506958
1175701652,13443,rreddy-22,2023-04-24T19:30:51Z,we would need to have a map called partitions and to remove every assigned partition each removal would cost o(logn) so for n removals worst case o(nlogn). the time complexity of just calculating at the end is o(n). so its really just time vs space. we save space of one map o(n+m) in this method but we spend more time for removal.,0,0.9880627393722534
1175703194,13443,rreddy-22,2023-04-24T19:32:33Z,2maps and o(n) time vs 1map (potentially takes up more space if its a tree set for sorted order) and o(nlogn) time,0,0.9909640550613403
1176483468,13443,dajac,2023-04-25T13:01:28Z,"this is not entirely correct. yes, the assignment is private final but this does not prevent you from mutating the hash map. it only prevents you from re-assigning the attribute.",0,0.9552263021469116
1176489630,13443,dajac,2023-04-25T13:06:30Z,"i agree that the sorted set may not be the best so let's put this aside for now. coming back to my other point, would it be possible to compute the unassigned partitions and to assign them directly in this loop? i mean after the current logic in the loop. it does not have to be combined. i understand that we can't assign partitions while we check if we want to keep existing ones or not. if we do this, we could potentially eliminate step 3 or more precisely combine it with the next step. this would simplify the data structures overall, i think.",0,0.9522615075111389
1176631579,13443,jeffkbkim,2023-04-25T14:47:25Z,nit: unassignedpartitionspertopic,0,0.9762005805969238
1176636568,13443,jeffkbkim,2023-04-25T14:50:24Z,"nit: accessing the field looks straightforward enough, do we need this?",0,0.9735080599784851
1176654241,13443,jeffkbkim,2023-04-25T15:00:47Z,"nit: `(""member "" + memberid)`",0,0.9887202382087708
1176661712,13443,jeffkbkim,2023-04-25T15:06:20Z,"we can also change this to `int` once is removed. also, it would be good to describe what this remaining field represents",0,0.9822868704795837
1176666308,13443,jeffkbkim,2023-04-25T15:09:50Z,what if the member already has min required quota + 1 assigned to it? i think it's handled in l192,0,0.9935656189918518
1176688479,13443,jeffkbkim,2023-04-25T15:26:48Z,"how's ""it has min req partitions but it may get an extra partition so it is a potentially unfilled member""?",0,0.9880529642105103
1176692608,13443,jeffkbkim,2023-04-25T15:29:52Z,"how's ""if remaining > 0: it has not met the minimum required quota and therefore is unfilled.""",0,0.9691126346588135
1176694961,13443,jeffkbkim,2023-04-25T15:31:44Z,nit: memberandremainingassignments,0,0.9837311506271362
1176836313,13443,jeffkbkim,2023-04-25T17:39:36Z,"do we have a test case where a consumer had 4 partitions, reassignment computes 3 + 1 including the extra partition and we ensure all 4 partitions stick? a case to test whether extra partition is also sticky",0,0.9929617047309875
1177109065,13443,rreddy-22,2023-04-25T22:01:44Z,"oh sorry my bad, i've always learnt that final means you can't modify the value after, but i guess for a map you can't modify the reference but can change the values. i'll see what i can change thanks!",-1,0.9895794987678528
1177128215,13443,rreddy-22,2023-04-25T22:30:12Z,"i think i made a new function cause the assign function was getting super long but yeah we can put just the calculation of unassigned partitions in the same loop, changed it now thanks! sry the step numbers were confusing",1,0.5779930949211121
1177128655,13443,rreddy-22,2023-04-25T22:30:59Z,i think you mean step 4? step 3 is filling in the potentially unfilled members map and that i can't elminate.,0,0.9869367480278015
1177136376,13443,rreddy-22,2023-04-25T22:45:36Z,yeah it is handled 173-179,0,0.9844503998756409
1177139606,13443,rreddy-22,2023-04-25T22:51:57Z,this whole function is removed now,0,0.988906741142273
1177156557,13443,rreddy-22,2023-04-25T23:27:09Z,"removed, since it was derived from a generic pair class, missed removing it, thanks for the catch!",1,0.9779794812202454
1177156668,13443,rreddy-22,2023-04-25T23:27:23Z,done,0,0.8974218964576721
1177168353,13443,rreddy-22,2023-04-25T23:53:27Z,changed,0,0.9270829558372498
1177168484,13443,rreddy-22,2023-04-25T23:53:41Z,renamed to memberwithremainingassignments,0,0.9931057095527649
1177177698,13443,rreddy-22,2023-04-26T00:15:03Z,added another test just in case,0,0.9861721396446228
1177178765,13443,rreddy-22,2023-04-26T00:17:29Z,"not straightforward anymore with the new code, so kept it",0,0.9425698518753052
1177432844,13443,dajac,2023-04-26T07:05:14Z,should those be part of the preceding ` `?,0,0.9941463470458984
1177433390,13443,dajac,2023-04-26T07:05:47Z,nit: does it have to be public?,0,0.9773924946784973
1177434215,13443,dajac,2023-04-26T07:06:42Z,"nit: let's use the javadoc format. also, i would not mention `potentiallyunfilledmembers` and `unfilledmembers` here. let's describe the purpose only.",0,0.9880140423774719
1177434539,13443,dajac,2023-04-26T07:07:06Z,"nit: if we put javadoc for attributes, let's do it for all of them.",0,0.9866630434989929
1177435182,13443,dajac,2023-04-26T07:07:52Z,"nit: as this class is purely internal, i think that we could make the attributes public and remove the getters. they don't bring anything here.",0,0.9796127080917358
1177435368,13443,dajac,2023-04-26T07:08:04Z,nit: javadoc?,0,0.9874733686447144
1177436746,13443,dajac,2023-04-26T07:09:29Z,nit: the javadoc is not aligned correctly.,0,0.674431324005127
1177437828,13443,dajac,2023-04-26T07:10:37Z,nit: i would remove all the references to variables in the javadoc. they will get out of sync quickly. let's use plain english instead.,0,0.8232865929603577
1177438770,13443,dajac,2023-04-26T07:11:38Z,"now that we have all the logic in the main loop, it seems that those maps are not necessary anymore. we could just use lists/sets defined in the loop.",0,0.9897609353065491
1177447096,13443,dajac,2023-04-26T07:20:03Z,now that we have everything in the main loop could we combine step 3 into step 5 and avoid having to recreate memberwithremainingassignments objects here? it seems that we could just adjust the `remaining` when we assign partitions. is it possible?,0,0.9942278861999512
1177447497,13443,dajac,2023-04-26T07:20:30Z,we already have `numpartitionsfortopic`. could we reuse it?,0,0.9947581887245178
1177450105,13443,dajac,2023-04-26T07:23:08Z,nit: we usually put a space before and after the `:`.,0,0.9907179474830627
1177452306,13443,dajac,2023-04-26T07:25:12Z,nit: we can remove this empty line.,0,0.9824963808059692
1177466123,13443,dajac,2023-04-26T07:37:01Z,"i have a general comment about the comments in the code. i think that your comments are very useful to understand the logic. however, they are a bit spread all over the places. i wonder if it would be possible to re-group them a bit. for instance in this case, we could either have one comment for the entire block or one comment per branch. [code block] or [code block]",0,0.8519936800003052
1177506264,13443,dajac,2023-04-26T08:13:32Z,nit: `testoneconsumerwithnosubscribedtopics`?,0,0.9912444353103638
1177508192,13443,dajac,2023-04-26T08:15:02Z,indentation of the arguments seems to be off. it should be like this: [code block],0,0.9757131338119507
1177509263,13443,dajac,2023-04-26T08:15:56Z,"nit: it is usually better to use assertequals for collections as it gives more information when it fails. `assertequals(collections.emptymap(), groupassignment.members())`.",0,0.9940592050552368
1177510234,13443,dajac,2023-04-26T08:16:35Z,nit: `testoneconsumersubscribedtononexistenttopic`?,0,0.9931174516677856
1177511835,13443,dajac,2023-04-26T08:17:38Z,nit: the closing parenthesis of `assignmentmemberspec` should be on a new line and aligned with `new assignmentmemberspec`. the closing parenthesis of `singletonmap` should be aligned with `map `.,0,0.994297206401825
1177530072,13443,dajac,2023-04-26T08:29:30Z,"nit: this comment feels a bit weird here. i also wonder if this comment is necessary. the subscriptions are clear based on the specs. if you want to keep it, i would rather put it before `members` or you could also have one comment before each `members.put`.",-1,0.9689944386482239
1177541233,13443,dajac,2023-04-26T08:38:56Z,"as i told you offline, i am not a fan of this method. the main issue is that it does not really verify the co-partitioning. moreover, it does not verify the member ids. i am thinking about two alternatives: option 1: [code block] option 2: we could perhaps use a `treemap` instead of an `hashmap` for the members that we pass into the `assignmentspec`. the `treemap` guarantees the order so the algorithm may be deterministic with this. if it is, we could simply compute the expected `groupassignment` and use `assertequals`.",0,0.6965052485466003
1177543425,13443,dajac,2023-04-26T08:40:49Z,"this is a perfect example to illustrate my previous comment. in this case, `consumera` cannot get `topic3uuid` but we don't really verify this.",0,0.9567575454711914
1177545492,13443,dajac,2023-04-26T08:42:35Z,nit: here we could use my `mkassignment` helper method and inline the current assignment. the would reduce the boilerplate.,0,0.9918020367622375
1177546403,13443,dajac,2023-04-26T08:43:25Z,nit: indentation is off here.,0,0.7780041694641113
1177549003,13443,dajac,2023-04-26T08:45:28Z,nit: indentation is not correct here. there are a few other cases in this file.,-1,0.5843307375907898
1177550694,13443,dajac,2023-04-26T08:46:56Z,nit: this empty line could be removed.,0,0.985887348651886
1177553020,13443,dajac,2023-04-26T08:48:55Z,"in this case, the expected assignment seems to be deterministic so we could just use `assertequals`. this seems to be true for most of the `testreassignment` test cases.",0,0.9904623627662659
1177565215,13443,dajac,2023-04-26T08:58:36Z,should we add tests where we remove or add more than one members?,0,0.9918767213821411
1178059673,13443,rreddy-22,2023-04-26T15:37:31Z,"i got comments before to add tags and put the variable names, thats why i did it",0,0.9582522511482239
1179556594,13443,rreddy-22,2023-04-27T18:44:47Z,changing multiple subscriptions has similar effects as adding and removing consumers and that test exists so i didn't add another one.,0,0.9687899947166443
1179557943,13443,rreddy-22,2023-04-27T18:46:26Z,on it,0,0.906390905380249
1179746842,13443,rreddy-22,2023-04-27T22:26:20Z,changed,0,0.9270829558372498
1179749224,13443,rreddy-22,2023-04-27T22:28:52Z,"it was public in the client assignor so i kept it public, should i change it to private?",0,0.9911779761314392
1179787876,13443,rreddy-22,2023-04-27T23:13:05Z,regrouped as much as possible,0,0.9754018187522888
1179789140,13443,rreddy-22,2023-04-27T23:14:40Z,oh okay got it,0,0.5775450468063354
1179793263,13443,rreddy-22,2023-04-27T23:23:24Z,added them since during reassignment its not really clear what the old subscriptions were but i removed them wherever it wasn't required,0,0.9690232872962952
1179796793,13443,rreddy-22,2023-04-27T23:31:11Z,"this was my concern too which is why i had asked for advice and this was the best idea we had all come up with, but i like the treemap idea i'm gonna go ahead and do that",1,0.6191722750663757
1179797144,13443,rreddy-22,2023-04-27T23:31:54Z,i verified with print statements so there's no issue with the code however jic that was also a concern,0,0.9792391657829285
1179797402,13443,rreddy-22,2023-04-27T23:32:24Z,"i like the treemap idea, i wish we thought of this sooner :(",-1,0.9768873453140259
1179966618,13443,dajac,2023-04-28T06:10:02Z,ack. we can keep it as public.,0,0.8536781072616577
1179967228,13443,dajac,2023-04-28T06:10:57Z,i understand that the code is doing the right thing. what i meant is that the assertions would not catch all issues.,0,0.9750673770904541
1179968856,13443,dajac,2023-04-28T06:13:40Z,interesting... it is weird to have variable names in the description. plain english is much better than `memberspertopic`.,-1,0.9911611080169678
1179969167,13443,dajac,2023-04-28T06:14:13Z,"yeah, sorry for this. i only thought about it when i raised this comment.",-1,0.9925758838653564
1182715705,13443,rreddy-22,2023-05-02T15:32:13Z,changing it,0,0.9351381063461304
1188009097,13443,rreddy-22,2023-05-09T00:34:03Z,done,0,0.8974218964576721
1188009762,13443,rreddy-22,2023-05-09T00:35:53Z,i think for readability its fine to have currentassignment for b and then just pass it,0,0.8658562898635864
1188270445,13443,dajac,2023-05-09T07:55:42Z,"i still find the html hard to read mainly because it is hard to visually know what is part of the main list and what is part of the sub-list. i wonder if we could indent things better. for instance, we could format it as follow. this is just a suggestion, there may be other ways. [code block]",0,0.7375720739364624
1188270698,13443,dajac,2023-05-09T07:55:58Z,we could use an `int` here.,0,0.9933289289474487
1188271077,13443,dajac,2023-05-09T07:56:18Z,nit: `topicids` -> `topic ids`?,0,0.9938742518424988
1188272308,13443,dajac,2023-05-09T07:57:26Z,i was thinking about this one. this should never happen because the `targetassignmentbuilder` handle this. therefore i wonder if we should throw a `partitionassignorexception` error with the same error here. what do you think?,0,0.850432276725769
1188273956,13443,dajac,2023-05-09T07:58:59Z,"i have the same comment regarding the html here. moreover, let's remove those variables in the test and replace them with regular text.",0,0.9827806949615479
1188274698,13443,dajac,2023-05-09T07:59:38Z,nit: `step 1` alone reads weird. could we say `step 1: something...`?,-1,0.9772104620933533
1188278175,13443,dajac,2023-05-09T08:02:57Z,"nit: as `topicdata` is never reused, should we just define `numpartitionsfortopic` as `assignmentspec.topics().get(topicid).numpartitions()`?",0,0.9946585297584534
1188281712,13443,dajac,2023-05-09T08:06:21Z,this comment looks out of context here. would it make sense to have a comment which covers both `minrequiredquota` and `nummemberswithextrapartition` and explains all of this?,0,0.9926908612251282
1188283167,13443,dajac,2023-05-09T08:07:43Z,nit: let's add a small explanation here as well.,0,0.9777293801307678
1188283174,13443,rreddy-22,2023-05-09T08:07:43Z,all tests are checked with 1:1 mapping now so this is taken care of now,0,0.9878121018409729
1188284004,13443,rreddy-22,2023-05-09T08:08:27Z,plain english for everything?,0,0.9645066857337952
1188291620,13443,dajac,2023-05-09T08:15:42Z,"nit: i wonder if we should just remove this part of the comment or shorten it. the important part, i think, is that we retain at max the min require quota.",0,0.9523886442184448
1188300132,13443,dajac,2023-05-09T08:23:09Z,"i feel like there are too many comments here. could we try to simplify and to re-group them? for instance, we could structure it as follow: [code block]",0,0.7334736585617065
1188302467,13443,dajac,2023-05-09T08:25:15Z,nit: it would be good to explain why `ascending order` is required here.,0,0.9852439165115356
1188303243,13443,dajac,2023-05-09T08:26:00Z,nit: indentation should be 4 spaces in order to be consistent with how you did it previously. the same applies to l226.,0,0.9935877323150635
1188307585,13443,dajac,2023-05-09T08:29:55Z,"i am curious. is there a reason why you structured it like this? everywhere, we usually structure it as follow: [code block] this is more readable in my opinion.",0,0.7911154627799988
1188323433,13443,rreddy-22,2023-05-09T08:43:39Z,changed it thanks!,1,0.9619366526603699
1188374768,13443,dajac,2023-05-09T09:25:54Z,nit: we should also assert the size.,0,0.9916029572486877
1188375282,13443,dajac,2023-05-09T09:26:23Z,is this still useful now that we have `assertassignment`?,0,0.9944974780082703
1188378752,13443,dajac,2023-05-09T09:29:18Z,let's remove step 5 here and include it in step 4.,0,0.9928580522537231
1188385263,13443,dajac,2023-05-09T09:34:38Z,this is interesting. should we still create a member in this case but with an empty assignment?,0,0.5829117298126221
1188387610,13443,dajac,2023-05-09T09:36:26Z,nit: you can use `mkassignment` to replace those. there are other similar cases.,0,0.9917600750923157
1188811581,13443,rreddy-22,2023-05-09T15:51:39Z,"it takes away from the fact that its step one if we write everything in the same line, i wanted to draw attention to it",0,0.9485310912132263
1188817725,13443,rreddy-22,2023-05-09T15:56:30Z,i had it before and then i was told to remove it,0,0.9782975316047668
1188819218,13443,rreddy-22,2023-05-09T15:57:42Z,"this was fixed already, please see the new code, it says outdated on the top",0,0.9795504808425903
1188821039,13443,rreddy-22,2023-05-09T15:59:12Z,"i think its fine honestly, its different from step 4. if its too much in one step there isn't really much point in breaking it up right?",-1,0.487199068069458
1188821932,13443,rreddy-22,2023-05-09T15:59:57Z,that's what i asked and you had told me that either way is fine. i can change it to anything depending on how the rest of the code works,0,0.9652016162872314
1188823115,13443,rreddy-22,2023-05-09T16:00:55Z,we don't need it but we wanted separate property tests right?,0,0.9643800854682922
1188832049,13443,rreddy-22,2023-05-09T16:08:31Z,i just wanted to do it topic wise so its easier to understand but i'll change it,0,0.9607306122779846
1188856580,13443,dajac,2023-05-09T16:29:27Z,[code block] is also fine. my point is that `step 1` alone is weird.,-1,0.9343753457069397
1188857767,13443,dajac,2023-05-09T16:30:29Z,"interesting... i feel like this part is more important than all the rest, no?",0,0.535392701625824
1188857900,13443,dajac,2023-05-09T16:30:36Z,ack.,0,0.5038502812385559
1188858930,13443,dajac,2023-05-09T16:31:36Z,"yeah, it was because we were not able to use equals. now that we can use it, i am not sure that this one bring any value. does it?",0,0.8580488562583923
1188873259,13443,dajac,2023-05-09T16:43:17Z,"yeah, that's right. it does not matter from the targetassignmentbuilder perspective. we can keep it as it is.",0,0.9452577829360962
1188891203,13443,rreddy-22,2023-05-09T16:59:51Z,done.,0,0.9640594124794006
1188891494,13443,dajac,2023-05-09T17:00:11Z,i think that it is better to have one comment for the entire block of code. it makes reading it easier.,0,0.9517609477043152
1188893117,13443,dajac,2023-05-09T17:01:47Z,nit: indentation is still inconsistent here.,-1,0.7348503470420837
1188893187,13443,dajac,2023-05-09T17:01:51Z,nit: indentation is still inconsistent here.,-1,0.7348503470420837
1188893478,13443,dajac,2023-05-09T17:02:07Z,nit: ` : `.,-1,0.8052791953086853
1188898373,13443,dajac,2023-05-09T17:06:58Z,`currentsize` does not exist any more. this is why i don't like to use variable names in comments :),1,0.874596118927002
1189210485,13443,rreddy-22,2023-05-09T23:13:29Z,"it looks a bit wonky after formatting it like that, i don't think there's a great way to add this html",-1,0.9804243445396423
1189212267,13443,rreddy-22,2023-05-09T23:17:31Z,i did it in a way that looks best to me in the next commit,0,0.9864627718925476
1189213049,13443,rreddy-22,2023-05-09T23:19:18Z,"nop we can remove it, ig whoever wants it later can write it again",0,0.9271215796470642
1189214614,13443,rreddy-22,2023-05-09T23:23:00Z,okayyy,0,0.7918105721473694
1189216148,13443,rreddy-22,2023-05-09T23:26:11Z,sorry,-1,0.9823289513587952
1189216494,13443,rreddy-22,2023-05-09T23:26:54Z,sorry fixed,-1,0.99104905128479
1189229522,13443,rreddy-22,2023-05-09T23:57:16Z,i got comments saying don't repeat something that's already been mentioned before so i'm pretty sure i had something there and then removed it,0,0.9355044960975647
1189229707,13443,rreddy-22,2023-05-09T23:57:46Z,its already in the java doc step by step so that is merely there to make sure people understand which step we're talking about,0,0.9872689247131348
1189229928,13443,rreddy-22,2023-05-09T23:58:14Z,sure,0,0.9137381911277771
1189231170,13443,rreddy-22,2023-05-10T00:01:09Z,"i removed it, its not that necessary, i just wanted people to have more information on things that i personally got confused about",-1,0.8124364614486694
1189231412,13443,rreddy-22,2023-05-10T00:01:40Z,"same explanation as before, i was told not to repeat things that have already been mentioned :(",-1,0.9918497800827026
1189231570,13443,rreddy-22,2023-05-10T00:01:58Z,i removed it,0,0.9447202086448669
1189235728,13443,rreddy-22,2023-05-10T00:11:46Z,okay i wont use variable names again,0,0.9177656769752502
1189237663,13443,rreddy-22,2023-05-10T00:16:32Z,thats how it was before and i was told to change it,0,0.9663457870483398
1189295560,13443,dajac,2023-05-10T02:31:46Z,ok. i was not aware of this.,-1,0.6477351784706116
1189296233,13443,dajac,2023-05-10T02:32:48Z,i understand. it was just misplaced in my opinion.,0,0.9094576239585876
1189296779,13443,dajac,2023-05-10T02:33:30Z,ok. i was not aware of this. sorry for this.,-1,0.9933894872665405
1189296913,13443,dajac,2023-05-10T02:33:41Z,ack.,0,0.5038502812385559
1189297499,13443,dajac,2023-05-10T02:34:49Z,"looks good, thanks.",1,0.9901825785636902
281150684,6592,miguno,2019-05-06T11:43:38Z,doesn't guard against npe (`data` might be null).,0,0.979468584060669
281151355,6592,miguno,2019-05-06T11:45:36Z,why isn't there an additional constructor with a default `comparator`?,0,0.9918922185897827
281152067,6592,miguno,2019-05-06T11:47:38Z,"also, why does the serde need a `comparator` at all?",0,0.9944362640380859
281263059,6592,miguno,2019-05-06T16:41:25Z,we should use try-with-resources here (for `datainputstream`).,0,0.9926620721817017
281263464,6592,miguno,2019-05-06T16:42:38Z,we should use try-with-resources here (for `bytearrayoutputstream` and `datainputstream`).,0,0.9932079911231995
281263644,6592,miguno,2019-05-06T16:43:05Z,"this also fixes the problem that, in the current code, the `bytearrayoutputstream` was not closed.",0,0.9918220639228821
281264102,6592,miguno,2019-05-06T16:44:24Z,asking because neither a `list ` nor a `deserializer ` need a `comparator`.,0,0.9918912649154663
281285669,6592,yeralin,2019-05-06T17:43:15Z,put it on a discussion: [a link] thank you for your input! i highly appreciate it :),1,0.9958611130714417
287207631,6592,mjsax,2019-05-24T03:52:15Z,i think we should call `deserializer.configure(...)` here,0,0.9901099801063538
287207698,6592,mjsax,2019-05-24T03:52:47Z,i think we should call `deserializer.close()` here,0,0.9885110855102539
287208093,6592,mjsax,2019-05-24T03:56:00Z,should we get the `size` first and pass it into `arraylist` constructor to make it more efficient?,0,0.9942111372947693
287208576,6592,mjsax,2019-05-24T04:00:08Z,forward call to `serializer`,0,0.9883381724357605
287460369,6592,yeralin,2019-05-24T17:55:17Z,is it sufficient for testing listserde?,0,0.993367612361908
287470423,6592,mjsax,2019-05-24T18:26:10Z,"we should also test `null` and empty array imho. please, add new test methods for both cases.",0,0.9929335117340088
296436321,6592,mjsax,2019-06-22T06:33:31Z,"as mentioned on the kip discussion, `bytesdeserializer` should not be included.",0,0.99504554271698
296436331,6592,mjsax,2019-06-22T06:34:22Z,i using `stream.of` the best was to populate the map? seems to be unnecessarily complex to me?,0,0.7204915285110474
296436380,6592,mjsax,2019-06-22T06:37:34Z,"i would add test for all primitive types. the test should also check the expected `byte[]` array size after serialization and test a ""round trip"". we should also have a test for non-primitive type round-trip. lastly, i would add a test for deserializing different list-types. also `null` corer case should be tested.",0,0.9927655458450317
303481813,6592,yeralin,2019-07-15T14:59:13Z,replaced it with simpler approach: [code block],0,0.989387035369873
304072719,6592,yeralin,2019-07-16T19:04:30Z,where should i place all of these new test cases? should i create a new class?,0,0.9913963675498962
307013332,6592,mjsax,2019-07-24T20:46:22Z,add new test methods to this test should be sufficient.,0,0.9876292943954468
307015039,6592,mjsax,2019-07-24T20:50:28Z,both `_doc` variables should me moved to `commonclientconfigs`,0,0.9947465062141418
307015480,6592,mjsax,2019-07-24T20:51:21Z,nit: remove whitespace before `default` (similar for the other 3 `_doc` strings),0,0.9932792782783508
307016006,6592,mjsax,2019-07-24T20:52:38Z,"why `or default_list_value_serde_inner_class` ? for the key, we only care about the key part. (similar below for value -- we should only care about the value part.)",0,0.9942982792854309
307016504,6592,mjsax,2019-07-24T20:53:53Z,we should explain that this config is only used if `key.deserializer` is set to `listdeserializer`. similar for the type config below.,0,0.9944084286689758
307016893,6592,mjsax,2019-07-24T20:54:47Z,the class does not implement `deserializer` but `list`.,0,0.9893103837966919
307017972,6592,mjsax,2019-07-24T20:57:33Z,can we actually include uuid type? it always 16 bytes.,0,0.9934161901473999
307018186,6592,mjsax,2019-07-24T20:58:04Z,nit: maybe call this `fixedlengthdeserializers` -- it's not about primitive types.,0,0.9864869117736816
307026623,6592,abbccdda,2019-07-24T21:20:06Z,"avoid star import, same for the rest",0,0.9845440983772278
307036896,6592,mjsax,2019-07-24T21:50:20Z,both new configs should be added below: [code block] similar for `producerconfig` and `streamsconfig`,0,0.993766188621521
307037138,6592,mjsax,2019-07-24T21:51:10Z,"i think this could be `string` or `class` type. not sure. for any case, we should test for both cases.",0,0.9086868166923523
307037211,6592,mjsax,2019-07-24T21:51:24Z,same here,0,0.9628711938858032
307037543,6592,mjsax,2019-07-24T21:52:22Z,should we have two try-catch blocks? one for `listclass` and one for `inner` ?,0,0.9944604635238647
307037605,6592,mjsax,2019-07-24T21:52:35Z,nit: remove `this` (not required),0,0.9923685193061829
307037957,6592,mjsax,2019-07-24T21:53:41Z,how do we know that all list types implement a constructor like this? should we have a fall back to default constructor?,0,0.9928215146064758
307038250,6592,mjsax,2019-07-24T21:54:41Z,rename similar to listdeserializer and add uuid type?,0,0.9947614073753357
307038415,6592,mjsax,2019-07-24T21:55:13Z,rename? why not use `boolean`?,0,0.9923282265663147
307038590,6592,mjsax,2019-07-24T21:55:50Z,this could also be `class` type?,0,0.9931461811065674
307296391,6592,yeralin,2019-07-25T13:31:34Z,"fixed, had to change my intellij config.",0,0.9639352560043335
307302882,6592,miguno,2019-07-25T13:44:40Z,"why is the `bytearrayoutputstream` not covered by try-with-resources? it should, no?",0,0.9889498353004456
307305083,6592,miguno,2019-07-25T13:48:24Z,"shouldn't we also add `bytesserializer` and `bytearrayserializer` here? same question for deserialization. edit: i did notice that we do some ""testing for primitives"" by doing `contains()` on `primitiveserializers`. +1 to also adding uuid serializer (and deserializer).",0,0.9229707717895508
307308603,6592,miguno,2019-07-25T13:55:01Z,"why is this needed only for non-primitives, and not always?",0,0.9763054847717285
307309387,6592,yeralin,2019-07-25T13:56:31Z,i guess smth like this: [code block],0,0.9841879606246948
307309648,6592,miguno,2019-07-25T13:57:02Z,"i think the list serde should return null (after a round trip) if and only if the input was null. if the input was an empty list, then the list serde should instead return an empty list. that is, i believe the serde needs to distinguish between the absence of a collection (indicated by null) and a collection that happens to be empty.",0,0.989213764667511
307311596,6592,yeralin,2019-07-25T14:00:36Z,changed to boolean primitive. what do you think is the best name for it instead of `isprimitive`? `isfixedlength` maybe?,0,0.99094557762146
307312643,6592,yeralin,2019-07-25T14:02:48Z,i was following impl of `sessionwindowedserializer`,0,0.9893468022346497
307316124,6592,yeralin,2019-07-25T14:09:34Z,mentioned during the kip discussion: [code block] i'll add uuid (de)serializers,0,0.9882579445838928
307320943,6592,yeralin,2019-07-25T14:19:01Z,you mean we can directly cast it to `class` object? i.e. `class listtype = (class) configs.get(listtypepropertyname);`,0,0.9943886399269104
307321201,6592,yeralin,2019-07-25T14:19:28Z,i was following impl of `sessionwindoweddeserializer`,0,0.9901186227798462
307322886,6592,yeralin,2019-07-25T14:22:49Z,"yes, i think it will make errors more descriptive",0,0.89049232006073
307323343,6592,yeralin,2019-07-25T14:23:38Z,probably add a warning log? what do you think?,0,0.9879165887832642
307326098,6592,yeralin,2019-07-25T14:28:36Z,"if i understand your question correctly: this was an optimization feature. if we have a collection of fixed length elements like `integer`, `long`, `uuid`, etc. we don't actually need to encode each element's size. that's why i have this extra if statement. if that's what you were asking",0,0.9218714237213135
307329101,6592,yeralin,2019-07-25T14:33:43Z,smth like: [code block],0,0.9904369711875916
307332736,6592,yeralin,2019-07-25T14:40:14Z,what `importance` should these configs be set to?,0,0.9938357472419739
307336073,6592,yeralin,2019-07-25T14:46:23Z,"should i add `doc`s for `default_list_key/value_serde_inner_class` configs? i was looking at `default_windowed_key/value_serde_inner_class` configs in `streamsconfig` class, and they don't have docs underneath them.",0,0.9935091137886047
307429344,6592,mjsax,2019-07-25T18:03:55Z,yes,0,0.9659429788589478
307429932,6592,mjsax,2019-07-25T18:05:13Z,i think low (or maybe medium) because it's dependent config,0,0.9606491327285767
307431168,6592,mjsax,2019-07-25T18:08:12Z,"yes. the user can use the config two ways: [code block] both should be supported and the code need to be able to handle both cases. hence, we should get is as `object` and use `instanceof` to check the type.",0,0.9928079843521118
307432566,6592,mjsax,2019-07-25T18:11:21Z,this may indicate a bug in `sessionwindoweddeserializer`,0,0.9938435554504395
307433215,6592,mjsax,2019-07-25T18:12:50Z,don't think we need a warning. wondering if we should use try-catch or better pro-actively check if an int-constructor exists?,0,0.7102757096290588
307433392,6592,mjsax,2019-07-25T18:13:16Z,sgtm,0,0.9109601974487305
307433534,6592,mjsax,2019-07-25T18:13:36Z,seems like a bug in `sessionwindowedserializer`,0,0.9696136713027954
307434421,6592,mjsax,2019-07-25T18:15:42Z,"sound like something we should fix, ie, add corresponding doc entries to `streamsconfig`",0,0.9934911131858826
307444815,6592,yeralin,2019-07-25T18:39:33Z,"yep, i think medium is more appropriate since it is a interconnected config scheme",0,0.9094403982162476
307448021,6592,yeralin,2019-07-25T18:47:13Z,something like this i presume: [code block],0,0.9854178428649902
307448892,6592,yeralin,2019-07-25T18:49:17Z,"we kind of implicitly check if int-constructor exists using this try-catch block, right?",0,0.9911553859710693
307464495,6592,yeralin,2019-07-25T19:28:42Z,"ok i added the following tests: `listserdeshouldroundtripprimitiveinput(): arrays.aslist(1, 2, 3)` `listserdeshouldrountripnonprimitiveinput(): arrays.aslist(""a"", ""b"", ""c"")` `listserdeshouldreturnemptycollection(): arrays.aslist()` `listserdeshouldreturnnull(): null` `listserdeserializershouldreturnbytearrayofsize(): arrays.aslist(1, 2, 3) => 16` `listserdeshouldreturnlinkedlist() new linkedlist<>()` `listserdeshouldreturnstack() new stack<>()` i think i covered it all. btw you said *all primitive types*, you mean all 6 of them, right?",0,0.9922186136245728
309339359,6592,mjsax,2019-07-31T17:22:07Z,seems this variable is still misssing the corresponding doc string? (same for `default_list_value_serde_inner_class` below),0,0.993890643119812
309341518,6592,mjsax,2019-07-31T17:26:44Z,"we should point out, that this config is only affective iff `key.deserializer` is set to `listdeserializer`.",0,0.992554247379303
309342714,6592,mjsax,2019-07-31T17:29:33Z,"seems you still did not add the config to the static `config` variable below. (this must be done for consumerconfig, producerconfig, and streamsconfig)",0,0.9948624968528748
309344282,6592,mjsax,2019-07-31T17:33:18Z,"not: remove space before `"" default...""` also, this variable should be moved to `commonclientconfigs` imho. (same commend for value below.)",0,0.9913354516029358
309344677,6592,mjsax,2019-07-31T17:34:24Z,this comment is not addressed yet,0,0.9662889838218689
310367315,6592,mjsax,2019-08-04T01:40:26Z,"`note when list serde class is used` -> seems be a little fuzzy if one does not know the context. it might be better to be very explicit. what about: [code block] we should be similarly explicit, for the ""inner serde"" configs.",0,0.9824880957603455
310367323,6592,mjsax,2019-08-04T01:41:02Z,avoid unnecessary reorderings (this class does not contain any actual code change).,0,0.9814122915267944
310367328,6592,mjsax,2019-08-04T01:41:34Z,as above (similar for other files below).,0,0.990455687046051
310367336,6592,mjsax,2019-08-04T01:42:10Z,nit: fix indention and align to existing code,0,0.9893710613250732
310367353,6592,mjsax,2019-08-04T01:43:38Z,should be type `class` (similar below); cf. `key_deserializer_class_config`,0,0.9952104687690735
310367365,6592,mjsax,2019-08-04T01:44:10Z,as above: `class` and fix indention,0,0.9876865744590759
310618942,6592,yeralin,2019-08-05T14:00:08Z,"`default_key_serde_class_config` is not accessible from `comminclientconfigs` since it lives in `streamsconfig`, the same applies for `listserde.class.getname()`",0,0.9954498410224915
329244889,6592,mjsax,2019-09-27T20:45:58Z,"should this be `map , integer>` ? seem we should declare it as `static` ?",0,0.9940741658210754
329245133,6592,mjsax,2019-09-27T20:46:40Z,should it be `class listclass` ? (or `class ` if we don't introduce `l`),0,0.9950297474861145
329249087,6592,mjsax,2019-09-27T20:58:26Z,"i am wondering, if we should get the `list` type as generic (not sure). `public class listdeseializer , t> implements deserializer `",0,0.9830211400985718
329250304,6592,mjsax,2019-09-27T21:02:21Z,should this be `class >` (or maybe `class ` if we introduce `l extends list ` as class generic?,0,0.9952263832092285
329250920,6592,mjsax,2019-09-27T21:04:18Z,we should limit this suppression to the method for which we really need it instead of the whole class,0,0.9889602661132812
329251104,6592,mjsax,2019-09-27T21:04:55Z,`constructor >` (or `constructor ` if we introduce `l`),0,0.9927347898483276
329251296,6592,mjsax,2019-09-27T21:05:33Z,update return type to `l` (if we introduce `l`),0,0.991563081741333
329251591,6592,mjsax,2019-09-27T21:06:32Z,update return type to `l` (if we introduce `l`),0,0.991563081741333
329251673,6592,mjsax,2019-09-27T21:06:45Z,update return type to `l` (if we introduce `l`),0,0.991563081741333
329252615,6592,mjsax,2019-09-27T21:10:07Z,avoid global suppress,0,0.9542028307914734
329253153,6592,mjsax,2019-09-27T21:12:14Z,`list >` should be `static`,0,0.9931117296218872
329253861,6592,mjsax,2019-09-27T21:14:49Z,`class ` (or just `class `?),0,0.992694616317749
329254244,6592,mjsax,2019-09-27T21:16:20Z,"should we change to `listserde , t> extends wrapperserde >` (cf. `listdeserializer` comments) note: we should not use `wrappedserde ` because the wrapper `serializer` uses `list ` but not `l` (not sure if we want to tie the serializer type to a fixed list type, but i guess we should not).",0,0.9944243431091309
329254510,6592,mjsax,2019-09-27T21:17:21Z,add missing `<>` to `new listserializer<>(...)`,0,0.9930413961410522
329255698,6592,mjsax,2019-09-27T21:21:49Z,"if we fix the generics, we don't need this suppress",0,0.9785056114196777
340187181,6592,vvcephei,2019-10-29T16:29:06Z,"it's better to avoid ""double-brace initialization"", which is actually declaring a new anonymous subclass of hashmap just to add some stuff to it in one statement. a little while back, i added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.utils#mkmap`, and the accompanying `org.apache.kafka.common.utils.utils#mkentry`.",0,0.9855044484138489
340190515,6592,vvcephei,2019-10-29T16:34:53Z,"this shouldn't be necessary. i believe the config parser will coerce the value to the type you declared the configuration as, `type.class`. might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.",0,0.9866471290588379
340191653,6592,vvcephei,2019-10-29T16:36:58Z,"that class is different because it doesn't actually `define` the config, it's just an undeclared ""extra"" config that gets passed around to be interpreted inside the serde. actually, this _is_ a bug, and that config _should_ be `define`d there the way you do it here.",0,0.9605243802070618
340192387,6592,vvcephei,2019-10-29T16:38:20Z,"+1, just add this suppression on the methods that need it.",0,0.9741668105125427
340237949,6592,vvcephei,2019-10-29T17:58:44Z,"these new tests look good. i agree, though, that we should test round trip + length for each of the primitive types (short, integer, long, float, double, and uuid). just because it would be easy to mess up just one of them, so we really should have test coverage for them all.",0,0.7575486898422241
342316240,6592,mjsax,2019-11-04T23:10:31Z,should we add a similar sentence like `this configuration will be read if....` to `commonclientconfigs#default_list_key_serde_inner_class_doc ` (similar for value) ?,0,0.9948101043701172
342320732,6592,mjsax,2019-11-04T23:27:37Z,nit: merge both lines: `byte[] payload = new byte[primitivesize == null ? dis.readint() : primitivesize];`,0,0.9939674139022827
342321230,6592,mjsax,2019-11-04T23:29:29Z,nit: indentation should be 4 spaces?,0,0.9566012024879456
342321277,6592,mjsax,2019-11-04T23:29:38Z,nit: indentation should be 4 spaces?,0,0.9566012024879456
342326150,6592,mjsax,2019-11-04T23:48:49Z,nit: move this class definition to l127 (after `static public final class uuidserde extends wrapperserde {`) to group all defined serde classes.,0,0.9952104687690735
342326188,6592,mjsax,2019-11-04T23:48:58Z,can be removed (if we change the class to `extends wrapperserde `),0,0.9954167604446411
342326296,6592,mjsax,2019-11-04T23:49:23Z,the cast to `(deserializer >)` is not necessary if we change the class to `extends wrapperserde `.,0,0.9952168464660645
342326601,6592,mjsax,2019-11-04T23:50:40Z,nit: add those into section `// medium` and insert in alphabetical order within the section,0,0.9924421310424805
342337097,6592,mjsax,2019-11-05T00:35:31Z,nit: this method should be after static method `static public serde void() {` to keep stuff grouped,0,0.9906870722770691
342345719,6592,mjsax,2019-11-05T01:14:54Z,"i was playing with the code a little bit, and turns out using `class ` instead of `class ` might actually be too strict. compare my other comments.",-1,0.5230319499969482
342345818,6592,mjsax,2019-11-05T01:15:29Z,not 100% sure -- but we need tests for this cases. the `configure()` code is untested atm,0,0.9773880839347839
342346108,6592,mjsax,2019-11-05T01:17:14Z,we could change the signature to [code block] to make it type safe... but there are issue (i also mentioned this for `listdeserializer` above -- also compare my comment below),0,0.9910504817962646
342346253,6592,mjsax,2019-11-05T01:17:59Z,"also could make types mores strict via `extends wrapperserde ` again, as mentioned above, not sure if this might be too strict.",0,0.9836075901985168
355461955,6592,JakobEdding,2019-12-09T13:56:55Z,"typo, `deerializer`",0,0.9932150840759277
364943202,6592,zorgz,2020-01-09T20:23:31Z,inner.serialize() can return null here in case of the list entry is null for example then npe will follow at [a link],0,0.9914233088493347
364993597,6592,yeralin,2020-01-09T22:35:10Z,"hmmm that's an interesting edge case. i cannot just return null since a list might contain real values i.e. `list data = {'a', null, 'c'}` i have to serialize `null` somehow...",0,0.8533819317817688
365021029,6592,zorgz,2020-01-10T00:13:25Z,i get it with abstractkafkaavroserializer and my custom array serde abstractkafkaavroserializer code: [code block],0,0.9837575554847717
368185579,6592,mjsax,2020-01-18T00:13:59Z,nit: should be `deserializer ` to avoid warnings about using a raw type,0,0.989840030670166
368185717,6592,mjsax,2020-01-18T00:14:55Z,nit: should be ` >` to avoid warning about using a raw type,0,0.9808792471885681
368186003,6592,mjsax,2020-01-18T00:16:30Z,nit: should be `class >` (2 times) -- (not `serde` compare comment above) and we want to avoid warning about using a raw type also `innerserde -> innerdeserializerclass`,0,0.9934996366500854
368187510,6592,mjsax,2020-01-18T00:25:38Z,"this is `listdeserializer` hence, shouldn't we use `consumerconfig.list_key_deserializer_inner_class_config` ? the ""serde"" config should be used in kafka streams codebase only? (same for value, and for both inner types in the next line).",0,0.9946966171264648
368188170,6592,mjsax,2020-01-18T00:29:56Z,nit: should be `serializer ` to avoid warnings about using a raw type,0,0.985797107219696
368188407,6592,mjsax,2020-01-18T00:31:15Z,"as above: use `producerconfg.list_key_serializer_inner_class_config` instead of ""serde"" config parameters (2 times) also `innerserdepropertyname -> innerserializerpropertyname`",0,0.9948837161064148
368188720,6592,mjsax,2020-01-18T00:33:05Z,nit: `innerserdepropertyname -> innerdeserializerpropertyname`,0,0.9937791228294373
368189063,6592,mjsax,2020-01-18T00:35:29Z,nit: `innerserde -> innerserializerclassorname`,0,0.9937471151351929
368189160,6592,mjsax,2020-01-18T00:36:10Z,should be: [code block],0,0.992592990398407
368189561,6592,mjsax,2020-01-18T00:38:33Z,should be: [code block],0,0.992592990398407
368189677,6592,mjsax,2020-01-18T00:39:28Z,"`""serde class ""` -> `""serializer class ""`",0,0.990312933921814
368191352,6592,mjsax,2020-01-18T00:51:39Z,"that is a tricky question. there are multiple ways how we could encode this, but this seem to be a design question that required to go back to the kip discussion? for example, we could skip the optimization of fixed-length types and encode the length for every entry -- a length of `-1` would indicate a `null`. or we introduce a ""header"" that tells us if there are `null` in the list (either a bit-array for short list or a ""list of null positions"") example for list of null positions would be: ` ` ie, with the example for above, we encode `1-1- - `. as bit array, it would be ` ` ie, with the example for above, we encode `1-0100000- - `",0,0.9738335609436035
368191525,6592,mjsax,2020-01-18T00:53:02Z,should be ` >` to avoid raw type warning and make build pass,0,0.993498682975769
368191582,6592,mjsax,2020-01-18T00:53:30Z,"should be ` , inner>` to avoid raw type warning and make build pass",0,0.9943464398384094
368191860,6592,mjsax,2020-01-18T00:55:56Z,"i am wondering now, why we actually need `commonclientconfigs.default_list_key_serde_inner_class` (maybe there was a reason by i forgot) -- can't we add the ""serde"" configs only to `streamsconfig`?",0,0.9796081781387329
369420107,6592,mjsax,2020-01-22T08:21:25Z,"thinking about it once more, it might not work what i suggested, because if you want to call `serde.listserde(arraylist.class, ...)` the `arraylist` does not specify any inner type information (but is a raw type) and thus it won't compile. i guess, we need to leave it as-is, and suppress the ""raw type"" warning (might be worth to add a comment why the raw type warning cannot be avoided for this case).",0,0.9705377221107483
369420640,6592,mjsax,2020-01-22T08:22:46Z,"same as below -- i guess my suggestion does not work in practice (it's correct that it would avoid the raw type warning, but it would make the api unusable in practise because we want to be able to pass in raw type list classes).",0,0.9828921556472778
370513438,6592,mjsax,2020-01-24T08:15:57Z,"i was thinking about this case more. i really think, that the fix-length optimization is valuable as it reduced the serialized byte size by 50% for e.g. integer lists. for the other two proposals, it's harder to judge which one is better. i see the following (dis)advantages for each: null-index-list: - low overhead for dense lists with few nulls (for zero nulls, its 4 byte overhead, for each null, its additional 4 bytes) - the longer the lists, the smaller the overhead bit-array: - low overhead for short lists (4 bytes for byte array length + list-lenght/8 bytes for the byte-array itself) - not ideal for long lists with few nulls hence, for short list both might be equally ok. for long lists, it depends of they are dense or sparse (for long-dense list, null-index-list seems to be better, for long-sparse-lists, bit-array seems to be better). it will be hard to tell which one is better, hence, i would suggest that we only implement the null-index-list list for now, because i assume that dense lists are more common and it works better for long dense lists than the bit-array idea. however, to allow us to support different serialization format in the future, we should add one more magic byte in the very beginning that encodes the choose serialization format. in our case, we will will have one format and the magic byte will always be ""zero"". if we add the byte-array format, we can just set the magic byte to one to indicate the other format. and we could even add more formats of people have a better idea how to do it later on. btw: we could actually already go with two formats: - 0 => optimized-fixed-length-encoding plus null-index-list - 1 => variable length encoding using `-1` in the length field to indicate `null` (no header to mark nulls is required at all for this case). if we agree on this design, we should update the kip accordingly. \cc : would love to hear your feedback, too.",0,0.9239575862884521
371434275,6592,yeralin,2020-01-27T19:23:57Z,"thank you for your input your outline makes sense, i like the idea of `null-index-list`, and i'm happy to jump back to the kip. however, could we please wrap up this round of review? make sure that all generics, docs, tests are in place. once it is clean and polished, i can start updating the kip and implementing this new feature. what do you think? p.s. rebased the branch with latest `trunk` and pushed another commit with review changes",1,0.9921196699142456
372120739,6592,mjsax,2020-01-28T23:41:43Z,"can be simplified to `(""unchecked"")`",0,0.9934172630310059
372121895,6592,mjsax,2020-01-28T23:45:47Z,`innerdeserializer` could be null; we should handle to case to avoid a npe calling `getclass()`,0,0.9935519695281982
372123553,6592,mjsax,2020-01-28T23:51:31Z,"there a two independent configs for the list-type and inner-type, hence it might be better to handle both independently: [code block]",0,0.9941174983978271
372123738,6592,mjsax,2020-01-28T23:52:12Z,as above; simplify,0,0.9822710156440735
372125306,6592,mjsax,2020-01-28T23:57:44Z,use `kafkaexception` instead of `runtimeexception`,0,0.9941617846488953
372125767,6592,mjsax,2020-01-28T23:59:23Z,in `utils.newinstance()` we catch exceptions more fine grained -- might be worth to do the same here?,0,0.9922067523002625
372126337,6592,mjsax,2020-01-29T00:01:19Z,use `kafkaexception` instead of `runtimeexception`,0,0.9941617846488953
372126509,6592,mjsax,2020-01-29T00:01:57Z,as above,0,0.9391705989837646
372126925,6592,mjsax,2020-01-29T00:03:37Z,"should we throw `kafkaexception` instead? also, we need to add an error message that clarifies which class was not found.",0,0.9936456680297852
372128389,6592,mjsax,2020-01-29T00:08:53Z,as above: `serializer` could be `null` and we should handle this case gracefully,0,0.9932259917259216
372128852,6592,mjsax,2020-01-29T00:10:43Z,maybe add a `null` check and throw `configexception` with detailed error message similar to the `null`-check for `listclass` in the `listdeserializer#configure(...)`? i think `instanceof` would be false for `null` and thus the `null` check within `utils.newinstance(...)` would not be executed.,0,0.9950156807899475
372129532,6592,mjsax,2020-01-29T00:13:33Z,use `kafkaexception` instead of `runtimeexception`,0,0.9941617846488953
372129790,6592,mjsax,2020-01-29T00:14:31Z,we should add a `null` check to allow closing a deserializer that was not properly setup,0,0.9944506883621216
372129838,6592,mjsax,2020-01-29T00:14:42Z,we should add a `null` check to allow closing a serializer that was not properly setup,0,0.9943645000457764
372131801,6592,mjsax,2020-01-29T00:22:12Z,`serializer` -> `serde`,0,0.9914708733558655
372131842,6592,mjsax,2020-01-29T00:22:22Z,`serializer` -> `serde`,0,0.9914708733558655
372131861,6592,mjsax,2020-01-29T00:22:27Z,`serializer` -> `serde`,0,0.9914708733558655
372132594,6592,mjsax,2020-01-29T00:25:25Z,this method is hard to read... can we format it differently? (maybe a empty line before `return...` is sufficient?),0,0.6276004314422607
378457483,6592,yeralin,2020-02-12T19:14:33Z,"`catch (instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception e)` kind of long, but i agree for it to be more fine grained",0,0.9740573167800903
453892518,6592,yeralin,2020-07-13T19:50:12Z,make sure that the serialization flag is known to the application.,0,0.9903934597969055
453892850,6592,yeralin,2020-07-13T19:50:48Z,it's probably better to wrap it into `if/else` construct instead.,0,0.9933472871780396
453893460,6592,yeralin,2020-07-13T19:52:01Z,"by default, if we are dealing with a list of primitives, we are using `serializationstrategy.null_index_list` vs. a list of non-primitives (`uuid`, `string`, or some custom object) `serializationstrategy.negative_size`.",0,0.993282675743103
453894509,6592,yeralin,2020-07-13T19:54:14Z,"this is what i was talking about in [a link] even if we are dealing with primitives, and a user chooses `serializationstrategy.negative_size`, we would have to encode each primitive's size in our payload.",0,0.9920856356620789
453894647,6592,yeralin,2020-07-13T19:54:32Z,should it be parametrized?,0,0.9926912188529968
613642681,6592,ableegoldman,2021-04-14T23:09:28Z,"just wondering, what is the reason for this change?",0,0.877322256565094
613647496,6592,ableegoldman,2021-04-14T23:23:03Z,"should it be valid for this to be null? i would think that these serdes should be configured either by instantiating it directly via this constructor, or via the default constructor + setting configs (eg list.key.serializer.inner). it doesn't seem to make sense to use this constructor and not pass in valid arguments. wdyt about throwing an exception if either parameter is `null` -- not sure if configexception or illegalargumentexception is more appropriate, up to you",0,0.8919413685798645
613648141,6592,ableegoldman,2021-04-14T23:24:53Z,nit: use `private static` ordering (for consistency with the rest of the code base),0,0.9941872358322144
613649139,6592,ableegoldman,2021-04-14T23:27:36Z,"if the `listclass` and `inner` have already been set by invoking the non-default constructor, but the user also set the `list.key.deserializer.inner` configs, should we verify that the configs match and throw a configexception otherwise?",0,0.9947432279586792
613651922,6592,ableegoldman,2021-04-14T23:36:10Z,what about the `list_key_deserializer_inner_class_config`?,0,0.993948221206665
613657189,6592,ableegoldman,2021-04-14T23:52:12Z,"hey, sorry that i'm jumping in here after there's been a long discussion which i missed, but i'm wondering why the serialization strategy would be configurable? iiuc the serialization strategy correctly, one of them basically means ""constant-size data/primitive type, don't encode the size only length of list"" while the other means ""variable-size data, encode the size of each element only"" i assume this is to allow users to indicate that their data is constant size when its a non-primitize type, to avoid the need to encode this same size data -- that makes sense to me. but i think we can simplify the api a bit so we don't have to let users shoot themselves in the foot, as you said earlier :slightly_smiling_face: how about: if it's a primitive type, and we can detect this (i think we should be able to), then we never encode the size info. if a user opts to do so, just log a warning and ignore it. by the way, this might also be due to some earlier discussion i missed, but i find the names of the two serializationstrategy enums super confusing. how about just `variable_size` and `constant_size`? imo it's better to describe what the enum actually _means_ than how its implemented, you can read the code to understand the latter. but you shouldn't need to read the code to understand what a config means. plus, this way we have flexibility to change the underlying implementation if we ever need to without also having to change the enum names which are now a public api",-1,0.9711370468139648
613658493,6592,ableegoldman,2021-04-14T23:56:23Z,"what is this? can you give it a name that describes what it means a little more -- iiuc this is a sentinel that indicates ""this list has variable-sized elements so we encode each element's size"". that said, coming up with names is hard -- you can probably do a better job than me but just to throw out a suggestion, what about something like `variable_size_sentinel`?",0,0.9072294235229492
613658799,6592,ableegoldman,2021-04-14T23:57:19Z,"nit: can we use `double.size` instead of just `8`, that way it's super clear that this value actually means?",0,0.9898430705070496
614950753,6592,yeralin,2021-04-16T15:54:30Z,hmmm `double.size` returns 64: [code block],0,0.9866743683815002
614954404,6592,yeralin,2021-04-16T15:59:41Z,otherwise the build will fail with: [code block] was addressed in [a link],0,0.9886674284934998
615005374,6592,yeralin,2021-04-16T17:14:20Z,"it was introduced in [a link] however, now i am looking at it and seems like we actually don't need any of: [code block] since we are operating only with: [code block] good observation, i'll remove these unused configs.",0,0.961145281791687
615008995,6592,yeralin,2021-04-16T17:20:31Z,that's a good idea. i think `illegalargumentexception` is the most appropriate. something like: [code block],1,0.9042405486106873
615010709,6592,yeralin,2021-04-16T17:23:38Z,"i was following the logic defined in similar (de)serializers like `sessionwindowedserializer`. there they are doing similar thing, simply checking whether a (de)serializer is null, then trying to get a value from configs. they don't perform any verification. what do you think? should we divert from that approach?",0,0.9153202176094055
615020981,6592,yeralin,2021-04-16T17:41:33Z,"hey, no worries. for: i think i am already doing that in the constructors: [code block] if a user doesn't pass `serstrategy` flag, we pick the best one for her based on passed serializer. if a user passes her own `serstrategy` flag, we simply obey to it. however, we don't print any warning logs, since i assumed if the user passes the flag, then she probably knows what she is doing. what do you think? i could add a warning log otherwise.",0,0.5976654887199402
615021158,6592,yeralin,2021-04-16T17:41:56Z,"as per flag names, totally agree. changing them to `variable_size` and `constant_size`.",0,0.9905481934547424
615075349,6592,yeralin,2021-04-16T19:23:08Z,"basically, if we are following `variable_size` serialization strategy **and** we have a `null` entry in our list, we encode this null entry as `-1`, so that during deserialization when we encounter `-1`, we append `null` entry to our list. example, to serialize a list like `{""a"", ""b"", null, ""c""}` of strings, the payload would look smth like: [code block]",0,0.9924675822257996
615075871,6592,yeralin,2021-04-16T19:24:11Z,could be called something like `null_entry_value` instead maybe?,0,0.9946369528770447
618823378,6592,ableegoldman,2021-04-22T23:51:07Z,"yes, i think we should. and it's not even a diversion from the approach elsewhere because there's a kip in progress to do so in classes like `sessionwindowedserializer` as well",0,0.9841957092285156
618823669,6592,ableegoldman,2021-04-22T23:52:16Z,"cool. i think the fewer configs overall, the better. if we can get away with just the serde configs then let's do so to keep the api surface area smaller for users :thumbs_up:",1,0.9888855218887329
618824127,6592,ableegoldman,2021-04-22T23:53:50Z,"ah, my bad. i think the variable i had in mind is actually called `double.bytes`. not 100% sure it's defined for all possible primitive types, but i would hope so",-1,0.9879337549209595
618824748,6592,ableegoldman,2021-04-22T23:55:45Z,that sounds good to me :thumbs_up:,1,0.9924324750900269
618826368,6592,ableegoldman,2021-04-23T00:00:19Z,"awesome. maybe i misunderstood this comment: or maybe you just wrote that a while ago and it's out of date. anyways what we're doing now sounds good, no reason to encode extra data even if the user selects this strategy for some reason. but i do think we should at least log a warning telling them they made a bad choice and it will be ignored. most likely they just didn't understand what the parameter meant, and it's a good opportunity to enlighten them",1,0.9859062433242798
618826641,6592,ableegoldman,2021-04-23T00:01:13Z,"ooooh ok, that makes a lot more sense now. i think your suggestion for the name sounds good",1,0.9559230208396912
618910174,6592,yeralin,2021-04-23T03:14:35Z,"yep, that checks out. only for `uuid` i'd have to leave hardcoded `36`.",0,0.9522026181221008
620449322,6592,yeralin,2021-04-26T16:17:55Z,"now, i am thinking about it. it seems a bit extra to compare the classes defined between the constructor and configs. maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? forcing the user to set only one or the other.",0,0.9398887753486633
620457633,6592,yeralin,2021-04-26T16:28:34Z,"hmmm, i thought you wanted to simply warn the user that the serialization strategy she chose is not optimal. but seems like you want to ignore the choice completely. then it doesn't make sense to expose this flag at all for the user to change. me and were discussing it earlier [a link]",0,0.6736191511154175
620716670,6592,ableegoldman,2021-04-26T23:20:45Z,"that works for me. tbh i actually prefer this, but thought you might consider it too harsh. someone else had that reaction to a similar scenario in the past. let's do it :thumbs_up:",1,0.9084321856498718
620720140,6592,ableegoldman,2021-04-26T23:29:50Z,"ah, sorry if that wasn't clear. yes i was proposing to ignore the choice if a user selects the `variable_size` strategy with primitive type data. and to also log a warning in this case so at least we're not just silently ignoring it. but i think you made a good point that perhaps we don't need to expose this flag at all. there seems to be no reason for a user to explicitly opt-in to the `variable_size` strategy. perhaps a better way of looking at this is to say that this strategy is the default, where the default will be overridden in two cases: data is a primitive/known type, or the data is a custom type that the user knows to be constant size and thus chooses to opt-in to the `constant_size` strategy. wdyt? we could simplify the api by making this a boolean parameter instead of having them choose a `serializationstrategy` directly, something like `isconstantsize`.",-1,0.9829553961753845
620802248,6592,yeralin,2021-04-27T02:27:58Z,"hmmm, reasoning was that in the future we could introduce **more** serialization strategies [a link] as per ignoring the choice, also from [a link] ... personally, i have a slight preference to allow both strategies for all types as i think easy of use is more important, but i am also fine otherwise. here is my thought process, if a user chooses a serialization strategy, then she probably knows what she is doing. ofc, the user will have a larger payload, and we certainly will notify her that the serialization strategy she chose is not optimal for the current type of data, but i don't think we should strictly forbid the user from ""shooting herself in the foot"".",0,0.6872543096542358
620804518,6592,ableegoldman,2021-04-27T02:34:31Z,"my feeling is, don't over-optimize for the future. if/when we do want to add new serialization strategies it won't be that hard to pass a kip that deprecates the current api in favor of whatever new one they decide on. and it won't be much work for users to migrate from the deprecated api. i'm all for future-proofness but imo it's better to start out with the simplest and best api for the current moment and then iterate on that, rather than try to address all possible eventualities with the very first set of changes. the only exception being cases where the overhead of migrating from the initial api to a new and improved one would be really high, either for the devs or for the user or both. but i don't think that applies here. that's just my personal take. maybe would disagree, or maybe not. i'll try to ping him and see what he thinks now, since it's been a while since that last set of comments. until then, what's your opinion here?",0,0.5690731406211853
621475071,6592,yeralin,2021-04-27T18:13:14Z,"ok, in this case, i think the best course of action is to completely remove `serializationstrategy` flag, and replace it with a simple boolean. do not expose it to the user, and automatically choose the strategy based on the type of data. if you agree, i'll go ahead and make the change.",0,0.9764194488525391
621676170,6592,ableegoldman,2021-04-27T23:05:42Z,"just to clarify you mean don't expose this to the user at all, right? that sounds completely fine to me. if there are enough people trying to serialize lists of custom classes with all constant data size who want this optimization exposed for general use, then someone will request the feature and we can go back and add it in. then we can debate what the api should look like at that time, and keep things simple for now. personally i suspect the vast majority of non-primitive data types are not going to be constant size anyways. given the above, i think whether to track the strategy as an actual `serializationstrategy` enum vs a boolean flag becomes a matter of code style and personal preference, since it's no longer exposed to the user. so it's up to you whether you find the enum or the flag to be more readable or clean",0,0.8802839517593384
629768563,6592,ableegoldman,2021-05-11T00:34:30Z,"same here, --> `public static`. can you also leave it on one line? i know it's super long, but that's just the style we use in kafka",0,0.963701069355011
629769396,6592,ableegoldman,2021-05-11T00:35:57Z,"super nit: we put the modifier first, ie use `public static` ordering.",0,0.9648817777633667
629770618,6592,ableegoldman,2021-05-11T00:40:07Z,"nit: kafka coding style doesn't use the `get` prefix in getters, ie this should be named `innerdeserializer` (same applies for any other getters in this pr, i won't bug you by commenting on every single one of them)",0,0.9844231009483337
629772320,6592,ableegoldman,2021-05-11T00:45:41Z,"is the unchecked warning coming from something in the test itself, or just from using the serde? it should be possible to just use the serde without getting a warning. i don't see anything in the test that looks suspicious so i'm guessing we need another suppression somewhere in the serde implementation?",0,0.9087780117988586
629772466,6592,ableegoldman,2021-05-11T00:46:11Z,super nit: extra blank line,-1,0.8090309500694275
629776651,6592,ableegoldman,2021-05-11T01:00:18Z,"i found it a bit difficult to understand what was going on here since i'm reading this first, before the serialize implementation, but i take it we just encode the indices of any null values at the beginning of the serialized list? can you leave a comment pointing that out, either here on the method itself or else down below where the method is used?",0,0.9572988748550415
629777825,6592,ableegoldman,2021-05-11T01:04:18Z,"since we no longer expose the serializationstrategy or let users explicitly select it, these two equality checks should have both be true or both be false, right? might read a bit easier if we only check `serstrategy == serializationstrategy.variable_size` here, and then just verify that `primitivesize` is not null when we parse the serialization strategy flag at the top. wdyt?",0,0.9772361516952515
629781672,6592,ableegoldman,2021-05-11T01:17:17Z,"since we don't know what the underlying list structure is, using `get(index)` like this could be pretty costly -- for example with a linkedlist this will be o(n), which makes it o(n^2) overall. might be safer to just iterate through the list with a plain `for int i` loop and take note of the nulls that way",0,0.9835754632949829
629781907,6592,ableegoldman,2021-05-11T01:18:05Z,nit: put the `out.writeint` on its own line,0,0.9929062128067017
629782907,6592,ableegoldman,2021-05-11T01:21:16Z,"same as my suggestion in listdeserializer, can you add a quick comment here or above the `serializenullindexlist` method explaining what this is doing (like you have above with `// write serialization strategy flag`)",0,0.9913440942764282
629784136,6592,ableegoldman,2021-05-11T01:25:13Z,"also similar to a comment in listdeserializer: it should not be possible for only one of these to be true, so let's just check one or the other here. in fact maybe we can get rid of the `isfixedlength` flag entirely now, since `serializationstrategy.variable_size` means exactly the same thing (or rather, the opposite of it)",0,0.994218111038208
630539763,6592,yeralin,2021-05-11T21:04:20Z,would something like this work? [code block],0,0.9886420369148254
630542548,6592,yeralin,2021-05-11T21:09:26Z,the problem is [a link] list `static public` first. ![a link],0,0.9899781942367554
630550102,6592,yeralin,2021-05-11T21:23:30Z,"unfortunately, it is unavoidable [a link] had to do it this way and sacrifice type safety for easier usage of this serde.",-1,0.8135857582092285
630603333,6592,ableegoldman,2021-05-11T23:27:32Z,"ah, i didn't notice...tbh we should probably just fix all of them, but it's fine with me to leave that out of this pr and just conform to this for now. i'll leave it up to you",0,0.7231677174568176
630605834,6592,ableegoldman,2021-05-11T23:34:18Z,"thanks for the context, it is what it is (and i agree with your decision to prioritize ease of use). i was more wondering whether we might be missing a `suppresswarnings(""unchecked"")` on one of the methods in the implementation, so that the user isn't forced to do the suppression themselves. but i can't quite tell where the warning is coming from, since it seems like we do already suppress unchecked warnings in `listdeserializer#createlistinstance` where the casting occurs? is it possible this was just left over from an earlier version, and we no longer need all the suppressions on these tests?",0,0.5817112922668457
630606384,6592,ableegoldman,2021-05-11T23:36:01Z,"yep, exactly (not sure why i said to use `for int i`, obviously that suffers from the same problem -- the iterator is what i had in mind)",0,0.9310334920883179
631151867,6592,yeralin,2021-05-12T15:33:20Z,this is a common practice leaving empty lines at the end of files: [a link],0,0.990250825881958
631158775,6592,yeralin,2021-05-12T15:40:10Z,"no, unfortunately they are still needed. afaik, suppression warnings cannot be propagated upwards. in `listdeserializer#createlistinstance` we indeed using `suppresswarnings(""unchecked"")` due to casting. however, in tests it is used bc `stack.class` (or `arraylist.class`, `linkedlist.class`, etc) is a raw-type and does not guarantee the required inner type (`integer` in this case). the only way to deal with these warnings is to create some wrapper classes as suggested, like: `public static class integerarraylist extends arraylist {}` but i do not this it is a scalable and clean solution. pretty much every time a user is calling `serdes.listserde(...)` they will have to put suppresswarnings statement. it is a limitation of java language. as said:",0,0.9901580214500427
631327191,6592,ableegoldman,2021-05-12T19:06:47Z,"well, it's not at the end of the file right? but if you'd prefer to keep it that's fine too, was just a ""super nit"" suggestion :slightly_smiling_face:",-1,0.9481686949729919
631328727,6592,ableegoldman,2021-05-12T19:09:22Z,"can you move this up to the top of this file, under the `streams changes in 3.0` section? it's in reverse order, so the newest stuff goes at the top.",0,0.9930939674377441
631334877,6592,ableegoldman,2021-05-12T19:19:33Z,"ah, i see, it's from the implicit casting of the parameters. that makes sense, i was just wondering since i didn't see any ""obvious"" casting in the test code itself. thanks for the explanation",1,0.6629734039306641
631339580,6592,yeralin,2021-05-12T19:27:24Z,"omg i am blind. sorry, you are right!",-1,0.993187427520752
212770210,5567,vvcephei,2018-08-24T22:37:13Z,i need to expose these so that i can query the window spec in ktableimpl,0,0.9887629151344299
212770275,5567,vvcephei,2018-08-24T22:37:50Z,"upon second look, i think i'll move these into a utility class to not pollute ktableimpl",0,0.9825489521026611
212770518,5567,vvcephei,2018-08-24T22:39:27Z,the basic idea is to traverse back through the topology until we find the window spec and get the grace period from it.,0,0.9862305521965027
212770687,5567,vvcephei,2018-08-24T22:40:59Z,on-the-side fixup of the generic types for groupby.,0,0.9898114204406738
212770823,5567,vvcephei,2018-08-24T22:42:02Z,"this is where the buffering would take place. right now, we throw an exception unless we detect that we can pass-through the record.",0,0.9755261540412903
212770994,5567,vvcephei,2018-08-24T22:43:20Z,`suppress` is split into interface/impl mostly to support these kinds of internal methods.,0,0.9909443855285645
212771115,5567,vvcephei,2018-08-24T22:44:11Z,decided to start using fuzzing to avoid magic numbers in the tests. let me know if you prefer it different.,0,0.9830112457275391
212771290,5567,vvcephei,2018-08-24T22:45:40Z,"`mockprocessorcontext` is pretty nice for unit tests, but we need `internalprocessorcontext` for the suppress processor.",0,0.9873263239860535
212771356,5567,vvcephei,2018-08-24T22:46:17Z,so you can just print the result of `forwarded()` for debugging.,0,0.9894207715988159
212771502,5567,vvcephei,2018-08-24T22:47:22Z,had to fix this to actually get the right timestamp forwarded.,0,0.9365145564079285
212771525,5567,vvcephei,2018-08-24T22:47:35Z,just to quit spamming the logs.,0,0.7154608964920044
213025428,5567,vvcephei,2018-08-27T15:56:16Z,"this preserves the existing behavior that if both `to.timestamp` and `this.timestamp` are unset, the forward time would be `-1`.",0,0.9926825165748596
213039753,5567,vvcephei,2018-08-27T16:46:07Z,"which i think is reasonable, since this context would only be used for unit tests.",0,0.9841032028198242
213190515,5567,guozhangwang,2018-08-28T05:49:13Z,nit: `bytestouseforsuppressionstorage` -> `numbytestostore`?,0,0.9940955638885498
213190554,5567,guozhangwang,2018-08-28T05:49:30Z,`numberofkeystoremember` -> `numkeystoremember`?,0,0.9948262572288513
213192247,5567,guozhangwang,2018-08-28T06:01:31Z,`intermediateevents` -> `emitintermediateresults`?,0,0.9940066337585449
213192826,5567,guozhangwang,2018-08-28T06:05:43Z,nit: `intermediateemitconfig`?,0,0.9940213561058044
213193035,5567,guozhangwang,2018-08-28T06:07:02Z,"hmm.. this makes me thinking if we should consider duplicate the `bufferfullstrategy` to `finalbufferfullstrategy` and `intermediatebufferfullstrategy` and also the corresponding caller `bufferconfig` as well, to replace runtime error with complication error?",0,0.9149890542030334
213193122,5567,guozhangwang,2018-08-28T06:07:34Z,why not `timewindows`?,0,0.9886035919189453
213194261,5567,guozhangwang,2018-08-28T06:14:53Z,"let's use `topologyexception` instead of `illegalargumentexception` here, ditto below.",0,0.9933131337165833
213194430,5567,guozhangwang,2018-08-28T06:15:50Z,actually today we have undefined operator for windowed-table / windowed-table join at all. but the logic itself looks good :p,1,0.9853976964950562
213196512,5567,guozhangwang,2018-08-28T06:28:15Z,"nit: just define two static `timedefinition ` and `timedefinition , v>`, one with context.timestamp and one with window end time?",0,0.9940053820610046
213321144,5567,bbejeck,2018-08-28T13:50:40Z,since [a link] should this be `suppress suppress` for consistency with the rest of the api?,0,0.9949719905853271
213326969,5567,bbejeck,2018-08-28T14:04:48Z,one meta-comment about the static methods on the interfaces in `suppress`. would we want to consider making them `default` instead of `static` in case down the line we want to implement any of these interfaces to have different behavior in the various methods?,0,0.9942246079444885
213333450,5567,bbejeck,2018-08-28T14:20:32Z,nit: we can get rid of the `else` here,0,0.9804259538650513
213336080,5567,bbejeck,2018-08-28T14:26:44Z,is this intentional or left over debugging?,0,0.9049319624900818
213376919,5567,vvcephei,2018-08-28T16:07:30Z,"this is actually ""suppress intermediate events"". it looks like this in the dsl: with static import: `table.suppress(intermediateevents(...))` without static import: `table.suppress(suppress.intermediateevents(...))` does that seem right?",0,0.994361400604248
213377265,5567,vvcephei,2018-08-28T16:08:30Z,"yeah, i was thinking something similar... i'll sketch something up.",0,0.7287521958351135
213377504,5567,vvcephei,2018-08-28T16:09:14Z,how do you know it's a `timewindows`?,0,0.9917883276939392
213377758,5567,vvcephei,2018-08-28T16:09:57Z,ok. thanks. that sounds much better.,1,0.9845616221427917
213379204,5567,vvcephei,2018-08-28T16:14:23Z,"i see. well, it's permitted by the api, so i'd rather keep the sanity check. actually, it seems like the only problem with further manipulations of windowed tables is that we won't know to use a windowed store (as by that point, we only know it's a ktable). might be worth revisiting this at some point...",0,0.9700242877006531
213383840,5567,vvcephei,2018-08-28T16:28:32Z,"yes, it should! thanks for the catch and the reference.",1,0.8617910146713257
213385791,5567,vvcephei,2018-08-28T16:34:57Z,"in general, this is something that's good to start thinking about. i think we have two kinds of interfaces/non-final classes: ones that are for implementing and ones that are for encapsulation. for implementing: serde, windows, statestore, etc. for encapsulation: ktable, materialized, etc. to me, `suppress` is in the latter category: since we cast it to `suppressimpl` immediately, it's not possible to pass in any other implementations of it. the interface/impl split is purely to provide a clean division of external/internal members. the regular java access modifiers are insufficient for this purpose, since suppressimpl's internal members need to be accessed from other internal classes, but outside of its package.",0,0.7926766872406006
213387916,5567,vvcephei,2018-08-28T16:41:18Z,"it's intentional. we first randomly generate a seed, then we create a (pseudo)random for test data generation from the seed. if the test fails, we can deterministicaly reproduce the (pseudorandom) test exactly, but only if we know the seed. that said, i want to play around with it some more, and see if i can get it to only print the seed if there are test failures. also, there's currently no option to run the tests with the seed, but you could always just drop in the literal when you're debugging locally.",0,0.9540268182754517
213389544,5567,vvcephei,2018-08-28T16:45:31Z,see prior response,0,0.988244891166687
213393351,5567,vvcephei,2018-08-28T16:56:01Z,"hmm, i don't know if i want to spend a bunch of time of this idea. i think what i'll do is switch to a fixed seed, so that we get deterministic testing while keeping the statement that there's nothing special about the values we're testing with.",-1,0.8442119359970093
213414494,5567,vvcephei,2018-08-28T17:59:15Z,how about `maxbytes`?,0,0.9923082590103149
213477348,5567,vvcephei,2018-08-28T21:24:05Z,"ah, it can't be static because of the generic parameters, but i can make it final, which would bring us to one anonymous class per instance ... but you get a new instance every time you call one of the builder methods anyway, so it's the same thing. i think this is what i was originally thinking when i left it like this.",0,0.8933326601982117
213479566,5567,vvcephei,2018-08-28T21:32:00Z,"actually, no it shouldn't ;) `suppress`'s bounds on `k` and `v` need to be tight, since the operator will actually serialize and deserialize the records (1. when it is size-constrained, 2. when it spills to disk, and 3. because this operator needs a changelog).",1,0.9489818811416626
213479948,5567,vvcephei,2018-08-28T21:33:31Z,"i previously missed that last point... it means that suppress requires serdes and not just serializers, and it needs them always, not just when it's size constrained or spilling to disk.",0,0.977344810962677
213480277,5567,vvcephei,2018-08-28T21:34:44Z,"oh, and i've also just now realized that it should be called `suppressed`, not `suppress`, in keeping with the rest of the config objects... this is a lot of changes. i think we'll probably have to recast votes this time.",0,0.954725980758667
213753581,5567,vvcephei,2018-08-29T16:45:49Z,"sorry, i was being silly, but upon second reading, it looks snarky... `windows ` is the tightest bound we can put on the window spec at this point, since this processor takes any window spec.",-1,0.9928330183029175
213760382,5567,vvcephei,2018-08-29T17:07:37Z,changed the name to `suppressed` in keeping with the other config objects.,0,0.9945454597473145
213819571,5567,vvcephei,2018-08-29T20:17:47Z,added these methods in lieu of the bufferfullstrategy enum,0,0.9930673837661743
213819739,5567,vvcephei,2018-08-29T20:18:25Z,"added `serialized` as a top-level property of the buffer, since the buffer itself will likely need a changelog for resilience.",0,0.9927405714988708
213820442,5567,vvcephei,2018-08-29T20:20:42Z,utility class just to encapsulate the graph search for looking back up the topology for the grace period (and verifying it's configured the same on all incoming branches),0,0.984965443611145
213820698,5567,vvcephei,2018-08-29T20:21:33Z,i'll fill this in in the next pr.,0,0.9856199026107788
213820934,5567,vvcephei,2018-08-29T20:22:26Z,"added this ""test"" to demonstrate what compiles and what doesn't.",0,0.9899590611457825
213822461,5567,vvcephei,2018-08-29T20:27:16Z,this allows us to insist on a `strictbufferconfig` for the final results use case.,0,0.9938910007476807
214188984,5567,vvcephei,2018-08-30T21:37:52Z,"i had a potentially kooky idea... what if instead of bumping up the node index here, we just tack ""suppress"" on to the parent node name somehow? this way, it would become fine to slap suppressions into topologies and restart without any other changes (because it wouldn't cause all the other nodes to get re-numbered). this might be especially important if we intend to insert suppressions in the future for optimization reasons. thoughts?",-1,0.8576072454452515
214207725,5567,guozhangwang,2018-08-30T23:14:02Z,"could you elaborate a bit more on `just tack ""suppress"" on to the parent node name somehow?` what is the concrete proposal of the naming scheme?",0,0.9939636588096619
214481155,5567,bbejeck,2018-08-31T21:38:59Z,"hmm, i'd have to see the concrete proposal. if we follow that approach wouldn't we still need to implement some sort of counter in the case of having multiple ""suppress"" nodes? then i think we'd still have the same issue, adding a new suppress operator would change the numbering scheme of the suppress nodes in the topology.",0,0.9613102674484253
214482095,5567,bbejeck,2018-08-31T21:44:40Z,we should have a unit test for this class covering both base cases as well as the success result,0,0.9896787405014038
214483409,5567,bbejeck,2018-08-31T21:51:23Z,this base case and the one below could be refactored into a method [code block] wdyt?,0,0.9937451481819153
214980375,5567,vvcephei,2018-09-04T16:21:43Z,"yeah, it would be like: [code block] so the suppressions would still be guaranteed a unique name, but any renumbering would only affect suppressions that are peers under the same ktable node.",0,0.9929038882255554
214982312,5567,vvcephei,2018-09-04T16:28:04Z,"yes, it seems like this would also work, but tbh it seems a little roundabout to me. is the objective to avoid duplicates of the error string? maybe we could just extract the exception construction into a method: [code block] then again, i have doubts about whether adding an extra method to de-duplicate the (to me) simple logic of creating the exception is worth it at all. especially considering that there's no particular reason that the exception message needs to be exactly the same in these two cases. what say you?",0,0.736341118812561
214983712,5567,vvcephei,2018-09-04T16:32:32Z,"i should say: i don't want to add it to *this* pr (which is already large). if you think there's merit to this idea, i would tackle it in another pr.",0,0.9542956352233887
215067976,5567,vvcephei,2018-09-04T21:10:15Z,this is where we insist on strict buffering for final results.,0,0.9731988310813904
215068069,5567,vvcephei,2018-09-04T21:10:32Z,see: [a link],0,0.9861002564430237
215315559,5567,bbejeck,2018-09-05T15:21:49Z,"makes sense to me to require users to specify how to handle the different scenarios as each user will have different needs concerning when they want a result emitted. but i'm wondering if we want to restrict users from having to supply a `strictbufferconfig` in all cases. i think there could be a case when faced with the option of either shutting down or emitting an early ""non-final"" result; there is a subset of users that would prefer an initial possible duplicate result vs. a production shut-down. so maybe the type could be ` ` unless of course, i'm wrong with my assumptions about the semantics of `strictbufferconfig.shutdownwhenfull`.",0,0.8987340331077576
215333841,5567,bbejeck,2018-09-05T16:09:07Z,what are the semantics around `strictbufferconfig.unboundedbuffer`? wouldn't have the same behavior as the `strictbufferconfig.spilltodiskwhenfull` option? what is the behavior of `shutdownwhenfull`?,0,0.9935528039932251
215339913,5567,vvcephei,2018-09-05T16:27:17Z,"there are several buffering options available that provide strict buffers: * unbounded (just keep allocating more until you get an oome) * bounded, shut down gracefully when full * unbounded, using disk instead of memory i think this provides plenty of options. i'm not sure we want to get into providing an option that says ""emit final results only (unless it turns out you need more memory than you allocated, in which case emit both intermediate and final results)"". 1, that's pretty confusing. 2, the main justification for ""final results mode"" is that the destination is some kind of system that doesn't permit updates. if we *claim* to support final-results-only, but send updates instead, we risk causing harder-to-debug downstream failures.",-1,0.9564135074615479
215340550,5567,vvcephei,2018-09-05T16:29:14Z,"an unbounded buffer has no specified bounds. it will just grow until the application runs out of heap. ""spill to disk"" and ""shut down when full"" are both bounded. you specify some limits on the size of the buffer or the number of keys, and it either shuts down gracefully or switches to disk when it runs out of space.",0,0.9811972975730896
215341057,5567,bbejeck,2018-09-05T16:30:36Z,i'm not opposed to the idea; i guess we'll need to weigh the pros and cons of having a separate approach to naming some nodes.,0,0.8282773494720459
215342060,5567,bbejeck,2018-09-05T16:34:06Z,"the overall objective was merely to reduce the duplication in code, as the two blocks seemed the same to me less the condition triggering the exception. but you have a point so maybe leave as is.",0,0.9725383520126343
215347029,5567,bbejeck,2018-09-05T16:49:32Z,"could maybe use `embeddedkafkacluster.deletealltopicsandwait` instead, as we've had problems in the past with test flakiness by not deleting internal topics.",0,0.9894170165061951
215350959,5567,bbejeck,2018-09-05T17:02:18Z,why not use `inegrationtestutils.produce..` method variants?,0,0.9937703013420105
215352500,5567,bbejeck,2018-09-05T17:07:10Z,"same here, why not use one of the `integrationtestutils.waitutill...` methods for consuming records?",0,0.9935430288314819
215352630,5567,bbejeck,2018-09-05T17:07:35Z,was this line intentional or leftover debugging?,0,0.919150710105896
215354084,5567,bbejeck,2018-09-05T17:11:57Z,"we'll need a timeout here because unless i'm missing something, this method could block forever (or at least make the test run longer than necessary) if the expected number records aren't received. another plug for using `integrationtestutils.wait..` methods as those methods provide timeout functionality.",0,0.9865028858184814
215357092,5567,bbejeck,2018-09-05T17:19:52Z,thanks for adding the integration test. i'm thinking we'd want to add test methods using the different `strictbufferconfig` options and the `eagerbufferconfig`.,1,0.8365874290466309
215360179,5567,bbejeck,2018-09-05T17:29:35Z,"great coverage, thanks for adding",1,0.9910799860954285
215371772,5567,vvcephei,2018-09-05T18:05:33Z,"ah, good catch. thanks!",1,0.9961154460906982
215373053,5567,vvcephei,2018-09-05T18:09:55Z,"to improve these tests' readability, i created a simplified ""record"": `kvt`. this allows us to produce a batch of records, all with potentially different timestamps, at once. the `integrationtestutils` methods only accept a collection of `keyvalue`, all with the same timestamp, or a collection of `v`, all with the same key and timestamp.",0,0.9924748539924622
215373138,5567,vvcephei,2018-09-05T18:10:12Z,"basically, the same explanation as above.",0,0.9903779029846191
215373244,5567,vvcephei,2018-09-05T18:10:32Z,doh! this is left over. sorry.,-1,0.9938693046569824
215373535,5567,vvcephei,2018-09-05T18:11:31Z,fair enough. i'll add a timeout.,0,0.904115617275238
215374308,5567,vvcephei,2018-09-05T18:14:00Z,"agreed. currently, no actual buffering is implemented. attempts to do anything but immediately emit will throw an exception. this is verified by the processor test. in the next pr, i implement buffering, and i have the integration tests for the different strategies there.",0,0.9905695915222168
215374466,5567,vvcephei,2018-09-05T18:14:27Z,thanks! i actually used the idea code coverage tool for this one :),1,0.995431661605835
215375753,5567,vvcephei,2018-09-05T18:18:23Z,"i considered adding to the utils, but i would also have to add kvt. it seems unnecessary at this point to dump a new method and keyvalue-esque class, which are only used in this test, into util.",0,0.9924761652946472
215378941,5567,vvcephei,2018-09-05T18:27:54Z,"ah, i remember what i was thinking: that if we run integration tests in parallel, we should only delete the topics we need to. but maybe we don't parallelize the methods within a test class, and we don't share embedded clusters between test classes?",0,0.9451575875282288
215663637,5567,bbejeck,2018-09-06T15:09:45Z,"fair enough. but imho i can't envision a case where users will voluntarily let a production system shut down, but again that's just my opinion.",0,0.5251641273498535
215673339,5567,bbejeck,2018-09-06T15:34:05Z,nit: do you need `cleanstateaftertest`? in `getcleanstartedstreams` you already call `driver.cleanup` and delete all topics in `cleanstatebeforetest`,0,0.9949519634246826
215677905,5567,vvcephei,2018-09-06T15:46:05Z,"the (maybe imaginary) scenario i had in mind was: * your business logic depends on exact buffering behavior (otherwise you wouldn't be using ""final"") * you want to bound how much memory the app uses * you discover that in practice the app needs more memory than your bound it seems like in a situation like this, you would like a graceful shutdown with a clear message so that you can reconsider your options. * maybe you take a look at your metrics and discover that you can decrease the window grace period, thereby relieving memory pressure * maybe you change the environment so you can allocate more memory to the task unless you are using iq or doing something time-sensitive like high-frequency trading, shutting the app down for short periods of time when it's misbehaving should be acceptable. having hard failures like this can actually be more operationally friendly than grey failures like frequent gc or apps stealing memory from each other. but of course, it depends on the situation. there is a possibility of implementing more complex behaviors, such as pausing some tasks to allow others to flush more work, but i don't think we need to think about that right now. that was all for context. at the end of the day, if we don't think we need the ""graceful shutdown"" mode, i'd rather not implement it.",0,0.9834977388381958
215678896,5567,vvcephei,2018-09-06T15:48:47Z,it's a belt-and-suspenders thing. we want it at the end so that the tests don't leave garbage around (for example the last test). i also added it at the beginning just in case a prior run got forcibly killed and never had a chance to clean up.,0,0.9626404643058777
215804228,5567,mjsax,2018-09-06T23:07:21Z,nit: `by the supplied { suppressed} specification.` (or `configuration`?),0,0.9937983155250549
215804652,5567,mjsax,2018-09-06T23:09:17Z,nit: `k` -> `key` and `v` -> `value` (we should try to avoid abbreviations) should we add `final`?,0,0.9949641227722168
215805094,5567,mjsax,2018-09-06T23:12:13Z,"seem i am missing something, but why do we need `k, v` as generic types here?",0,0.9770960211753845
215805317,5567,mjsax,2018-09-06T23:13:35Z,nit: `eagerbcimpl` -> `eagerbufferconfigimpl` (avoid abbreviations -- make the code unnecessarily harder to read for newcomers),0,0.9862216711044312
215805813,5567,mjsax,2018-09-06T23:16:33Z,as above,0,0.9391705989837646
215806026,5567,mjsax,2018-09-06T23:17:59Z,seem the interface lacks some javadocs to explain this?,0,0.9667580723762512
215806779,5567,mjsax,2018-09-06T23:23:38Z,`boundedbykeys` -> `maxbufferedkeys` (cf. comment below),0,0.9931761622428894
215807022,5567,mjsax,2018-09-06T23:25:12Z,"if we rename above, rename this to `withmaxbufferedkeys` ? (other interfaced -- eg, `produced` -- also use `withxx` for all non-static methods as counterpart to `xx` for static ones. might be nice to follow this pattern? better suggestions are welcome.",1,0.9630141258239746
215807451,5567,mjsax,2018-09-06T23:27:42Z,as above: `maxbufferedbytes` ?,0,0.9937653541564941
215807482,5567,mjsax,2018-09-06T23:27:54Z,`withmaxbufferedbytes` ?,0,0.9934805631637573
215807736,5567,mjsax,2018-09-06T23:29:19Z,"nit: to follow other interface, the non-static methods should have the `with` prefix (similar below)",0,0.9927389025688171
215808672,5567,mjsax,2018-09-06T23:35:23Z,"for the case you describe, `emitfinalresultsonly` seem to be the wrong user choice, and they should use `intermediateevents` with ""infinite time duration"" and limited buffer size.",0,0.9842251539230347
215809634,5567,mjsax,2018-09-06T23:42:03Z,"i understand the desire, however, it would not solve the overall re-naming issue -- i would prefer to have a holistic solution for the problem instead of introducing complex code that does not really help.",0,0.9465479254722595
215809978,5567,mjsax,2018-09-06T23:44:29Z,`findandverifywindowgraceorthrow` (and remove the comment) ? (self-documenting code ftw :)),1,0.7710167765617371
215810340,5567,mjsax,2018-09-06T23:46:44Z,nit: comment unnecessary,-1,0.6455734968185425
215810366,5567,mjsax,2018-09-06T23:47:00Z,comment unnecessary,0,0.590660035610199
215810406,5567,mjsax,2018-09-06T23:47:25Z,comment unnecessary,0,0.590660035610199
215810981,5567,mjsax,2018-09-06T23:51:32Z,can we use ` ` directly here? also let `buildfinalresultssuppression` return this type instead of windowed?,0,0.9950243830680847
215811536,5567,mjsax,2018-09-06T23:55:09Z,"""all parents"" ? `suppress` is only available for `ktable` and thus there should be only one parent node? also, do we need to handle chaining of `.suppress()` within `extractgraceperiod`? i also don't understand how there could be multiple parent grace periods (and thus, why do they need to match -- there should only be one anyway?) -- do i miss something? i also just realize, that windowed-ktables have another issue: we cannot only not join two, but we can also not `.filter(..., materialize)` because this would also create an ever growing key-value store instead of a windowed store... \cc thoughts?",0,0.9781173467636108
215813625,5567,mjsax,2018-09-07T00:10:34Z,"wy not use `new unsupportedoperationexception(""not implemented yet."")` :)",1,0.9032215476036072
215813819,5567,mjsax,2018-09-07T00:11:58Z,"nit: is a negative value valid? if `duration` does not check this, we should check and throw?",0,0.9659033417701721
215814619,5567,mjsax,2018-09-07T00:17:50Z,"don't understand the second check? why must the record-time (or window-end-time) be less-or-equal to current stream-time? for record-time, this should be true all the time, but for window-end time, i don't think this is true -- why do we want to fail for this case?",0,0.9306277632713318
215815381,5567,mjsax,2018-09-07T00:23:16Z,could this be `private`?,0,0.9925561547279358
215816045,5567,mjsax,2018-09-07T00:28:20Z,`keyvaluetimestamp`,0,0.9931167364120483
215816087,5567,mjsax,2018-09-07T00:28:39Z,`keyvaluetimestamp`,0,0.9931167364120483
215816526,5567,mjsax,2018-09-07T00:32:14Z,"""shouldaccept only"" -- sound like a negative test but i don't see any exception? the `doesn't compile because the buffer is eager` part is weird... the condition you express is ensured via the interface -- ie, it does not compile. thus, i don't think we need a negative test.",-1,0.8616344928741455
215816861,5567,mjsax,2018-09-07T00:35:06Z,"i am fine with this; however, it might be better to take `system.currenttimemillis()` as seed and log the seed -- if it fails, we can reproduced using the logged seed? also: it's multiple test methods and i don't think that the execution order is defined. thus, we should initialize the with known seed, for each test, ie, via ``",0,0.9722242951393127
215817497,5567,mjsax,2018-09-07T00:40:48Z,`end` could be `0` and thus `nextint(end)` would throw. use `end = 1 + random.nextint(integer.max_value - 1);` above,0,0.9939246773719788
215817777,5567,mjsax,2018-09-07T00:43:16Z,should `timestamp` not fall into the window boundaries? not sure if it's important for the test?,0,0.9689385890960693
215818040,5567,mjsax,2018-09-07T00:45:22Z,why do we need an extra test for this? seems to be covered in `finalresultssuppressionshouldthrow` ?,0,0.9938493371009827
215818075,5567,mjsax,2018-09-07T00:45:38Z,as above,0,0.9391705989837646
215818472,5567,mjsax,2018-09-07T00:48:45Z,"there is already an `internalstreamsconfig` in `streamspartitionsassignor` -- if we want to use it multiple time, should we make it a public internal call that we can reuse here instead of duplicating code? maybe in a new package `...streams.internals` ?",0,0.9959601759910583
215993196,5567,vvcephei,2018-09-07T15:14:19Z,"good catch on the abbreviations. about `final`, i'll check. it might not be allowed in an interface method header.",1,0.8228758573532104
215993869,5567,vvcephei,2018-09-07T15:16:21Z,"hmm. maybe we don't... i used to have serdes in the buffer config, but they are gone now. also, we need k/v in `suppressed` so that we can bound the k to be windowed for final updates. i'll try and drop them. it would be awesome if we don't need them.",1,0.6195133924484253
215994325,5567,vvcephei,2018-09-07T15:17:42Z,"it's actually `eagerbritishcolumbiaimpl`, but i can see how you'd get confused.",0,0.7779785394668579
215995058,5567,vvcephei,2018-09-07T15:19:44Z,thanks for the suggestion. i've really struggled to come up with good names for these static/instance methods that make sense in context. i'll give this a shot.,1,0.9629108905792236
215997251,5567,vvcephei,2018-09-07T15:26:19Z,"i figured that ""verify"" means ""orthrow"". the comment is part of a series that explains why the casts in this method are safe. i think that it would be very difficult to understand later why it's ok to cast `k` to `windowed`, and then why we would cast the resultant suppression back to `k`.",0,0.9885424375534058
215998650,5567,vvcephei,2018-09-07T15:30:34Z,"no, the final results suppression is defined only for windowed tables, by design. as the comments explained, we happen to know that k is a windowed, but the generic bound is still just `k extends object`, so we have to ""forget"" our knowledge that k is a windowed in order to return the result properly typed. this is what i was trying to explain in the comments, and your question illustrates why i think the comments are necessary. but i guess i need to try harder to make the comments explain this situation fully.",0,0.9670189619064331
216000969,5567,vvcephei,2018-09-07T15:37:15Z,"the last point is correct. i thought that we were already aware of this shortcoming... but now i don't remember who i was talking to about it. about the parents... the immediate parent of suppress is a single ktable, but may not be the one with a defined grace period. it might be a filter, in which case we need to examine the parent of the filter, or it might be a join, in which case we need to examine *both* parents of the join. the fact that we currently have a design flaw that prevents this situation doesn't imply that we should encode this limitation here. once we fix that design flaw, we would have to remember that we also coded that flaw into this method and come back to revert it to the state it's in right now!",0,0.9257449507713318
216002077,5567,vvcephei,2018-09-07T15:40:42Z,"` \_()_/ ` sure, that would work too. i'm removing this exception in the next pr, so i don't think it matters much. using the specifically defined exception makes it slightly easier to make sure i remove all usages of it in the next pr, as i can delete the exception class and the code won't compile until i remove all usages.",0,0.972662627696991
216002534,5567,vvcephei,2018-09-07T15:42:13Z,i don't see why i need to worry about that here.,-1,0.5987890958786011
216004459,5567,vvcephei,2018-09-07T15:48:09Z,"as you pointed out, a record in an open window will have a time greater than the current stream time. this means we should buffer it (when it's implemented) and *not* immediately emit it.",0,0.9861347079277039
216004765,5567,vvcephei,2018-09-07T15:49:08Z,"hmm, i'll check. i don't think so, but i don't remember why.",0,0.798660397529602
216005077,5567,vvcephei,2018-09-07T15:50:07Z,k ;),1,0.9918694496154785
216006317,5567,vvcephei,2018-09-07T15:54:01Z,"the purpose of this ""test"" is explicitly to demonstrate what compiles and what doesn't. it's of course not possible to write code that doesn't compile in order to demonstrate that it doesn't compile, so i wrote the code and commented it out. if you'd like to ""run"" the test, you can uncomment the ""negative test"" lines and verify they are not permitted. if you think this is silly, i can rename the test.",0,0.972926676273346
216007362,5567,vvcephei,2018-09-07T15:57:30Z,"what you are describing is what i had initially. it seemed a little too fancy, though. i think if we like this approach, we should consider bringing in a real fuzzing framework instead of hand-rolling it. about ``, this is a good point. i'll do it.",0,0.6927871108055115
216008190,5567,vvcephei,2018-09-07T16:00:14Z,"in practice, it would, but since the processor itself doesn't make any assumption between the record timestamp and the window boundary, it doesn't matter for the test. in fact, the test verifies that the processor makes no such assumption.",0,0.9910388588905334
216008629,5567,vvcephei,2018-09-07T16:01:31Z,"it's a stub of a test that i have in the next pr. when i extracted this one and replaced buffering with exceptions, i just replaced all the test bodies with verification of the exception.",0,0.9908707737922668
216008726,5567,vvcephei,2018-09-07T16:01:55Z,explained above.,0,0.9903995394706726
216009989,5567,vvcephei,2018-09-07T16:06:32Z,"i considered that, but it seemed better to keep the mockprocessorcontext in test-utils as decoupled as possible from the internals of streams. in general, when we're modifying streams code, we exercise a lot of freedom in modifying internals, and i don't want to risk accidentally changing the behavior of the mock if we decide to add some more stuff to the one used by streamspartitionassigner. if it helps, i can give this one a different name...",0,0.9722779393196106
216041459,5567,guozhangwang,2018-09-07T18:01:14Z,`eagerbritishcolumbiaimpl` yeah that's what i thought too!,1,0.8270618319511414
216042101,5567,guozhangwang,2018-09-07T18:03:42Z,how about `emitintermediateevents` to be better aligned with `emitfinalresultsonly`?,0,0.9938894510269165
216043674,5567,guozhangwang,2018-09-07T18:09:34Z,could you elaborate why we need `bc extends bufferconfig ` as its template?,0,0.9945182204246521
216044564,5567,guozhangwang,2018-09-07T18:12:29Z,`kstreamwindowaggregate` is used only for time windowed aggregations (the class name was added when we only have time windowed at that time). for session windowed aggregations we have `kstreamsessionwindowaggregate`.,0,0.9951086640357971
216044943,5567,guozhangwang,2018-09-07T18:13:49Z,"with this idea, whether or not we insert a suppression or not would not affect any downstream operators, right? why that would not solve the re-naming issue?",0,0.9861536026000977
216046368,5567,guozhangwang,2018-09-07T18:18:38Z,"nit: why put this class under `suppress`? we usually try to get consistent hierarchy among main v.s. test directories unless there is a strong motivation not to. i.e. it is fine to have `ktablesuppressprocessortest.java` under `suppress`, but this class may just be `ktablesuppresstest` under `kstream/internals`.",0,0.9949990510940552
216068984,5567,vvcephei,2018-09-07T19:47:04Z,"yeah, this is another spot where i really struggled with naming. i liked `suppress(intermediateevents())` aka ""suppress intermediate events"", but the version for final would be like ""suppress all but final events"", and `suppress(allbutfinalevents()` just seems too confusing, so i compromised. note that this method isn't saying to _emit_ the events, but actually the opposite: to _suppress_ them. i think the symmetric name would be `suppressintermediateevents()`, which looks a little redundant in practice: `suppress(suppressintermediateevents())` or `suppress(suppressed.suppressintermediateevents())` :/ another idea would be to choose one of the synonyms. since we are accomplishing this suppression via buffering, we could call it `bufferintermediateevents` or just `buffer`... thoughts?",-1,0.9109224081039429
216070493,5567,vvcephei,2018-09-07T19:53:12Z,"ah! this has a name: ""curiously recurring generics"" (or ""curiously recurring template"" from c++). this allows us to declare builder methods in the interface that return an instance of whatever subclass was used to invoke the method. such as `bc bufferkeys(final long maxkeys)`. when we call this on an eager config, we get back an eager config, and when we call it on a strict config, we get back a strict config. if you recall the weird comment in windows that says ""all subclasses should override this method so they can return the correct type"", we were looking for the same property. if we had used this pattern, we wouldn't have needed that comment, as the overridden methods would automatically take on the correct return type.",0,0.6763643622398376
216071247,5567,vvcephei,2018-09-07T19:56:14Z,"sure, i can do that. i agree 100% on the unit tests. for this semi-integration test, i stuck it in this package just because `internals` already has like 1.5m test classes in it. i'll move it.",0,0.9146444797515869
216071967,5567,vvcephei,2018-09-07T19:59:15Z,"i think `kstreamwindowaggregate` is used for any subclass of `windows`, of which `timewindows` is one. it's definitely not `sessionwindows`, since `sessionwindows` is not a subclass of `windows`, but it could be `unlimitedwindows` or any user-supplied `windows` subclass.",0,0.994590163230896
216142211,5567,mjsax,2018-09-08T22:26:18Z,ack -- was just a thought.,0,0.627456545829773
216142224,5567,mjsax,2018-09-08T22:27:34Z,"i understood the comments -- was just not sure if we can improve the code. if we cannot change the generic type, it's fine.",0,0.9387175440788269
216142390,5567,mjsax,2018-09-08T22:36:05Z,"hmmm... i did originally not consider ktable-ktable join -- however, a grace period is only defined for windowed aggregations, right? thus, this would only make sense if two windowed-ktables are joined? thus, if we consider that we might fix joining two windowed-ktables in the future (was is broker atm), i am wondering, if we should use the maximum grace period over both base-join-tables as required bound for the suppression, instead of forcing both base-windowed-tables to have the same grace period configured?",0,0.9828575849533081
216142405,5567,mjsax,2018-09-08T22:37:35Z,i guess `<=` is ok (it was a nit) -- was just wondering if we should use `==` instead.,0,0.9856427311897278
216142501,5567,mjsax,2018-09-08T22:43:20Z,"why should we buffer it? if `suppress.isimmediateemit()` is true, i though we would not buffer it but emit it immediately to obey the config? or do i miss understand the semantics of `isimmediateemit()`?",0,0.9906942844390869
216142530,5567,mjsax,2018-09-08T22:45:25Z,"well, i guess nobody will ever uncomment those lines to test if it does not compile -- seems to be dead code to me.",-1,0.6751572489738464
216142579,5567,mjsax,2018-09-08T22:47:58Z,"ack. fine with me to not go too fancy. however, for this case i don't see why we need `random` at all, and not just hardcode some values for window-start-time etc -- if we seed with `42`, we will get some (unknown) but fixed values anyway -- so what do we gain to use `random` ? we can just put some fixed values into the code directly.",0,0.5950583815574646
216149809,5567,mjsax,2018-09-09T07:22:32Z,i don't see a big risk in 'coupling' for this case -- but not a big deal anyway. renaming doesn't buy us anything. just leave it as is.,0,0.6846303939819336
216149889,5567,mjsax,2018-09-09T07:27:07Z,"because it does not help us, if somebody inserts a `filter()` for example. the overall renaming issue is, that inserting new operator results in re-indexing. this would be a ""local"" solution for `suppress()` only, but no global solution for all operators. thus, my concern is, that we end up with different solutions for different operators for the same underlying issue. it's about consistency. does this make sense?",0,0.9590761065483093
216358799,5567,vvcephei,2018-09-10T15:08:27Z,"ah, sorry, i misunderstood the root of your question. since the type system doesn't have evidence that `k` extends `windowed`, we have to do a cast to assign to ` `. i separated it into the next line just to avoid doing too much in one line of code.",-1,0.9829158782958984
216361603,5567,vvcephei,2018-09-10T15:15:53Z,"yeah, we could make it more permissive that way. this is a discussion for the future when we do fix that operation, but it seems safest to support that join only when both streams have the exact same window configuration (otherwise there's no guarantee that the streams have any keys in common). in such a situation, we wouldn't have to worry about enforcing it here. but for now, i was thinking to be strict about the common grace periods as a basic precaution against mixing window types. (even though the grace period isn't part of the windowed key).",0,0.9755565524101257
216365179,5567,vvcephei,2018-09-10T15:24:25Z,"hmm i guess my method name is misleading. it's not that the suppression is configured like ""emit immediately"" (there is no such config option, but maybe there should be). rather, it's an internal utility method to indicate whether the buffer config allows us to just emit events that are on-time or late, rather than buffering them. regardless, we still need to buffer future events if there is room to buffer them. this logic is just a little murky right now because there isn't a buffer yet. so this logic is an attempt to emit any event that we can determine right away is legal to emit, since any buffering operation is actually an exception in this pr. i guess i could have made it simpler by just unilaterally throwing an exception for any record here, but i thought it would be nice to have some non-exceptional paths to have tests for. even though the implementation details will change when we add the buffer, any tests that currently check for events getting immediately emitted should continue to pass on the buffer-based implementation.",0,0.6442124843597412
216370098,5567,vvcephei,2018-09-10T15:37:27Z,"yes, this is the downside i was concerned about. i won't make any change to this in this pr. i've created a jira to continue the discussion: [a link]",0,0.5431562066078186
216394282,5567,guozhangwang,2018-09-10T16:49:09Z,"i see. and with this reasoning i think i also like `intermediateevents` as well. how about `suppress(intermediateevents())` and `suppress(untilwindowends())` since the latter should be only called for windowed table result, and hence putting the keyword `window` as part of the func name should be fine?",0,0.9418143630027771
216394504,5567,guozhangwang,2018-09-10T16:49:54Z,ack.,0,0.5038502812385559
216405880,5567,vvcephei,2018-09-10T17:23:55Z,"ooh! i like it! (although i think i'll say `untilwindowcloses`, since it waits for the grace period after the ""end"" of the window (which reminds me that i should make sure the window lifecycle is well documented for the 2.1 release))",1,0.9940472841262817
216517843,5567,mjsax,2018-09-11T00:52:49Z,"cannot follow here. can you elaborate? also, thinking about this once more: why do we need to force `suppress` to have a larger grace period that it's parents?",0,0.9839764833450317
216518207,5567,mjsax,2018-09-11T00:55:52Z,ack.,0,0.5038502812385559
216826714,5567,vvcephei,2018-09-11T21:20:33Z,"what i meant is that if the left stream and the right stream have completely different window specs, then the join will be completely disjoint. this is probably a programming mistake, and i think it's better to fail fast.",0,0.6423675417900085
216827058,5567,vvcephei,2018-09-11T21:21:45Z,about: i didn't understand. we set suppress's suppression time *equal* to the grace period of the parent.,0,0.5815078020095825
216870298,5567,mjsax,2018-09-12T01:08:21Z,"this makes sense -- however, if no suppress operation is defined, this would not be detected -- and if we put a check somewhere else, suppress does not need to check it either. does it? additionally, even if suppress does this check, i would exclude the grace period from the check. from my understanding, this method should checks that the grace period is larger than the window-size of the upstream ktable -- we don't need to set the grace-period, but just take whatever the users specified for it. there is no comparison of parent grace period and suppress grace period? and there is no need? or do i miss something?",0,0.9829618334770203
217177283,5567,vvcephei,2018-09-12T20:28:55Z,"yeah, i think we're miscommunicating. suppression does not have a ""grace period"", it only has the ""emit after"" config. the method `findandverifywindowgrace` only extracts the exact specified grace period, as configured upstream. we pass the value we get back to `org.apache.kafka.streams.kstream.internals.suppress.suppressedimpl#buildfinalresultssuppression`, which then creates a `suppressed` configuration using that time (the extracted grace period) as the ""emit after"" config, along with setting the `timedefinition` to the window end time. together these configs cause suppression to emit immediately right at the end of the grace period (as configured somewhere upstream).",0,0.9658676385879517
217179331,5567,vvcephei,2018-09-12T20:34:57Z,"you raised a separate question about whether we should be strict or permissive if the suppression node actually has multiple parents which specify two different grace periods. i favored strict because i think this makes the situation more debuggable and comprehensible. but you are correct in stating that it's not a correctness issue, since the grace period doesn't affect the key. for this reason, i would be ok with logging a warning and just using the larger grace period. the consideration we need to weigh is in that situation with two different windowed tables getting merged/joined, assuming they only differ in grace period, how can we ensure that all operators follow the same strategy of taking the larger grace period. it affects windowed store retention as well as suppression. i think taking the larger is a reasonably obvious choice, so maybe it's not a big deal, though.",0,0.9554949402809143
217476838,5567,mjsax,2018-09-13T17:51:03Z,"thanks for clarification! would be good to get input from about this. should we fail? or should we pick ""max""? i still favor ""max"", but it's not a deal breaker if we fail instead. nevertheless, i don't think `suppress` should check the window spec (size/advance etc) -- if a user does a ""weird"" join and we want to disallow it, this check should be done in `join()` instead.",1,0.9302593469619751
217514478,5567,bbejeck,2018-09-13T19:58:51Z,"i would favor taking the `max` as well, as, imho, we can't account for all use cases so better to chose max. we should document the behavior so users can be made aware of what happens with setting different grace periods would it be too much to make this a configurable item? i'm not sure as we have several config items to consider already.",0,0.9659347534179688
217805092,5567,guozhangwang,2018-09-14T18:34:31Z,"regarding the `.filter(..., materialize)` issue, yes this is a known bug. i think has raised a kip for fixing this. regarding the windowed-ktable / ktable join, there are some very old discussions before on how to tackle it ([a link] is filed recently), and the idea at that time was: 1) we would require the joining table's window-spec to be well aligned, i.e. they must have the same length. note since window boundaries are the same as they are all starting from the epoch time, it means that same window length guarantees aligned windows, and each the join operation becoming joining each paired windows of the table. we do not yet have session windows at all so this was not discussed, but with session windows it is definitely more complicated.. as for grace period, i think we do not need to make it strict that requires grace to be the same as well. personally i think either `min` or `max` are fine (i'm slightly leaning towards `min` though :p).",0,0.9334040880203247
217850548,5567,mjsax,2018-09-14T21:46:34Z,"why `min`? `max` seems to be inclusive and guarantees to respect the configs of both upstream operators, while `min` does not?",0,0.9923861026763916
217853758,5567,vvcephei,2018-09-14T22:05:17Z,"ok, * fwiw: i 100% agree that it's not this component's job to verify other aspects of the window spec. it should only care about grace period. * i think the semantics are perfectly well defined with `max`, and i buy these arguments that it's unnecessary to fail. i'd like to log a warning (just during the topology build) in case the mis-match was accidental. : i agree with , i don't think that `min` has the right semantics. the purpose of configuring the suppression interval equal to the grace period to begin with is that we already know that the window results will never be updated after the grace period ends. if we set the suppression smaller than the grace period (or in this case _one_ of the grace periods), then there will be an inconsistency between the aggregation results upstream vs. downstream of suppression. in fact, it's generally ok if we make the suppression interval _larger_ than the grace period. it just means that we'll emit the final result ""after"" the window closes, not ""at"" the window close. thus, `max` satisfies everyone's semantics and ensures consistent results throughout the topology. the ""more graceful"" parent will see its final results close after its grace period expires, and the ""less graceful"" one has to wait longer, but they will both never see their materialized state differ from the results downstream of the suppression.",0,0.5865524411201477
217856097,5567,guozhangwang,2018-09-14T22:22:06Z,"to me the grace period for a window is letting users to trade-off between latency and correctness, and hence users may actually prefer latency over correctness in some cases, so i said in the previous comment that personally i'd prefer `min`, just to express this intention :) anyways, i do not have strong preference which option to go, and i'm also fine with `max` if most people feel that way.",1,0.9871941208839417
217861650,5567,mjsax,2018-09-14T23:04:37Z,"from my understanding, using max will be the default behavior -- users can still manually specify a smaller one, right? it must just be larger than window-size?",0,0.991234540939331
217868845,5567,guozhangwang,2018-09-15T00:24:11Z,"grace period is the additional time on top of the window-size, and assuming that the window-size of the joining tables are the same, the grace period of 0 can also be used right?",0,0.9944581985473633
218138620,5567,vvcephei,2018-09-17T16:29:29Z,"ok, recall that we are talking about the special case in which the suppress operation has two parents who have different grace periods configured. in this case, ""max"" means that the suppression will be configured with the larger of the two parents' grace periods. normally, suppression only has one parent, in which case, it's configured to suppress for n ms, where n equals it's parent's grace period. n might be 0. if you select ""final results"", there is *no* option to configure the suppression interval. it is _always_ taken from the parent(s)'s configured grace period. to do anything else would threaten consistency. however, it's always possible just to do regular intermediate suppression, and choose any time you like, larger or smaller than the window size. you're just not guaranteed to get exactly one result per key/window if you pick any time shorter than window size + grace period.",0,0.9903432130813599
218451116,5567,vvcephei,2018-09-18T14:16:33Z,it is used in the static factory method of the interface.,0,0.9928755760192871
218604503,5567,bbejeck,2018-09-18T21:40:20Z,nit: can we take this out?,0,0.9849462509155273
218611217,5567,vvcephei,2018-09-18T22:07:06Z,"sure. i actually used this multiple times during this refactoring, but i think it'll be stable and therefore less useful now.",0,0.9710394740104675
218622057,5567,mjsax,2018-09-18T23:03:37Z,"this was not included in the kip, but is also public api. i think, we need to update the kip accordingly. similar to `strictbufferconfig` below? or is this for internal use only? for this case, we might want to move them to `internal` package but not nest them within `suppressed` interface.",0,0.9928755760192871
218622547,5567,mjsax,2018-09-18T23:06:19Z,"this method is not mentioned in the kip either. (or is it renamed `withbufferedkeys` -- if yes, should the return type not be `bufferconfig` as describe in the kip?) it seems there is a glitch between the pr and the kip -- will not comment on it further -- please revisit and update pr and/or kip to align both (for kip updates, please follow up on the mailing list; just a fyi email if it's just renaming bunch of methods).",0,0.9832428097724915
218623475,5567,mjsax,2018-09-18T23:11:32Z,kip has different generic types.,0,0.9270455241203308
218626835,5567,mjsax,2018-09-18T23:30:21Z,nit: remove `this`,0,0.9891441464424133
218628237,5567,mjsax,2018-09-18T23:39:08Z,nit: `grace` -> `defaultgrace`,0,0.9925997257232666
218628588,5567,mjsax,2018-09-18T23:41:03Z,"should we not honor the grace period as specified in `suppress` and use default one only, if user did not specify one (ie, maybe optimized to `min(usergrace, defaultgrace)` -- not sure if this optimization is desired or not, or if we should ""blindly"" accept `usergrace` even if it's larger than `defaultgrace` what does not by anything and only increases latency...?) also, first parameter in `buildfinalresultssuppression` is called `windowclosetime`, thus, should this be `windowsize + grace` (or `maxwindowsize + grace` for multiple parents) ?",0,0.9914677143096924
218631401,5567,mjsax,2018-09-18T23:57:34Z,can we define this as `timedefinition ` ? (and get rid of `getdefaulttimedefinition()`),0,0.9945818781852722
218633801,5567,mjsax,2018-09-19T00:13:26Z,naming: `withuntiltimeelapses` sounds clumsy -- `withelapsetime` ?,0,0.7266187071800232
218634055,5567,mjsax,2018-09-19T00:15:19Z,`*not*` -> ` not ` (or other html markup),0,0.990328848361969
218634393,5567,mjsax,2018-09-19T00:17:30Z,this is discussed in the kip. should it be defined within the interface? or removed from the kip if it's not public api but impl detail?,0,0.9933562874794006
218634430,5567,mjsax,2018-09-19T00:17:49Z,nit: indention,0,0.7825920581817627
218634537,5567,mjsax,2018-09-19T00:18:21Z,nit: remove empty line,0,0.9540706276893616
218655637,5567,vvcephei,2018-09-19T03:07:11Z,"yes, i plan to update the kip if you all liked this interface.",1,0.5168272852897644
218656056,5567,vvcephei,2018-09-19T03:10:50Z,"the user is not capable of specifying a suppress time for final results suppressions (see `suppressed.untilwindowclose`). only a buffer config. the grace period is the only way to ""set"" the suppression time. i'll rename the parameter to `graceperiod` this is correct, since the time definition for final results mode uses the window end as the starting point.",0,0.9939273595809937
218656226,5567,vvcephei,2018-09-19T03:12:22Z,"we can make it a ` `, but only if we drop the `static`. the static may be nice for performance, since we only need one function class & instance, but i'm not sure if it matters that much.",0,0.9823032021522522
218656366,5567,vvcephei,2018-09-19T03:13:29Z,"agreed. double preposition :( . on the other hand, i'm not sure what an ""elapse time"" might be. i'll try to think of something.",-1,0.9935065507888794
218656587,5567,vvcephei,2018-09-19T03:15:10Z,"yeah, if there were no objections on `suppressed`, i was basically going to smash what i had in the kip with it and send out an update. it's still fundamentally the same proposal, but i like the interface we've arrived at via this discussion a _lot_ better than what i originally proposed. so thanks!",1,0.9902162551879883
218659126,5567,vvcephei,2018-09-19T03:37:21Z,"but i don't like that this wasn't immediately obvious, so i'll make some clarifying changes.",-1,0.889217734336853
218666331,5567,mjsax,2018-09-19T04:38:29Z,i see. than i need to have a closer look -- i usually compare the pr with the kip and try to catch gaps... if you don't update the kip on purpose (what is ok) i need to change my strategy.,0,0.9475951790809631
218666810,5567,mjsax,2018-09-19T04:43:23Z,why this limitation? let's say i have [code block] does this make sense?,0,0.9837489128112793
218666974,5567,mjsax,2018-09-19T04:45:10Z,"this is not runtime critical -- and having a few more objects (we don't have about hundreds) is not overhead concern imho. it would be cleaner with specify type and get rid of the ""cast helper method"" imho.",0,0.9819930791854858
218667036,5567,mjsax,2018-09-19T04:45:41Z,"maybe ""flushdelay"" ? or ""suppressperiod"" ?",0,0.9942051768302917
218667438,5567,mjsax,2018-09-19T04:48:30Z,independent of the kip update. why return `eagerbufferconfig` here instead of `bufferconfig`? just curious. what is the advantage/disadvantage for each case?,0,0.8674303293228149
218667521,5567,mjsax,2018-09-19T04:49:12Z,"nit: `maxkeystostore` -> `max[numberof]keystostore` ? (also, why `keys`? maybe `records` is better/more accurate?); do we need `tostore`? maybe we can strip this?",0,0.994759738445282
218667577,5567,mjsax,2018-09-19T04:49:42Z,"nit `max[numberof]keystostore`? (or `records` -- cf, above)",0,0.9949771761894226
218668072,5567,mjsax,2018-09-19T04:54:26Z,`boundedbysize` above vs. `withbytesbound` -- should we align both?,0,0.9954730868339539
218668328,5567,mjsax,2018-09-19T04:55:56Z,`passes` -> `passed` ? `expires` -> `expired` ?,0,0.9902111887931824
218668393,5567,mjsax,2018-09-19T04:56:40Z,why `eventually` ?,0,0.9852409958839417
218668694,5567,mjsax,2018-09-19T04:59:25Z,"follow up: for `untilwindowcloses` it makes sense what you say -- my argument is, that offering only `untilwindowcloses` might not be flexible enough.",0,0.9817813634872437
218669272,5567,mjsax,2018-09-19T05:03:07Z,"i am not 100% convinced about `boundedbykeys` -- no better suggestion atm though. maybe tomorrow, or anybody else has some more ideas? maybe: `bufferconfig.maxrecords().withmaxrecords()` ? `bufferconfig.maxbytes().withmaxbytes()`?",0,0.9232050776481628
218840039,5567,vvcephei,2018-09-19T15:00:07Z,"sure, will do right now... including the cover page.",0,0.9905173182487488
218854676,5567,vvcephei,2018-09-19T15:36:19Z,"your example use case is legitimate, and it is indeed something that we sacrifice here. allow me to paraphrase: [code block] this was a point of discussion early on in the kip. the downside of this api is that querying ""count"" and observing ""output"", we will see divergent results, since ""count"" will permit some records that the suppression drops (say, any record that arrives more than 10ms later than its window). we felt that if the operator's job is to emit only ""final result"" of the window's aggregation, then that's exactly what it should do. redefining the window parameters is out of scope. however, to your second comment, i didn't follow. we don't _just_ offer `untilwindowcloses`. you could alternatively do: [code block] this won't give you ""final results"", since it will still emit updates if they are needed. final thought: like i said, i don't think it's unreasonable what you proposed, but i think it's better to start with something simple and safe. if people are asking for this api later on, we can always add it.",0,0.9002400636672974
218855860,5567,vvcephei,2018-09-19T15:39:04Z,"not in this case, since the sentence is in future tense. if i changed the verb to `would`, then it would be subjunctive, and we should say ""passed"" and ""expired"".",0,0.9916567802429199
218856509,5567,vvcephei,2018-09-19T15:40:45Z,"because the upstream state is updated immediately, but the suppression buffers the update and only emits it after the grace period passes. _then_ they will be consistent.",0,0.9914564490318298
218864237,5567,vvcephei,2018-09-19T15:59:54Z,"i've taken these naming suggestions. re: `eagerbufferconfig` -> `bufferconfig`, this works perfectly, it just didn't occur to me!",1,0.6297056674957275
218864734,5567,vvcephei,2018-09-19T16:01:10Z,"as discussed elsewhere, this is not a default. it's just the (only) grace period.",0,0.9872909188270569
218867967,5567,vvcephei,2018-09-19T16:10:53Z,i've imported 12mb of javascript libraries to italicize this word. i hope that's ok.,1,0.913523256778717
218918921,5567,vvcephei,2018-09-19T18:38:52Z,"this is the ""partially built"" config you get when you call `untilwindowclose`. it's only partial because we need to get the grace period during the topology build.",0,0.9930174350738525
218958071,5567,mjsax,2018-09-19T20:47:00Z,ack. thanks for clarification. it's a complex discussion... sorry for repeating part of the kip discussion here.,-1,0.993520200252533
218958929,5567,mjsax,2018-09-19T20:49:50Z,"grammar... at least i can play the ""i am not a native speaker""-card :)",1,0.9885125160217285
218958970,5567,vvcephei,2018-09-19T20:50:00Z,no worries. there are indeed a lot of nuances to keep track of.,1,0.5138577818870544
218959457,5567,vvcephei,2018-09-19T20:51:41Z,"heh, no worries. hope i didn't come on too strong.",1,0.8232677578926086
218959897,5567,mjsax,2018-09-19T20:53:04Z,"that is only regular latency. also, suppress did not emit anything before -- i wouldn't the ""missing result"" not consider an inconsistency? i understand what you are trying to say, but ""eventual consistency"" might not be the best term here imho. (might be a nitpick though...)",0,0.8981801867485046
218962219,5567,vvcephei,2018-09-19T21:00:43Z,"that is a good point. i was thinking of ""final results emitted"" in aggregate, as in the downstream state is eventually consistent with the upstream state. it sounds like your reading is more like ""each result emitted is eventually consistent with its upstream version"". i think this reading is actually the more likely one. and, as you point out, this statement is almost nonsense: if you look at each result when it gets emitted, it is fully consistent with the upstream state. and of course, ""eventual consistency"" as a term probably opens up a whole bag of worms we don't want to deal with anyway, as people may bring assumptions (and bad associations) from distributed databases. i'll just say ""will match the upstream"" instead.",0,0.557938277721405
219002231,5567,mjsax,2018-09-20T00:14:40Z,sounds good.,1,0.9417163729667664
219380904,5567,mjsax,2018-09-21T04:33:21Z,"do we need this here? ie, do we care if `streamsconfig` is logged in the test? if we do care, it might be good to do one pr that fixes it for all test? or at least make `internslstreamsconfig` it's own class for sharing?",0,0.992931604385376
219381301,5567,mjsax,2018-09-21T04:37:44Z,meta comment: why is this called `initialized`? or should it be `initialize` ? where does it come from? could we fix it? or is it public api?,0,0.9934198260307312
219381463,5567,mjsax,2018-09-21T04:39:42Z,nit: simply to `private static long anylong = 5;`,0,0.9900160431861877
219381518,5567,mjsax,2018-09-21T04:40:14Z,as above,0,0.9391705989837646
219381601,5567,mjsax,2018-09-21T04:41:04Z,don't understand the test name. seem you test for `shouldemitimmediatelyifuntiltimelimitiszero` ?,0,0.9583008289337158
219382014,5567,mjsax,2018-09-21T04:43:38Z,as above,0,0.9391705989837646
219383229,5567,mjsax,2018-09-21T04:51:40Z,"why do we use a stateless here and a stateful above? if you want to test both cases, might be worth to add corresponding standalone tests?",0,0.9904929995536804
219383308,5567,mjsax,2018-09-21T04:52:39Z,wondering if this test subsumes the test from above?,0,0.99081951379776
219384557,5567,mjsax,2018-09-21T05:04:20Z,"if you don't trust the regular cleanup, the question is why? also, should we apply this patter to other tests, too?",0,0.9512595534324646
219384803,5567,mjsax,2018-09-21T05:05:27Z,"this class seems to be duplicated below -- even if it's trivial, might be worth to share the code?",0,0.9651471972465515
219385047,5567,mjsax,2018-09-21T05:08:28Z,this can be an `else` as `committransaction()` would flush -- not even sure if flushing would be valid without calling `begintransaction()` before,0,0.9933403134346008
219385150,5567,mjsax,2018-09-21T05:09:39Z,"not sure if i understand. if it's a the same argument, could you not use `integrationtestutils.waitutill..` twice instead of duplicating the code?",0,0.9488226175308228
219516422,5567,vvcephei,2018-09-21T14:26:31Z,"this change does fix it for all tests that use the mockprocessorcontext. i'm happy to remove this change from this pr and do a separate one, if you're not happy with the current state of it. i wouldn't want to mess with extracting it and bloating the current pr even more than it currently is. i think it's better not to log the config for unit tests. i disabled it because the extra logging made it hard for me to read the unit test output. logging the config is really only useful during runtime so we know what configurations people are running when they post logs to the mailing list. when a test fails, you can easily just look at the test's configuration. bill brought this up earlier. i can make a non-logging config for sharing between mockprocessorcontext and the topologytestdriver. i'm hesitant to share the config class between the test utils and production code, as the risk of making an apparently harmless change in one context and screwing up the other is non-trivial. let me know if you want me to remove this from this pr now, or i can also just create a jira to make a class for the test-utils to share.",1,0.9133430123329163
219516922,5567,vvcephei,2018-09-21T14:28:15Z,it's in internalprocessorcontext. i'll fix it in a separate pr today.,0,0.9883233308792114
219517355,5567,vvcephei,2018-09-21T14:29:27Z,"uh, yeah, i changed the api and not the test name :/",-1,0.9895758628845215
219536345,5567,vvcephei,2018-09-21T15:25:42Z,i'll check...,0,0.9501587748527527
219536496,5567,vvcephei,2018-09-21T15:26:10Z,"ah, ok.",0,0.844211757183075
219540617,5567,vvcephei,2018-09-21T15:38:56Z,"ah, my apologies to . you are right. this is not the same argument as above, and the `waituntilminrecordsreceived` is fine here.",-1,0.9629794955253601
219544268,5567,vvcephei,2018-09-21T15:50:06Z,"specifically, the ""if"" i described above happens to me when i am debugging integration tests. if you set a breakpoint and then hit the ""stop"" button, it doesn't get a chance to run the normal ""after"" cleanup. depending on whether the test uses a randomized state directory or not, this will either give you dirty state for the next run, or it'll just consume more and more disk space in `/tmp` until you run out. i have had both happen to me in the last few months. i do think we should use the same pattern for all the integration tests.",0,0.9723103046417236
219544784,5567,vvcephei,2018-09-21T15:52:00Z,"yes, now it does. they were separate when this method was checking for an exception. good catch!",1,0.9938206076622009
219546526,5567,vvcephei,2018-09-21T15:57:30Z,"the stateless node is the starting point for the search. the two parents are stateful nodes because the test needs the parents to be windowed aggregations, which are stateful. the child node could be stateful as well, but it's not necessary. do you think this test should be duplicated to make sure the search works using both a stateless and a stateful processing code as the starting point?",0,0.9937041401863098
219551965,5567,vvcephei,2018-09-21T16:16:47Z,"ok, here you go: [a link] i'll pull this code from this pr.",0,0.9818887114524841
219553532,5567,vvcephei,2018-09-21T16:22:11Z,here you go: [a link],0,0.9867554903030396
219597029,5567,mjsax,2018-09-21T18:58:08Z,"i understood the setup -- the question is, is there any difference in stateful/stateless parent that is worth testing? if not, we should use the same for all tests (otherwise, it's confusion --- at least to me -> ""why do you need to use the one or the other?"" question arrises)",0,0.9597057104110718
710561967,11331,jolshan,2021-09-16T23:19:51Z,nit: remove comment -- we add unresolved names now too.,0,0.9907398223876953
710590303,11331,jolshan,2021-09-16T23:59:44Z,can remove redundant this.topic == null,0,0.9796786308288574
710592488,11331,jolshan,2021-09-17T00:03:37Z,since we moved an inconsistent topic id check to the fetchresponse.of method we may want to remove this and similar checks in other contexts,0,0.9937532544136047
710592733,11331,jolshan,2021-09-17T00:04:05Z,nit: fix spacing in imports -- there are a few of these in the pr,0,0.9811919331550598
712488389,11331,jolshan,2021-09-20T20:24:23Z,not sure if i should go through and rename some of these to `topicidpartition`,0,0.958167314529419
712491310,11331,jolshan,2021-09-20T20:29:01Z,nit: spacing,0,0.7450315356254578
712495759,11331,jolshan,2021-09-20T20:35:55Z,"i commented out this test, since i removed the behavior to catch inconsistent ids at this stage. i can try to simulate catching the inconsistent id later, but not sure if that is helpful to show in a test.",0,0.9883137941360474
715684131,11331,dajac,2021-09-24T14:55:31Z,"when a session is used, resolving the topic ids is not really necessary here because we should already have the names in the session or we would resolve them later anyway. i wonder if it would be better to do this entirely in the `fetchmanager.newconext` based on the context type. have you considered something like this?",0,0.9921950101852417
715684533,11331,dajac,2021-09-24T14:56:02Z,do we still need this `sessiontopicids` mapping if we have the topic id in the `topicidpartition`?,0,0.9951499104499817
715685093,11331,dajac,2021-09-24T14:56:44Z,nit: could we add an overload to `partitionresponse` which takes a `topicidpartition`? this would reduce the boiler plate code a bit here.,0,0.994317352771759
715686005,11331,dajac,2021-09-24T14:57:54Z,could we direclty check if the topic name is null here and put the unresolved ones to `erroneous`? this would avoid the filter on the next line.,0,0.9896787405014038
715687416,11331,dajac,2021-09-24T14:59:43Z,should we create `tp` after this check? we could also create a `topicpartition` as we don't really use `topicidpartition` for the metric.,0,0.9949331879615784
715690689,11331,dajac,2021-09-24T15:03:55Z,side note here: i think that we should implement `override def elementkeysareequal(that: any): boolean` from the `implicitlinkedhashcollection.element` interface to make it clear that we do this for comparing elements in the collections.,0,0.9923100471496582
715690947,11331,dajac,2021-09-24T15:04:17Z,could we add a scaladoc for this method which explains what we do and why?,0,0.9916921854019165
715691830,11331,dajac,2021-09-24T15:05:25Z,this might not be necessary if we won't resolve topic ids in the request in all cases (see my previous comment).,0,0.9918963313102722
715695751,11331,dajac,2021-09-24T15:10:21Z,"do we still need to return `inconsistent_topic_id` a top level error? fetcher prior to this change would need it, for sure. with this pr, we actually don't want the fetcher to treat it as a top level error but rather as a partition error. we need to think/discuss this a little more, i think.",0,0.9510554671287537
715697860,11331,dajac,2021-09-24T15:13:12Z,not related to this line. don't wee need to update the fetcher to handle the topic id errors at the partition level?,0,0.9395998120307922
715735268,11331,jolshan,2021-09-24T16:04:14Z,we could i suppose? i think the only difference is whether we pass in these values or the fetch request itself (+ topicname map). i don't know if how we handle changes based on context type (besides full/sessionless sessions not having forgotten topics). we could save time translating though if we end up having something like an error session.,0,0.9744521975517273
715736288,11331,jolshan,2021-09-24T16:05:50Z,hmmm maybe not. looks like i just put into this map but never get anything.,0,0.9538102746009827
715738000,11331,jolshan,2021-09-24T16:08:24Z,yes we will need to do that.,0,0.9859325289726257
715740312,11331,jolshan,2021-09-24T16:11:26Z,"yeah. we can change this but the issue was with how we deal with this partition after the error is returned. with the changes to the fetchsessionhandler, we will be able to distinguish the topics, but the implementation i have now still delays partitions on a topic partition level. we don't want to delay the topic partition with the valid id though! there may be something we can do to handle this case.",0,0.6480611562728882
715740801,11331,jolshan,2021-09-24T16:12:12Z,we should do that in addition to this method?,0,0.993934690952301
715743267,11331,jolshan,2021-09-24T16:16:04Z,"i'm not sure i follow here. we have an unresolved partition in the session and we are updating it. why would we not resolve the partition? i suppose it will get picked up by the foreach partition resolving process, but not sure how the earlier comment applies here.",0,0.6958785057067871
718910814,11331,jolshan,2021-09-29T21:51:26Z,it seems like right now `elementkeysareequal` is just `equals`. is the idea in implementing this to prevent someone else from doing so and not using `equals`/the logic from equals?,0,0.9910777807235718
718911636,11331,jolshan,2021-09-29T21:53:20Z,or is it that the javadoc says things like `key.elementkeysareequal(e) and key.hashcode() == e.hashcode()` so we should be using elementkeysareequal in fetchsession?,0,0.995426595211029
718912221,11331,jolshan,2021-09-29T21:54:28Z,^ this is still something we need to resolve.,0,0.9659808874130249
719649068,11331,jolshan,2021-09-30T18:15:00Z,reassigning partitions takes a topic id partition unfortunately. but i suppose we can change that. not sure if we want to distinguish between reassigning partitions if we had two with the same name in the session.,0,0.6551979780197144
719668223,11331,jolshan,2021-09-30T18:42:24Z,"for the replica fetcher, we could choose not delay partitions with this error. seems like in the fetcher, we just choose whether to update metadata. so maybe this won't be too difficult. alternatively, we change the fetching flow to contain topic id earlier in the process and so we can include in the error response as well. that would be a lot of work. still need to think through the current setup to make sure we aren't losing critical data in this state.",0,0.9859498143196106
727155822,11331,dajac,2021-10-12T13:48:07Z,"i have been looking at the changes in the `fetchsessionhandler` as well at the changes in the related classes. i am a bit worried by two things: 1) the `fetchsessionhandler` is quite complicated now, at least a bit more than before; and 2) the reliance on the request version is spread in many places now. it seems that we could get away with a simpler solution which, i think, cover all the cases as well. at the moment in the `fetchsessionhandler`, we track the `added`, `removed` and `altered` partitions and the `fetchrequest` is constructed based `next` (`added` + `altered`) and `removed`. now imagine that we would track another list `replaced` (or `upgraded`...). we would add a partition to this list when we detect that the topic id of the partition in `next` is different from the one in the session. then, we would pass that new list to the `fetchrequestbuilder` as well. in the builder, we would add it to the forgotten set if version >= 13 or ignore it otherwise. i have tried to implement this based on `trunk`: [a link] i think that we should be able to do something similar based on your version which uses `topicidpartition`. the pros is that the version handling remains in the `fetchrequest` class. the cons is that it does not allow to restart the session immediately without doing a round-trip to the broker, which is not a big deal as this could only happen during the upgrade. what do you think? would this approach cover all the cases?",-1,0.501447856426239
727909392,11331,dajac,2021-10-13T10:12:09Z,i have simplified the code and removed a few maps along the way. here is the diff: [a link],0,0.9821017384529114
727996093,11331,dajac,2021-10-13T12:12:52Z,with ismael's pr ([a link] this trick does not work any more. we need to think about an alternative/better approach.,0,0.9545193314552307
728096221,11331,ijuma,2021-10-13T14:00:29Z,"hmm, how does my pr affect this?",0,0.7757118940353394
728115288,11331,dajac,2021-10-13T14:19:30Z,"actually, you're right. that is not entirely true. i thought that the `requirenonnull` for the `topic` in one of the [a link] would prevent this to work. however as we use the other `topicidpartition` constructor in this case, it is not impacted by the `requirenonnull`.",0,0.9873440265655518
728124707,11331,dajac,2021-10-13T14:28:47Z,"in this case, it would be nice if we would have a `topicidpartition` which contains an optional topic name. for the context, the issue is that we might have partitions in the fetch requests for which the topic name is unknown or not yet known by the broker.",0,0.9939540028572083
728127262,11331,ijuma,2021-10-13T14:31:14Z,"we should probably remove that non null check, since it's weird to have it only in that one path. i can submit a pr.",-1,0.9328174591064453
728132912,11331,dajac,2021-10-13T14:36:38Z,"sounds good, thanks!",1,0.9953889846801758
728455837,11331,jolshan,2021-10-13T21:20:16Z,"i think we may even be able to get away with fewer maps. i see in the commit you have we add to topicids at the start but i'm not sure that works if we have more than one id for a topic. i was thinking if we stored the id in the fetch data, we wouldn't need to build a map from ids to names. do we still use that anywhere?",0,0.9726170301437378
735854783,11331,jolshan,2021-10-25T18:25:53Z,todo: we can also put toforget back after the update step as we handle forgetting using different ids.,0,0.9900895357131958
735863741,11331,jolshan,2021-10-25T18:38:22Z,"todo 2: if we have an update with an unresolved name, should we change the name to be unresolved here? i think we should but want to confirm.",0,0.992117702960968
735935021,11331,jolshan,2021-10-25T20:22:50Z,do we not care to change ids if the data is equal? we wouldn't usually send a request and i don't know if it is possible to even have the same data in such a case.,0,0.8889608383178711
741789472,11331,dajac,2021-11-03T10:20:45Z,could we iterate over `sessionpartitions` and directly populate `sessiontopicnames` by using `putifabsent` or even `put`? the grouping seems unnecessary to me here unless i am missing something.,0,0.9853976964950562
741791658,11331,dajac,2021-11-03T10:22:16Z,"as `tosend` is not used before l288, how about putting this line over there?",0,0.9935421943664551
741793046,11331,dajac,2021-11-03T10:23:03Z,not related to this pr but could we use `collections.emtpymap` here? that would avoid allocating a `hashmap` all the times.,0,0.9944943785667419
741795602,11331,dajac,2021-11-03T10:25:08Z,same comment as before.,0,0.9839754104614258
741796143,11331,dajac,2021-11-03T10:25:34Z,nit: could we align like it was before?,0,0.9865744709968567
741796825,11331,dajac,2021-11-03T10:26:09Z,nit: this change and the following ones do not seem necessary. i would revert them back.,0,0.7924155592918396
741797904,11331,dajac,2021-11-03T10:27:04Z,is this method still used? i can't find any usages of it.,0,0.8790721893310547
741798898,11331,dajac,2021-11-03T10:27:52Z,it seems that this method is not used anymore. could we remove it?,0,0.9792293310165405
741801854,11331,dajac,2021-11-03T10:30:20Z,"this block is identical to the previous one. should we pull it into a helper method? (yeah, i know, i wrote this...)",0,0.9874603748321533
741804871,11331,dajac,2021-11-03T10:32:43Z,should we add a comment here which explains that the topic name might be null in `topicidpartition` if we were unable to resolve it?,0,0.9957926273345947
741806142,11331,dajac,2021-11-03T10:33:46Z,i would also add a small comment here.,0,0.9878697991371155
741817990,11331,dajac,2021-11-03T10:46:40Z,"putting this here but it is not related to this line. it seems that we have an opportunity in `processfetchrequest` to better handle the `fetch_session_topic_id_error` error. at the moment, it delays all the partitions. it seems to me that we could retry directly, no? if you agree, we could file a jira and address this in a subsequent pr.",0,0.978409469127655
741818303,11331,dajac,2021-11-03T10:47:08Z,"yeah, that would be great. `topicpartition.topicpartition` looks really weird while reading.",-1,0.9474335312843323
741823983,11331,dajac,2021-11-03T10:55:09Z,nit: should we format the code as follow? [code block],0,0.9931366443634033
741826013,11331,dajac,2021-11-03T10:58:00Z,`that.canequal(this)` seems weird to me. it seems that we could just remove it.,-1,0.9750006198883057
741938548,11331,dajac,2021-11-03T13:30:57Z,nit: the if/else inline reads a bit weird. should we extract the if/else? [code block],-1,0.9783464074134827
741939805,11331,dajac,2021-11-03T13:32:18Z,nit: we could add another constructor which takes a `topicidpartition`.,0,0.9940299987792969
741940362,11331,dajac,2021-11-03T13:32:52Z,is `usestopicids` used anywhere in this method?,0,0.9946644306182861
741943413,11331,dajac,2021-11-03T13:35:54Z,nit: how about naming it `cachedpartitionkey`? we could also benefits from passing `topicidpartition` to the constructor directly.,0,0.9950661659240723
741945969,11331,dajac,2021-11-03T13:38:24Z,nit: it might be better to encapsulate this in `cachedpartition`. we could add a method called `maybesettopicname` or piggy back on `updaterequestparams`.,0,0.9955965876579285
741964245,11331,dajac,2021-11-03T13:56:41Z,nit: there is an extra space after `== null`,0,0.9931778907775879
741967434,11331,dajac,2021-11-03T13:59:40Z,nit: we can remove the parenthesis here.,0,0.979286789894104
741968413,11331,dajac,2021-11-03T14:00:35Z,i wonder if we should reply with `unknown_topic_id` for the topics whose are not resolved.,0,0.9694375395774841
741968554,11331,dajac,2021-11-03T14:00:43Z,nit: we can remove the parenthesis here.,0,0.979286789894104
741969873,11331,dajac,2021-11-03T14:02:00Z,nit: we can use `tp.partition` here and a few other places.,0,0.9901667833328247
741974511,11331,dajac,2021-11-03T14:06:51Z,nit: parenthesis after `partitionindex` could be omitted.,0,0.99196457862854
741976525,11331,dajac,2021-11-03T14:08:55Z,nit: parenthesis after partitionindex could be omitted.,0,0.9870922565460205
741982676,11331,dajac,2021-11-03T14:15:06Z,i already mentioned this before but it seems that we could retry immediately in this case when the session was upgraded/downgraded. that would avoid having to wait for the backoff.,0,0.9904966354370117
741983857,11331,dajac,2021-11-03T14:16:13Z,nit: `topicidpartition.topic` should work.,0,0.9923417568206787
741985410,11331,dajac,2021-11-03T14:17:34Z,nit: we could add another `apply` method to `topicpartitionoperationkey` which accepts a `topicidpartition`. that will be convenient.,0,0.9913663268089294
741987160,11331,dajac,2021-11-03T14:19:01Z,nit: `tp.topic`,0,0.9920427203178406
741990473,11331,dajac,2021-11-03T14:22:18Z,do we still use this constructor?,0,0.9907592535018921
742113471,11331,jolshan,2021-11-03T16:20:20Z,the idea was to not do a put operation for every partition but instead every topic. maybe grouping is slower though.,0,0.9538355469703674
742114292,11331,jolshan,2021-11-03T16:21:11Z,good catch,1,0.981269359588623
742116109,11331,jolshan,2021-11-03T16:23:08Z,"fetch_session_topic_id_error occurs when we switch from not using topic ids in the request to using them (or vice versa). i think maybe we'd want to delay partitions to get the latest metadata, but not sure.",0,0.9703866243362427
742119691,11331,jolshan,2021-11-03T16:26:48Z,hmmm. so we'd sort out the ones with null names? what benefit are we thinking we'll get from this?,0,0.9648276567459106
742121483,11331,jolshan,2021-11-03T16:28:40Z,i think i wrote all of these before the class was updated. but i will change them. :),1,0.9942513704299927
742232425,11331,jolshan,2021-11-03T18:40:50Z,yeah. it's used in 49 places. some of the places i intentionally left as zero uuids. i can convert all of them to uuid.zero_uuid if we think this may be bug prone.,0,0.5942862033843994
742285803,11331,jolshan,2021-11-03T19:58:44Z,"this was here before my change, but i can remove it.",0,0.9767773747444153
742920899,11331,dajac,2021-11-04T14:58:23Z,nit: is it worth bringing back this line on the previous one as there is space now? it might be too long though.,0,0.9665172100067139
742926299,11331,dajac,2021-11-04T15:03:40Z,would it be more appropriate to move the above assertions to `fetchrequesttest`?,0,0.9955025315284729
742928420,11331,dajac,2021-11-04T15:05:55Z,"should we also test when the current topic-partition in the session does not have a topic id? in this case, it should not be added to the `toreplace` set.",0,0.9951679706573486
742931656,11331,dajac,2021-11-04T15:09:21Z,why do we use 12 here?,0,0.9855835437774658
742933244,11331,dajac,2021-11-04T15:11:00Z,it is curious that we don't assert the forgotten partitions here. is there a reason?,0,0.7533537745475769
742935279,11331,dajac,2021-11-04T15:13:04Z,is there any reason for this change?,0,0.9875248670578003
742936005,11331,dajac,2021-11-04T15:13:51Z,do we still need this change?,0,0.9877305626869202
742938518,11331,dajac,2021-11-04T15:16:26Z,do we still need this change?,0,0.9877305626869202
742938637,11331,dajac,2021-11-04T15:16:34Z,ditto. there is a few other cases in this file.,0,0.5822722911834717
742939518,11331,dajac,2021-11-04T15:17:24Z,nit: there are two spaces after `=`.,0,0.9857832193374634
742944210,11331,dajac,2021-11-04T15:22:16Z,the pr changed how some errors are handled in the `fetcher`. do we have any tests for this new behavior?,0,0.9924151301383972
742950222,11331,dajac,2021-11-04T15:28:22Z,nit: it seems that we could use `topicidpartition` directly and remove `topicids` map entirely. we could also pass the `topicidpartition` to `buildfetchmetadata`.,0,0.995197594165802
742954020,11331,dajac,2021-11-04T15:32:15Z,`0.equals(0)` was very likely put here by mistake.,0,0.9898027777671814
742963289,11331,dajac,2021-11-04T15:42:04Z,nit: we could get the topic id from `tp*.topicid`.,0,0.9934890270233154
742968374,11331,dajac,2021-11-04T15:47:22Z,nit: i would expand this comment a little and stress the fact that topic names are lazily resolved when the partitions are iterated over.,0,0.9811643958091736
742969700,11331,dajac,2021-11-04T15:48:38Z,should we assert that the `topicidpartition` received here contains the topic name?,0,0.9953910112380981
742975252,11331,dajac,2021-11-04T15:54:17Z,should we iterate over the partitions in the context to check the `topicidpartition`?,0,0.9953562617301941
742978184,11331,dajac,2021-11-04T15:57:14Z,it seems to be that it would be simpler to declare `fooid` and `barid` and to use them instead of getting them from the map.,0,0.9936792254447937
742979446,11331,dajac,2021-11-04T15:58:29Z,i wonder if we should add a third topic which is never resolved. what do you think?,0,0.7605817317962646
742987345,11331,dajac,2021-11-04T16:06:50Z,should we add any tests for the new logic in kafkaapis?,0,0.9949343800544739
742993451,11331,dajac,2021-11-04T16:13:22Z,this is not ideal. could we validate that the topic id is correct as well?,-1,0.8973722457885742
743011890,11331,dajac,2021-11-04T16:33:33Z,"i wonder if we could add a few more unit tests. for instance, we should test the equals/hash methods of the cachedpartition (and possibly other methods there). we might want to add some for other classes as well. what do you think?",0,0.9894863367080688
743041695,11331,dajac,2021-11-04T17:06:58Z,"i think that the grouping is slower because it has to allocate another map, sets for each uuid, etc.",0,0.8881844282150269
743044369,11331,dajac,2021-11-04T17:10:17Z,"i think that would for instance happen when the controller fails over to an older ibp during an upgrade. this should remove the topic ids which means that v12 will be used for the next fetch request and trigger a fetch_session_topic_id_error. in this particular case, re-trying directly would be the optimal way to proceed for a follower. i wonder if they are other cases to consider here. for the consumer, it is definitely different.",0,0.981837809085846
743044970,11331,dajac,2021-11-04T17:10:57Z,right. it seems to be that the `canequal(this)` does not make any sense here. could you double check?,0,0.988730251789093
743046003,11331,dajac,2021-11-04T17:12:18Z,i guess that it does not change much in the end. i was considering this in order to be consistent with how we handle this for the consumer.,0,0.977128803730011
743046927,11331,dajac,2021-11-04T17:13:29Z,"yeah, that's a good question. i guess that that constructor is convenient for tests but might be bug prone in the regular code. i am tempted to remove it entirely.... what do you think?",-1,0.9373082518577576
743239514,11331,jolshan,2021-11-04T22:13:41Z,i moved some back.,0,0.9562954306602478
743240074,11331,jolshan,2021-11-04T22:14:51Z,ah good catch.,1,0.9841926693916321
743240526,11331,jolshan,2021-11-04T22:15:49Z,"to clarify -- are you referring to a case where we upgraded? ie, it started with no id in the first request and added one in the second request?",0,0.9932515025138855
743241204,11331,jolshan,2021-11-04T22:17:09Z,i could theoretically check replace in the other test that checks multiple scenarios,0,0.9905260801315308
743241513,11331,jolshan,2021-11-04T22:17:46Z,i'm not sure i follow. did you mean the other test file?,-1,0.5477884411811829
743242346,11331,jolshan,2021-11-04T22:19:26Z,"this was the case i tested when we had the bug of sending v13 for this scenario. the idea was that the session was empty and we had the correct topic id usage, not whether forgotten partitions were added correctly. i can add a check for forgotten partitions for completeness.",0,0.9925538897514343
743242849,11331,jolshan,2021-11-04T22:20:26Z,it likely had something to do with how the mock client was handling metadata. but that may have been for the older version where we checked nodeapiversion. i can try to switch it back.,0,0.9866739511489868
743243111,11331,jolshan,2021-11-04T22:20:49Z,nope. looks like another change i forgot to cleanup.,0,0.5156524777412415
743243975,11331,jolshan,2021-11-04T22:22:40Z,i think i'm misunderstanding something here. did you mean to say append?,-1,0.7337347865104675
743349235,11331,jolshan,2021-11-05T02:23:35Z,are you referring to how we changed unknown_topic_id and inconsistent_topic_id? for these cases we have testfetchinconsistenttopicid and testfetchunknowntopicid which check that we update the metadata for a partition level error.,0,0.9943331480026245
743349370,11331,jolshan,2021-11-05T02:23:52Z,these tests changed from returning a top level error to partition level error.,0,0.9900153279304504
743350813,11331,jolshan,2021-11-05T02:28:10Z,what logic are we thinking? checking that the unresolved topics are handled correctly?,0,0.9782334566116333
743351017,11331,jolshan,2021-11-05T02:28:54Z,i can add some for the equals and hash methods in cachedpartition. what classes were you thinking of for others?,0,0.991797685623169
743354926,11331,jolshan,2021-11-05T02:42:15Z,hmm. i'm not quite sure why this would not make sense. i believe it is checking the types are correct.,-1,0.5523940324783325
743355748,11331,jolshan,2021-11-05T02:44:59Z,i think we would want to keep the authorization error. since it just logs a message. the unknown_topic_id error would request a metadata update which doesn't make sense when there is an authorization error.,0,0.9652429819107056
743360648,11331,jolshan,2021-11-05T03:01:38Z,or are you just referring to a case where we don't ever have topic ids?,0,0.9835414290428162
743361897,11331,jolshan,2021-11-05T03:05:57Z,looks like most of these changes were done by this commit: [a link] so i can remove them pretty easily.,0,0.9773649573326111
743365481,11331,jolshan,2021-11-05T03:18:35Z,i have no idea why this is here.,-1,0.8848277926445007
743369512,11331,jolshan,2021-11-05T03:33:09Z,"not quite sure what you meant here but i added this for now: `context1.foreachpartition((topicidpartition, _) => assertequals(topicids.get(""foo""), topicidpartition.topicid))`",0,0.986351728439331
743370419,11331,jolshan,2021-11-05T03:36:47Z,"we could do that, but then this check will be a bit more complicated. `context2.foreachpartition((topicidpartition, _) => assertequals(topicnames.get(topicidpartition.topicid), topicidpartition.topic))`",0,0.9937179088592529
743370521,11331,jolshan,2021-11-05T03:37:06Z,i can think more on this.,0,0.9475715160369873
743370708,11331,jolshan,2021-11-05T03:37:39Z,still todo for friday,0,0.9818063974380493
743574922,11331,dajac,2021-11-05T11:16:18Z,"sorry, i meant below assertions not above. yes, it seems that they are testing the logic of the `fetchrequest` itself and not really the logic of the fetchsessionhandler.",-1,0.9909194707870483
743575635,11331,dajac,2021-11-05T11:17:38Z,correct. i was referring to the upgrade case. we might need to handle the downgrade case for [a link],0,0.9767571091651917
743576928,11331,dajac,2021-11-05T11:20:00Z,"yeah, it would be good to assert what we expect in `data2` for completeness.",0,0.9672805666923523
743577292,11331,dajac,2021-11-05T11:20:37Z,"yes, i was referring to those. ack, i missed them during my first read.",0,0.9212363958358765
743578252,11331,dajac,2021-11-05T11:22:24Z,"yeah, i meant exactly that. how about using `assertpartitionsorder` helper? the assertion would be more complete.",0,0.9889819025993347
743578382,11331,dajac,2021-11-05T11:22:41Z,you could use `assertpartitionsorder` helper here as well.,0,0.9943667054176331
743578530,11331,dajac,2021-11-05T11:22:54Z,that is right.,0,0.9661063551902771
743745314,11331,dajac,2021-11-05T15:09:43Z,should we add or extend a test in `fetchertest` to cover this change? i would like to have one which ensure that the request sent is populated correctly (especially the replaced part) by the fetcher based on the session handler. it seems that we don't have such test in the suite at the moment.,0,0.9937992691993713
743749915,11331,dajac,2021-11-05T15:15:11Z,should we add a few unit tests to validate the changes that we have done in this class? we could add a few to fetchrequesttest (not use if it already exists though).,0,0.994469165802002
743750508,11331,dajac,2021-11-05T15:15:55Z,do we have a unit test for this one and for `forgottentopics`?,0,0.9947468638420105
743751246,11331,dajac,2021-11-05T15:16:48Z,there are a few more cases where we could put the partition data back on the previous line in this file.,0,0.9915890097618103
743753319,11331,dajac,2021-11-05T15:19:17Z,"sorry, i wanted to say happen.",-1,0.9914630055427551
743753874,11331,dajac,2021-11-05T15:19:55Z,"anyway, we don't need to address this in this pr. i just wanted to point out that there is an opportunity for an improvement.",0,0.9783713817596436
743755936,11331,dajac,2021-11-05T15:22:10Z,do we have unit tests covering those cases? there are almost no changes in `abstractfetcherthreadtest` so it seems that we don't. are they somewhere else perhaps?,0,0.9928942322731018
743756690,11331,dajac,2021-11-05T15:23:01Z,i guess that we could remove it now.,0,0.957014262676239
743759128,11331,dajac,2021-11-05T15:25:46Z,"should we use the same name for both `maybesetunknownname` and `mayberesolveunknownname`? i guess that you could differ by their argument. if we add unit tests for other methods of this class, should we cover all the methods that we have changed or added as well?",0,0.9924271106719971
743763229,11331,dajac,2021-11-05T15:30:37Z,do we have tests verifying this change?,0,0.9907329082489014
743764793,11331,dajac,2021-11-05T15:32:14Z,should we use `equals` instead of `==`? we use `equals` at l304 btw.,0,0.9946107864379883
743830587,11331,jolshan,2021-11-05T16:56:46Z,so you are asking for a test that is checking the fetcher builds the request correctly? is this a test for the fetcher or the builder?,0,0.9938722848892212
743830862,11331,jolshan,2021-11-05T16:57:08Z,i can do that but it will take some time. :grinning_face_with_sweat:,0,0.9877772927284241
743836225,11331,dajac,2021-11-05T17:04:29Z,we should have a test in the fetcher which ensure that the builder received the correct information. then we could have one for the request which ensure that the builder does its job correctly as well.,0,0.9903697371482849
743839587,11331,jolshan,2021-11-05T17:09:17Z,"the part i don't understand is that this building is in a method that sends the requests. i'm not sure how to pull that out and test specifically that the fetcher is getting the correct info. the fetcher is simply pulling from the fetchsessionhandler's build fetchrequestdata, so i feel like that is sufficient unless i'm missing something.",0,0.7906579971313477
743841128,11331,jolshan,2021-11-05T17:11:26Z,"i thought about the same name, but i thought it was a slightly different approach --> looking up in the map where it is maybe there vs. supplying the name.",0,0.9770399332046509
743908454,11331,dajac,2021-11-05T18:56:22Z,"right. you might have to assert on the request in the fetcher as well. as you said, we can't really get the data out from the builder otherwise.",0,0.9842087626457214
743909554,11331,dajac,2021-11-05T18:58:13Z,"yeah, i agree with you. perhaps, we could just remove the maybesettopicname and move its logic into the update request params method.",0,0.9651626348495483
743949497,11331,jolshan,2021-11-05T20:09:27Z,"ok, so we'll pass a name and the reqdata in that method.",0,0.983269453048706
743968305,11331,jolshan,2021-11-05T20:47:38Z,so i can write a separate callback for each one that checks the id.,0,0.9915209412574768
743973388,11331,jolshan,2021-11-05T20:58:27Z,"hmm, so this looks like another case of not having a test file for the java (unit test version) i can create that and add the tests you've been mentioning here. alternatively i can put the tests in the scala integration test file. seems like there are unit tests mixed in there too.",0,0.9852873086929321
743973792,11331,jolshan,2021-11-05T20:59:21Z,so #11459 doesn't touch the fetchsessionhandler code. but i can still add these cases.,0,0.9858723282814026
743976846,11331,jolshan,2021-11-05T21:06:19Z,"i don't think processfetchrequest is tested anywhere. there tests for the much higher level method dowork, so i can try to write one like that and check if there is that partition with error?",0,0.9804258346557617
743977547,11331,jolshan,2021-11-05T21:07:56Z,"i think i have the same confusion here as i do for the fetcher tests. i agree that changes should be tested, but i'm not really sure how to do this here.",0,0.840756356716156
743979130,11331,jolshan,2021-11-05T21:11:07Z,"i think for correctness either works, but i will switch to equals for consistency.",0,0.9461157917976379
743981159,11331,jolshan,2021-11-05T21:15:45Z,ah i'm already doing this. :grinning_face_with_sweat: ok. sounds good.,1,0.9660388231277466
743983833,11331,jolshan,2021-11-05T21:21:23Z,sorry i'm still a bit confused. the request is sent in this method. we don't get access to the request. we have access to the data that is tested in fetchsessionhandler and that is passed into this method where the request is built and sent.,-1,0.991435706615448
743997732,11331,jolshan,2021-11-05T21:56:17Z,nice. this works well.,1,0.9864813089370728
744103895,11331,dajac,2021-11-06T09:18:49Z,"we must be able to verify that the request sent out by this method is correct. in the unit tests, we mock the network client for this purpose. if i remember correctly, we can pass a request matcher to it. i need to look into the existing unit tests for this class to see how we have done it for other cases. we might already have tests verifying that the version of the fetch request sent out is correct based on wether topic ids are used or not. if we do, i suppose that we could proceed similarly.",0,0.9869346618652344
744104240,11331,dajac,2021-11-06T09:22:33Z,let's create that file and put new unit tests there. that is the way it should be.,0,0.9885662198066711
744138150,11331,jolshan,2021-11-06T15:41:50Z,got it. i guess i was wondering if there would be an issue if we change semantics/expected flow for fetch again.,0,0.930098831653595
744138204,11331,jolshan,2021-11-06T15:42:12Z,confirmed this was a strange quirk from 4 years ago,0,0.8162731528282166
744177445,11331,jolshan,2021-11-06T22:57:45Z,"seems like the other issue is that fetchsessionhandler.fetchrequestdata constructor is private. so if i want to test in another file i need to either make the constructor public, create a fetchsessionhandler and duplicate the code here, or just put the values into the builder directly (skipping the class). i'm open to just putting the values directly if that makes sense.",0,0.9869502186775208
744875433,11331,dajac,2021-11-08T16:10:05Z,`buildfetch` seems to be well isolated so it should be quite easy to write a few unit tests for it. `buildfetch` returns a `builder` so you will have to build the request in order to inspect it.,0,0.9673448801040649
744877634,11331,dajac,2021-11-08T16:12:31Z,"yeah, that should work. otherwise, we could also make the method package private and add a few unit tests for it.",0,0.9749436378479004
744880575,11331,jolshan,2021-11-08T16:15:40Z,i guess the part i didn't understand is that buildfetch's builder is tested in fetchsessionhandler tests. but i guess there is one more method call we can test.,0,0.9759994745254517
744883112,11331,jolshan,2021-11-08T16:18:27Z,is there a reason we do this? if the previous data had a topic id and this one doesn't we should send a different fetch request version and the session will be closed.,0,0.9904353618621826
744892585,11331,dajac,2021-11-08T16:28:38Z,"without this, when a topic id is set back to ""zero"", the former topic id is added to the replaced set which is a bit unintuitive, i think. in the end, it does not matter too much because the version is downgraded in this case so the replaced set is ignored. i was debating if it worth handling this case explicitly here.",0,0.5641360878944397
744905470,11331,jolshan,2021-11-08T16:43:11Z,"i realize we may still want this as if the partition data is exactly the same, we will actually ignore the downgrade which is not good.",0,0.8704944849014282
744906035,11331,jolshan,2021-11-08T16:43:48Z,i have a test where this happens. :grinning_face_with_sweat:,0,0.9782684445381165
744942958,11331,dajac,2021-11-08T17:27:58Z,right. here i would like to have tests which ensure that the builder is fed correctly based on the fetchsessionhandler's data.,0,0.9851471781730652
745010308,11331,jolshan,2021-11-08T19:00:45Z,do we need to reassign to empty map here?,0,0.9928945899009705
745033891,11331,jolshan,2021-11-08T19:35:27Z,i added the initialization in the other builder since we were missing it.,0,0.9890429377555847
745050242,11331,dajac,2021-11-08T19:59:14Z,that is a good question. i thought that it is better to empty the map if we don't use topic ids instead of keeping a out-of-date mapping. what do you think?,1,0.7885228991508484
745050475,11331,dajac,2021-11-08T19:59:35Z,thanks!,1,0.9051083922386169
745053425,11331,jolshan,2021-11-08T20:04:05Z,i think the session will already have an empty map or close but it don't think it makes a big difference with or without this change.,0,0.9534263014793396
745060151,11331,dajac,2021-11-08T20:14:32Z,i am not sure that i follow. we should only test the fetchrequest/builder in fetchrequesttest.,0,0.49902841448783875
745091391,11331,jolshan,2021-11-08T21:04:31Z,i ended up making the new test file. i was confused because i thought the data object needed to be tested but it doesn't. i think this can be resolved.,-1,0.5553219318389893
745182731,11331,jolshan,2021-11-08T23:56:28Z,"for my understanding, is this line necessary? we are assigning the same topic partition, right?",0,0.9866053462028503
745478693,11331,dajac,2021-11-09T10:24:12Z,nit: it might be worth expanding this comment a little more.,0,0.9484673142433167
745487251,11331,dajac,2021-11-09T10:34:59Z,nit: could we use `assertequals`? the advantage is that it ensure that the map contains only what we want.,0,0.9917126893997192
745488238,11331,dajac,2021-11-09T10:36:18Z,nit: could we use `assertequals` here as well?,0,0.9932299852371216
745492071,11331,dajac,2021-11-09T10:41:12Z,nit: i wonder if doing the following would be a bit more complete? [code block],0,0.9606651663780212
745495072,11331,dajac,2021-11-09T10:45:06Z,"no, it is not. i kept it for completeness.",0,0.9555389881134033
745497189,11331,dajac,2021-11-09T10:47:49Z,nit: could we actually compare the content of both collections instead of only verifying their size? that would be more complete.,0,0.9889801740646362
745499051,11331,dajac,2021-11-09T10:50:23Z,"nit: in this case, we could actually do the following which seems a bit better: [code block] then, we can use `tp.topicpartition` when we need it. what do you think?",0,0.9882351160049438
745499747,11331,dajac,2021-11-09T10:51:11Z,nit: could we put this on the top of the test?,0,0.9902164936065674
745505533,11331,dajac,2021-11-09T10:58:49Z,"nit: would it be simpler to do the following? [code block] we have to use `new topicidpartition(topicid1, new topicpartition(null, 0))` because [a link] is not merged yet. the advantage of this way is that it test the whole map, including the ordering.",0,0.9940919280052185
745506626,11331,dajac,2021-11-09T11:00:14Z,"i am not sure that we gain much by testing this because testing `fetchdata` already verify that all the partitions are included, no?",0,0.9276022911071777
745511442,11331,dajac,2021-11-09T11:06:56Z,"this is a bit weird. i would have expected a `null` as the topic name if `topicnames` does not contain the mapping, no?",-1,0.9875259399414062
745512157,11331,dajac,2021-11-09T11:08:07Z,can't we use `assertequals`? it seems that it should work here.,0,0.9899224638938904
745515647,11331,dajac,2021-11-09T11:13:12Z,"as discussed, we must test this.",0,0.988381564617157
745518340,11331,dajac,2021-11-09T11:16:58Z,nit: should we put `topicid` first to be consistent with `topicidpartition`'s constructor?,0,0.9948248863220215
745518525,11331,dajac,2021-11-09T11:17:17Z,could we add a unit test for this?,0,0.9916877150535583
745518658,11331,dajac,2021-11-09T11:17:30Z,could we add a unit test for this new method?,0,0.9914907813072205
745518818,11331,dajac,2021-11-09T11:17:43Z,could we add a unit test for this one as well?,0,0.9915193915367126
745571481,11331,dajac,2021-11-09T12:31:38Z,"nit: fyi, you could use an anonymous class in this case: ``` val fetcher = new mockfetcherthread(fetchbackoffms = fetchbackoffms) { override def fetchfromleader(fetchrequest: fetchrequest.builder): map[topicpartition, fetchdata] = { } }",0,0.9919012188911438
745576080,11331,dajac,2021-11-09T12:38:04Z,nit: a space is missing before `10`.,0,0.9404938817024231
745576158,11331,dajac,2021-11-09T12:38:10Z,ditto.,0,0.6705162525177002
745577596,11331,dajac,2021-11-09T12:40:05Z,nit: there is an extra space after `foreach(`.,0,0.991609513759613
745580364,11331,dajac,2021-11-09T12:43:45Z,nit: i am not a fan of this. i would usually prefer something like the following in this case. i guess that it is a matter of taste so i leave it up to you. [code block],-1,0.8721795678138733
745595523,11331,dajac,2021-11-09T13:03:52Z,should we assert the content of `context2`?,0,0.9946250319480896
745595783,11331,dajac,2021-11-09T13:04:14Z,"i guess that `respdata1` is used by mistake here, isn't it? this is a good example why it is better to use `assertequals` to verify collections instead of iterating over them. the assertions that you have below have not caught this.",0,0.9898269176483154
745597673,11331,dajac,2021-11-09T13:06:56Z,`startswithtopicids` and `endswithtopicids` are a bit misleading here. i suppose that they refer to either the broker knows about the topic id or not (present in its metadata cache). am i right?,0,0.9557860493659973
745612156,11331,dajac,2021-11-09T13:25:35Z,nit: a space is missing before `{` and `}` should be on a new line for blocks.,0,0.9899889230728149
745612631,11331,dajac,2021-11-09T13:26:10Z,ditto about the code format.,-1,0.719528079032898
745613827,11331,dajac,2021-11-09T13:27:41Z,"the size is implicitly verified by the next assertion. we could remove it, i guess.",0,0.9895648956298828
745613931,11331,dajac,2021-11-09T13:27:47Z,ditto.,0,0.6705162525177002
745615375,11331,dajac,2021-11-09T13:29:29Z,can't we use `assertequals` here?,0,0.994016170501709
745686335,11331,dajac,2021-11-09T14:46:02Z,"thinking a little more about this one. how about doing the following? we could define an helper method `fetchmessages` which wraps `replicamanager.fetchmessages` (takes the same arguments) and returns `seq[(topicidpartition, fetchpartitiondata)]`. this would avoid all these callbacks that we have here.",0,0.9926913380622864
745693355,11331,dajac,2021-11-09T14:52:41Z,"should we do another round before this one to ensure that a partition would be removed from the context while still having an `incrementalfetchcontext`? we could perhaps have multiple partitions in the context, resolved and unresolved, and then we could remove them one by one.",0,0.9947429895401001
745699410,11331,dajac,2021-11-09T14:58:37Z,"should we pass `topicnamesforrequest1` instead of `topicnames` here? in practice, we already use the same mapping in all cases when the context is created.",0,0.9940006136894226
745701165,11331,dajac,2021-11-09T15:00:19Z,should we make it private?,0,0.9907426238059998
745701266,11331,dajac,2021-11-09T15:00:25Z,should we make it private?,0,0.9907426238059998
745751523,11331,dajac,2021-11-09T15:49:55Z,"should we verify what the context contains? this is very likely the most important point to verify in this test, no?",0,0.9784668684005737
745789936,11331,dajac,2021-11-09T16:25:51Z,i find those block of code really hard to read. i wonder if we could simplify them.,-1,0.8512152433395386
745863973,11331,jolshan,2021-11-09T17:47:25Z,is `assertmapequals` not already doing this? it seems like we check all entries and make sure there is nothing left over.,0,0.9922160506248474
745864456,11331,jolshan,2021-11-09T17:47:59Z,unless you are referring to the sessiontopicnames line. :grinning_face_with_sweat:,0,0.9930806756019592
745865347,11331,jolshan,2021-11-09T17:49:03Z,assertequals for the tosend/toreplace lists/map?,0,0.9911269545555115
745867608,11331,jolshan,2021-11-09T17:51:48Z,are we thinking this would be in the if block? or in a separate one outside?,0,0.9945095181465149
745869793,11331,dajac,2021-11-09T17:54:22Z,"yes, i was referring to `sessiontopicnames`.",0,0.9904603958129883
745869947,11331,dajac,2021-11-09T17:54:34Z,right.,0,0.9793882369995117
745871819,11331,dajac,2021-11-09T17:56:55Z,"yeah, that could remain in the if block. we could simply replaces those two lines, i guess.",0,0.9855340719223022
745924906,11331,jolshan,2021-11-09T18:58:38Z,i caught a bug with our partitiondata.equals method from implementing this. (we should be using .equals and not ==),0,0.8071564435958862
745925751,11331,jolshan,2021-11-09T18:59:58Z,"i was mostly testing the serialization here, but maybe that's not important? i can remove if we don't need that.",0,0.965124785900116
745930497,11331,jolshan,2021-11-09T19:06:49Z,the expectedname will be null if it is not in the map. map.get returns null if the id is not in the map.,0,0.9910278916358948
745941900,11331,jolshan,2021-11-09T19:23:09Z,"is this different than assertpartitionsorder(context2, seq(foo0, foo1, emptyzar0))?",0,0.9946585297584534
745942320,11331,jolshan,2021-11-09T19:23:44Z,i can change the ordering of these asserts so they are consistent with the earlier ones,0,0.9891844987869263
745943714,11331,jolshan,2021-11-09T19:25:42Z,you are correct. i can change to `startswithtopicidsinmetadatacache` etc if that is not too verbose.,0,0.9593834280967712
745947154,11331,jolshan,2021-11-09T19:30:38Z,would we pass in the topicidpartition we want to match as well?,0,0.9943893551826477
745963579,11331,dajac,2021-11-09T19:54:23Z,gotcha. i missed it. changing the order to be consistent makes sense.,0,0.797945499420166
745965419,11331,dajac,2021-11-09T19:57:02Z,hum.. i was thinking that the method would return the partitions and we would do the assertion after. that would make the helper generic enough to be reused in other places as well. i guess that either ways would work.,0,0.7116814255714417
746038595,11331,jolshan,2021-11-09T21:01:47Z,oh so we wouldn't do the filter as part of the method?,0,0.9863215088844299
746051435,11331,dajac,2021-11-09T21:14:01Z,correct. the method would return the full response. then we can assert it.,0,0.9914858937263489
746077096,11331,jolshan,2021-11-09T21:56:06Z,we can do that. i believe this is being tested via `testfetchsessionwithunknownid` already. but an explicit test will be good.,0,0.8214952945709229
746078020,11331,jolshan,2021-11-09T21:57:39Z,"i can add another one that is more explicitly testing this method, but it is tested via `testupdatedpartitionresolvesid`",0,0.9938162565231323
746096126,11331,jolshan,2021-11-09T22:28:59Z,"i think the issue with that approach is it doesn't quite cover the four cases, right? i could keep as is, but have a second partition that just uses ids and resolve that one on the second round.",0,0.9497812986373901
746100239,11331,jolshan,2021-11-09T22:36:15Z,hmm. could i also just remove the filter and do that after to use just the single callback?,0,0.9654094576835632
746217460,11331,jolshan,2021-11-10T03:15:51Z,"is this replacing `testupdatedpartitionresolvesid`? this is definitely cleaner, but i'm not sure we are covering the same cases here. for context, the test i mentioned before is testing different update scenarios (i probably named it poorly). mostly the idea is that the update method works correctly. (ie, we update a partition that once had a topic id to one that does not, etc). maybe that is covered in some of the other tests i've added (like `def maybeupdaterequestparamsorname`) and we can just remove that test. what do you think? i'll also think about this a bit more.",0,0.9860900640487671
746220127,11331,jolshan,2021-11-10T03:24:38Z,alternatively i can just rewrite this.,0,0.9842405915260315
746220311,11331,jolshan,2021-11-10T03:25:14Z,^ this is what i've done.,0,0.7867797017097473
746376488,11331,dajac,2021-11-10T09:05:48Z,"yeah, that works as well.",0,0.9634232521057129
746404173,11331,dajac,2021-11-10T09:29:25Z,"i wrote that test to illustrate how we could improve the readability. my concern is that they are so many lines/assertions in `testupdatedpartitionresolvesid` and `testtoforgetcases` that we get distracted and we have almost missed the most important assertions - the ones which validate what the session contains (`assertpartitionsorder`). `assertpartitionsorder` is actually the piece which ensures that the names are resolved or not, right?",0,0.9781663417816162
746420015,11331,dajac,2021-11-10T09:47:54Z,"could we simplify all of that by defining two `topicidpartition`? for instance, we could have the following: [code block] then, we can use them where we need them.",0,0.9914730787277222
746423986,11331,dajac,2021-11-10T09:52:41Z,we usually prefer to not use `any*` but to rather provide the expected values.,0,0.9913367033004761
746425514,11331,dajac,2021-11-10T09:54:31Z,we have two paths (fetch from follower and fetch from consumer) in `handlefetchrequest` where we handle unknown topic names. should we parameterize the test to cover both of them?,0,0.9934775829315186
746433053,11331,dajac,2021-11-10T10:03:26Z,"i am not sure that i understand the value that we get out of this logic. `updateandgenerateresponsedata` creates a fetchresponse based on its input. therefore, the response that we assert is not so surprising in the end, right? it will contain `inconsistent_topic_id` if when the method gets it as an input. this logic would make sense for a test which verifies `updateandgenerateresponsedata` but looks like a distraction in a test which verify the name resolution logic. am i missing something here?",0,0.8439945578575134
746433401,11331,dajac,2021-11-10T10:03:52Z,nit: you could use `assertequals` as it calls `equals`.,0,0.9936422109603882
746461644,11331,dajac,2021-11-10T10:38:21Z,i guess that it does not hurt to keep it.,0,0.5761052966117859
746783340,11331,jolshan,2021-11-10T16:45:20Z,"there are two places it may be resolved -- either in the update method if the partition with the new id is sent in the request or in the assertpartitionsorder. i was also trying to ensure the correct error messages are returned in the response specifically via `updateandgenerateresponsedata`, but maybe we don't care about this here?",0,0.9946035742759705
746785542,11331,jolshan,2021-11-10T16:47:42Z,i copied this from the test above. :grinning_face_with_sweat: wasn't sure if we wanted consistency amongst the tests.,0,0.968985915184021
746789815,11331,jolshan,2021-11-10T16:52:21Z,"sure. we can remove it. i think i was concerned about the correct handling of the resolved partitions (ie, we get a response back that we can actually parse), but maybe that's not really necessary.",0,0.9769904613494873
746803000,11331,dajac,2021-11-10T17:06:46Z,"do you mean the correct handling of the resolved partitions by `updateandgenerateresponsedata`? i think testing `updateandgenerateresponsedata` is a good thing in general. perhaps, we should just put this into a separate test specific to that method? we should also test it for all context types with and without topic id, i guess.",0,0.9905639886856079
746805054,11331,dajac,2021-11-10T17:09:04Z,"right. the question is how to validate that the first update method works? you have to get the partitions from the session as well, isn't it?",0,0.9910179376602173
746807276,11331,jolshan,2021-11-10T17:11:51Z,i suppose so. i wonder if we should even include the update method at all then...,0,0.9543220400810242
746826740,11331,dajac,2021-11-10T17:35:47Z,what do you mean?,0,0.9843899607658386
746829235,11331,jolshan,2021-11-10T17:39:01Z,"if we always resolve when iterating through the partitions, then do we need to resolve via the update method?",0,0.9940968751907349
746836952,11331,jolshan,2021-11-10T17:49:20Z,is there a way to make such a test without duplicating the newcontext portions?,0,0.9930517673492432
746852321,11331,dajac,2021-11-10T18:01:40Z,"yeah, that is not really necessary as you said. i don't mind if you remove it.",0,0.7764152884483337
746867390,11331,jolshan,2021-11-10T18:22:07Z,should this be a check when topic is null?,0,0.9933521747589111
746870544,11331,dajac,2021-11-10T18:26:06Z,that could be :grinning_face_with_smiling_eyes:,0,0.9918054342269897
746873252,11331,jolshan,2021-11-10T18:29:51Z,i've concluded that your new test will now cover the necessary cases (especially with your new commit) so i think we can just remove this.,0,0.9531371593475342
176640732,4756,ijuma,2018-03-23T05:14:32Z,we don't use logback for anything else. i'd suggest keeping it consistent with the project.,0,0.9657588005065918
176640868,4756,ijuma,2018-03-23T05:15:57Z,`scalalogging` is already defined in this file.,0,0.9938522577285767
176640906,4756,ijuma,2018-03-23T05:16:15Z,this is already defined in this file.,0,0.9925627112388611
176645062,4756,debasishg,2018-03-23T06:02:06Z,done ..,0,0.9705991744995117
176645077,4756,debasishg,2018-03-23T06:02:13Z,removed.,0,0.9782117605209351
176645090,4756,debasishg,2018-03-23T06:02:21Z,removed.,0,0.9782117605209351
176799631,4756,guozhangwang,2018-03-23T16:56:25Z,do we need to import these two dependencies? could we use kafka's own embeddedkafkacluster?,0,0.9949559569358826
176799962,4756,guozhangwang,2018-03-23T16:57:34Z,does it worth to include this dependency at test runtime? cc .,0,0.9927814602851868
176800608,4756,guozhangwang,2018-03-23T16:59:42Z,could we add the default for short and bytebuffer as well?,0,0.9947742819786072
176801533,4756,guozhangwang,2018-03-23T17:02:47Z,i'm wondering if we could provide default serdes for windowed key as well? see `o.a.k.streams.kstream.windowedserdes` for java code.,0,0.9932679533958435
176802156,4756,guozhangwang,2018-03-23T17:05:08Z,nit: how about rename to `flatvaluemapperfromfunction` for better understanding? ditto below.,0,0.9871119856834412
176802758,4756,guozhangwang,2018-03-23T17:06:56Z,"just for my own education: is it necessary to add `, _` in the end? what are the possible classes we want to still include?",0,0.9798010587692261
176803277,4756,guozhangwang,2018-03-23T17:08:49Z,nit: newline for the second parameter.,0,0.9859245419502258
176805401,4756,guozhangwang,2018-03-23T17:16:14Z,why we can ignore the topic here? ditto below?,0,0.9868048429489136
176806499,4756,guozhangwang,2018-03-23T17:20:01Z,"nit: `long2long(_)` to be consistent with others? actually, do we need to explicitly call it? i thought it will be implicitly triggered anyways from `predef`.",0,0.9937818646430969
176809033,4756,guozhangwang,2018-03-23T17:28:54Z,"could we add this syntax sugar in the implicit conversion so all classes like `kgroupedstream`, `ktable` and `streamsbuilder` can use it?",0,0.9949260950088501
176809497,4756,guozhangwang,2018-03-23T17:30:34Z,why do we need the `asvaluemapper` here explicitly? ditto below.,0,0.9929916858673096
176812165,4756,guozhangwang,2018-03-23T17:39:43Z,"do we have to convert two parameters to a tuple and then apply the function.tupled? i'm asking this because this is on the critical code path (called per map per record), and if there is non-negligible overhead..",0,0.9787827730178833
176812703,4756,guozhangwang,2018-03-23T17:41:40Z,"no `scalastyle:off null` before, is this intentional?",0,0.9920943379402161
176812967,4756,guozhangwang,2018-03-23T17:42:37Z,nit: space after comma.,0,0.9043383598327637
176816332,4756,guozhangwang,2018-03-23T17:53:26Z,"is it a syntax sugar as `branch`? i'd prefer to keep java and scala interfaces consistent, so that if we think it is worthwhile we'd better add it in java apis as well, otherwise we should remove it from scala apis. wdyt?",0,0.9897536039352417
176817831,4756,guozhangwang,2018-03-23T17:57:29Z,"this is a deprecated api in java, we should replace it with materialized.",0,0.9911086559295654
176819139,4756,guozhangwang,2018-03-23T18:01:58Z,nit: default to `info`?,0,0.9920645356178284
176819498,4756,guozhangwang,2018-03-23T18:03:20Z,the file `logs/kafka-server.log` seems not appropriate as it is not for kafka broker logs right?,0,0.982032060623169
176820184,4756,guozhangwang,2018-03-23T18:05:54Z,"this is a meta comment: i'd suggest we consider adding logback generally for kafka, instead of sneaking in for streams scala wrapper. we can still use log4j for now. see [a link] cc",0,0.9856929779052734
176897781,4756,debasishg,2018-03-24T03:00:43Z,this library `scalatestembeddedkafka` has a nice integration with scalatest. hence it makes writing tests easier and we don't have to bother starting / managing the embedded kafka instance. the test code becomes very concise.,1,0.5031746029853821
176897811,4756,debasishg,2018-03-24T03:02:24Z,it's only to demonstrate custom serdes. we picked up avro since (afair) suggested this example in one of the earlier pr discussions. this example goes to show that custom serdes can be handled as seamlessly as primitive ones.,0,0.9879099130630493
176897854,4756,debasishg,2018-03-24T03:05:35Z,we need this for sam type conversion which is not fully supported in scala 2.11. in scala 2.12 we don't need this. this code base runs both in scala 2.11 and scala 2.12.,0,0.9944002032279968
176898091,4756,debasishg,2018-03-24T03:18:32Z,"the `, _` takes care of the other imports that don't need to be renamed like `serialized`, `joined` etc.",0,0.9944391250610352
176898176,4756,debasishg,2018-03-24T03:23:51Z,don't find the `topic` being used in de-serializer implementations e.g. [a link],0,0.9950464963912964
176898673,4756,debasishg,2018-03-24T03:40:43Z,"we need to call it explicitly. `predef` has an implicit conversion between `long` and `java.lang.long` but not between `ktable[k, long]` and `ktable[k, java.lang.long]` which we are dealing with here.",0,0.9946485161781311
176899296,4756,ijuma,2018-03-24T04:05:50Z,"yes, let's stick to log4j in this pr.",0,0.9901324510574341
176899431,4756,debasishg,2018-03-24T04:10:36Z,this may not be relevant here. we were using scalastyle plugin with sbt. guess we can ignore it for now.,0,0.9795702695846558
176899457,4756,debasishg,2018-03-24T04:11:36Z,maybe we can have a `package object` with such stuff that can be reused across abstractions. better than repeating for every class. will do this.,0,0.9861867427825928
176899731,4756,debasishg,2018-03-24T04:27:28Z,we can add the following: [code block] but this one also may be useful when the user just needs to pass in the `keyserde`. she need not construct any `materialized` which is abstracted within the implementation of the api. suggestions ?,0,0.9949328303337097
176899763,4756,debasishg,2018-03-24T04:29:11Z,should we remove `logback.xml` ?,0,0.9946632385253906
176928234,4756,guozhangwang,2018-03-25T04:15:10Z,generally speaking ak repo tend to avoid dependencies unless it is necessary. i'm wondering if we can improve on kafka's own embeddedkafkacluster to have the same functionalities as the `net.manub:scalatest-embedded-kafka-streams`.,0,0.9699516892433167
176928257,4756,guozhangwang,2018-03-25T04:17:34Z,"are these interfaces only used for built-in primitive types, or are they going to be extended by users for their own serdes, like avro? if it is the latter case we cannot enforce users to always ignore the topic.",0,0.9844724535942078
176928265,4756,guozhangwang,2018-03-25T04:18:35Z,ack. makes sense. scala `predef` is not as smart as applying to nested types yet.,-1,0.7450428605079651
176928266,4756,guozhangwang,2018-03-25T04:18:57Z,ack.,0,0.5038502812385559
176928367,4756,guozhangwang,2018-03-25T04:28:27Z,"i'd vote for keeping java / scala api consistent, and we are going to remove deprecated apis in future releases anyway. in current api we'd only have one additional overload: [code block] i think for users who do not want to specify the store name at all, they can rely on [code block] to still hide the `materialized` parameter with implicit conversion. for users who do want to specify the store name, but want to rely on type conversion, we could call `withkeyserde` and `withvalueserde` internally in the implicit conversion so that user only need to give `materialized.as(storename)` does that work?",0,0.9909234642982483
176928378,4756,guozhangwang,2018-03-25T04:28:53Z,"yup, please remove that file as well.",0,0.9598717093467712
176929613,4756,debasishg,2018-03-25T05:46:27Z,"we can definitely use kafka's own `embeddedkafkacluster` to integrate with scalatest. in `net.manub:scalatest-embedded-kafka-streams`, the main value add is integration with scalatest and hence you don't have to explicitly start / stop server as part of the test. also with kafka streams it has very nice constructs like the one we use here .. [a link] .. note you just have to define the transformations and do the publish and consume as part of a closure. no need to start / stop the topology. hence the test code becomes very concise. of course it depends on the opinion of the committee but i think this would be a great addition to the dependency. here's a suggestion .. we use `net.manub:scalatest-embedded-kafka-streams` for now. after all it's a *test* dependency. and work on a separate pr to make the integration between `embeddedkafkacluster` and scalatest better and in line with the functionalities offered by the library. wdyat ?",1,0.8395432829856873
176930041,4756,debasishg,2018-03-25T06:12:10Z,+1 .. will remove this overload for `count`.,0,0.9799599647521973
176931307,4756,debasishg,2018-03-25T07:21:36Z,the implementation [a link] is only for *stateless* serdes implementation where nothing gets stored in topics. for stateful implementation involving topics the user can provide her own implementation of `scalaserde`. we provide this as a reference implementation of stateless serdes that we use in implementing `avroserde` in the test. of course we can decide if we should bundle this as part of the source or test. but we thought that the implementation may be useful to users implementing stateless custom serdes. thoughts?,0,0.9901122450828552
176931378,4756,debasishg,2018-03-25T07:25:00Z,+1,0,0.7702900171279907
176931381,4756,debasishg,2018-03-25T07:25:14Z,+1,0,0.7702900171279907
176931387,4756,debasishg,2018-03-25T07:25:27Z,+1,0,0.7702900171279907
176931389,4756,debasishg,2018-03-25T07:25:38Z,+1,0,0.7702900171279907
176931394,4756,debasishg,2018-03-25T07:25:56Z,+1,0,0.7702900171279907
176931402,4756,debasishg,2018-03-25T07:26:13Z,+1,0,0.7702900171279907
176931414,4756,debasishg,2018-03-25T07:26:42Z,will change the name to `kafka-streams-scala.log`,0,0.9947662353515625
176931419,4756,debasishg,2018-03-25T07:26:52Z,+1,0,0.7702900171279907
176985739,4756,mjsax,2018-03-26T05:49:58Z,nit: those are actually sorted alphabetically -- can we clean this up? thx.,0,0.8832674026489258
176985752,4756,mjsax,2018-03-26T05:50:06Z,as above.,0,0.9878018498420715
176986121,4756,mjsax,2018-03-26T05:54:10Z,"should we add those exclusions? i know that we put exclusions when introducing findbugs because it is not possible to introduce it and rewrite all the code -- but for new code, we should consider changing the code. i am not a scale person though -- can you elaborate on this?",0,0.9436361193656921
176986532,4756,mjsax,2018-03-26T05:58:09Z,should this be `bytearraykeyvaluestore`? -- we don't use abbreviations in the java code base.,0,0.9934106469154358
176987291,4756,mjsax,2018-03-26T06:05:20Z,why do we need an `asinstanceof` here? (same below),0,0.9927564263343811
176987359,4756,mjsax,2018-03-26T06:05:52Z,why do we not import `bytes` ?,0,0.9882270693778992
176987713,4756,mjsax,2018-03-26T06:09:03Z,"nit: should we use `[k, v, vr]` as in java?",0,0.9944092631340027
176988085,4756,mjsax,2018-03-26T06:12:20Z,nit: name `v` instead of `vr` ?,0,0.9942130446434021
176988134,4756,mjsax,2018-03-26T06:12:39Z,nit: name `v` instead of `t` ?,0,0.9940306544303894
176988730,4756,mjsax,2018-03-26T06:16:53Z,nit: `kvo` -> `keyvalueother` ?,0,0.9925187826156616
176988977,4756,mjsax,2018-03-26T06:19:03Z,"for my own education. what is a ""stateless serde"" ?",0,0.7482942938804626
176989413,4756,mjsax,2018-03-26T06:22:09Z,"nit: remove spaced -> `{keyvalue, consumed}`",0,0.9928966164588928
176989878,4756,mjsax,2018-03-26T06:26:05Z,this should only take 4 parameters. we simplified the api and this method is deprecated (cf. [a link],0,0.9910577535629272
177137368,4756,debasishg,2018-03-26T15:39:23Z,+1 ..,0,0.8453341126441956
177184454,4756,mjsax,2018-03-26T18:09:25Z,"nit: i am not a fan of adding links in javadocs, because links might break; better reference to the corresponding class as javadoc cross reference? also: i am wondering if we should remove this method from the wrapper in the first place? imho, it's not a good idea to add deprecated api in new code?",-1,0.9364738464355469
177185072,4756,mjsax,2018-03-26T18:11:39Z,"a `valuetransformer` also have `init()`, `punctuate()` and `close()` method. why is this code much simpler than the wrapper for `transform()` above?",0,0.9935787916183472
177185869,4756,mjsax,2018-03-26T18:14:29Z,"as above. what about `init()`, `punctuate()`, and `close()` ?",0,0.9933904409408569
177188532,4756,mjsax,2018-03-26T18:23:14Z,"i agree that both apis should be consistent. does a `split` add much value compare to `branch`? btw, this might be related to [a link] i am also open to add a `split()` if we think it's useful.",0,0.9580013751983643
177189344,4756,mjsax,2018-03-26T18:26:04Z,why do we only allow to specify a `keyserde` but not replace the store with a different one? scala noob question: would it be possible to have a single `count` / `reduce` etc instead of overloads and use `option` and implicits to infer optional arguments?,0,0.9859985113143921
177201338,4756,seglo,2018-03-26T19:06:51Z,"i'm a fan of `net.manub:scalatest-embedded-kafka-streams`, but i understand the concern about bringing in more deps. i only mentioned it on the dev-kafka list because i didn't think there was much value in improving the embedded kafka implementation in `kafka-stream-scala` and making it a public interface because `scalatest-embedded-kafka` already existed. i wasn't aware of `embeddedkafkacluster`. if `scalatest-embedded-kafka` were brought into the project then there will be drift between the version of kafka broker in code and whatever this test lib references. i like your suggestion: perhaps we can do this now for this pr, but keep it simple. i could work on it if you're busy.",1,0.71920245885849
177206327,4756,vvcephei,2018-03-26T19:25:44Z,"i'd like to confirm that this option is actually safe. is this a best practice at this point for targeting 2.11? also, how can we know we're not dragging in other (potentially unwanted) experimental compiler features with this?",0,0.9849603772163391
177206719,4756,vvcephei,2018-03-26T19:27:21Z,"cool. in that case, maybe we should also add 'streams:streams-scala:examples' and put it there?",1,0.6554496884346008
177207156,4756,vvcephei,2018-03-26T19:28:57Z,nit: this is a bit cumbersome. can we do project(':streams:scala-wrapper') and archive: 'kafka-streams-scala-wrapper' or some such instead?,-1,0.8742208480834961
177210106,4756,vvcephei,2018-03-26T19:39:58Z,"i have used `net.manub:scalatest-embedded-kafka-streams` before, and it *is* very nice. but i also worry about adding dependencies to the core project, even test deps. if our tests become a bit uglier, or if we have some test-util class that duplicates some of the functionality you're using, i would consider that to be a worthy tradeoff for dropping the dependency. i would absolutely support planning to come back in a follow-up pr to build out support for testing scala code and then terraforming these tests to use the new support. or even delaying this pr until a test-support one is available.",1,0.7194948196411133
177211622,4756,vvcephei,2018-03-26T19:46:08Z,"i think it's because we're presenting the `serde[java.lang.long]` as a `serde[scala.lang.long]`, but casting the serde won't automatically cast the parameters and returns of its methods. i'm surprised you don't get cast class exceptions trying to use the java long serde as a scala long serde. unless i'm wrong about what this is for...",-1,0.5632346272468567
177214912,4756,vvcephei,2018-03-26T19:58:11Z,"+1 on not including this method in the wrapper. the code that would use this library is not written yet, so it's better if deprecated methods are simply not available.",0,0.9843346476554871
177215699,4756,vvcephei,2018-03-26T20:00:27Z,i agree.,0,0.8401532769203186
177222153,4756,ijuma,2018-03-26T20:23:09Z,"there is no such thing as a `scala.long` at runtime, scala changed to use the same classes as java for boxing around the 2.8 timeframe if i remember correctly. previously there was a `richlong`, `richint`, etc. in any case, this seems like a variance issue, but i didn't look into it.",0,0.9792631268501282
177225591,4756,seglo,2018-03-26T20:35:21Z,"this seems to be a false positive. findbugs is reporting that `serializer` and `deserializer` should be defined as a different type name than what it's inheriting. iirc the consensus earlier is that we want type names the same as the base types they're wrapping (which includes traits and interfaces imo). i've updated the findbugs rule exclusion to be specific to the types generating the violation, rather than the entire `scalaserde` file.",0,0.9708069562911987
177227080,4756,seglo,2018-03-26T20:40:17Z,"i assume it was to disambiguate with `serdes.bytes`, but that's not a problem. i'll update it.",0,0.9893578886985779
177227812,4756,seglo,2018-03-26T20:42:47Z,i've renamed the type param to `va` to match the java dsl.,0,0.9932540059089661
177228111,4756,seglo,2018-03-26T20:43:44Z,i've renamed the type param to `va` to match the java dsl. is that ok?,0,0.9934606552124023
177228492,4756,guozhangwang,2018-03-26T20:45:05Z,thanks for your thoughts. we do have plans to publish testing-util artifacts inside ak in the future. and in fact we have been doing so for kafka-streams module as a first step and going to do that for kafka-core and kafka-clients soon. in kafka-clients testing utils we are going to include some improved version of embeddedkafkacluster for users to easily write their integration tests that involve interacting with a mock a kafka cluster. so i'd suggest we stay with the uglier implementation with the existing embedded kafka cluster and not bring in the dependency.,1,0.9453843235969543
177230451,4756,guozhangwang,2018-03-26T20:51:18Z,"i see. i guess i was a bit misled by the name itself: i was thinking ""stateless"" is for the stateless operators in kafka streams dsl, and thinking the inclusion of topic name or not does not necessarily depend on whether the serde is used for stateful or stateless operations. your explanation makes sense now. maybe we can add some comments on top of `statelessserde` claiming that this serde class is used for serde where topic names does not affect the serde logic, i.e. topic name will be ignored. if users need some serde mechanism that does differentiate on topic names, please implement the other underlying `serde` interface.",0,0.9784997701644897
177231716,4756,guozhangwang,2018-03-26T20:55:24Z,it is discussed in [a link] i think the name `stateless` may be a tart misleading but i cannot come up with a better name yet.,0,0.9546604156494141
177232798,4756,guozhangwang,2018-03-26T20:59:16Z,"i'm a bit on the fence for introducing avro as ""the one"" serde in our demonstration examples rather than keeping kafka and avro separate, since there are many protobufs / etc fans in the community. how about adding avro examples in eco-system repos, e.g. in lightbend / confluent / etc's own examples repo they can add their own example? cc",0,0.9410991668701172
177238405,4756,seglo,2018-03-26T21:19:47Z,"i agree it looks concerning, i'll need to check what other potential features this brings in, unfortunately there's no way to be more specific about just enabling sam type conversion afaik. we could remove this flag, but we would need to desugar all the places where conversions occur.",0,0.9442282915115356
177268099,4756,mjsax,2018-03-26T23:44:21Z,"maybe `simpleserde` as name ? ""stateless"" seems to be confusing.",0,0.9204085469245911
177268698,4756,mjsax,2018-03-26T23:47:33Z,+1 sounds reasonable to me.,0,0.8111982941627502
177289406,4756,debasishg,2018-03-27T02:19:29Z,- cool .. then we can remove the test `streamtotablejoinscalaintegrationtestimplicitserdeswithavro` and the dependencies from `build.gradle` .. ok ?,1,0.9731036424636841
177289806,4756,debasishg,2018-03-27T02:21:20Z,"for the time being, we can remove `split` from the scala api and rethink if / when it's implemented as a java api",0,0.993990957736969
177290643,4756,debasishg,2018-03-27T02:28:37Z,in scala there's an implicit conversion between `scala.long` and `java.lang.long` but not between `serde[scala.long]` and `serde[java.lang.long]` - hence the cast. in fact picked this trick from [a link],0,0.9926015734672546
177296715,4756,debasishg,2018-03-27T03:19:43Z,"- i think i may be missing something here. we are allowing the user to pass in the `store` *and* `keyserde`. and we create the `materialized` out of the 2 with `long` as the value serde. however we were allowing the user to pass in the `keyserde` optionally and in case the user does not supply one we assumed it will be taken from the config. this is actually a remnant from the earlier thoughts where we thought passing serdes through config may be a good idea. however in the current context, we should not make `keyserde` optional. here's the suggestion for the changed api .. [code block] an alternative option could have been to allow the user to pass in the `materialized` instance itself (like we do in the `reduce` function). the problem with that alternative is that the java api expects `java.lang.long` as the value serde, while the scala api needs to take a `scala.long`. and there is no way we can convert a `materialized.as[k, scala.long, bytearraykeyvaluestore]` to `materialized.as[k, java.lang.long, bytearraykeyvaluestore]` without a cast. hence the divergence in the api signature between `count` and `reduce`. please share if u have any other thoughts.",0,0.9902419447898865
177297602,4756,debasishg,2018-03-27T03:24:58Z,"hi - regarding the above, we had a discussion on the 2 approaches on this thread only and the universal suggestion was to use the same name across scala and java apis. in fact in the initial version that we posted, we had different names (`kstream` / `kstreams`). the reasoning of using the same names is that the renaming of imports in the user code needs to be done only very occasionally when we mix usage of scala and java apis.",0,0.9907228350639343
177305370,4756,debasishg,2018-03-27T04:29:40Z,"here, the deprecation is on `punctuate`, which is part of the contract of `transformer`. how do we remove this ? we can *only* remove this when `punctuate` is removed from `transformer` ? or am i missing something ?",0,0.9934341907501221
177306580,4756,debasishg,2018-03-27T04:41:33Z,we don't need to provide implementation of `valuetransformer` here since the passed in `() => valuetransformer[a link] for sam type conversions in scala.,0,0.9929621815681458
177306659,4756,debasishg,2018-03-27T04:42:17Z,same logic as `valuetransformer` above.,0,0.9932639598846436
177320316,4756,debasishg,2018-03-27T06:34:09Z,thanks for your thoughts .. we will remove the dependency on `net.manub:scalatest-embedded-kafka-streams` and use `embeddedkafkacluster` instead.,1,0.9057191610336304
177420275,4756,seglo,2018-03-27T13:20:12Z,"there's no list of what's brought in with the experimental flag, unless you grep the compiler code. the purpose of the sam type conversion feature in 2.11 was only to get early feedback and only properly finished in 2.12. as its name suggests it's not meant to be used in production code. since kafka is still targeting 2.11 it makes sense to not include this flag to build a releasable artifact. i'll remove the flag and desugar the conversions.",0,0.9912347793579102
177438559,4756,vvcephei,2018-03-27T14:10:55Z,"thanks for the explanation, i missed that discussion. sorry to bring it back up! thanks! am i correct in thinking that only affects our code, and not our users' code? i.e., if they are using 2.12, they can pass in lambdas as arguments, right?",-1,0.9714254140853882
177440570,4756,seglo,2018-03-27T14:16:01Z,"yes, this change won't affect end users at all. if kafka drops scala 2.11 support then we can bring back the sam conversions as they're available without any ominous compiler flags.",0,0.9848784804344177
177441103,4756,vvcephei,2018-03-27T14:17:26Z,"huh! well, that explains it. i have seen the conversions of the raw types, and also suffered from type errors that `serde[scala.long]` != `serde[java.lang.long]`, so i just assumed that `scala.long` was a different class than `java.long`. thanks for the explanation, .",1,0.9940062761306763
177442727,4756,vvcephei,2018-03-27T14:21:33Z,"oh, right, i thought this was one of your scala replacement classes. what i have been doing for cases like this is throwing an `unsupportedoperationexception` in the body. it's not as good as not having the method, but it def. ensures it can't be used. and you don't have to maintain the code that's in the body.",0,0.8649864792823792
177449950,4756,vvcephei,2018-03-27T14:40:09Z,"that makes sense. my 2 cents: we're presenting the scala kgroupedstream basically *as* the java one, but not implementing the interface so that we can smooth over a couple of specific gaps. i think this is a good call, but it's also a huge risk for cognitive dissonance and developer confusion, since they will read the java version of the docs and try to use that knowledge in scala. therefore, it's important to be super disciplined about making sure the methods available are as close to the java interface as possible. clearly, moving serdes, etc., to implicit params is the kind of thing we *do* want to do. but i think that presenting `count(string,serde[k])` instead of `count(materialized[k, long, keyvaluestore[bytes, array[byte]]]` is too far off. i do agree that the method should take a scala type. apparently, it's perfectly fine to cast `serde[scala.long]` to `serde[java.long]`. does that same logic apply here? alternatively, we can actually convert the `materialized[java]` to a `materialized[scala]`.",0,0.8037176728248596
177457781,4756,debasishg,2018-03-27T15:00:05Z,.. sure we can do the following instead .. [code block] wdyt ?,0,0.9895524382591248
177531590,4756,vvcephei,2018-03-27T18:44:36Z,"ok, i'm already a little nervous about the cast in one direction, so this feels super gross, but would this work? [code block] please understand i'm wincing as i type this.",-1,0.9911023378372192
177532059,4756,mjsax,2018-03-27T18:46:17Z,"well, we allowing to pass in a store ""name"" (string) but not a store. note, that `materialized` allows to replace default rocksdb with an in-memory story, disable change-capture-logging or even use a custom store implementation.",0,0.9938236474990845
177532408,4756,guozhangwang,2018-03-27T18:47:27Z,sounds good.,1,0.9417163729667664
177532680,4756,guozhangwang,2018-03-27T18:48:20Z,sounds good.,1,0.9417163729667664
177533039,4756,guozhangwang,2018-03-27T18:49:18Z,that sounds better.,0,0.9587995409965515
177534627,4756,debasishg,2018-03-27T18:54:13Z,how about the api that i suggested above ? it takes materialized much like the java api though we need a cast. - in my implementation we have 1 cast and the other map for the long conversion in ktable.,0,0.9831157326698303
177537597,4756,mjsax,2018-03-27T19:04:24Z,i understand that you cannot change the java `transformer` interface and must implement the deprecated method when calling `new transformer` -- what i was wondering is about `scala.transformer` interface -- should we add one and remove `punctuate` from it?,0,0.9928719401359558
177540520,4756,vvcephei,2018-03-27T19:13:02Z,"sorry, i should have acked your implementation. i was actually proposing an evolution of it. it just seems a bit unfortunate to have to add a real function invocation to the topology in order to do the cast back to `scala.long`. the version i proposed just does a cast back out without adding anything new to the topology. does that make sense? at the risk of sounding like an idiot, if it's fine to do the cast on the way in, then it should be fine again on the way out, right?",-1,0.9893296360969543
177542082,4756,vvcephei,2018-03-27T19:17:17Z,"fwiw, i think adding a new scala interface just to remove a method that we plan to remove from the java interface is not necessary. better just to implement it and move on. also, it would be a bit trickier to swap in a scala replacement for `transformer` than for the top-level dsl classes, since implementations of the java `transformer` won't implement the scala `transfomer`, so you wouldn't be able to plug them in via the scala dsl wrapper. but there's otherwise no reason this shouldn't work.",0,0.8990122675895691
177554002,4756,mjsax,2018-03-27T20:01:50Z,"ack. was just an idea. i don't really speak scala (yet) -- this is an exercise to learn something about it... if we need to have it, i vote to throw an exception to forces users to use the new api.",-1,0.9723972082138062
177564717,4756,mjsax,2018-03-27T20:39:26Z,"this and all other classes are public api. thus, we should improve the javadocs for those classes and also add javadocs for all methods. i guess we can c&p from existing java classes.",0,0.9837397933006287
177636021,4756,debasishg,2018-03-28T04:25:29Z,- cast is a runtime operation and my philosophy is to minimize its use. and `scala.predef` indeed uses `long2long` to do such conversions. hence i would like to prefer using proper functions when available instead of the cast.,0,0.9906794428825378
177638616,4756,debasishg,2018-03-28T04:56:34Z,"ok, will remove `split` from `kstream` for now.",0,0.9929174184799194
177660176,4756,debasishg,2018-03-28T07:32:08Z,renamed to `simplescalaserde` ..,0,0.9922544956207275
177660317,4756,debasishg,2018-03-28T07:32:45Z,removed!,0,0.7937257289886475
177662427,4756,debasishg,2018-03-28T07:42:53Z,- looking for suggestions. should we copy/paste javadoc from java classes or use `` annotation ? the problem with copy is maintenance - when one changes someone needs to be careful enough to change the other.,0,0.9737250208854675
177685679,4756,debasishg,2018-03-28T09:12:55Z,- removed all dependencies on `net.manub:scalatest-embedded-kafka` and `net.manub:scalatest-embedded-kafka-streams`. now using `embeddedkafkacluster` instead for tests. also removed the test that used avro - hence dependency on `avros` eliminated.,0,0.9948487281799316
177793180,4756,deanwampler,2018-03-28T15:34:39Z,"a little more detail; what this import is saying is ""import these items, but give them an alias, then import everything else without an alias"".",0,0.9806575179100037
177826543,4756,guozhangwang,2018-03-28T17:22:58Z,thanks !,1,0.9159799218177795
177950361,4756,mjsax,2018-03-29T04:19:27Z,good question. not sure. i agree that maintaining javadocs twice is a hassle and error prone. but might be annoying for user if it's only linked on the other hand. would be good to hear what others thing. \cc,1,0.9926090836524963
178029830,4756,seglo,2018-03-29T11:41:02Z,"adding javadocs to all the public api methods in the pr is the same amount of work any way we do it. from an end user perspective i agree it would be nice to have the same (or slightly tweaked, as necessary) javadocs for all public api methods, plus a `` or `` tag to the corresponding java api method. it will be a small burden to maintain it going forward so i defer to the ak committers to make the call on the format.",0,0.9802040457725525
178136346,4756,guozhangwang,2018-03-29T18:01:06Z,"i'd vote for using `` and `` to avoid maintaining two copies, because we have some public classes following this pattern in the repo (like [a link] and from the past i find most people would not remember or bother to update two places than one. i think the web docs (in `docs/streams`) needs to be updated as well, especially in the `upgrade-guide.html` page, as well as the `streams-api` page.",0,0.9888262748718262
178136538,4756,guozhangwang,2018-03-29T18:01:48Z,"for `streams-api` page above, i meant [a link]",0,0.9894160628318787
178139790,4756,ijuma,2018-03-29T18:13:51Z,"some thoughts: - i think the consumer and kafkaconsumer pattern is bad. the documentation should have been on `consumer` instead. the `adminclient` follows the latter pattern. - i think it's a poor user experience to ask users to read the docs in the java class. my recommendation would be to at least include a short description in the scala docs along with a link to the relevant java documentation. the short description is less likely to change and it helps users make progress without having to jump to the java code all the time. however, for more detailed information (which is more likely to change), they can check the java code.",0,0.7093771696090698
178448558,4756,mjsax,2018-04-01T05:20:06Z,"i tend to agree with comment about `kafkaconsumer`/`consumer` pattern -- it's quite annoying to not get the javadocs directly. thus, even if it's a burden it seems to be worth to maintain two copies.",-1,0.9031277298927307
178450057,4756,debasishg,2018-04-01T07:16:38Z,- i have started writing the scaladocs in the commit [a link] .. pls review if it's following the correct pattern,0,0.9398400187492371
178976326,4756,guozhangwang,2018-04-03T22:07:53Z,nit: period at the end of the sentence.,0,0.9617739915847778
178976444,4756,guozhangwang,2018-04-03T22:08:35Z,maybe mention again which artifact to include in order to import this package.,0,0.9913506507873535
178976955,4756,guozhangwang,2018-04-03T22:11:09Z,we do not need indentation in the code block; the following code blocks are formatted correctly.,0,0.9895519614219666
178977137,4756,guozhangwang,2018-04-03T22:12:07Z,this is not introduced in this pr: duplicated `provides`.,0,0.993808925151825
179201680,4756,seglo,2018-04-04T16:20:47Z,"i fixed the typos in this line, but i'm not sure what you mean by it not being introduced in this pr. this line is to indicate the presence of the kafka streams dsl for scala library.",0,0.9761586785316467
179202074,4756,seglo,2018-04-04T16:22:13Z,i copied the formatting from the streams main page which indented the wordcount examples: [a link],0,0.9776877760887146
179202109,4756,seglo,2018-04-04T16:22:22Z,:+1:,0,0.9166757464408875
179202130,4756,seglo,2018-04-04T16:22:28Z,:+1:,0,0.9166757464408875
179202465,4756,seglo,2018-04-04T16:23:36Z,i removed the initial indentation for this example on this page to make it consistent with the others.,0,0.9912781119346619
179268477,4756,guozhangwang,2018-04-04T20:15:02Z,"i meant the duplicated `provides` exist before this pr, so it is not a regression introduced from this pr.",0,0.9931944608688354
181648477,4756,mjsax,2018-04-16T07:54:15Z,"""is available here"" is bad phrasing. `here` -> `in the developer guide`",0,0.7419582605361938
181649571,4756,mjsax,2018-04-16T07:58:35Z,`to include it your maven` -- sounds weird,-1,0.9870877265930176
181649928,4756,mjsax,2018-04-16T08:00:05Z,i am wondering if this is correct? should the scala version not be included here?,0,0.9418651461601257
181650115,4756,mjsax,2018-04-16T08:00:56Z,"don't we need the scala version, here?",0,0.9922405481338501
181650350,4756,mjsax,2018-04-16T08:01:54Z,don't we need the scala version here?,0,0.9927482008934021
181650623,4756,mjsax,2018-04-16T08:03:07Z,typo: is a wrapper around `stream[s]builder`,0,0.9936825037002563
181650718,4756,mjsax,2018-04-16T08:03:31Z,nit: `wordcount` ?,0,0.9930849075317383
181650779,4756,mjsax,2018-04-16T08:03:47Z,typo: `stream[s]builder`,0,0.9933619499206543
181652632,4756,mjsax,2018-04-16T08:11:33Z,scala version missing?,0,0.988392174243927
181652730,4756,mjsax,2018-04-16T08:12:00Z,scala version missing?,0,0.988392174243927
181652863,4756,mjsax,2018-04-16T08:12:40Z,"i think, we should not have indention here for better rendering",0,0.906039834022522
181653308,4756,mjsax,2018-04-16T08:14:23Z,nit: should be added such the alphabetical order is maintained.,0,0.988278329372406
181653441,4756,mjsax,2018-04-16T08:14:56Z,can't we merge this with the one from above?,0,0.9940598011016846
181656561,4756,mjsax,2018-04-16T08:27:10Z,this seems to be rather short compared to `stream` and `table` docs from above.,0,0.9851232171058655
181656843,4756,mjsax,2018-04-16T08:28:06Z,"maybe we can add, that a store must still be ""connected"" to a `processor`, `transformer`, or `valuetransformer` before it can be used?",0,0.9952903985977173
181657170,4756,mjsax,2018-04-16T08:29:17Z,"maybe add, that global stores do not be added to `processor`, `transformer`, or `valuetransformer` (in contrast to regular stores).",0,0.9942923784255981
181658989,4756,mjsax,2018-04-16T08:36:36Z,"maybe add a sentence, that stores must be added via `addstatestore` or `addglobalstore` before they can be connected to the `transformer` ?",0,0.9954286813735962
181659066,4756,mjsax,2018-04-16T08:36:53Z,as above?,0,0.986420750617981
181659114,4756,mjsax,2018-04-16T08:37:05Z,as above?,0,0.986420750617981
181659257,4756,mjsax,2018-04-16T08:37:38Z,as above?,0,0.986420750617981
181660310,4756,mjsax,2018-04-16T08:41:42Z,"maybe explain, that there is not ordering guarantee for the merged result stream for records of different input streams? relative order is only preserved for record of the same input stream?",0,0.9893603324890137
181662152,4756,mjsax,2018-04-16T08:48:00Z,markup seems weird? why do you have javadoc comment markup? would a single `#` not be sufficient?,-1,0.8945598602294922
181904753,4756,guozhangwang,2018-04-16T22:31:18Z,"for different scala version compiled packages, their project name is actually the same. and here people only need to specify the version of the artifact itself, which will be the kafka version. users can, indeed, build kafka-streams-scala with different scala versions other than the default one, but that is to be done before they include it in the dependency. for maven, it will always be whatever is uploaded to maven central.",0,0.9931296706199646
181909480,4756,guozhangwang,2018-04-16T22:57:47Z,"cc -hamill we are adding a few new sections in web docs regarding the streams scala api, which may be affecting [a link]",0,0.9657991528511047
181909865,4756,guozhangwang,2018-04-16T23:00:09Z,"i think the scala version cannot be changed when specifying the `kafka-streams-scala` artifact, as it is encapsulated when that artifact is compiled already. please correct me if i'm wrong.",0,0.7851731181144714
181910307,4756,guozhangwang,2018-04-16T23:02:43Z,i think we do not need avro4sversion any more? same as line 86 here.,0,0.989824116230011
181910344,4756,guozhangwang,2018-04-16T23:02:56Z,this is not needed.,0,0.9542514681816101
181910430,4756,guozhangwang,2018-04-16T23:03:34Z,do we still need `scalatestembeddedkafkaversion`?,0,0.9951238036155701
181910448,4756,guozhangwang,2018-04-16T23:03:40Z,+1,0,0.7702900171279907
181910836,4756,guozhangwang,2018-04-16T23:06:10Z,should we add `copyright 2018 the apache software foundation.` as well?,0,0.9931517839431763
181911680,4756,guozhangwang,2018-04-16T23:11:08Z,"ping on this comment again, could you elaborate if my concern is valid or not?",0,0.9840608239173889
181911985,4756,guozhangwang,2018-04-16T23:12:59Z,could we remove this line then?,0,0.9911109209060669
181916063,4756,guozhangwang,2018-04-16T23:39:02Z,"nit: move `import org.junit.assert._` after line 22, ditto below elsewhere.",0,0.9930431842803955
181916302,4756,guozhangwang,2018-04-16T23:40:40Z,"nit: replace the `_1/2/3` suffix with some more meaningful name? e.g. `simple`, `aggregate`, `join`?",0,0.9944585561752319
181972834,4756,debasishg,2018-04-17T07:18:17Z,done ..,0,0.9705991744995117
181973173,4756,debasishg,2018-04-17T07:19:47Z,done ..,0,0.9705991744995117
181974944,4756,debasishg,2018-04-17T07:28:02Z,enriched ..,0,0.977510392665863
181975406,4756,debasishg,2018-04-17T07:30:03Z,done ..,0,0.9705991744995117
181975843,4756,debasishg,2018-04-17T07:31:59Z,done ..,0,0.9705991744995117
181978439,4756,debasishg,2018-04-17T07:43:03Z,done ..,0,0.9705991744995117
181978475,4756,debasishg,2018-04-17T07:43:11Z,done ..,0,0.9705991744995117
181978790,4756,debasishg,2018-04-17T07:44:41Z,done ..,0,0.9705991744995117
181979232,4756,debasishg,2018-04-17T07:46:16Z,done ..,0,0.9705991744995117
181979824,4756,debasishg,2018-04-17T07:48:50Z,done ..,0,0.9705991744995117
181980358,4756,debasishg,2018-04-17T07:50:55Z,done ..,0,0.9705991744995117
181980630,4756,debasishg,2018-04-17T07:52:07Z,removed ..,0,0.971264660358429
181981140,4756,debasishg,2018-04-17T07:54:09Z,removed ..,0,0.971264660358429
181982186,4756,debasishg,2018-04-17T07:57:46Z,done ..,0,0.9705991744995117
181984159,4756,debasishg,2018-04-17T08:02:37Z,done ..,0,0.9705991744995117
181985862,4756,debasishg,2018-04-17T08:09:17Z,"i am not sure i understand your concern. the only purpose of this implicit is to allow an implicit conversion from `tuple2` to `keyvalue(key, value)`. just a helper which we found useful in many cases for developing applications or tests.",0,0.9488773345947266
181986497,4756,debasishg,2018-04-17T08:11:46Z,removed the duplicate entry ..,0,0.9712435007095337
182133565,4756,guozhangwang,2018-04-17T15:59:15Z,"here is my concern: in `map` and `flatmap`, we call [code block] does that mean that for each pair of k, v pair parameters, we would first construct a `tuple2` object of this case class, and then apply the mapper, and then create a new `keyvalue` from the result `tuple2` object? if that is true, then we are creating a short-lived object for each record processed in `map`. i'm not sure if it will have a pressure on the gc.",0,0.9438591599464417
182333791,4756,debasishg,2018-04-18T07:37:56Z,- you are correct that with the current implementation there will be `tuple2`s created. but it's difficult to say if there will be gc pressure. for that we need to analyze runtime behaviors and see what the jit does. there's of course a way we can fall back to the implementation which does less allocation .. [code block] we did run some tests in bulk to check the diff in performance between the 2 versions. couldn't find much of a difference though.,0,0.980536937713623
182418338,4756,seglo,2018-04-18T13:05:49Z,:+1:,0,0.9166757464408875
182418770,4756,seglo,2018-04-18T13:07:07Z,:+1:,0,0.9166757464408875
182424831,4756,ijuma,2018-04-18T13:25:51Z,not sure what you mean . the scala version is usually part of the artifact name.,0,0.6992051601409912
182448107,4756,seglo,2018-04-18T14:30:39Z,"i'm not very familiar with gradle, but it appears to not support cross building jars in the same manner as sbt. the build needs to be run for each scala version you want a jar for, but the output won't encode the version into the filename. i think what we need to do is add a task to the gradle file, or some other build related packaging script, to pluck the generated `kafka-streams-scala` file, rename it to include the scala version, and then publish it to maven central. ex) the built outputs this when specifying a 2.12 `scala_version` (`./gradlew -pscalaversion=2.12 jar`) [code block] when a release artifact is published we'll publish a file: `kafka-streams-scala_2.12-1.2.0.jar` with the scala major version encoded into the artifact name. a maven user would reference the artifact with: [code block] please let me know if i'm missing something here about the kafka build system. on a related note i found a gradle build plugin that handles cross building projects and referencing scala dependencies in a sbt style here: [a link]",0,0.9175398349761963
182454071,4756,ijuma,2018-04-18T14:45:42Z,"we already so the right thing for core jars. we just need to follow the same approach. and yes, the scala version needs to be encoded in the artifact id. not sure what was trying to say, but doesn't seem correct to me.",0,0.9574659466743469
182461208,4756,seglo,2018-04-18T15:04:21Z,"ok, is the approach you refer to in the core project of the `build.gradle`? i'll take a closer look. wrt the docs is correct that we should update the maven dependency examples to include the scala version.",0,0.9929030537605286
182503294,4756,guozhangwang,2018-04-18T17:13:46Z,"what i was saying is that when we build the artifact we already chose which scala version to use compiling the jar and made the scala version as part of the artifact name, so users do not need to specify the scala version in declaring the dependency, but just: [code block]",0,0.9913628101348877
182704470,4756,seglo,2018-04-19T10:40:56Z,i'll correct this to include the scala version (2.11) across all the maven `pom.xml` references.,0,0.9926477670669556
182704820,4756,seglo,2018-04-19T10:42:14Z,we don't need to specify the scala version here. the `%%` operator in sbt will automatically determine the right artifact based on the running scala version.,0,0.9927570223808289
182705719,4756,seglo,2018-04-19T10:46:15Z,:+1:,0,0.9166757464408875
182705959,4756,seglo,2018-04-19T10:47:21Z,:+1:,0,0.9166757464408875
182706259,4756,seglo,2018-04-19T10:48:44Z,:+1:,0,0.9166757464408875
182706791,4756,seglo,2018-04-19T10:51:22Z,:+1:,0,0.9166757464408875
182707211,4756,seglo,2018-04-19T10:53:13Z,"i followed the convention of preceding java examples which also have indentation, but i'll remove the indentation for the scala example.",0,0.9890608787536621
182711723,4756,seglo,2018-04-19T11:13:11Z,:+1:,0,0.9166757464408875
182742751,4756,mjsax,2018-04-19T13:21:46Z,that's what i meant by my comment -- sorry for expressing myself unclear.,-1,0.990607500076294
184075333,4756,miguno,2018-04-25T14:16:17Z,"this doesn't look right to me. the latest `trunk` build of kafka only generates the following artifact(s): [code block] the maven coordinates for the artifacts above have an `artifactid` of `kafka-streams-scala`, not `kafka-streams-scala_2.11`.",0,0.9853576421737671
184082552,4756,miguno,2018-04-25T14:34:24Z,"this example code doesn't compile, because e.g. the import for `streamsbuilder` is missing (from package `org.apache.kafka.streams.scala`). i would probably double-check the other examples that are shown in the documentation, too.",0,0.9939370155334473
184119748,4756,guozhangwang,2018-04-25T16:11:54Z,"looking at the `build.gradle` again, today we only build `kafka-streams-scala` with the default scala versions defined in `dependencies.gradle`, 2.11.12. if we want to publish multiple artifacts with different scala versions we should follow the `core` project pattern, i.e. sth. like: [code block] we could also consider just building one artifact with the default scala version, in this case we would remove the suffix here and add the explanation which scala version users should be expected to use.",0,0.9953794479370117
184124327,4756,seglo,2018-04-25T16:25:25Z,"i recommend releasing versions of `kafka-streams-scala` for both major versions of scala currently supported by kafka. we should copy build and release conventions used by kafka core so that both artifacts are produced. i'm not very familiar with gradle or the kafka release process, so i wasn't sure how far to go with this, but now that that gradle snippet is right in front of me it's clear that the same should be done for this library. i believe recommended this earlier, but i didn't make the appropriate update before the merge. ~~ how are multiple versions of kafka core published at part of the release process? is the build script called twice with appropriate `scalaversion` parameter?~~ nevermind, i see how it's done now. only making the library available to scala 2.11 will leave behind a lot of users that are already on 2.12, which has been out for several years now. cross building (building an artifact per version of scala) will also make it a trivial matter to support future of versions of scala in the release process.",0,0.597002387046814
184148190,4756,miguno,2018-04-25T17:42:03Z,"i agree that we should generate artifacts for both 2.11 and 2.12, like we do for kafka core.",0,0.9834426045417786
184153041,4756,guozhangwang,2018-04-25T17:56:24Z,sounds good. could you submit a follow-up pr to modify `build.gradle` for publishing multiple artifacts for different scala versions of `kafka-streams-scala` then?,1,0.7900579571723938
184153302,4756,guozhangwang,2018-04-25T17:57:11Z,could you take a look?,0,0.9828481674194336
184193473,4756,seglo,2018-04-25T20:20:20Z,"yes. i'm travelling atm, but i'll make a new pr in the next few days.",0,0.9556874632835388
184193680,4756,seglo,2018-04-25T20:21:11Z,yes. i'll test the snippets in the build pr.,0,0.9816502928733826
186375027,4756,miguno,2018-05-07T09:37:32Z,"the single parameter for `transform()` is a `transformer`, not a `transformersupplier`. the variable needs renaming and the javadocs updating.",0,0.9943879246711731
186387729,4756,miguno,2018-05-07T10:44:02Z,i raised [a link] for this.,0,0.9854602217674255
65546724,1446,enothereska,2016-06-02T14:13:40Z,"these name changes are not strictly part of this fix, i'm wondering if we can open a minor pr for these while having this pr focus on streams only (to avoid confusion).",0,0.9690611362457275
65564787,1446,aartigupta,2016-06-02T15:42:11Z,"agreed, theses were not intended for this fix, they managed to sneak their way in. my bad, fixed it now",-1,0.9893605709075928
65923002,1446,jklukas,2016-06-06T16:32:36Z,the line break here seems unnecessary.,0,0.8241376876831055
65923529,1446,jklukas,2016-06-06T16:36:02Z,"since there are now two implementations of `streamsmetrics`, is it confusing to have them both named `streamsmetricsimpl`? this could be `threadstreamsmetrics` and the other could be `processornodestreamsmetrics`.",0,0.9845557808876038
65947627,1446,enothereska,2016-06-06T18:56:29Z,do we still need the subsequent variable?,0,0.9915837049484253
65948134,1446,enothereska,2016-06-06T18:59:27Z,i wonder if there is a way to use the other sensor calls for the latency sensor too. or will this one always remain special?,0,0.973339319229126
65948578,1446,enothereska,2016-06-06T19:02:06Z,"would it be better for `metrics` to be passed in the `processornode` constructor instead? for example, like it's done in the `streamthread` constructor.",0,0.9948257803916931
65948746,1446,enothereska,2016-06-06T19:03:11Z,same comment as above about passing in constructor instead.,0,0.988560140132904
65948820,1446,enothereska,2016-06-06T19:03:36Z,same comment as above about passing in constructor instead.,0,0.988560140132904
65951530,1446,enothereska,2016-06-06T19:20:32Z,is it correct to do the commit sensor recording for task.node() or even here? why not do it in `streamtask's` `commit`?,0,0.9952150583267212
65951650,1446,enothereska,2016-06-06T19:21:19Z,is it correct to do the punctuation sensor recording for task.node() or even here? why not do it in `streamtask's` `punctuate`?,0,0.9952321648597717
66099715,1446,aartigupta,2016-06-07T15:58:00Z,"there seem to be two ways to make this happen a. for the processornode to accept metrics in the constructor, the processornodefactory would have to have a pointer to metrics, which would imply that addprocessor in topologybuilder would need to have that, and since metrics is internal to kstreams, users of topologybuilder do not have a pointer to metrics. alternatively b. the build method of processornodefactory can take metrics in addition to applicationid and then a processornode can be constructed by passing metrics in the processornode constructor as opposed to piggy backing on the streamsmetrics which the current review request shows (which is not uniform with streamthread...) b, would look like this [code block]",0,0.9946566820144653
66102111,1446,aartigupta,2016-06-07T16:11:35Z,"you are correct, previously this made sense since we did not expose adding arbitrary sensors onto the base metrics registry, but now that we do, having this in the interface stands out as odd that said there seems to be a lot of boiler plate code around tags, parsing and logging. // first add the global operation metrics if not yet, with the global tags only sensor parent = metrics.sensor(scopename + ""-"" + operationname); addlatencymetrics(metricgroupname, parent, ""all"", operationname, this.metrictags); [code block] what do these tags buy us ? (it is not clear :) ) if we can get rid of the tags, then does it make sense to have an a base implementation of the streamsmetrics interface, because with the exception of the actual sensors contained in them, the two implementations start to look very similar protected class processornodestreamsmetrics implements streamsmetrics .... protected class threadstreamsmetrics implements streamsmetrics ....",0,0.9840302467346191
66291188,1446,aartigupta,2016-06-08T16:35:15Z,"you are right, this was not the right place. streamtask's commit is the right place. fixed locally and working on a unit test and integration test to ""count down"" commit and punctuate metrics to ensure correctness.",0,0.9868307113647461
91086491,1446,ijuma,2016-12-06T14:23:19Z,should this be `recordlevel`?,0,0.9939560294151306
91086702,1446,ijuma,2016-12-06T14:24:24Z,"we don't need the `sensor` prefix in the name. also, are these the only two levels we care about?",0,0.9915046095848083
91231975,1446,aartiguptaa,2016-12-07T06:08:57Z,"info would map to the level we use for normal production runs, and debug could be used to optimize the job in the development or instrumentation/debugging phase. can't think of any more use cases, maybe trace could be a finer level, but personally have never found that useful.",0,0.9866416454315186
91587971,1446,guozhangwang,2016-12-08T19:25:50Z,"nit: new line between functions, ditto below.",0,0.897019624710083
91588145,1446,guozhangwang,2016-12-08T19:26:45Z,"also we need to add the javadoc for those newly added functions, especially explain the `recordlevel`.",0,0.9898749589920044
91588780,1446,guozhangwang,2016-12-08T19:29:50Z,"we can reuse `recordlevel.sensor_info_str` etc here, to avoid split places of those global constant strings.",0,0.9945539236068726
91589025,1446,guozhangwang,2016-12-08T19:31:07Z,could this result in npe? may be we can directly throw an illegalargumentexception here.,0,0.9771289229393005
91589076,1446,guozhangwang,2016-12-08T19:31:25Z,"how about returning ""unknown"" or ""illegal_level"" than null?",0,0.9830819964408875
91590844,1446,guozhangwang,2016-12-08T19:39:29Z,"this is a meta comment: in additional to skip `record`, we can probably go further to even avoid registering the sensor at all in the reporter. its benefits are: 1. the reporter will not show these metrics at all (i.e. they will not display in the monitoring ui, for example), whereas today the reporter will still show these metrics but the value is always the initialized value (most likely 0). 2. we can further reduce the overhead of function calls as well as the registry space; i'm not sure by how much though. admittedly this will require a larger change on `o.a.k.common.metrics`. what do you think ?",0,0.9858397245407104
91591063,1446,guozhangwang,2016-12-08T19:40:45Z,ditto above.,0,0.9803552627563477
91591235,1446,guozhangwang,2016-12-08T19:41:40Z,is this really part of this pr?,0,0.9911686182022095
91592681,1446,guozhangwang,2016-12-08T19:48:09Z,"won't time be always null here, since it is never initialized?",0,0.9841150045394897
91594176,1446,guozhangwang,2016-12-08T19:55:40Z,"`streams-processor-node-metrics` to be consistent with other group names, and only include the node name in the tags as `put(""processor-node-id"", name);` (not sure why you added a ""-"" before the name?).",0,0.9953912496566772
91594356,1446,guozhangwang,2016-12-08T19:56:39Z,"nit: ""processor-node"" to be more clear with other scope, for example ""producer-metrics"" also have a per-node sensor level, where `node` there means the destination brokers.",0,0.9941537976264954
91595483,1446,guozhangwang,2016-12-08T20:02:31Z,"this is not introduced in this patch, but we could fix it together: in line 1133 below [code block] we'd better change it to [code block]",0,0.993399977684021
91596211,1446,guozhangwang,2016-12-08T20:06:29Z,"again, to be consistent the sensor name better be the form of `(sensornameprefix + "".node-forward-time""): to add a `.` after the prefix, and we do not need the `name` as the suffix since it is already used in tags.",0,0.9939979314804077
91596966,1446,guozhangwang,2016-12-08T20:10:50Z,"the explanation does not sound right to me. i think it is ""the average per-second number of records processed by this processor"". also maybe we can rename the variable name to `nodethroughputsensor` to be more meaningful?",0,0.9633829593658447
91596999,1446,guozhangwang,2016-12-08T20:11:03Z,ditto for other sensor names.,0,0.8446000218391418
91597224,1446,guozhangwang,2016-12-08T20:12:24Z,seems like the explanation text are not updated after copying :p,1,0.8251142501831055
91597427,1446,guozhangwang,2016-12-08T20:13:33Z,"is the creation and deconstruction rate really useful? i feel the creation and deconstruction latency is more useful, since for rate it is mostly 0 unless there is a rebalance.",0,0.8697264194488525
91597796,1446,guozhangwang,2016-12-08T20:15:57Z,"also we do not need the prefix in metric name, but only in sensor name.",0,0.9916103482246399
91598240,1446,guozhangwang,2016-12-08T20:18:23Z,"and following that comment, the sensor name can be changed to `(sensornameprefix + "".process-throughput"")`, and the metrics name can be changed to `""record-process-rate""`.",0,0.9938656687736511
91598693,1446,guozhangwang,2016-12-08T20:21:13Z,"i think this is not a per-node sensor, but rather a per-task sensor right? shall we create a `taskmetrics` class accordingly for this layer?",0,0.9937547445297241
91598975,1446,guozhangwang,2016-12-08T20:22:59Z,"by layer i mean three layers: thread, task, node, and for task i think just one sensor ""commit"" is good enough, for punctuating the node-level metrics should be sufficient to cover.",0,0.9771101474761963
91599246,1446,guozhangwang,2016-12-08T20:24:37Z,why we want to pass in these as parameters instead of computing them internally? it seems `streamsmetricsimpl` is still only used once.,0,0.9811440706253052
91599430,1446,guozhangwang,2016-12-08T20:25:45Z,why we do not want to use `computelatency` any more?,0,0.9845845103263855
91668435,1446,aartiguptaa,2016-12-09T07:13:36Z,"removed it for now, don't remember why and when this was added.",0,0.9698077440261841
91676685,1446,aartiguptaa,2016-12-09T08:42:53Z,"done, that makes it consistent. feeling better about it after that refactor.",1,0.9322985410690308
91679111,1446,aartiguptaa,2016-12-09T09:02:50Z,fixed the variable name to streamsmetrics (was sensors) streamsmetricsimpl is used 12 times. also fixed the computation,0,0.9947311878204346
91680753,1446,dguy,2016-12-09T09:16:06Z,why protected?,0,0.9564509987831116
91685809,1446,dguy,2016-12-09T09:49:32Z,why not record this inside `init`? it seems wrong to expose a field of `processornode`,0,0.9489814639091492
91700552,1446,enothereska,2016-12-09T11:25:12Z,"unfortunately 2 different tasks on the same thread can register the same two metrics and we'll get an exception in the thread library (current test fails because of this). so the prefix is not sufficient just for the sensor, but is also needed for the metric.",0,0.807384729385376
91821831,1446,guozhangwang,2016-12-10T00:43:02Z,"that's right, but shouldn't the `sensornameprefix` contains that? currently it only contains the taskid but i think it should include both since each task can have its own copy of the topology. as for the group name, it is used for grouping metrics that may come from different classes even (see producer's `sender` and `selector` classes), so it should not include the node id, but rather just ""streams-processor-node-metrics"".",0,0.9944849610328674
91821954,1446,guozhangwang,2016-12-10T00:45:08Z,"this is at the very critical path of streams, called millions of times per sec, so calling `time.nanoseconds()` on each call is really expensive if `debug` level is used.",0,0.5570722818374634
91822004,1446,guozhangwang,2016-12-10T00:45:45Z,+1.,0,0.9498199820518494
91822140,1446,guozhangwang,2016-12-10T00:47:38Z,do we still need to keep this variable as it is now in the taskmetrics already?,0,0.9942722320556641
91922123,1446,enothereska,2016-12-12T10:40:57Z,done.,0,0.9640594124794006
91923060,1446,enothereska,2016-12-12T10:46:48Z,done.,0,0.9640594124794006
91923083,1446,enothereska,2016-12-12T10:46:56Z,done.,0,0.9640594124794006
91924605,1446,enothereska,2016-12-12T10:56:27Z,i'm not sure i understand your comment. `sensornameprefix` contains the task id. we use that for both sensor and metric name. with your last comment you seem to be saying the same we're saying. unless i misunderstood it. so as action item i'm just re-adding `sensornameprefix` to the metric name? (i can probably rename `sensornameprefix` to just `prefix` since it's used for sensor and metric). anything else? thanks.,0,0.7424979209899902
91926667,1446,enothereska,2016-12-12T11:10:52Z,fixed.,0,0.979083240032196
91927862,1446,enothereska,2016-12-12T11:19:14Z,actually i still need protected because source and sink node have to use this field.,0,0.9841581583023071
92004035,1446,dguy,2016-12-12T18:07:12Z,can this be private now?,0,0.9917477369308472
92006773,1446,dguy,2016-12-12T18:21:24Z,"in this method and `punctuate` the blocks of code are largely the same. is this pattern going to be common? if it is just in this class, then i'd probably create a method in here that accepts a `runnable` and have `process` and `punctuate` delegate to it, i.e., [code block]",0,0.9933852553367615
92021599,1446,enothereska,2016-12-12T19:31:49Z,annoyingly sourcenode uses it.,0,0.5397894978523254
92027755,1446,guozhangwang,2016-12-12T20:01:12Z,"my suggestion is to remove the suffix of `name`, which is the processor name in sensor, since it is already included in the tags. take the `jmxreporter` as an example, it generates the mbean for streams as: [code block] where `kafka-streams` is the prefix passed in `kafkastreams`, and `streams-processor-node-metrics` is the pre-defined `metricgrpname `. you can see here that the processor name suffix in attribute names are redundant, and more generally for any reporters implementations, metrics will be grouped by ""group name"" and ""tags"".",0,0.9941287040710449
92028572,1446,guozhangwang,2016-12-12T20:05:35Z,"tags are not used at all, actually do they need to be added? see my previous comment.",0,0.9910974502563477
92028877,1446,guozhangwang,2016-12-12T20:07:04Z,tags are not used here.,0,0.9848414659500122
92029084,1446,guozhangwang,2016-12-12T20:08:02Z,"this additional tag pair `""processor-node-id"" -> name` is redundant since it is already added in line 168.",0,0.9944151639938354
92029769,1446,guozhangwang,2016-12-12T20:11:32Z,"i left a follow-up comment about not needing to include `name` in the prefix anymore, let me know what do you think.",0,0.9788228869438171
92033622,1446,guozhangwang,2016-12-12T20:33:02Z,"one more meta comment about `scopename`, `entityname` and `operationname`: in latency sensors they are managed as a two-layer metrics with the top-level metrics as: 1. `prefix.scopename-operationname`; which is the parent of all: 2. `prefix.scopename-entityname-operationname`; which means that whenever any of the children get updated, the parent also gets update. so for state store operations. `scopenames` are `in-memory-state`, `rocksdb-state` etc, and `entitynames` are specific store names, and `operationname` are `put`, `get` etc. in addition, the `scopename` is also used in the group name, so you can think of groupnames as `streams-in-memory-state-metrics` `streams-rocksdb-state-metrics` `streams-processor-node-metrics` `streams-task-metrics` `streams-metrics` /* this is actually per-thread metrics */ etc where scope is `processor-node`, `task`, etc. in your implementation, the `scopename` is removed from the sensor name, which i think is a good fix as it would redundant since it is already in the group name. however, the parental hierarchy is not encoded in the scopename / entityname / operationname in this function, and i'm wondering if it still makes sense to still capture this hierarchy in these names while still letting users specify ""additional"" parents in the last parameters?",0,0.9906244874000549
92224454,1446,enothereska,2016-12-13T17:42:54Z,"ok, it's latency now.",0,0.981067419052124
92228908,1446,enothereska,2016-12-13T18:05:21Z,one problem here is the `prefix` which so far has been hardcoded in `streamthread.java`,0,0.9933446645736694
92230530,1446,guozhangwang,2016-12-13T18:12:51Z,"i'm not sure i understand your comment above? btw following my comment below i think we still cannot remove the `scopename` from the sensor name, since otherwise they will be collapsed into the same sensor.",0,0.9774667620658875
92235489,1446,enothereska,2016-12-13T18:36:31Z,i only have 2 cases of this so far. worried about one more layer of indirection.,-1,0.9465198516845703
92237153,1446,enothereska,2016-12-13T18:44:00Z,"i see, sure. thanks.",1,0.96910560131073
92248305,1446,enothereska,2016-12-13T19:35:26Z,"with my latest commit i think i have got things consistent, could you have a look if you can. with `jconsole` i can verify that i can see the sensors and metrics.",0,0.8212528228759766
92681462,1446,mjsax,2016-12-15T19:25:52Z,"of -> or ""to ensure name well-formedness and conformity "" -> to ensure that metric names are well-formed and conform",0,0.9920142292976379
92709588,1446,mjsax,2016-12-15T22:00:00Z,in `processornode` we also do should we do the same here? what about a more general way to measure this latency? it seems we do not do this correctly right -- we could abstract `nodemetrics` such that it can be private in and avoid code duplication. i am also wondering why `this.processor.init(...)` is only called `processornode` and not in `sourcenode` or `sinknode`.,0,0.9769929647445679
92719109,1446,guozhangwang,2016-12-15T22:57:38Z,"honestly i am not sure if we should ever be ""completely generic"" or not. but if we feel that we should do it, then we can simply expose them as [code block] in stead of still enforcing the naming convention in terms of `scope, entity, operation`? or simply just expose the internal `metrics` to let users call its `sensor` functions directly: [code block] if we do not want to allow ""completely generic sensor registry"", then i'd suggest renaming the functions to `addgenericsensor` and make it very clear how the `scope / entity / operation` names will be used to construct the group-name, sensor name, or even tags, etc in the javadoc.",0,0.9190265536308289
92724770,1446,guozhangwang,2016-12-15T23:40:34Z,"this is not introduced in this pr, but i'm wondering if there is any value we add this specific `addcachesensor` instead of just using the ""generic adding sensor"" functions since we have already introduced them in this pr. afterwards there is only one place using it for recording `cache hits` with `min, max, avg` which to me is quite generic usage.",0,0.9633843898773193
92725173,1446,guozhangwang,2016-12-15T23:43:58Z,we could save this `nanoseconds` with `mayberecord` pattern as well with debug level.,0,0.9922309517860413
92725338,1446,guozhangwang,2016-12-15T23:44:59Z,we could apply the `mayberecord` pattern in the `meteredstore` as well for all these debug level sensors.,0,0.9947729706764221
92725404,1446,guozhangwang,2016-12-15T23:45:36Z,ditto above.,0,0.9803552627563477
92725740,1446,guozhangwang,2016-12-15T23:48:22Z,there are a couple of other places where we can potentially save `nanoseconds` calls (left comments on those places where `sensor_debug` sensors may require getting the startns and endns). so i feel this could be a common pattern to add.,0,0.9882398843765259
92870610,1446,enothereska,2016-12-16T19:24:35Z,"this pr is not about allowing users to register their own sensor yet, for the scope of this pr these are helper functions for our own usage internally. i'd like to separate the two if possible.",0,0.9792609810829163
92999354,1446,enothereska,2016-12-19T09:57:26Z,"good catch, thanks!",1,0.9953822493553162
92999461,1446,enothereska,2016-12-19T09:58:00Z,thanks!,1,0.9051083922386169
93007886,1446,enothereska,2016-12-19T10:48:03Z,ok.,0,0.9740158319473267
93012648,1446,enothereska,2016-12-19T11:19:33Z,the answer is that we'll provide helper functions but also expose the metrics registry as well.,0,0.9879597425460815
93102705,1446,enothereska,2016-12-19T19:32:23Z,"done, thanks.",1,0.6998467445373535
93230666,1446,ijuma,2016-12-20T12:50:12Z,maybe `the higher recording level for metrics` or something like that?,0,0.9934749007225037
93230738,1446,ijuma,2016-12-20T12:50:39Z,adding a config typically requires a kip. are we planning to do that?,0,0.9748265743255615
93231030,1446,ijuma,2016-12-20T12:52:30Z,why is this not simply `info` and `debug`?,0,0.9879621863365173
93231096,1446,ijuma,2016-12-20T12:52:55Z,why do we expose this instead of getting it via the enum?,0,0.9923743605613708
93231227,1446,ijuma,2016-12-20T12:53:51Z,"typically, this would be done by iterating over the enums (i.e. `recordlevel.values()`) and then it doesn't have to be changed if we add more levels. any reason why we can't do that?",0,0.9897081851959229
93231324,1446,ijuma,2016-12-20T12:54:33Z,"instead of doing this, we can simply override `tostring` in each enum. however, if we go with my suggestion of renaming the enum values, the `tostring` will be the right one by default, i think.",0,0.9901785850524902
93231397,1446,ijuma,2016-12-20T12:55:07Z,this should disappear with my suggestion.,0,0.9492776393890381
93232020,1446,ijuma,2016-12-20T12:59:15Z,"we shouldn't really be using the `ordinal` in this way imo. we should expose a method in the `recordlevel` class to return a boolean in this case. for example, the invocation could look like `recordlevel.shouldrecord(config.recordlevel)`. also, using the `ordinal` internally can work, but it's a bit opaque (i.e. if people change the order of definition, they break the code). one often adds a new parameter to the enum instance to make it clearer.",0,0.9902254939079285
93232147,1446,ijuma,2016-12-20T13:00:06Z,`shouldrecord`? `mayberecord` sounds like it would record it for you.,0,0.993523359298706
93275266,1446,enothereska,2016-12-20T16:39:03Z,ok,0,0.8787186145782471
93275350,1446,enothereska,2016-12-20T16:39:25Z,what do you think?,0,0.9768986105918884
93275549,1446,enothereska,2016-12-20T16:40:24Z,ok,0,0.8787186145782471
93275798,1446,enothereska,2016-12-20T16:41:36Z,good point.,1,0.9406900405883789
93276750,1446,enothereska,2016-12-20T16:46:33Z,yup.,0,0.7193294763565063
93276771,1446,enothereska,2016-12-20T16:46:38Z,yup.,0,0.7193294763565063
93276794,1446,enothereska,2016-12-20T16:46:44Z,"yup, thanks.",1,0.8448188900947571
93277891,1446,enothereska,2016-12-20T16:51:44Z,"makes sense, thanks.",1,0.7218227386474609
93283534,1446,enothereska,2016-12-20T17:18:07Z,ok,0,0.8787186145782471
93296992,1446,guozhangwang,2016-12-20T18:33:22Z,"yup, sounds good to me.",1,0.8889482617378235
93298089,1446,guozhangwang,2016-12-20T18:39:23Z,do we really want to expose this function as a public api ?,0,0.9920701384544373
93298423,1446,guozhangwang,2016-12-20T18:41:15Z,"so what is the final decision for these two functions? i saw that you have already exposed the underlying `metrics` registry directly; in this case do we still need these two functions? personally i feel it is not necessary any more, but if you have a strong opinion maybe we should at least rename it to `addgenericsensor` to be consistent with other two.",0,0.9820494055747986
93298928,1446,guozhangwang,2016-12-20T18:43:54Z,shall we add a `recordthroughput` function as well?,0,0.9929165840148926
93304064,1446,ijuma,2016-12-20T19:10:19Z,"thanks for the updates. looking better. :) one thing i wasn't too clear about. for the `shouldrecord` case, we can pass a number to make the comparison more efficient. it's pretty similar to using `ordinal`, but the number is explicit instead of being based on the order of definition. classes like `apikeys` and `securityprotocol` do that. we could also just use the ordinal if it's just used internally. another thing is that enums get a `name` method that returns the declaration name. in this case `info` and `debug`. so, again, if it's an internal thing, we could potentially reuse that. defining it explicitly is fine too (we tend to do that for public enums. finally, we don't use getter notation in kafka so `getvalue()` should be `value` (if we decide to keep it).",1,0.9951692223548889
93305783,1446,enothereska,2016-12-20T19:19:21Z,sure. it's useful internally as well. this pr is primarily for internal needs so far.,0,0.980354368686676
93310227,1446,guozhangwang,2016-12-20T19:43:16Z,"the issue is that, streamsmetrics is a public class so any public functions of this interface will be accessible to users as well. if we really want to add it to let users be able to use it, we need to think about how to clearly differentiate with `recordlatency`, when to use which, etc. personally i'd rather not exposing it but only for internal usage, and let users to make their own optimizations if they want.",0,0.9806488752365112
93505557,1446,junrao,2016-12-21T19:39:40Z,do we need to expose a similar config on the broker side since the broker also uses the client side metrics in certain cases?,0,0.9933944344520569
94743881,1446,enothereska,2017-01-05T10:22:16Z,done.,0,0.9640594124794006
94746977,1446,enothereska,2017-01-05T10:44:00Z,ok.,0,0.9740158319473267
94748307,1446,enothereska,2017-01-05T10:53:17Z,"ok, removing.",0,0.9745228886604309
94751245,1446,enothereska,2017-01-05T11:16:35Z,yeah probably. will add. thanks.,1,0.9814167022705078
94757229,1446,enothereska,2017-01-05T12:09:16Z,"will do this, ideally before feature freeze, but definitely before code freeze. stay tuned.",0,0.9884853363037109
95413470,1446,guozhangwang,2017-01-10T17:22:32Z,i am not sure if it is needed: `metrics.sensor` will recursively link parent sensor to its children; `metrics.removesensor` will recursively remove its children sensor as well.,0,0.9460524320602417
95413953,1446,enothereska,2017-01-10T17:25:00Z,"`addlatencymetrics` is supposed to return 1 sensors, but it creates 2 internally. one of them, the parent, is never exposed to the user, so the user has no way of deleting it. with this solution, the user deletes the child sensor and we internally delete the parent sensor.",0,0.9854434132575989
95415769,1446,guozhangwang,2017-01-10T17:33:39Z,"got it, thanks.",1,0.6973482370376587
95559941,1446,enothereska,2017-01-11T11:24:12Z,"done now, thanks",1,0.5960099697113037
95629070,1446,guozhangwang,2017-01-11T17:30:33Z,is this intentional? ditto below.,0,0.9420239925384521
191968009,5101,lindong28,2018-05-31T01:29:34Z,why do we need to change it to 0? do we expect to initialize `controllercontext.epochzkversion` to -1?,0,0.99178546667099
192005699,5101,lindong28,2018-05-31T07:05:43Z,nits: we probably don't need `{` here so that the code style is consistent with the existing code.,0,0.9919496774673462
192008864,5101,lindong28,2018-05-31T07:22:46Z,"here `setdatarequest/setdataresponse` is replaced with `multioprequest/multiopresponse`. this may cause problem for existing code (e.g. `zookeeperclient.send()`) whose logic relies on the type of the request. instead of adding a new subclass of asyncrequest, would it be better to modify the existing request (maybe the asyncrequest) to include the expected controller epoch version so that, when the expected controller epoch exists, zookeeperclient.send() will take care of the version check?",0,0.994855523109436
192020116,5101,hzxa21,2018-05-31T08:13:18Z,"i think the `initialcontrollerepochzkversion` represents the initial value when the controller epoch znode first gets created so it should be set to 0 for consistency just like `initialcontrollerepoch`. also, during cluster initialization (i.e controller epoch znode does not exists), we explicitly set `controllercontext.epochzkversion` to `initialcontrollerepochzkversion`, which was 1 before. ([a link] this will cause problems for the first controller to update zk states after this patch because the actual znode version is 0. this is not a problem before because we didn't use `controllercontext.epochzkversion` to fence zk state updates and after controller failover, we will update it by reading controller epoch znode. this change is only for readbility. actually we can just remove the line to set `controllercontext.epochzkversion` to `initialcontrollerepochzkversion` and keep `initialcontrollerepochzkversion` to be 1.",0,0.9912514090538025
192020231,5101,hzxa21,2018-05-31T08:13:50Z,thanks for pointing out. will fix that.,1,0.8992891907691956
192023554,5101,hzxa21,2018-05-31T08:27:18Z,"that is a good point. the reason why i add the multiop subclass is that we can extend `zookeeperclient` to handle arbitrary multi() operations, not specifically for checking controller epoch version and updating zk states. also, i think `zookeeperclient` should only be aware of zookeeper related context not the kafka related context (e.g. controller epoch version) for cleanness. instead of modifying asyncrequest, do you think it is better to add some helper functions in `kafkazkclient` to wrap around the check and set/update/create logic? also, i am a little bit confused on what are the problems caused by `zookeeperclient.send()` if we use `zookeeper.multi()` for `multioprequest`. can you give me more contexts on that?",0,0.8816578984260559
192188682,5101,lindong28,2018-05-31T18:09:13Z,cool. this makes sense.,1,0.9810681939125061
192206415,5101,lindong28,2018-05-31T19:10:04Z,"i think it is reasonable not to have kafka specific thing in zookeeperclient. on the other hand we don't have to -- we can provide anther zk path and expected version as parameters to these apis, the api should return proper error without executing the original request if the version of the path is different from the expected version. this solution is probably not kafka specific. not sure that we don't need arbitrary multi() operations in the near future. currently we only need to check the zk version of another path when controller changes zookeeper state. after checking the code, it seems that there is no current problem caused by using multioprequest. but some information (e.g. `createresponse.name` and `setdataresponse.stat`) is discarded in the response which may potentially be problem in the future. in general it seems more flexible to be able to use different case class for different requests so that we can have different parameters (as is the case now) and apply different processing logic to different case class. just my opinion. if you like the current solution, maybe you can keep it and other committers can comment on this.",0,0.9672849774360657
192302796,5101,hzxa21,2018-06-01T05:46:08Z,i see what you mean. that makes sense to me. i will update the pr to differentiate set/update/create with check parameters provided in `zookeeperclient` to expose different information. thanks for the explanation.,1,0.7922524213790894
194241899,5101,lindong28,2018-06-10T00:17:10Z,should the comment be `expected controller epoch zkversion`?,0,0.9955209493637085
194241972,5101,lindong28,2018-06-10T00:24:23Z,do we need the `path` field here? can we remove this class and replace it with e.g. `zkversioncheckresultcode: resultcode`?,0,0.9958083629608154
194242568,5101,lindong28,2018-06-10T01:08:00Z,"in general we want to the exception returned to the caller to uniquely identify the problem. but here we can output the badversionexception if either the controller epoch zkversion is bad or the data znode zkversion is bad. it maybe confusing. it is probably simpler to create a new exception, e.g. `controllerepochzkversionmismatchexception` and do the following before checking `setdataresponse.resultcode`: [code block]",0,0.9917810559272766
194242678,5101,lindong28,2018-06-10T01:17:21Z,"can we name it `case class zkversioncheck(path: string, zkversion: int )`",0,0.9939603805541992
194242922,5101,lindong28,2018-06-10T01:34:55Z,typo,0,0.9635167717933655
194243046,5101,lindong28,2018-06-10T01:44:43Z,we can name it to be `controllerepochzkversion` to be consistent with `controllercontext.epochzkversion`? same for other uses of `controllerepochversion`.,0,0.9954332113265991
194243176,5101,lindong28,2018-06-10T01:55:46Z,"the current patch checks `resultcode`, and based on its value, adds additional logic to check `checkresult`. similar to the comment for `updateleaderandisr`, could we simplify the logic here by checking `deleteresponse.checkresult` before the existing logic of checking the resultcode?",0,0.9930393099784851
194243224,5101,lindong28,2018-06-10T02:00:42Z,it seems that we will return `badversionexception` for two different scenarios. can we output a unique exception if the controller znode has different version from what is expected?,0,0.9568350315093994
194244953,5101,lindong28,2018-06-10T04:37:09Z,"`generateasyncresponsewithcheckresult()` is called for `createrequest`, `setdatarequest` and `deleterequest`. however, most of the code (or logic) in `generateasyncresponsewithcheckresult()` is different for these three requests anyway. would it be more intuitive and simpler to remove the method `generateasyncresponsewithcheckresult()` and moves its request-specific logic in `send()`? we can put the logic that is common to all requests, e.g. the first part of generateasyncresponsewithcheckresult(), in a method if needed.",0,0.9949408769607544
194577297,5101,hzxa21,2018-06-11T23:28:09Z,yes. will fix it.,0,0.982218325138092
194577987,5101,hzxa21,2018-06-11T23:32:42Z,"the path is needed to generate keeper exception with path information without assuming it to be controller epoch path. if we are going to generate the `controllerepochzkversionmismatch` exception in `kafkazkclient` instead of `keeperexception` in `zookeeperclient`, i think we can remove the path and just keep the resultcode.",0,0.9938240051269531
194578905,5101,hzxa21,2018-06-11T23:38:42Z,"thanks for the suggestion. it is simpler and cleaner this way. btw, i think we can just use `controllermoveexception()` in this case. also, related to your comment on my last commit, instead of putting the exception in some data structures, can we just simply throw the exception when the check fails? in this case, we can skip processing unnecessary controller event until we hit `controllerchange` event. to optimize it further, we can also catch 'contollermoveexception' explicitly in the `controllereventthread` and let the controller resigns immediately.",1,0.940797746181488
194578945,5101,hzxa21,2018-06-11T23:38:58Z,sure. will do.,0,0.9894702434539795
194578974,5101,hzxa21,2018-06-11T23:39:07Z,thanks. will fix.,1,0.9579344391822815
194578989,5101,hzxa21,2018-06-11T23:39:14Z,sure.,0,0.9664214849472046
194579028,5101,hzxa21,2018-06-11T23:39:29Z,will fix it. thanks for pointing out.,1,0.9223467111587524
204258438,5101,lindong28,2018-07-22T23:09:20Z,maybe rename `controllermovelistener` to `controllermovedlistener` so that it is more consistent with the existing name `eventprocessedlistener`.,0,0.9948074221611023
204258805,5101,lindong28,2018-07-22T23:21:35Z,type: should be `emptyeventqueueandreelect`. also it seems the name `cleareventqueueandreelect` is more consistent with the existing method names.,0,0.9938670992851257
204258904,5101,lindong28,2018-07-22T23:24:44Z,"nits: we typically just use `e: controllermovedexception` here for simplicity. `cme` does not provide much information since most users would still need to read the actual type to understand what it is. if it makes sense, can you rename it here and in other places of the patch?",0,0.9930150508880615
204259174,5101,lindong28,2018-07-22T23:32:47Z,in general the code may be more consistent and readable if we name the variable after this type. and `zkversioncheck` seems more informative than the `checkinfo`. can you rename the `checkinfo` here and in other places of the patch (including local variable)?,0,0.99160236120224
204259221,5101,lindong28,2018-07-22T23:34:24Z,"would it be better to rename `controllerepochzkversion` to `expectedcontrollerepochzkversion`? the current method signature seems to suggest that the `controllerepochzkversion` will be written to the znode. if it makes sense, can you rename the variable here and in other places of the patch?",0,0.9949350953102112
204259339,5101,lindong28,2018-07-22T23:37:53Z,i am wondering whether it will be useful to print the expected/current controllerepoch and zkversion. not sure if this information is already printed when controller processes `reelect` etc.,0,0.9428499937057495
204259617,5101,lindong28,2018-07-22T23:45:57Z,"just in case this patch causes any issue, it may be useful if we still print the message such as `error completing reassignment of partition ...`. if it makes sense, can you add the additional log based on the existing log (if exists) here and in other places where the `controllermovedexception` is caught and thrown?",0,0.9946342706680298
204259978,5101,lindong28,2018-07-22T23:56:12Z,"can we specify `zkversion` in the name, e.g. `controllerzkversioncheck`? also, can you add the return type to the method signature?",0,0.994726836681366
204260316,5101,lindong28,2018-07-23T00:05:52Z,"it seems that checkopresult should be either `checkresult` or `errorresult`. maybe we should throw illegalstateexception otherwise? by doing so we could simplify the signature of `getmultiopresults` to `(code, opresult)`. and we can also simplify the signature of e.g. `createresponse` such that zkversioncheckresultcode is of type `code`.",0,0.9954084753990173
204260401,5101,lindong28,2018-07-23T00:08:58Z,would it be simpler to name it `zkversioncheck`?,0,0.9950538873672485
204260465,5101,lindong28,2018-07-23T00:10:59Z,can you add the return type to the signature of `checkop()`?,0,0.9939882755279541
210026725,5101,hzxa21,2018-08-14T16:53:58Z,done.,0,0.9640594124794006
211706198,5101,hzxa21,2018-08-21T18:12:07Z,done.,0,0.9640594124794006
211706290,5101,hzxa21,2018-08-21T18:12:24Z,done.,0,0.9640594124794006
211706505,5101,hzxa21,2018-08-21T18:13:01Z,done.,0,0.9640594124794006
211706631,5101,hzxa21,2018-08-21T18:13:27Z,done.,0,0.9640594124794006
211707860,5101,hzxa21,2018-08-21T18:16:52Z,that is a good point. i have added a log in the reelect controller event to print out this information.,1,0.8374127745628357
211708052,5101,hzxa21,2018-08-21T18:17:25Z,done.,0,0.9640594124794006
211708354,5101,hzxa21,2018-08-21T18:18:20Z,done.,0,0.9640594124794006
211708407,5101,hzxa21,2018-08-21T18:18:30Z,done.,0,0.9640594124794006
211708530,5101,hzxa21,2018-08-21T18:18:49Z,yes. done.,0,0.819446325302124
211708610,5101,hzxa21,2018-08-21T18:19:02Z,done.,0,0.9640594124794006
211709050,5101,hzxa21,2018-08-21T18:20:15Z,done.,0,0.9640594124794006
211709057,5101,hzxa21,2018-08-21T18:20:16Z,done.,0,0.9640594124794006
211719034,5101,lindong28,2018-08-21T18:50:34Z,"not sure if this line invokes the callback. maybe we should change it to controllermovedlistener.apply(). if the existing version does not actually execute this callback, then it means all existing test does not catch this issue. then it may be worthwhile adding a test.",0,0.9913249015808105
211720966,5101,lindong28,2018-08-21T18:56:54Z,"nits: it seems a bit confusing that we print more information (i.e. newreplicas) for `controllermovedexception` than all other exception. it may be better to make the log information consistent and still print `error(s""error completing reassignment of partition $tp"", e)`.",-1,0.5479839444160461
211721256,5101,lindong28,2018-08-21T18:57:52Z,"can we still print `error(s""error completing preferred replica leader election for partitions ${partitions.mkstring("","")}"", e)` for consistency?",0,0.9921525120735168
211721459,5101,lindong28,2018-08-21T18:58:29Z,nits: can we replace `epoch version is now` with `epoch zk version is now`,0,0.994341254234314
211731340,5101,lindong28,2018-08-21T19:32:32Z,"since `kafkacontroller.incrementcontrollerepoch()` will always print controllercontext.epochzkversion, the only extra information we are seeking here is the current zkversion of the controller epoch znode. it seems that we only need this information when the broker observes controllermovedexception when it thinks it is controller. since `reelect` is triggered in every broker every time there is controller movement, it may not be very intuitive or necessary to print the extra log here in `relect.process()`. another thing to note that that we would like to know the zkversion of the controller epoch znode that causes the controllermovedexception, but this zk version may have changed after the controller observes controllermovedexception but before the controller processes reelect event. so it is better to read the zkversion earlier (e.g. in `controllereventthread.dowork()`) than later. the best solution is probably to include the expected zkversion in the message of `controllermovedexception` thrown by `maybethrowcontrollermoveexception()`.",0,0.9914604425430298
211734782,5101,lindong28,2018-08-21T19:44:24Z,"given that there may be other zookeeper operation other than `controllerzkversioncheck` which can also check the zkversion of the corresponding znode, some response may also show `zkversioncheckresultcode != code.ok` and cause `maybethrowcontrollermoveexception` to throw `controllermovedexception` even if it is not for the `controllerzkversioncheck`. will this be a problem? also, any chance we can also include the expected zkversion in the message of `controllermovedexception`?",0,0.9954930543899536
211735664,5101,lindong28,2018-08-21T19:47:24Z,"for code style consistency, can you change the code to use one of the following styles: [code block] or [code block]",0,0.9936518669128418
211738667,5101,lindong28,2018-08-21T19:57:09Z,"nits: i am not sure what is the expected code style here. but if there is no clear standard and it is not very obvious, it is probably simpler to keep the existing style so that we avoid back-and-force change in the open source community.",0,0.8659895062446594
212047310,5101,hzxa21,2018-08-22T17:51:22Z,done.,0,0.9640594124794006
212050784,5101,hzxa21,2018-08-22T18:01:05Z,"yes, i think it is better to include the expected zkversion in the zookeeper response and extract the information from the response when throwing `controllermovedexception`. i have added `zkversioncheckresult: option[zkversioncheckresult]` to achieve this.",0,0.991926372051239
212059088,5101,hzxa21,2018-08-22T18:24:40Z,make sense. i have removed the extra logs and included the expected zkversion in the message of `controllermovedexception`.,0,0.9923301339149475
212059196,5101,hzxa21,2018-08-22T18:24:57Z,done.,0,0.9640594124794006
212059233,5101,hzxa21,2018-08-22T18:25:04Z,done.,0,0.9640594124794006
212059283,5101,hzxa21,2018-08-22T18:25:13Z,done.,0,0.9640594124794006
212059557,5101,hzxa21,2018-08-22T18:26:05Z,i have changed it to `controllermovedlistener.apply()`. will add a test in future commits.,0,0.9925230145454407
212083665,5101,lindong28,2018-08-22T19:43:26Z,nits: can we also replace `-1` with `zkversion.matchanyversion`?,0,0.9943808913230896
212085220,5101,lindong28,2018-08-22T19:49:09Z,it seems that we need extra indentation for the body of the `if` statement.,0,0.9916328191757202
212086207,5101,lindong28,2018-08-22T19:52:42Z,`zoodefs` seems to be unused.,0,0.9848841428756714
212086264,5101,lindong28,2018-08-22T19:52:52Z,`checkresult` seems to be unused.,0,0.9795885682106018
212086460,5101,lindong28,2018-08-22T19:53:36Z,`checkresult` and `errorresult` seems to be unused.,0,0.9887879490852356
212128308,5101,hzxa21,2018-08-22T22:18:47Z,fixed.,0,0.979083240032196
212128341,5101,hzxa21,2018-08-22T22:18:56Z,removed.,0,0.9782117605209351
212128387,5101,hzxa21,2018-08-22T22:19:03Z,removed.,0,0.9782117605209351
212128438,5101,hzxa21,2018-08-22T22:19:10Z,removed.,0,0.9782117605209351
212144205,5101,junrao,2018-08-22T23:42:44Z,"hmm, technically, only when the error code is badversion, it's an indication that the controller has moved. for other errors, we probably just want to propagate as they are to the caller.",0,0.9238917231559753
212144563,5101,junrao,2018-08-22T23:44:48Z,could this just be controllermovedlistener()?,0,0.9932720065116882
212147981,5101,junrao,2018-08-23T00:05:44Z,"we probably need to be a bit careful about bumping up the controller epoch at the beginning of oncontrollerfailover(). currently, the reading and the incrementing of the controller epoch is done independently after the controller path has been created successfully. this can create the following problem. broker a creates the controller path and is about to call oncontrollerfailover(). admin deletes the controller path and broker b creates the controller path, reads the controller epoch and updates it to 1. broker a reads the controller epoch and updates it to 2. now broker b is the controller, but its controller epoch is outdated. one way to address this issue is to use multi() when creating the controller path. to elect a new controller, a broker first reads the current controller epoch from zk and then do a multi() to (1) write the controller path (2) do a conditional update to the controller epoch. not sure if this is the best way though.",0,0.9724039435386658
212153922,5101,junrao,2018-08-23T00:48:34Z,we log e here but not in line 260. it would be useful to be consistent.,0,0.9911632537841797
212155652,5101,junrao,2018-08-23T01:01:49Z,could this be private?,0,0.9903441071510315
212155764,5101,junrao,2018-08-23T01:02:40Z,could this be private?,0,0.9903441071510315
212793210,5101,hzxa21,2018-08-25T08:48:27Z,done.,0,0.9640594124794006
212793216,5101,hzxa21,2018-08-25T08:48:36Z,yes. done.,0,0.819446325302124
212793218,5101,hzxa21,2018-08-25T08:48:43Z,yes. done.,0,0.819446325302124
212793233,5101,hzxa21,2018-08-25T08:49:02Z,that is a good point. fixed.,1,0.9642317295074463
212793237,5101,hzxa21,2018-08-25T08:49:13Z,yes. fixed.,0,0.9153916835784912
212793993,5101,hzxa21,2018-08-25T09:25:41Z,"thanks for pointing this out. this is indeed a very dangerous race condition. if it happens, the current controller (broker b) cannot update any zookeeper state due to controller epoch zkversion mismatch and no other broker can become the controller because the current controller (broker b) does not release the ""lock"" for `\controller` znode. wrapping `\controller` creation and `\controller_epoch` update in a zookeeper transaction can prevent this race condition and i think it is a safe option. i will make the change and see whether there will be performance overhead in the perf testing.",1,0.9065600633621216
212843697,5101,lindong28,2018-08-26T23:56:09Z,"hey , it seems that what you and jun suggested to do is to have a single multiops that 1) updates controller path, 2) read controller epoch and 3) updates controller epoch. another alternative approach is to have a single multiops that 1) updates controller path and 2) reads controller epoch with its zkversoin. then the controller can updates controller epoch with the addition zkversion check. do you think the alternative approach would avoid the race condition and ensure correctness? if so, i am wondering if the alternative would be easier to reason about. i find it a bit easier because the it follows the idea that all zookeeper write operation by controller will be based on the controller epoch zkversion check, except for the controller znode write operation which by design can not rely on the controller epoch zkversion check. and a multiop that does one write and one read seems simpler than a multiop that does write-read-write.",0,0.7464780211448669
212868803,5101,hzxa21,2018-08-27T05:26:48Z,"from a design and code readability perspective, i agree with what you have proposed (first atomic read `\controller_epoch` and create `\controller`, then update `\controller_epoch`). from the implementation perspective, zookeeper does not have a `read` op meaning that we cannot perform `read` operation with the `multi` (see [a link] basically, we use the time when a broker succeeds in incrementing the controller epoch as the ""commit"" point of the controller election and use the time when a broker succeeds in creating `\controller` znode as the ""prepare"" point. so for the correctness of the controller election ""commit"", we need to ensure `\controller_epoch` doesn't change from ""prepare"" to ""commit"". to achieve, we can implement the logic using zk `multi` following the steps: 1. read `\controller_epoch` to get the current controller epoch **e1** with zkversion **v1** 2. create `\controller` if `\controller_epoch` zkversion matches **v1** (use zk `multi`) 3. update `\controller_epoch` to be **e1+1** if its zkversion matches **v1** (zk conditional set)",0,0.9893905520439148
212913449,5101,hzxa21,2018-08-27T09:12:14Z,pr updated to address this issue.,0,0.9876707792282104
213035777,5101,lindong28,2018-08-27T16:31:37Z,"if `oncontrollerfailover()` throws `controllermovedexception` after controller has registered itself as controller, it seems possible that some events may have already been inserted into the controller event queue. should we propagate the `controllermovedexception` to `controllereventthread` in order to clear the controller event queue? also, i think in most places we will just name the exception varaible as `e` and throwable variable as `t`. naming them e1, e2, and specifically naming a throwalble as `e2`, seems unusual. i know this style is used in the existing controller code. i am wondering if we can change this.",0,0.9893046617507935
213040676,5101,lindong28,2018-08-27T16:49:32Z,i am wondering if the code will be more readable by removing this method and putting these three lines in `elect()` directly. the method is used only once and it is very short. and the two additional lines used to update the in-memory controllercontext seems more inline with the update of `activecontrollerid` in `elect` than with the name of `tryregistercontroller()`.,0,0.9903501868247986
213041250,5101,lindong28,2018-08-27T16:51:44Z,"if there is no existing controller, `getcontrollerepoch` returns `none`. should we still try to register controller in this case?",0,0.9926384687423706
213041939,5101,lindong28,2018-08-27T16:54:32Z,can we rename this method to `maybecreatecontrollerznode` so that it is more consistent with the existing names such as `kafkacontroller.maybetriggerpartitionreassignment()`?,0,0.9956770539283752
213043734,5101,lindong28,2018-08-27T17:01:26Z,currently the variable `timestamp` is passed all the way from `elect()` to `kafkazkclient.trycreatecontrollerznode()`. would it be simpler to replace this variable with `time.milliseconds` in `kafkazkclient.trycreatecontrollerznode()`?,0,0.9948937892913818
213087554,5101,lindong28,2018-08-27T19:29:41Z,"since it is not very intuitive from the method name to understand the meaning of the returned value `(int, int)`, can we add java doc for the returned value? since the new implementation of this method will try to create/update controller znode and increments controller epoch in a safe manner, would it be better to rename the method `registercontrollerandincrementcontrollerepoch`?",0,0.9936754107475281
213089263,5101,lindong28,2018-08-27T19:35:44Z,"info level logging is needed if user always want to see the message and it is usually used when something major is completed, e.g. server is started, rather than when something is attempted. it seems that ""try to create.."" and ""try to increment controller..."" may be more appropriate to be debug level logging if they are needed. the controller epoch and zkversion have been logged at info level in `elect()`.",0,0.9945008754730225
213097271,5101,lindong28,2018-08-27T20:03:39Z,"prior to this patch, if setcontrollerepochraw fails and the error is not `nonode`, controllermovedexception will be thrown which will be caught and `triggercontrollermove()` will be executed. after this patch, if setcontrollerepochraw returns a non-ok error code, we will always throw controllermovedexception(), which will be caught in the upper layer without executing `triggercontrollermove()`. i am wondering if we should throw illegalstateexception if the error code suggests something other than controller move, so that we can still execute `triggercontrollermove()` in this scenario.",0,0.9905313849449158
213100747,5101,junrao,2018-08-27T20:16:30Z,"for errors other than badversion, we should just propagate the original error as an exception.",0,0.9509973526000977
213112066,5101,junrao,2018-08-27T20:54:22Z,"not sure if we need to explicitly do the creation here. when the controller path is removed, every broker's controller listener will fire, which will trigger the controller election logic again.",0,0.9870196580886841
213118760,5101,hzxa21,2018-08-27T21:18:09Z,you are right. we should propagate the exception here. done.,0,0.8022876977920532
213118780,5101,hzxa21,2018-08-27T21:18:13Z,done.,0,0.9640594124794006
213122229,5101,hzxa21,2018-08-27T21:30:23Z,"no. previously we create `/controller_epoch` on-demand if it does not exist when we try to increment controller epoch. imo, this makes the code hard to read and reason about, especially after this patch because in that way we need to either create `/controller_epoch` if not exists and retry the atomic operation or we have two different atomic operations (one for check+create, the other one for create+create). i think `/controller_epoch` should pre-exists before we actually use it, like other persistent zk paths (e.g. /brokers, /admin/delete_topics) . so i have included `/controller_epoch` in the ""persistentzkpaths"" so that it will be created if not exists on broker startup. in this case, `getcontrollerepoch` should not return none unless admin deletes `/controller_epoch` explicitly, which will ruin the cluster anyway. one drawback of pre-creating `\controller_epoch` is that admin now cannot re-initialize controller epoch by simply deleting `\controller_epoch`. instead, admin should delete `/controller` and `/controller_epoch`, then re-create `\controller_epoch` to achieve this. but i don't know whether that is a valid use case. may i have your opinion?",0,0.9353325963020325
213122263,5101,hzxa21,2018-08-27T21:30:31Z,done.,0,0.9640594124794006
213122308,5101,hzxa21,2018-08-27T21:30:40Z,i agree. fixed.,1,0.5435817241668701
213122347,5101,hzxa21,2018-08-27T21:30:45Z,done.,0,0.9640594124794006
213122376,5101,hzxa21,2018-08-27T21:30:49Z,done.,0,0.9640594124794006
213124615,5101,junrao,2018-08-27T21:39:33Z,"this is called on controllermovedexception. in this case, we know that another broker has become the controller. we just need to clear the event queue, mark the controller as inactive and call oncontrollerresignation() . there is no need to do the controller election. if the new controller is gone afterward, every broker's controller path watcher will be triggered and a controller election will be tried. we probably should rename this method accordingly. also, we probably want to consolidate this method and triggercontrollermove() somehow. to me, the latter will just do what this method does and one more thing, removing the controller path.",0,0.9871691465377808
213126066,5101,hzxa21,2018-08-27T21:45:16Z,"per [a link] `/controller_epoch` should exists and `setcontrollerepochraw` should not return `nonode`. if that does happen, we will rely on admin to recover and `triggercontrollermove()` will not help. i agree that throwing `controllermovedexception` is not a good idea. maybe we should just throw `illegalstateexception` and indicate that is a fatal error. what do you think?",0,0.9838551878929138
213136758,5101,junrao,2018-08-27T22:37:02Z,perhaps we should just fold the logic in here to cleareventqueueandreelect() and always let eventmanager handle controllermovedexception.,0,0.994288444519043
213137736,5101,junrao,2018-08-27T22:42:18Z,could we just do the conditional controller epoch update and the creation of the controller path together in trycreatecontrollerznode()? this avoids an extra zk step.,0,0.9950220584869385
213140323,5101,junrao,2018-08-27T22:56:14Z,it process => it processes,0,0.9175534844398499
213140367,5101,junrao,2018-08-27T22:56:27Z,what's ple?,0,0.9755644798278809
213141257,5101,junrao,2018-08-27T23:00:57Z,"suspend()/resume() are deprecated. we can probably simulate this by adding a new controller event type. within the event, we can let it wait on a countdownlatch. once the controller is moved, we can unblock the countdownlatch.",0,0.9936514496803284
213142512,5101,junrao,2018-08-27T23:08:35Z,should we assert the return value?,0,0.9905173182487488
213142665,5101,junrao,2018-08-27T23:09:21Z,it seems that the last one is enough?,0,0.9907943606376648
213142925,5101,lindong28,2018-08-27T23:10:34Z,"prior to this patch, we only include znode in zkdata.persistentzkpaths() if there is no need for the data in the znode. this patch changes this behavior such that we create znode will null data and we assume epoch is -1 if the data is null. the previous approach says that either the znode does not exist, or the znode exists with valid data. the new approach says that either the znode exists with null, or the znode exists with valid data. i personally prefer the previous approach and i would prefer not to define a znode with null data and add additional code to handle that case. and in general it is probably better to keep the existing code if there is no difference in correctness/performance and the difference in code style is not very obvious w.r.t which one is better. it looks like the main concern with the previous approach is about code complexity. how about we have create and call method `maybecreatecontrollerepochznode` at the beginning of `registercontroller()`?",0,0.9827483296394348
213143236,5101,junrao,2018-08-27T23:12:20Z,this is an existing issue. could you add a space after the comma in the next line?,0,0.9875413775444031
213144214,5101,lindong28,2018-08-27T23:18:33Z,"now that `controllermovedexception` may be handled differently from other exceptions, the logic would be cleaner if we use this exception only when we know the another broker is the controller. thinking about it more, illegalstateexception means something impossible has happened inside the controller state. in this case the exception can happen if controller fails to write to controller epoch znode, which is possible from controller's point of view since zookeeper service is out of controller of the controller. how about `zookeeperclientexception(...)` and include error code in the message of the exception?",0,0.9832077026367188
213144670,5101,junrao,2018-08-27T23:21:30Z,"since createandregister has side effect, we should do createandregister().",0,0.9902011752128601
213145071,5101,junrao,2018-08-27T23:23:46Z,should we clear events?,0,0.9905428290367126
213151722,5101,hzxa21,2018-08-28T00:07:57Z,thanks for the suggestion. i have added `maybecreatecontrollerepochznode` and avoid crearting the znode on broker start up.,1,0.9306079745292664
213158074,5101,hzxa21,2018-08-28T01:00:08Z,thanks for the comment. i have updated the pr to throw `controllermovedexception` only when we see badversion in `setcontrollerepochraw`. i also applied the same idea to `maybecreatecontrollerznode`.,1,0.9110531806945801
213179550,5101,hzxa21,2018-08-28T04:11:44Z,"if we don't try to trigger `elect` after we clear the queue and the new controller goes away before we clear the queue, the watch may have put `reelect` in the queue before the clear happens. in this case, that broker will miss controller election. from the correctness point of view, this may not be a problem because at least one other broker will conduct the controller election and become the controller. it is safe to clear and resign if we don't care about fairness in controller election.",0,0.9868229627609253
213436446,5101,junrao,2018-08-28T19:05:53Z,"great point. we could just do reelect here as you suggested. i was thinking that we could also potentially inline the logic (clear the event queue, mark the controller as inactive and call oncontrollerresignation()) here instead of enqueuing the logic to the event queue. however, it seems that the former may be simpler.",1,0.8267164826393127
213610117,5101,omkreddy,2018-08-29T09:38:39Z,"nit: we can remove ""unit""",0,0.9845513701438904
213726027,5101,omkreddy,2018-08-29T15:29:31Z,do we need [code block] flag? looks like none of the tests depends on deletetopicenable=false. all tests are passing without this line.,0,0.9923281073570251
213727391,5101,omkreddy,2018-08-29T15:32:47Z,do we need these changes? tests are passing without these changes.,0,0.9815729856491089
213880720,5101,hzxa21,2018-08-30T01:26:49Z,done.,0,0.9640594124794006
213880874,5101,hzxa21,2018-08-30T01:28:21Z,you are right. changed to throw `controllermovedexception` instead.,0,0.9787846207618713
213880937,5101,hzxa21,2018-08-30T01:28:56Z,agree. code refactored.,0,0.9898719191551208
213880947,5101,hzxa21,2018-08-30T01:29:03Z,done.,0,0.9640594124794006
213881008,5101,hzxa21,2018-08-30T01:29:37Z,"yes, you are right. fixed.",1,0.6430003046989441
213881027,5101,hzxa21,2018-08-30T01:29:43Z,fixed.,0,0.979083240032196
213881117,5101,hzxa21,2018-08-30T01:30:27Z,i use that to stand for preferredleaderelection. fixed the comments to make it more clear.,0,0.9862414598464966
213881217,5101,hzxa21,2018-08-30T01:31:14Z,remove the deprecated methods and added the additional event for the test.,0,0.9889233112335205
213881231,5101,hzxa21,2018-08-30T01:31:20Z,yes. fixed.,0,0.9153916835784912
213881242,5101,hzxa21,2018-08-30T01:31:27Z,yes. fixed.,0,0.9153916835784912
213881251,5101,hzxa21,2018-08-30T01:31:33Z,done.,0,0.9640594124794006
213881264,5101,hzxa21,2018-08-30T01:31:38Z,done.,0,0.9640594124794006
213881314,5101,hzxa21,2018-08-30T01:31:59Z,done.,0,0.9640594124794006
213881326,5101,hzxa21,2018-08-30T01:32:04Z,done.,0,0.9640594124794006
213881555,5101,hzxa21,2018-08-30T01:34:03Z,yes. i added that for `testcontrollermoveontopicdeletion` but it turns out we don't actually need to enable topic deletion to test throwing and handling `controllermovedexception` happening in `topicdeletion` event. fixed.,0,0.9863007068634033
213881574,5101,hzxa21,2018-08-30T01:34:10Z,removed.,0,0.9782117605209351
214443770,5101,lindong28,2018-08-31T18:44:42Z,would logic be more intuitive to just treat the controllermovedexception as `controllerchange` event and do `mayberesign()`? the code would be simpler since this approach doesn't need `markinactiveandresign`.,0,0.994738757610321
214444603,5101,lindong28,2018-08-31T18:48:10Z,"nits: ""controller move listener"" -> ""controllermovedlistener"". also, it seems simpler to just remove `trigger controller move listener immediately` as we typically do not log which method is executed next other than logging the event itself. developer is expected look into the code and understand what happens next in the code after this event.",0,0.992059588432312
214444932,5101,lindong28,2018-08-31T18:49:39Z,can you remove `awaitonlatch` if it is not used?,0,0.9947429895401001
214447851,5101,lindong28,2018-08-31T19:00:50Z,"this line throws `nosuchelementexception` if controller epoch does not exist. it seems better to do `getcontrollerepoch.getorelse(throw new illegalstateexception(""...""))`.",0,0.99014812707901
214524631,5101,lindong28,2018-09-01T22:51:44Z,would it be more consistent with the other code in this method to do `case code.ok =>`?,0,0.9946788549423218
214524720,5101,lindong28,2018-09-01T22:59:50Z,"when sre deletes controller znode, multiple brokers may be doing `elect()` concurrently and all but one broker will find that the controller znode alread exists. prior to this patch, these brokers will log `debug(s""broker $activecontrollerid was elected as controller instead of broker ${config.brokerid}"")` if controller znode exists and the controller id is not this broker. after this patch, these brokers will log `error(s""error while creating ephemeral at ${controllerznode.path}, node already exists and owner ${getdataresponse.stat.getephemeralowner} does not match current session ${zookeeperclient.sessionid}"")` and `error(s""error while electing or becoming controller on broker ${config.brokerid} because controller moved to another broker"", e)` if controller znode exists and the controller id is not this broker. since we expect most brokers to find znode to be created by another broker during `elect()`, we probably want to keep the old behavior instead of having error level logs.",0,0.9891446232795715
214524844,5101,lindong28,2018-09-01T23:09:45Z,"it seems that we can enter this state only if broker executes `registercontrollerandincrementcontrollerepoch()` and finds that the controller znode has already been created by itself. the question is, is this possible? previously if broker tries to create controller znode and node already exists, the broker will simply read the controller id from the controller znode and move on. this patches added quite a few new logic in `controllernodeexistshandler()`, e.g. uses zk session id to detect whether the controller znode is created by this broker, handles the scenario that the controller znode is created by this broker. so the new code is more complicated than the previous version. can you explain a bit why we need these new logic?",0,0.9914159178733826
214525056,5101,lindong28,2018-09-01T23:28:05Z,is it possible for error code to be `code.ok` while `zkversioncheckresult.opresult` is of type `errorresult`?,0,0.9954919219017029
214525058,5101,lindong28,2018-09-01T23:28:33Z,is it possible for `controllerepochznode.path` to be different from `zkversioncheck.checkpath`?,0,0.9954460859298706
214534027,5101,hzxa21,2018-09-02T09:15:22Z,"yes. for example, if we wrap `check` + `create` in zookeeper `multi`, and `multi` fails due to `create` fails, the result of `check` will be of type `errorresult` with `code.ok` as error code.",0,0.9948497414588928
214534041,5101,hzxa21,2018-09-02T09:15:47Z,`awaitonlatch` is used in `controllerintegrationtest`,0,0.9939013719558716
214534378,5101,hzxa21,2018-09-02T09:28:42Z,"in short, the purpose of `controllernodeexistshandler` is to mimic `checkedephemeralcreate `, which previously is used to create `/controller` ephemeral node. in `checkedephemeral`, we need to double check the owner of the node if we saw `code.nodeexists`. i think the purpose of the check and the additional logic is to handle transient network connection loss while creating the ephemeral. let's say our client sent a `create` request to zookeeper to create ephemeral znode and zookeeper receives this request and successfully creates the znode but fail to send back the response to our client because of transient network issue. in `retryuntilconnected`, our client tries to resend the request and gets the `code.nodeexists`. in this case, our client actually successfully creates and owns the znode.",0,0.991231381893158
214534566,5101,hzxa21,2018-09-02T09:36:15Z,currently no. the check here is for general purpose and safety because the zkversioncheck can apply on any znode if needed.,0,0.9930247068405151
214535433,5101,hzxa21,2018-09-02T10:15:22Z,agree. fixed.,0,0.9794597029685974
214535436,5101,hzxa21,2018-09-02T10:15:28Z,done.,0,0.9640594124794006
214535441,5101,hzxa21,2018-09-02T10:15:39Z,done.,0,0.9640594124794006
214535445,5101,hzxa21,2018-09-02T10:15:54Z,yes. done.,0,0.819446325302124
214535450,5101,hzxa21,2018-09-02T10:16:05Z,agree. fixed.,0,0.9794597029685974
214542290,5101,lindong28,2018-09-02T14:12:48Z,"the creation of the ephemeral znode `/controller` is probably a bit different from the creation of other ephemeral znode. the broker which creates the ephemeral znode `/controller` is explicitly specified in the znode data. thus the old approach, which reads the broker id from the controller znode after seeing `code.nodeexists`, seems ok. and that old approach seems to handle the network connection loss scenario described here. i am wondering if we can use the old approach since its logic looks simpler. what do you think?",0,0.9831096529960632
214542333,5101,lindong28,2018-09-02T14:14:01Z,cool. i see.,1,0.9800633192062378
214542476,5101,lindong28,2018-09-02T14:17:24Z,got it. could you add a comment above the case class `` that says `used only by test`? this is similar to e.g. `replicamanager.markpartitionoffline(...)`.,0,0.9947035908699036
214542542,5101,lindong28,2018-09-02T14:19:30Z,got it.,0,0.9649474024772644
214542750,5101,lindong28,2018-09-02T14:25:53Z,"btw, for the case `getdataresponse.stat.getephemeralowner != zookeeperclient.sessionid`, we know this case may happen and the code will automatically recover from this. in this case it is probably better to log at warning level instead of error level. here is a good explanation for how to choose log level. [a link]",0,0.9865161180496216
214760829,5101,hzxa21,2018-09-03T22:52:10Z,"i am a little bit confused about what do you mean by the old approach. are you referring to `checkedephemeralcreate`? the logic in `controllernodeexistshandler ` is essentially the same as `checkedephmeralcreate` when the node already exists, except that `controllernodeexistshandler` will read `/controller_epoch` to get back the epoch zkversion when the owner of `/controller` is the current broker.",-1,0.5188470482826233
214780256,5101,lindong28,2018-09-04T03:43:44Z,"my bad. i missed the fact that the controller znode was created using `kafkazkclient.checkedephemeralcreate()` which has the logic similar to what you are doing here. it seems that the most important logic in the `kafkazkclient.checkedephemeralcreate` is to translate `code.nodeexists` to `code.ok` for the znode creation operation if `getdataresponse.stat.getephemeralowner == zookeeperclient.sessionid`. this logic was added in [a link] by onur. my understanding is that, in case of connection issue between broker and zookeeper, it is possible for controller znode to be successfully created and yet the return code is `code.nodeexists`. `kafkazkclient.checkedephemeralcreate` will handle this scenario properly. it will be good for to clarify whether this understanding is correct so that we can decide whether we should keep this logic. here is another question. with the current patch, if the controller znode creation has failed due to znode exists exception and then broker find that `getdataresponse.stat.getephemeralowner == zookeeperclient.sessionid`, it seems `registercontrollerandincrementcontrollerepoch()` can return `(newcontrollerepoch, stat.getversion)` if `epoch == newcontrollerepoch`. but is controller epoch incremented in this case? if not, then it seems something is wrong?",-1,0.9735409617424011
214995831,5101,hzxa21,2018-09-04T17:11:11Z,"i re-think about your previous suggestion for checking the payload of `/controller` only and i think it will work. i will check with onur offline to understand more about `checkedephemeralcreate` and confirm. in terms of your second concern, if we already see `getdataresponse.stat.getephemeralowner == zookeeperclient.sessionid`, that means `/controller` has been created successfully. since the only code path to create `/controller` is within a zookeeper transaction along with the `/controller_epoch` update, we can infer that the controller epoch must get incremented in this case.",0,0.9350798726081848
215069911,5101,hzxa21,2018-09-04T21:17:26Z,"discussed with onur offline, the purpose of `getafternodeexists` in `checkedephemeral` is indeed used to handle the case when zk connection loss happens. after digging around both zookeeper and kafka codes, we think it is safe to remove the extra complexity for `controllernodeexistshandler` in this pr when we make `/controller` creation and `/controller_epoch` update atomic. so the logic will be: 1). try to create `/controller_epoch` if not exists 2). read `/controller_epoch` from zk 3). atomically create `/controller` and update `/controller_epoch` 4). if 3) throws nodeexistsexception, read `/controller` and if controller id in zk equals the current broker id and if controller epoch in zk equals the expected epoch, successfully finish controller election; otherwise, throw controllermovedexception.",0,0.9931847453117371
215105046,5101,junrao,2018-09-05T00:26:22Z,"since we are doing a conditional setdata in line 117, we don't need the check operation here.",0,0.9908158779144287
215107229,5101,junrao,2018-09-05T00:41:49Z,"if the client loses a connection to a zk server in the middle of an operation, the client will get a connectionlossexception. normally, we handle this by retrying through retryrequestsuntilconnected(). so, we probably need to create a similar routine to retry on connectionlossexception when doing transaction.commit() too. the controller path could have been created successfully when connectionlossexception was incurred. a retry could result in either nodeexistsexception or badversionexception. you handled the former properly in the code below. we will need to do the same thing for the latter.",0,0.9920316934585571
215109171,5101,junrao,2018-09-05T00:56:27Z,"for any other types of exceptions, we want to just propagate the keeperexception to the caller.",0,0.9842680096626282
215109447,5101,junrao,2018-09-05T00:58:36Z,"in the common case, the controller epoch path already exists. so, perhaps it would be better to always do getcontrollerepoch first and then try maybecreatecontrollerepochznode if we hit a nonodeexception.",0,0.9916456341743469
215109576,5101,junrao,2018-09-05T00:59:41Z,the info level will be too verbose if we call maybecreatecontrollerepochznode() on every controller election.,0,0.8909603357315063
215112397,5101,junrao,2018-09-05T01:22:17Z,"""before the pre-defined logic is triggered and before it processes controller change."" it seems that we just need one of the two before?",0,0.9910076260566711
215135718,5101,junrao,2018-09-05T04:55:18Z,"hmm, i am not sure this is safe. the controller path could have been deleted and grabbed by another broker in the window between line 123 and here. then, we would have grabbed the wrong controller epoch.",-1,0.594243586063385
215176421,5101,hzxa21,2018-09-05T08:22:50Z,"you are right. but in line 133 we will check the epoch value. if it is different from what we expected, we will throw `controllermovedexception`. in the case of `/controller` gets deleted between line 123 and 127, and another broker becomes the controller, the controller epoch will increment accordingly, causing line 133 to fail.",0,0.9902356266975403
215359852,5101,junrao,2018-09-05T17:28:33Z,ah. ok. that's fine then.,0,0.7300576567649841
215360130,5101,junrao,2018-09-05T17:29:25Z,"should we explicitly call return here? otherwise, it seems that we are always throwing controllermovedexception.",0,0.9835522770881653
215418284,5101,hzxa21,2018-09-05T20:40:41Z,that's right. fixed.,0,0.8242564797401428
215418324,5101,hzxa21,2018-09-05T20:40:47Z,done.,0,0.9640594124794006
215418651,5101,hzxa21,2018-09-05T20:41:51Z,here we don't catch other types of exceptions so the keeperexception is already propogated to the caller.,0,0.9905667901039124
215420284,5101,hzxa21,2018-09-05T20:47:19Z,done.,0,0.9640594124794006
215420905,5101,hzxa21,2018-09-05T20:49:25Z,"this log will only get print when `/controller_epoch` is absent, which is typically when the cluster gets initialized, not on every controller election.",0,0.9939447045326233
215420928,5101,hzxa21,2018-09-05T20:49:31Z,fixed.,0,0.979083240032196
215420986,5101,hzxa21,2018-09-05T20:49:43Z,ah... my bad. fixed.,-1,0.9922693967819214
215444417,5101,junrao,2018-09-05T22:25:17Z,"on connectionlossexception, it's not efficient to blindly retry immediately. instead, it's better to wait until the zk connection is ready before retry. you can check how this is done in retryrequestsuntilconnected().",0,0.9862340688705444
215444912,5101,junrao,2018-09-05T22:27:36Z,"it is possible that the controller_epoch path is created by another broker between getcontrollerepoch() and createcontrollerepochznode(). in this case, we want to get the controller epoch again, instead of throwing controllermovedexception.",0,0.989584743976593
215447046,5101,junrao,2018-09-05T22:37:52Z,it seems that every usage of kafkacontroller.initialcontrollerepoch and kafkacontroller.initialcontrollerepochzkversion as 0 requires subtraction by 1. could we just define them as 0?,0,0.9891446232795715
215448079,5101,junrao,2018-09-05T22:43:14Z,"according to zk doc, multi propagates the error from one of the operations. the badversionexception could be the result of a retry after connectionlossexception. so, it seems that we need to handle it in the same way as nodeexistsexception.",0,0.9833246469497681
215462227,5101,hzxa21,2018-09-06T00:10:45Z,got it. thanks for pointing this out.,1,0.9081185460090637
215462635,5101,hzxa21,2018-09-06T00:13:29Z,"if the controller_epoch path is created by another broker between getcontrollerepoch() and createcontrollerepochznode(), i was thinking whether we can infer that other broker wins in this round of controller election even if it hasn't created the controller znode. after a second thought, i think we should follow what you suggested for extra safety because if the broker fails to talk to zk for some reason, the cluster will get into a no-controller state.",0,0.9835596084594727
215466660,5101,hzxa21,2018-09-06T00:45:31Z,"correct me if i am wrong, i think there are two cases when we see badversionexception here: 1. another round of controller election kicks in and the controller does switch. it is safe to throw `controllermovedexception` in this case. 2. the current broker loss zk connection after zk successfully finishes the transaction, **but the controller znode is gone before the next retry**. in this case, another round of controller election will be triggered by zk watcher `handledeleted`. so i think it is also safe to throw `controllermovedexception` here.",0,0.9817542433738708
215467856,5101,hzxa21,2018-09-06T00:55:55Z,yes. done.,0,0.819446325302124
215467866,5101,hzxa21,2018-09-06T00:56:00Z,fixed.,0,0.979083240032196
215467880,5101,hzxa21,2018-09-06T00:56:06Z,done.,0,0.9640594124794006
215561349,5101,omkreddy,2018-09-06T09:42:13Z,nit: missing expectedcontrollerepochzkversion params in method comments,0,0.9943423271179199
215570923,5101,omkreddy,2018-09-06T10:12:30Z,can we use initialcontrollerepochzkversion constant in place of zero?,0,0.9952635765075684
215576221,5101,omkreddy,2018-09-06T10:31:49Z,looks like this line is not required.,0,0.9722985625267029
215711690,5101,hzxa21,2018-09-06T17:28:21Z,added.,0,0.9822506308555603
215711716,5101,hzxa21,2018-09-06T17:28:29Z,sure. done.,0,0.9251468181610107
215711801,5101,hzxa21,2018-09-06T17:28:43Z,thanks for pointing out. removed.,1,0.9253675937652588
215738649,5101,junrao,2018-09-06T18:52:06Z,perhaps it's better to name this maybecreatecontrollerepochznode?,0,0.992815375328064
215740626,5101,junrao,2018-09-06T18:58:19Z,"i was thinking about case 2, but with the controller path still there. the zk multi api doesn't say that it will run the operations in a multi request in any particular order. so, during the retry on a connectionlossexception, it may be possible that the conditional update of the controller epoch path is executed first and a badversionexception is thrown?",0,0.9667211771011353
215769317,5101,hzxa21,2018-09-06T20:38:10Z,"thanks for the prompt reply! i actually checked both client and server side codes of zookeeper, the implementation honors the order and the thrown exception will correspond to the first error it sees. but since the muli api doesn't explicitly say that it is the case or it will maintain this guarantee in the future, i agree to also handle badversion the same way as nodeexists for safety given that the performance overhead is little.",1,0.9674615859985352
215773516,5101,hzxa21,2018-09-06T20:49:54Z,done.,0,0.9640594124794006
215773534,5101,hzxa21,2018-09-06T20:49:58Z,done.,0,0.9640594124794006
215775823,5101,junrao,2018-09-06T20:57:12Z,could this be private?,0,0.9903441071510315
215779888,5101,hzxa21,2018-09-06T21:11:24Z,done.,0,0.9640594124794006
215847375,5101,lindong28,2018-09-07T05:09:12Z,"i have two questions here: 1) when would we enter a scenario that `controllerid == curcontrollerid` and `epoch != newcontrollerepoch)`? 2) currently when this happens, `checkcontrollerandepoch` will throw `controllermovedexception()`, which is caught in `kafkacontroller.elect()` and trigger `mayberesign()`. however `mayberesign()` will do nothing because `controllerid == curcontrollerid` and this broker is considered to be the active controller. in this case no other broker will be controller. and the current broker will not function properly as controller because it has not executed `oncontrollerfailover()`. so maybe we should throw `illegalstateexception` here if `controllerid == curcontrollerid` and `epoch != newcontrollerepoch)`?",0,0.9931413531303406
215847674,5101,lindong28,2018-09-07T05:12:27Z,"in `maybecreatecontrollerepochznode()`, we throw `illegalstateexception(...)` if we first find controller epoch znode exists and then find it disappeared. following the same logic, it is probably consistent and reasonable to throw `illegalstateexception(...)` if `checkcontrollerandepoch(...)` can not read controller epoch, right?",0,0.9937618374824524
215849517,5101,lindong28,2018-09-07T05:28:04Z,"if `registercontrollerandincrementcontrollerepoch()` has successfully written the broker id to controller znode but then an illegalstateexception is thrown (e.g. in the case `controllerid == curcontrollerid` and `epoch != newcontrollerepoch` described in the other comment), an illegalstateexception will be thrown which is caught in `elect()` and `triggercontrollermove()` will be executed. however, since the `activecontrollerid` has not been updated, `isactive()` is evaluated to false and `triggercontrollermove()` will do nothing. maybe we should first do `activecontrollerid = zkclient.getcontrollerid.getorelse(-1)` in `triggercontrollermove()`. also, to be consistent with most other usage of `isactive()`, can we do something like the code below instead of using if/else? [code block]",0,0.9951582551002502
215849923,5101,lindong28,2018-09-07T05:31:43Z,nits: can we use `controllercontext.epochzkversion` instead of using `expectedcontrollerepochzkversion` to be consistent with other usage of `controllercontext.epochzkversion` in this patch?,0,0.9959824085235596
215851146,5101,lindong28,2018-09-07T05:41:07Z,nits: `successfully create` => `successfully created`,0,0.9529118537902832
216039463,5101,hzxa21,2018-09-07T17:54:48Z,"1. because we first get /controller and then get /controller_epoch (rather than do it atomically), it is possible that after we see `controllerid == curcontrollerid` and before we get /controller_epoch, another round of controller election is triggered. in this case, we will see `epoch != newcontrollerepoch`. 2. when we see `epoch != newcontrollerepoch`, `controllerid == curcontrollerid` does not hold because another broker must become the controller. in this case, `mayberesign` will work fine.",0,0.9931818842887878
216039681,5101,hzxa21,2018-09-07T17:55:27Z,make sense to me. will fix it.,0,0.9633685946464539
216044300,5101,hzxa21,2018-09-07T18:11:45Z,"in `oncontrollerresignation`, `controllercontext` will be reset. so here we need to keep the value before `oncontrollerresignation` and reuse it in deletion.",0,0.9937586784362793
216048155,5101,hzxa21,2018-09-07T18:25:39Z,yes. fixed.,0,0.9153916835784912
216048195,5101,hzxa21,2018-09-07T18:25:45Z,done.,0,0.9640594124794006
216048226,5101,hzxa21,2018-09-07T18:25:51Z,fixed.,0,0.979083240032196
216049295,5101,lindong28,2018-09-07T18:30:20Z,thanks for the explanation. this makes sense.,1,0.5454516410827637
216049364,5101,lindong28,2018-09-07T18:30:36Z,this makes sense.,0,0.9686249494552612
216108832,5101,junrao,2018-09-07T23:23:46Z,": actually, i am wondering if it's simpler to replace lines 116-124 with a check that the ephemeral owner of the controller path equals to the zk session id (like we did before in checkedephemeralcreate()). the controller path or the controller epoch path could change after that check. but that's fine and will be handled by the next zk event on the controller path change.",0,0.9905019998550415
216150289,5101,hzxa21,2018-09-09T07:49:41Z,it is safe to replace the /controller payload check with session id check but we still need to read /controller_epoch to get back the corresponding zk version if we loss connection when doing the zk transaction.,0,0.9938524961471558
216521044,5101,junrao,2018-09-11T01:18:07Z,"hmm, to me, if the ephemeral owner of the controller path equals to the zk session id, it means that at that particular time, the controller path and the controller epoch path are created by the current zk session, and therefore the controller epoch used for creation should be valid. this seems to be equivalent as checking the value of the controller path and the controller epoch value. in both cases, after the check, the controller could change again. however, that will be handled by the zk watcher event.",0,0.9841673970222473
216524610,5101,lindong28,2018-09-11T01:45:34Z,"my understanding is that the approach using ephemeral owner has the same performance and correctness guarantee as the current approach which uses epoch from the znode data. the approach using ephemeral owner is probably more intuitive/readable because it exactly handles the root cause of `nodeexistsexception | _: badversionexception`, i.e. `checkcontrollerandepoch()` should effectively translate nodeexistsexception/badversionexception to `code.ok` if and only if `ephemeral owner of the controller path equals to the zk session id`. and it is also more consistent with the existing logic in `checkedephemeralcreate()`. if it sounds reasonable, maybe we can have a minor followup patch (without requiring a jira ticket) to improve it.",0,0.9805853962898254
216723540,5101,junrao,2018-09-11T15:57:24Z,"i was thinking that the ephemeral owner approach will be cheaper since we only need to read the controller path, not both controller path and the controller epoch path.",0,0.9749618768692017
216757532,5101,hzxa21,2018-09-11T17:41:08Z,"from the correctness and performance point of view, checking `/controller` payload and checking `/controller` ephemeral owner is the same. the question is whether we need to read `/controller_epoch`. the reason why i do it is because if `nodeexistsexception| badversionexception` happens, we no longer have the `stat` (new zkversion) of `/controller_epoch` even though the `/controller_epoch` update succeeds in zookeeper server. we can avoid the extra read on `/controller_epoch` if we can assume that zkversion is always incremented by one. since `/controller_epoch` zkversion is critical for us after this patch and zookeeper doc does not explicitly say that this assumption holds, i think it is safer to do one extra read during controller election.",0,0.994486391544342
217395000,5101,junrao,2018-09-13T14:01:19Z,: that's a great point. thanks. then we can just keep the code as it is.,1,0.9935257434844971
263337259,6295,enothereska,2019-03-07T11:13:10Z,not clear from the kip why you need to keep track of both downstream and upstream offset.,0,0.899264395236969
263338227,6295,enothereska,2019-03-07T11:16:00Z,looks like it's missing the methods like shouldcheckpointtopic. i'm assuming that is because this is still wip.,0,0.9715881943702698
263340233,6295,enothereska,2019-03-07T11:22:15Z,the methods here are slightly different from what was described in the kip but you're using the helper class to create adminclient so i'm on with it (as long as we update the kip at some point).,0,0.9883389472961426
263461244,6295,ryannedolan,2019-03-07T16:27:17Z,"the discussion so far has been about emitting upstream offsets and then translating them within remoteclusterutils. however, i've found it's just as easy for the checkpoints to be translated already, which drastically simplifies remoteclusterutils. i'm not certain both upstream and downstream offsets are really necessary here, but it's nice as a sanity check when tailing the checkpoint stream, at least.",0,0.9099984765052795
263462174,6295,ryannedolan,2019-03-07T16:29:15Z,i'll update the kip and call out the changes to the discuss thread prior to marking this ready-for-review.,0,0.9890350699424744
263469394,6295,ryannedolan,2019-03-07T16:44:58Z,"i plan to remove those methods from the kip, for a few reasons: 1) the same logic is encoded in the config, for the most part. e.g. shouldcheckpointtopic is just combining the topic and group whitelists. if we already have those properties, it's best not to provide a second mechanism to redefine the behavior here. i think regexes are sufficiently powerful. 2) i want to enable using the same replication policy for both the connectors and the clients. the clients don't care about most of the methods in the kip, so it's best not to make a client define them. 3) i want replication policies to be pretty much static across an entire organization, not per-cluster. the organization decides what remote topics look like, and then all connectors and clients know how to interpret them. so anything related to specific topics or groups doesn't fit that goal. it's possible that replicationpolicy is no longer a good name for this, but i think it works.",0,0.9721840620040894
266605739,6295,williamhammond,2019-03-18T19:29:17Z,should non-replicated topics be filtered before being passed in potentially should this be an exception? in `mirrorclient#upstreamclusters` do we need to filter nulls similar to how `mirrorclient#replicationhops` needs to filter -1?,0,0.9948384165763855
266610210,6295,ryannedolan,2019-03-18T19:41:47Z,"thanks for the suggestion. i think it's reasonable to throw an exception here and in replicationhops(), but i'll need to add an additional method like hassource() or something. seems like a good trade to reduce magic numbers and nulls.",1,0.8985208868980408
269820527,6295,williamhammond,2019-03-28T00:27:21Z,shouldn't this be false?,0,0.9783737659454346
269831729,6295,ryannedolan,2019-03-28T01:45:38Z,thanks :),1,0.9741679430007935
271842542,6295,ryannedolan,2019-04-03T17:05:46Z,"update: i've broken the missing methods out into topicfilter, groupfilter, configpropertyfilter, instead of having them all in replicationpolicy. lmk what you think.",0,0.9811177849769592
272189918,6295,viktorsomogyi,2019-04-04T13:53:44Z,nit: i think it'd be better to keep this and the zkclient on info level as they might be useful in a troubleshooting scenario.,0,0.986404538154602
272195234,6295,viktorsomogyi,2019-04-04T14:05:26Z,"have you considered using the protocol generator framework that is available for clients or would it make this more complicated than necessary? as i see you're simply using these messages as payload and they're not really protocol messages but we might gain something as they generate hashcode and equals methods. also, why are these (checkpoint, heartbeat) not protocol messages?",0,0.9818083643913269
272263389,6295,ryannedolan,2019-04-04T16:28:32Z,"will do, thanks",1,0.9009454250335693
272269172,6295,ryannedolan,2019-04-04T16:44:13Z,"as you say, these aren't really protocol messages, as they are not requests or responses, so i don't think the generator stuff would be a good fit here. maybe there are parts of it i could use. i suppose we could use json here as well. these are simple, unstructured records, so there isn't much to be gained from encoding in json, but it would be nice to get rid of some of this code.",0,0.9357017278671265
272558159,6295,kujon,2019-04-05T12:09:56Z,i'm wondering: what is the advantage of using `-1` over say `null` to represent no value?,0,0.952406108379364
273276967,6295,ryannedolan,2019-04-08T23:31:34Z,that would work too. whatever is more conventional in kafka is fine with me.,0,0.9787948131561279
274046687,6295,ryannedolan,2019-04-10T16:18:38Z,let's change to latency.,0,0.9892106056213379
274671893,6295,halorgium,2019-04-11T21:25:14Z,this needs the `security_protocol` added. [code block],0,0.9917736649513245
281541554,6295,viktorsomogyi,2019-05-07T09:14:22Z,as i understand this is a standard property of the connector config but i think it could be omitted in this case as we're always using mirrorsourceconnector. perhaps we can dynamically add this config in mirrormaker on creation time. or is it there because of the mirrorsinkconnector you'll create according to the kip?,0,0.9941991567611694
281572293,6295,viktorsomogyi,2019-05-07T10:47:32Z,"i think it would be safer to use the `await(long, timeunit)` method with a reasonable value (maybe taking it from a config) with both this one and with `startlatch` so we won't wait if the other thread died and never gonna count down.",0,0.9881405830383301
281855279,6295,ryannedolan,2019-05-07T22:35:30Z,thanks for catching! fixed.,1,0.9924986958503723
282122493,6295,ryannedolan,2019-05-08T15:33:19Z,"yes, mirrormaker fills this in for you normally. this config file is provided just for running mirrorsourceconnector in ""standalone mode"" as follows: ./bin/connect-standalone.sh config/connect-standalone.properties config/connect-mirror-source.properties i.e. without the top-level mm2 driver doing the work for you. organizations that already have a connect-as-a-service cluster will find this useful as well, as they may wish to leverage their existing cluster and just configure it to run the mm2 connectors.",0,0.9912298917770386
282141748,6295,ryannedolan,2019-05-08T16:16:57Z,"this latch is being used as a signal that stop() has been called, so we can't timeout here. but i've added a timeout to the shutdown hook and added a `finally` to ensure that stop() is called.",0,0.9927871823310852
282144470,6295,ryannedolan,2019-05-08T16:23:54Z,"i was able to drop this file entirely, and just use the existing connect-log4j.properties file. it's a little verbose that way, but no more so than connect-distributed.sh.",0,0.9701446294784546
284428968,6295,viktorsomogyi,2019-05-15T20:06:42Z,nit: exception is not thrown by anyone,0,0.9634343981742859
284431092,6295,viktorsomogyi,2019-05-15T20:12:24Z,"there is no clusters config, i think you should add `clusters=upstream`. i get an npe without it: [code block]",0,0.9809457659721375
284432272,6295,viktorsomogyi,2019-05-15T20:15:29Z,the adminclient requires a bootstrap.server property. would it make sense to pass either the source or the target's bootstrap.server property? [code block],0,0.9948970675468445
284433973,6295,viktorsomogyi,2019-05-15T20:20:06Z,also on a second note i think it'd be nice to give the users some meaningful error here.,0,0.9327089190483093
284434170,6295,viktorsomogyi,2019-05-15T20:20:36Z,what should be the real version?,0,0.9904926419258118
284443402,6295,viktorsomogyi,2019-05-15T20:45:39Z,"i would consider using `optional ` here and probably in other places in this interface too. these are interface methods, used in a bunch of places and i think it's better to enforce null checks in a safe way.",0,0.9876335859298706
284444200,6295,viktorsomogyi,2019-05-15T20:47:42Z,`.evolving` (and generally to all interfaces),0,0.9921213388442993
284446688,6295,viktorsomogyi,2019-05-15T20:54:18Z,distinct is not needed because of it'll be collected into a set.,0,0.9939018487930298
284446809,6295,viktorsomogyi,2019-05-15T20:54:38Z,not needed either.,0,0.8972542881965637
284447065,6295,viktorsomogyi,2019-05-15T20:55:22Z,this method doesn't seem to be used. what's the purpose?,0,0.848585307598114
284447829,6295,viktorsomogyi,2019-05-15T20:57:31Z,nit: these are not thrown anywhere,0,0.9233417510986328
284448042,6295,viktorsomogyi,2019-05-15T20:58:06Z,"nit: could be made private, or is there a reason for this to be protected?",0,0.9911500215530396
284448576,6295,viktorsomogyi,2019-05-15T20:59:36Z,this method doesn't seem to be used.,0,0.9510666131973267
284450836,6295,viktorsomogyi,2019-05-15T21:05:45Z,nit: this doesn't seem to be used nor contains the required information.,0,0.9618443250656128
284453686,6295,viktorsomogyi,2019-05-15T21:13:32Z,"usually the kafka convention of internal topic notation is double underscore, such as `__topic-name`. i wonder if we'd should to apply this here too. also it seems to me that there internal topics are `mm2-offsets...`, `mm2-status...`, `mm2-offset-syncs` and `mm2-configs...` for the source and target clusters so we might be able just dynamically populate the topic blacklist for these and that way we'd probably leave the `.internal` notation. just putting this out for conversation.",0,0.9896518588066101
284455448,6295,viktorsomogyi,2019-05-15T21:18:55Z,"why do we need to throw `executionexception, timeoutexception` in these methods?",0,0.9916495084762573
284458764,6295,viktorsomogyi,2019-05-15T21:28:42Z,would it make sense to be the implementation of `org.apache.kafka.common.utils.scheduler`?,0,0.9952046871185303
284459118,6295,viktorsomogyi,2019-05-15T21:29:39Z,nit: `interruptedexception` is not thrown.,0,0.9869106411933899
284459418,6295,viktorsomogyi,2019-05-15T21:30:27Z,this doesn't seem to be used.,0,0.9257559776306152
284460793,6295,viktorsomogyi,2019-05-15T21:34:18Z,nit: this isn't actually used.,-1,0.5669716596603394
284461711,6295,viktorsomogyi,2019-05-15T21:37:08Z,what should be the real version?,0,0.9904926419258118
284462552,6295,viktorsomogyi,2019-05-15T21:39:45Z,nit: these can be private,0,0.9467979669570923
284462956,6295,viktorsomogyi,2019-05-15T21:41:01Z,how much effort would be to expose this property? as far as i can tell all we need is to provide a config and then we'd be good to go.,0,0.8976808190345764
284463213,6295,viktorsomogyi,2019-05-15T21:41:53Z,nit: what is the real version? :),1,0.9935858845710754
284464247,6295,viktorsomogyi,2019-05-15T21:45:17Z,as i see this is assigned only in `start()` but i think just for the sake of clean code we should use a `final object` to lock.,0,0.9885158538818359
284464701,6295,viktorsomogyi,2019-05-15T21:46:34Z,nit: this is not used,0,0.7606443762779236
284464776,6295,viktorsomogyi,2019-05-15T21:46:47Z,nit: this is not used,0,0.7606443762779236
284523993,6295,kamalcph,2019-05-16T03:04:56Z,nit: unused variable.,0,0.8920056223869324
284524085,6295,kamalcph,2019-05-16T03:05:38Z,topic_filter_class_doc -> group_filter_class_doc,0,0.9907348155975342
284524187,6295,kamalcph,2019-05-16T03:06:13Z,unused variable.,0,0.9747744798660278
284524413,6295,kamalcph,2019-05-16T03:07:52Z,whether to include `__transaction_state` internal topic here?,0,0.9947879314422607
284524591,6295,kamalcph,2019-05-16T03:09:16Z,could you change the method name in symmetry to the topic name? (offsetsyncstopic()),0,0.9949291944503784
284524745,6295,kamalcph,2019-05-16T03:10:37Z,give a name to this scheduler to track it in threaddump.,0,0.9931759238243103
284524882,6295,kamalcph,2019-05-16T03:11:36Z,give a name to this thread.,0,0.9898293614387512
284525104,6295,kamalcph,2019-05-16T03:13:08Z,"once a lock is taken, no other operation should be done outside the try-catch block. call the `consumer.close()` either inside the try-catch or before taking the lock.",0,0.9938713312149048
284525159,6295,kamalcph,2019-05-16T03:13:30Z,unlock the taken lock.,0,0.9849972724914551
284525244,6295,kamalcph,2019-05-16T03:14:10Z,ie is not thrown. could you please remove the `throws ie`?,0,0.9769582152366638
284526932,6295,kamalcph,2019-05-16T03:26:01Z,consider taking the `lock` before the try-catch block as it's best practice.,0,0.9915209412574768
284611735,6295,kamalcph,2019-05-16T09:13:17Z,"you may have to update the description of the max, min and avg for record_age, replication_latency and checkpoint_latency metric name templates. (eg) the **maximum** age of incoming ...",0,0.9931679964065552
284612564,6295,kamalcph,2019-05-16T09:15:13Z,"`pause()` and `resume()` methods are unused. and, you can merge both these methods by taking action as a parameter.",0,0.9932349324226379
284613640,6295,kamalcph,2019-05-16T09:17:47Z,nit: pending todo.,0,0.9287520051002502
284614159,6295,kamalcph,2019-05-16T09:18:56Z,unused variable.,0,0.9747744798660278
284614303,6295,kamalcph,2019-05-16T09:19:17Z,unused variable.,0,0.9747744798660278
284614370,6295,kamalcph,2019-05-16T09:19:26Z,unused variable.,0,0.9747744798660278
284615520,6295,kamalcph,2019-05-16T09:22:05Z,it's better to unlock the taken lock.,0,0.989946186542511
284648386,6295,arunmathew88,2019-05-16T10:48:23Z,"from my experience with large kafka clusters, one node being down for maintenance or so is very common, so for topics with more than one replica in source topic, we should have at least 2 replicas in destination, for the data to be realistically available in failover scenarios. just my thought.",0,0.8877621293067932
284898791,6295,ryannedolan,2019-05-16T21:07:51Z,"this config is for the mirrorsourceconnector alone, not a top-level mm2.properties file. the properties required in either case are distinct. i can see this is a source of confusion, so i'll add a comment here. i think maybe we need an example mm2.properties file as well.",0,0.988636314868927
284899900,6295,ryannedolan,2019-05-16T21:11:03Z,"you're using the wrong config file (see above). you need something like: clusters = upstream, downstream upstream.bootstrap.servers = ... downstream.bootstrap.servers = ... then, the mirrormaker driver sets up a bunch of connectors with the required properties, which will look like the connect-mirror-source.properties here.",0,0.994082510471344
284900808,6295,ryannedolan,2019-05-16T21:13:47Z,"i think optional is supposed to be used only within the context of the java 8 streams api. it's not unusual to return nulls in java, nor in this code base. (though coming from scala this hurts a bit :grinning_face_with_smiling_eyes:)",0,0.7271184325218201
284945642,6295,ryannedolan,2019-05-17T00:41:48Z,"will fix, thanks.",1,0.9264264702796936
284947928,6295,ryannedolan,2019-05-17T00:59:12Z,"let's add min.insync.replicas here too, as this is likely to cause problems. h/t",0,0.9871860146522522
284948127,6295,ryannedolan,2019-05-17T01:00:47Z,"yeah let's blacklist anything with `__` prefix, thanks.",1,0.8504990339279175
284948535,6295,ryannedolan,2019-05-17T01:04:18Z,"yeah, herder requires an advertisedurl, tho we don't use it. i'll change this to `not used` to avoid confusion.",0,0.9724084734916687
284948676,6295,ryannedolan,2019-05-17T01:05:40Z,"we can drop these, thanks.",0,0.5629297494888306
284950066,6295,ryannedolan,2019-05-17T01:16:28Z,"i've left this as-is because it's convenient to test whether a topic has a source with `topicsource(topic) != null`, rather than to define and use a separate method like `hassource()` or something.",0,0.9940140843391418
284950514,6295,ryannedolan,2019-05-17T01:19:51Z,"`toset()` will throw an exception if it finds duplicates. this seems unlikely unless someone defines a really strange `replicationpolicy`, but i think it's worthwhile to avoid the exception just in case.",0,0.9618093967437744
284952693,6295,ryannedolan,2019-05-17T01:35:53Z,"this is just a convenience method, but i believe it is worthwhile. otherwise it is a bit cumbersome to recreate externally: [code block]",-1,0.7261770963668823
284954715,6295,ryannedolan,2019-05-17T01:51:24Z,this is useful for external tooling.,0,0.9849426746368408
284957873,6295,ryannedolan,2019-05-17T02:16:00Z,"i think the `__` should be limited to topics internal to kafka proper. the topics `mm2-offsets...`, `mm2-status...`, and `mm2-config...` are based on connect's defaults, `connect-offsets`, `connect-config` etc, which are not internal per se. i've added .internal to these so that you don't need to configure mm2 to blacklist itself, thought it's an interesting idea to just blacklist them automatically.",0,0.9848686456680298
285062422,6295,enothereska,2019-05-17T10:08:44Z,the readme could be re-worded a bit to start with a quickstart simplest case and then build from there to increasingly more complex cases. this could be done at a later pass too.,0,0.9922080636024475
285063053,6295,enothereska,2019-05-17T10:10:54Z,could we add a sentence on what the implications of this are? it's not immediately clear what should happen if mm runs with same source and target...perhaps nothing at all?,0,0.9302091002464294
285063661,6295,enothereska,2019-05-17T10:12:45Z,should we check in such a sample file in the config folder?,0,0.9951887130737305
285064156,6295,enothereska,2019-05-17T10:14:12Z,nit: mm2.properties or mm2.config?,0,0.9945247173309326
285480888,6295,viktorsomogyi,2019-05-20T08:40:35Z,"yea that would be helpful, people could use it as a template.",0,0.8629462122917175
285488395,6295,viktorsomogyi,2019-05-20T08:57:43Z,"well, oracle's own example uses optional in the context of return values so i think it'd be idiomatic to do so: [a link] generally i agree that in this codebase we often return nulls but if you look at for instance the transactionmanager, it uses optionals this way, so i think it's definitely encouraged here too :) [a link]",1,0.9909005165100098
285507212,6295,viktorsomogyi,2019-05-20T09:42:38Z,on this note we probably want to document that it doesn't work for transactional topics (also as this was one of the first questions on the summit :) ),1,0.7683148384094238
285510919,6295,viktorsomogyi,2019-05-20T09:51:48Z,i think it would make sense to pass `true` (or use the single param super constructor). it helps debugging the config.,0,0.9754109382629395
285513326,6295,viktorsomogyi,2019-05-20T09:57:38Z,`type.list` would be better maybe?,0,0.9936528205871582
285518598,6295,viktorsomogyi,2019-05-20T10:10:50Z,i'd like to make a general point but i didn't know any specific places so i'd put it here. it'd be helpful from the usability perspective to validate configs. i've tried to specify this config: [code block] you can notice that i put a `;` in the cluster separator config but nothing thrown an exception saying that i haven't specified the correct clusters (mm2 just started up and shut down).,0,0.9477949738502502
285562725,6295,viktorsomogyi,2019-05-20T12:21:22Z,we might pass `true` if that makes sense.,0,0.9920699000358582
286460327,6295,viktorsomogyi,2019-05-22T12:22:07Z,nit: maybesendoffsetsync?,0,0.9895210266113281
286465012,6295,viktorsomogyi,2019-05-22T12:34:12Z,i was wondering if - would it make sense to make this configurable? - wouldn't this be mostly the same as configuring the `max.in.flight.requests.per.connection` property of the `offsetproducer` and have you thought about using just that config?,0,0.9924426674842834
286471163,6295,viktorsomogyi,2019-05-22T12:48:53Z,i think it would be better to use some timeout here as it spams the log with the below warn message.,0,0.9804002046585083
286475429,6295,viktorsomogyi,2019-05-22T12:58:11Z,as far as i understand offsets would be synced eventually so i think we might want to reconsider if this is a warn level log message (maybe even lower it to debug?).,0,0.9877986907958984
286585537,6295,jeremy-l-ford,2019-05-22T16:41:55Z,should the returned classloader be restored at the end of the method?,0,0.9947391152381897
286638392,6295,harshach,2019-05-22T18:58:03Z,there seems to be null some places and other places -1. if possible can we standardize or leave a comment.,0,0.9650153517723083
288238131,6295,jeremy-l-ford,2019-05-28T18:17:28Z,"i have been testing this branch and used the connector.class option noted above in my configuration. i noticed that records were being copied 3x instead of the expected 1. debugging through the source, apparently that configuration will override the connector name that is setup during mirrormakerconfig.connectorbaseconfig. since mirrormaker attempts to setup the source, health, and checkpoint connectors, i actually ended up with 3 source connectors.",0,0.9848259687423706
288280080,6295,ryannedolan,2019-05-28T20:07:25Z,"-l-ford funny problem! i think this, along with others' experiences here, indicates i need to remove this sample configuration altogether, and just provide a top-level configuration file like in the ""quick start"" above. the connector configuration is just confusing. moreover, it doesn't really demonstrate anything beyond the existing generic connect-standalone.properties file. i'll remove this file, thanks.",-1,0.9452269077301025
289196474,6295,OneCricketeer,2019-05-30T22:26:56Z,"related to i assume with the addition of record header copying, it will also only work for when `log.message.format.version` >= `0.11.0` ? at least, we've noticed that when clients try to use headers (or transactional producers) after broker upgrades, but before log format changes, then they are usually throwing `unknownserverexception`. --- one workaround i did (for an smt) was to conditionally copy the headers to the transformed record. e.g. [a link]",0,0.9929798245429993
289495296,6295,jeremy-l-ford,2019-05-31T18:03:55Z,try/finally close the consumer,0,0.9714640974998474
290088869,6295,ryannedolan,2019-06-04T00:36:16Z,let's just remove the log message altogether.,0,0.9776781797409058
290090082,6295,ryannedolan,2019-06-04T00:43:44Z,"i'm not certain, but the other drivers (connect-standalone, connect-distributed) do it this way. i'll just cargo-cult here.",0,0.8038166165351868
290369229,6295,ryannedolan,2019-06-04T15:50:36Z,"my intention is to support 0.11.0 onwards, at least for now. we can revisit making headers optional to support older versions, but i think this probably isn't the only thing that would break before 0.11.0.",0,0.9833995699882507
290371819,6295,ryannedolan,2019-06-04T15:55:40Z,i dropped this file to avoid confusion.,0,0.9512293338775635
290372405,6295,ryannedolan,2019-06-04T15:56:58Z,"this method doesn't contain a conditional branch (the existing maybesendoffsetsync does), so i'll leave this as is.",0,0.9933027029037476
290372816,6295,ryannedolan,2019-06-04T15:57:53Z,"i dropped the logging entirely. there is no harm if tryacquire fails, so better to not spam the log as you say.",0,0.8153191208839417
290407619,6295,ryannedolan,2019-06-04T17:22:51Z,"fixed. this was b/c mm was finding only a single cluster (""upstream;downstream"") and had no source->target pairs to replicated. i've added an exception ""no source->target replication flows"" in this case, which should at least point you in the right direction.",0,0.9930925369262695
291329247,6295,vpernin,2019-06-06T19:06:16Z,is this intended to not set the interrupted flag again ? same question elsewhere like in mirrorsourcetask.cleanup().,0,0.992510199546814
291333700,6295,vpernin,2019-06-06T19:19:28Z,is there a risk the semaphore not to be released if the async send fails internal before invoking this callback ?,0,0.9865328073501587
291354482,6295,vpernin,2019-06-06T20:19:21Z,"the underlying client method seems to use a default timeout of long.max_value, timeunit.milliseconds. i'm worried that it can prevent the jvm to stop ?",-1,0.883604109287262
291590085,6295,vpernin,2019-06-07T13:24:28Z,the kip seems to refresh.topics is true by default. the property refresh_topics_enabled is named refresh.topics.enabled and the default does not seem to be refresh_topics_enabled_default used. so the topics are not refreshed by default.,0,0.9932615160942078
291660048,6295,ryannedolan,2019-06-07T16:11:37Z,the default is set here: [a link] and used here: [a link] i've verified this works as expected. happy to take suggestions if this is not clear.,1,0.9757029414176941
291839414,6295,williamhammond,2019-06-09T14:58:07Z,don't we need a catch for `org.apache.kafka.common.kafkaexception` as well when calling `consumer.close()`?,0,0.9947078227996826
291840811,6295,williamhammond,2019-06-09T15:44:07Z,i feel like i must be missing something obvious but since the source admin client will be an instance of `kafkaadminclient` since we're calling `[a link] to create the client and the `kafkaadminclient` overrides close as such [a link] are we not actually releasing resources but calling close without a duration? i'm probably misremembering something about inheritance but either way i think we should be passing in a duration here since the default close just is kind of odd vpernin pointed out.,0,0.6795547008514404
296221720,6295,jeremy-l-ford,2019-06-21T12:51:34Z,"based on [a link] seems like the consumer may be null when attempting to close it. also, should the call to close the producer be in a separate try/catch to at least attempt to close the producer in the case where closing the consumer causes an exception?",0,0.9937547445297241
297175786,6295,vpernin,2019-06-25T13:03:58Z,"you're right. i might miss something obvious, but the propagation of topic creation on downstream cluster does not seem to work. the mirrorsourceconnector.refreshtopicpartitions detects a new topic properly and and it requests a task reconfiguration. but the code that really proceed to the topic creation seems to be in mirrorsourceconnector.createtopicpartitions and this task is only executed once at startup and not at the reconfigure phase.",0,0.9676542282104492
298207543,6295,vpernin,2019-06-27T14:30:17Z,"shouldn't we have a check on the enabled status of the herder like b->a.enabled = false ? with a simple setup enabled on the a->b direction and disabled on the b->a, i see that the herder b->a is created and heartbeats are emitted to cluster[a].topic[heartbeats], to its replicated on cluster[b].topic[a.heartbeats] and also on cluster[b].topic[heartbeats].",0,0.9930710196495056
298289975,6295,arunmathew88,2019-06-27T17:34:21Z,"as per the kip the mirrored topic should be writable by mirror maker only, how is this ensured? i couldn't find a filter rejecting any write acls to the topic in this call?",0,0.9946786165237427
298543696,6295,vpernin,2019-06-28T10:37:46Z,"shouldn't we have a public way to deserialize heartbeat object, heartbeat.deserializerecord not being public ?",0,0.9924330711364746
299083439,6295,ryannedolan,2019-07-01T14:55:06Z,"this behavior is subtle but correct. we want heartbeats going everywhere, even to clusters that aren't a target of any source->target replication. this is because we need heartbeats to exist upstream in order to replicate them downstream. if we are replicating a->b, we don't want to emit heartbeats only to b -- that wouldn't really tell us much, except that mm can send to b. what we want to know is how long it takes records to travel from a to b. so we emit heartbeats to a and _replicate them_ to b. this lets us monitor latency between a and b even when no other records are being replicated. specifically, we create herders between every pair of clusters (a fully-connected mesh) and emit heartbeats everywhere. then, for the subset of ""enabled"" replications, we start at least one mirrorsourceconnector task. these tasks _always_ replicate heartbeats, so the result is ""a.heartbeat"" in cluster b whenever a->b is enabled. we could _only_ emit records upstream (i.e. only to sources and not targets) and achieve this same result, but heartbeats are useful for more than measuring cross-cluster latency. emitting heartbeats everywhere makes various other tooling possible. for example, you can query any single cluster and find out about every other cluster just by consuming the heartbeat topic, since heartbeats will have come from everywhere.",0,0.7927557229995728
299085902,6295,ryannedolan,2019-07-01T14:59:43Z,i'm fine with that.,0,0.8899003863334656
299213804,6295,ryannedolan,2019-07-01T20:55:04Z,connector.reconfigure() by default just calls stop() and start(config). there is no other logic related to reconfiguration at present.,0,0.9928293824195862
299324123,6295,vpernin,2019-07-02T06:45:34Z,"ok, i understand this conception. maybe, this clear explanation has its place in the kip and the documentation.",0,0.9534593820571899
299339279,6295,vpernin,2019-07-02T07:32:33Z,"i'm just noticing, that in my case, the creation of a new topic (matching replication pattern) upstream is not propagated downstream. the subject of the reconfigure process is just a attempt to explain the problem. kmm2 need to be restarted, so mirrorsourceconnector.createtopicpartitions is called. connector.reconfigure() does indeed stop and start, which would work, but this is not invoked. we call context.requesttaskreconfiguration() and it does not do that.",0,0.97342449426651
308616567,6295,o-kasian,2019-07-30T09:16:29Z,"this should probably be `this.herderpairs = config.enabledclusterpairs().stream()`, otherwise `a->b.enabled` makes no sense",0,0.9946910738945007
308690793,6295,o-kasian,2019-07-30T12:27:26Z,"`kafka/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/mirrorsourceconnector.java:106` offset sync topic is created in `target`, however offsetproducer uses `config.sourceproducerconfig()` it results in messages like `error while fetching metadata with correlation id 416 : {mm2-offset-syncs.backup.internal=unknown_topic_or_partition}` in logs, and is not able to write offset mappings",0,0.9923104047775269
308953520,6295,ryannedolan,2019-07-30T21:35:28Z,"good catch, thanks!",1,0.9953822493553162
308954111,6295,ryannedolan,2019-07-30T21:37:07Z,see this earlier comment: [a link] i'll add a comment in the code somewhere to explain.,0,0.9817781448364258
310134951,6295,mimaison,2019-08-02T13:37:55Z,`record.value()` can be null here. this leads to [a link],0,0.9929584264755249
310137707,6295,mimaison,2019-08-02T13:44:46Z,"the order of the arguments is inverted, `(short) 1` should be the 2nd argument and the replication factor the 3rd one. the prototype is `createtopic(string topicname, short partition, short replicationfactor, map adminprops)`",0,0.9949491024017334
310138665,6295,mimaison,2019-08-02T13:46:59Z,"the order of the arguments is inverted, `(short) 1` should be the 2nd argument and the replication factor the 3rd one. the prototype is `createtopic(string topicname, short partition, short replicationfactor, map adminprops)`",0,0.9949491024017334
311630254,6295,mimaison,2019-08-07T15:50:11Z,"should this use `config.sourceadminconfig()` instead of `config.targetadminconfig()` ? otherwise, i'm getting: [code block] and the topic is only created in the target cluster.",0,0.9895535707473755
311789488,6295,ryannedolan,2019-08-07T22:29:05Z,"fixed, thanks",1,0.8305290937423706
311789612,6295,ryannedolan,2019-08-07T22:29:31Z,"fixed, thx",0,0.9519848823547363
311790132,6295,ryannedolan,2019-08-07T22:31:41Z,"fixed, thx",0,0.9519848823547363
312966989,6295,mimaison,2019-08-12T14:53:36Z,`x.getkey()` is the topic name. we need to iterate over `topicconfigs.values().entries()` instead to filter out topic properties.,0,0.9939688444137573
312967159,6295,mimaison,2019-08-12T14:53:56Z,should we also filter configs with `static_broker_config` as the source?,0,0.9951241612434387
314489069,6295,ryannedolan,2019-08-15T20:41:47Z,"i dropped the enabledclusterpairs() method, so marking this resolved.",0,0.9937402009963989
314559556,6295,ryannedolan,2019-08-16T01:52:52Z,great catch! i've fixed and added a unit test.,1,0.9953961968421936
314801873,6295,ryannedolan,2019-08-16T16:46:05Z,i _think_ isdefault() will catch that case? not sure.,0,0.8801502585411072
314809527,6295,mimaison,2019-08-16T17:08:11Z,`isdefault()` only matches `configsource.default_config`. see [a link],0,0.993681788444519
314812870,6295,ryannedolan,2019-08-16T17:17:16Z,"ah, thanks . fixed.",1,0.9787132740020752
317319292,6295,ryannedolan,2019-08-23T22:20:08Z,we never block on the semaphore -- only trywait() -- so there is no chance of deadlocking at least. i don't think there is any other consequence if we don't get around to releasing a semaphore.,0,0.9637467861175537
317335237,6295,ryannedolan,2019-08-24T00:15:52Z,"do you mean to implement the ..utils.scheduler interface here, or to instead use the internal kafka.utils.kafkascheduler? the latter would work just fine, but i'm reluctant to depend on something in kafka.utils.",0,0.8176820278167725
317342841,6295,ryannedolan,2019-08-24T03:22:37Z,"fixed, thx",0,0.9519848823547363
317343051,6295,ryannedolan,2019-08-24T03:30:54Z,"it's hard to imagine a case where you'd need to tweak this property. i guess if you had offsets.lag.max set to zero, which means every replicated record would cause an offset sync, then you'd run up against the max outstanding offset syncs limit pretty quick. but i don't know why you'd do that. normally offset syncs are very sparse, and it never matters if you drop a few occasionally. so this is mostly an arbitrary number, and anything greater than 0 will work fine.",0,0.779624879360199
317346004,6295,ryannedolan,2019-08-24T05:39:36Z,"fixed, thx",0,0.9519848823547363
317346028,6295,ryannedolan,2019-08-24T05:41:12Z,"thanks guys, this does seem like a problem. fixed by adding a configurable timeout.",1,0.8841202259063721
323912773,6295,qihongchen,2019-09-12T19:31:32Z,"there's no argument for `""metatadata=%s""`, it should be removed, or add an argument for it (correct the typo as well).",0,0.995012104511261
326590142,6295,dataGeeek,2019-09-20T11:43:38Z,"knowntargettopics state is currently only refreshed at two occasions: * startup of the connector, before topics in downstream cluster are created and therefore stays empty * new partitions/ dead partitions in upstream cluster are found. in the case of no creation of new partitions in upstream cluster, the state remains empty, which blocks config syncing, since only configs of knowntargettopics will be synced. i propose refreshing the state of knowntargettopics at startup after topics in downstream cluster are created and have provided a pr: [a link]",0,0.9923006296157837
327205321,6295,ryannedolan,2019-09-23T16:15:16Z,great find! merged.,1,0.9955288767814636
327276472,6295,dataGeeek,2019-09-23T18:56:10Z,"your're welcome! besides that, our tests of the mm2 were very promising. great work and lgtm",1,0.9960538148880005
328867657,6295,junrao,2019-09-26T23:41:46Z,"hmm, why do we need to call commitrecord twice?",0,0.8352935910224915
328867839,6295,junrao,2019-09-26T23:42:42Z,should we version the value schema for potential future extension? ditto is other newly added schemas.,0,0.9916182160377502
328867958,6295,junrao,2019-09-26T23:43:24Z,could we add the javadoc for each of the public method in this and other user facing classes?,0,0.9943075776100159
328867995,6295,junrao,2019-09-26T23:43:34Z,is it useful to have a metric that just captures the lag of the current record?,0,0.9914585947990417
328868071,6295,junrao,2019-09-26T23:43:57Z,should we add max in the description? ditto in a few other places.,0,0.9921798706054688
328868144,6295,junrao,2019-09-26T23:44:25Z,"hmm, the downstream offset doesn't alway advance faster than the upstream. for example, when mirroring a compacted topic, the downstream offset could advance slower than upstream when the upstream offsets have holes.",0,0.8714476227760315
328868189,6295,junrao,2019-09-26T23:44:40Z,"hmm, how do we make sure that the latest offset in offsetsyncstore match what's needed for the consumer offset?",0,0.9558855891227722
328868228,6295,junrao,2019-09-26T23:44:51Z,do we need debug by default? it could slow down the tests on jenkins.,0,0.9618027806282043
328868442,6295,junrao,2019-09-26T23:46:06Z,calling system.currenttimemillis() on every record could be expensive.,0,0.981086015701294
328868644,6295,junrao,2019-09-26T23:47:12Z,should we update lastsyncupstreamoffset and lastsyncdownstreamoffset only after the offsets have been successfully written to the offset sync topic?,0,0.9947364926338196
328868859,6295,junrao,2019-09-26T23:48:22Z,should offsetsync topic always be single partition?,0,0.9928985834121704
328869797,6295,junrao,2019-09-26T23:53:43Z,should we replicate prefix acls too?,0,0.9934961795806885
329268348,6295,ryannedolan,2019-09-27T22:13:48Z,"offset syncs (and checkpoints and heartbeats) are sparse and rare in practice, so this topic is very small. it's only written to when the upstream and downstream offsets for a partition don't match what is expected, which is approximately as rare as duplicate records being sent to a topic. mm2 can run for days without sending a message here. so there isn't a need to have multiple partitions, and doing so would complicate the logic for scanning the topic for a given offset, to some extent.",0,0.9331610202789307
329268969,6295,ryannedolan,2019-09-27T22:15:59Z,"good point, will fix.",1,0.9226331114768982
329274932,6295,ryannedolan,2019-09-27T22:46:42Z,"yes that would be useful, however, not nearly as useful as latency of each record, since latency is more easily aggregated over entire topics (and, externally, over entire clusters), and is much more relevant to the operator. consider that an mm2 operator would not know how to compare a lag of 100 offsets in one partition to a lag of 1 offset in another partition, as they could both represent <1s behind real-time, depending on the size of messages etc. so while offset lag may be very useful to an operator of a specific app consuming from specific topics, it is unlikely useful to an mm2 operator replicating entire clusters.",0,0.9822748899459839
329277034,6295,ryannedolan,2019-09-27T22:59:00Z,"a sourcetask implementation is unlikely to implement both methods. they are nops by default. if it does, it's unlikely an implementation would do the same thing in both methods. if it does, the interface does not guarantee that commitrecord() is called exactly once per record anyway (or even at least once). and indeed other methods, e.g. stop() and commit(), make no such guarantees either. i'd be in favor of deprecating commitrecord(record) to avoid confusion here, but that is out of scope for this kip and pr.",0,0.9542409181594849
329835717,6295,ryannedolan,2019-10-01T00:07:02Z,done,0,0.8974218964576721
329835749,6295,ryannedolan,2019-10-01T00:07:10Z,done,0,0.8974218964576721
329835788,6295,ryannedolan,2019-10-01T00:07:20Z,done,0,0.8974218964576721
329835885,6295,ryannedolan,2019-10-01T00:07:49Z,done,0,0.8974218964576721
329863044,6295,ryannedolan,2019-10-01T03:00:19Z,"good idea, this would improve accuracy of the offset syncs and checkpoints. i've made this change locally and don't see any problems. however, i'd rather not make a functional change this close to a code freeze. let's make this improvement in a short follow-up pr.",1,0.9314689040184021
330097541,6295,junrao,2019-10-01T14:42:48Z,"since this is a public api change, i think it's important to think through the impact to connector developers. i am thinking that we can (1) provide a default implementation of commitrecord(sourcerecord record, recordmetadata metadata) in sourcetask that calls commitrecord(sourcerecord record) by ignoring recordmetadata to provide backward compatibility; (2) only use commitrecord(sourcerecord record, recordmetadata metadata) in workersourcetask; (3) mark commitrecord(sourcerecord record) as deprecated to encourage people to use the new api and document the behavior if both methods are implemented (the implementation for the old api will be ignored). any thought on this?",0,0.9819308519363403
330130857,6295,rhauch,2019-10-01T15:41:22Z,"so far, the connect api exposes only a few kafka client types in a few areas (right now just `sinktask`). we should be careful and explicit about making the `sourcetask` interface use `recordmetadata`. but assuming that's okay, i think having connect call two distinct `commitrecord(...)` methods with different signatures is at best confusing for developers (which do i implement) and at worst a potential source of error. we have resolved similar evolutions in the past by following the approach that mentioned, and i think that makes the most sense here. (we've not always deprecated the older method when it still applicable, but in this case i think we'd want to deprecate the older method.) however, before we introduce a new variant of an existing method, we should also consider whether we might need to again modify the signature in the future. if so, we should consider whether it makes sense to create a new interface type to pass to the method that would make it easier in the future. i'm not sure that we do, since the `workersourcetask` calls this from within the producer callback and only when the exception is not null, meaning there currently is no other data available to the invocation.",0,0.9442505836486816
330134311,6295,rhauch,2019-10-01T15:47:50Z,this pr probably needs to mention it is also implementing kip-416.,0,0.9930405616760254
330137341,6295,ryannedolan,2019-10-01T15:53:53Z,happy to deprecate the older method if we have concensus here.,1,0.8500864505767822
330149902,6295,ewencp,2019-10-01T16:20:22Z,"given we can use default implementations now, just providing a default implementation and not deprecating seems better. afaik, `recordmetadata` has never been requested before, but a number of connectors use the existing signature for `commitrecord`. calling twice and having to understand that does seem confusing, but having overloads and simplified versions doesn't -- you just get to choose to implement something simpler. we've been pretty conservative with deprecation in the connect and that has served us well wrt broad compatibility -- i think only `onpartitionsassigned/revoked` for sink tasks and a couple of configs have gone through this, and still haven't been removed (with little maintenance cost afaik), which means we've remained cleanly compatible in most ways all the way back to 0.9. i'm generally for deprecation and removal (e.g. there's lots of core configs that i think are unnecessary and could be cleaned up), but only if the cost is worth it. in this case, there *is* a transition cost since the existing api is being used, and i'm not sure the reduction in confusion is worth it (vs some simple api docs explaining default impl).",0,0.9297474026679993
330154422,6295,rhauch,2019-10-01T16:30:30Z,"good point about not deprecating, . i could definitely go either way, and definitely see value in not deprecating and leaving it up to the implementer to choose which they'd implement. but i do think overriding one method is better than having to potentially override both methods for different purposes. because this is changing the connect api, it does seem like we need to come to consensus and approve kip-416 before this pr can be merged, though.",0,0.5197669863700867
330162479,6295,ryannedolan,2019-10-01T16:49:07Z,"that would be neat, but there are landmines here. we don't want a prefix pattern to accidentally apply to topics on another cluster, so we can't just copy prefixes across. we could maybe expand a prefix ""foo"" on cluster ""primary"" to an equivalent ""primary.foo"" prefix, but that would only work if replicationpolicy used something like the default topic renaming convention -- a custom naming convention like ""topic-dc1"" would not work with prefixes this way. we could maybe find all prefix patterns and replicate them as explicit literal patterns. so a prefix of ""foo"" turns into literals ""primary.foo-1"", ""primary.foo-bar"", etc. but even that is a little dangerous, as it is not easily reversible. for example, what happens when an upstream prefix acl is deleted? if there is a safe way to do this, i haven't thought of one yet. we should stick with literals only for now.",0,0.6983280181884766
330168213,6295,ryannedolan,2019-10-01T17:01:31Z,"my vote is for keeping both methods (as implemented here), since this doesn't break or deprecate existing code, nor is it especially confusing to see the same method with overloaded parameters in an interface, especially when neither are required to implement. i think the confusing part is just in the workersourcetask implementation, not the sourcetask interface -- it's a little surprising to see the same method called twice here. i suggest we add a comment here and move on. thoughts?",0,0.5447492599487305
330203738,6295,ryannedolan,2019-10-01T18:20:07Z,"done, thanks.",1,0.6998467445373535
330206785,6295,AndrewJSchofield,2019-10-01T18:26:49Z,"i'd prefer to see kip-416 introduce `public void commitrecord(sourcerecord sourcerecord, recordmetadata recordmetadata)` which is called in exactly the same situations as the existing `public void commitrecord(sourcerecord sourcerecord)`. the new method might be called with null record metadata. the implementor has a choice of which to implement.",0,0.9937791228294373
330209568,6295,rhauch,2019-10-01T18:32:48Z,", i disagree that the confusing part is just in the `workersourcetask` implementation. i believe it is confusing that both methods might be called with the same record, and that there is no benefit from doing that. so the issue i have is that i believe the proposed changes to the connect api make it less clear how to properly implement it. it is much clearer for the api to offer two methods and to say the framework always calls the new one, the new one by default calls the old one, and that task implementations can override one or none of them. then it is entirely up to the task implementation to decide whether to even treat these conditions as distinct.",-1,0.7119473814964294
330213298,6295,ryannedolan,2019-10-01T18:41:02Z,"just clarifying, are you suggesting we take 's suggestion, except we don't deprecate the existing method? i.e. have the new method call the old? does that satisfy your concern as well?",0,0.9836783409118652
330304627,6295,rhauch,2019-10-01T22:28:58Z,", yes, i am suggesting that we follow 's suggestion minus deprecating the old method. iow, we'd do the following: 1) add the new method that by default calls the old method; and 2) change all uses in the connect runtime (namely in workersinktask and its test class) to use the new method and update kip-416 accordingly.",0,0.9861836433410645
330323913,6295,ryannedolan,2019-10-01T23:50:39Z,sounds like we have concensus. will update shortly.,0,0.9338513016700745
330852160,6295,ryannedolan,2019-10-03T03:33:55Z,i made the change. happy with either approach.,1,0.9858662486076355
331279220,6295,junrao,2019-10-03T22:24:15Z,could we add some comments to make it clear that one only needs to implement one of the commitrecord()?,0,0.9942860007286072
331279346,6295,ryannedolan,2019-10-03T22:24:53Z,"agree, there is room for improvement here. an obvious improvement would be to track latency only for the last record in each batch. i can address this in a later pr.",0,0.9881188273429871
331283010,6295,ryannedolan,2019-10-03T22:40:15Z,"we don't use the offsetsyncstore's offsets until we create a checkpoint. if the offsets are invalid or too far behind (-1 here), the checkpoint is not emitted for that topic-partition. so a downstream consumer would see an older checkpoint record for that topic-partition, which in turn was computed from a previous (valid) offset-sync. when replication first starts, there will be no checkpoints. once offsetsyncstore is primed with offset-offset pairs, checkpoints will be emitted. if, say, mm2 fails to send to the offset-syncs topic for whatever reason, there will be no checkpoints until this process succeeds. both offset-syncs and checkpoints are ""opportunistic"" in the sense that it is never _essential_ that they are sent at any given point in time in order for downstream consumers to be correct. so we only send them when we are in a good state and have enough information to send a valid checkpoint.",0,0.9893581867218018
331283663,6295,ryannedolan,2019-10-03T22:43:07Z,"yes, this is actually handled here. any holes upstream will trigger an offset-sync immediately. if such an offset-sync _fails_, for whatever reason, it just means that a checkpoint will not be emitted until the next sync... generally a few seconds later. i'll call out a unit test that shows this in action.",0,0.9895944595336914
331284770,6295,ryannedolan,2019-10-03T22:47:52Z,"holes in a compacted topic are handled, as shown here.",0,0.9920769929885864
331301537,6295,junrao,2019-10-04T00:10:16Z,"unused exceptions interruptedexception, timeoutexception. also, does this test cover anything more than the previous test?",0,0.9782218933105469
331494794,6295,omkreddy,2019-10-04T13:16:35Z,"we need to include javadocs section for newly added public interfaces/classes. example: [a link] i assume, we will be adding kafka website documentation as part of kafka-8930. [a link] also looks like test failures are related.",0,0.9940571784973145
331577566,6295,ryannedolan,2019-10-04T16:08:07Z,"ah thanks i'll fix the javadocs this morning. for the website documentation, we'll need to keep the existing mirror-maker section for now, but i'll add a section re mm2, probably in a separate pr. the failing tests seem to be related to flakiness in the connect integration test framework. i'll see what i can do.",1,0.8208009600639343
331732524,6295,ryannedolan,2019-10-05T04:44:20Z,"fixed. in the second test, additional topics are added, detected, and replicated. detecting new topics will trigger a task rebalance in the middle of the test, which doesn't happen in the first. granted, it might make sense to collapse these into a single test rather than bring up and tear down the clusters twice.",0,0.992312490940094
331732663,6295,ryannedolan,2019-10-05T04:49:34Z,added a couple lines locally. will hold on to the commit for now -- i don't want to trigger another build at the moment.,0,0.9784064292907715
331746988,6295,rhauch,2019-10-05T13:37:45Z,", we need to clearly specify that `metadata` parameter can be null, and then in the javadoc above specify what this means for the source task, namely that a transform dropped/skipped the record and it was not written to kafka. imo this is necessary so that developers of connector implementations know what the behavior is so they can properly implement their task. (the javadoc was not in [a link] i also think that it's also worth mentioning here that `sourcetask` implementations need only implement this method *or* the older `commitrecord(sourcerecord)` *or* neither method, but that generally they do not need to implement both since connect will only call this method. again, this will help developers that are implementing their own `sourcetask` what they need to do.",0,0.9872404932975769
331750101,6295,ryannedolan,2019-10-05T15:15:01Z,i improved the javadocs further. should be clear now.,0,0.9792537689208984
331750119,6295,ryannedolan,2019-10-05T15:15:46Z,i collapsed the two integration tests into one -- seems to save 30 seconds or so.,0,0.9846087694168091
331795997,6295,ijuma,2019-10-06T15:42:24Z,is there a reason why this is not using the `time` interface? we generally never use `system.currenttimemillis()` in kafka.,0,0.9914071559906006
331800260,6295,ryannedolan,2019-10-06T17:14:55Z,"good idea, we should replace these in a subsequent pr.",1,0.9354078769683838
381865765,6295,amanullah92,2020-02-20T09:06:17Z,"this directive (a->b.enabled) is missing in kip in the ""running mirrormaker in production section""-- i got the cluster up but no replication was happening. until i saw this and fixed this. i am new to mirrormaker/connect framework- forgive me if this is a well known thing.",0,0.707767903804779
526479473,9485,rajinisivaram,2020-11-18T22:58:26Z,we should document what this default implementation does and why a custom implementation may want to override this default.,0,0.9849432706832886
526479478,9485,rajinisivaram,2020-11-18T22:58:26Z,we should document what this default implementation does and why a custom implementation may want to override this default.,0,0.9849432706832886
526481573,9485,rajinisivaram,2020-11-18T23:03:40Z,nit: indentation,0,0.5517857670783997
526482899,9485,rajinisivaram,2020-11-18T23:07:07Z,"this looks identical to the code block above for prefix, we could just run the same code in a loop that checks both allow literals and prefixes.",0,0.9906845092773438
526483476,9485,rajinisivaram,2020-11-18T23:08:45Z,we should have exactly one call to `logauditmessage` that says whether access was allowed or denied.,0,0.9943621158599854
526486028,9485,rajinisivaram,2020-11-18T23:15:24Z,"request.principal can be a custom extension of kafkaprincipal, we cannot use tostring for comparison",0,0.9942217469215393
526487176,9485,rajinisivaram,2020-11-18T23:18:26Z,not sure it is worth making a whole copy of this structure for a method that is not used frequently. it will be good to add microbenchmarks to `aclauthorizerbenchmark` to understand how the new method performs.,0,0.9858012795448303
526487761,9485,rajinisivaram,2020-11-18T23:19:56Z,"same as in the authorizer default method, we cannot use request.principal().tostring()",0,0.9943566918373108
526489152,9485,rajinisivaram,2020-11-18T23:23:54Z,"we should optimize for the case where there are no deny acls. there is no point in finding all matching allow entries in that case, we would just need to check for one allow.",0,0.9929898977279663
526494014,9485,rajinisivaram,2020-11-18T23:37:05Z,make this all the methods below `private`,0,0.9932697415351868
526494298,9485,rajinisivaram,2020-11-18T23:37:54Z,we coul just inline all the methods below instead of separate methods for host etc.?,0,0.9685915112495422
526495928,9485,rajinisivaram,2020-11-18T23:42:06Z,"hmm, produce s authorized for topic anyway. why would we use a very expensive authorizebyresourcetype here?",0,0.911263108253479
526496224,9485,rajinisivaram,2020-11-18T23:42:56Z,"first authorize should use `logifallowed=true`, `logifdenied=false`",0,0.9943791031837463
526496998,9485,rajinisivaram,2020-11-18T23:44:48Z,`durability`?,0,0.9902965426445007
526499159,9485,rajinisivaram,2020-11-18T23:50:40Z,it may be better to put the mock tests into another test class. that wouldn't request zookeeper for example.,0,0.9939125776290894
526499504,9485,rajinisivaram,2020-11-18T23:51:38Z,"as before, references to durability in authorizer tests are confusing.",0,0.5528138279914856
526500688,9485,rajinisivaram,2020-11-18T23:54:50Z,are we going to add tests here?,0,0.9918318390846252
526502000,9485,rajinisivaram,2020-11-18T23:58:19Z,we should run the microbenchmarks in aclauthorizerbenchmark to make sure we don't add too much overhead here.,0,0.9909634590148926
526503975,9485,rajinisivaram,2020-11-19T00:03:44Z,don't we reuse this in multiple tests? how do we guarantee that no state is preserved between tests?,0,0.9902663826942444
526504244,9485,rajinisivaram,2020-11-19T00:04:32Z,we could mock this fully instead of using aclauthorizer?,0,0.992330014705658
526504251,9485,rajinisivaram,2020-11-19T00:04:33Z,we could mock this fully instead of using aclauthorizer?,0,0.992330014705658
529008307,9485,ctan888,2020-11-23T21:29:27Z,"yeah, that's right. construct a kafkaprinciple instance with params referred from principal.gettype() and getname() commit 89df4d7600cad4e3785d0d95624d0918efce1f44",0,0.9873802661895752
529008818,9485,ctan888,2020-11-23T21:30:18Z,"yeah, that's right. construct a kafkaprinciple instance with params referred from principal.gettype() and getname() commit 89df4d7600cad4e3785d0d95624d0918efce1f44",0,0.9873802661895752
529031043,9485,ctan888,2020-11-23T22:15:54Z,yes. using an arraylist to group allow-literals & allow-prefixes in order to deduplicate the logic using a loop commit 188536ad8df13fc327008e59c9787ad2230a7186,0,0.9932793974876404
529089666,9485,ctan888,2020-11-24T00:45:42Z,good point. deferred the collection generation until we need it. commit 3906f978e62255ff266f081bf646a4b3c6b896ad,0,0.7236259579658508
529089823,9485,ctan888,2020-11-24T00:46:09Z,good catch. commit 3906f978e62255ff266f081bf646a4b3c6b896ad,1,0.9785639047622681
529090156,9485,ctan888,2020-11-24T00:47:03Z,yeah. but i'd guess that the compiler will optimize for us. commit 3906f978e62255ff266f081bf646a4b3c6b896ad,0,0.9771162867546082
532327560,9485,ctan888,2020-11-30T03:20:04Z,"commit 230ee36b9147a11d7ce299aa9fcbb590324faf68 added the authorizebyresourcetype() api to the benchmark and simulate the worst case: every allow acl on the same resource has a dominant deny acl. adjust the `resourcecount` parameter to ""10000"", ""40000"", ""80000"" since each cluster is unlikely to have more than 10k resources. also, since we are testing against the worst case mentioned above, i think the ""10000"" cases are adequate for us. performance result here: [a link]",0,0.9811211228370667
532327775,9485,ctan888,2020-11-30T03:21:02Z,"commit 230ee36b9147a11d7ce299aa9fcbb590324faf68 added the authorizebyresourcetype() api to the benchmark and simulate the worst case: every allow acl on the same resource has a dominant deny acl. adjust the `resourcecount` parameter to ""10000"", ""40000"", ""80000"" since each cluster is unlikely to have more than 10k resources. also, since we are testing against the worst case mentioned above, i think the ""10000"" cases are adequate for us. performance result here: [a link]",0,0.9811211228370667
532336627,9485,ctan888,2020-11-30T04:03:00Z,yes. commit 254af37df5e2d6ec462e7b70497ceb655edea596,0,0.9840076565742493
532337358,9485,ctan888,2020-11-30T04:06:39Z,right. deleted the else branch. commit 254af37,0,0.9816657900810242
532337445,9485,ctan888,2020-11-30T04:06:59Z,commit 254af37,0,0.9736488461494446
532337761,9485,ctan888,2020-11-30T04:08:19Z,i was trying to prove that the new api can work properly with multiple add / remove operations. changed to `testauthorizeranymultipleaddandremove` for now. any naming suggestion? commit b0aa305d8c043075ef0bb7b41d2c37e0072284c5,0,0.9898082613945007
532338240,9485,ctan888,2020-11-30T04:10:31Z,the mockauthorizer is an aclauthorizer using the interface default to do `authorizebyresourcetype`. i was trying to prevent the duplicated code and ease the test implementation. do you think we can keep it here?,0,0.990822434425354
532341814,9485,ctan888,2020-11-30T04:27:40Z,right. didn't realize that staitc variables in the permgen area will stay there during the whole unit test process. turn the class variable into the instance variable.,0,0.9577983617782593
532342253,9485,ctan888,2020-11-30T04:29:39Z,"if we are mocking this fully, we'd probably need tests on the `authorize` api which the interface default `authorizebyresourcetype` is based on. also, we'll have much more duplicated code in order to implement all the interfaces.",0,0.9896695017814636
532343635,9485,ctan888,2020-11-30T04:36:10Z,i was trying to prove that the new api can work properly with multiple add / remove operations. changed to `testauthorizeranymultipleaddandremove` for now. any naming suggestion? commit b0aa305d8c043075ef0bb7b41d2c37e0072284c5,0,0.9898082613945007
532343754,9485,ctan888,2020-11-30T04:36:40Z,no. i was going to but that would add tons of duplicated codes. so i added the interface default test logic into aclauthorizertest. file deleted.,0,0.9653894901275635
532346213,9485,ctan888,2020-11-30T04:48:19Z,yes. let's document this after we finally settle down all the implementations.,0,0.9696490168571472
533501963,9485,rajinisivaram,2020-12-01T15:29:01Z,"this looks odd, do we really need these to index into arrays?",-1,0.9547027349472046
533502417,9485,rajinisivaram,2020-12-01T15:29:33Z,why do we create arraylist(arrays.aslist)?,0,0.990541398525238
533503119,9485,rajinisivaram,2020-12-01T15:30:24Z,we could get host address and store in a variable outside the loop.,0,0.9928399324417114
533503166,9485,rajinisivaram,2020-12-01T15:30:27Z,why is this inside the for loop? we could just create one principal and use it inside the loop.,0,0.9910300970077515
533505561,9485,rajinisivaram,2020-12-01T15:33:34Z,an enummap may be neater.,0,0.984801709651947
533510467,9485,rajinisivaram,2020-12-01T15:39:45Z,we should probably move this common code to securityutils and use it both here and in the default implementation.,0,0.9928223490715027
533510477,9485,rajinisivaram,2020-12-01T15:39:46Z,we should probably move this common code to securityutils and use it both here and in the default implementation.,0,0.9928223490715027
533513021,9485,rajinisivaram,2020-12-01T15:42:54Z,"we have lost the resource type for auditing, we should include a resource pattern with empty name or something.",0,0.9638096690177917
533564908,9485,rajinisivaram,2020-12-01T16:49:59Z,"ok, i seem to have forgotten this. why is this code different from the one in the default implementation?",0,0.6482862830162048
533567312,9485,rajinisivaram,2020-12-01T16:53:18Z,we should try to preserve the format for this for compatibility with scripts that parse these logs.,0,0.9897969365119934
533622127,9485,rajinisivaram,2020-12-01T18:15:06Z,do we have a benchmark for updates (not authorize)?,0,0.992154061794281
533623715,9485,rajinisivaram,2020-12-01T18:17:41Z,"if `denyallresource` is true, we can just return denied?",0,0.9934333562850952
533626460,9485,rajinisivaram,2020-12-01T18:21:58Z,looks like a lot of duplicate code here. we should see how to share code for all this. can we move the default implementation into securityutils and share some of the matching implementation across the classes?,0,0.8493049740791321
533630212,9485,rajinisivaram,2020-12-01T18:27:59Z,should this be `&&` since we we only need one?,0,0.9902268648147583
533644589,9485,rajinisivaram,2020-12-01T18:51:24Z,"i wasn't sure what the result shows (not that familiar with the output format, sorry) the useful comparisons would be: 1) for authorizebyresourcetype, what is the performance advantage we get by using this duplicate cache versus just using `aclcache`. 2) what is the impact on updates which hold a lock for maintaining two caches (without the pr vs with this pr) 3) does this pr impact regular authorize() calls? i think the answer is no. in any case, it seems unnecessary to maintain a second cache with all acls. we never use authorizebyresourcetype for anything other than topics, so it seems a waste to store acls for other resource types here. we could just use `super.authorizebyresourcetype` for other types.",-1,0.8847600221633911
533720425,9485,rajinisivaram,2020-12-01T21:04:39Z,this should perhaps be called delegatingauthorizer rather than mockauthorizer since it is not a mock and requires zk.,0,0.9946457147598267
533720971,9485,rajinisivaram,2020-12-01T21:05:42Z,"i am not sure why we would make this change. if we need the change because we have become slower, we need to understand why.",-1,0.5131400227546692
533722349,9485,rajinisivaram,2020-12-01T21:08:29Z,spelling: principal,0,0.9611907601356506
533723836,9485,rajinisivaram,2020-12-01T21:11:24Z,"we probably want to retain the old benchmark as-is and add a different one for `authorizebyresourcetype`. we were testing a common pattern before, but now we seem to be testing a very unlikely scenario. while this may be useful for testing `authorizebyresourcetype`, it is not what we want for regression testing the authorizer.",0,0.9857651591300964
533724379,9485,rajinisivaram,2020-12-01T21:12:21Z,spelling: principal (multiple places),0,0.9865960478782654
533727081,9485,rajinisivaram,2020-12-01T21:17:34Z,can we move testing of `interfacedefaultauthorizer.authorizer` into another class? this is `aclauthorizertest` and testing of `interfacedefaultauthorizer` seems unrelated to this test.,0,0.9945656061172485
533737220,9485,ctan888,2020-12-01T21:37:01Z,right. delegatingauthorizer is more reasonable as a design pattern naming here.,0,0.9889370203018188
533765909,9485,ctan888,2020-12-01T22:32:01Z,"the underlying algorithm of authorizebyresourcetype() implementation in aclauthorizer has several characteristics: 1. if any ""allow resource"" of the given ace does not have a dominant ""deny resource"", the api will return immediately 2. the complexity is o(n*m) where `n` is the number of ""allow resources"" of the given ace, 'm' is the number of ""deny resources"" of the given ace, but not related to the number of ""ace"" in the cluster. $1 means that, given an ace, suppose `p%` of its ""allow resource"" does not have a dominant ""deny resource"", if `resourcecount` is `r`, on average, after checking `r * p * 0.01` ""allow resources"", the api will return. a) if we are let the ""dominant deny resource"" distribute evenly, like use the (loop index % something) to determine which ""allow resource"" should have a dominant ""deny resource"", we end up iterating the same amount of the ""allow resource"" and returning from the api call every time, which is `r*p*0.01` b) if we are determine which ""allow resource"" should have a dominant ""deny resource"", the result will be too noisy. we may iterate only 1 resource or iterate all resources based on the randomize algorithm and seed. $2 means that, the api time cost is not related to the number of ""ace"" but is hyperbolically increasing when `resourcecount` is increasing. under the assumption in (1), the actual complexity would be (r * r * p * 0.01) as a result, we should get an insight into how long does the worst case takes, as `t`. then we can estimate some reasonable values of `p` and then estimate the api cost by `t * p`. so i was directly testing the worst case, where p = 1, which means 100% of the ""allow resource"" will have a dominant ""deny resource. the complexity hence would be (r^2). it's rare that a cluster can have 200k ""allow resources"" and 200k corresponding ""dominant deny resources"" for each user, and it's not fair to have a relatively smaller `aclcount` and huger `resourcecount`, as the api is optimizing the performance by indexing on `ace`.",0,0.9927154183387756
533915036,9485,ctan888,2020-12-02T05:57:25Z,enummap make sense. commit 1a139ce744a279e4424188008ee5158186b0fcbe,0,0.9912748336791992
533915142,9485,ctan888,2020-12-02T05:57:49Z,yeah. took out. commit 1a139ce744a279e4424188008ee5158186b0fcbe,0,0.9710185527801514
533915261,9485,ctan888,2020-12-02T05:58:12Z,enummap make sense. commit 1a139ce744a279e4424188008ee5158186b0fcbe,0,0.9912748336791992
533915275,9485,ctan888,2020-12-02T05:58:15Z,enummap make sense. commit 1a139ce744a279e4424188008ee5158186b0fcbe,0,0.9912748336791992
533916889,9485,ctan888,2020-12-02T06:03:33Z,right. just as what we've done to principle. commit 29ac8628089ddf1210072bbf52e01a41e123a718,0,0.973980188369751
533919425,9485,ctan888,2020-12-02T06:10:11Z,commit f6d2a39706998160ebe77a854b8bf64268eec68a,0,0.9648637175559998
533922526,9485,ctan888,2020-12-02T06:19:38Z,commit 6ab95d3668b3de27a7f6f58fc171a1e2e8925f69,0,0.9779214262962341
533922580,9485,ctan888,2020-12-02T06:19:47Z,commit 6ab95d3668b3de27a7f6f58fc171a1e2e8925f69,0,0.9779214262962341
534447773,9485,ctan888,2020-12-02T20:05:42Z,"use ""none"" for the pattern name and ""unknown` for the pattern type commit cebbbd47a8e7d318e327e3a279072c718b535abd",0,0.9948478937149048
534447894,9485,ctan888,2020-12-02T20:05:57Z,leave the message as it is now. commit cebbbd47a8e7d318e327e3a279072c718b535abd,0,0.994594156742096
534477631,9485,ctan888,2020-12-02T20:59:42Z,"i just realized that, in order to check the dominant denies, my aclauthorizer implementation is calling `string::startwith` which also has an o(d) complexity where `d` is the length of the ""deny pattern"" string of the given acl. so the complexity would be o(n * m * d). so given all ""allow pattern"" and ""deny pattern"" of a given ace, we have 2 algorithms now 1. iterate through all the prefixes of the `allow pattern` string and check if any prefix is contained in the set of `deny pattern`, which has a complexity of o(n * a), where `a` is the length of the ""allow pattern"" string. my interface default is using this approach. 2. iterate through all the ""deny patterns"", which has a complexity of o(n * m * d), where d is the length of the `deny pattern` string. my aclauthorizer is using this approach. comparasion: since the average of the `allow pattern` string length should be close to that of the `deny pattern`, we can say `a = d`. so o(n * a) = o(n * d) > o(n * m * d), which means approach 1 is much better. conclusion: i'll change aclauthorizer to use approach 1.",0,0.986727774143219
534589923,9485,ctan888,2020-12-03T01:07:31Z,right. just as what aclauthorizer does. commit 18c5c04ad4d8c98dc3cdaa6d15bf70b9991a6b88,0,0.9851441383361816
534751595,9485,ctan888,2020-12-03T06:51:40Z,"yeah, moved to securityutils. commit 30899c45ac50b70625baa2e5f12f58cfe9d79404",0,0.9916995763778687
534755163,9485,ctan888,2020-12-03T06:53:59Z,"now the only difference is that the aclauthorizer is indexing on ace, so the number of ace won't impact the query efficiency.",0,0.9890413880348206
534763817,9485,ctan888,2020-12-03T06:59:40Z,"i think adding some dominant denies won't change the performance pattern of aclauthorizer::acls and aclauthorizer::authorize. 1. aclauthorizer::acls just return all the matching acls by the filter rule. the portion btw ""allow"" and ""deny"" resources doesn't matter. 2. aclauthorizer::authorize will iterate the and filter out the allow and deny aces respectively. since it's using resourcepattern as its indexing method, the portion btw ""allow"" and ""deny"" resources doesn't matter as well.",0,0.9908496141433716
534983615,9485,ctan888,2020-12-03T09:12:16Z,"move the interface default test to a new class. also, created a util class for code sharing. commit 6c550fd04a0c1912e669bf18d60dee27dd03e53c",0,0.9937891364097595
536305219,9485,ctan888,2020-12-04T18:46:54Z,commit 7af4a7ff7ed2dddc06cf11ab7ff2d4b9fee5fb56,0,0.9776257872581482
537657552,9485,ctan888,2020-12-07T16:46:03Z,good catch commit 031c2f41e6611df3d18ef9b709c7d98c91b93326,1,0.9286508560180664
537667755,9485,ctan888,2020-12-07T16:58:58Z,please see below,0,0.9777863621711731
538522173,9485,lbradstreet,2020-12-08T15:49:08Z,"nit, unnecessary whitespace in `i++`.",-1,0.8068413138389587
538524117,9485,lbradstreet,2020-12-08T15:50:45Z,i think it's useful to understand how the cache performs at smaller sizes as well as larger sizes. is there a reason we went with a fixed size and fixed number of resources now?,0,0.9854553937911987
538528015,9485,lbradstreet,2020-12-08T15:54:15Z,it might be better for the purpose of this microbenchmark to setup the cache with the desired size ahead of the time and then measure the time to update the cache with one entry. otherwise you risk measuring a lot of the setup costs rather than the cost of the typical usage.,0,0.9904972314834595
538553851,9485,lbradstreet,2020-12-08T16:16:33Z,"if you take an async profile of this benchmark method you end up spending most of the time in building the entries and immutable set, and barely any time on `aclauthorizer#updatecache`.",0,0.9887937903404236
538613769,9485,ctan888,2020-12-08T17:09:18Z,"oh, i'm just demonstrating the chart 3 i uploaded. i'll change them back.",0,0.8946086168289185
538618149,9485,ctan888,2020-12-08T17:13:15Z,"do you think we'll keep this `testupdatecache` and merge it into trunk? if so, let's setup the cache ahead of time. but i think this benchmark is mainly for comparing the trunk with my branch, which means that we probably won't merge this `testupdatecache` into master, which also means the same procedure constructing some memory records are acceptable since we are taking the time cost difference.",0,0.9858178496360779
538618817,9485,ctan888,2020-12-08T17:13:55Z,yeah. agree. let's see what think about the above discussion,0,0.9128519296646118
538768554,9485,ctan888,2020-12-08T20:04:09Z,thanks. fixed.,1,0.9529776573181152
539594382,9485,rajinisivaram,2020-12-09T19:42:17Z,"this package is part of the public api, but the class looks like it should be internal?",0,0.9905059933662415
539595584,9485,rajinisivaram,2020-12-09T19:44:19Z,perhaps resourceaclentry or something along those lines would be better than `resourceindex` since this class has no notion of index.,0,0.9946445226669312
539599430,9485,rajinisivaram,2020-12-09T19:50:25Z,can we remove the todo comments?,0,0.9930223822593689
539602809,9485,rajinisivaram,2020-12-09T19:55:39Z,"in the typical case, we have a large number of `allowliterals` and `allowprefixes`, no `denyliterals` or `denprefixes`. i think it would make sense to special case `denyliterals.isempty && denyprefixes.isempty`. in this case, we don't need to find all matching resources, we just need to check that there is at least one matching resource.",0,0.9934329986572266
539604360,9485,rajinisivaram,2020-12-09T19:58:05Z,why can't this be a `set` instead of `list of sets`?,0,0.9924679398536682
539604845,9485,rajinisivaram,2020-12-09T19:58:51Z,`aclentry.wildcardprincipalstring`,0,0.9939092397689819
539607223,9485,rajinisivaram,2020-12-09T20:02:33Z,this method can be in securityutils and shared with the default authorizer?,0,0.9955071210861206
539607563,9485,rajinisivaram,2020-12-09T20:03:07Z,private def?,0,0.986415684223175
539612536,9485,rajinisivaram,2020-12-09T20:11:00Z,"we cannot do this here. `authorizerwrapper` is used to wrap any custom authorizer using the old authorizer api. `alloweveryoneifnoaclisfoundprop` is a custom config of `simpleaclauthorizer` and `aclauthorizer`, we cannot use that with any custom authorizer. we should find a way to support the config for simpleaclauthorizer that doesn't impact other custom authorizers.",0,0.9902520179748535
539614719,9485,rajinisivaram,2020-12-09T20:14:37Z,does this work with an acl with wildcard host?,0,0.9943976402282715
539614739,9485,rajinisivaram,2020-12-09T20:14:38Z,does this work with an acl with wildcard host?,0,0.9943976402282715
539615189,9485,rajinisivaram,2020-12-09T20:15:25Z,"the main logic of this could potentially be moved to securityutils since the default authorizer implementation, aclauthorizer and the wrapper all do this.",0,0.9946786165237427
539630084,9485,rajinisivaram,2020-12-09T20:37:40Z,why do we need this in teardown?,0,0.9844093918800354
539631425,9485,rajinisivaram,2020-12-09T20:40:04Z,a lot of these changes look unnecessary,-1,0.5743902921676636
539632426,9485,rajinisivaram,2020-12-09T20:41:50Z,looks like this hasn't been reverted?,0,0.9826813340187073
539632653,9485,rajinisivaram,2020-12-09T20:42:14Z,revert?,0,0.9784512519836426
539634789,9485,rajinisivaram,2020-12-09T20:45:38Z,why? this no longer reflects the comment above. can we revert?,0,0.937495768070221
539635426,9485,rajinisivaram,2020-12-09T20:46:42Z,we should revert changes to existing benchmark because it hard to tell why these changes were made and what impact it has on the original benchmark.,0,0.9809931516647339
539638872,9485,rajinisivaram,2020-12-09T20:52:14Z,it makes sense to merge the benchmarks to trunk. let's make sure it measures just updatecache.,0,0.9911661744117737
539730884,9485,ctan888,2020-12-09T23:41:08Z,shall we make the class constructor package-private or make this class an inner class of aclauthorizer?,0,0.9948945045471191
539734315,9485,ctan888,2020-12-09T23:47:14Z,i used index as it's used as the index of the hashmap. what about something like `resourcenamefilter`?,0,0.9937082529067993
539734983,9485,ctan888,2020-12-09T23:48:51Z,yeah. removed.,0,0.9569175243377686
539736828,9485,ctan888,2020-12-09T23:53:14Z,yes. commit 2fd4babe2c27ee0723fa1cd720ca35d2bbefe57b,0,0.9803627133369446
539737110,9485,ctan888,2020-12-09T23:53:55Z,commit 2fd4babe2c27ee0723fa1cd720ca35d2bbefe57b,0,0.9707683324813843
539737287,9485,ctan888,2020-12-09T23:54:20Z,sure,0,0.9137381911277771
539751258,9485,ctan888,2020-12-10T00:28:50Z,yes. commit 1dc143fc78a3b9927189751255346ef0b6cafd90 if (nodeny) { ..if (hasallow) { ....return authorize.allowed ..} else { ....return authorize.denied // since no allow exists ..} },0,0.9870462417602539
539782093,9485,ctan888,2020-12-10T01:50:16Z,because we don't wanna reconstruct a new large set containing all the matching resources. we are constructing a list of ~ 3 * 3 * 3 elements which refer to existing hashsets maintained by `updatecache`.,0,0.9764664173126221
539787542,9485,ctan888,2020-12-10T02:03:20Z,i was trying to share it but it seems like the different collection type btw java and scala is a headache. we'll then need some java converters or instantiate a java collection in the scala code. do you think it deserves this?,-1,0.9129014015197754
540418386,9485,ctan888,2020-12-10T18:56:44Z,"given that we probably don't want to change the deprecated authorizer interface, i can only think of one way to achieve this: besides checking if the `alloweveryoneifnoaclisfoundprop` exists and if it equals to `true`, i added another check to authorize on a hardcoded session, operation, and resource. since configure() will be called immediately after the authorizer instantiation, it's guaranteed that no acls would exist when we do this check. override def configure(configs: util.map[string, _]): unit = { ..baseauthorizer.configure(configs) ....shouldalloweveryoneifnoaclisfound = (configs.asscala.get( ......aclauthorizer.alloweveryoneifnoaclisfoundprop).exists(_.tostring.toboolean) ........&& baseauthorizer.authorize( ..........new session(kafkaprincipal.anonymous, inetaddress.getbyname(""1.2.3.4"")), ............read, new resource(topic, ""hi"", patterntype.literal))) } commit 2ed79a0a7788f8841475badfd1c26adf0eb3435c",0,0.9921585321426392
540655651,9485,ctan888,2020-12-11T03:03:41Z,"good catch. commit 8263bd319f63d39808f90129db55427b98385dd4 since it's a bit hard to test `allowanyoneifnoaclfound` and many other logics in the integration test, i added a new test class `authorizerwrappertest`.",1,0.8208502531051636
540658692,9485,ctan888,2020-12-11T03:13:10Z,commit 8263bd3 changed the authorizerwrapper logic and optimized the performance a bit. now authorizerwrapper#denyallresource will 1. only use authorizer#acls() to filter out the `wildcardresource` with the pattern type `literal`. 2. check if any of the filtered out bindings match the `request principle` and `request host`. so it's behavior diverges more from the interface default now.,0,0.9949465394020081
540705023,9485,ctan888,2020-12-11T05:43:38Z,"otherwise ""deny all"" will remain in zk during the whole test process since zk won't be restarted or re-instantiated.",0,0.962245523929596
540706117,9485,ctan888,2020-12-11T05:46:49Z,"since `authorizerinterfacedefaulttest`, `aclauthorizertest`, and `authorizerwrappertest` are sharing some test utils, we need to make this method signature abstract a bit, in order to make it usable by authorizertestfactory.",0,0.9939287900924683
541202572,9485,ctan888,2020-12-11T19:35:27Z,yeah. i was doing resourcename = resourcename + 95 to re-use this variable. we can revert it.,0,0.9899559020996094
541206048,9485,ctan888,2020-12-11T19:38:55Z,yes.,0,0.9818659424781799
541206648,9485,ctan888,2020-12-11T19:39:31Z,yes,0,0.9659429788589478
541212190,9485,ctan888,2020-12-11T19:45:19Z,"the existing benchmark does not have any deny resource in it. adding some deny bindings whose percentage is controlled by parameters will be an improvement to the existing benchmark and help us understand the performance better. i've reverted all changes other than adding some deny bindings. also, i moved those memory intense operations into the phase so now the benchmark just measures updatecache(). does the benchmark look good to you now? commit 6536cea788210860a764f3f0a6901244e8d974fe",0,0.9416503310203552
541779975,9485,ctan888,2020-12-12T21:02:27Z,reverted other test changes commit 4f9b79a810c4da3030fe262d4bfdc97df4945e8c,0,0.9891720414161682
542039322,9485,ctan888,2020-12-14T00:14:52Z,"benchmark result: [a link] performance pattern doesn't change, except `testupdatecache` runs much faster now.",0,0.9858434796333313
542790510,9485,rajinisivaram,2020-12-14T21:10:16Z,"we have to move the class outside of the public package, so putting it alongside aclauthorizer makes sense.",0,0.9941691160202026
542830098,9485,rajinisivaram,2020-12-14T21:47:04Z,"since this is the javadoc of a public api, we should move the details on how the default implementation works outside of the javadoc. we can move this list of comments inside the method.",0,0.9922160506248474
542851551,9485,rajinisivaram,2020-12-14T22:07:06Z,"we don't currently have anything in the default implementation to support super.users right? unlike `allow.everyone.if.no.acl.found` which is not particularly suitable for production use, `super.users` is a commonly used config that is likely to be in use in a lot of deployments. the simplest fix may be to `authorize()` with a hard-coded name and return allowed if `authorize()` returns allowed before any of the logic below is executed.",0,0.9904530048370361
542854629,9485,rajinisivaram,2020-12-14T22:09:57Z,this needs to be an immutable map or a concurrenthashmap since we read this without lock.,0,0.9933195114135742
542855316,9485,rajinisivaram,2020-12-14T22:10:36Z,we need to check if the principal is a super.user and return allowed for super users before executing any of the logic below.,0,0.9912657141685486
542860969,9485,rajinisivaram,2020-12-14T22:16:10Z,"ok, makes sense",0,0.8243910670280457
542861839,9485,rajinisivaram,2020-12-14T22:16:57Z,"ok, let's leave as is.",0,0.9854375123977661
542871579,9485,rajinisivaram,2020-12-14T22:26:24Z,"this is too hacky. and it breaks if anonymous has all access (e.g. because inter-broker listener alone uses plaintext). we could check `baseauthorizer.isinstanceof[simpleaclauthorizer]` perhaps. it is not perfect since it would break if there was a custom authorizer that extended simpleaclauthorizer, but doesn't support alloweveryoneifnoaclisfoundprop and the prop was set to true. but that seems like an unlikely scenario.",-1,0.9016407132148743
542879143,9485,rajinisivaram,2020-12-14T22:33:41Z,this sequence doesn't work with super.users. we probably should do something like: [code block],0,0.9791064262390137
542881770,9485,rajinisivaram,2020-12-14T22:36:27Z,we could have done principal.tostring() once in the caller rather than convert everytime.,0,0.9924001693725586
542884517,9485,rajinisivaram,2020-12-14T22:39:08Z,zk is reinstantiated for every test.,0,0.9813970327377319
542887409,9485,rajinisivaram,2020-12-14T22:41:58Z,"as in the other class, we don't need this in teardown",0,0.9923627376556396
542888614,9485,rajinisivaram,2020-12-14T22:43:13Z,we should add tests for super users.,0,0.9902854561805725
542890465,9485,rajinisivaram,2020-12-14T22:45:10Z,why are we storing these?,0,0.9558109641075134
542892942,9485,rajinisivaram,2020-12-14T22:47:34Z,why?,0,0.8699262738227844
542893393,9485,rajinisivaram,2020-12-14T22:48:00Z,why was this changed from aclauthorizer to authorizer?,0,0.9926778078079224
542893665,9485,rajinisivaram,2020-12-14T22:48:15Z,why are we storing this?,0,0.9416288733482361
542900213,9485,rajinisivaram,2020-12-14T22:54:40Z,it would be better to move this inside authorizerinterfacedefaulttest since it is specific to that test.,0,0.9946396946907043
542906008,9485,rajinisivaram,2020-12-14T23:00:35Z,"for map, you would say `key` rather than `index`. but this is not a `resource` or `resourcename` - it has no resource name, it is not a filter, but it includes accesscontrolentry. maybe just resourcetypekey is sufficient, but you could also include something to indicate it includes the accesscontrolentry if you want. either way, putting it along with aclauthorizer would make naming less critical.",0,0.9938281178474426
543080612,9485,ctan888,2020-12-15T06:30:16Z,sure. commit 25e0bfcc97f956ceb4254ab8c457fe5d8d250e82,0,0.985629141330719
543093393,9485,ctan888,2020-12-15T07:00:05Z,"so we have three approaches here: 1. use .getclass 2. use .isinstanceof 3. only configure the property with the key ""aclauthorizer.alloweveryoneifnoaclisfoundprop"" in the authorizerwrapper instance construction so no other property will get in. neither of them is perfect but approach 2 also seems better to me. commit 1217394c0c3767ac11df958c02a681c8cbc8382b",0,0.978929340839386
543099934,9485,ctan888,2020-12-15T07:14:00Z,yeah. i was trying to restrict the type in order to remind people to construct a kafkaprinciple first. but tostring() is an expensive operation. commit 16576f85a858648cfc4ff882b554ddc65922021c,0,0.8131139278411865
543114091,9485,ctan888,2020-12-15T07:41:41Z,"i replied here. maybe i shouldn't have resolved it. [a link] since authorizerinterfacedefaulttest, aclauthorizertest, and authorizerwrappertest are sharing some test cases, we need to make this method signature abstract a bit, in order to pass the method reference to authorizertestfactory.",0,0.9855678081512451
543116084,9485,ctan888,2020-12-15T07:45:14Z,"for this method, i changed the signature back to aclauthorzier as the authorizertestfactory is not depending on it.",0,0.9915832877159119
543117875,9485,ctan888,2020-12-15T07:48:38Z,removed as we are not removing acls in teaddown() anymore. commit 825a8ba77ad1766f998a71a9a15f21e73daad84a,0,0.9949848651885986
543117908,9485,ctan888,2020-12-15T07:48:42Z,commit 825a8ba77ad1766f998a71a9a15f21e73daad84a,0,0.972724199295044
543117954,9485,ctan888,2020-12-15T07:48:48Z,commit 825a8ba77ad1766f998a71a9a15f21e73daad84a,0,0.972724199295044
543118616,9485,ctan888,2020-12-15T07:49:54Z,removed as we are not removing acls in teaddown() anymore. commit 825a8ba,0,0.9951011538505554
543120808,9485,ctan888,2020-12-15T07:53:47Z,make sense. commit e31f157eaac1213445dd284fd2209a29f4fa18fd,0,0.984784722328186
543134773,9485,ctan888,2020-12-15T08:18:45Z,"would scala ""foreach"" throw any exception when read operation races with write in hashmap / hashset? if not, i think we can tolerate some read inconsistency as zk is also broadcasting the acl changes asynchronously to brokers.",0,0.9884677529335022
543174139,9485,ctan888,2020-12-15T09:18:00Z,"i tested a bit, using 1 bg thread adding and removing elements to a mutable.hashset while the main thread constantly iterating the hashset using ""foreach"". the ""foreach"" call doesn't throw any exception. but i'm a bit unsure what would happen if the iteration hits a bucket where some elements are being added to or deleted from. let me test what's the overhead using the immutable map. i'd prefer this approach as we're expecting much more read than write to the hashset.",0,0.9104691743850708
543744087,9485,ctan888,2020-12-15T22:49:36Z,good catch. this is super important. commit dae1a788b70ebc03eab265b1027a4b43ad8e773b,1,0.9916754961013794
543744182,9485,ctan888,2020-12-15T22:49:47Z,good catch. this is super important. commit dae1a788b70ebc03eab265b1027a4b43ad8e773b,1,0.9916754961013794
543745352,9485,ctan888,2020-12-15T22:52:00Z,"test added for authorizerinterfacedefaulttest, aclauthorizertest, authorizerwrappertest. commit dae1a788b70ebc03eab265b1027a4b43ad8e773b",0,0.9946466088294983
543805858,9485,ctan888,2020-12-16T01:18:49Z,"use immutable collections: benchmark (aclcount) (denypercentage) (resourcecount) mode cnt score error units aclauthorizerbenchmark.testaclsiterator 50 100 200000 avgt 5 4132.824  2967.122 ms/op aclauthorizerbenchmark.testauthorizebyresourcetype 50 100 200000 avgt 5 46.733  5.397 ms/op aclauthorizerbenchmark.testauthorizer 50 100 200000 avgt 5 6.844  0.915 ms/op aclauthorizerbenchmark.testupdatecache 50 100 200000 avgt 5 7219.696  4018.189 ms/op jmh benchmarks done use mutable collections: aclauthorizerbenchmark.testupdatecache 50 100 200000 avgt 5 4927.832  2570.786 ms/op when aclcount = 50, denypercentage = 100, resourcecount = 200000, the time cost is 2.3 seconds more with immutable collections. but since adding 50 * 20000 acl bindings only takes ~7 seconds, i think the performance should be acceptable.",0,0.993451714515686
543813486,9485,ctan888,2020-12-16T01:39:14Z,removed.,0,0.9782117605209351
543814295,9485,ctan888,2020-12-16T01:41:28Z,resourcetypekey sounds good: commit 7fe92c6436432760adf9465c3f0bcf3c91104b10,0,0.8749487400054932
543814563,9485,ctan888,2020-12-16T01:42:04Z,make resourcetypekey an inner class of aclauthorizer commit 7fe92c6436432760adf9465c3f0bcf3c91104b10,0,0.9915750622749329
543814681,9485,ctan888,2020-12-16T01:42:19Z,good catch. this is super important. commit dae1a78,1,0.9942790269851685
543817949,9485,ctan888,2020-12-16T01:51:12Z,commit 62c44ade550a90671ff41bfb847e2bc28adc7baa,0,0.9658219814300537
544223127,9485,rajinisivaram,2020-12-16T11:29:11Z,use `op` rather than read since that fits with why we are allowing access. we also need a test that verifies that permission to read everything doesn't imply `authorizebyresourcetype` for write.,0,0.9940407872200012
544223630,9485,rajinisivaram,2020-12-16T11:29:58Z,use `logifallowed=true` since we are granting access in that case.,0,0.9938429594039917
544229673,9485,rajinisivaram,2020-12-16T11:40:14Z,can we used named arguments for the booleans: `authorized = false` - we should update all usages of `logauditmessage` below.,0,0.995804488658905
544232558,9485,rajinisivaram,2020-12-16T11:44:53Z,"we should make this a `case class`. we can then remove all the methods (equals, hashcode and tostring) since we get those for free.",0,0.9906664490699768
544239742,9485,rajinisivaram,2020-12-16T11:56:47Z,"not a `custom` principal, just a `principal`.",0,0.989109992980957
544239749,9485,rajinisivaram,2020-12-16T11:56:48Z,"not a `custom` principal, just a `principal`.",0,0.989109992980957
544240156,9485,rajinisivaram,2020-12-16T11:57:27Z,all these tests are using `read` which happens to work for the default implementation since we used read there.,0,0.9944161176681519
544244813,9485,rajinisivaram,2020-12-16T12:05:14Z,can we check how much work it would be to convert `authorizertestfactory` into an `abstract baseauthorizertest` class that the three xxxauthorizertest classes extend? having to repeat these tests in all three places makes it too easy to miss one in the future.,0,0.9770324230194092
544246252,9485,rajinisivaram,2020-12-16T12:07:37Z,nit: principle => principal,0,0.9774878025054932
544545938,9485,ctan888,2020-12-16T18:57:59Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9686306715011597
544545948,9485,ctan888,2020-12-16T18:58:00Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9686306715011597
544545971,9485,ctan888,2020-12-16T18:58:04Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9686306715011597
544546002,9485,ctan888,2020-12-16T18:58:07Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9686306715011597
544546101,9485,ctan888,2020-12-16T18:58:15Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9686306715011597
544546172,9485,ctan888,2020-12-16T18:58:22Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9686306715011597
544546946,9485,ctan888,2020-12-16T18:59:31Z,"yeah. since i've changed `read` to `op`, this has been resolved.",0,0.9637218713760376
544547081,9485,ctan888,2020-12-16T18:59:40Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9686306715011597
544713670,9485,ctan888,2020-12-17T00:09:14Z,"commit 092fec70a9547ec07cba999e77be1c0cf79fa275 commit e5e3d18f57ab22df20133f9841905af384d9b641 these two commits are condensing the class methods and members into the baseauthorizertest. in baseauthorizertest, the only abstract method is an authorizer provider. after overriding the provider, those test cases in it are sufficient to run. now the test code looks much cleaner. if the changes look too much to you, we can revert 092fec70a9547ec07cba999e77be1c0cf79fa275 and move the head to e5e3d18f57ab22df20133f9841905af384d9b641",0,0.9766666293144226
545246428,9485,rajinisivaram,2020-12-17T16:56:46Z,`resourceindex` => `resourcetypekey` and omit `new`.,0,0.9932880997657776
545247397,9485,rajinisivaram,2020-12-17T16:58:03Z,couldn't we just check:`resourcecache.contains(resourcekey)` ?,0,0.9933769106864929
545261128,9485,rajinisivaram,2020-12-17T17:17:49Z,"`resourceindex` => `resourcetypekey`, also we can omit new for resourcetypekey since it is a case class.",0,0.9953950047492981
545264795,9485,rajinisivaram,2020-12-17T17:23:02Z,`private def`,0,0.9891440272331238
545264898,9485,rajinisivaram,2020-12-17T17:23:10Z,`private def`,0,0.9891440272331238
545267737,9485,rajinisivaram,2020-12-17T17:27:13Z,we can use `map` instead of `match`: [code block],0,0.9932326078414917
545270222,9485,rajinisivaram,2020-12-17T17:30:45Z,"`resourceindex` => `resourcetypekey`, omit `new`",0,0.9932605624198914
545270292,9485,rajinisivaram,2020-12-17T17:30:53Z,"`resourceindex` => `resourcetypekey`, omit `new`",0,0.9932605624198914
545273561,9485,rajinisivaram,2020-12-17T17:35:05Z,`candenyall` => `denyall` since `can` doesn't fit with `deny`,0,0.994436502456665
545280654,9485,rajinisivaram,2020-12-17T17:45:19Z,"suggestions to improve this (feel free to ignore/update): ``` custom authorizer implementations should consider overriding this default implementation because: 1) the default implementation iterates all aclbindings multiple times, without any caching for resource types. more efficient implementations may be added in custom authorizers that directly access cached entries. 2) the default implementation cannot integrate with any audit logging included in the authorizer implementation. 3) the default implementation does not support any custom authorizer configs or other access rules apart from acls.",0,0.9932282567024231
545282374,9485,rajinisivaram,2020-12-17T17:47:45Z,add a comment to say that we check for one hard-coded name to ensure that super users are granted access regardless of deny acls.,0,0.9921278953552246
545287419,9485,rajinisivaram,2020-12-17T17:55:22Z,can we make this comment two lines instead of 4 since each sentence seems short enough to fit into a line?,0,0.9930511713027954
545325909,9485,rajinisivaram,2020-12-17T18:53:16Z,"`patterntype.unknown` looks odd in audit logs, `any` may be better.",0,0.979638934135437
545363933,9485,rajinisivaram,2020-12-17T19:55:50Z,the nested for loop can be replaced with: [code block],0,0.9925306439399719
545365855,9485,rajinisivaram,2020-12-17T19:58:45Z,we can make this a `val` by using an arraybuffer instead of list that we keep recreating,0,0.9918400049209595
545366101,9485,rajinisivaram,2020-12-17T19:59:08Z,"as before, we can use a single for loop instead of nested loop",0,0.9921014904975891
545367497,9485,rajinisivaram,2020-12-17T20:01:27Z,can use `denyliterals.exists(_.contains(resourcepattern.wildcard_resource))`,0,0.9943825006484985
545368045,9485,rajinisivaram,2020-12-17T20:02:13Z,"can use `allowprefixes.exists(_.exists`, similarly for `allowliterals`.",0,0.9927394986152649
545368198,9485,rajinisivaram,2020-12-17T20:02:31Z,nit: space before {,0,0.8546809554100037
545369571,9485,rajinisivaram,2020-12-17T20:04:55Z,can be `!denyliterals.exists(_.contains(literalname))`?,0,0.9933116436004639
545399101,9485,rajinisivaram,2020-12-17T20:57:59Z,we should use the same pattern as the usage of `aclcache` where we get a `aclcachesnapshot` at the start of the method and then use the same snapshot throughout the method rather than use a changing value of resourcecache within the loop.,0,0.9945712685585022
545410322,9485,rajinisivaram,2020-12-17T21:19:25Z,could just close `interfacedefaultauthorizer` instead of creating an `authorizers` collection?,0,0.9951836466789246
545411361,9485,rajinisivaram,2020-12-17T21:21:34Z,the `authorizer` parameter is not used. can't we just move this into the test method `testauthorizebyresourcetypenoaclfoundoverride` above?,0,0.9958204030990601
545411829,9485,rajinisivaram,2020-12-17T21:22:24Z,can't this be `aclauthorizer`?,0,0.9934884309768677
545412639,9485,rajinisivaram,2020-12-17T21:24:09Z,"there is only one authorizer, we could just use it directly instead of creating a seq",0,0.9916096329689026
545413800,9485,rajinisivaram,2020-12-17T21:26:29Z,"looks like there is opportunity to move some of this stuff into baseauthorizertest, but we can do that in a follow-up later.",0,0.9917126893997192
545471749,9485,ctan888,2020-12-17T23:26:46Z,[code block] i think the resourcepattern constructor is preventing us passing patterntype.any. it's only usable with filter.,0,0.9902966618537903
545525163,9485,ctan888,2020-12-18T02:04:45Z,right. to prevent the phantom problem.,0,0.6919018030166626
545527187,9485,ctan888,2020-12-18T02:11:19Z,"i think that the zookeeperclient has a different metric group name. i'm not sure how the name will be used though. and yes, we can do that in a follow-up pr later.",0,0.926732063293457
545529131,9485,ctan888,2020-12-18T02:17:51Z,commit b6a766b228034a442e3a6e8b71ecee78eefdbfd3,0,0.9724216461181641
545529436,9485,ctan888,2020-12-18T02:18:49Z,commit b6a766b,0,0.9735074043273926
545529534,9485,ctan888,2020-12-18T02:19:03Z,commit b6a766b,0,0.9735074043273926
545531049,9485,ctan888,2020-12-18T02:24:18Z,commit b6a766b,0,0.9735074043273926
545531079,9485,ctan888,2020-12-18T02:24:22Z,commit b6a766b,0,0.9735074043273926
545576162,9485,ctan888,2020-12-18T05:09:08Z,commit b6a766b,0,0.9735074043273926
545576394,9485,ctan888,2020-12-18T05:10:16Z,commit b6a766b,0,0.9735074043273926
545576579,9485,ctan888,2020-12-18T05:11:03Z,commit b6a766b,0,0.9735074043273926
545576700,9485,ctan888,2020-12-18T05:11:32Z,commit b6a766b,0,0.9735074043273926
545576808,9485,ctan888,2020-12-18T05:11:58Z,![a link] commit b6a766b,0,0.9166514873504639
545577772,9485,ctan888,2020-12-18T05:15:41Z,// check a hard-coded name to ensure that super users are granted // access regardless of deny acls.,0,0.9791114926338196
545577832,9485,ctan888,2020-12-18T05:15:56Z,commit b6a766b,0,0.9735074043273926
545577865,9485,ctan888,2020-12-18T05:16:03Z,commit b6a766b,0,0.9735074043273926
545577952,9485,ctan888,2020-12-18T05:16:18Z,commit b6a766b,0,0.9735074043273926
545578070,9485,ctan888,2020-12-18T05:16:49Z,"right, though it's only a list of 8. commit b6a766b",0,0.973370373249054
545578559,9485,ctan888,2020-12-18T05:18:28Z,commit b6a766b,0,0.9735074043273926
545578734,9485,ctan888,2020-12-18T05:18:58Z,yes. didn't realize the existence of this syntax be4. thanks. commit b6a766b,1,0.9718918204307556
545579837,9485,ctan888,2020-12-18T05:23:04Z,commit b6a766b,0,0.9735074043273926
545581171,9485,ctan888,2020-12-18T05:27:40Z,commit b6a766b,0,0.9735074043273926
545584468,9485,ctan888,2020-12-18T05:39:14Z,right. we can bring the ! to the front. commit 9407b1697d976fc6cff90703573a64f7a3c9f348,0,0.9900145530700684
545584783,9485,ctan888,2020-12-18T05:40:19Z,commit b6a766b,0,0.9735074043273926
545584825,9485,ctan888,2020-12-18T05:40:28Z,yes. commit b6a766b,0,0.9759650826454163
545584872,9485,ctan888,2020-12-18T05:40:35Z,yes. commit b6a766b,0,0.9759650826454163
545585037,9485,ctan888,2020-12-18T05:41:19Z,yes. renamed to aclauthorizer. commit b6a766b,0,0.9874758124351501
545585355,9485,ctan888,2020-12-18T05:42:34Z,yes. remove the seq construction and make a single class member call. commit b6a766b,0,0.990100085735321
76054354,1776,ijuma,2016-08-24T13:20:34Z,the scala `enumeration` class has a bunch of problems and we typically use adts. an example is `rackawaremode`.,0,0.9662677645683289
76104237,1776,benstopford,2016-08-24T17:43:14Z,changed - thanks bud.,1,0.9456843733787537
76720190,1776,junrao,2016-08-30T02:00:43Z,delta is no longer valid. typo evalutated,0,0.9570378661155701
76720206,1776,junrao,2016-08-30T02:00:53Z,"is that only used for testing? if so, could we define it under src/test?",0,0.995478093624115
76720217,1776,junrao,2016-08-30T02:01:03Z,do we need this new class? rate.windowsize() is modified this way to address kafka-2443 and kafka-2567. it would be better if all sensors are of the same type of rate.,0,0.9934709072113037
76720224,1776,junrao,2016-08-30T02:01:07Z,kip says using comma separated.,0,0.9864187836647034
76720231,1776,junrao,2016-08-30T02:01:11Z,the kip says it's comma separated.,0,0.9873272776603699
76720243,1776,junrao,2016-08-30T02:01:17Z,"perhaps we can avoid calling split(""-"") twice by doing that once first?",0,0.9931447505950928
76720245,1776,junrao,2016-08-30T02:01:25Z,"to be consistent with the existing naming, perhaps the params can be brokerid and brokerconfig?",0,0.9951687455177307
76720249,1776,junrao,2016-08-30T02:01:26Z,space after if,0,0.9853398203849792
76720258,1776,junrao,2016-08-30T02:01:31Z,shouldn't we do this check before line 127?,0,0.992511510848999
76720265,1776,junrao,2016-08-30T02:01:37Z,it's clearer if we use quota.upperbound(limit) in this and the next line.,0,0.9933385252952576
76720272,1776,junrao,2016-08-30T02:01:41Z,this can be private?,0,0.9890809059143066
76720336,1776,junrao,2016-08-30T02:02:47Z,"does this guarantee that the minbytes requirement is met? for example, suppose that all replicas are throttled and quota is not exceeded at this point. however, when we call forcecomplete(0, we could get fewer bytes than minbytes and return the fetch response prematurely. same question in case c on line 94. if the fetch offset is on an old segment from the last segment, we force a return immediately. however, it could be that the quota is violated and we will return an empty response.",0,0.9902673363685608
76720343,1776,junrao,2016-08-30T02:02:51Z,"to be consistent, should broker be brokers?",0,0.99356609582901
76720349,1776,junrao,2016-08-30T02:02:55Z,no need to change this line?,0,0.9853307008743286
76720356,1776,junrao,2016-08-30T02:03:04Z,this can be private?,0,0.9890809059143066
76720360,1776,junrao,2016-08-30T02:03:07Z,an => a,0,0.8990496397018433
76720364,1776,junrao,2016-08-30T02:03:12Z,could we use the defined name for quota.replication.throttled.replicas?,0,0.9942916631698608
76720369,1776,junrao,2016-08-30T02:03:16Z,missing license header.,0,0.9745213985443115
76720377,1776,junrao,2016-08-30T02:03:19Z,extra space after object,0,0.9864428043365479
76720409,1776,junrao,2016-08-30T02:03:46Z,perhaps noquota is better?,0,0.9781123995780945
76720415,1776,junrao,2016-08-30T02:03:51Z,"for clarity, would it be better to rename leaderreplication and followerreplication to leaderquotamanager and followerquotamanager?",0,0.9949668049812317
76720426,1776,junrao,2016-08-30T02:04:01Z,no need for the package name org.apache.kafka.common.utils. ditto two lines below.,0,0.9879618287086487
76720437,1776,junrao,2016-08-30T02:04:14Z,do we really need fetchresponseprocessingcomplete()? could we just do the logic here in processpartitiondata?,0,0.9952055215835571
76720447,1776,junrao,2016-08-30T02:04:22Z,"is this still needed? if not, it seems that we don't need to expose bound() as a public api in replicationquotamanager.",0,0.9938111901283264
76720504,1776,junrao,2016-08-30T02:05:11Z,"does this need to be info? also, don't need to reference logger. there are a few other places like that.",0,0.9846353530883789
76720509,1776,junrao,2016-08-30T02:05:16Z,typo excedded,0,0.9735924601554871
76720512,1776,junrao,2016-08-30T02:05:21Z,"hmm, shouldn't we pass in fetch.messageset.sizeinbytes to quota.isquotaexceededby()?",0,0.9876298308372498
76720516,1776,junrao,2016-08-30T02:05:27Z,do we have to read from the log again? it seems that we can just set fetch.messageset to an empty bytebuffermessageset.,0,0.991928219795227
76720525,1776,junrao,2016-08-30T02:05:31Z,unused import coreutils,0,0.9772605299949646
76720529,1776,junrao,2016-08-30T02:05:37Z,readonlyquota seems a bit too general. perhaps sth like replicaquota?,0,0.6457161903381348
76720550,1776,junrao,2016-08-30T02:05:41Z,bound() => upperbound() to make it clear?,0,0.9924170970916748
76720605,1776,junrao,2016-08-30T02:06:24Z,"this may not be enough since the sensor can be removed after it's inactive for some time (say, throttled replicas are removed). when that happens, sensor will be pointing to an obsolete object. to be safe, we probably need a getorcreatequotasensors() method like in clientquotamanager.",0,0.9903548955917358
76720612,1776,junrao,2016-08-30T02:06:26Z,could this be a val instead of a method?,0,0.9928152561187744
76720626,1776,junrao,2016-08-30T02:06:32Z,"it seems that this can be private? also, getquota() can be just quota().",0,0.9944032430648804
76720637,1776,junrao,2016-08-30T02:06:41Z,"does this need to be at info? also, not need to use logger. info() is enough.",0,0.9910708665847778
76720651,1776,junrao,2016-08-30T02:06:52Z,"hmm, should bound() return int? with things like infiniband, it actually can be legit to set a quota larger than 2gb/sec.",0,0.9472850561141968
76815241,1776,benstopford,2016-08-30T15:11:18Z,"our standard mechanism won't permit commas in config, hence i proposed this. i did actually change the kip.",0,0.9714404940605164
76815773,1776,benstopford,2016-08-30T15:13:40Z,will change to quota.isquotaexceededby(fetchmetadata.fetchminbytes).,0,0.989790141582489
76816162,1776,benstopford,2016-08-30T15:15:42Z,i'll fix all logging etc when i have something i'm prepared to merge. this is just a first cut remember.,0,0.9635764956474304
76817729,1776,benstopford,2016-08-30T15:22:59Z,yes - that's better.,0,0.8552565574645996
76817871,1776,benstopford,2016-08-30T15:23:42Z,that makes sense. will change. thanks for the heads up.,1,0.9580927491188049
76817957,1776,benstopford,2016-08-30T15:24:08Z,no should be long everywhere. will change.,0,0.8246945142745972
76819932,1776,benstopford,2016-08-30T15:33:39Z,"sorry - deleted previous. as i understand it the fetch, here, is just a single partition's data. thus i'm keeping a running total of throttled bytes in all partitions, checking against the quota to see when the 'proposed' fetch will exceed to. remember isquotaexceededby() doesn't record anything. let me know if i'm missing something.",-1,0.9916248917579651
76946201,1776,ijuma,2016-08-31T08:38:48Z,these should be final and probably exposed via an accessor.,0,0.9915863275527954
76947111,1776,ijuma,2016-08-31T08:44:36Z,"i think ben just meant the `value` parameter to be called `delta`. from an api perspective, it seems like it would make sense to also have a public `checkquota` method if we expose a `checkquotawithdelta`.",0,0.9914109706878662
76948313,1776,ijuma,2016-08-31T08:52:43Z,"not sure i understand, we support multiple items separated by commas in configs via the `list` type.",0,0.9862223267555237
76948517,1776,ijuma,2016-08-31T08:54:18Z,not sure if these formatting changes are intended.,0,0.8723142147064209
76948664,1776,ijuma,2016-08-31T08:55:22Z,nitpick: we don't usually include the type annotation for simple local variables like this.,0,0.9865320324897766
76948830,1776,ijuma,2016-08-31T08:56:22Z,it seems to me that the `partitions.map(_.tostring)` doesn't do anything since the default behaviour is to call `tostring` on each element anyway.,0,0.9923772811889648
76958141,1776,ijuma,2016-08-31T09:55:37Z,"generally in scala, you would write this like: [code block]",0,0.9937236905097961
76958968,1776,ijuma,2016-08-31T10:00:47Z,nitpick: we don't need the `string` type annotation.,0,0.9899237751960754
76959741,1776,ijuma,2016-08-31T10:05:48Z,can we not make a copy of kafkaconfig instead?,0,0.9924941062927246
76959836,1776,ijuma,2016-08-31T10:06:36Z,`unboundedquota` maybe?,0,0.9904680848121643
76960609,1776,ijuma,2016-08-31T10:09:22Z,"given that the containing class is `quotamanagers`, it seems like it may be ok to not repeat `quotamanager` for each field. if we do rename it as per jun's suggestion, then we probably should rename `client` too.",0,0.9929346442222595
76961281,1776,ijuma,2016-08-31T10:14:22Z,"this class seems a bit inconsistent in that it groups the client replication types in a map, but not the replication ones. it seems like it might be better to either have them all as fields or all in maps. is there a reason to do it this way instead?",0,0.9373731017112732
76961490,1776,ijuma,2016-08-31T10:16:00Z,it would be nice if a `time` instance was passed instead of hardcoding `systemtime` here.,0,0.9916364550590515
76962421,1776,ijuma,2016-08-31T10:23:20Z,there should be no `unit.` here.,0,0.9912413358688354
76964270,1776,ijuma,2016-08-31T10:37:15Z,nitpick: methods should start with lowercase letter.,0,0.9911335110664368
77510050,1776,benstopford,2016-09-05T11:45:24Z,renamed value->delta. added an (unused) method: public void checkquotas(),0,0.9948281645774841
77542394,1776,benstopford,2016-09-05T16:27:23Z,dynamic configs don't support commas. i've added a task to look at changing this.,0,0.9393571615219116
77543779,1776,benstopford,2016-09-05T16:44:59Z,thanks,0,0.5400217771530151
77544027,1776,ijuma,2016-09-05T16:49:06Z,"they should do, see `cleanup.policy` for an example. there's a test in `logcleanerintegrationtest.testcleanscombinedcompactanddeletetopic` that verifies this.",0,0.9956316947937012
77544671,1776,benstopford,2016-09-05T16:56:04Z,ok,0,0.8787186145782471
77544719,1776,benstopford,2016-09-05T16:56:56Z,thanks,0,0.5400217771530151
77544895,1776,benstopford,2016-09-05T17:00:00Z,"yes, good spot. thank you.",1,0.9949318766593933
77545048,1776,benstopford,2016-09-05T17:02:02Z,agreed. changed.,0,0.9229452610015869
77545600,1776,benstopford,2016-09-05T17:08:33Z,yeah - it was just used by a test. have changed to test the ensurevalid method instead.,0,0.9903496503829956
77545753,1776,benstopford,2016-09-05T17:11:11Z,done. thanks,1,0.8948071599006653
77545866,1776,benstopford,2016-09-05T17:13:16Z,sure can,0,0.9532712697982788
77545936,1776,benstopford,2016-09-05T17:14:33Z,thanks,0,0.5400217771530151
77545961,1776,benstopford,2016-09-05T17:14:59Z,good idea. thanks.,1,0.9934762120246887
77546037,1776,benstopford,2016-09-05T17:16:39Z,added. thanks,1,0.9106941819190979
77546111,1776,benstopford,2016-09-05T17:17:55Z,thanks,0,0.5400217771530151
77546161,1776,benstopford,2016-09-05T17:18:51Z,unboundedquota sounds good to me.,0,0.5153108835220337
77549097,1776,benstopford,2016-09-05T18:16:57Z,yeah - i should have put a comment on that. it's a historical artefact from the way the original client quota managers worked. i knew i had to rework it. it should be a bit better now.,0,0.9460112452507019
77549138,1776,benstopford,2016-09-05T18:17:51Z,done,0,0.8974218964576721
77549657,1776,benstopford,2016-09-05T18:30:34Z,nope. hangover from when we had separate throttled replica fetcher threads. removed.,0,0.9154624938964844
77554690,1776,ijuma,2016-09-05T20:36:09Z,you can express the the rhs of `==` as: [code block],0,0.9916239380836487
77554722,1776,ijuma,2016-09-05T20:36:44Z,is this a left-over debugging thing? it seems like you don't need this var at all.,0,0.9797669649124146
77625349,1776,benstopford,2016-09-06T12:36:06Z,nope. removed.,0,0.9158164858818054
77626384,1776,benstopford,2016-09-06T12:43:41Z,"that test verifies you can create a logconfig object, but doesn't verify that you can update that same log config from the configcommand, which you can't currently.",0,0.9926744103431702
77627001,1776,ijuma,2016-09-06T12:48:10Z,"interesting, this is an issue for kip-71 too then. cc",0,0.9521238207817078
77632698,1776,dguy,2016-09-06T13:23:27Z,"hmm, yes indeed. it appears configcommand doesn't like commas. topiccommand otoh does.",-1,0.5129077434539795
77806141,1776,benstopford,2016-09-07T11:44:55Z,thanks,0,0.5400217771530151
77806226,1776,benstopford,2016-09-07T11:45:37Z,ok,0,0.8787186145782471
77806309,1776,benstopford,2016-09-07T11:46:13Z,good idea.,1,0.9718119502067566
77855115,1776,benstopford,2016-09-07T16:14:31Z,"have extracted the logic from the clientquotamanager and reused, which, i think, is better!",0,0.8649213314056396
77855598,1776,benstopford,2016-09-07T16:17:02Z,sure can.,0,0.9785173535346985
77855719,1776,benstopford,2016-09-07T16:17:42Z,yes. thanks,1,0.9152973890304565
77855772,1776,benstopford,2016-09-07T16:18:04Z,will do all these at the end.,0,0.9883546829223633
77855817,1776,benstopford,2016-09-07T16:18:21Z,this was changed,0,0.9793764352798462
77856461,1776,benstopford,2016-09-07T16:22:17Z,"i wouldn't typically add accessors here, although i would have some years back. if you're super keen on this kind of stuff i'll change.",0,0.785946249961853
77856804,1776,benstopford,2016-09-07T16:24:06Z,nope. removed,0,0.9406323432922363
77857026,1776,benstopford,2016-09-07T16:25:25Z,good spot. thank you.,1,0.9935682415962219
77857237,1776,benstopford,2016-09-07T16:26:34Z,cool. thanks.,1,0.9940014481544495
77862056,1776,benstopford,2016-09-07T16:53:20Z,changed,0,0.9270829558372498
77868592,1776,benstopford,2016-09-07T17:31:01Z,"interesting. so it's not actually used anywhere. the value is just passed into the quota managers, following the same pattern used in the clientquotamanager. so maybe we don't need to change kafkaconfig at all? what do you think?",0,0.9694412350654602
77873545,1776,ijuma,2016-09-07T17:59:02Z,"i'm not super-keen on the accessors, it's just the general kafka convention. i'm keen on the fields being `final` though. also, do we want `value` and `bound` to be nullable? if not, then they should be lowercase `double`.",0,0.9474345445632935
77880926,1776,benstopford,2016-09-07T18:44:11Z,ok,0,0.8787186145782471
77881060,1776,benstopford,2016-09-07T18:44:55Z,thanks,0,0.5400217771530151
77881100,1776,benstopford,2016-09-07T18:45:11Z,ok,0,0.8787186145782471
77881343,1776,benstopford,2016-09-07T18:46:39Z,ah yes. thanks,1,0.9613673686981201
77881777,1776,benstopford,2016-09-07T18:49:13Z,it most certainly is. thank you. i'll do a refactor of these tests in my final pass.,1,0.9546829462051392
77893695,1776,benstopford,2016-09-07T20:06:14Z,ok - changed,0,0.9282888174057007
77974298,1776,ijuma,2016-09-08T09:34:33Z,"we are leaking the thread right? if you just want to execute something in the background, you can do something like: [code block] if you store the future, you can also await on the result or just completion by using `await.result` or `await.ready` (probably not applicable in this case, but worth knowing).",0,0.9903234243392944
78008266,1776,benstopford,2016-09-08T13:45:41Z,thanks. good to know.,1,0.9918861389160156
78140580,1776,ijuma,2016-09-09T07:45:12Z,nitpick: `value` and `bound` should be lowercase `double` since they can't be null (annoying that scala and java are different in this respect so it's a bit confusing when writing code in both languages).,0,0.8536593317985535
78140755,1776,ijuma,2016-09-09T07:46:58Z,nitpick: should be `brokers` to be consistent with the other ones? or should the other ones be made singular?,0,0.9893823862075806
78141062,1776,ijuma,2016-09-09T07:49:48Z,nitpick: no return needed and no blocks are needed. example: [code block],0,0.9894816875457764
78141122,1776,ijuma,2016-09-09T07:50:16Z,i'd include the `broker` variable in the message.,0,0.9894168972969055
78141182,1776,ijuma,2016-09-09T07:50:49Z,i think it would be a bit better if this method returned an `int` and the caller just wrapped the result in `seq(...)`.,0,0.9898367524147034
78141363,1776,ijuma,2016-09-09T07:52:32Z,"seems like this code would be a bit nicer if we had a `val supportedtypes = set(configtype.topic, configtype.client, configtype.broker)` somewhere.",0,0.98373943567276
78141952,1776,ijuma,2016-09-09T07:58:20Z,"maybe something like: [code block] i think you also need to handle errors if the format doesn't match what you expect, right? at the moment, we will get unhelpful `arrayoutofboundsexception`s and `numberformatexception`s.",0,0.9817211627960205
78142068,1776,ijuma,2016-09-09T07:59:32Z,"i see that there's a `throttledreplicavalidator`, is that ensuring that things will be in the right format by the time we get here?",0,0.9944571256637573
78142129,1776,ijuma,2016-09-09T08:00:03Z,nitpick: space after `:`,0,0.9912277460098267
78142280,1776,ijuma,2016-09-09T08:01:30Z,"unless i am missing something, i think this should take a `string` since the caller is passing it a `string`. then you don't need `tostring` below.",0,0.9815312623977661
78142342,1776,ijuma,2016-09-09T08:02:13Z,this message doesn't mention `broker`. another case where having a definition of supported types would make the code more robust.,0,0.9918701648712158
78142470,1776,ijuma,2016-09-09T08:03:42Z,wouldn't it be better to have a `shutdown()` in `quotas` that closes all of them?,0,0.9954749941825867
78142661,1776,ijuma,2016-09-09T08:05:36Z,it doesn't seem like this is used any more.,0,0.921427309513092
78142693,1776,ijuma,2016-09-09T08:05:55Z,do we still need this?,0,0.9834956526756287
78142931,1776,ijuma,2016-09-09T08:08:06Z,"maybe this should be `def props(map: map[string, string])` and then you would use it like: [code block]",0,0.9940072298049927
78143052,1776,ijuma,2016-09-09T08:09:27Z,thanks for changing the calling code. can we remove this method then?,0,0.6874550580978394
78143150,1776,ijuma,2016-09-09T08:10:18Z,have you seen `testutils.producemessages`?,0,0.9937902092933655
78143190,1776,ijuma,2016-09-09T08:10:43Z,`unit.` should not be here.,0,0.99196457862854
78147862,1776,benstopford,2016-09-09T08:52:10Z,"good point. i've changed to ""add/remove entity config for a topic, client or broker"" (command only lets you change one at a time)",1,0.9283950328826904
78147928,1776,benstopford,2016-09-09T08:52:40Z,thanks,0,0.5400217771530151
78148028,1776,benstopford,2016-09-09T08:53:24Z,good idea. thanks,1,0.9903182983398438
78148279,1776,benstopford,2016-09-09T08:55:32Z,ok,0,0.8787186145782471
78149087,1776,benstopford,2016-09-09T09:02:07Z,definitely!,1,0.5977357625961304
78149712,1776,benstopford,2016-09-09T09:06:56Z,yep. that's the idea.,0,0.8490039110183716
78150344,1776,benstopford,2016-09-09T09:11:59Z,"it just means the tostring has to be called in the ensurevalid method, so six of one and half a dozen of the other. unless i'm missing something.",0,0.9215644001960754
78150565,1776,benstopford,2016-09-09T09:13:27Z,done (with enumerated list),0,0.95624178647995
78150976,1776,benstopford,2016-09-09T09:16:47Z,ok.,0,0.9740158319473267
78151082,1776,benstopford,2016-09-09T09:17:29Z,thanks,0,0.5400217771530151
78151223,1776,benstopford,2016-09-09T09:18:29Z,yep. it's the definitive list of broker configs you can change.,0,0.951164186000824
78151950,1776,benstopford,2016-09-09T09:23:48Z,have removed & refactored original. was a bit pointless.,-1,0.9613227248191833
78152713,1776,ijuma,2016-09-09T09:30:00Z,"no, you don't need to do that because of the pattern matching clause. you have to pass `s` instead of `value`.",0,0.9886327385902405
78154280,1776,benstopford,2016-09-09T09:42:58Z,have changed,0,0.9430906176567078
78154318,1776,benstopford,2016-09-09T09:43:19Z,thanks,0,0.5400217771530151
78159088,1776,benstopford,2016-09-09T10:28:01Z,"ah, gottcha. thanks",1,0.9869222044944763
78160093,1776,benstopford,2016-09-09T10:37:03Z,"i've consolidated onto a single class, keeping simplerate. this encompasses a different approach to fixing kafka-2567 whilst being a little simpler to test.",0,0.9765561819076538
78160165,1776,benstopford,2016-09-09T10:37:41Z,ok,0,0.8787186145782471
78160327,1776,benstopford,2016-09-09T10:39:04Z,done. thanks.,1,0.9619041085243225
78231105,1776,benstopford,2016-09-09T18:54:39Z,"i've added support for comma separated lists in the configcommand. you specify the list using a square bracket: k1=v1,k2=[v2,v3]",0,0.9917792677879333
78249903,1776,apurvam,2016-09-09T21:12:02Z,nitpick: would it be better to just use `messageset` from line 118 instead of doing `partitiondata.tobytebuffermessageset` again? this way you save an allocation.,0,0.9947472214698792
78259626,1776,apurvam,2016-09-09T22:40:41Z,would this be better as a typed enum rather than a string? makes compile time checks stronger.,0,0.9902238249778748
78265368,1776,apurvam,2016-09-10T00:04:53Z,"this message doesn't match the test. shouldn't it be ""throttled replication of n ms should > m ms""",0,0.938116729259491
78269010,1776,junrao,2016-09-10T02:01:24Z,timems in the comment is no long valid.,0,0.930877685546875
78269016,1776,junrao,2016-09-10T02:01:46Z,"having two different rates is going to make it harder for developers to decide which one to use. if this is strictly better than rate, perhaps we should just change rate.windowsize(). if this is just for testing, perhaps we can create simplerate in test?",0,0.9714322686195374
78269021,1776,junrao,2016-09-10T02:01:54Z,"the comment in line 470 doesn't seem to match the test. also, space before 0.",0,0.9761900305747986
78269023,1776,junrao,2016-09-10T02:02:00Z,is this comment accurate?,0,0.9839099645614624
78269027,1776,junrao,2016-09-10T02:02:03Z,space before {,0,0.9824872612953186
78269029,1776,junrao,2016-09-10T02:02:07Z,space after if,0,0.9853398203849792
78269031,1776,junrao,2016-09-10T02:02:13Z,this doesn't seem to be used?,0,0.9484621286392212
78269033,1776,junrao,2016-09-10T02:02:17Z,does --execute block?,0,0.9877800941467285
78269036,1776,junrao,2016-09-10T02:02:20Z,b/s => bytes/sec ?,0,0.9868588447570801
78269040,1776,junrao,2016-09-10T02:02:33Z,addthrottle => maybeaddthrottle ?,0,0.9934803247451782
78269041,1776,junrao,2016-09-10T02:02:37Z,unused import javaconverters,0,0.981778621673584
78269052,1776,junrao,2016-09-10T02:03:12Z,"if quota is not exceeded, should we check (accumulatedsize + accumulatedthrottledsize) >= fetchmetadata.fetchminbytes?",0,0.9927042722702026
78269056,1776,junrao,2016-09-10T02:03:18Z,extra space before result,0,0.9841887950897217
78269059,1776,junrao,2016-09-10T02:03:22Z,a few unused imports.,0,0.9093608856201172
78269063,1776,junrao,2016-09-10T02:03:29Z,the upper bound => the upper bound in bytes/sec ?,0,0.9921850562095642
78269069,1776,junrao,2016-09-10T02:03:42Z,unused import,0,0.9524969458580017
78269090,1776,junrao,2016-09-10T02:04:27Z,would it be better to just check quota.isquotaexceeded once and make the same decision for each throttled partition on whether it should be included or not?,0,0.9923593401908875
78269091,1776,junrao,2016-09-10T02:04:31Z,there is already a trace statement in abstractfetcherthread that logs each fetch request. do we still need this trace logging?,0,0.9930830001831055
78269148,1776,junrao,2016-09-10T02:07:42Z,unused imports metricname and rate.,0,0.9904658794403076
78269151,1776,junrao,2016-09-10T02:07:48Z,allreplicas instead?,0,0.9901188611984253
78269161,1776,junrao,2016-09-10T02:08:16Z,the above may not be 100% safe since the metric could be expired and removed between the two statements. it's safer if we save metrics.metrics.get(ratemetricname) to a local val and then check null and update the config.,0,0.9933006763458252
78269165,1776,junrao,2016-09-10T02:08:23Z,"since sensor() has side effect, it would be clearer if all references to sensor are sensor().",0,0.9938456416130066
78269169,1776,junrao,2016-09-10T02:08:44Z,"the convention is to use trace() which does does the if check already. also, for string formatting, we are moving towards the s notation instead of format. ditto in a few other places.",0,0.98272705078125
78269173,1776,junrao,2016-09-10T02:08:56Z,partitions == allreplicas should probably be partitions eq allreplicas?,0,0.9908758401870728
78269178,1776,junrao,2016-09-10T02:09:08Z,"to be consistent, if there is no return value, we just do method() {}.",0,0.9909714460372925
78269179,1776,junrao,2016-09-10T02:09:11Z,"if partitions is empty, should we remove that topic from the map?",0,0.9920715689659119
78269182,1776,junrao,2016-09-10T02:09:18Z,is there a reason to remove these? it seems the test is still useful.,0,0.9855958223342896
78269185,1776,junrao,2016-09-10T02:09:21Z,unused import,0,0.9524969458580017
78269187,1776,junrao,2016-09-10T02:09:25Z,10 sec seems inaccurate now?,-1,0.6610565781593323
78269190,1776,junrao,2016-09-10T02:09:29Z,is this really done in a separate thread?,0,0.991356372833252
78269192,1776,junrao,2016-09-10T02:09:33Z,1 second seems inaccurate now?,-1,0.5208472013473511
78269194,1776,junrao,2016-09-10T02:09:34Z,20s seems inaccurate now?,0,0.5734149813652039
78269197,1776,junrao,2016-09-10T02:09:37Z,remove unit,0,0.973983108997345
78269199,1776,junrao,2016-09-10T02:09:41Z,is len 100 or 1?,0,0.9909222722053528
78269200,1776,junrao,2016-09-10T02:09:44Z,unused imports,0,0.961042582988739
78269203,1776,junrao,2016-09-10T02:09:49Z,could this and next method be private?,0,0.9932006001472473
78269206,1776,junrao,2016-09-10T02:09:56Z,"do we ""put replicas for all partitions on the not-started brokers""?",0,0.9938763976097107
78269212,1776,junrao,2016-09-10T02:10:06Z,the text in here and line 172 seem inaccurate.,0,0.8331124186515808
78269223,1776,junrao,2016-09-10T02:10:35Z,"with this, after recording the bytes, the quota could be exceeded? the earlier approach where we use quota.isquotaexceed(expectedbytes) seems more conservative and is less likely for quota to be exceeded. is there a reason not to use quota.isquotaexceed(expectedbytes)?",0,0.98631751537323
78298061,1776,junrao,2016-09-11T16:29:39Z,"it seems that we need to handle case c better. if the follower is lagging on old segments and the quota is exceeded, we may return an empty result well before max wait. returning an empty result early occasionally is fine. however, in this case, it seems that this can happen continuously.",0,0.9787876009941101
78298089,1776,junrao,2016-09-11T16:31:28Z,"there could be a subtle issue with timeout. say we check the quota and it's exceeded, and we will put the delayedfetch in the purgatory. if no more bytes are produced, the delayedfetch has to wait for maxwait. however, quota could become available before maxwait (and we won't get a chance to check). one potential way to address this is that if quota is exceeded, we calculate the amount of time that needs to pass before quota is available. we set the timeout in delayedfetch to the be smaller of that time and maxwait. then, if delayedfetch expires, in delayedfetch.oncomplete(), if minbytes is not satisfied and maxwait hasn't been exceeded. we put delayedfetch to purgatory again.",0,0.9654068946838379
78318335,1776,benstopford,2016-09-12T06:02:51Z,thanks,0,0.5400217771530151
78320891,1776,benstopford,2016-09-12T06:39:58Z,yes. agree.,0,0.892427921295166
78321116,1776,benstopford,2016-09-12T06:43:20Z,thanks. changed.,1,0.950593113899231
78321156,1776,benstopford,2016-09-12T06:43:49Z,thanks,0,0.5400217771530151
78321274,1776,benstopford,2016-09-12T06:45:31Z,good spot. thanks,1,0.9917556047439575
78321313,1776,benstopford,2016-09-12T06:46:10Z,yes it is. have clarified the test comment a bit.,0,0.9442899227142334
78321694,1776,benstopford,2016-09-12T06:51:30Z,thanks,0,0.5400217771530151
78321704,1776,benstopford,2016-09-12T06:51:34Z,thanks,0,0.5400217771530151
78321742,1776,benstopford,2016-09-12T06:52:05Z,oops - thanks,1,0.8398441672325134
78321998,1776,benstopford,2016-09-12T06:54:54Z,no. mistake. thanks,1,0.9800789952278137
78322063,1776,benstopford,2016-09-12T06:55:42Z,done,0,0.8974218964576721
78322189,1776,benstopford,2016-09-12T06:57:17Z,done. thanks,1,0.8948071599006653
78322192,1776,benstopford,2016-09-12T06:57:21Z,done. thanks,1,0.8948071599006653
78322413,1776,benstopford,2016-09-12T07:00:09Z,yes. that's a great spot. thank you.,1,0.9958934783935547
78322533,1776,benstopford,2016-09-12T07:01:44Z,thanks,0,0.5400217771530151
78322678,1776,benstopford,2016-09-12T07:03:28Z,good spot,1,0.972886860370636
78322720,1776,benstopford,2016-09-12T07:03:59Z,thanks,0,0.5400217771530151
78323225,1776,benstopford,2016-09-12T07:09:45Z,sure thing.,0,0.8936349749565125
78323280,1776,benstopford,2016-09-12T07:10:27Z,thanks. removed,1,0.9252122640609741
78323319,1776,benstopford,2016-09-12T07:10:54Z,thanks,0,0.5400217771530151
78323346,1776,benstopford,2016-09-12T07:11:08Z,ok. cool,1,0.9911901950836182
78325258,1776,benstopford,2016-09-12T07:31:41Z,i've changed this both here and also in the clientquotamanager (which had the same logic),0,0.9908384680747986
78325391,1776,benstopford,2016-09-12T07:33:06Z,yes - good call. thanks,1,0.9914372563362122
78326425,1776,benstopford,2016-09-12T07:43:20Z,thanks for the heads up. changed,1,0.8470109105110168
78327387,1776,benstopford,2016-09-12T07:51:33Z,ok - makes sense.,0,0.9244316220283508
78328609,1776,benstopford,2016-09-12T08:02:26Z,ok - thanks for the heads up - have changed tidied up where this was wrong elsewhere too.,1,0.7461366653442383
78333596,1776,ijuma,2016-09-12T08:40:30Z,probably unintended change?,0,0.887256920337677
78333653,1776,ijuma,2016-09-12T08:40:58Z,probably unintended change?,0,0.887256920337677
78404954,1776,benstopford,2016-09-12T16:22:47Z,"no, i missed that somehow. have added it now.",0,0.9754106998443604
78406716,1776,benstopford,2016-09-12T16:32:52Z,how strange. that was removed when i merged from my previous branch. good spot.,1,0.9051375985145569
78407140,1776,benstopford,2016-09-12T16:35:15Z,thanks,0,0.5400217771530151
78407153,1776,benstopford,2016-09-12T16:35:20Z,thanks,0,0.5400217771530151
78407241,1776,benstopford,2016-09-12T16:36:03Z,it certainly isn't! thanks.,1,0.9783796072006226
78407355,1776,benstopford,2016-09-12T16:36:44Z,thanks,0,0.5400217771530151
78407542,1776,benstopford,2016-09-12T16:38:05Z,thanks,0,0.5400217771530151
78407632,1776,benstopford,2016-09-12T16:38:36Z,thanks,0,0.5400217771530151
78407763,1776,benstopford,2016-09-12T16:39:17Z,thanks,0,0.5400217771530151
78407832,1776,benstopford,2016-09-12T16:39:39Z,thanks,0,0.5400217771530151
78408120,1776,benstopford,2016-09-12T16:41:14Z,sure can,0,0.9532712697982788
78408614,1776,benstopford,2016-09-12T16:44:06Z,clarified. thanks,1,0.9830403923988342
78410438,1776,benstopford,2016-09-12T16:54:31Z,"yes - the idea seemed like a good one, but it led to some complexities. the main problem was that the ratio of the requestsize:quotasize correlated with the amount the throttle would be undercut. also, if you asked for more than the quota in a single request you could never make progress. the upshot was that the behaviour was a little unintuitive, and the simpler mechanism seems to work well on aggregate. so after thinking about it for a while i decided to ditch the isexceededby(bytes) approach. keep it simple ... and this way it more closely matches the way the follower works more closely. i hope that makes sense.",0,0.8954389095306396
78411666,1776,benstopford,2016-09-12T17:02:01Z,"i did consider this issue. you are right that we could make the leader algorithm more responsive by altering the timeout (i didn't think of that - good idea). for now i'm inclined to raise a jira for this as a future enhancement. it shouldn't affect throttling significantly. the extra delay will even out over time. also, this problem exists on the follower too so the optimisation is only of value for the leader side of the throttle. the main concern i have is actually the lack of smarts on the follower, particularly if throttled partitions enter the isr, as the follower logic is very basic.",0,0.7186493873596191
78412609,1776,benstopford,2016-09-12T17:07:49Z,thanks,0,0.5400217771530151
78412775,1776,benstopford,2016-09-12T17:08:59Z,thanks,0,0.5400217771530151
78432823,1776,benstopford,2016-09-12T18:56:06Z,good spot. i think this should be as simple as: [code block] but i'll need to write a test which will take a little time.,1,0.9296528100967407
78783831,1776,junrao,2016-09-14T16:25:33Z,"yes, the follower has a similar issue. there is already logic to add a delay per partition. so, if a partition is throttled in the follower, we can calculate a delay from quota and delay the partition accordingly. we probably also need to change the backoff logic in abstractfetcherthread a bit. instead of always backing off for a fixed amount of time, it's probably better to backoff based on the smallest delay among all partitions. i agree that this is probably not a common issue. it only becomes a big issue if the maxwait or replica backoff time are configured very large (say close to the metric window \* sample size). so, we can address that in a followup jira.",0,0.9818228483200073
78865421,1776,junrao,2016-09-14T23:43:57Z,"processconfigchanges() only gets called if there is overridden config on brokerid in zk. so, if that doesn't exist, it seems that we won't apply the static default throttledreplicationlimit in broker property file?",0,0.9949250221252441
78865431,1776,junrao,2016-09-14T23:44:05Z,extra space after :,0,0.9805262684822083
78865451,1776,junrao,2016-09-14T23:44:17Z,throttle should be type long?,0,0.9905626773834229
78865458,1776,junrao,2016-09-14T23:44:22Z,convention: use trace().,0,0.9927204847335815
78865572,1776,junrao,2016-09-14T23:45:23Z,unused import,0,0.9524969458580017
78865576,1776,junrao,2016-09-14T23:45:27Z,typo bakc,0,0.9396021366119385
78865588,1776,junrao,2016-09-14T23:45:34Z,"perhaps we should just test excluding the property, which is consistent with the test in line 484?",0,0.9951463341712952
78865602,1776,junrao,2016-09-14T23:45:40Z,should we make limit long since throttledreplicationratelimitprop is of type long?,0,0.9933591485023499
78865609,1776,junrao,2016-09-14T23:45:44Z,take => taken,0,0.9568630456924438
78865626,1776,junrao,2016-09-14T23:45:49Z,are we using a separate thread?,0,0.9891133308410645
78865633,1776,junrao,2016-09-14T23:45:55Z,are we using a separate thread?,0,0.9891133308410645
78865643,1776,junrao,2016-09-14T23:46:00Z,should this be private?,0,0.9891258478164673
78893471,1776,junrao,2016-09-15T05:47:04Z,"i think we can just get rid of the static config throttledreplicationratelimitprop and just rely on the dynamic broker level config, which is more flexible.",0,0.9899932742118835
78959050,1776,benstopford,2016-09-15T13:10:37Z,"yes - i raised a bug for this, but it's not a big deal so lets lose the config it as you say.",-1,0.6739891767501831
78959367,1776,benstopford,2016-09-15T13:12:20Z,thanks. done,1,0.9596986770629883
78959375,1776,benstopford,2016-09-15T13:12:24Z,thanks. done,1,0.9596986770629883
78959967,1776,benstopford,2016-09-15T13:15:33Z,thanks,0,0.5400217771530151
78959976,1776,benstopford,2016-09-15T13:15:37Z,thanks,0,0.5400217771530151
78961026,1776,benstopford,2016-09-15T13:20:52Z,"we have that already on line 428. are you concerned about it being there, or objecting to the format of the test?",0,0.9917860627174377
78961219,1776,benstopford,2016-09-15T13:21:56Z,ok,0,0.8787186145782471
78979265,1776,benstopford,2016-09-15T14:38:40Z,"the nice thing about having it in the config is validation. if we remove the prop, we'd probably need another list of dynamic broker configs somewhere. what do you think?",0,0.5105630159378052
78994469,1776,junrao,2016-09-15T15:38:36Z,"yes, we are doing similar things in kip-55. we are deprecating the static client quota configs in the broker in favor of dynamic quotas. so, for new broker configs, if it can be made dynamically, it seems it's less confusing to also add a static config in the broker property.",0,0.9841466546058655
79071084,1776,apurvam,2016-09-15T21:57:41Z,"you should log a message here, with information of the old and new quota topic for the broker/topic/partition being modified. otherwise these dynamic changes without any auditing will be impossible to debug.",0,0.9872892498970032
79080424,1776,benstopford,2016-09-15T23:03:46Z,it should be visible from the logging in the dynamicconfigmanager (line 106). do you not see that?,0,0.9938632249832153
79080650,1776,apurvam,2016-09-15T23:05:40Z,"yes, i see it now. sorry for the false alarm.",-1,0.9896977543830872
1379392210,14690,kirktrue,2023-11-01T22:26:33Z,"now that i'm noticing, is this a public api violation? it's not in `internals` and we're adding a `public` method :thinking_face:",0,0.501270055770874
1379396122,14690,kirktrue,2023-11-01T22:31:10Z,nit: more idiomatic: [code block],0,0.9630059599876404
1379398154,14690,kirktrue,2023-11-01T22:34:25Z,"i'm probably confused by taking the naming of the `onheartbeatrequestsent` method too literally, but the request hasn't been _sent_, only _enqueued_. do we need to call this when it's really _sent_ or is enqueued ""good enough?""",0,0.9029582142829895
1379399402,14690,kirktrue,2023-11-01T22:36:41Z,"this is the case where the consumer is not in a group _presently_, right? a consumer without a configured group id wouldn't get to this point, would it?",0,0.9853906631469727
1379400497,14690,kirktrue,2023-11-01T22:38:28Z,"as i understand, this is saying the consumer will leave the `acknowledging_reconciled_assignment` state as soon as the next heartbeat is sent off, rather than the next heartbeat is received, right? what happens if that heartbeat request gets lost?",0,0.9746661186218262
1379402695,14690,kirktrue,2023-11-01T22:42:06Z,"sorry to retread this: how are `leaving_group` and `sending_leave_request` different? they both will call the `onpartitionslost()` callback first, right?",-1,0.9911124110221863
1379404682,14690,kirktrue,2023-11-01T22:45:53Z,does the consumer transition from `join` to `reconciling` mean that the first heartbeat response after the join request will (may?) contain an assignment?,0,0.9950297474861145
1379407419,14690,kirktrue,2023-11-01T22:50:32Z,`targetassignment()` looks to only be used by unit tests at the moment. does it make sense to remove it from the interface and leave it as a method on the implementation only?,0,0.9945236444473267
1379408357,14690,kirktrue,2023-11-01T22:52:23Z,can this be called directly via the `applicationeventprocessor` when the consumer sends an event to the network thread to state it is closing? the only other place i see it called at the moment is from a unit test.,0,0.9927782416343689
1379413852,14690,kirktrue,2023-11-01T23:02:28Z,"the ide is showing this line with a warning because it's invoking `get()` without a `ispresent()` check. i know that it's being set in `settargetassignment` right above, but can we refactor this code to make it more obvious to the compiler (and any humans reading it)? here's a quick take: [code block] that way all the logic is together and we can remove `settargetassignment()`, too. just a thought.",0,0.9823976159095764
1379415462,14690,kirktrue,2023-11-01T23:05:54Z,would you mind making a constant for `-1` just so it's easier to grep through the code and find places where the consumer is in this state?,0,0.9918864369392395
1379415743,14690,kirktrue,2023-11-01T23:06:34Z,"same here, regarding the magic numbers.",0,0.9892458319664001
1379418198,14690,kirktrue,2023-11-01T23:11:23Z,"i guess it's ok to use `consumermetadata` directly like this as we ""own"" updating it on the consumer network thread.",0,0.9659880995750427
1379419317,14690,kirktrue,2023-11-01T23:13:40Z,"yes, we'll have to resolve how the callbacks fit into this model that uses `future`s, because the callbacks need to be invoked on the application thread.",0,0.9914311766624451
1379420036,14690,kirktrue,2023-11-01T23:15:16Z,i made a comment up above about removing `targetassignment()` from the `membershipmanager` interface because it was only used for testing. does the removal of this statement imply that it will be used in non-testing later?,0,0.9954042434692383
1379420603,14690,kirktrue,2023-11-01T23:16:23Z,"would it be ""wrong"" to have the method implementation log the message instead of throwing an error?",0,0.9811872243881226
1379420811,14690,kirktrue,2023-11-01T23:16:48Z,this makes sense!,1,0.9226936101913452
1379422902,14690,kirktrue,2023-11-01T23:20:46Z,"two questions: 1. `topic` wants to unify the topic id and topic name information, but it explicitly allows either to be `null`. technically, since there are no checks, both values could be `null`. is that intentional? 2. notwithstanding the above, can we add this class without a kip? if not, can we move it to `o.a.k.common.internals`?",0,0.995587944984436
1379423191,14690,kirktrue,2023-11-01T23:21:23Z,"this would throw a `nullpointerexception`, wouldn't it?",0,0.9882900714874268
1380063605,14690,AndrewJSchofield,2023-11-02T13:00:44Z,"i see what means, but this package is not part of the public javadoc. the closest that the public interface has to exposing this kind of information is `org.apache.kafka.common.cluster`.",0,0.985798716545105
1380073097,14690,AndrewJSchofield,2023-11-02T13:07:41Z,"i'm surprised that the previous valid states for fatal is not all of the other states, such as fenced.",-1,0.6898397207260132
1380077957,14690,AndrewJSchofield,2023-11-02T13:11:42Z,`topicidpartition`? you do know the topic ids and they're relevant for guarding against topics which have been recreated.,0,0.9936680197715759
1380079966,14690,AndrewJSchofield,2023-11-02T13:13:15Z,"i suggest ""skip sending the heartbeat to the coordinator"". i do like the method naming convention you're establishing with ""skip"" in the name.",0,0.974877655506134
1380080844,14690,AndrewJSchofield,2023-11-02T13:14:02Z,"just ""leaving"" would match the other states better.",0,0.9876097440719604
1380083241,14690,AndrewJSchofield,2023-11-02T13:16:03Z,`transitiontojoining`?,0,0.9938600063323975
1380083590,14690,AndrewJSchofield,2023-11-02T13:16:20Z,`transitiontofatal`?,0,0.991139829158783
1380086392,14690,AndrewJSchofield,2023-11-02T13:18:34Z,"personally, i'd capture the value of `state()` in a local variable and then use it twice, rather than calling the method twice. there are a couple of instances of this.",0,0.9914337396621704
1380088445,14690,AndrewJSchofield,2023-11-02T13:20:16Z,"i think so. also, the set return by `consumermetadata` is immutable.",0,0.9900597333908081
1380090093,14690,AndrewJSchofield,2023-11-02T13:21:37Z,i think that theoretically it could and the action you've proposed is correct.,0,0.9669811725616455
1380092591,14690,AndrewJSchofield,2023-11-02T13:23:36Z,interesting :),1,0.9907955527305603
1380121804,14690,AndrewJSchofield,2023-11-02T13:31:50Z,i would say that it needs a kip in this package.,0,0.986747145652771
1380144482,14690,AndrewJSchofield,2023-11-02T13:35:57Z,`objects.hashcode()` is your friend.,0,0.9192750453948975
1380218718,14690,lianetm,2023-11-02T14:17:40Z,totally! i missed that,-1,0.9865986108779907
1380372614,14690,lianetm,2023-11-02T15:53:22Z,"that was considering that the member could only got to fatal from states where it sends heartbeat, when receiving non-retriable errors in the heartbeat response (and states like fenced or leaving do not send heartbeat)",0,0.9397101402282715
1380393617,14690,AndrewJSchofield,2023-11-02T16:06:13Z,that's ok. i was just asking an innocent question. makes sense to me.,-1,0.8621577024459839
1380592053,14690,lianetm,2023-11-02T17:59:27Z,"i expect that topic class will be exposed at some point, as we spread the usage of topic id in the client code, that's why i added it there, but totally missed that it could then require a kip. so i just moved it to the internal package, as it is truly only internal for now.",0,0.9896793365478516
1380659584,14690,lianetm,2023-11-02T19:06:20Z,"i moved it to the internals for now, as it's truly for internal use (even though i expect we might want something similar later on as we use topicid more in the client code).",0,0.9913821816444397
1380660843,14690,lianetm,2023-11-02T19:07:45Z,"you're right, this is the case where a consumer, with a groupid, is not part of the group (either it hasn't called subscribed, or it called unsubscribe)",0,0.9934547543525696
1380683789,14690,lianetm,2023-11-02T19:31:50Z,"this is the check we discussed earlier about target assignment and subscription. leaving it for now only so you can see exactly what it is, but we can remove it then if we still think it should be better to let the broker drive this.",0,0.9923432469367981
1380693973,14690,lianetm,2023-11-02T19:43:42Z,"good catch, i needed it public at some point but it ended up not being needed in the end. so putting it back to package-private and ""visible for testing""",1,0.8537984490394592
1380694833,14690,lianetm,2023-11-02T19:44:42Z,"totally, it seemed it was needed here at some point but not anymore. removing it & cleaning up, thanks!",1,0.9871438145637512
1381667636,14690,dajac,2023-11-03T13:17:23Z,nit: i think that we tend to indent with 4 spaces in this case.,0,0.8618605732917786
1381676706,14690,dajac,2023-11-03T13:25:32Z,"i think that this is not enough because we only need to send it if it has changed and we also need to re-send them on failure. i was thinking about introducing a stateful builder object for the request which remembers the last fields sent out and decider whether the fields must be set or not. on errors, we could just reset the builder to re-send all fields. i think that could possibly always set all the fields in this pr and tackle this separately as we need to solve it more generally. what do you think?",0,0.9409752488136292
1381679771,14690,dajac,2023-11-03T13:27:57Z,i am not a big fan of the `not_in_group` name because the consumer could still have a group id configured and commit offsets to a group. this is why i used `unsubscribed` earlier. i wonder if we could find a better name... what do you think?,-1,0.8445311784744263
1381680532,14690,dajac,2023-11-03T13:28:35Z,could we extend the description to explain what we do in this state? i would also do it for the others.,0,0.9895814657211304
1381683004,14690,dajac,2023-11-03T13:30:21Z,"so i i understand it correctly, the member transitions to this state as soon as the reconciliation is done and then transition to stable as soon as the ack is sent out. did i get it right?",0,0.9738931059837341
1381683686,14690,dajac,2023-11-03T13:30:53Z,do we call `lost` in this case?,0,0.9930683374404907
1381686009,14690,dajac,2023-11-03T13:32:50Z,i also wonder if we should call it `acknowledging` to follow the naming of the other states. thoughts?,0,0.9721862077713013
1381688086,14690,dajac,2023-11-03T13:34:36Z,"my understanding is that `leaving` do the pre-leaving steps (e.g. pause partitions, commit offsets, etc) while `sending_leave_request` sends out the actually leave request. perhaps, using `prepare_leaving` and `leaving` would make it clearer. thoughts?",0,0.9915614724159241
1381690930,14690,dajac,2023-11-03T13:36:52Z,i think that we already define them in the `consumergroupheartbeatrequest` class. we could reuse them.,0,0.987561821937561
1381692974,14690,dajac,2023-11-03T13:38:13Z,`targetassignment` seems to be accessible directly. do we really need to pass it here?,0,0.9937990307807922
1381801641,14690,dajac,2023-11-03T14:44:53Z,"okay. i think that we could get into this situations in two cases. 1. an assigned topic was just created and the metadata request got to a broker unaware of it yet. in this case, ignoring it means that the newly created topic will never be consumed by the member. or, at least, it won't be consumed until another assignment is received. in the current implementation, i think that the fetcher will keep retrying on those topics. ideally, we would need something similar here. 2. an assigned topic was just deleted before the member got the chance to get the metadata. this is somewhat the opposite case. in the case of 1., we could argue that we should just keep retrying until it succeeds and it should eventually succeed. in this case of 2., it would never succeed if the topic is deleted so the member will never send an ack and will eventually be kicked out from the group. to make it worst, the member won't receive an new assignment without the deleted topic because the previous assignment is not ack'ed. the issue is that there is no way to differentiate the two cases. ideally, we should set the subscription based on the topic ids instead of the topic names. however, this does not resolve the need to have the topic names for the callbacks. there are really annoying... another thing that i wanted to point out is that it is not all or nothing. for instance, the member could get 10 partitions assigned to him and only one is unresolvable.",0,0.9757777452468872
1381802659,14690,dajac,2023-11-03T14:45:40Z,"as discussed offline, i would remove this. in my opinion, the member should just follow what the coordinator provide and should not try to be too smart here.",0,0.8401373624801636
1381802850,14690,dajac,2023-11-03T14:45:49Z,nit: extra line.,0,0.8806825876235962
1381810747,14690,dajac,2023-11-03T14:52:17Z,i wonder if we should also check if the target assignment is still the same one. i am not sure if it is possible but could we have a callback coming really late and the state machine could have already transitioned to fenced and rejoined the group and got a new assignment so be in reconciling state again?,0,0.8625040054321289
1381814507,14690,dajac,2023-11-03T14:55:03Z,"one concern that i have with using the manager directly is that it does not seem to populate the metadata cache afterwards. so, we would resolve topics once here and then the fetcher would redo it because the metadata cache does not have the topics. this is not ideal.",0,0.6584088802337646
1381819971,14690,dajac,2023-11-03T14:58:48Z,from the kip:,0,0.9915892481803894
1382108731,14690,philipnee,2023-11-03T18:50:20Z,we should just return early here. `return completablefuture.completedfuture(null);`,0,0.9929439425468445
1382450219,14690,philipnee,2023-11-04T19:50:27Z,i believe the reconciliation result is completed by the main thread.,0,0.9807156324386597
1382665763,14690,lianetm,2023-11-05T22:51:45Z,`unsubscribed` describes the state better to me too. renamed it and added comments explaining better how the member gets there and what it can do while in this state.,0,0.9863278865814209
1382666152,14690,lianetm,2023-11-05T22:54:17Z,"you're right, this state is only until the next hb is sent, and then the member moves on. if the hb with the ack is lost, what happens is that, when the rebalance timeout expires, the broker will re-assign the partitions to another member and kick this one out of the group.",0,0.9886300563812256
1382666539,14690,lianetm,2023-11-05T22:56:18Z,"you're right about what each does, and agree with the `prepare_leaving` and `leaving`. renamed them and updated comments, it looks clearer.",0,0.9145296216011047
1382666673,14690,lianetm,2023-11-05T22:57:15Z,"removed all static membership logic for now, given that is it not supported yet.",0,0.9870638847351074
1382666792,14690,lianetm,2023-11-05T22:57:56Z,done,0,0.8974218964576721
1382666862,14690,lianetm,2023-11-05T22:58:42Z,totally. done.,0,0.8580508232116699
1382667315,14690,lianetm,2023-11-05T23:01:42Z,"good point. i reused the -1, and removed the static membership constant and logic from our side given that it is not supported yet.",1,0.8865999579429626
1382667377,14690,lianetm,2023-11-05T23:02:08Z,"you're right, not needed, removed.",0,0.8583015203475952
1382668541,14690,lianetm,2023-11-05T23:08:59Z,"good point, this was not the right way so i updated how metadata is used here, all based on the metadata object now (request update when needed, and get notified when it happened). this ensures that the centralized cache is updated, and this is actually how other managers interact with metadata (ex. `offsetsrequestmanager` when it needs metadata to find leaders).",0,0.5796260833740234
1382724053,14690,lianetm,2023-11-06T02:20:05Z,"exactly, that's the case the transition is covering.",0,0.990103006362915
1382728096,14690,lianetm,2023-11-06T02:31:49Z,"makes sense, i will include the changes for the initial approach sending all, to tune it afterwards and send only what's needed",0,0.9754610657691956
1382742662,14690,lianetm,2023-11-06T03:08:57Z,"done. i updated them all, explaining more of what the member does in each and the relationship with the hb requests content and timing.",0,0.9138438701629639
1382772899,14690,lianetm,2023-11-06T04:35:39Z,"yes, we do, based on the epoch (epoch > 0 => onpartitionsrevoked, else onpartitionslost). the prepare leaving will trigger the `onpartitionsrevoked` in most of the cases i expect, but if the member is not in the group anymore it calls `onpartitionslost`. i was mainly thinking about the edge case where a member gets fenced, and while fenced (ex. waiting for user callback to complete), there is a call to unsubscribe. at that point the member would attempt to leave the group, but it is not currently an active member, so will call `onpartitionslost`. makes sense? that being said, i realize that even though the implementation supports that case, it was not a valid transition, so i just added it. will add tests for it shortly.",0,0.980790376663208
1383374287,14690,lianetm,2023-11-06T13:59:51Z,"the callback execution will be completed in the main thread (when implemented), but this is the reconciliation result that completes here in the background thread, that involves not only the callbacks. it involves 3 main async operations: - metadata (to resolve topic names for assignment) - commit - user callbacks (executed in the main thread)",0,0.9946756362915039
1383433245,14690,lianetm,2023-11-06T14:32:23Z,"thanks for confirming . after the change to integrate this with the centralized metadata object and cache, we do achieve this behaviour (we keep retrying until all assigned topic ids are found in metadata)",1,0.8347955942153931
1383435641,14690,lianetm,2023-11-06T14:34:08Z,"totally, all changed, thanks!",1,0.9935619831085205
1383513687,14690,lianetm,2023-11-06T15:26:08Z,"done, i updated it back to sending all fields for now. i will follow up in a next pr to send only what's needed. i expect that it will be the existing `heartbeatstate` the one to extend, to be able to build a `consumergrouprequestdata` based on the last one sent, the member info, and the subscription info (determine difference to send only what changed, and send all on the failed attempts that it already handles for retry/backoff)",0,0.9892187714576721
1383532710,14690,lianetm,2023-11-06T15:36:59Z,"i think we should have both points solved now with the new metadata approach. 1. we continue to request metadata updates as long as there are assigned topic ids not resolved ([a link]. this will solve the first case as you described. 2. we keep a local cache of assigned topicid->topicnames for assigned topics that have been previously resolved. if topic is not in metadata when it comes in a next target assignment it will be resolved from the local cache ([a link], as it is a known/assigned topic. this will solve case 2. thoughts?",0,0.9642482995986938
1383551733,14690,lianetm,2023-11-06T15:48:15Z,"just for the record, it wasn't integrated initially when you took a look but it was added in this pr. and yes, you're right, it is integrated via the applicationeventprocessor and the hbmanager",0,0.9772493839263916
1383566278,14690,philipnee,2023-11-06T15:57:47Z,if the reconciliationresult is completed by the main thread then i think the whencomplete block is also completed by the main thread.,0,0.9915158748626709
1383599082,14690,lianetm,2023-11-06T16:19:09Z,"i will share thoughts on this on our next sync with and you , as this is interesting. just for the record, i do agree that spreading topic ids is the right way forward, and we do have them now in the assignment path, but i realized when exploring this suggestion that it is a much bigger change if we move away from `topicpartition`, and we're not ready for it at this point (mainly tricky/ugly because not all paths support topicid yet but most of them access/update the shared `subscriptionstate` component and `topicpartition`) at this point looks to me that we're better of making use of the topic ids kind of ""on the side"", like we're doing now in the `membershipmanager`, that keeps the assigned topicid/names but still uses the same `topicpartition`. this is the same approach followed by the `fetch` and `metadata` paths, that introduced topic ids in a similar ""on the side"" way. there's interesting food for thought here anyway.",1,0.8716344237327576
1383610788,14690,lianetm,2023-11-06T16:27:55Z,"i'm using `send` to align with how the hb manager was naming the existing `onsendattempt` and such, and i think that as seen from the manager point of view it is enough, the membership manager only needs to know that the request is sent out of the hb manager to transition accordingly. it is not literally sent over the network. i would leave send/sent to keep it consistent between the 2 managers, but let me know if you think it would be clearer differently.",0,0.9802044034004211
1383623183,14690,dajac,2023-11-06T16:33:24Z,"i think that a client could still get an unresolvable topic id and be stuck in the reconciling state. for instance, it could happen if the member sees a topic id for the first time and the topic id is deleted just before it could resolve it.",0,0.9388380646705627
1383699023,14690,philipnee,2023-11-06T17:21:25Z,is there any reason we want to combine onpartitionslost and onpartitionsrevoke into a single function? couldn't we directly invoke `invokeonpartitionsrevoke` or `invokeonpartitionslost`? i.e. by the time the consumer is fenced or would know we need to invoke onpartitionslost,0,0.9947630763053894
1383701313,14690,philipnee,2023-11-06T17:23:02Z,"as previously mentioned, it is clearer to directly invoke `invokeonpartitionslost` here. is there a case we don't invoke onpartitionslost?",0,0.9951171875
1383780173,14690,philipnee,2023-11-06T18:21:36Z,i don't think the exception will actually be thrown here.,0,0.739597737789154
1383786483,14690,philipnee,2023-11-06T18:26:42Z,"looking at the current consumer, i think it can be quite complicated in this implementation. maybe what we should do is to invoke the listener on the spot, then send an even to the background thread to leave group.",0,0.9093562960624695
1383791886,14690,philipnee,2023-11-06T18:32:02Z,i'm guessing the idea is we need to ignore the backoff and heartbeat.,0,0.9584978222846985
1383959347,14690,lianetm,2023-11-06T20:42:13Z,"yes, as we discussed for the states that would send heartbeat without waiting for the interval (sending ack for an assignment and leave group requests basically)",0,0.9911296367645264
1383962388,14690,lianetm,2023-11-06T20:44:53Z,"you're right, it should happen in the poll to maintain the current contract. i will just remove it since we don't execute callbacks yet, and it should be included in the pr that introduces the callback execution.",0,0.9739769101142883
1383968073,14690,philipnee,2023-11-06T20:49:52Z,can we use the standard tostring format? topic(topicid=...),0,0.9947564601898193
1383974744,14690,philipnee,2023-11-06T20:54:17Z,can we just fail the consumer?,0,0.9836927056312561
1383979443,14690,lianetm,2023-11-06T20:58:28Z,"the reason is the leave group logic. on leave group it could be lost or revoked, depending on the epoch. on fence or fatal is always lost. i was just reusing the same func for convenience, but will change the fence and fatal transitions to directly invoke the `onpartitionslost` just to make the intention clearer.",0,0.9782984852790833
1383983917,14690,lianetm,2023-11-06T21:02:21Z,"the kip states that we should do exactly this, and actually the consumer would stay functional. `consumer#enforcerebalance will be deprecated and will be a no-op if used when the new protocol is enable. a warning will be logged in this case.` do you have a concern that i may be missing?",0,0.9941595792770386
1383986418,14690,lianetm,2023-11-06T21:04:19Z,"actually i intentionally followed the standard of the topicpartition and topicidpartition tostring implementations, since this new topic class is kind of a sibling, makes sense?",0,0.9822991490364075
1383995398,14690,philipnee,2023-11-06T21:11:42Z,thanks for the clarification!,1,0.7521101832389832
1384004581,14690,philipnee,2023-11-06T21:19:24Z,thanks for the clarification!,1,0.7521101832389832
1384016549,14690,philipnee,2023-11-06T21:29:38Z,"i think unsubscribe() actually blocks on callback invocation and throw if possible. instead of putting the logic in whencomplete, it seems like we should try to wait till the callback completes then throw if needed. i assume we want to maintain this behavior for the async consumer.",0,0.9861750602722168
1384076305,14690,philipnee,2023-11-06T22:00:43Z,"i think this kafkaexception might not be in the right place because the rebalance listener needs to be invoked on the mainthread, probably before sending out the event. i wonder if we could just remove this whencomplete and rely on the background thread to log the failures during the leave group event. if there's a fatal exception being thrown there, it seems the sensible way is to enqueue to the backgroundeventqueue and handle in the poll. wdyt? in the current code path, i think only exceptions can only be thrown in `onleaveprepare`.",0,0.9653082489967346
1385059304,14690,lianetm,2023-11-07T14:59:12Z,"agree that the unsubscribe blocks on the callbacks, but since we don't have the implementation for how callbacks are going to be executed on this pr this unsubscribe is still not using it. it should come when we nail the implementation details on the follow-up pr (will depend on how we end up doing it, maybe blocking not here, but on the subscribe/unsubscribe events) as for the exception, it will originate in the application thread, where the callback is executed, and it should only be returned to the user when it calls poll, to maintain the current behaviour, so i removed it from here to stay consistent and leave all logic related to the callback execution out, i see the confusion introduced. the when complete should stay because it represents a concept we need, un-related to callbacks: we do need to update the `subscriptionstate` only when the unsubscribe event completes (hb to leave group sent to the broker). we need it know to make sure we are able to run unsubscribe, no callbacks, sending leave group, and clearing up the subscription state after sending the request. trying to leave it in a consistent state with no callbacks. follow-up pr should introduce implementation for executing them, blocking appropriately on the execution, and throwing the exceptions.",0,0.9860373139381409
1385082158,14690,lianetm,2023-11-07T15:14:06Z,"agree, done here. note my answer above though, about the cases where we do need revoke or lost, that one should stay.",0,0.976205050945282
1385085418,14690,lianetm,2023-11-07T15:15:58Z,"just for the record, as discussed offline, none of these futures are expected to be completed in the main thread. this is a reconciliation future, which is much more than the callbacks (metadata, commit, callbacks). and callbacks, when implemented, will be based on events shared between the app thread and the background thread (not based on futures from one thread complete on the other, as that would be problematic)",0,0.9938157796859741
1385350785,14690,lianetm,2023-11-07T18:18:35Z,"agree. just for the record, we're trying to figure out how to properly handle the cases where metadata wouldn't be available for a target assignment (permanently when topic deleted, or even just temporarily). with the current shape where the client attempts to reconcile the full target assignment, what happens now is rather disruptive, as the member would be kicked out of the group after rebalance timeout expires.",0,0.9264036417007446
1387282757,14690,philipnee,2023-11-08T22:48:58Z,this is just a transient state for the member to send the leave group heartbeat with epoch -1/-2 (dynamic/static membership) right?,0,0.9924063086509705
1389220863,14690,dajac,2023-11-10T10:31:26Z,do we still need the changes in this class? it seems that we don't use them anymore. i have the same question for the new `topic` class.,0,0.9844063520431519
1390582429,14690,lianetm,2023-11-13T03:01:07Z,"you're right, not needed anymore (all metadata interaction is now based on the centralized metadata cache). all removed.",0,0.8977290391921997
1390583612,14690,lianetm,2023-11-13T03:03:33Z,"yes, similar to the acknowledging in the sense that they are just a way to indicate that a heartbeat must be sent without waiting for the interval, and as soon as the request is sent the member transitions out of the state.",0,0.9918676018714905
1390590490,14690,lianetm,2023-11-13T03:20:45Z,"totally valid point. i fixed it, but comparing assignments seemed more complicated and harder to reason about with the current approach. now the target assignment is kind of a moving target, it can be modified anytime not only from the server, but also from metadata updates. so back to the problem of making sure that delayed reconciliations are not applied after a member rejoins, i added just a check based on the current member id, to identify that a reconciliation completed but the member is already re-joining. what do you think? (whenever there are no rejoins in the picture, i expect that the reconciling state check alone should be enough given that reconciliations are always applied sequentially)",0,0.8739162683486938
1391828060,14690,kirktrue,2023-11-14T00:01:15Z,"the closure that the application thread is passing to `whencomplete()` will be run in the background thread, right? the closure is modifying the `subscriptionstate`, it shouldn't cause any problems, but still... since we have access to the `subscriptionstate` in the background thread already, can the background thread just update the `subscriptionstate` directly?",0,0.993022620677948
1391862343,14690,kirktrue,2023-11-14T01:04:51Z,"there's another `subscribeinternal()` for the topic pattern path. we want this there too, right?",0,0.9917164444923401
1391875622,14690,kirktrue,2023-11-14T01:30:29Z,"i apologize if it's here somewhere, but i don't see where we ""register"" the membership manager with the cluster resource listeners.",-1,0.9590093493461609
1391875744,14690,kirktrue,2023-11-14T01:30:45Z,good call!,1,0.9947137236595154
1391876960,14690,kirktrue,2023-11-14T01:33:12Z,"the intention of the `completeableapplicationevent` was to have a way for the consumer to block on the results of operations performed in the background thread. since the `consumer.unsubscribe()` api call is non-blocking, i'm thinking this should be a subclass of `applicationevent`.",0,0.993319034576416
1391879026,14690,kirktrue,2023-11-14T01:37:29Z,are we missing the initialization of `unsubscribed`?,0,0.9943724870681763
1391880921,14690,kirktrue,2023-11-14T01:41:16Z,[code block] `subscription_change` is a bit vague. does it encompass more than the event of the user calling `consumer.subscribe()`?,0,0.9751192927360535
1391882860,14690,kirktrue,2023-11-14T01:45:20Z,[code block] suggestion: use the double-underscore to denote to the reader that the variable is intended to remain unused.,0,0.9930699467658997
1391883884,14690,kirktrue,2023-11-14T01:47:24Z,"suggestion: consider moving this to an `assignpartitions()` method, similar to the `revokepartitions` method, for consistency and readability.",0,0.9937077760696411
1391885027,14690,kirktrue,2023-11-14T01:49:38Z,"suggestion: make `groupinstanceid` and `serverassignor` `optional` as constructor parameters to convey to the callers that they are, indeed, _optional_.",0,0.9919126033782959
1391885243,14690,kirktrue,2023-11-14T01:50:07Z,[code block] haha. i don't really care :smirking_face:,1,0.9783015251159668
1391888737,14690,kirktrue,2023-11-14T01:56:43Z,[code block] nit: remove extra newline.,0,0.9901635050773621
1391889559,14690,kirktrue,2023-11-14T01:58:16Z,[code block] nit: it'll be visually easier to parse with the space before the next sentence.,0,0.9713249206542969
1391890695,14690,kirktrue,2023-11-14T02:00:28Z,"i think this `equals()` call is ok. from looking at `abstractset`, it appears that `sortedset.equals()` is ok to accept any ol' `set` implementation.",0,0.9788024425506592
1392717259,14690,lianetm,2023-11-14T14:50:53Z,"the `consumer.unsubscribe` does block on the callback execution, that's why it is a `completableapplicationevent`. only after the callback completes the unsubscribe can send the actual leave group heartbeat request. makes sense?",0,0.9922600388526917
1392732597,14690,lianetm,2023-11-14T14:59:46Z,"i see, i was just intentionally leaving out all the pattern based logic because we don't support it at this point. but this makes me realize that that `subscribeinternal` based on pattern that you mentioned is wired to the `subscribe(pattern pattern)` api call, when it's truly not supported yet. i think we should disable all the subscribe based on patterns until we implement them properly. what do you think?",0,0.6981325149536133
1392733198,14690,lianetm,2023-11-14T15:00:07Z,"good catch, added.",1,0.9726673364639282
1392744058,14690,lianetm,2023-11-14T15:05:01Z,"indeed, only from the state when the leave group hb is sent out. added and test. thanks!",1,0.9923680424690247
1392748787,14690,lianetm,2023-11-14T15:07:53Z,"it's exactly when the user changes the subscription via a call to subscribe. i used the name `subscription_change` because it seemed clear and to be consistent with the existing `assignment_change`, but let me know if you think another name would be better.",0,0.9925244450569153
1392790381,14690,lianetm,2023-11-14T15:32:12Z,"done. just to make sure we are on the same page, the whole snippet marked is not really assign. assign is only ln 581 and ln 591 where the subscription state is updated and calling callbacks, and yes, i extracted those into an `assignpartitions()`. the rest of the checks, cache and errors is related to the revocation (or the transition from revocation to assign) so leaving it here where the revocation and assign are linked.",0,0.9895456433296204
1392802141,14690,lianetm,2023-11-14T15:38:34Z,"he he, i do avoid this, missed it here, fixed ;)",1,0.9876608848571777
1392827512,14690,kirktrue,2023-11-14T15:55:51Z,where does it block? i didn't see a call to `future.get()` when i looked.,0,0.9813591837882996
1392829031,14690,kirktrue,2023-11-14T15:56:51Z,"i never liked `assignment_change` either, but i guess it's consistent, so :thumbs_up:",1,0.94178307056427
1392830639,14690,kirktrue,2023-11-14T15:57:54Z,"those kinds of things tend to jump out in _other people's_ code, but i frequently miss them in my own :grinning_face_with_smiling_eyes:",0,0.8752569556236267
1392954694,14690,lianetm,2023-11-14T17:18:17Z,"agree that the equals here does what we want, but actually this made me notice another detail. i wasn't passing the custom comparator when creating the `assignnedpartitions` sorted set. also, for the owned ones, i already have a sorted set a few lines below so just moving it up to reuse it and make the comparison clearer.",0,0.9825983047485352
1393793669,14690,dajac,2023-11-15T07:59:21Z,nit: we could remove this empty line.,0,0.9825745224952698
1393794196,14690,dajac,2023-11-15T07:59:49Z,should we add a unit test for the newly added topic names mapping?,0,0.9921661615371704
1393830838,14690,dajac,2023-11-15T08:30:47Z,"from an architectural point of view, i wonder if this method and the next one are in the right place. intuitively, i would have put them into the membership manager directly because they don't interact with the heartbeat manager state at all. what's your take on this?",0,0.8668348789215088
1393833703,14690,dajac,2023-11-15T08:33:05Z,"have we reached a conclusion on this one? it seems correct to me to consider it as a no-op if the member is already leaving. however, i was wondering whether we should return a future here that will be completed only when the on-going leave operation completes.",0,0.9857310652732849
1393834178,14690,dajac,2023-11-15T08:33:32Z,"nit: we could remove a few empty lines here, i suppose.",0,0.9659862518310547
1393839254,14690,dajac,2023-11-15T08:37:43Z,nit: -1 or -2.,0,0.9690282344818115
1393842585,14690,dajac,2023-11-15T08:40:19Z,could we transition to fatal from prepare leaving and leaving?,0,0.9811128377914429
1393842889,14690,dajac,2023-11-15T08:40:35Z,could we transition to fatal from prepare leaving?,0,0.9896861910820007
1393848768,14690,dajac,2023-11-15T08:45:11Z,`acknowledges the target assignment` is confusing here. my understanding is that it will acknowledge the part of the target assignment that was actually reconciled. am i correct?,-1,0.8227043151855469
1393850232,14690,dajac,2023-11-15T08:46:22Z,nit: i think that we usually put static variables first when declaring attributes.,0,0.9775223731994629
1393852447,14690,dajac,2023-11-15T08:47:55Z,nit: should we move this one to `consumergroupheartbeatrequest` as we already have `leave_group_member_epoch` there?,0,0.9950371384620667
1393854091,14690,dajac,2023-11-15T08:49:07Z,i am confused by this. did we say that we should keep the member id forever when we receive one?,-1,0.8302293419837952
1393856821,14690,dajac,2023-11-15T08:51:05Z,"note that it is possible to receive the exact same assignment multiple times. i suppose that in this case, we transition to reconciling and the reconciliation process will be a no-op because the current and the target are the same. did i get it right?",0,0.9872499108314514
1393914776,14690,dajac,2023-11-15T09:32:14Z,nit: i wonder whether we should log this as an error.,0,0.7117986679077148
1393915412,14690,dajac,2023-11-15T09:32:42Z,should we also react to the future completion here for e.g. log something?,0,0.9920369386672974
1393915845,14690,dajac,2023-11-15T09:33:01Z,don't we need to call `subscriptions.assignfromsubscribed(collections.emptyset());` here as well?,0,0.9954291582107544
1393916982,14690,dajac,2023-11-15T09:33:50Z,nit: we could remove this empty line.,0,0.9825745224952698
1393917097,14690,dajac,2023-11-15T09:33:55Z,ditto.,0,0.6705162525177002
1393958634,14690,dajac,2023-11-15T10:03:02Z,"is this really true? we could have the same topic name in both but with different topic ids for instance. in my opinion, we should move towards using topicidpartition for both the assigned partitions and the partitions ready to reconcile. we can of course tackle separately from this pr.",0,0.9833531379699707
1393958878,14690,dajac,2023-11-15T10:03:13Z,nit: we can remove an empty line here.,0,0.9897288084030151
1393960227,14690,dajac,2023-11-15T10:04:15Z,should we trigger both in parallel?,0,0.9924972057342529
1393962052,14690,dajac,2023-11-15T10:05:30Z,nit: we could remove this empty line.,0,0.9825745224952698
1393962754,14690,dajac,2023-11-15T10:06:01Z,should we log this as an error?,0,0.9894920587539673
1393968230,14690,dajac,2023-11-15T10:09:53Z,"as i said before, this does not seem correct to me because we should keep the member id forever.",0,0.8828184604644775
1393968517,14690,dajac,2023-11-15T10:10:06Z,nit: we could remove this empty line.,0,0.9825745224952698
1393970046,14690,dajac,2023-11-15T10:11:17Z,nit: we could remove this empty line.,0,0.9825745224952698
1393972135,14690,dajac,2023-11-15T10:12:59Z,what happen in this case? i suppose that the reconciliation will be retried. did i get it right?,0,0.9787189364433289
1393972399,14690,dajac,2023-11-15T10:13:13Z,nit: we can remove the space after the `.`.,0,0.9915837049484253
1393972835,14690,dajac,2023-11-15T10:13:35Z,nit: we could remove this empty line.,0,0.9825745224952698
1393973543,14690,dajac,2023-11-15T10:14:13Z,nit: we could remove this empty line.,0,0.9825745224952698
1393974377,14690,dajac,2023-11-15T10:14:56Z,i agree that the other state transition should take care of updating the state. we should only abort here.,0,0.9804056882858276
1393976328,14690,dajac,2023-11-15T10:16:29Z,nit: we could remove this empty line.,0,0.9825745224952698
1393977197,14690,dajac,2023-11-15T10:17:09Z,"nit: using `ifpresent` would be a bit more idiomatic, i think.",0,0.9598172307014465
1393987062,14690,dajac,2023-11-15T10:24:43Z,"i am not sure to understand how the metadata cache knows which new topic ids it should resolve. or does the consumer request metadata for all topics in the cluster? looking at the code, it is may be what it does.",0,0.6228683590888977
1393993623,14690,dajac,2023-11-15T10:29:34Z,+1,0,0.7702900171279907
1394012157,14690,dajac,2023-11-15T10:44:58Z,"there is a subtile behaviour changes here. 1) in the legacy implementation, `this.coordinator.onleaveprepare()` is called here and it triggers the callback before returning from `unsubscribe`. 2) `subscriptions.unsubscribe()` is actually called before `unsubscribe` returns as well.",0,0.9941666126251221
1394032677,14690,dajac,2023-11-15T10:55:05Z,"btw, it seems that we could have transitioned to another state while waiting on this one as well.",0,0.9898109436035156
1394042794,14690,dajac,2023-11-15T11:00:07Z,"i also wonder whether if would be possible to parallelize more. for instance, is there a reason not to trigger the revocation and the assignment callbacks at the same time? this would ensure that they are call within one poll; otherwise, it can take multiple calls to poll to complete the assignment. we could consider this as a optimization for the future.",0,0.9922153353691101
1394053638,14690,dajac,2023-11-15T11:09:11Z,`partitionsassigned` could also be empty here so we should handle this case appropriately. e.g. we should not trigger the callback.,0,0.9946029782295227
1394322340,14690,lianetm,2023-11-15T14:55:14Z,filed [a link] for this and i will take care of it right after this pr as a follow-up.,0,0.9844236969947815
1394344222,14690,lianetm,2023-11-15T15:10:46Z,"yes, done.",0,0.9001237750053406
1394493344,14690,lianetm,2023-11-15T16:57:39Z,"yes, that's what it does, get metadata for all topics [a link]. it seems that there was an intention of a partial update [a link] but not fully implemented, so it effectively ends up getting them all anyways.",0,0.9812373518943787
1394570775,14690,lianetm,2023-11-15T18:00:25Z,"yes, you're right, i will rephrase this. it acknowledges the reconciled assignment, which is the subset of the target that was resolved from metadata and actually reconciled.",0,0.8926464915275574
1394581206,14690,lianetm,2023-11-15T18:07:38Z,"done, re-arranged a couple of them.",0,0.9793393015861511
1394585362,14690,lianetm,2023-11-15T18:10:24Z,"totally, done.",0,0.9707270860671997
1394619681,14690,lianetm,2023-11-15T18:28:38Z,"yes, done. it is actually the level used for this in the legacy coordinator.",0,0.9738795757293701
1394629300,14690,lianetm,2023-11-15T18:37:34Z,"cool, thanks for confirming.",1,0.9439111351966858
1394646561,14690,lianetm,2023-11-15T18:51:40Z,"the legacy coordinator does trigger the `onpartitionsassigned` with empty partitions (not the `onpartitionsrevoked` though), so i intentionally left the same behaviour, makes sense? i had also added a note on the [a link] to make sure that we keep that contract when implementing callbacks.",0,0.9935613870620728
1394733589,14690,lianetm,2023-11-15T20:03:07Z,"yes, done. that's how it's done for other callbacks (aligned the messages too to make them consistent for all callbacks)",0,0.9838598966598511
1394742401,14690,lianetm,2023-11-15T20:12:53Z,"you're right, we do. added it, along with a log in case of error.",0,0.8848277926445007
1394746271,14690,lianetm,2023-11-15T20:17:20Z,"sure, done. logging error in the same way that it's done for other callback failures.",0,0.982257068157196
1394753399,14690,lianetm,2023-11-15T20:24:11Z,"yes, i just updated this. we're on the same page regarding that the client will keep the member id forever and provide it back....but i was wrongly expecting it would change after rejoining. updated now. the goal is to be able to identify a rejoin, so using the member epoch (expecting that every time a member rejoins will get a bumped epoch).",0,0.9670426845550537
1394759427,14690,lianetm,2023-11-15T20:28:46Z,"you got it right, i expect the same thing (i had this [a link] for that)",0,0.9201591610908508
1394774045,14690,lianetm,2023-11-15T20:42:16Z,"agree, same member id forever. updated this to use the member epoch as a way of identifying that the member has rejoined.",0,0.978869616985321
1394786770,14690,lianetm,2023-11-15T20:53:01Z,"yes, makes sense to me. it could be bundled up along with the callbacks triggering (both, revocation and assign), so that we trigger them all in the same poll iteration, while still making sure that they are executed in the right order. filed [a link] and i will address that as a follow-up right after this.",0,0.9738401174545288
1394789418,14690,lianetm,2023-11-15T20:55:11Z,"agree, filed [a link] and i will address that as a follow-up right after this (considering all the 3 parts: commit, revoke callback, assign callback)",0,0.9786050319671631
1395130865,14690,lianetm,2023-11-16T04:18:22Z,"agree, i merged them into the membership manager, and this actually goes in the same direction we've discussed about the membership manager becoming a first-class manager (supporting poll, for instance).so for now i integrated it with the `applicationeventprocessor` already, to be able to move these 2 funcs that i totally agree make sense in the membership manager (when tackling the poll for triggering reconciliations, i will extend on this same direction)",0,0.9654704928398132
1395132794,14690,lianetm,2023-11-16T04:22:54Z,"done (now in the membership manager `leavegroup`). no-op if already leaving, and returning the future that will complete when the ongoing leave completes. also handling the case where the member already left (no-op and return right away)",0,0.9930874705314636
1395138233,14690,lianetm,2023-11-16T04:33:38Z,"there is no transition from prepare leaving to fatal with the current usage of fatal (only when receiving fatal errors in hb response), because we don't send hb while in prepare leaving. as for leaving, i would say we shouldn't either, because even if it is a state where we do send hb, we transition out of it as soon as the hb request is ready to be sent (without waiting for the actual send or any response). that being said, this makes me realize that the same reasoning applies for acknowledging, there shouldn't be a way of transitioning from ack to fatal, just because we transition out of it on heartbeat sent.",0,0.9876463413238525
1395138981,14690,lianetm,2023-11-16T04:35:13Z,not with the current usage of fatal as i see it (message above),0,0.9897608160972595
1395143611,14690,lianetm,2023-11-16T04:43:07Z,"agree, filed [a link] to extend topic id usage in the whole assignment reconciliation flow to make sure we handle topic re-creation properly.",0,0.9937050938606262
1395665723,14690,dajac,2023-11-16T13:07:00Z,"we don't send an explicit hb while in prepare leaving. however, we continue to heartbeat so i assume that we could receive an error or be fenced while in this state. regarding the ack case, i think that we could receive a similar response while in ack so the same applies. do you agree?",0,0.9870945811271667
1395667965,14690,dajac,2023-11-16T13:08:56Z,interesting... i wonder if this was done on purpose or if this just a bug. i don't really see the value in calling `onpartitionsassigned` without any partitions. i suppose that we should double check this. we could perhaps file a jira and clarify this separately. what do you think?,0,0.7690022587776184
1395669911,14690,dajac,2023-11-16T13:10:27Z,"let's file a jira to improve this as well. ideally, assuming that we don't use client side regex anymore, the client should only request the topics that it needs.",0,0.9904296398162842
1395677889,14690,dajac,2023-11-16T13:16:48Z,nit: i suppose that this one should go on the previous line.,0,0.9774881601333618
1395680718,14690,dajac,2023-11-16T13:17:46Z,i would remove the todos for which we have jiras.,0,0.9839850068092346
1395687362,14690,dajac,2023-11-16T13:22:10Z,nit: i may be worth logging something here as well to be consistent with `transitiontofatal`.,0,0.9897516965866089
1395689326,14690,dajac,2023-11-16T13:23:36Z,nit: should we also log the member epoch?,0,0.9920003414154053
1395690012,14690,dajac,2023-11-16T13:24:13Z,is this still valid? it looks like we call onpartitionslost explicitly now.,0,0.991517961025238
1395691085,14690,dajac,2023-11-16T13:25:09Z,i wonder why we clear it here whereas in transitiontofenced we clear it when the callback future is completed. is there a reason for this subtile difference?,0,0.9603221416473389
1395691853,14690,dajac,2023-11-16T13:25:43Z,is there a reason why we don't do this as the first thing in this method? this would be more consistent with transitiontofenced.,0,0.9940882921218872
1395693217,14690,dajac,2023-11-16T13:26:48Z,"i think that the next hb should pick it up. otherwise, we could perhaps transition to joining to force an immediate hb. i am not sure that it is worth it.",0,0.9158864617347717
1395697755,14690,dajac,2023-11-16T13:30:35Z,"i am a bit confuse by where we call `clearpendingassignmentsandlocalnamescache`. sometime we call it when the callback future is completed, sometime right after scheduling the callback. i wonder if it would be possible to be more consistent or if there are specific reasons that i did not get.",-1,0.7736384868621826
1395717674,14690,dajac,2023-11-16T13:46:36Z,"note that here we clear the `assignedtopicnamescache` but we only clear the assigned partitions after the callback is executed. this means that we have a period of time during which we are not able to resolve ids from the names in the subscription. i suppose that it does not matter in this case but this could be a source of subtile bugs. as we discussed offline, i think that we really need to update the subscriptions to use topicidpartitions. if this is not possible, an intermediate approach would be to keep the assigned topicidpartitions in this manager and to update the subscriptions with `subscriptions.assignfromsubscribed` when we update it. or, we could also move the bookkeeping of the cache closer to calls to `subscriptions.assignfromsubscribed`.",0,0.9843623638153076
1395721501,14690,dajac,2023-11-16T13:49:34Z,nit: we could use `==` here now.,0,0.9925083518028259
1395722320,14690,dajac,2023-11-16T13:50:12Z,do we need to check the epoch here as well?,0,0.9937173128128052
1395747556,14690,dajac,2023-11-16T14:06:11Z,nit: `t` -> `it`?,0,0.9913486838340759
1395783384,14690,dajac,2023-11-16T14:31:03Z,`the broker will continue to send the assignment to the member.` this is not entirely true. the broker may not send anything.,0,0.9848591685295105
1395862422,14690,lianetm,2023-11-16T15:05:18Z,"agree, rephrased it. this test is just for the case where the broker does keep sending (and the test above for when it does not)",0,0.9903906583786011
1395877609,14690,lianetm,2023-11-16T15:14:22Z,"agree, done. all todos in this class have jiras already.",0,0.8521877527236938
1395894946,14690,lianetm,2023-11-16T15:21:59Z,"you're right, not needed anymore. the member will transition to fatal state but can keep its last member id and epoch.",0,0.9332189559936523
1395907406,14690,lianetm,2023-11-16T15:28:39Z,"no reason, moved it to after the callback completes, consistent with how it is done on fencing, leave and reconcile",0,0.991826057434082
1395912856,14690,lianetm,2023-11-16T15:32:16Z,"no reason, updated it to make it consistent with the fencing transition",0,0.9819803237915039
1395929369,14690,lianetm,2023-11-16T15:42:56Z,agree that the next hb will pick it up based on the interval (also not seeing much need/value in the forced hb). removed the todo.,0,0.9890017509460449
1395947490,14690,lianetm,2023-11-16T15:55:00Z,"yes, i think we need it too. added.",0,0.963917076587677
1396006392,14690,lianetm,2023-11-16T16:31:16Z,"i moved the clear cache close to the `assignedfromsubscribed` in this manager, as a first step to align both and have a consistent usage",0,0.9906449317932129
1396013115,14690,lianetm,2023-11-16T16:35:22Z,"agree it was not consistent. i moved it close to the call to `assignpartitions`, so when callbacks complete we have a single `updateassignment` that makes the assignment effective and clears cache if needed.",0,0.992771327495575
1396088885,14690,lianetm,2023-11-16T17:26:05Z,"agree on handling that separately, but leaving the current behaviour as in the legacy coordinator. i also don't see the value either but it would introduce a change on when the `onpartitionsassigned` is called or not, so let's put some more though on it. filed [a link] to follow-up on this.",0,0.9844319224357605
1396462214,14690,lianetm,2023-11-16T22:50:07Z,"i updated it to align with the current behaviour (callbacks, best effort to send leave group request without any response handling or retry, and call to `subscriptions.unsubscribe` when everything completes). this has the gap of the callback execution that would require a poll. given that we don't support callbacks in this pr, it won't block the flow, but definitely to be solved (i added the details of the challenge to solve in the [a link]",0,0.9910440444946289
1396474166,14690,lianetm,2023-11-16T23:01:39Z,"makes sense, [a link]",0,0.9858096241950989
1396494887,14690,lianetm,2023-11-16T23:26:51Z,"yes, it will be retried on the next reconciliation loop (known shortcoming is how we trigger the reconciliation loops. it will be improved right after with [a link]",0,0.9917142987251282
1396826235,14690,lianetm,2023-11-17T07:55:29Z,"pushed one fix as a first step towards integrating topicidpartitions, which i agree should be the way forward. for now it is integrated in the membershipmanager, only in the reconciliation path where we do have all the info clearly in hand. will continue the integration as follow-up with [a link] as it requires a little bit more thought",0,0.9460172057151794
1398998763,14690,dajac,2023-11-20T10:41:19Z,"i think that this should actually outside of the `else` branch, isn't it?",0,0.9924525618553162
1399012130,14690,dajac,2023-11-20T10:50:03Z,"nit: if we would use `consumergroupheartbeatrequestdata.topicpartitions` in the `hashmap` and the `list`, we could skip this step.",0,0.9954853653907776
1399012491,14690,dajac,2023-11-20T10:50:20Z,nit: we could probably use `computeifabsent` to simplify this code.,0,0.9920463562011719
1399013422,14690,dajac,2023-11-20T10:50:43Z,we still need to conclude on this one.,0,0.973254919052124
1399026661,14690,dajac,2023-11-20T10:59:17Z,nit: should we move this code into `assignpartitions`?,0,0.9940734505653381
1399044241,14690,dajac,2023-11-20T11:14:04Z,i am curious here. is it better to build a `sortedset` with all elements and then to add it to `assignmentreadytoreconcile` vs adding to `assignmentreadytoreconcile` directly?,-1,0.6851421594619751
1399045098,14690,dajac,2023-11-20T11:14:49Z,nit: i have noticed that most of the comments end with a period but not all of them. it may be good to be consistent.,0,0.9352198839187622
1408353902,14690,lianetm,2023-11-28T19:58:37Z,"yeah, no value in it. i simplified it by just adding the topicpartition items directly to the `assignmentreadytoreconcile` (in [a link]",0,0.9838851690292358
1408354526,14690,lianetm,2023-11-28T19:59:17Z,"totally, and actually it made me realize it could be further simplified by retaining the assigned. it is included now in the [a link] with the other minor fixes.",0,0.9733988046646118
1408355119,14690,lianetm,2023-11-28T19:59:53Z,"definitely, done in the [a link]",0,0.9920608997344971
1408357542,14690,lianetm,2023-11-28T20:02:32Z,agree. it disappeared anyways after simplifying it all with the use of topicpartitions.,0,0.9762905836105347
1408361923,14690,lianetm,2023-11-28T20:07:07Z,"agree, we were definitely missing here transitions to fatal/fenced that may occur while the member is leaving (any of the 2 phases of leaving). i included the changes to properly handle them in the [a link] so we can continue the conversation there.",0,0.9857256412506104
98550533,2466,mjsax,2017-01-30T21:54:48Z,"this should be added to the first paragraph: [code block] please make sure, that the line is not longer than 120 chars. please adjust other javadocs, too.",0,0.9908305406570435
98553210,2466,mjsax,2017-01-30T22:06:11Z,"`return stream(null, null, keyserde, valserde, topics);` do the call directly instead of the cast.",0,0.9934533834457397
98553705,2466,mjsax,2017-01-30T22:08:30Z,"update to `return stream(offsetreset, null, null, null, topics);` to avoid too many indirections. to this for other overloads, too, please.",0,0.9930015802383423
98554156,2466,mjsax,2017-01-30T22:10:41Z,this should be the only method with actual code. all other overloads should call this one.,0,0.9877759218215942
98554261,2466,mjsax,2017-01-30T22:11:18Z,should not have an implementation but call overloaded method.,0,0.9866971373558044
98554337,2466,mjsax,2017-01-30T22:11:40Z,should not have an implementation but call overloaded method.,0,0.9866971373558044
98554471,2466,mjsax,2017-01-30T22:12:27Z,remove this line -- not required.,0,0.9815877676010132
98554659,2466,mjsax,2017-01-30T22:13:24Z,"nit: adjust indention of other parameters; line should not be longer than 120 chars. indent second/third/etc line, too. text can be shorter: [code block] (no need to link to `timestampextractor` as there will be a link in the javadocs anyway.",0,0.9924303889274597
98555452,2466,mjsax,2017-01-30T22:17:42Z,as above.,0,0.9878018498420715
98555469,2466,mjsax,2017-01-30T22:17:48Z,as above,0,0.9391705989837646
98555494,2466,mjsax,2017-01-30T22:17:56Z,remove,0,0.9477053284645081
98555525,2466,mjsax,2017-01-30T22:18:06Z,as above,0,0.9391705989837646
98555721,2466,mjsax,2017-01-30T22:19:11Z,remove,0,0.9477053284645081
98555745,2466,mjsax,2017-01-30T22:19:21Z,as above,0,0.9391705989837646
98555929,2466,mjsax,2017-01-30T22:20:16Z,"no reformatting, please",0,0.9477276802062988
98555957,2466,mjsax,2017-01-30T22:20:24Z,"no reformatting, please",0,0.9477276802062988
98556721,2466,mjsax,2017-01-30T22:24:30Z,nice catch!,1,0.9950374960899353
98557646,2466,mjsax,2017-01-30T22:29:44Z,we should not add this to the context -- see comments below.,0,0.9879248142242432
98558044,2466,mjsax,2017-01-30T22:31:50Z,keep this but rename to `defaulttimestampextractor`,0,0.9945387244224548
98558367,2466,mjsax,2017-01-30T22:33:32Z,"add line: `timestampextractor sourcetimestampextractor = source.gettimestampextractor();` and change to `recordqueue queue = createrecordqueue(partition, source, sourcetimestampextractor != null ? sourcetimestampextractor : defaulttimestampextractor);`",0,0.9943743944168091
98770837,2466,mjsax,2017-01-31T21:09:30Z,"nit: ""default { timestampextractor}[,] and"" the rule is ""a and b"" (for two things no comma), but ""a, b, c, and d"" (for three or more things, use commas)",0,0.9934817552566528
98771506,2466,mjsax,2017-01-31T21:13:00Z,"nit: please use the same order in all javacode -- above timestampextractor is second -- i don't care which order, but please be consistent. maybe follow parameter order of the method overload that provides all parameters ?",0,0.9870016574859619
98771974,2466,mjsax,2017-01-31T21:15:16Z,"remove ""(if any)""",0,0.9921737909317017
98772167,2466,mjsax,2017-01-31T21:16:10Z,"nit: no ""."" at the end please update everywhere.",0,0.9205074310302734
98773132,2466,mjsax,2017-01-31T21:20:22Z,update javadoc. same below,0,0.9903860092163086
98773266,2466,mjsax,2017-01-31T21:20:59Z,as above,0,0.9391705989837646
98773635,2466,mjsax,2017-01-31T21:22:48Z,nit: can you insert this method further down -- we want to order method overloads with regard to number of parameters -- it simplifies to keep track of what overloads are there.,0,0.9914273023605347
98777135,2466,mjsax,2017-01-31T21:38:44Z,check `source != null` not necessary. in doubt add an assertion.,0,0.9856868386268616
98777360,2466,mjsax,2017-01-31T21:39:46Z,this can be reverted.,0,0.98460453748703
98777858,2466,mjsax,2017-01-31T21:41:49Z,"does this add anything -- i doubt it? (ie, using a second mock tsextractor)",0,0.9467777609825134
98779356,2466,jeyhunkarimov,2017-01-31T21:48:56Z,which does not make sense: using two separate tsextractors or this test case as a whole?,0,0.9423006176948547
98780572,2466,jeyhunkarimov,2017-01-31T21:54:56Z,once i removed it failed most of the tests of `streamthreadstatestoreprovidertest` class with nullpointerexception.,0,0.992066502571106
98781354,2466,mjsax,2017-01-31T21:58:42Z,the test is fine -- but what's the value in testing overwrite the default extractor two times.,0,0.9866183400154114
98782371,2466,jeyhunkarimov,2017-01-31T22:03:37Z,i see. so i will remove `mocktimestampextractor2` class and correct the test accordingly.,0,0.9915932416915894
98847610,2466,dguy,2017-02-01T08:44:58Z,guaranteed -> guarantees,0,0.9864134788513184
98847825,2466,dguy,2017-02-01T08:46:39Z,"same as above. i guess this is largely copy & pasted from other javadoc, so the issue is most likely elsewhere",0,0.9903379678726196
98849518,2466,dguy,2017-02-01T08:58:47Z,"topics -> topic. this may well be elsewhere in the java-doc, too",0,0.9927001595497131
98850120,2466,dguy,2017-02-01T09:02:55Z,"i know you've only added the one param here, but seeing as you are changing it can you make all the params `final`?",0,0.9881943464279175
98850172,2466,dguy,2017-02-01T09:03:19Z,make all params `final`,0,0.9927229285240173
98850208,2466,dguy,2017-02-01T09:03:31Z,as above,0,0.9391705989837646
98850243,2466,dguy,2017-02-01T09:03:48Z,as above,0,0.9391705989837646
98850272,2466,dguy,2017-02-01T09:04:01Z,as above,0,0.9391705989837646
98850377,2466,dguy,2017-02-01T09:04:40Z,"here also, would be great if you could make the params `final`",0,0.9452996253967285
98850934,2466,dguy,2017-02-01T09:08:22Z,and again with `final` if you don't mind,0,0.9863698482513428
98851089,2466,dguy,2017-02-01T09:09:29Z,`final` ? all of the fields should be `final` really,0,0.9901916980743408
98851203,2466,dguy,2017-02-01T09:10:13Z,this method can be package-private,0,0.9924072623252869
98851316,2466,dguy,2017-02-01T09:10:54Z,"we should make this `final`, too",0,0.992374837398529
98853125,2466,dguy,2017-02-01T09:22:44Z,+1 to what said. the `source` should never be null. so you should change the `streamthreadstatestoreprovidertest`. it just needs to have the topic name extracted to a field on line 73. and then that same topic name used on line 189 in `new topicpartition(...)`,0,0.9905011653900146
98853314,2466,dguy,2017-02-01T09:23:49Z,i'd also consider extracting: `source.gettimestampextractor() != null ? ...` into a local as the line is quite long and it will make the code a bit easier to read.,0,0.9892829656600952
98853584,2466,dguy,2017-02-01T09:25:26Z,maybe `shouldaddtimestampextractorpersource` ?,0,0.9945419430732727
98853717,2466,dguy,2017-02-01T09:26:13Z,make all locals `final`,0,0.9915797710418701
99165540,2466,dguy,2017-02-02T16:51:07Z,"i'd probably extract lines 121 -> 130 into a method, i.e, `findsourcenode(...)` also, we -> if",0,0.99332195520401
99165983,2466,dguy,2017-02-02T16:52:46Z,there is no need to test this as it is calling the same method as above.,0,0.9887657165527344
99167116,2466,dguy,2017-02-02T16:57:08Z,i'm not sure what this test has to do with `streamtask`? to me this test should be in `topologybuildertest`. you don't need a `streamtask` in this case to check that the `timestampextractor` was assigned to the source,0,0.9407964944839478
99200243,2466,mjsax,2017-02-02T19:30:02Z,"i just realized, that we use different wording for topics as array of strings and topic pattern: ""there is no ordering guarantee"" vs ""there are no ordering guarantees"" -- i think we should clean this up for consistency. would you mind to add this fix to this pr? the singular version sounds better, imho.",0,0.9020047187805176
99200386,2466,mjsax,2017-02-02T19:30:57Z,sorry -- mixed it up with `table`.,-1,0.991358757019043
99201790,2466,jeyhunkarimov,2017-02-02T19:37:55Z,"i found `streamtasktest` the best suitable place, as it was suggested to make `sourcenode.gettimestampextractor()` method available within package. so, it is not accessible inside `topologybuildertest` currently. then i am making `sourcenode.gettimestampextractor()` public and moving the tests to `topologybuildertest`.",0,0.9926744103431702
99202642,2466,mjsax,2017-02-02T19:41:54Z,key -> topic,0,0.9553210139274597
99203389,2466,mjsax,2017-02-02T19:45:19Z,"i am still confused, about `source` being `null`. in the original code (l121) `source` is handed to `createrecrodqueue` and must not be `null` -- because this was never an issues before, i am still puzzled. why it is now.",0,0.5597339272499084
99204674,2466,mjsax,2017-02-02T19:51:20Z,"i agree with if you test `topologybuilder#addsource()` it should go to `topologybuildertest`, and if you test `kstreambuilder#stream` it should go to `kstreambuildertest` -- this also implies, you should split this test into two. also testing `kstreambuilder#addsource` is redundant because its inherited from `topologybuilder`.",0,0.9919006824493408
99206508,2466,jeyhunkarimov,2017-02-02T19:59:00Z,"when we add the sources by pattern (`kstreambuilder.stream(final pattern topicpattern)`), the source name is given like `""pattern ["" + regex + ""]""`. for example, for `t.*` pattern it would be `""pattern[t.*]""`. in `streamtask`, we search for sources (in 121) by topic name. for example, for topic name`""topic1""`, it gives `null`,because the source name is `""pattern[t.*]""`.",0,0.994716465473175
99446130,2466,mjsax,2017-02-03T23:55:23Z,"revert this for `.stream(...)`, because it can be multiple here. original comment only applies to `.table()` has has always a single input topic.",0,0.9933746457099915
99499027,2466,mjsax,2017-02-05T20:38:46Z,"can you address this comment, too?",0,0.9920294284820557
99499541,2466,mjsax,2017-02-05T20:58:02Z,can you please add `final` wherever possible.,0,0.9922366738319397
99499677,2466,mjsax,2017-02-05T21:02:29Z,why do you not reuse `kstreambuildertest#builder` ?,0,0.993466317653656
99499696,2466,mjsax,2017-02-05T21:03:00Z,"it's better to split this test into multiple -- here you test if no source specific extractor is set, thus, this should be a test method `sourceextractorshouldbenull` (or similar) and the test should end here. apply to below tests, too. (split into positive/negative tests and own tests for stream/table -- for stream/table add overload methods same way to test `topologbuilder.addsource()`",0,0.992300271987915
99500035,2466,mjsax,2017-02-05T21:16:02Z,add `final` wherever possible,0,0.9922616481781006
99500140,2466,mjsax,2017-02-05T21:19:41Z,why this change?,0,0.9617691040039062
99500765,2466,mjsax,2017-02-05T21:39:07Z,why not use `topology.sourcetopicpattern()` ? and than check if `partition.topic()` matches the pattern?,0,0.9942479133605957
99500810,2466,mjsax,2017-02-05T21:40:36Z,why this change?,0,0.9617691040039062
99500845,2466,mjsax,2017-02-05T21:42:09Z,apply `final` wherever possible (also within method),0,0.9915663599967957
100309277,2466,jeyhunkarimov,2017-02-09T13:51:52Z,"i think `sourcetopicpattern()` is a method of `topologybuilder`. in `streamtask` on the other hand, we get `processortopology` instance.",0,0.9937452077865601
100309989,2466,jeyhunkarimov,2017-02-09T13:55:31Z,"if we need to find the `topic` of the given source (`streamtask.findsource()`) by pattern, either we have to remove `""pattern [ ]""` part from source name and try all matches, or we can remove it (`""pattern [ ]""` part) when we assign the name for `sourcenode` and directly use its name as `pattern`. i thought the second case would be more usable.",0,0.9936322569847107
100310215,2466,jeyhunkarimov,2017-02-09T13:56:37Z,"because the test classes (`topologybuildertest` for example) cannot access the protected method , i leave it as it is",0,0.9937454462051392
100374990,2466,mjsax,2017-02-09T18:23:53Z,ack. by bad.,-1,0.9928272366523743
100493505,2466,dguy,2017-02-10T08:56:52Z,it would be nice if you made these `final` while you are doing this change.,0,0.9776608943939209
100493542,2466,dguy,2017-02-10T08:57:06Z,+1,0,0.7702900171279907
100493741,2466,dguy,2017-02-10T08:58:40Z,`return topology.source(topic);`,0,0.991981565952301
100493758,2466,dguy,2017-02-10T08:58:50Z,`final`,0,0.9858572483062744
100493997,2466,dguy,2017-02-10T09:00:43Z,"using `assertthat` is nicer as it gives better failure messages. `assertthat(sourcenode.gettimestampextractor(), instanceof(mocktimestaampextractor))` in other places, too",0,0.9943197965621948
100494305,2466,dguy,2017-02-10T09:02:58Z,"typo: kstreamhould... -> kstreamshould in fact i'd probably rename these methods to begin with should, i.e., `shouldaddtimestampextractortostreamwithoffsetresetpersource` etc",0,0.9916597008705139
100494435,2466,dguy,2017-02-10T09:03:54Z,"as per previous `assertthat(..., instanceof(...))` would be better",0,0.9931232333183289
107829914,2466,mjsax,2017-03-24T03:39:21Z,please fix this: `use { } instead`,0,0.9924160242080688
107830212,2466,mjsax,2017-03-24T03:42:17Z,nit: add missing `.` at the end.,0,0.9888486862182617
107830238,2466,mjsax,2017-03-24T03:42:34Z,nit: missing `.`,0,0.9742144346237183
107830487,2466,mjsax,2017-03-24T03:46:55Z,nit: add `final` twice,0,0.9780265688896179
107830501,2466,mjsax,2017-03-24T03:47:08Z,nit: add `final`,0,0.9897833466529846
107830511,2466,mjsax,2017-03-24T03:47:21Z,nit: add `final`,0,0.9897833466529846
107830528,2466,mjsax,2017-03-24T03:47:36Z,add `final`,0,0.9863189458847046
107830534,2466,mjsax,2017-03-24T03:47:45Z,nit: add `final`,0,0.9897833466529846
113301565,2466,mjsax,2017-04-25T20:28:20Z,"just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. would you mind to not move configs that get deprecate and add the new config at the ""right"" place. thanks a lot. :)",1,0.9954525828361511
113312440,2466,mjsax,2017-04-25T21:09:13Z,"just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. would you mind to not move configs that get deprecate and add the new config at the ""right"" place. thanks a lot. :)",1,0.9954525828361511
113312517,2466,mjsax,2017-04-25T21:09:35Z,"for backward compatibility, we need to keep the old default value. btw: we don't do any ordering here yet -- just above. so no need to reorder anything here.",0,0.9904036521911621
113312570,2466,mjsax,2017-04-25T21:09:50Z,as above: need to keep default value.,0,0.9852250218391418
113312651,2466,mjsax,2017-04-25T21:10:11Z,you can simple call `serde = defaultkeyserde()` here.,0,0.994288444519043
113312708,2466,mjsax,2017-04-25T21:10:27Z,"`.configure()` is called within `getconfiguredinstance()` already -- you can remove this line (i know this pattern was there before, but it's wrong -- can you please fit it :)) this can be a single liner within try-catch-block: `return getconfiguredinstance(default_key_serde_class_config, serde.class);`",0,0.9919328093528748
113312767,2466,mjsax,2017-04-25T21:10:44Z,as above,0,0.9391705989837646
113312830,2466,mjsax,2017-04-25T21:11:04Z,as above.,0,0.9878018498420715
113508449,2466,jeyhunkarimov,2017-04-26T17:02:32Z,"if we want to distinguish between `value_serde_class_config` and `default_value_serde_class_config` for example, in `public serde valueserde()` method, we have to differentiate whether ` serde serde = getconfiguredinstance(value_serde_class_config, serde.class); ` is default or not. if it is default, then we will call `defaultvalueserde()` method. if we don't set the default value to `null`, then its default value will be some object initialized with `serdes.bytearrayserde.class.getname()` class. in this case, it is hard to know whether the old `serde` (`value_serde_class_config`) is overridden (so we return it) or it has default value (so we call `defaultvalueserde() `method). moreover, because we are controlling the access to `value_serde_class_config` via `valueserde()` method, we handle `null` cases here as well. the same applies to `key_serde_class_config` and `timestamp_extractor_class_config` as well.",0,0.9957608580589294
113564584,2466,mjsax,2017-04-26T21:16:04Z,ah. makes sense!,1,0.9412059187889099
113564805,2466,mjsax,2017-04-26T21:17:08Z,it's actually pretty elegant! :),1,0.9961003065109253
113777778,2466,jeyhunkarimov,2017-04-27T19:06:41Z,"i think in `getconfiguredinstance() ` method, `configurable.configure(map configs)` method is called, but in `keyserde() `and `valueserde() `methods we need also to call `serde.configure(map configs, boolean iskey)` method. so i think the two `configure` methods are different.",0,0.9930040240287781
113808802,2466,mjsax,2017-04-27T21:37:30Z,`serde` implements `configurable` -- the object `o` in `((configurable) o).configure(originals());` is the serde object.,0,0.9940869808197021
113811258,2466,jeyhunkarimov,2017-04-27T21:50:46Z,"yes i want to say that `serde.configure(arg1, arg2)` is different from `configurable.configure(arg1)`. so, inside `getconfiguredinstance()` method it is not called `configure(arg1, arg2)` but `configure(arg1)`",0,0.9936263561248779
113829911,2466,mjsax,2017-04-28T00:13:13Z,i did have a closer look into the code. you are right. i also double checked and `serde` does actually not implement `configurable` (so there will also not be two calls what would be bad). sorry for the confusion -- and thanks a lot for pointing out that it is correct as is!!,-1,0.8056467771530151
115824780,2466,guozhangwang,2017-05-10T18:59:48Z,with this change how would the caller differentiate between the case that of a single subscribed topic v.s. a subscribed pattern?,0,0.9945963025093079
115825542,2466,guozhangwang,2017-05-10T19:02:52Z,could we add a similar function in `streamsconfig` as `keyserde` in which we capture the deprecated / new default values there so that we do not need to leak that logic here?,0,0.9956525564193726
115826174,2466,guozhangwang,2017-05-10T19:05:50Z,"related to the question i have before: in the `tostring` function at line 85, we are printing `topics:string`, and we canno tell if it is a pattern or a single topic right?",0,0.9928199648857117
115826873,2466,guozhangwang,2017-05-10T19:09:14Z,"why do we need to augment this function here? i.e. by the time the stream task is created, we should have populated the `sourcebytopics` map with the pattern matched topics already, so i'm not sure if the additional computational logic is needed? cc .",0,0.9917402267456055
115845233,2466,jeyhunkarimov,2017-05-10T20:33:16Z,"actually `""pattern[ ]""` string is just cosmetic part of the code snippet `""pattern["" + pattern + ""]""`. we don't use `""pattern""` string (anywhere in the code) for detecting if it is a single subscribed topic or subscribed pattern.",0,0.9934045672416687
115847989,2466,jeyhunkarimov,2017-05-10T20:45:21Z,you are right. the main reason that i put this extra function is that i was getting many fails in tests. there were some tests with no source nodes defined in the test topology or the defined source nodes are not related with partitions.,0,0.9272563457489014
115850388,2466,guozhangwang,2017-05-10T20:55:16Z,"hmm, maybe it's better to fix these tests than modifying the production-code? e.g. we can add some test-only function to fill the topics from the pattern in `` rule.",0,0.9892202019691467
115850952,2466,jeyhunkarimov,2017-05-10T20:57:43Z,i fixed the tests as well and added this code snippet too. i mentioned this in [a link],0,0.9736225008964539
115852641,2466,jeyhunkarimov,2017-05-10T21:05:15Z,"yes, once the source is defined and added to topology, we cannot tell if it is defined by name or by pattern. this was the case before this pr as well.",0,0.9927756786346436
115853285,2466,jeyhunkarimov,2017-05-10T21:08:34Z,but i got your point,0,0.9285346865653992
115907018,2466,guozhangwang,2017-05-11T05:24:18Z,"thanks for the explanation, makes sense.",0,0.5293073058128357
115907121,2466,guozhangwang,2017-05-11T05:25:37Z,yeah i think if the logic is not needed in real cases then we should not add that since it may hide some potential bugs. as long as the tests can be covered then we can get rid of the unnecessary logic.,0,0.9755107164382935
115925128,2466,jeyhunkarimov,2017-05-11T07:53:51Z,"i recognized this issue: `builder.stream(pattern.compile(""t.*""))`; // this line adds sourcenode with name ""t*"", (before this pr it was `""pattern[t*]""`) after that, in `streamtask:120` when one executes: `final sourcenode source = topology.source(partition.topic());` // where `partition.topic()` is ""t1"" here the `source` will be `null` because `topology.source()` is just key value lookup. so i moved extra extra lookup for patterns from `streamtask` to` topology.source()`",0,0.9914155602455139
116282834,2466,guozhangwang,2017-05-12T17:27:51Z,"hmm, in `topologybuilder#build` when we are adding the source node we will execute the pattern matching from the current topic metadata so the map should already be filled with the actual topic right? i think the problem, as i added in `sourcenodefactory#gettopics`'s comment, is that under debugging / unit testing environment, there is no topic metadata available to pass the topic list to `list gettopics(collection subscribedtopics)`. what we need to do to fix the unit tests then is to call `subscriptionupdates#updatetopics()` before calling `builder.build()` for regex involved tests. [code block]",0,0.9927424192428589
116317477,2466,bbejeck,2017-05-12T20:26:15Z,sorry for jumping in a little late. is correct about the test. an example for unit-testing with regex defined topics using the `topologybuilder` is `topologybuildertest#shouldsetcorrectsourcenodeswithregexupdatedtopics` (line 675),-1,0.9903334975242615
116348919,2466,jeyhunkarimov,2017-05-13T02:50:11Z,thanks for your comments. done.,1,0.844511866569519
281873083,6694,ableegoldman,2019-05-08T00:04:47Z,nit: use recordqueue.unknown instead of -1,0,0.9890351891517639
281885338,6694,ConcurrencyPractitioner,2019-05-08T01:27:58Z,"no problem, could fix that.",0,0.9563262462615967
282344028,6694,ableegoldman,2019-05-09T05:38:23Z,"can we add separate unit tests to confirm this produces the expected behavior? i think the jira had some examples highlighting why this is a problem, it would be good to convert those into tests to make sure we're really fixing the problem at hand :)",1,0.6659415364265442
282726631,6694,ConcurrencyPractitioner,2019-05-10T02:16:04Z,no problem. added a new test case to confirm behavior.,0,0.9648642539978027
289592039,6694,mjsax,2019-06-01T04:34:51Z,"can we add those method to the end of the class -- we have already a ""section"" for methods that we only need for testing.",0,0.9924595952033997
289592091,6694,mjsax,2019-06-01T04:37:43Z,"to be future prove, we should encode a version number as prefix in case we ever what to change this metadata. what about ` : ` with version number ""1"" ? also, line is too long. move both parameters to their own lines.",0,0.9913808703422546
289592181,6694,mjsax,2019-06-01T04:41:15Z,"i am not an expert on this api, but i would expect that even if we commit using the producer, the consumer should still be able to read the metadata. did you verify that we cannot retrieve the metadata if eos is enabled? if this is the case, i would claim it's a bug that need to be fix.",0,0.9461551904678345
289592249,6694,mjsax,2019-06-01T04:44:17Z,"we call `addrecords` during regular processing but only need to restore the partition time if a rebalance happened. hence, i don't think this is the right place to add this code. from my understanding, we should do this in `streamthread#rebalancelistener.onpartitionsassigned` instead? \cc to confirm/comment",0,0.9824249148368835
289592273,6694,mjsax,2019-06-01T04:45:41Z,we should not piggy-back test for new features to existing tests. it's better to add a new test method `shouldaddpartitiontimetooffsetmetatdataoncommit`,0,0.9944767355918884
289592283,6694,mjsax,2019-06-01T04:46:20Z,"nit: `shouldrestorepartitiontimeonrestart` -- ""update timestamp"" is a little fuzzy",0,0.9886125922203064
289609768,6694,ConcurrencyPractitioner,2019-06-01T15:48:41Z,"alright, i will check on that.",0,0.9771658182144165
289613688,6694,ConcurrencyPractitioner,2019-06-01T17:51:50Z,just realized the test i added included the test for commit mechanism anyways.,0,0.9875240325927734
289613963,6694,ConcurrencyPractitioner,2019-06-01T18:03:07Z,"ok, so after some checks, i have discovered the following: the producer and consumer are not assigned to the same topicpartition (however, that is not necessarily the reason for the failure i'm about to describe.) i'm not 100% sure if this was supposed to happen. when producer committed the transaction, that is supposed to mean the consumer group coordinator was notified to commit the offsets right? however, when the consumer available to streamtask is called (i.e. [code block]), null is returned (indicating no offsets were committed). producer's sendoffsetstotransaction requires the user to also enter a consumer group id (which is specified by user config) which we send the offsets to commit to. it is possible that unless the user specifies the right consumer group id, we would not be able to retrieve associated metadata.",0,0.9783632755279541
289677945,6694,ConcurrencyPractitioner,2019-06-03T03:17:38Z,"oh, thats a good suggestion. would need to change test location in that case.",1,0.8138227462768555
299187366,6694,abbccdda,2019-07-01T19:36:08Z,should we check for partition existence for 2 calls?,0,0.9927273988723755
299187593,6694,abbccdda,2019-07-01T19:36:56Z,better to append suffix for time variables like `timestampms`,0,0.9935682415962219
301350910,6694,mjsax,2019-07-09T00:14:07Z,"what do you mean by ""for 2 calls""? the call to `partitiontime()`? if the partition does not exists, it's a bug anyway and current code throws a npe. what do we gain by checking if the partition exists? there is still a bug and we would need to throw an exception, too, imho. what do we gain by manually throwing an exception?",0,0.8645113706588745
301351239,6694,mjsax,2019-07-09T00:15:46Z,"it's not a duration, hence, i am not sure if adding `ms` suffix helps much here? `timestamp` is always unix epoch in ms throughout the whole code base and we never add `ms` so far. thoughts?",0,0.9083617329597473
301351580,6694,mjsax,2019-07-09T00:17:51Z,might be better to use `recordqueue.unknown` instead of `no_timestamp` (cf. `clear()` below),0,0.9952084422111511
301351875,6694,mjsax,2019-07-09T00:19:26Z,wdyt about this?,0,0.5780844688415527
301354251,6694,mjsax,2019-07-09T00:32:55Z,"i sync with guozhang about this. it's not correct to get the committed offsets within `onpartitionsassigned()` callback, because the consumer might not have fetched/updated the offsets from the brokers. however, we should still move the off the main loop. we only need to initialize the partition time if we get a new task assigned. hence, we should move it into `assignedtasks#initializenewtasks()`?",0,0.981460452079773
301355250,6694,mjsax,2019-07-09T00:38:34Z,"not sure what you mean by this? a producer is never _assigned_ any partitions. we use the term _assigned_ for consumers only. can you clarify? absolutely. the `group.id` used to commit offsets via the producer must match the `group.id` used by the consumer to read those offsets. in kafka streams the `application.id` is used as `group.id` for the consumer and it's also passed into `producer.sendoffsetstotransaction()`. hence, i still think that we don't need to handle eos differently to get the partition-time. does this help?",0,0.9800691604614258
301355349,6694,mjsax,2019-07-09T00:39:05Z,nit: revert,0,0.8522955179214478
301668666,6694,ConcurrencyPractitioner,2019-07-09T16:02:31Z,"sure, no problem with that.",0,0.8051892518997192
301685923,6694,ConcurrencyPractitioner,2019-07-09T16:41:21Z,"ah, forgot that producer isn't assigned partitions. let me see what i can do to handle to the eos case then.",0,0.8811970949172974
309349352,6694,mjsax,2019-07-31T17:45:04Z,"this code would crash if the cast fails. to avoid the issue, we should add `setassignmenttostoredtimestamps` to `task` interface (and remove the cast here) and add an empty implementation of the method to `standbytask`. i would also rename the method to `initializetasktime()`",0,0.9932210445404053
309349964,6694,mjsax,2019-07-31T17:46:30Z,we don't need to add this any longer. we added `public long streamtime()` in another pr already.,0,0.9900617599487305
309351486,6694,mjsax,2019-07-31T17:49:54Z,"i think we should throw an exception for this case, because the added partitions of the queue are fixed and should never change (and we should never request the partition time for unknown partitions -- it we do this, it would indicate a bug and would should raise it as an exception). [code block]",0,0.9915586709976196
309351989,6694,mjsax,2019-07-31T17:50:59Z,"nit: can we rename this to `partitiontime` (to align the name to `streamtime()` method) -- in kafka, we usually omit the `get` prefix on getter methods, and a record has a ""timestamp"" while for a partition or task it's a ""time"" (of course, both a ""timestamp"" and a ""time"" is just a long and quite similar, whoever, it seems more accurate to refer to their semantic meaning correctly).",0,0.9918516278266907
309352168,6694,mjsax,2019-07-31T17:51:22Z,nit: rename to `setpartitiontime()` (cf. other comment from above) also rename parameter `timestamp -> partitiontime`.,0,0.9949967861175537
309352994,6694,mjsax,2019-07-31T17:53:16Z,"similar as above, we should throw an exception here.",0,0.9828747510910034
309354307,6694,mjsax,2019-07-31T17:56:06Z,nit: rename `timestamp -> partitiontime`,0,0.9941344857215881
309354740,6694,mjsax,2019-07-31T17:57:06Z,"why do we need to make `partitiontime` `public` ? in any case, please preserve the javadocs if you move the method.",0,0.9945857524871826
309355477,6694,mjsax,2019-07-31T17:58:36Z,"we merge another pr recently that updates `partitiontime` already (cf. below) -- hence, no need to add this any longer.",0,0.9935686588287354
309359552,6694,mjsax,2019-07-31T18:07:51Z,i don't understand the purpose of this method. why not just get the `partitiontime` of the task and commit it?,0,0.6678735017776489
309360061,6694,mjsax,2019-07-31T18:09:05Z,do you think it's worth to add a version number for the binary format of the committed offsets (i tend to think we should add a version number). i would also not encode the timestamps as `string` but as 8-byte binary long.,0,0.992259681224823
309362468,6694,mjsax,2019-07-31T18:14:41Z,so we need to log this at info level? seems error might be more appropriate because it actually indicates corrupted metadata? we should also update the error message accordingly: [code block],0,0.9930635094642639
309363884,6694,mjsax,2019-07-31T18:17:51Z,why is the return type not `void` (similar for `setassignmenttostoredtimestamps` below)? seem you added it for testing? i would prefer to keep it `void` and change the tests if possible.,0,0.9946228265762329
309364369,6694,mjsax,2019-07-31T18:18:53Z,nit: remove `get` prefix (similar below for `getpartitiontime()`,0,0.9929897785186768
309364980,6694,mjsax,2019-07-31T18:20:05Z,"instead of using 3 broker for this test, we should reconfigure the brokers to allow using eos with a single broker. to do this, we need to set `transaction.state.log.replication.factor=1` in the passed-in broker config (maybe something else... not 100% sure).",0,0.9935484528541565
309366581,6694,mjsax,2019-07-31T18:23:34Z,nit: simplify to `throws exception`,0,0.9933127760887146
309366881,6694,mjsax,2019-07-31T18:24:11Z,this seems to be rather complicate. just hard code the `appid` ?,0,0.6331450343132019
309367084,6694,mjsax,2019-07-31T18:24:29Z,why do we need a store for this test? i think a simple `builder.stream().to()` should be sufficient?,0,0.9904491305351257
309367958,6694,mjsax,2019-07-31T18:26:20Z,"not sure what your comment means. can you elaborate? (i think it makes sense to test with multiple partitions, but i am not sure if i understand the comment -- how id the default key partitioner related?)",0,0.7213061451911926
309368689,6694,mjsax,2019-07-31T18:27:42Z,"nit: rename `driver -> kafkastreams` (we always name it `kafkastreams` in test, and it would be good to keep the name for consistency)",0,0.9885658621788025
309369523,6694,mjsax,2019-07-31T18:29:34Z,"we don't need to sleep (in general, sleeping is bad practice because it makes test flaky), because when `close()` is called below, it is ensured that offsets are committed.",0,0.9440820217132568
309371664,6694,mjsax,2019-07-31T18:34:30Z,"why do we need this validation step? the partition time or stream time is not exposed in the `context` and thus, i don't understand what this step verifies? why do we need to check the topic name?",0,0.9585552215576172
309371951,6694,mjsax,2019-07-31T18:35:09Z,nit: rename `maxtimestamp -> partitiontime`,0,0.994272768497467
309372240,6694,mjsax,2019-07-31T18:35:52Z,why do we need to write two records?,0,0.9424091577529907
309373077,6694,mjsax,2019-07-31T18:37:56Z,this variable is accessed by multiple threads that thus should be declared `volatile`,0,0.9935122132301331
309373488,6694,mjsax,2019-07-31T18:38:57Z,unnecessary comment,0,0.6772856116294861
309373698,6694,mjsax,2019-07-31T18:39:30Z,no need to call `cleanup()` if we remove the state.,0,0.9928263425827026
309375797,6694,mjsax,2019-07-31T18:44:23Z,"we should not care about `record.timestamp()` imho, but instead use a second variable similar to `lastrecordedtimestamp`: something like `map expectedpartitiontimeperpartition`. this allows us to set an expected partition time per partition and compare it to the passed in `partitiontime` (what you now call `maxtimestamp`) if passed in partition time does not match expected partition time, we can just throw an `runtimeexception` what will kill kafkastreams and the test will eventually time out.",0,0.9891841411590576
309375948,6694,mjsax,2019-07-31T18:44:44Z,seem not to be required?,0,0.9882946014404297
309457372,6694,ConcurrencyPractitioner,2019-07-31T22:25:10Z,"ah, this was something i added after i discovered a bug during integration tests. what happened was that offsets are periodically right (that is, it is automated)? so imagine this, the partitiontime has advanced to 10 milliseconds. we commit that time, and then streams experienced some sort of failure (akin to a restart of streams). that would mean the locally stored partitiontime was reset to -1. let's say we start processing again, and the partition time is now 9. what happens is that 9 is the timestamp committed, not 10. it overwrites the previous committed timestamp. so what we need to do is retrieve the previously committed timestamp if there was any, and then commit _that_ one instead, since that is the correct one. i had some second thoughts on this, particularly since it becomes a little difficult to distinguish between restarts, cleanups, or failures which could have the same effect. so i'm not so sure if this is still needed or we still need to modify the behavior for these cases. the thing is without this method, the test that i have added at any rate fails.",0,0.8076217770576477
309457844,6694,ConcurrencyPractitioner,2019-07-31T22:27:03Z,"yeah, forgot to remove it during previous debugging.",0,0.8501573801040649
309459876,6694,ConcurrencyPractitioner,2019-07-31T22:34:50Z,"oh, the thing is this logic is neccessary, or otherwise the test will crash. if you were to look closely at [code block] logic, the class updates the partitiontime _after_ timestampextractor was called. this is important, because partitiontime is always passed in first. that means that [code block] is always passed in first when we first start processing, and if we always return maxtimestamp without checking if record.timestamp() is greater, than that means -1 will be returned no matter how many records are passed through timestampextractor. thus, what we do here is stimulate an update to partitiontime _before_ it is actually updated in [code block].",0,0.9724062085151672
309466633,6694,ConcurrencyPractitioner,2019-07-31T23:03:31Z,"alright, will do.",0,0.9772015810012817
309469061,6694,ConcurrencyPractitioner,2019-07-31T23:14:47Z,"actually, on further investigation, this method might not be needed. we will see.",0,0.9847545623779297
309478195,6694,mjsax,2019-08-01T00:01:01Z,"yes. yes, but you code return `return record.timestamp();` anyway. so for the second call of `extract()` method, `partitiontime` (ie, `maxtimestamp`) gets advanced. for a stop-restart of `kafakstreams`, with this fix on restart `partitiontime` should be `unknown` any longer, as it's should be initialized from the commit-metadata that is preserved. hence, we should see `unknown` only a single time, and the integration test should verify that we only see on the first start of `kafakstreams` but not for the second start. i cannot follow here. `partitiontime` is tracked internally and it will be updated after timestampextractor returns, base on the value that is provided in `return`.",0,0.9934775829315186
309749298,6694,ConcurrencyPractitioner,2019-08-01T15:07:52Z,"ah, but if we do throw a nullpointer here, the test i added fails. so i don't know if that is what we really should do.",-1,0.7746077179908752
309776403,6694,ConcurrencyPractitioner,2019-08-01T16:01:29Z,"yeah, accidentally removed it when i was rebasing the pr. will add it back.",0,0.6858945488929749
309795005,6694,ConcurrencyPractitioner,2019-08-01T16:45:43Z,"ah, okay. then i will change that.",0,0.9067351818084717
309917436,6694,mjsax,2019-08-01T22:12:31Z,not sure -- but maybe you setup the test incorrectly? `partitiongroup` constructor get a `map partitionqueues` and you should only call `setpartitiontimestamp()` for `topicpartitions` that are provided by this map. could this explain the test issue?,0,0.9858155250549316
309918847,6694,ConcurrencyPractitioner,2019-08-01T22:17:53Z,"oh, that might be the case. i was going through the consumer assignment's topic partitions instead. will check it out.",0,0.954410195350647
309933316,6694,ConcurrencyPractitioner,2019-08-01T23:23:00Z,"well, i put the sleep there because otherwise the test (eos enabled case) breaks. i have done quite a bit of digging, and it appears what happens is that the committed metadata retrieved is incorrect after the streams restart. i added some debug statements, and the strange thing is though is that committed() doesn't return the right metadata. i made two calls to committed() -- this is during initializetasktime() -- and the first call returns the incorrect metadata (the result suggests that no offsetandmetadata was committed), yet on the second call, it returns the correct metadata (perhaps because this time offsetandmetadata has been persisted and could now be returned by committed()). the sleep() method i put there because it seems that offsetandmetadata needs enough time to actually persist in kafka log in eosenabled=true case, otherwise, consumer#committed() returns inconsistent results.",0,0.7628995776176453
309968392,6694,ConcurrencyPractitioner,2019-08-02T03:13:55Z,"oh, i could remove them. done that.",0,0.9839038848876953
310275056,6694,abbccdda,2019-08-02T19:50:28Z,nit: space before `no-op`,0,0.9906952381134033
310275504,6694,abbccdda,2019-08-02T19:52:04Z,is old metadata missing expected after we start off? might be useful to add a debug log or trace if this is not normal.,0,0.9919393658638
310275800,6694,abbccdda,2019-08-02T19:53:05Z,would be favorable to order comparison result according to first citizen. like `metadatatimestamp >= localpartitiontime ? metadatatimestamp : localpartitiontime;`,0,0.932159423828125
310275999,6694,abbccdda,2019-08-02T19:53:45Z,maybe refactor out a helper for the above condition?,0,0.9937730431556702
310276422,6694,abbccdda,2019-08-02T19:55:06Z,why `-1`?could we define a constant referring to it?,0,0.9937834739685059
310276582,6694,abbccdda,2019-08-02T19:55:38Z,this comment is not needed.,0,0.9740467071533203
310276679,6694,abbccdda,2019-08-02T19:56:00Z,s/time stamp/timestamp,0,0.9827370643615723
310276764,6694,abbccdda,2019-08-02T19:56:17Z,would be good to define `1000` as a variable.,0,0.9873701333999634
310276812,6694,abbccdda,2019-08-02T19:56:26Z,same here,0,0.9628711938858032
310319615,6694,mjsax,2019-08-02T22:50:32Z,we can remove this method -- it's declared in the interface and there is no need to have an implementation in `abstracttask`,0,0.9932793974876404
310320109,6694,mjsax,2019-08-02T22:53:28Z,can `setpartitiontime()` be package-private?,0,0.9944359064102173
310320883,6694,mjsax,2019-08-02T22:58:18Z,still not sure why we need this method? (or did you forget to remove it?),0,0.9396858811378479
310321420,6694,mjsax,2019-08-02T23:02:07Z,why do we call `initializetasktime` in `addrecordstotasks()` -- in a previous version it was called in `initializenewtasks()` what seems to be more appropriate -- why did you move it?,0,0.9949232935905457
310321680,6694,mjsax,2019-08-02T23:03:47Z,"nit: `shouldpreservepartitiontimeonkafkastreamrestart` (nothing is reset in this test). (also, avoid naming overlap with `kstream` and `ktable`)",0,0.9950070381164551
310321935,6694,mjsax,2019-08-02T23:05:34Z,why do we need to suffix the appid and topic names with the `testid` ?,0,0.9948037266731262
310322139,6694,ConcurrencyPractitioner,2019-08-02T23:06:58Z,"well, since before, we never stored any metadata in kafka log, especially relating to committed timestamps. there is a possibility that an old version of offsetandmetadata is committed where it doesn't contain the committed timestamp, so i suppose this is expected behavior.",0,0.9932336211204529
310322225,6694,ConcurrencyPractitioner,2019-08-02T23:07:37Z,"well, the order in general doesn't seem to matter that much. but could change it.",0,0.9747978448867798
310322293,6694,ConcurrencyPractitioner,2019-08-02T23:08:04Z,"yeah, it looks like it appeared several times in the code, might want to add it as some separate static helper method.",0,0.9841837882995605
310322589,6694,mjsax,2019-08-02T23:10:17Z,"that is weird. \cc how could the happen? if we stop the first instance, the transactions should be committed and afterwards, if we start a new instance, the new consumer client should be able to read the correct offset and metadata. any idea?",-1,0.9930315017700195
310323805,6694,ConcurrencyPractitioner,2019-08-02T23:19:48Z,"oh, tried to run a test without this method, but abstracttasktest would break unfortunately if this method is not implemented in abstracttask (apparently, abstracttask's constructor is called, and compiler complains about it as a result).",0,0.5577567219734192
310324030,6694,ConcurrencyPractitioner,2019-08-02T23:21:31Z,"oh, actually, yeah, we can remove this method. we could just modify the abstracttasktest itself.",0,0.973206639289856
310324216,6694,ConcurrencyPractitioner,2019-08-02T23:22:56Z,"sure, there shouldn't be any problems.",0,0.8605420589447021
310324305,6694,ConcurrencyPractitioner,2019-08-02T23:23:33Z,"ok, no problem.",0,0.908890962600708
310324616,6694,ConcurrencyPractitioner,2019-08-02T23:26:15Z,just thought it would be a good idea to include more information in the the id names. they can be hardcoded.,0,0.9694836139678955
310324663,6694,ConcurrencyPractitioner,2019-08-02T23:26:36Z,done.,0,0.9640594124794006
310327228,6694,ConcurrencyPractitioner,2019-08-02T23:51:20Z,"ok, i realized what is happening. during the process to close a streamtask, the partitiontimes are reset to -1 first before the local partition times are committed. effectively, what is occurring is that we are committing -1 during close() due to the order of operations we are performing it. i have found a solution to it, so i will push a change shortly.",0,0.9497123956680298
310327593,6694,mjsax,2019-08-02T23:55:17Z,good find!,1,0.9923742413520813
310704615,6694,ConcurrencyPractitioner,2019-08-05T17:10:51Z,"how would you do that though? i don't think offsetandmetadata could store an 8-byte binary long directly, so we have to use encode and decode the byte array as some string. is that how we should do it?",0,0.9814206957817078
310707714,6694,ConcurrencyPractitioner,2019-08-05T17:19:15Z,i was thinking about using utf8 conversions.,0,0.7428737282752991
310722093,6694,mjsax,2019-08-05T17:56:43Z,"good pointed. i missed that the type is `string` (expected it to be `byte[]`). hence, for efficient encoding, and to allow us to add a magic/version byte, we should first serialize the timestamp, prefix it with a magic byte and then ""deserialize"" it to `string`. [code block]",1,0.6434541940689087
310764557,6694,ConcurrencyPractitioner,2019-08-05T19:50:43Z,"okay. i pushed a version of what i thought was pretty close to the process you were describing. mind taking a look? at the moment, it doesn't seem to work though. i did some research and what we are using is basically utf8 encodings. it did look like however that some information was lost. (i did some debug statements and found that the decoded value was 1007 instead of 1000, somewhat bizarre).",0,0.5460754632949829
310803256,6694,ConcurrencyPractitioner,2019-08-05T21:39:26Z,"alright, i have done thorough investigations and here is what i found. i came across the following on stack overflow: [a link] if one looks closely, they would quickly realize that utf8 is not fit for the task at hand. in reality, we would need to do something like using base64 encodings instead (which is supposedly part of java since version 1.8). however, gradle does not allow the usage of base64 since it ""could not be found"" according to the compiler anyways. in conclusion, i don't think the current approach as it is will work. if things don't progress any further, i'd suggest sticking with the original idea of just sticking the long unencrpyted directly into the string (plus a version number). your thoughts ?",0,0.9375336766242981
311705840,6694,mjsax,2019-08-07T18:42:09Z,`task` is of type `task` -- no need to cast :),1,0.932621955871582
311707813,6694,mjsax,2019-08-07T18:46:49Z,"good find! how did you try to use it? everything from the standard library should be available... i would prefer to use base64 if we can. if not possible, we can still fall back to using string, but i would really like to avoid it if we can.",1,0.9881796836853027
311713153,6694,mjsax,2019-08-07T18:59:17Z,nit: avoid changes in unrelated files,0,0.8806718587875366
311714343,6694,mjsax,2019-08-07T19:02:03Z,why not do this unconditionally? if it's not `clear` we won't commit anyway. it's seems cleaner to avoid to many branches and it's not on the hot code path so the overhead of updating `partitiontime` is not relevant.,0,0.9901424646377563
311714674,6694,mjsax,2019-08-07T19:02:49Z,i am not sure why we need this variable? can you elaborate?,-1,0.5013667345046997
311817120,6694,ConcurrencyPractitioner,2019-08-08T00:45:54Z,"alright, that's fine.",0,0.9265199899673462
311817419,6694,ConcurrencyPractitioner,2019-08-08T00:47:53Z,"oh, because we need to differentiate between a commit that is triggered by a regular process or by a close. if we call partitiontime() in a commit triggered by a close() call, then partitiontime() would always return -1. (recall that due to the order of operations in close, the partition times has been reset to -1 first before the commit call was made).",0,0.9792110323905945
311819651,6694,ConcurrencyPractitioner,2019-08-08T01:01:37Z,"ah okay, so this is the error that i've found. [code block] notice that the package name does not start with java. it might be some third party library that gradle does not account for.",0,0.9080634117126465
311819717,6694,ConcurrencyPractitioner,2019-08-08T01:02:01Z,this might help explain why base64 might not be used.,0,0.9848724603652954
311820182,6694,ConcurrencyPractitioner,2019-08-08T01:05:13Z,yeah. my bad. didn't realize t extends task.,-1,0.9915750622749329
311849604,6694,mjsax,2019-08-08T04:14:21Z,seem you include the wrong class/package: [a link],0,0.9690057039260864
311850528,6694,mjsax,2019-08-08T04:20:46Z,is the any advantage of this library compare to [a link] \cc,0,0.964503288269043
311851742,6694,mjsax,2019-08-08T04:30:36Z,"thanks. understood. it might be better, to actually change `stream#commit(boolean startnewtransaction)` to accept a second parameter `map partitiontimes` to pass in the information. in `close()` before we actually ""loose"" the timestamps we preserve them and pass into `commit()` later. in a regular `commit()` we get the timestamps from the `partitiongroup` (ie, some code that is now in `commit(boolean)` would go into `commit()`). this would avoid the requirement to introduce the flag and make the code more readable, because decision are more local an encapsulated in each method without cross-method dependencies.",1,0.7711591720581055
311852052,6694,mjsax,2019-08-08T04:32:39Z,we should return `recordqueue.unknown` instead.,0,0.9926712512969971
311852198,6694,mjsax,2019-08-08T04:33:39Z,"same as above: also, we should log a warn message there, that the the found metadata is corrupted and cannot be decoded.",0,0.9910275340080261
311859113,6694,ConcurrencyPractitioner,2019-08-08T05:20:50Z,"actually, just realized that this library existed. :p didn't know until later. will remove this dependency (the old bouncycastle one).",1,0.7760545015335083
311862190,6694,ijuma,2019-08-08T05:38:39Z,sounds good.,1,0.9417163729667664
312137582,6694,ConcurrencyPractitioner,2019-08-08T16:48:16Z,"oh, sure, that would work.",0,0.9374471306800842
312165368,6694,mjsax,2019-08-08T17:51:53Z,"passing in `null` is not idea imho. at this point, we _know_ that we want to get the timestamps from the `partitiongroup`. hence, seems better to build up the correct `map< topicpartition, long>`, by looping over all committed offsets: [code block]",0,0.9844731688499451
312165647,6694,mjsax,2019-08-08T17:52:27Z,i think we don't need this method if we apply my other suggestions,0,0.93585205078125
312166158,6694,mjsax,2019-08-08T17:53:38Z,"input parameter `partitiontimes` should always contain the correct partition time, hence, we can just get it: [code block]",0,0.9897346496582031
312166420,6694,mjsax,2019-08-08T17:54:11Z,nit: `partitiontimemap` -> `partitiontimes`,0,0.9939101934432983
312167539,6694,mjsax,2019-08-08T17:56:37Z,this block can be moved outside of the `try-catch-block`,0,0.9941800832748413
312167714,6694,mjsax,2019-08-08T17:56:57Z,i guess we can remove this comment,0,0.9115568995475769
312169542,6694,mjsax,2019-08-08T18:00:42Z,might be good to add an `else` and also add a debug log stating that no committed offset was found,0,0.9947646856307983
312170299,6694,mjsax,2019-08-08T18:02:20Z,this method is not only _receiving_ but also _setting_ the partition time. what about renaming it to `initializepartitiontime()`,0,0.9910734295845032
312170692,6694,mjsax,2019-08-08T18:03:15Z,return type is `void` -- remove this line,0,0.99136883020401
312171157,6694,mjsax,2019-08-08T18:04:15Z,nit: add comment `// visible for testing` (same for decodetimestamp() below) also add test methods to `streamtasktest` to test both methods.,0,0.9928845763206482
312171865,6694,mjsax,2019-08-08T18:05:40Z,"nit: (simplify to) `""unsupported offset metadata version found. supported version {}. found version {}.""`",0,0.9892310500144958
312235875,6694,mjsax,2019-08-08T20:47:29Z,nit: could we use `getstartedstreams()` again?,0,0.9934346675872803
312237424,6694,mjsax,2019-08-08T20:51:27Z,"`assertthat(task.decodetimestamp(consumer.committed(partition1).metadata()), equalto(default_timestamp));` simplify `task.cosumer` -> `consumer`",0,0.9952507019042969
312238609,6694,mjsax,2019-08-08T20:54:22Z,nit: remove unnecessary comment,0,0.6970692873001099
312239083,6694,mjsax,2019-08-08T20:55:32Z,nit: remove unnecessary comment,0,0.6970692873001099
312239225,6694,mjsax,2019-08-08T20:55:50Z,nit: remove unnecessary comment,0,0.6970692873001099
312289819,6694,mjsax,2019-08-09T00:06:23Z,"this test setup defeats the purpose fo this test. if eos is enabled, the producer is used to commit offsets, and thus, we should check if the producer does commit the corresponding metadata correctly. therefore, we need to change the test setup a little bit. in `createstatelesstask()`, we create an anonymous `producersupplier` and we need to get hold off the generated mock-producer instance. we can then use `mockproducer#consumergroupoffsetshistory` to get the committed offsets and metadata.",0,0.9894800186157227
312289927,6694,mjsax,2019-08-09T00:07:06Z,as above (similar below),0,0.9875968098640442
312309368,6694,ConcurrencyPractitioner,2019-08-09T02:23:56Z,done that.,0,0.9776254296302795
312581629,6694,mjsax,2019-08-09T17:38:06Z,not 100% sure if we nee this `null` check any longer after the refactoring. \cc wdyt?,0,0.9253356456756592
312588676,6694,mjsax,2019-08-09T17:57:06Z,"seems we should test `partitiontimestamp` above already, when we `verifybuffered(6, 3, 3);` ? also, we should check the returned time for both partitions each time? i would also add a test of `group.streamtime()` for each step in the test (not sure why it's missing -- this would be a good additional improvement).",0,0.9920841455459595
312588867,6694,mjsax,2019-08-09T17:57:43Z,we should test this method in it's own test method,0,0.9938886165618896
312589597,6694,mjsax,2019-08-09T17:59:44Z,"use `assertthrows` instead of the try catch block, and use `assertthat` to verify the exception message. also, this should be two tests, one for ""set"" and one for ""get"".",0,0.9942268133163452
312590312,6694,mjsax,2019-08-09T18:01:52Z,"in addition, we should check if ""stream time"" was updated correctly. nit: `assertequals` take ""excepted value"" as first parameter, so you need to flip both (otherwise the error message would be confusing if the test fails)",0,0.9932286739349365
312592021,6694,mjsax,2019-08-09T18:07:04Z,please rewrite using `assertthat` (or at least `assertequals`) -- similar below,0,0.9951423406600952
312592448,6694,mjsax,2019-08-09T18:08:18Z,"we should add more test method for the different error cases, too.",0,0.9878317713737488
312593338,6694,mjsax,2019-08-09T18:10:52Z,"this whole block (l680-687) can be remove -- there is no need for the test to commit anything in addition. note that the `assert` above tests the previous `commitsync()` what is not useful, as test-code should not test other test-code :)",1,0.9291390180587769
312595808,6694,mjsax,2019-08-09T18:17:49Z,no need to use a nested for loops. this can be simplified to: [code block],0,0.9904367327690125
312634550,6694,ableegoldman,2019-08-09T20:18:36Z,"yeah, i don't see how a partition could be in `consumedoffsets` but not in `partitiontimes`?",0,0.9645763635635376
313846296,6694,cadonna,2019-08-14T12:26:00Z,why do you need this assertion? `close()` waits for `long.max_value` for state `not_running`.,0,0.9908484220504761
313850160,6694,cadonna,2019-08-14T12:36:04Z,the order of the imports in kafka streams is usually as follows: kafka imports and 3rd-party imports in one block a block of `java.*` imports `import static`.,0,0.9950717091560364
314216469,6694,cadonna,2019-08-15T08:26:06Z,"wouldn't creating a new task be better? afaik, that is what happens during a restart. no need to simulate anything. furthermore, it avoids introducing a new method just for testing.",0,0.981421709060669
314220806,6694,cadonna,2019-08-15T08:39:56Z,"would be good to extract `""stream-task-test""` to a member field of the test and use it in `createconfig()` and here.",0,0.9935686588287354
314221852,6694,cadonna,2019-08-15T08:43:09Z,see above,0,0.9138815402984619
314223844,6694,cadonna,2019-08-15T08:49:05Z,see above,0,0.9138815402984619
314223931,6694,cadonna,2019-08-15T08:49:18Z,why do we need this assertion here?,0,0.9807620644569397
314226105,6694,cadonna,2019-08-15T08:55:49Z,"i see that you tested the different error cases as suggested. however, i would put each test in its own test method.",0,0.9863220453262329
314227123,6694,cadonna,2019-08-15T08:58:51Z,see my comment on the usage of this method in `streamtasktest`.,0,0.9918580651283264
314230884,6694,cadonna,2019-08-15T09:09:53Z,i would put methods to write and read record metadata in their own classes. those classes would be kind of serdes for metadata. such serdes would make the code better testable and separates the concerns of a task and reading and writing metadata which are completely independent. it does not need to be done in this pr. i just wanted to mention it.,0,0.9803920388221741
314236760,6694,cadonna,2019-08-15T09:28:24Z,please remove empty line before this line.,0,0.9876833558082581
314238406,6694,cadonna,2019-08-15T09:33:50Z,"this tests misses to verify whether `streamtime` is set or not. furthermore, i would write two (or three) distinct tests: - `partitiontimestamp` is set (could be further split for `streamtime` is set or not) - `nullpointerexception` is thrown",0,0.9944985508918762
314241100,6694,cadonna,2019-08-15T09:42:10Z,the code block from the beginning of the method until here can be extracted and re-used in this and the previous test methods.,0,0.9939576387405396
314241548,6694,cadonna,2019-08-15T09:43:59Z,"i think, we use `should...` for newly added test methods.",0,0.9896739721298218
314375243,6694,ConcurrencyPractitioner,2019-08-15T15:49:28Z,its just to confirm that there's no problems with the state being removed. thought it would be good to keep that at the very least.,0,0.97092604637146
314398959,6694,ConcurrencyPractitioner,2019-08-15T16:46:54Z,"yeah, that would probably be a good idea in the future.",0,0.9477941989898682
314402987,6694,ConcurrencyPractitioner,2019-08-15T16:57:09Z,"yeah, it can be removed. its somewhat redundant.",0,0.7314488291740417
320293937,6694,cadonna,2019-09-03T14:11:38Z,here it would be better to call `partitionqueues.get(partition)` only once and store its result in a variable. then check the variable for `null` and call `partitiontime()` on the variable.,0,0.9928787350654602
320294207,6694,cadonna,2019-09-03T14:12:03Z,same as above.,0,0.9857698678970337
321203916,6694,cadonna,2019-09-05T11:18:20Z,"i am wondering whether we can do better here. encoding partition time in base64 seems to me a bit a waste of space. as far as i can see, a 8 byte value is encoded in 11 bytes with base64. would be great, if we could store partition time in 8 bytes. i am also wondering why `metadata` in `offsetandmetadata` is a `string` and not something more bytes friendly.",0,0.9128255248069763
321938111,6694,ConcurrencyPractitioner,2019-09-06T23:14:51Z,"yeah, it is still unclear at this point if the [code block] field in [code block] could be used in this manner. or knows this matter better. anyhow, offsetandmetadata right now is the only medium through which we can checkpoint partition time anyways. so we might be stuck with using the [code block] field.",0,0.8659355044364929
323392057,6694,mjsax,2019-09-11T18:25:53Z,"i know that i recommended to add this parameter, but now, after more refactoring of the code, i am not sure any longer why we need it? it seems that this method is called twice and both calls pass in the result of `extractpartitiontimes()` as parameter -- hence, it seems we can remove the parameter and do the call to `extractpartitiontimes()` within the method itself?",0,0.9840240478515625
323397342,6694,mjsax,2019-09-11T18:37:46Z,"this is a blocking call, and just proposed kip-520 to make it more efficient by allowing to pass in multiple partitions at once. should we wait for kip-520 to be implemented? if now, we should make sure the update this code after kip-520 is merged. i am also wondering how we should handle `timeoutexception` for this call? maybe not, but might be worth to clarify? \cc",0,0.9768185615539551
323496050,6694,mjsax,2019-09-11T23:03:23Z,"i don't have the full context on the history, but it would not be easy to change the api... i talked to jason about it, and it seem we can just move forward with this pr as-is, and could do a kip later that allows us to store metadata as `byte[]` type if we really need to change it. atm, the metadata is just a few bytes and the overhead does not really matter imho.",0,0.8660663962364197
323621863,6694,cadonna,2019-09-12T08:40:55Z,agreed,0,0.9622275233268738
324510011,6694,mjsax,2019-09-16T04:55:22Z,i remember now -- can we add a comment to explain that we need to get `partitiontimes` before we `closetopology()` (sorry for my previous comment -- forgot about that),-1,0.9844421744346619
324917516,6694,guozhangwang,2019-09-16T22:48:38Z,in my pr ([a link] i've refactored this part in streamtask. i'd suggest we merge that one before this.,0,0.9853593111038208
324926772,6694,ConcurrencyPractitioner,2019-09-16T23:29:05Z,"cool, got it done.",1,0.8305388689041138
325385581,6694,guozhangwang,2019-09-17T21:05:42Z,just realized i need to do another rebase on my pr. so if this pr is closer to be merged i'd suggest you guys just move forward and i will rebase mine later.,0,0.966602087020874
325432250,6694,ConcurrencyPractitioner,2019-09-17T23:53:00Z,"cool, sounds good. in that case, we could get this one merged since it is about complete.",1,0.9362577199935913
184775884,4931,rhauch,2018-04-27T18:47:37Z,it'd be nice to have javadoc for this interface (and all other public api types) that explains the purpose.,0,0.9639373421669006
184776184,4931,rhauch,2018-04-27T18:48:44Z,"nit: this method returns a list of connector _names_, not connector instances.",0,0.9914754629135132
184776264,4931,rhauch,2018-04-27T18:49:05Z,how about just `connectorstate`?,0,0.9933650493621826
184776561,4931,rhauch,2018-04-27T18:50:16Z,"missing javadoc on the type and method. imo, the javadoc on the interface should fully describe how to provide an implementation (by implementing this class, but what about other interfaces), how to package it (e.g., java service provider file), and how to install it (put it on the plugin path). it should also go into detail about how connect uses this interface, when implementations are instantiated and when the register method is called, and when the close method is called. what exceptions can be thrown by this method? will the supplied context ever be null? what are the behaviors that are expected/allowed? what happens when a resource is already registered?",0,0.9909281134605408
184777667,4931,rhauch,2018-04-27T18:54:30Z,"it should be clear that implementations are provided by the framework, but it should be clear what this does and how it can be used by extension implementations.",0,0.9919846653938293
184777830,4931,rhauch,2018-04-27T18:55:11Z,"why not an interface? that would offer us so much more flexibility in the implementation, and all of the implementation details can be hidden from the public api. by having the nested classes here, they are in the public api and need to be managed through kips.",0,0.989427387714386
184778299,4931,rhauch,2018-04-27T18:57:11Z,minor: let's not add unnecessary whitespace.,0,0.960259735584259
184778412,4931,rhauch,2018-04-27T18:57:41Z,unnecessary whitespace.,0,0.9008945226669312
184778471,4931,rhauch,2018-04-27T18:57:58Z,this can be `final`.,0,0.9902233481407166
184778842,4931,rhauch,2018-04-27T18:59:34Z,how about javadoc that explains that this class is for hiding the jax-rs framework implementation and for handling registration of duplicate resources.,0,0.9896590113639832
184779307,4931,rhauch,2018-04-27T19:01:24Z,"as i mentioned earlier, we need to use java service provider api to find which plugin has the specified implementation, and we should change plugins to support creating these instances. this code only works if the implementations are on the classpath.",0,0.9908554553985596
184829319,4931,mageshn,2018-04-27T23:48:41Z,yes agreed. i still haven't integrated with the plugin classloader yet. hence used this method for the draft so that we get a better picture of the public interfaces.,0,0.9782556891441345
184829507,4931,mageshn,2018-04-27T23:51:05Z,connectorstatedetails provides both the connectorstate and connector taskstate. the original entity class has a name of connectorstateinfo but didn't want to use the same name because i thought it might be a little confusing,0,0.7725841999053955
184829705,4931,mageshn,2018-04-27T23:53:26Z,"the nested classes are also technically part of the public api since user can access it. but imo, having interfaces for pojo or entities might be a little bit of overhead. the only thing we can hide by making it an interface is the constructor.",0,0.9463666081428528
184830969,4931,rhauch,2018-04-28T00:09:38Z,"using an interface gives us more options on the implementation side, and it helps clarify intentions more explicitly and minimally, without exposing implementation details.",0,0.9851412773132324
184830991,4931,rhauch,2018-04-28T00:09:56Z,or maybe just `connectordetail` or `connectordescription`?,0,0.9937771558761597
184831075,4931,rhauch,2018-04-28T00:11:01Z,"is it intentional that these tasks are ordered? to the indexes correspond to the task id? if not, perhaps a collection is sufficient, or a map keyed by task id.",0,0.9936748147010803
185244935,4931,rhauch,2018-05-01T15:12:34Z,"first, the iterator returned by the `serviceloader.load` method will be instances of `t`, not `class `, so the call to `addplugindesc` above should result in a class cast exception. third, since these are already instantiated by the serviceloader and match the specified type, why not forgo the logic in `addplugindesc` and simply instantiate a `plugindesc like the only thing we need to do is finally, `serviceloader` is `iterable`, which means the iterator logic can be simpler. put all these three together: [code block] in order to do this, we would need to add a `versionable` interface so that connector and rest extension can extend it.",0,0.9875553250312805
185245899,4931,rhauch,2018-05-01T15:16:10Z,"i know that much of this logic was from the original code, but it might be good to add some debug/trace log messages here, especially in the missing `else` condition (e.g., ""skipping {} since it is not a concrete type."").",0,0.9881613254547119
185246193,4931,rhauch,2018-05-01T15:17:10Z,this won't work for interfaces other than `connector`.,0,0.9755723476409912
185256557,4931,mageshn,2018-05-01T15:56:01Z,"good catch on the serviceloader returning an implementation. having said that, do you think we should cache these implementations instead of creating an instance ourselves? i don't personally see a benefit to using the same instance the one returned by the serviceloader.",0,0.7677516341209412
185260491,4931,rhauch,2018-05-01T16:12:16Z,"if we can make this method more generic or general purpose, then this method should probably be called within a conditional block checking whether it implements `configurable`.",0,0.9916942715644836
185261384,4931,rhauch,2018-05-01T16:15:52Z,this method does not have much logic that is specific to `connectrestextension`. have you thought about making this more general-purpose to load any extensions (other than when a more specific method is available)? doing that might make it easier to add future extensions.,0,0.9912019968032837
185262140,4931,rhauch,2018-05-01T16:18:36Z,"the serviceloader is usually just used directly to load all instances of a particular extension point, but that's not really what we do. and really there's nothing special about _how_ serviceloader instantiates the class: it really just does a new instance on the class.",0,0.9561070799827576
185262431,4931,rhauch,2018-05-01T16:19:51Z,"btw, we should have a test case that loads a test implementation of `restextension` using plugins.",0,0.992449164390564
185384782,4931,mageshn,2018-05-02T03:11:12Z,"yes, i will be adding more tests. once we all agree on the public interfaces, i will update the kip and refine this pr",0,0.9513433575630188
185385261,4931,mageshn,2018-05-02T03:17:30Z,would be good to have state or status in there since its just not a connectordescription,0,0.9881188273429871
185537702,4931,rhauch,2018-05-02T15:26:54Z,"use ""component"" rather than ""plugin""?",0,0.9943863153457642
185539183,4931,rhauch,2018-05-02T15:30:46Z,"how about `connectorhealth`, since this is likely to be used by health check extensions? the `detail` in `connectorstatedetail` just seems superfluous to me.",0,0.9588490724563599
185540424,4931,rhauch,2018-05-02T15:34:18Z,suggest at a minimum:,0,0.9869519472122192
185540807,4931,rhauch,2018-05-02T15:35:30Z,this logic is in two places. how about a helper method? if it were named `vesrionfor(class clazz)` then it could be more easily inlined where it's used.,0,0.9942125678062439
185892000,4931,wicknicks,2018-05-03T18:13:24Z,"maybe you guys have already talked about this, but does it make sense to have a per extension prefix for the configs? similar to how it is done for transformations?",0,0.9897458553314209
185893483,4931,wicknicks,2018-05-03T18:18:40Z,should we pass in `connectrestextensioncontext` with the `newconnectrestextensions(..)` method above? it will be cleaner to create and register the plugin in one place.,0,0.994255006313324
185903792,4931,wicknicks,2018-05-03T18:56:19Z,"yeah, i agree with randall here. `detail` is not a good fit here. maybe you can use `connectorscontext`?",0,0.960147500038147
185904747,4931,wicknicks,2018-05-03T18:59:53Z,should we expose connector metrics here? it could be a good fit for the health check resource in the kip).,0,0.9915709495544434
186196449,4931,kkonstantine,2018-05-04T19:43:23Z,i think we are stretching the use `-able` here. i'd suggest `versioned` as one of the less frequent cases where we'd use an adjective that does not and in `-able` but which makes a lot of sense for the functionality that this interface describes.,0,0.9877303242683411
186197396,4931,kkonstantine,2018-05-04T19:47:59Z,javadoc?,0,0.9876783490180969
187750001,4931,kkonstantine,2018-05-11T22:52:32Z,i think we are stretching the use -able here. i'd suggest `versioned` as one of the less frequent cases where we'd use an adjective that does not and in -able but which makes a lot of sense for the functionality that this interface describes.,0,0.9829278588294983
187750848,4931,kkonstantine,2018-05-11T23:00:25Z,nit: missing ``,0,0.8780630826950073
187750866,4931,kkonstantine,2018-05-11T23:00:33Z,nit: missing ``,0,0.8780630826950073
187756954,4931,kkonstantine,2018-05-12T00:10:00Z,"if we want to be precise, we shouldn't mention `list` here. this is implementation specific but the interface could return a set or actually anything that is a `collection`. i'd love if we could rephrase the descriptions here to keep our options open.",0,0.9457971453666687
187757323,4931,kkonstantine,2018-05-12T00:15:16Z,"i'd suggest referring to plugin path as only `plugin.path` and basically when it makes more sense referring to the parameter. maybe here you could replace with something like: `for the connect's class loader's to be able to discover the ...""",0,0.9929136633872986
187757374,4931,kkonstantine,2018-05-12T00:16:11Z,typo? `place` -> `placed`? also maybe rephrase into shorter sentences to make easier to follow?,0,0.9946796298027039
187757473,4931,kkonstantine,2018-05-12T00:17:59Z,"i'm torn about upper casing here. feels like lower cased words make more sense: `security (authentication and authorization), logging, request validations, etc`. ...",-1,0.9550309777259827
187757938,4931,kkonstantine,2018-05-12T00:25:48Z,"nit: framework means connect here i assume. so, maybe it's better to call this out as: `connect` or `connect framework`",0,0.9938303828239441
187758006,4931,kkonstantine,2018-05-12T00:27:05Z,nit: again i'd use lower case for anything that's not a name or a code class (mostly): `connect resources`,0,0.9781784415245056
187758037,4931,kkonstantine,2018-05-12T00:27:34Z,nit: extra blank line,0,0.7656126022338867
187758071,4931,kkonstantine,2018-05-12T00:28:08Z,nit: `provides the ability`?,0,0.9936138987541199
187758104,4931,kkonstantine,2018-05-12T00:28:58Z,`the connect framework`? which framework?,0,0.9944275617599487
187758167,4931,kkonstantine,2018-05-12T00:29:55Z,description is missing. i'm not a fan of javadoc that contains only ``. maybe most text could be in the description and `` could be brief.,-1,0.9275285601615906
187758286,4931,kkonstantine,2018-05-12T00:31:44Z,"typos: return a -> return an (no 1+ spaces), ot -> to",0,0.9878566265106201
188085678,4931,kkonstantine,2018-05-14T20:22:57Z,this applies unchecked overriding of the return type. in `connectrestextensioncontext` its `configurable ` and the same should be used in the member field as well as the return type here.,0,0.9951704144477844
188085791,4931,kkonstantine,2018-05-14T20:23:17Z,`configurable ` same as below,0,0.9916361570358276
188086026,4931,kkonstantine,2018-05-14T20:24:04Z,"nit: extra blank line, here and elsewhere in this class.",0,0.9676231741905212
188086886,4931,kkonstantine,2018-05-14T20:26:56Z,"javadoc would be nice, here and in the rest of the public inner classes (especially since we have `abstractstate` elsewhere too)",0,0.978947639465332
188087495,4931,kkonstantine,2018-05-14T20:28:53Z,"should this be called `taskid`, equivalently to `workerid` above? it'll make initialization and usage clear (i think)",0,0.9938483834266663
188088345,4931,kkonstantine,2018-05-14T20:31:44Z,an `enum` with the same name and the same `tostring` implementation is already defined here: `org.apache.kafka.connect.runtime.rest.entities.connectortype` do we need to add this one?,0,0.9943426847457886
188089609,4931,kkonstantine,2018-05-14T20:35:59Z,it's common to write `username` as `password` (instead of `password`). would you agree changing it wherever we use `username` in this pr? (check with `grep -rl username`),0,0.9952784776687622
188090162,4931,kkonstantine,2018-05-14T20:37:47Z,not clear what's the meaning of `32` here. can we declare an intuitive `static final` variable?,0,0.9703415036201477
188090361,4931,kkonstantine,2018-05-14T20:38:33Z,also a nice candidate for `static final` member variable.,1,0.5407061576843262
188091528,4931,kkonstantine,2018-05-14T20:42:51Z,should we throw `unsupportedcallbackexception` if it doesn't match? especially since we declare it and that's the intended use of this exception according to the interface (actually we're violating the interfaces contract if we don't).,0,0.9916467070579529
188093766,4931,kkonstantine,2018-05-14T20:50:37Z,"probably makes sense to be `static`, especially because of its size.",0,0.991621732711792
188093995,4931,kkonstantine,2018-05-14T20:51:27Z,nit: should be in the same line as above,0,0.9874489307403564
188094029,4931,kkonstantine,2018-05-14T20:51:33Z,nit: should be in the same line as above,0,0.9874489307403564
188094120,4931,kkonstantine,2018-05-14T20:51:51Z,nit: should be in the same line as above,0,0.9874489307403564
188094141,4931,kkonstantine,2018-05-14T20:51:56Z,nit: should be in the same line as above,0,0.9874489307403564
188094184,4931,kkonstantine,2018-05-14T20:52:05Z,nit: should be in the same line as above,0,0.9874489307403564
188094421,4931,kkonstantine,2018-05-14T20:52:55Z,"`class names`. no caps (same as classloader, etc).",0,0.9930965304374695
188094764,4931,kkonstantine,2018-05-14T20:53:59Z,"nit: you may fit args in one line, as in `newheaderconverter`",0,0.9880752563476562
188094969,4931,kkonstantine,2018-05-14T20:54:37Z,nit: extra space between: `of plugins`,0,0.9579834342002869
188096167,4931,kkonstantine,2018-05-14T20:58:50Z,"no caps pls. `empty` -> `empty list`, `null` -> `{ null}`",0,0.9932465553283691
188096202,4931,kkonstantine,2018-05-14T20:58:58Z,"no caps pls. empty -> empty list, null -> { null}",0,0.9853283762931824
188097792,4931,kkonstantine,2018-05-14T21:04:02Z,"also the generic name of this method contradicts its functionality. in not general, but pertains only to `connectrestextension`. should probably be named same as with the others above, until we perform some short of consolidation in the functionality. so `newconnectrestextensionplugins` here",0,0.9932714104652405
188097949,4931,kkonstantine,2018-05-14T21:04:28Z,"for the same reasons as above, this should probably be: `newconnectrestextensionplugin`. the log message bellow shows that this method is specific to `connectrestextensions `",0,0.9934671521186829
188099111,4931,kkonstantine,2018-05-14T21:08:33Z,nit: extra blank line,0,0.7656126022338867
188099600,4931,kkonstantine,2018-05-14T21:10:17Z,~java.util.~ collection,0,0.9898043870925903
188100389,4931,kkonstantine,2018-05-14T21:13:15Z,should be `final`,0,0.9899633526802063
188100820,4931,kkonstantine,2018-05-14T21:14:44Z,"if that's a todo comment (which we should avoid adding if we can), it should be marked as `//todo: log ... something more` i'm only guessing what it means here.",0,0.9840972423553467
188100846,4931,kkonstantine,2018-05-14T21:14:51Z,"if that's a todo comment (which we should avoid adding if we can), it should be marked as `//todo: log ... something more`",0,0.9946871995925903
188101268,4931,kkonstantine,2018-05-14T21:16:21Z,both exception are unused here.,0,0.9571055173873901
188101632,4931,kkonstantine,2018-05-14T21:17:43Z,"symmetrically to the above similar method, it's better if `result` is declared close to where it's used. here just before the `for (t impl : serviceloader)` loop",0,0.9922884106636047
188102042,4931,kkonstantine,2018-05-14T21:19:11Z,nit: alignment probably better as: [code block],0,0.9653220176696777
188108937,4931,mageshn,2018-05-14T21:47:39Z,there was a debate about moving the required entity class from runtime to api but we decided not to. hence we see this copy. the connecthealth class introduced itself is pretty much same as connectorstateinfo. i personally still think that entities can be part of the public api. but i'm fine either ways.,0,0.8963050842285156
188110010,4931,mageshn,2018-05-14T21:52:15Z,"it started as newconnectrestextensionplugins and based on earlier pr discussion, we decided to make it generic. may be i missed out generalizing some of the log statements",0,0.9881077408790588
188802909,4931,rhauch,2018-05-16T23:40:05Z,"i'm fine with `versioned`, since this interface defines something that has a version and is not something that can be versioned.",0,0.9788351058959961
188803007,4931,rhauch,2018-05-16T23:40:51Z,nit: rest should be capitalized.,0,0.9896654486656189
188803095,4931,rhauch,2018-05-16T23:41:21Z,"""plugin class loading mechanism"" rather than ""class loader's"".",0,0.9933441877365112
188803391,4931,rhauch,2018-05-16T23:43:26Z,"""implementations should be packaged in a jar that includes the file { meta-inf/services/org.apache.kafka.connect.rest.extension.connectrestextension} that contains the fully-qualified name of the implementation class."" also, ` ` tags should always start on new lines, and for readability should probably be preceded by a blank line.",0,0.9945078492164612
188803420,4931,rhauch,2018-05-16T23:43:39Z,+1 for fixing this.,0,0.9041102528572083
189633739,4931,rhauch,2018-05-21T16:00:00Z,javadoc for this interface. a simple sentence would suffice.,0,0.9838756918907166
189633925,4931,rhauch,2018-05-21T16:00:34Z,javadoc ... a simple sentence would suffice.,0,0.9783918261528015
189634016,4931,rhauch,2018-05-21T16:00:54Z,javadoc ... a simple sentence would suffice.,0,0.9783918261528015
189634067,4931,rhauch,2018-05-21T16:01:02Z,javadoc ... a simple sentence would suffice.,0,0.9783918261528015
189634263,4931,rhauch,2018-05-21T16:01:43Z,javadoc ... a simple sentence would suffice.,0,0.9783918261528015
189634410,4931,rhauch,2018-05-21T16:02:07Z,"""rest"" is an acronym and should be capitalized.",0,0.9890039563179016
189634561,4931,rhauch,2018-05-21T16:02:37Z,paragraphs should begin on a new line and have a blank line before them in javadoc.,0,0.9927678108215332
189634630,4931,rhauch,2018-05-21T16:02:48Z,paragraphs should begin on a new line and have a blank line before them in javadoc.,0,0.9927678108215332
189634810,4931,rhauch,2018-05-21T16:03:21Z,"""connect"" is a name and should be capitalized.",0,0.9920833110809326
189635129,4931,rhauch,2018-05-21T16:04:30Z,"use quotes or `{ }` around ""kafkaconnect"" to highlight the importance of that literal.",0,0.9912382960319519
189635519,4931,rhauch,2018-05-21T16:05:38Z,"how about also mentioned that it must be configured in the worker configuration, and providing an example configuration fragment that shows how to use this sample extension.",0,0.9877102375030518
189636428,4931,rhauch,2018-05-21T16:08:40Z,"should this mention that this is a sample implementation? how does it work, and where does it get the credentials? seems like this needs a lot more context to be useful as an example.",0,0.9842111468315125
189637087,4931,rhauch,2018-05-21T16:10:39Z,how about `to connect's rest api` rather than `to connect rest`?,0,0.9945076107978821
189637462,4931,rhauch,2018-05-21T16:11:43Z,nit: this can be defined on one line.,0,0.9880114197731018
189637562,4931,rhauch,2018-05-21T16:12:03Z,nit: this can be one line.,0,0.9700406789779663
189637966,4931,rhauch,2018-05-21T16:13:27Z,"nit: would using `state` rather than `taskstatefromherder` make this a bit more readable, such that the instantiation of the `taskstate` could be done on a single line?",0,0.9930574893951416
189639210,4931,rhauch,2018-05-21T16:17:52Z,why do we need this conditional logic? is it ever called with a classloader that is not a pluginclassloader?,0,0.9816398024559021
189640314,4931,rhauch,2018-05-21T16:22:00Z,"this should be usable by plugin types other than just connect rest extensions, so i think the non-specific name is important. if we want a specific name for the connect rest extension, then we should add that as the public method and keep this as a protected/private method.",0,0.9889317750930786
189640748,4931,rhauch,2018-05-21T16:23:33Z,seems like this boolean check is backwards. shouldn't this method return true if the component is _not_ already registered?,0,0.9518163800239563
189640850,4931,rhauch,2018-05-21T16:23:59Z,"same incorrect boolean logic here, too.",0,0.8096464276313782
189641853,4931,rhauch,2018-05-21T16:27:28Z,"is this the only rest extension that we'll have in this project? if so, should we have a better and more descriptive name for the project rather than simple `rest-extension`?",0,0.9936869740486145
189966266,4931,rhauch,2018-05-22T16:22:13Z,"perhaps ""connect requires some components implement this interface to define a version string.""",0,0.9939369559288025
189966612,4931,rhauch,2018-05-22T16:23:17Z,"again, capitalize ""connect"" as a name rather than ""connect"" as a verb.",0,0.9924593567848206
189966880,4931,rhauch,2018-05-22T16:24:09Z,need javadoc here. what does the string value represent? can this method ever return null or an empty string?,0,0.9853481650352478
189966913,4931,rhauch,2018-05-22T16:24:14Z,need javadoc here. what does the string value represent? can this method ever return null or an empty string?,0,0.9853481650352478
189966983,4931,rhauch,2018-05-22T16:24:29Z,need javadoc here. what does the string value represent?,0,0.9840019941329956
189967160,4931,rhauch,2018-05-22T16:25:04Z,"are there any requirements about whether these can be null or empty? what is `trace`? need javadoc since this is part of the api, and also verify the arguments match the requirements.",0,0.9943887591362
189967589,4931,rhauch,2018-05-22T16:26:22Z,"""connector"" is not a name and should not be capitalized.",0,0.9814079403877258
189967877,4931,rhauch,2018-05-22T16:27:17Z,"grammar: it's more correct to say ""get the names of the connectors currently running..."", since the names are not running in the cluster. :-) also, do the connectors need to be running for them to be included here? what if they died and were not restarted? i suggest the statement refer to connectors **_deployed_** in this cluster.",1,0.9784461259841919
189968731,4931,rhauch,2018-05-22T16:30:01Z,need javadoc here to define which parameters can be null and/or empty.,0,0.9884241819381714
189968885,4931,rhauch,2018-05-22T16:30:28Z,"add javadoc, since this is part of the public api.",0,0.9885820746421814
189968977,4931,rhauch,2018-05-22T16:30:48Z,"add javadoc, since this is part of the public api. which of the parameters are allowed to be null and/or empty?",0,0.9942601919174194
189969183,4931,rhauch,2018-05-22T16:31:28Z,"nit: remove the unnecessary ""the"" on this line.",0,0.9802639484405518
189969774,4931,rhauch,2018-05-22T16:33:18Z,"nit: i'd suggest ""the implementation class must be packaged in a jar that includes the { ...} file containing the fully qualified name of the implementation class.""",0,0.9916532635688782
189970477,4931,rhauch,2018-05-22T16:35:32Z,"suggest: ""when connect's worker configuration uses the rest extension implementation class, upon startup connect will instantiate the implementation and pass the configuration to the instance via { configurable#configure(map)}.""",0,0.9946050047874451
189970682,4931,rhauch,2018-05-22T16:36:13Z,"use ""the connect framework ..."" instead.",0,0.9922367930412292
189970767,4931,rhauch,2018-05-22T16:36:35Z,"nit: singular ""implementation""",0,0.9760199189186096
189971395,4931,rhauch,2018-05-22T16:38:35Z,"rather than use ` ` tags, rst files use two sequential back quotes before and after code-like text.",0,0.9941112399101257
189971743,4931,rhauch,2018-05-22T16:39:36Z,"grammar: ""... allows you to inject into connect's rest api user defined resources like filters.""",0,0.9878371953964233
189971830,4931,rhauch,2018-05-22T16:39:53Z,replace the ` ` tags.,0,0.9875867366790771
190068865,4931,mageshn,2018-05-22T22:09:26Z,other places like metrics reporter use the same convention. tried to be consistent with it.,0,0.9771013855934143
190069307,4931,mageshn,2018-05-22T22:11:13Z,"atm, this is the only implementation. i named it just like other components for transforms. i'm not too particular about the module name being generic. i could call it connect-basic-auth-extension",0,0.8567477464675903
190759541,4931,rhauch,2018-05-24T23:42:08Z,"yeah, maybe `basic-auth-extension` (e.g., to go with `file`, etc.). i'm just concerned that `rest-extension` is pretty generic and actually sounds like it's the api, not a reference impl.",0,0.9571160078048706
190793197,4931,mageshn,2018-05-25T05:18:35Z,other places like metrics reporter class use the same convention of using <code> tried to be consistent with the same.,0,0.9895804524421692
190793246,4931,mageshn,2018-05-25T05:19:06Z,this is fixed,0,0.979988694190979
190955448,4931,mageshn,2018-05-25T17:06:13Z,"the method is now generic enough to instantiate any plugin. irrespective, i think registering resources belongs in restserver.",0,0.992334246635437
190956787,4931,rhauch,2018-05-25T17:12:32Z,ack.,0,0.5038502812385559
190958825,4931,rhauch,2018-05-25T17:20:37Z,"don't we want these classes to be in a different package than `org.apache.kafka.connect.rest.extension`, since that's the package that exists in the api? the file source and sink, for example, are in `org.apache.kafka.connect.file`. i'd recommend something like `org.apache.kafka.connect.extension.auth.jaas`.",0,0.9941996335983276
190959257,4931,rhauch,2018-05-25T17:22:11Z,"also, since this is a reference implementation, perhaps we could have some javadoc that explains at a high level how this implements the `connectrestextension`, how it works (briefly), and how it is packaged.",0,0.9926101565361023
190959594,4931,rhauch,2018-05-25T17:23:23Z,"make sure this package name is changed accordingly. also, this is a good reason why we want a different package name, since this looks like the extension implementation is built-in to the connect framework.",0,0.9894145727157593
190959834,4931,rhauch,2018-05-25T17:24:18Z,"are we okay with people using this in production? if not, we need to say so. if we're okay with it, we should probably outline a few caveats or important things to keep in mind when evaluating whether to use it. for example, passwords will be stored in cleartext in the property file. this alone suggests that maybe we should call it out as a sample reference implementation that may not be suitable for production use.",0,0.9881347417831421
190960784,4931,rhauch,2018-05-25T17:28:23Z,"i think we should highlight the characteristics that users should be aware of, such as that passwords are stored in plaintext in the referenced file, and that because of this it is likely not recommended for production but is instead part of a sample implementation of the connect rest extension and should not be used in production. perhaps the same paragraph with bold `note:` in all of the files in this package.",0,0.9920682907104492
190961652,4931,rhauch,2018-05-25T17:31:58Z,can this be private?,0,0.9889413714408875
190961740,4931,rhauch,2018-05-25T17:32:19Z,nit: blank line at the beginning of the method is unnecessary.,0,0.5930303931236267
190962339,4931,rhauch,2018-05-25T17:34:48Z,nit: `into` rather than `in to`.,0,0.9858565330505371
190962903,4931,mageshn,2018-05-25T17:36:55Z,ack,0,0.8596508502960205
190996405,4931,rhauch,2018-05-25T19:59:24Z,ping.,0,0.9552854299545288
190996589,4931,rhauch,2018-05-25T20:00:18Z,maybe just `rest_extension`?,0,0.9940223097801208
190996744,4931,rhauch,2018-05-25T20:01:10Z,always need a sentence in javadoc.,0,0.9897936582565308
190996769,4931,rhauch,2018-05-25T20:01:16Z,nit: add a period.,0,0.9632896184921265
190997074,4931,rhauch,2018-05-25T20:02:51Z,"rather than describe the return in the description (2nd sentence), i'd suggest putting it in the param: state of the connector or task; never null or empty it's more concise, and it puts the information where people will look for it.",0,0.9902493357658386
190997151,4931,rhauch,2018-05-25T20:03:12Z,"nit: ""id"" or ""identifier"" (or even ""id""), but not ""id"".",0,0.9896970391273499
190997266,4931,rhauch,2018-05-25T20:03:48Z,"again, remove the 2nd sentence in the description and put it in the param: the worker id; never null or empty",0,0.992927610874176
190997323,4931,rhauch,2018-05-25T20:04:07Z,"again, remove the 2nd sentence in the description and put it in the param: the trace message; may be null or empty",0,0.9942301511764526
190997381,4931,rhauch,2018-05-25T20:04:24Z,"how about `tracemessage`, rather than `trace`?",0,0.9945018291473389
190997661,4931,rhauch,2018-05-25T20:05:49Z,for consistency: * state - the status of connector or task; may not be null or empty * workerid - the workerid associated with the connector or the task; may not be null or empty * tracemsg - any error trace message associated with the connector or the task; may be null or empty,0,0.9931460618972778
190997897,4931,rhauch,2018-05-25T20:06:53Z,how about: the version string; may not be null or empty,0,0.9897243976593018
190998205,4931,rhauch,2018-05-25T20:08:09Z,"`isempty()` just checks whether the length is 0, so a string with 1+ whitespace will be allowed. instead, use: assert state != null && !state.trim().isempty();",0,0.9944286346435547
190998580,4931,rhauch,2018-05-25T20:09:18Z,nit: period.,0,0.6218096017837524
190998660,4931,rhauch,2018-05-25T20:09:41Z,this should be a sentence.,0,0.9897109866142273
190998760,4931,rhauch,2018-05-25T20:10:11Z,"the connector name can this be null or empty? if not, then should check in the constructor. and if the framework calls the constructor, asserts are fine; if users can call it, then `objects.requirenotnull` is better.",0,0.9950729012489319
190999238,4931,rhauch,2018-05-25T20:12:32Z,"same here. sentence, and specify whether it can be null",0,0.990980327129364
190999527,4931,rhauch,2018-05-25T20:13:58Z,"no need to specify the type; it can only get lost and it's already in the signature. again, full sentences are needed in javadoc, and the state for each task id; never null",0,0.9921309351921082
190999572,4931,rhauch,2018-05-25T20:14:09Z,check the input parameters here.,0,0.9861211180686951
190999619,4931,rhauch,2018-05-25T20:14:23Z,same here.,0,0.9755119681358337
190999676,4931,rhauch,2018-05-25T20:14:45Z,need a sentence in javadoc.,0,0.9905923008918762
190999795,4931,rhauch,2018-05-25T20:15:23Z,"nit: it's sufficient to just say ""describes the status, worker id, and any errors associated with a connector."" no need to include a link to this class.",0,0.9854457378387451
190999885,4931,rhauch,2018-05-25T20:15:51Z,"this is public api, so we need javadoc for this class and the enumeration literals.",0,0.9915586709976196
191000029,4931,rhauch,2018-05-25T20:16:37Z,"""describes the state, ids, and any errors of a connector task."" no link, no capitalized ""connector"", and consistent use of ""id"".",0,0.9922156929969788
191000240,4931,rhauch,2018-05-25T20:17:44Z,"for consistency, use `; may not be null or empty` in parameter descriptions. also, no `-` after the parameter name since javadoc already handles this. fix these everywhere.",0,0.9952327609062195
191000313,4931,rhauch,2018-05-25T20:18:12Z,"full sentence, and ` the task id`",0,0.9922550916671753
191000490,4931,rhauch,2018-05-25T20:19:03Z,"nit: multiple `by` in this sentence, so change this one to `using`.",0,0.9881453514099121
191001129,4931,rhauch,2018-05-25T20:21:54Z,perhaps the following helps better explain all of the packaging requirements: [code block],0,0.9915744662284851
191002545,4931,rhauch,2018-05-25T20:29:16Z,nit: [code block],0,0.9847351312637329
191002688,4931,rhauch,2018-05-25T20:30:02Z,the jax-rs { javax.ws.rs.core.configurable}; never null,0,0.9935035109519958
191002712,4931,rhauch,2018-05-25T20:30:12Z,missing a period.,0,0.9328659772872925
191003024,4931,rhauch,2018-05-25T20:31:52Z,change to: provides the cluster state and health information about the connectors and tasks. the cluster state information; never null,0,0.9912392497062683
191003130,4931,rhauch,2018-05-25T20:32:27Z,"nit: begin without a link to this class: ""a sample rest extension that authenticates incoming ...""",0,0.9711332321166992
191013751,4931,mageshn,2018-05-25T21:30:44Z,i don't think we can guarantee or enforce the version,0,0.701248824596405
191061506,4931,ewencp,2018-05-27T00:29:20Z,very minor nit: easier to keep track of these if we group common package prefixes together,1,0.6567860245704651
191061533,4931,ewencp,2018-05-27T00:31:38Z,isn't this the same subpackage we're defining rules for? self-referential imports shouldn't need to be defined here -- imports from the same package shouldn't need special allowance.,0,0.991295337677002
191061585,4931,ewencp,2018-05-27T00:35:26Z,"this doesn't seem like a good thing to enable -- it's the opposite dependency we would normally want to have here. i see the only use is in a javadoc, can we adjust that so the import is not required? for example, use the fully qualified class name instead of just the class name so we don't rely on the import?",0,0.970782458782196
191062417,4931,ewencp,2018-05-27T01:50:27Z,"we don't enforce this today, though you could reasonable argue this is a ""bug"" that we don't validate them today. i think documenting this in the interface as an expectation would be reasonable. whether we enforce it or not on various `versioned` implementations might vary -- we could, for example, enforce proper versioning from day 1 of these new rest extensions, whereas for, e.g., connectors, we might want to think about adding validation that produces warnings if they return `null` or empty values, then eventually actually enforcing it (say, with ak 3.0).",0,0.9916092753410339
191062502,4931,ewencp,2018-05-27T01:54:20Z,"do we want these to be asserts or check conditions and throw, e.g., `illegalargumentexception` with a more useful message?",0,0.9915469288825989
191062585,4931,ewencp,2018-05-27T02:00:04Z,"`connectorstate` is the wrong capitalization for a javadoc, i'd also simplify to just ""about the connector and its tasks"", rest of the api docs can give further details.",0,0.9889804124832153
191062771,4931,ewencp,2018-05-27T02:14:01Z,"is this actually what we want? seems like if you wanted to keep a previous `taskstate` and check whether it had changed, this is going to be confusing behavior.",-1,0.5745308995246887
191063008,4931,ewencp,2018-05-27T02:36:32Z,"i'm noticing now that the context object exposes the cluster state, but doesn't explain the semantics for the returned state. since the extension only gets a hook into the context on the register() call, that means this must be returning dynamic state. it seems like you don't necessarily get a consistent snapshot of the state when you call this -- you get a `connectclusterstate`(`impl`) object back, but that object can mutate out from under you since it's backed just by the dynamic herder state. this is actually problematic and kind of difficult for plugin implementations since the calls to get the list of connectors and to get their state are separate and non-atomic. which means there are chances of hitting `notfound` exceptions and maybe others, which aren't clear from the interfaces. is there any reason not to make collection of the cluster state atomic and take a snapshot instead? that has way more intuitive semantics. if we don't do that, i think we need to clearly document the semantics in the javadocs.",0,0.5883699655532837
191063158,4931,ewencp,2018-05-27T02:52:03Z,"nit: typo ""teh""",0,0.9311183094978333
191063275,4931,ewencp,2018-05-27T03:03:30Z,"seems redundant, we could just refactor out the part up to `getpassword` to a statement before this.",0,0.9740371704101562
191063281,4931,ewencp,2018-05-27T03:04:26Z,is `credentialproperties` guaranteed non-null? it doesn't really seem like it given the logic in `initialize`.,0,0.9928915500640869
191063473,4931,ewencp,2018-05-27T03:19:11Z,"this is global, static state. i think we should be careful to clean this up after the test.",0,0.9629136323928833
191063510,4931,ewencp,2018-05-27T03:23:08Z,"yeah, we just don't have a good way to handle multiple formats today. we'll want to adjust to rst-style if we implement kafka-2967",0,0.7998144030570984
191063925,4931,ewencp,2018-05-27T03:59:08Z,"nit: typo: ""no re-registering"" -> ""not re-registering""",0,0.9827191829681396
191063955,4931,ewencp,2018-05-27T04:01:12Z,"doesn't matter much, but seems weird to use `boolean.true` and `boolean.false` instead of just `true`/`false` literals here",-1,0.9196272492408752
191064077,4931,ewencp,2018-05-27T04:10:34Z,"should these calls be protected by exception handlers for each since they're user pluggable? i.e. so if one fails, we don't just skip closing the rest (and the jetty server)?",0,0.9924718141555786
191292103,4931,mageshn,2018-05-29T02:23:49Z,good point. i will add documentation to mention that these are not atomic and could potentially get an exception.,1,0.9118198752403259
191292150,4931,mageshn,2018-05-29T02:24:25Z,good catch. throwing an exception now if the file can't be loaded.,1,0.8650674819946289
191293267,4931,mageshn,2018-05-29T02:37:15Z,added some docs on connectclusterstate. let me know,0,0.9898858070373535
191598513,4931,rhauch,2018-05-29T22:52:14Z,"i also think that it's useful to specify the expectations on an interface like this that's intended to be implemented by others. it provides useful guidance for implementers, whether or not we enforce it now.",0,0.9673365354537964
191599600,4931,rhauch,2018-05-29T22:58:18Z,"with the changes to externalize secrets in [a link], the existing connectclusterstate is going to output the transformed configurations, which may include secrets. do we want to do that? or, would we prefer to get the pre-transformed configurations?",0,0.995192289352417
191599981,4931,rhauch,2018-05-29T23:00:23Z,nit: javadoc for a class shouldn't really have links to that same class. readers will think that it's something different.,0,0.8260883092880249
191600425,4931,rhauch,2018-05-29T23:02:33Z,"""the connect framework"", not ""connect framework"". check this elsewhere, since it seems like i've requested this change multiple times already and the usage in this commit still is not consistent. :-)",1,0.9652231931686401
191600823,4931,mageshn,2018-05-29T23:04:35Z,"iiuc, kip-297 is for connector configurations and we are only dealing with those here atm.",0,0.9928244352340698
191601149,4931,mageshn,2018-05-29T23:06:29Z,the latest commit already specifies this.,0,0.9872326850891113
191601292,4931,rhauch,2018-05-29T23:07:18Z,"""... current configuration, which may change over time.""",0,0.984071671962738
191601381,4931,rhauch,2018-05-29T23:07:51Z,"the method description in the javadoc says that a `notfoundexception` will be thrown if no connector with the supplied name exists when this method is called, but the `` description says that the method can return null. we should decide: is it better to throw an exception or return null. if we throw an exception, we should add ` notfoundexception if a connector with the supplied name does not exist` to fully document the behavior. (in general, the kafka javadocs are relatively poor on this front.)",0,0.9867299795150757
191602202,4931,rhauch,2018-05-29T23:12:30Z,missing a period to terminate the sentence.,0,0.9323387742042542
191602750,4931,rhauch,2018-05-29T23:15:29Z,capitalize the first word in the sentence.,0,0.9824747443199158
191602778,4931,rhauch,2018-05-29T23:15:39Z,"capitalize the first word in the sentence. (check for other places, too.)",0,0.9917422533035278
191602947,4931,rhauch,2018-05-29T23:16:39Z,"it'd be better to call the parameter `tracemessage` and then use ""any error message..."" in the description.",0,0.993375837802887
191603062,4931,rhauch,2018-05-29T23:17:18Z,nit: missing the period to terminate the sentence.,0,0.7715409994125366
191603211,4931,rhauch,2018-05-29T23:18:06Z,nit: should be `class(es)` to match line 33.,0,0.9944739937782288
191603371,4931,rhauch,2018-05-29T23:19:10Z,"nit: ""implementations"" (plural)",0,0.9896988272666931
191603895,4931,rhauch,2018-05-29T23:22:16Z,"we shouldn't use ` `; instead, use a ` ` section around the lines.",0,0.9933335185050964
191604301,4931,rhauch,2018-05-29T23:24:44Z,"these should be ` ` rather than ` `. the latter is more for phrases, not blocks, and loses all indentation and line breaks within a block of code. then you can get rid of the ` ` tags.",0,0.993380069732666
191605111,4931,rhauch,2018-05-29T23:29:21Z,"good point, but it could be clearer. this implementation can be used in production, but the `propertyfileloginmodule` that also ships with this reference implementation should not be used in production.",0,0.8528521060943604
191605490,4931,rhauch,2018-05-29T23:31:43Z,"should we log a warning in an `else` block for this `if` block? if somebody does not specify the filename, this login module will always fail authentication, right?",0,0.9887575507164001
191605741,4931,rhauch,2018-05-29T23:33:21Z,"for 2.0, should we log this as an error rather than throw an exception? iiuc, this is what you suggested, .",0,0.9866073131561279
191605853,4931,rhauch,2018-05-29T23:34:04Z,nit: why `boolean` rather than `boolean`?,0,0.9890574812889099
191606424,4931,rhauch,2018-05-29T23:37:49Z,"sorry, i now realize that this connectclusterstate is the interface in the api, whereas kip-297 is changing the implementation in the runtime. the api interface doesn't expose the configuration, so that's a good thing.",-1,0.9907591342926025
191618735,4931,mageshn,2018-05-30T01:14:57Z,my understanding was that we enforce it strictly for restextension in 2.0. older implementations can be enforced in 3.0,0,0.9913597702980042
191637634,4931,ewencp,2018-05-30T04:09:22Z,"i think there's confusion in the discussion. i think 's point is that, since we have not enforced correctness in returned values thus far, we should be liberal in what we accept for now. so if they return `null` or an empty value, we should log an error, but not throw an exception that would kill the connector. on 3.0 or some later version, we'd do as this code currently does and throw an exception since we will have given connectors a reasonable grace period to fix their behavior given that we didn't previously enforce the behavior.",0,0.9814159870147705
191638435,4931,ewencp,2018-05-30T04:17:50Z,"i actually think the question is still relevant -- `connectclusterstate` used to be purely immutable and now we'll be exposing an interface that changes based on when you call it. i think it doesn't matter much here, but it is mainly relevant because the docs on `connectclusterstate` aren't really accurate anymore since the contents can change over time. but it's also a weird mix of mutability -- the set of connectors & tasks won't change in the `connectclusterstate` object, you would need to re-callthis method to get updated cluster state. however, the actual values returned for a connector/task config *could* change due to kip-297 replacements.",0,0.893317699432373
249744367,6177,stanislavkozlovski,2019-01-22T11:38:07Z,should we mention that this configuration enabled a static membership and its lack would mean dynamic membership?,0,0.9947474598884583
249745157,6177,stanislavkozlovski,2019-01-22T11:40:41Z,is there any reason to not maintain backward compatibility here? why not have dynamic members continue to rely on `leavegrouponclose`? (i lack the context of why this setting exists in the first place),0,0.9829031825065613
249749343,6177,stanislavkozlovski,2019-01-22T11:54:37Z,"_this is me thinking out loud. for the record i don't believe we should apply my suggestion in this pr as it would over-complicate things_ i'm wondering whether it will be worth it to think about cleaning up this bloated constructor, it takes almost 20 parameters with no defaults. the book [a link] makes a good point on how bundling up related parameters into separate classes results in code that is more domain-oriented (reads better) and is easier to mock/construct. ([a link] we have done something similar in `groupcoordinator` with its [a link] regardless, i was just interest in hearing people's thoughts on this matter",-1,0.854575514793396
249749782,6177,stanislavkozlovski,2019-01-22T11:55:54Z,should we maintain the present tense? `member.id does not match the record on coordinator`,0,0.9942896366119385
249856731,6177,abbccdda,2019-01-22T16:25:04Z,"yea, good idea! let me update both the doc and kip",1,0.9934553503990173
249862352,6177,abbccdda,2019-01-22T16:37:27Z,"`leavegrouponclose` was set through internal config `internal.leave.group.on.close` which is by default set to true for normal consumer/connect, but set to false for streams. checking groupinstanceid could perfectly remove this internal config without backward compatibility concern (since the config is not exposed)",0,0.9957692623138428
249864434,6177,abbccdda,2019-01-22T16:42:27Z,"hey stanis, i'm also in favor of simplifying the constructor logic here. i will get a jira to resolve this issue once this diff is landed.",0,0.7094117999076843
249864597,6177,abbccdda,2019-01-22T16:42:51Z,done!,0,0.6890168786048889
250660764,6177,stanislavkozlovski,2019-01-24T15:47:08Z,could we add a javadoc explaining when we expect to receive this exception and what could cause it? my understanding is that a consumer that was part of the group used a `group.instance.id-member.id` pair and later that pair got updated with a new `member.id` by another consumer? that is what i understand as a possibility from the explanation in the kip:,0,0.9919151067733765
250662548,6177,stanislavkozlovski,2019-01-24T15:50:48Z,could we update the kip as it currently says: [code block] which is not true as we can raise this for joingroup requests as well,0,0.9941826462745667
250664415,6177,stanislavkozlovski,2019-01-24T15:54:42Z,nit: should we call this empty_group_instance_id? `unknown` implies that it will be known in some time (like with member.id) but in this case it is intentionally set to none,0,0.9941473007202148
250672375,6177,stanislavkozlovski,2019-01-24T16:11:05Z,nit: could we append the comment above with `if member id required (dynamic membership)` just to make it even more clearer than static members won't be pending members (i know this is noted in `dojoingroup`,0,0.9937469959259033
250672737,6177,stanislavkozlovski,2019-01-24T16:11:59Z,nit: space between comma and `clientid`. i guess that comma could be on the line above,0,0.989185094833374
250672974,6177,stanislavkozlovski,2019-01-24T16:12:33Z,nit: `informing member` - `inform the member to`,0,0.9911437034606934
250673259,6177,stanislavkozlovski,2019-01-24T16:13:09Z,nit: `should inform` - `inform duplicate instance...` this keeps it consistent with the tense in the other comments,0,0.9932740926742554
250674281,6177,stanislavkozlovski,2019-01-24T16:15:17Z,nit: i think that it will be clearer if we define this variable inside `dojoingroup()`,0,0.9824258089065552
250678345,6177,stanislavkozlovski,2019-01-24T16:24:41Z,nit: `a un-recognized` - `an unrecognized`,0,0.9233575463294983
250678917,6177,stanislavkozlovski,2019-01-24T16:26:00Z,good call with splitting this logic into a method! :thumbs_up:,1,0.9953941106796265
250685315,6177,stanislavkozlovski,2019-01-24T16:41:01Z,should we also test `member.isstaticmember`?,0,0.9949976205825806
250686301,6177,stanislavkozlovski,2019-01-24T16:43:27Z,"we don't have `group.getstaticmemberid` in tests anywhere, i think this is a good spot to assert it works as well",0,0.848809540271759
250688550,6177,stanislavkozlovski,2019-01-24T16:48:38Z,"not sure of the implications here, should we somehow work on removing the static member when the same `memberid` re-joins as a dynamic member? i guess it might not hurt, it will eventually get removed when the member leaves or its heartbeat fails, but we will continue to lock that `group.instance.id` with the `member.id` so new joins from static members with that group.instaince.id won't work. in other words, if a consumer becomes a static member and later re-joins as a dynamic, that `group.instance.id` is still taken. am i correct? that might not be unwanted behavior though",0,0.9690817594528198
250692730,6177,stanislavkozlovski,2019-01-24T16:58:26Z,should we add a test which exercises this code path? i think it's critical for the kip that this works,0,0.9729071855545044
250693889,6177,stanislavkozlovski,2019-01-24T17:01:14Z,"if it's not too much work, maybe we could add a test to ensure `member_id_mismatch` is fatal?",0,0.9703906774520874
250775259,6177,abbccdda,2019-01-24T21:02:21Z,"hey stanis, once i started the implementation, i realized that it's more clear to use the current member.id for static members instead of generating a new one, since we need member.id to track heartbeat & stuffs. i will update the kip to reflect this change. as for the `memberidmismatchexception`, i put the explanation within errors.java as error message to feedback end user.",0,0.9141075611114502
250776499,6177,abbccdda,2019-01-24T21:06:21Z,good catch! will address this.,1,0.9940736889839172
250780087,6177,abbccdda,2019-01-24T21:17:15Z,+1,0,0.7702900171279907
250780539,6177,abbccdda,2019-01-24T21:18:32Z,"yea of course, will try to see how to make that happen",0,0.9378986954689026
250781826,6177,abbccdda,2019-01-24T21:22:22Z,it should be trivial to test.,0,0.9686141014099121
250782168,6177,abbccdda,2019-01-24T21:23:22Z,lol,1,0.9600763916969299
251090933,6177,abbccdda,2019-01-25T18:39:32Z,sounds good!,1,0.9947521686553955
251091132,6177,abbccdda,2019-01-25T18:40:01Z,make sense,0,0.9401010274887085
251092116,6177,abbccdda,2019-01-25T18:41:30Z,+1,0,0.7702900171279907
251093276,6177,abbccdda,2019-01-25T18:45:00Z,"hey stanis, the condition you proposed here is not possible within the current setup. membership type transformation has to go through service restart, which will inevitably reset the member.id. so there is no way we see a dynamic member joining with its member.id points to a known static member. however this is a vaild concern, which i think by enforcing an assertion would be safer!",1,0.6281419396400452
251669585,6177,Ishiihara,2019-01-29T02:16:43Z,do we want to use assert here? it will crash the broker if this happens.,0,0.9397883415222168
251683035,6177,Ishiihara,2019-01-29T03:46:22Z,"can you also add comments to the case when the member doe not have a valid protocol, why do we want to force rebalance? are we handling the case of rolling upgrades?",0,0.9940793514251709
251684242,6177,Ishiihara,2019-01-29T03:55:07Z,"as a disclaimer, i have forgotten the kafka coding style. do we use assert in code?",0,0.981770932674408
251685753,6177,Ishiihara,2019-01-29T04:07:32Z,"this should be a fatal exception to the client, right?",0,0.9571473598480225
251686132,6177,Ishiihara,2019-01-29T04:10:02Z,this makes sense. although the name is a bit confusing.,-1,0.6824843883514404
251686408,6177,Ishiihara,2019-01-29T04:12:09Z,"this handles consumer restarts, correct? in that case, the member id will be unknown.",0,0.9934338331222534
251936369,6177,abbccdda,2019-01-29T17:27:40Z,the reason to use `assert` is to prevent future implementation from breaking the existing assumption. basically known static member should never be `pending`.,0,0.9906402826309204
251937129,6177,abbccdda,2019-01-29T17:29:40Z,"yes we do have examples using assert, see `oncompletejoin()` in groupcoordinator.scala",0,0.9931105375289917
251937266,6177,abbccdda,2019-01-29T17:29:58Z,yes that's right.,0,0.964028000831604
251937638,6177,abbccdda,2019-01-29T17:30:57Z,that is correct. in `dounknownjoingroup` we don't have a known member id to process with.,0,0.9918335676193237
251939458,6177,abbccdda,2019-01-29T17:35:28Z,"usually a change of protocol indicates that the group needs to use a different strategy to allocate topic partitions. current logic is to trigger rebalance anyway to find a common agreed strategy for all current members. this diff doesn't change this part of the logic, however this is a good thing to discuss in a separate jira!",1,0.6097621917724609
260423217,6177,hachikuji,2019-02-26T18:25:01Z,"rather than adding more exceptions, should we try to refactor the code?",0,0.9879746437072754
260426269,6177,hachikuji,2019-02-26T18:32:40Z,"i am wondering if `fenced_member_id` would be a clearer indication of the likely problem. in any case, we should try to give the user a helpful exception message.",0,0.9607703685760498
260429304,6177,hachikuji,2019-02-26T18:40:32Z,do we need a new error code for this case? i'm wondering if we could just use unknown_member_id.,0,0.9832866191864014
260432780,6177,hachikuji,2019-02-26T18:48:54Z,nit: a bit more intuitive to put the static member check first. maybe we can also have an `isdynamicmember` or an `isstaticmember` method.,0,0.7137939929962158
260437389,6177,hachikuji,2019-02-26T18:59:43Z,"is there a good reason to favor """" over null for indicating that no instance id is provided? i think using null would reduce the chance of providing an invalid value by mistake. in fact, we can reject the use of """" and raise an error. so if a user provides any instance id, it must be valid.",0,0.9846470355987549
260439690,6177,hachikuji,2019-02-26T19:05:19Z,"so clearly the intent is to silently fall back to the old join group logic, which means we become a dynamic member. it may be helpful having a log message indicating that this has happened. one additional note: if the brokers are later upgraded to a version that does support static membership, we don't have any logic to detect it. i think this is probably fine, just worth keeping in mind.",0,0.8602698445320129
260442064,6177,hachikuji,2019-02-26T19:10:47Z,hmm.. i think i missed this addition in the kip. how much effort would it be to pull this change into a separate pr? i think we may need some discussion.,-1,0.5276589393615723
260608268,6177,abbccdda,2019-02-27T06:28:52Z,"yes, good suggestion! i got a jira to track this work [a link] will attempt to fix it once this change is merged.",1,0.9919724464416504
260609201,6177,abbccdda,2019-02-27T06:33:25Z,sounds good!,1,0.9947521686553955
260611209,6177,abbccdda,2019-02-27T06:44:15Z,maybe unknown instance id is more aligned? it's slightly different comparing with member id unknown.,0,0.9568290114402771
260611350,6177,abbccdda,2019-02-27T06:44:54Z,sounds good.,1,0.9417163729667664
260886942,6177,hachikuji,2019-02-27T18:38:43Z,"our response to this error is to discard our current memberid and rejoin. that seems true regardless whether static or dynamic membership is used, so i thought we may as well make the error consistent. does that make sense?",0,0.9911760091781616
260902762,6177,abbccdda,2019-02-27T19:17:55Z,"it should be ok since the error message clearly states: `the group.instance.id is already in the consumer, however the corresponding member.id is not matching the record on coordinator`",0,0.9929220676422119
260923497,6177,abbccdda,2019-02-27T20:09:39Z,sure,0,0.9137381911277771
260935391,6177,abbccdda,2019-02-27T20:43:08Z,why couldn't we piggy-back the change in this pr? connect could also benefit from using static membership right.,0,0.9926348328590393
261272738,6177,kkonstantine,2019-02-28T16:19:30Z,i agree with this is too significant to be omitted from a kip and we should probably avoid piggybacking such a change in a subtle way in this already big pr. the doc of the config below is indicative that we need to give this more thought. the connect worker is not a consumer and it doesn't use the group membership protocol in the same way. this is even more true with the changes being introduced soon with incremental cooperative rebalancing in connect. the interplay between kip-415 and static membership has not been sufficiently studied yet and therefore i'd suggest not introducing everything at once with the upcoming release.,0,0.9770414233207703
261308442,6177,abbccdda,2019-02-28T17:44:05Z,"sounds great! my original thought was that the change happens on abstract coordinator layer, so consequently we could cover all the subclass use cases (both consumer and connect). i will revert connect related changes.",1,0.9929320812225342
261350730,6177,hachikuji,2019-02-28T19:33:17Z,"possibly so, though i am not sure since it does not have local state like streams. in any case, i do not want to see this pr blocked by this discussion, so my thought was to split it out. cc any thoughts about this?",-1,0.5219873189926147
261353864,6177,abbccdda,2019-02-28T19:41:27Z,"although we would react the error with same handling logic, i do see the benefit of decoupling error for now, because the error log could better help user triage during consumer incident.",0,0.9866670966148376
261403394,6177,hachikuji,2019-02-28T22:05:40Z,apologies for the late comment above. i hadn't refreshed the page and seen the updates.,0,0.9706661105155945
261448929,6177,abbccdda,2019-03-01T01:09:11Z,it's fine :),1,0.9947977066040039
261759212,6177,hachikuji,2019-03-01T21:11:35Z,"hmm.. the unknown_member_id error is unambiguous in either case. it means that the coordinator isn't aware of the memberid. what debugging benefit is there in having another error code? the reason i'm resisting a little bit is that every error code adds more complexity to the protocol, so we should be sure it's necessary. here is the reason i find it confusing. with a provided instance id, there are two join cases: 1) joingroup(instanceid=""foo"", memberid=""""): the consumer has no memberid and needs to be assigned one. 2) joingroup(instanceid=""foo"", memberid=""xyz""): the consumer has a memberid and expects it to be valid. the group_instance_id_not_found would only make sense if it was a valid error in both cases. but it only applies to the second case. so my suggestion is that we view the second case as having a missing memberid. then the behavior is consistent for static and dynamic members.",0,0.5017097592353821
261792206,6177,hachikuji,2019-03-01T23:41:22Z,i think it would be clearer if we represented this as `option[string]`.,0,0.9830633997917175
261792477,6177,hachikuji,2019-03-01T23:42:56Z,we generally frown on assertions. it is usually better to raise an exception with a clear message.,0,0.533328115940094
261793705,6177,hachikuji,2019-03-01T23:50:50Z,hmm.. i thought the proposal called for generation of a new memberid when a static consumer is restarted. the purpose is to fence the old static member. how do we avoid two static members from being active at the same time? perhaps i'm missing something?,0,0.6373694539070129
262186803,6177,abbccdda,2019-03-04T18:31:48Z,"i see your point jason, make sense here. the logic is the since `group_instance_id_not_found` is not covering the whole cases (like when member id is unknown), we could just bypass this check.",0,0.9795596599578857
262201770,6177,abbccdda,2019-03-04T19:12:33Z,"good catch! we have slightly diverged from the original proposal, so that we no longer kick off rebalance when static member rejoins with unknown member id. thus the generation could not be used to fence against duplicate static members. will address this problem by replacing with a new member id.",1,0.9643067717552185
262203003,6177,abbccdda,2019-03-04T19:16:05Z,"could you share more details? the reason for using assertion is to avoid creating invalid state from the code change stage. for example, we have [code block] and [code block] it would be great if you shed light on the trade-offs on these cases, thank you!",1,0.9578160047531128
262788694,6177,abbccdda,2019-03-06T04:32:21Z,i think we handle the null case when building the join group request struct?,0,0.9942615032196045
268418696,6177,abbccdda,2019-03-24T05:18:08Z,could you give me some guidance on this? thank you!,1,0.9288981556892395
268419130,6177,stanislavkozlovski,2019-03-24T05:44:40Z,"- judging by `groupmetadata#replace()`, the current behavior is to generate a new member id and return it, right? what happens if a misconfigured consumer joins with an existing, duplicate `consumer.instance.id`? it essentially kicks out the old consumer using it (by invalidating its member.id)? does the old consumer try to rejoin with its group.instance.id afterwards? we could get into a bad loop if that is the case",0,0.9783459305763245
268446363,6177,abbccdda,2019-03-24T18:33:39Z,"thats a very good question. previously my thought was to use conflict member.id to shut down duplicate consumer instances. however, this probably wont work because upon receiving unknown_member_id exception in either `syncgroup, heartbeat, offsetcommit` requests will immediately reset the generation info which includes the member.id. one approach i could think of is to restrict the caller of `resetgeneration` on client side to only joingroup logic, which means for any other types of requests after receiving unknown_member_id will be rejoining the group with their current generation info (the conflicting member.id). this should be able to help us detect the id collision and shut down duplicate member with member_id_mismatch exception. thoughts?",0,0.6651166081428528
268484117,6177,stanislavkozlovski,2019-03-25T04:13:37Z,"i don't understand, who would receive the unknown_member_id? if consumer a has `member.id=1, instance.id=one` and consumer b joins with `member.id=2, instance.id=one`, wouldn't a receive member_id_mismatch and shut down?",0,0.9562336206436157
268491234,6177,abbccdda,2019-03-25T05:16:58Z,"this won't happen automatically. the flow is like: 1. consumer a with `member.id=1, instance.id=one` is working under stable group. the static member metadata map contains kv entry `one=1`. 2. consumer b starts up, joining with same `instance.id=one` and `member.id=unknown` 3. consumer b enters `dounknownjoingroup` block and successfully gets identity `member.id=2`. the static member metadata map now updates to `one=2` 4. consumer a gets fenced by either `syncgroup, heartbeat, offsetcommit` which informs a with `unknown_member_id` error, which will trigger `resetgeneration()` on client side abstractcoordinator. 5. now consumer a rejoins with `instance.id=one` and `member.id=unknown`, repeating step 2 like b. so eventually a, b will bounce forever within the loop 2~5 unless one of them refuses to reset their assigned member.id. otherwise `member_id_mismatch` shall never trigger.",0,0.9875417351722717
268790882,6177,stanislavkozlovski,2019-03-25T18:27:48Z,"aha, yeah. we can only raise `member_id_mismatch ` in the `joingroup` request because that's the only request that has the group instance id field, right? as you proposed, i think making the consumer issue a new joingroup with the same member.id would be the better approach. otherwise, we'd probably need to add the new field to all the requests. the old functionality of resetting the generation should continue to work just fine, we'd just be adding an extra hop.",0,0.9680463075637817
270133661,6177,guozhangwang,2019-03-28T18:06:11Z,"not clear if this is right to me: from my understanding ([a link] in case 6, we will still require a member.id and hence would reply the error with `member_id_required` if it is not specified, right?",0,0.9537435173988342
270134521,6177,guozhangwang,2019-03-28T18:08:12Z,"nit: can we just do this check inside `dojoingroup`, seems unnecessary to create a boolean at the caller and pass in to `dojoingroup`.",0,0.9939125776290894
270136870,6177,guozhangwang,2019-03-28T18:13:59Z,nit for doc: .. for static members only.,0,0.9683040976524353
270137792,6177,guozhangwang,2019-03-28T18:16:15Z,`new member id will be the same`: what does this mean?,0,0.9909948706626892
270139366,6177,guozhangwang,2019-03-28T18:20:10Z,"following the comment of `kafkaapis`: current logic is that if instance.id is not empty, then `requireknownmemberid` would never be required. is that intentional? i think even with non-empty instance.id, if there's no existing entry in static members, we would still return the created member.id with member_id_required to let the client re-join?",0,0.9950268864631653
270140569,6177,guozhangwang,2019-03-28T18:23:13Z,"yeah to be honest we do use assertions somewhere like mentioned in ongrouploaded; they are used to indicate ""this should never happen, and if it happens, it's a bug"". as a hind-sight we can actually just replace with if-throw-illegal-state-exception across the board so that when it happens indeed, it will crash hard but leave us a meaning stack trace.",0,0.962298572063446
270140799,6177,guozhangwang,2019-03-28T18:23:53Z,hmm... this is not what i was thinking. maybe we can elaborate a bit more on the kip wiki?,-1,0.7725397348403931
270142218,6177,guozhangwang,2019-03-28T18:26:51Z,what if two consumers joining with the same instance id and member id?,0,0.9755926728248596
270236415,6177,guozhangwang,2019-03-28T23:28:56Z,"i think restricting `resetgeneration` to only joingroup request is not the best approach since we do rely on, e.g. heartbeat response to notify consumers as early as possible. on the other hand, this issue would only raise if users mis configure their `instance.id` to have two running instances to have the same id, such issue is similar to producer client that two instances mistakenly configured with the same `transactional.id` and today it is handled by letting one of them to receive a fatal error (`fenced`) and either handle it themselves or die hard -- the bottom line is, brokers would not need to be responsible for abstracting such human errors from clients. so i'd like to present an alternative proposal: 1) when receiving a join group of null member.id, but existing instance.id, create a new member.id just instead of returning the associated member.id to the client (your pr already did this anyways) 2) when receiving a join group of non-empty member.id, and existing instance.id, but is inconsistent with the static members map, return error `member_id_required`. now the only issue is what if two instances come with the same instance.id and the same member.id. i think it would not be possible for new members due to 1) since we always generate a new member.id. ----------------------- edit: after thinking about this and discussing with a bit more, i am now inclined towards the original proposal now, i.e. for all responses other than join-group request, we let it client to not reset generation / member-id immediately, but try to re-join the group again. this logic is simpler because: 1. for static members, not reseting the member-id and re-join, will then result in an fatal `member-id-mismatch`, and hence we can avoid the ping-pong scenario of two mis-configured clients keep kicking each other out by reseting the member id and re-join. 2. for dynamic members, not resetting the member-id and then rejoin will likely to get the same `unknown-member-id` again, and then it can reset generation. the cons is that this requires one more round-trip. but to me, simpler logic that does not require much complexity worth the cost, compared to my proposal above that special handles static and dynamic members on client side much more. 3. moreover, as we move on to kip-429 which will assume the assignors to be ""sticky"" somehow anyways, so even if somehow the member-id is still recognized by the group-coordinator when re-joining and the member happen to be the leader, this unnecessary rebalance triggered will be cheap. cc",0,0.9667063355445862
270628741,6177,abbccdda,2019-03-30T14:51:43Z,i believe the `member_id_required` exception is assumed to be used only for dynamic members now.,0,0.9930370450019836
270645251,6177,abbccdda,2019-03-30T23:46:18Z,"as we have discussed, we shall generate a new member id each time the static member rejoins. so the former consumer will not have the same member.id as the previous one",0,0.9916355609893799
270679831,6177,guozhangwang,2019-03-31T19:00:54Z,"ack, i will update the comment on the kip regarding the updated logic. could you update the kip wiki with that logic and also update the voting thread as well?",0,0.9751606583595276
270680233,6177,guozhangwang,2019-03-31T19:12:21Z,updated the comment in the wiki page: [a link] please double check and also update the wiki page for better illustration if that makes sense.,0,0.9863229990005493
271098896,6177,abbccdda,2019-04-02T00:37:32Z,"i see, so we should choose to throw exception for most times?",0,0.9844177961349487
272441872,6177,guozhangwang,2019-04-05T04:34:35Z,yeah i'd suggest so.,0,0.9610059857368469
273648617,6177,hachikuji,2019-04-09T18:46:33Z,the thing about an empty id might be misleading since we use null to indicate absence. a few more details may also be helpful. perhaps we can say something like this:,0,0.9864614605903625
273671882,6177,hachikuji,2019-04-09T19:49:31Z,nit: perhaps quote the exact config? for example: [code block],0,0.9936687350273132
273673756,6177,hachikuji,2019-04-09T19:54:40Z,i think one of the things we have regretted is not limiting the group.id to a reduced character set. this has made acls more difficult for example. do you think it is worth being stricter about the instance id? potentially we could limit the character set to the same characters we allow for topics.,0,0.5414478778839111
273674941,6177,hachikuji,2019-04-09T19:57:54Z,let me try one more time. how about `fenced_instance_id`?,0,0.989966630935669
273727881,6177,hachikuji,2019-04-09T22:22:41Z,hmm.. this method is also called when a call to `unsubscribe()` is made. would we not want a static member to leave in this case?,0,0.9835756421089172
273728352,6177,hachikuji,2019-04-09T22:24:20Z,this is unused since we use the generated classes now.,0,0.9907540082931519
273733855,6177,hachikuji,2019-04-09T22:47:16Z,"i think we can be a little clearer in this message. how about simply ""the coordinator reports a more recent member.id associated with the consumer's group.instance.id.""",0,0.9855097532272339
273734276,6177,hachikuji,2019-04-09T22:49:14Z,"i may have asked this before, but do we want to use empty to indicate no group instance id? alternatively, we can let the `groupinstanceid` type be nullable in the schema and we can use null. this would be consistent with the config.",0,0.9938284754753113
273737121,6177,hachikuji,2019-04-09T23:03:22Z,"i'm just saying that it would be clearer to represent the difference between static and dynamic members by using an optional field. otherwise you have to dig into the code to make sure the uses are all safe. for example, we have a bunch of cases below where we are using the empty instance id in calls to `hasstaticmember`. this opens the door to bugs if we are not really careful with our checking. the nice thing about options is that they force us to check for absence.",0,0.9399178624153137
273738245,6177,hachikuji,2019-04-09T23:08:38Z,nit: you can drop the `s` since there are no substitutions.,0,0.9921436309814453
273738796,6177,hachikuji,2019-04-09T23:11:29Z,can you elaborate on this comment? i'm not sure i understand the problem.,0,0.6608000993728638
273739061,6177,hachikuji,2019-04-09T23:12:49Z,i think we should not try to overload `requireknownmemberid`. it makes this pretty confusing.,-1,0.808971107006073
273739420,6177,hachikuji,2019-04-09T23:14:32Z,"yes, exactly. we like stack traces and nice error messages! a lot of these impossible states have a way of becoming more possible over time.",1,0.9890056252479553
273742089,6177,hachikuji,2019-04-09T23:27:52Z,maybe slightly nicer: [code block],0,0.9716254472732544
273743469,6177,hachikuji,2019-04-09T23:35:19Z,we did get some flack in 2.1 for a change to this format. the problem is that we cannot downgrade once the new format is in use. we will probably have to mention this in the upgrade notes at a minimum. unfortunately i don't see any great options at the moment to avoid this. perhaps we should just switch to json.,0,0.890214204788208
273744396,6177,hachikuji,2019-04-09T23:40:22Z,i'm trying to think through the implications of this. we are silently discarding the instance id which means that replicas won't know about it. the member will be considered a static member until there is a coordinator change. then it will suddenly become dynamic again and i think that would trigger this assertion: [a link] i think we probably need to avoid using the static membership logic entirely until the ibp supports it.,0,0.8335378170013428
274084303,6177,abbccdda,2019-04-10T17:53:39Z,sure!,0,0.8522761464118958
274157146,6177,abbccdda,2019-04-10T20:56:44Z,thanks!,1,0.9051083922386169
274157459,6177,abbccdda,2019-04-10T20:57:38Z,sounds good,1,0.9683692455291748
274162476,6177,abbccdda,2019-04-10T21:11:41Z,fixed. i was about to say the new heartbeat shall be scheduled with new member id.,0,0.988020122051239
274163062,6177,abbccdda,2019-04-10T21:13:40Z,"yes, for static member we shall never require a rejoin, because its identity is declared by the instance id.",0,0.9906722903251648
274163632,6177,abbccdda,2019-04-10T21:15:25Z,thanks!,1,0.9051083922386169
274261445,6177,abbccdda,2019-04-11T05:23:58Z,"i see, we could discuss offline some time for a holistic solution.",0,0.9715163111686707
274261996,6177,abbccdda,2019-04-11T05:27:51Z,"that sounds reasonable. i'm not sure i'm fully following here because unless broker upgrades to latest, the group instance id should not include the join group because of automatic request downgrade.",0,0.9228523373603821
274263375,6177,abbccdda,2019-04-11T05:35:38Z,"yea, updated explicitly in the kip",0,0.9920338988304138
274263890,6177,abbccdda,2019-04-11T05:38:46Z,"ugh, `empty_group_instance_id` will just be empty string right?",0,0.9754379987716675
274265007,6177,abbccdda,2019-04-11T05:45:00Z,"let me check the code real quick, do you have good example for character set check? right now what i found on admin client is sth like: [code block] which is not very useful.",0,0.6020864248275757
274265965,6177,abbccdda,2019-04-11T05:50:52Z,"i quickly checked `unsubscribe()` use cases, and there are mainly two: 1. illegal topic/partition data, i.e empty topic partitions to subscribe 2. consumer self managed membership (subscription) i think it makes sense to make static member behavior consistent in these two cases, because the effect of leaving is minimal.",0,0.9916395545005798
274266402,6177,abbccdda,2019-04-11T05:53:18Z,this is just for the sake of reducing code duplication and keep if-else blocks intact.,0,0.9876219630241394
274267268,6177,abbccdda,2019-04-11T05:57:41Z,i don't think that comment is needed here. it's just an edge i caught during my experiment.,0,0.9190161228179932
274667775,6177,abbccdda,2019-04-11T21:16:28Z,"we still need an empty string field to make sure we could correctly serialize the member metadata. also checking null for string is not very intuitive in java compared with scala option, so my suggestion is to keep using empty string on client side for now.",0,0.9845355153083801
274731954,6177,guozhangwang,2019-04-12T01:19:13Z,the topic validation logic can be found at `org.apache.kafka.common.internals.topic`,0,0.9937493801116943
274732699,6177,guozhangwang,2019-04-12T01:25:05Z,what's `ibp`?,0,0.9930319786071777
274750177,6177,abbccdda,2019-04-12T03:39:32Z,inter broker protocol,0,0.9895681738853455
275141269,6177,abbccdda,2019-04-14T05:38:54Z,sounds like a good idea!,1,0.9938940405845642
275591198,6177,hachikuji,2019-04-16T00:27:22Z,"i'm not sure i follow this. we _can_ serialize null. my point is we should try to be consistent. null is a good way to represent something which is missing. java also has an `optional` type which we could use, but we'd still have to decide what gets transmitted in the protocol.",0,0.7715557813644409
275592368,6177,hachikuji,2019-04-16T00:34:39Z,nit: this could probably be implemented more concisely with a regex.,0,0.9854148626327515
275593388,6177,hachikuji,2019-04-16T00:40:57Z,this method doesn't really make sense if `groupinstanceid` is `none`. wouldn't it clearer to force the caller to ensure that that is the case? same for the other methods below.,0,0.9923830628395081
275595976,6177,hachikuji,2019-04-16T00:58:51Z,"we expose the new joingroup protocol as soon as the binary is updated. the client will begin using it. that itself is fine, but it is not safe for the broker to use the static member logic until we are sure that all brokers support it, as indicated through the ibp. otherwise, the case i mentioned is possible. we seem to have removed the assertion i mentioned above, but i am still not sure the logic is correct. the simplest option would be to set `groupinstanceid` to `none` if the ibp is below `kafka_2_3_iv0`.",0,0.988962709903717
275596088,6177,hachikuji,2019-04-16T00:59:38Z,shouldn't this be `kafka_2_3_iv0`? do we have any tests?,0,0.9951687455177307
275596574,6177,hachikuji,2019-04-16T01:02:33Z,why not let `groupinstanceid` be represented as an `option` inside `membermetadata` as well?,0,0.9947949051856995
275597196,6177,hachikuji,2019-04-16T01:06:07Z,nit: parenthesis are unneeded,0,0.9184994101524353
275607536,6177,abbccdda,2019-04-16T02:13:53Z,i tried one time and it failed due to serialization issue. let me try one more time.,0,0.9242051243782043
275630797,6177,abbccdda,2019-04-16T05:07:57Z,"to make the full e2e consistency, we should consider supporting optional[string] type for part of auto-mated protocol in `joingrouprequest.json` and other protocol classes. otherwise, we still need to have `empty_instance_id` as a special type to handle null case in the serde of request.",0,0.9953529834747314
276082373,6177,abbccdda,2019-04-17T05:19:07Z,good catch!,1,0.9947227239608765
276083793,6177,abbccdda,2019-04-17T05:28:24Z,"i think adding an assertion here would be helpful. would be messy if we do null check in caller every time when we call `replace`, `addstaticmember` and `getstaticmemberid`, what do you think?",0,0.8296255469322205
276084326,6177,abbccdda,2019-04-17T05:31:37Z,"sounds good, i think it's probably better to do the refactoring in one diff for both topic and group instance id.",1,0.5740092396736145
276085073,6177,abbccdda,2019-04-17T05:35:56Z,addressed in groupcoordinator.scala,0,0.9914786219596863
276745404,6177,guozhangwang,2019-04-18T16:45:46Z,how about rename it to `maybereplacegroupinstance` and do the check in the callee and make it no-op if `groupinstanceid` is empty then?,0,0.9952367544174194
276749603,6177,guozhangwang,2019-04-18T16:57:47Z,"the automated protocol supports `nullable string` (it will be serialized and stored as `0xffff` over the wire), and hence could we encode null for this instance id, and then: 1) on client side we can have this parameter nullable, and upon constructing join-group request it will be auto-serialized. 2) on broker side we can have this parameter as `option[string]`, upon deserializing if the returned value is null construct the field as `none`.",0,0.9918455481529236
276750288,6177,guozhangwang,2019-04-18T16:59:51Z,"i think on the broker side we should be using `option` in scala to be consistent with other fields (see my other comment). on the client side though, it is true that since we only recently dropped j7, `optional` is not commonly used elsewhere, and i think having it just as a nullable field is fine (we can, do a universal refactoring on client side using `optional` in another pr but this does not need to be done in this scope).",0,0.9850237369537354
276827600,6177,abbccdda,2019-04-18T20:46:28Z,thanks for the info!,1,0.7535163164138794
276828558,6177,hachikuji,2019-04-18T20:49:21Z,"sorry, if this wasn't clear, but here is what you need to add to the schema definition. see the `nullableversions` field. [code block] in the common tongue, 0xffff is -1 :wink:. this is how we represent null arrays and strings.",-1,0.9897201657295227
276836547,6177,abbccdda,2019-04-18T21:14:10Z,"yea, i just figured it out, thank you!!",1,0.9934836030006409
276864867,6177,abbccdda,2019-04-18T23:21:00Z,i agree with renaming but feel slightly against second proposal. i think the goal is to avoid people from passing in null group.instance.id in the code level.,0,0.9361691474914551
277374681,6177,guozhangwang,2019-04-22T17:59:41Z,"i've thought about this a bit more, and also searched in github: [a link] i think a third common case is to use a temporary consumer for its apis, like get offset by timestamp, get log end offset etc; generally speaking for temporary consumer case, they should not use static members (and by default it would not be the case). so i think it really boils down to: for static members, do we consider the admin request kicking it out of the group be the only appropriate way for it to leave in time or not? i.e. even if the consumer shuts down itself, it should not be considered as ""i want to leave"" but another request has to be made to effectively kick him out.",0,0.9586185216903687
277477265,6177,guozhangwang,2019-04-22T23:55:45Z,should we remove this const string then?,0,0.9936975836753845
277478955,6177,guozhangwang,2019-04-23T00:05:31Z,should we still need these calls if we can get rid of const `empty_group_instance_id` with optional?,0,0.9950386881828308
277480160,6177,guozhangwang,2019-04-23T00:12:40Z,nit: i think it worth being an `info` since this should not happen frequently and hence each time it happens we should pay attention.,0,0.9466676115989685
277480223,6177,guozhangwang,2019-04-23T00:13:09Z,also: better include the groupinstanceid as well?,0,0.9929272532463074
277480459,6177,guozhangwang,2019-04-23T00:14:29Z,"as we discussed before, better change `assert` to `throw illegalstateexception` with a meaningful error message; ditto below.",0,0.9929056167602539
277481055,6177,guozhangwang,2019-04-23T00:18:13Z,for all the three callers of it: two already checks `member.isstaticmember` and one has the assert already. so i'd suggest we pass in `groupinstanceid: string` as parameter directly from caller.,0,0.9875015020370483
277481439,6177,guozhangwang,2019-04-23T00:20:36Z,"hmm.. does this function only have one caller who's already checked `group.hasstaticmember(groupinstanceid)`? in this case i think we can just name it `replacegroupinstance` as it should always replace unless we have a bug. originally i was thinking there are multiple callers of it, and some may really turn into a no-op since it is not for static members, but now the call trace seems to indicate only one caller.",0,0.9802663922309875
277481592,6177,guozhangwang,2019-04-23T00:21:38Z,just to confirm: is `map.remove(null)` a no-op with no side-effect?,0,0.9884993433952332
277481815,6177,guozhangwang,2019-04-23T00:22:58Z,nit: we can just do `else if` and `else`.,0,0.9885128736495972
277482417,6177,guozhangwang,2019-04-23T00:26:46Z,if this is nullable we can get rid of `empty_group_instance_id` right?,0,0.9947593808174133
277482886,6177,guozhangwang,2019-04-23T00:29:58Z,"actually, for all such `setgroupinstanceid` calls we can by default remove it since without any setters is equal to using `setgroupinstanceid(null)` right?",0,0.9938541650772095
277483066,6177,guozhangwang,2019-04-23T00:31:15Z,do we have unit test coverage on compatibility? i.e. old formatted data can be loaded with new versioned byte code with new fields set to default (null) values?,0,0.9922865629196167
277483221,6177,guozhangwang,2019-04-23T00:32:14Z,i think we should remove this part from streams first. there are some open questions that i've in mind and needs to potentially create a new streams kip for it. cc,0,0.9788404703140259
277484517,6177,guozhangwang,2019-04-23T00:41:13Z,"i think `null` default value should still work, e.g. the group-id used `null` as default values above.",0,0.9930979609489441
277503483,6177,abbccdda,2019-04-23T02:57:03Z,the tricky thing is that we couldn't set the key to `null` in `verifiableconsumer` because it will throw exception.,0,0.9702610373497009
277503751,6177,abbccdda,2019-04-23T02:59:19Z,sounds good,1,0.9683692455291748
277503848,6177,abbccdda,2019-04-23T03:00:04Z,"my bad, didn't see the upper comment.",-1,0.9869179129600525
277513354,6177,abbccdda,2019-04-23T04:20:25Z,"we could remove the assertion here, but i guess we still need to throw exception since new caller may forget to check it.",0,0.9823371171951294
277515294,6177,abbccdda,2019-04-23T04:36:42Z,yep!,1,0.9602143168449402
277515412,6177,abbccdda,2019-04-23T04:37:41Z,we don't,0,0.8272238969802856
277813801,6177,abbccdda,2019-04-23T18:28:46Z,mind giving me an example for compatibility test? i look around and haven't found one good example.,0,0.7936855554580688
277912948,6177,abbccdda,2019-04-23T23:51:03Z,"after offline discussion with , we sort out following key points: 1) will the static membership affect unit test independence? short answer: no. the reason is because without explicitly setting the `client.id` config for stream instances, the static member id will be changed throughout the restarts since we add a random hash to `client.id`. it will essentially behave the same as current dynamic membership. also one another confusion was that we are changing *max session timeout cap* to 30 min, instead of *default session timeout* which will remain as 10 s for either static or dynamic member. so the out-dated members will be kicked out in 10 seconds as expected. 2) the concern about thread id change throughout restarts. this is a valid concern in case where we configure two stream jobs within one jvm, so the threads will sometime shuffle from job a to job b, which unfortunately breaks the expectation of persistent thread-id numbers. this, however, shall not block us from enabling static membership for streams because the worst case is just doing repetitive rebalances as current dynamic membership. we could choose to address this application layer problem in another diff. the conclusion is that, it does no harm to enable static membership on streams, we are just realizing there are more subtle cases we need to handle. let me know if this addresses your concern, thanks!",0,0.9922177791595459
277927199,6177,guozhangwang,2019-04-24T01:28:38Z,that sounds good. we can check that the passed in `string` (not `option[string]` for simplicity since all current callers actually can pass in the string parameter) is not null and throw otherwise.,1,0.6575610637664795
277927290,6177,guozhangwang,2019-04-24T01:29:16Z,is that the case?,0,0.990729033946991
277927492,6177,guozhangwang,2019-04-24T01:30:40Z,"you can for example take a look at this pr: [a link] when we update the consumer protocol, we added unit test to make sure old versioned code can still deser it, and similarly in this case, we need to change that new versioned code can still deser old versioned data.",0,0.9911959171295166
277927851,6177,guozhangwang,2019-04-24T01:33:11Z,"i'd still suggest we add streams logic leveraging static members in this pr for further discussion than rush it in this pr. for people who wants to use the feature in streams asap, they can still do it by manually set the group.instance.id via consumer config prefix in streamsconfig. but we need to think through all the cases before making it turned on by default in streams.",0,0.9927494525909424
277950657,6177,abbccdda,2019-04-24T04:21:56Z,"i see. however it's currently not possible, since they need to have access to stream internal to set `group.instance.id` config.",0,0.9909756779670715
277953016,6177,abbccdda,2019-04-24T04:40:56Z,thanks!,1,0.9051083922386169
277953572,6177,abbccdda,2019-04-24T04:45:48Z,i feel we could keep option[string] in the function parameters. the reason is for consistent handling of this piece of information in groupcoordinator until we actually extract the string for internal data structure update. the other approach would be using the case switch here which is more option friendly. wdyt?,0,0.9348748922348022
278737190,6177,guozhangwang,2019-04-25T21:22:33Z,"got it, that makes sense. i think we would consider fixing the following the static stream-thread suffix number first, and then requiring users who wants to turn on static membership to specify the client-id then (otherwise internally created client-id would never be the same across lives of a streams instance). i saw you've created jira tickets for these tasks.",0,0.9381363391876221
278737600,6177,guozhangwang,2019-04-25T21:23:36Z,"after a second thought i think i agree with you, it's not worth optimizing the parameter while giving up consistency in call traces.",0,0.9141363501548767
278739994,6177,guozhangwang,2019-04-25T21:31:03Z,we should check that `staticmembers` is also empty by default when deserializing from old versions.,0,0.993990957736969
109102899,2772,michaelandrepearce,2017-03-31T07:29:53Z,"accidental formatting, no need, need to revert.",0,0.7334936261177063
109102944,2772,michaelandrepearce,2017-03-31T07:30:14Z,remove extra space,0,0.9621213674545288
109102987,2772,michaelandrepearce,2017-03-31T07:30:33Z,remove extra un-needed whitespace,0,0.979300856590271
109103041,2772,michaelandrepearce,2017-03-31T07:30:54Z,is this needed?,0,0.9838624596595764
109103189,2772,michaelandrepearce,2017-03-31T07:31:53Z,"remove accidental, whitespace formatting change.",0,0.9160231947898865
109141852,2772,jeroenvandisseldorp,2017-03-31T11:37:45Z,"you use pretty much everywhere k, v, h as parameter order, so would be more consistent to do so here too.",0,0.9850552082061768
109150487,2772,michaelandrepearce,2017-03-31T12:39:53Z,"good spot, and its a very good point, will adjust to make it more consistent. thanks :)",1,0.9961597919464111
109287859,2772,radai-rosenblatt,2017-04-01T16:01:42Z,"nit pick - returns all headers _in the order they were added in_, also clarify if returns null or some empty collection if nothing found",0,0.9921442270278931
109287981,2772,radai-rosenblatt,2017-04-01T16:09:02Z,header doesnt allow for a null key. should lastheader(null) throw or just return nothing?,0,0.9808858036994934
109288040,2772,radai-rosenblatt,2017-04-01T16:12:35Z,can this inner class be made static? if so would save an outerclass.this call above,0,0.9942860007286072
109292288,2772,michaelandrepearce,2017-04-01T19:32:43Z,"yes this one could have been, it was using java 8 feature previous, was simply quickly removing our usage of java 8, as kip 118 isn't in master and thus would cause a build failure as still needing java 7 support atm. i will change to static inner class for now. didn't actually even need the recordheaders.this call it the method call filter was in scope, but will make it a static inner class. n.b the other closeaware iterator we cannot make static inner, as it needs reference to isclosed, unless we made that an atomic which would be more of an overkill imo.",0,0.9503495097160339
109292305,2772,michaelandrepearce,2017-04-01T19:33:15Z,"good point, behaviour should be as per creating a header with a null, and throw.",0,0.6030928492546082
109292344,2772,michaelandrepearce,2017-04-01T19:34:00Z,"will update java doc with additional detail, was just copying java doc that was as per kip page for the interfaces.",0,0.98655104637146
110308619,2772,becketqin,2017-04-07T02:56:08Z,can we use standard java doc in the public interface?,0,0.9945551156997681
110308937,2772,becketqin,2017-04-07T03:00:14Z,this java doc seems a little misleading. even for kafka 0.11 we can still use this constructor to construct a consumer record although the headers is empty. and the message format will still be in 0.11.,0,0.9133544564247131
110310796,2772,becketqin,2017-04-07T03:27:30Z,it is a little unfortunate that we have to do this hack just to maintain the backwards compatibility of the serializer and deserializer interface. there were some discussion about this on the side channel that we hope can start to use java 8 so a default implementation can be added to the existing serde interface. personally i think it is fine to just start to set sourcecompatibility to 1.8 in this patch and drop support for java 1.7 given that kip-118 has already passed. this way we can avoid this hack. what do you think?,-1,0.6726416349411011
110314115,2772,becketqin,2017-04-07T04:22:00Z,can we rename this to `closeheaders`?,0,0.9942358136177063
110314866,2772,becketqin,2017-04-07T04:34:55Z,is this change intentional? this change will cause an additional memory copy in `defaultrecord.readfrom()`.,0,0.9908610582351685
110315042,2772,becketqin,2017-04-07T04:37:46Z,it seems we already has a `record.empty_headers`. can we reuse that?,0,0.9947704672813416
110315300,2772,becketqin,2017-04-07T04:41:46Z,"""recordheaders has been closed.""",0,0.9909027218818665
110315649,2772,becketqin,2017-04-07T04:47:10Z,it is a little tricky here because we would require the order of the header to be the same as well. i am wondering if this would be a little too demanding.,-1,0.8504810333251953
110316068,2772,becketqin,2017-04-07T04:53:50Z,see previous comment about memory copy.,0,0.9890378713607788
110316561,2772,becketqin,2017-04-07T05:02:32Z,is there any special consideration of creating a mutable new header here?,0,0.9875083565711975
110316924,2772,becketqin,2017-04-07T05:08:16Z,do we want to close the headers here?,0,0.9929760694503784
110319166,2772,michaelandrepearce,2017-04-07T05:39:29Z,"the discussion in the kip seemed to come to conclusion we only want to close them on produce. as in consume if you consume you may wish via the interceptors to manage the headers again, e.g. remove it. on the front of mutability if you change the headers but consumed again the headers would be per the original messages as it would be created again. this is different to the producer record issue, which is why we closed that during send.",0,0.9904189705848694
110319402,2772,michaelandrepearce,2017-04-07T05:42:32Z,"so here the only thing we do is create the header object which is string, byte[]. as per kip. should note the string is memory copied already. as such we can make this a buffer but a line or two down when we hand over to the header object it would be a byte[]. also same comment as above, in kip we agreed on interface to be byte[] we can change this to a bytebuffer, and personally not opposed to this, just we should note, it would be a change to the kip",0,0.9650275111198425
110319457,2772,michaelandrepearce,2017-04-07T05:43:11Z,"yes we could, alas the import check would fail, i can amend the import check and reuse it. i will do this",0,0.9611302018165588
110319516,2772,michaelandrepearce,2017-04-07T05:44:06Z,"sure, good point, was just copying off the kip document. i will do this.",0,0.8792102932929993
110319547,2772,michaelandrepearce,2017-04-07T05:44:24Z,sure :). i will do this,1,0.8971973657608032
110319762,2772,michaelandrepearce,2017-04-07T05:47:12Z,"so this is to the equality of arraylist equals. i believe therefor we get this for free. as per java doc compares the specified object with this list for equality. returns true if and only if the specified object is also a list, both lists have the same size, and all corresponding pairs of elements in the two lists are equal. (two elements e1 and e2 are equal if (e1==null ? e2==null : e1.equals(e2)).) in other words, two lists are defined to be equal if they contain the same elements in the same order. we should also note ordering is important, as noted in kip discussion as we use the ordering for add/lastheaders, as such if i had two headers but for the same key the order was different, lastheaders would return differently, therefor i would argue the headers are there for not equal.",0,0.9620761871337891
110319886,2772,michaelandrepearce,2017-04-07T05:49:07Z,"this is inline with the comment left when the constructor for timestamp was added. it also is the same, it created a valid / correct message format still, and you can still use the constructor. see constructor directly above, its pretty much a copy and paste job, with just slight modification. constructor comment added when 0.10 changes done. * creates a record to be received from a specified topic and partition (provided for * compatibility with kafka 0.9 before the message format supported timestamps and before * serialized metadata were exposed). * our new constructor comment with 0.11 changes, following same lines. * creates a record to be received from a specified topic and partition (provided for * compatibility with kafka 0.10 before the message format supported headers).",0,0.9788064360618591
110320089,2772,michaelandrepearce,2017-04-07T05:51:45Z,"yes there was. so that it is set so if someone in their consumer interceptors consumes and needs to modify headers. also recordheaders uses array list, which does an empty array memory saving, so really the over head for cleaness of code and keeping in line with producerrecord, for empty headers the overhead is just the recordheaders object, no real sizeable data/memory. if this really is of a concern, we could do null and then have a if null create lazily on the headers() method. though we wouldn't be able to make the same saving on producerrecord as we call the headers() method on send to get them, if we wanted to do the same we would need to introduce a hasheaders() or headerssize() method on the producer/consumer record, so you can avoid calling headers() and initialising the object. also trying to make this saving would cause complexity where we want to provide headers to the ser/des for the linkedin use case's [a link] where they may need or want access to headers, we need to pass headers object, if not to force it to handle null headers also which would uk.",0,0.9806813597679138
110321627,2772,michaelandrepearce,2017-04-07T06:08:18Z,"yes it was, as the kip interface and constructor for a header is byte[]. when we create the headers in producer it will be a byte[] as such this would not be any memory copy, like wise on consume when the header is read a byte[] would need to be returned as such any saving would be negated. if we want bytebuffer, then it would be best to change that you construct headers with a bytebuffer value, and like wise byte[] value(), changes to bytebuffer value(). im not opposed to this, just isn't as agreed in kip, we would update the kip if we changed this.",0,0.9811168313026428
110321649,2772,michaelandrepearce,2017-04-07T06:08:36Z,sure. i will do this.,0,0.9772207736968994
110321692,2772,michaelandrepearce,2017-04-07T06:09:16Z,"yes totally agree, and as per commit comment, this was for lack of java 8 optimisation.",0,0.9540594816207886
110335355,2772,michaelandrepearce,2017-04-07T07:55:24Z,"on seeing what we can do to try alleviate your concern as much as possible we can make it so it uses bytebuffer, again we should note though, that on header.value() will incure a memory copy still, as simply we move when this copy occurs. as such its only incurred if the header is read.",0,0.9824915528297424
110335364,2772,michaelandrepearce,2017-04-07T07:55:29Z,"on seeing what we can do to try alleviate your concern as much as possible we can make it so it uses bytebuffer, again we should note though, that on header.value() will incure a memory copy still, as simply we move when this copy occurs. as such its only incurred if the header is read.",0,0.9824915528297424
110414387,2772,ijuma,2017-04-07T15:17:32Z,"as i explained here [a link] we need to update our system tests infrastructure to run with java 8 before we can make the switch. it may take a bit of time to get that done, so my suggestion was to do what can be done with java 7 in the initial pr and file a jira for the follow-up work once the java 8 switch happens. that way, we can make progress instead of being blocked.",0,0.9811689853668213
110428445,2772,michaelandrepearce,2017-04-07T16:22:17Z,"ok, so i have pushed a commit to revert back to java 7 (again) so this pr could be merged to make progress. i have locally stashed the java 8 changes for later.",0,0.9732319116592407
112817815,2772,hachikuji,2017-04-22T20:16:43Z,nit: is this needed?,0,0.9602025747299194
112817938,2772,hachikuji,2017-04-22T20:22:21Z,nit: could we use `record.empty_headers` instead of `null` for all of these?,0,0.9940550327301025
112817953,2772,hachikuji,2017-04-22T20:23:03Z,we should probably update the producer and consumer config documentation to mention these new interfaces. it should probably also be added to the kip.,0,0.9920763969421387
112818039,2772,hachikuji,2017-04-22T20:26:11Z,"does this need to be public? not much harm, but maybe unnecessary.",0,0.7376067042350769
112818193,2772,hachikuji,2017-04-22T20:32:52Z,"could replace this constructor with `this(key, utils.wrapnullable(value))`?",0,0.9937835931777954
112818215,2772,hachikuji,2017-04-22T20:34:10Z,maybe we should cache this value and potentially set the buffer to null?,0,0.9927869439125061
112818309,2772,hachikuji,2017-04-22T20:39:09Z,"if we added another method `add(string key, byte[] value)`, would there be any need to expose a concrete implementation of `header`?",0,0.9949280023574829
112818423,2772,hachikuji,2017-04-22T20:45:15Z,"if we want this package to be included in the javadocs (i.e. if we want it to be exposed to users), then we need to update `build.gradle`.",0,0.9947975873947144
112819053,2772,michaelandrepearce,2017-04-22T21:17:13Z,"no its not, was just left in by accident, good spot, will remove.",0,0.7032752633094788
112819065,2772,michaelandrepearce,2017-04-22T21:17:59Z,"makes sense, will update.",0,0.9867188334465027
112819106,2772,michaelandrepearce,2017-04-22T21:19:55Z,"agreed, was hoping that we get to have source in java 8 and thus then don't need these class's. as discussed previously we will do the java 8 changes in separate pr, once kip 118 is implemented.",0,0.9820485711097717
112819124,2772,michaelandrepearce,2017-04-22T21:21:09Z,"agreed. though based on below comment on note on cache and set buffer to null, then for the byte[] constructor, we should then not wrap but simply set the byte array value.",0,0.9911579489707947
112819135,2772,michaelandrepearce,2017-04-22T21:21:43Z,"a nice optimisation, this actually saves us on the produce side, as we don't then need to wrap the byte array and then unwrap it again.",1,0.7394534945487976
112819183,2772,michaelandrepearce,2017-04-22T21:24:22Z,"agreed, i recall during the kip discussion we originally had add(string key, byte[] value) but someone (will need to trawl the history) requested it to be add(header header). im happy having both, as such will add it, and once merged to master will update the kip document and send out a notification.",1,0.9436490535736084
112819919,2772,michaelandrepearce,2017-04-22T22:14:22Z,"no it doesn't. again anyhow once kip 118 (java 8) is done, will raise separate pr, which this would be removed anyhow. this is so we can merge/commit to master with current java 7.",0,0.9916521906852722
112821175,2772,michaelandrepearce,2017-04-22T23:27:53Z,"thanks, will update",1,0.8372783660888672
113302283,2772,hachikuji,2017-04-25T20:31:46Z,"since we now only have the `header` and `headers` classes public, maybe we could locate them under `common`?",0,0.9947169423103333
113338574,2772,michaelandrepearce,2017-04-25T23:51:50Z,"i was purposely wanting to avoid that and use packaging structure to keep things tidy/grouped together as is nicely done with other parts, else the common package level (one level up) would become a dumping ground over a period, if that approach was constantly taken. this is simply allowing package org.apache.kafka.common.record import org.apache.kafka.common.header",0,0.9508233666419983
113436597,2772,ijuma,2017-04-26T12:22:16Z,this constructor doesn't take a timestamp. is that intentional?,0,0.8731407523155212
113438319,2772,michaelandrepearce,2017-04-26T12:31:15Z,"yes it was, there is a constructor line 66, that does take timestamp, which this one delegates to. [code block]",0,0.9927773475646973
113439712,2772,ijuma,2017-04-26T12:38:23Z,"yes, but one takes `headers` and the other takes `iterable ` and it's unclear why that is so.",0,0.9392235279083252
113455023,2772,michaelandrepearce,2017-04-26T13:46:11Z,"ah no that is a mistake it should be `iterable `, gotcha now, good spot, will correct it.",1,0.5409054756164551
113456401,2772,michaelandrepearce,2017-04-26T13:51:12Z,fix committed.,0,0.9885330200195312
113772475,2772,hachikuji,2017-04-27T18:42:20Z,fair enough.,0,0.9010565876960754
113832198,2772,ijuma,2017-04-28T00:38:49Z,"nit: we typically don't use all caps in our javadocs. it's ok to just say ""all headers"", i think. there are a few cases like this.",0,0.9837592840194702
113832491,2772,ijuma,2017-04-28T00:41:59Z,"i don't think this comment is accurate. [code block] and `arrays.aslist.toarray`: [code block] i'd just remove the comment. the code is implemented as one would expect, we don't need to worry about java's implementation details.",0,0.9807106852531433
113832530,2772,ijuma,2017-04-28T00:42:27Z,"no need for this comment, it just repeats what the code is doing.",0,0.9792683124542236
113833156,2772,ijuma,2017-04-28T00:49:14Z,"as you can see in the code i pasted in the other comment, the first thing that the constructor does is call `c.toarray` so it actually depends on the collection. `arraylist` does `arrays.copyof` today, but could be something else later. i think a single comment at the top saying ""use efficient copy constructor if possible, fallback to iteration otherwise"" is clear and not dependent on implementation details.",0,0.9920937418937683
113833598,2772,ijuma,2017-04-28T00:53:59Z,`headers` is missing from here and from the other `append` that was added.,0,0.9927682876586914
113833664,2772,ijuma,2017-04-28T00:54:42Z,`front` seems to be redundant,0,0.9620509147644043
113833820,2772,ijuma,2017-04-28T00:56:07Z,nit: `standardcharsets.utf_8` is nicer than `charset.forname`,0,0.9822551012039185
113834118,2772,ijuma,2017-04-28T00:58:41Z,"it would be good to exercise a few more methods after `remove` is called. also, it would be good to interleave `add` and `remove` calls in one test.",0,0.9855422973632812
113834436,2772,ijuma,2017-04-28T01:01:31Z,"i was thinking about this and maybe `close` is not the right name. because we can still use the class, we simply cannot mutate it any more. the name that came to mind is `seal`, but maybe that's not clear either. we could do the boring `closeforupdates` or something like that. thoughts?",0,0.7765409350395203
113834747,2772,ijuma,2017-04-28T01:04:50Z,we should check the keys too in every case in this test.,0,0.9928132891654968
113835397,2772,michaelandrepearce,2017-04-28T01:12:53Z,"close, is what was the end method, in the kip discussion, and is naturally for java what you tend to implement closable interface for.",0,0.9867218732833862
113835523,2772,michaelandrepearce,2017-04-28T01:14:22Z,agreed.,0,0.9005043506622314
113835615,2772,ijuma,2017-04-28T01:15:30Z,"this is an internal method, so it's really part of the kip. in java, you typically can't use a class after you call `close()`, so i don't really agree. for example, using try with resources doesn't make sense for this class.",0,0.8748823404312134
113836292,2772,ijuma,2017-04-28T01:22:33Z,"one more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.",0,0.987630307674408
113837107,2772,michaelandrepearce,2017-04-28T01:33:15Z,"it is true, that as you say, it is meant to be no longer useable. how about setreadonly() inline with file.setreadonly() from java api's",0,0.9923489093780518
113837206,2772,michaelandrepearce,2017-04-28T01:34:34Z,will remove,0,0.9702575206756592
113837251,2772,michaelandrepearce,2017-04-28T01:35:05Z,will add,0,0.9739036560058594
113837325,2772,michaelandrepearce,2017-04-28T01:36:00Z,laptop died as i was committing this will do tomorrow now. could we merge? and i open another pr tomorrow?,0,0.9317717552185059
113837349,2772,michaelandrepearce,2017-04-28T01:36:20Z,will enhance,0,0.9352317452430725
113837395,2772,michaelandrepearce,2017-04-28T01:36:57Z,"sure, more test ideas always welcome",0,0.9645042419433594
113869779,2772,michaelandrepearce,2017-04-28T07:34:41Z,added,0,0.9267084002494812
113869831,2772,michaelandrepearce,2017-04-28T07:34:58Z,added,0,0.9267084002494812
95493943,2330,ewencp,2017-01-11T01:08:45Z,nit typo: mey,0,0.7253204584121704
95495767,2330,ewencp,2017-01-11T01:25:32Z,it seems like the channelbuilder implementations respect the possibility that these are null but we always seem to pass `none` if we don't want an implementation? did the intended usage just diverge during development of the pr? should we stick to only one or the other?,0,0.9864259958267212
95502827,2330,ewencp,2017-01-11T02:37:23Z,"nit throughout -- all lowercase is fine for stuff like comments, but for user-facing messages, it'd be nice to emphasize proper capitalization, grammar, etc.",0,0.9454200267791748
95503095,2330,ewencp,2017-01-11T02:41:00Z,"not critical since these aren't public apis, but there are a bunch of references to methods in these javadocs that could be ``ified.",0,0.9776487946510315
95503684,2330,ewencp,2017-01-11T02:48:51Z,it seems this class isn't even used anywhere. maybe we should just remove it entirely?,0,0.9625185132026672
95505219,2330,ewencp,2017-01-11T03:09:58Z,"using the `memorypool` for `networkreceive` only works if everyone actually uses the `memorypool` for all relevant allocations. there are still uses of the other constructores -- this is only used by `kafkachannel`. i just want to verify we know the implications of leaving the other ones. obviously the constructor with `bytebuffer` doesn't need the `memorypool`. a few are used in `saslclientauthenticator`/`saslserverauthenticator`. those seem fairly reasonable (one is unbounded, which doesn't seem ideal, although i'm not sure a bound can easily be placed on it). the last case is in `blockingchannel`. it seems this is only used in controlled shutdown. i assume the kip was mainly targeted at client requests and the controlled shutdown message is constrained enough in its request size that we just don't need to worry about that case? (i'm not sure how completely we want to make the enforcement for this kip, i.e. want to catch everything except stated exceptions to protect against even malicious users or if we are just trying to address ""accidental"" issues caused by clients.)",0,0.9838864207267761
95505706,2330,ewencp,2017-01-11T03:17:19Z,"re: comment, do you have a stacktrace or something from where this happens? would be good to know if there's a valid case or if the condition checked a few lines up should be `receivesize <= 0`. intuitively, a zero length receive seems like it would be invalid (but possible for clients to transmit, and so perhaps handled gracefully even if it is invalid).",0,0.9853277206420898
95505922,2330,ewencp,2017-01-11T03:20:24Z,these don't need `public` on them since it's an interface.,0,0.9898402690887451
95506702,2330,ewencp,2017-01-11T03:31:41Z,would this be worth raising to `warn`? seems like it might be relevant for users to know via the logs that they are effectively throttling reads. or are we assuming the new sensor is sufficient?,0,0.9882523417472839
95508527,2330,ewencp,2017-01-11T04:00:44Z,"this is fine. you can also put those all in an array and just index with `min(ordinal, units.length-1)`.",0,0.9849897623062134
95508782,2330,ewencp,2017-01-11T04:04:41Z,"is there any concern that we might lose track of updating this properly? it's not just an issue with adding new request types; it's also a problem if a request type that didn't have `bytes` or `nullable_bytes` fields is updated to a version of the schema that does have them. i'm skeptical that folks will even know about, let alone remember to update, this list if they introduce such a field. would some sort of static determination based on the full list of schemas be more reliable but equally fast?",-1,0.5354661345481873
95511403,2330,ewencp,2017-01-11T04:44:34Z,"is there any concern about efficiency here? in particular, this allocates a new list and runs an additional linear time algorithm. a simpler alternative that has weaker randomization guarantees would be to select a random starting offset and use a couple of iterators to implement a sort of rotated view of the original list. or perhaps overall it's not a concern since we have a linear cost to process all the keys anyway?",0,0.9865860939025879
95548748,2330,ijuma,2017-01-11T10:15:32Z,"i think it would be nice to avoid unnecessary naming inconsistencies between this and `bufferpool`. it may make sense to deviate in some cases, but could you take a pass and see if some names here or there should be renamed for consistency?",0,0.9911367893218994
95550443,2330,ijuma,2017-01-11T10:25:52Z,"`controlledshutdown` only uses `blockingchannel` if the `inter.broker.protocol.version < 0.9.0.0`, so it's safe to ignore. it's only there to allow rolling upgrades from 0.8.x. i haven't checked the other cases, it would indeed be good to know if there's a good reason why they are not using the memory pool.",0,0.9921505451202393
95582422,2330,rajinisivaram,2017-01-11T13:59:16Z,are there scenarios where you would expect this to be different from `transportlayer#ready()`?,0,0.9945517182350159
95583150,2330,rajinisivaram,2017-01-11T14:03:43Z,perhaps you want to return `this.ready()`? it looks like both ssl and sasl handshakes are done without using the memory pool. so the check should be for any handshake.,0,0.99458909034729
95584021,2330,rajinisivaram,2017-01-11T14:08:42Z,i am not sure of the value of this loop. it is muting a subset of channels (ones that are not in handshake and have not allocated memory and have started read). channels not muted here and new channels are muted when and only when allocation for read fails. wouldn't it be better to do the same for the subset handled here as well and remove this loop altogether? it seems to me that this loop simply prevents channels from reading the 4-byte size for which space has already been allocated.,0,0.6934894323348999
95589701,2330,rajinisivaram,2017-01-11T14:38:14Z,"not sure about this. `ssltransportlayer#hasbytesbuffered` returns true if there is any data in `netreadbuffer`. if more data is needed to unwrap and no data arrives from the client, i think the handling of `keyswithbytesbuffered` results in a tight polling loop with timeout=0.",0,0.989866316318512
95611883,2330,rajinisivaram,2017-01-11T16:13:52Z,i think you can have empty message body in sasl exchanges.,0,0.9857805371284485
95612479,2330,rajinisivaram,2017-01-11T16:16:22Z,perhaps we don't want to release `empty_buffer`?,0,0.9892746806144714
95613398,2330,rajinisivaram,2017-01-11T16:19:58Z,"similar to the mute in `poll()` - the mute could be delayed until a buffer needs to be allocated? it is possible that the channel already has a buffer allocated, in which case, we want it to complete read.",0,0.9939234852790833
95638139,2330,ewencp,2017-01-11T18:17:51Z,"it's just more proactive, right? if you're out of memory, you're not going to be able to do anything (beyond the handshake) on any channel anyway. i think the value is that instead of going through a more polling unnecessarily only to end up muting all the channels, you can just do so immediately.",0,0.9511253833770752
95754342,2330,rajinisivaram,2017-01-12T09:41:39Z,"the code looks like it is proactively closing most channels. but actually it closes a small subset of channels. channels can be in one of these states: 1. handshake 2. authentication 3. waiting to receive a message (receive == null) 4. received partial message size (receive != null, buffer == null) 5. received size and partial message body (receive != null, buffer != null) 6. muted after receiving size due to oom 7. explicitly muted 8. disconnect the loop actually handles only 4). it mutes 2) at the moment, but that is pointless since authentication doesn't use the pool, so that needs fixing anyway. 4) already has the size buffer, so there is not much point in muting before size is read, after which it will move to 6) if still oom. muting proactively is not particularly helpful since disconnect processing gets delayed as well, hence 3) is not muted. if we decide to allocate small buffers outside the pool to handle consumers as mickael has suggested, it will be useful to mute only in one place - i.e. when a buffer needs to get allocated and its size is known. i think `isinmutablestate` is unnecessary if muting is done on allocation failure and that makes the code simpler.",0,0.9786513447761536
95868086,2330,radai-rosenblatt,2017-01-12T19:37:53Z,"mostly because i was going after a specific oom scenario - dos by large producer requests. anything can be ""opted-in"" to using memory pools later on, i was trying to solve just one problem.",0,0.896208643913269
95868466,2330,radai-rosenblatt,2017-01-12T19:39:30Z,i originally had a <= 0 check which triggered while testing my code. it surprised me (as evident by the comment) but i decided to live with it instead of tracking it down. also looks like its an expected scenario. i'll update the comment to reflect this,0,0.9512505531311035
95868992,2330,radai-rosenblatt,2017-01-12T19:41:59Z,"thats a good idea, i'll see if i can improve this.",1,0.8658446073532104
96104452,2330,radai-rosenblatt,2017-01-14T01:43:22Z,"i account for null as a safety net even though using none is clearer. so its both by design. having said that, i'll gladly go for one or the other if there's a style guideline.",0,0.9369867444038391
96104700,2330,radai-rosenblatt,2017-01-14T01:48:29Z,personally i dont think this is a warning - its normal operations. users who care can get at this information in a much better way via the sensors exposed in this kip.,0,0.9338263869285583
96105233,2330,radai-rosenblatt,2017-01-14T02:00:23Z,this whole clause is (in my opinion) premature optimization of an edge case - trying to guarantee fairness when operating under memory pressure and assuming that selectionkeys iteration order is not pseudo random. i'll improve on it if you insist but i would prefer to wait for real world complaints,0,0.8162397742271423
96512094,2330,radai-rosenblatt,2017-01-17T21:16:12Z,- i've implemented a simple schema visitor and used that to find the relevant api keys for this dynamically. please see the revised code.,0,0.9800869226455688
96512145,2330,radai-rosenblatt,2017-01-17T21:16:26Z,done,0,0.8974218964576721
96512217,2330,radai-rosenblatt,2017-01-17T21:16:50Z,done,0,0.8974218964576721
96512883,2330,radai-rosenblatt,2017-01-17T21:19:43Z,"right now no, this exists as a separate api becuase its a different ""aspect"". ideally under java8 i could have made this a method with a default impl",0,0.9886230826377869
96513168,2330,radai-rosenblatt,2017-01-17T21:21:02Z,again - its an issue of mutability vs ready being 2 logically different things (even if they are tied for the 2 current implementations of transport). you could think of a future qos implementation where inter-broker transports arent mutable (as opposed to client-broker transports),0,0.9807583093643188
96514142,2330,radai-rosenblatt,2017-01-17T21:25:51Z,"ssltransportlayer#hasbytesbuffered returns true if either the net or app buffers have data. its possible that net is done/empty, nothing will ever again be coming out of the socket, but there is data unread in app buffer (so already decrypted, just not read out)",0,0.9871913194656372
96515272,2330,radai-rosenblatt,2017-01-17T21:30:48Z,it looks like this code is only ever called from tests?,0,0.9894232153892517
96522660,2330,radai-rosenblatt,2017-01-17T22:08:37Z,done,0,0.8974218964576721
96522883,2330,radai-rosenblatt,2017-01-17T22:09:40Z,"i have removed the ""mute everything in advance"" loop in favor of letting channels mute themselves.",0,0.986570417881012
96606921,2330,rajinisivaram,2017-01-18T10:42:38Z,"if this code was only called from tests, then channels would remain in `explicitlymutedchannels` forever :-) it is actually called by the broker - mute/unmute to control reading from the channel and hence the need to track explicitly muted channels.",1,0.8871694207191467
96609022,2330,rajinisivaram,2017-01-18T10:54:43Z,"-rosenblatt i agree you do need the logic to read buffered data from `ssltransportlayer`. but i think the implementation needs to ensure that it doesn't end up in a tight polling loop when attempting to drain the buffered data. when there is data in the app buffer, it is reasonable to set timeout=0 and read the data. when there is some data in the net buffer, it is likely that more data is required to unwrap the data to move it from net to app buffer. if there is a network issue that stops any more data arriving, then i think `keyswithbytesbuffered` will set timeout=0 and continue in a polling loop until idle timeout causes the connection to be closed (i.e. 10 minutes of tight polling).",0,0.9901700615882874
96611992,2330,rajinisivaram,2017-01-18T11:11:49Z,-rosenblatt it is also about which layers need to know about these different aspects. does `ssltransportlayer` really need to know about mutability of buffers? and the reason i suggested the change was because `kafkachannel.isinmutablestate()` should return false if either of the conditions in `this.ready()` is false (i.e. transport layer handshake or authenticating). i don't think it makes sense for transport later or authenticator to have to worry about mutability of buffers.,0,0.9893250465393066
96612136,2330,rajinisivaram,2017-01-18T11:12:44Z,see comment below.,0,0.9845473170280457
96726102,2330,radai-rosenblatt,2017-01-18T20:25:46Z,": 1. is it guaranteed that if there's anything in net buffer after a read there must always be more incoming? because if so i can just react solely to data in app buffer. 2. i think i now understand the scenario you describe. my ""best"" idea of how to solve it would be have a boolean return value from pollselectionkeys() to indicate if any ""progress"" has been made. if no progress has been made in the previous call to poll() the next call would not set timeout to 0. my issue with this solution is that getting progress indications out of channel.read() / channel.write() is a non-trivial refactor (they are currently designed to return null or a complete object, would need to be extended)",0,0.8871756792068481
96774619,2330,radai-rosenblatt,2017-01-19T01:25:16Z,- i've introduced a simple (relatively...) notion of progress made to try and prevent the tight loop you pointed out.,0,0.9467959403991699
96777022,2330,radai-rosenblatt,2017-01-19T01:47:23Z,- i've dropped transport.ismutable() in favor of just calling ready(),0,0.9922052025794983
96855844,2330,rajinisivaram,2017-01-19T13:10:48Z,it may be better to call `this.ready()` rather than `transportlayer.ready()` authenticators don't use the memory pool and channels don't need to be muted during authentication.,0,0.9943150877952576
96856882,2330,rajinisivaram,2017-01-19T13:17:12Z,"why does this check `datainbuffers`? with ssl, poll will go through this conditional block most of the time and it (the trace in particular) can be confusing. wouldn't the first poll after oom is reset handle the unmute?",0,0.9646285772323608
96858147,2330,rajinisivaram,2017-01-19T13:25:02Z,you want the loop to read even when there is no data from the network. so the condition needs to be something along the lines of `if (channel.ready() && (key.isreadable() || channel.hasbytesbuffered()) && !explicitlymutedchannels.contains(channel) && !hasstagedreceive(channel))`,0,0.9935865998268127
96859079,2330,rajinisivaram,2017-01-19T13:30:26Z,"since`keyswithbytesbuffered` was cleared earlier, it needs to be populated regardless of the status of staged receives. i think `""if(..) { keyswithbytesbuffered.add(..); }""` should be done outside the outer if that checks staged receives.",0,0.994880199432373
96860499,2330,rajinisivaram,2017-01-19T13:39:14Z,"the current implementation of `addtocompletedreceives` moves receives from staged to completed state if the channel is not muted. i think it will better to replace `!channel.ismute()` with `!explicitlymutedchannels.contains(channel)`. buffers have already been allocated for the staged receives, so we should allow them to make progress and release the buffers.",0,0.9941169023513794
96914943,2330,radai-rosenblatt,2017-01-19T17:41:09Z,"this isnt about handling the unmute, this is about not waiting (up to 300ms currently) on other sockets if we know we have socket(s) with data in buffers that we can read immediately.",0,0.9722685813903809
96919823,2330,radai-rosenblatt,2017-01-19T18:05:03Z,"will do. also, to save on the cost of the explicitlymutedchannels map, do you think its better to replace it with an extra boolean flag on channel? have boolean muted and boolean explicitelymuted? (or rather bool mutedforoom and bool mutedforordering)",0,0.9922871589660645
96948979,2330,rajinisivaram,2017-01-19T20:21:01Z,"i think it would be slightly neater to store the muted state in channel rather than selector (not necessarily to save on cost, it just feels like channel state).",0,0.974653422832489
96949265,2330,rajinisivaram,2017-01-19T20:22:30Z,there are two if statements - one just above this one sets timeout to zero and that needs to check `datainbuffers`. this one is just unmuting and resetting `outofmemory` flag. not sure why this needs to check `datainbuffers`.,0,0.9783810973167419
97010154,2330,radai-rosenblatt,2017-01-20T04:16:52Z,done,0,0.8974218964576721
97012152,2330,radai-rosenblatt,2017-01-20T04:47:19Z,"youre probably right. if datainbuffers = true it means either: 1. there is data in app buffer. only way (i think?) to get to this situation is that it could not be read out of app buffer because no memory, hence outofmemory will be true, which will be enough to trigger an unmute when memory becomes available 2. there's data only in net buffer. this means must data must come from socket and we have successfully read out everything that may have been in app buffer, so we didnt run oom, so channel is not muted and will show up in a future poll as a read key",0,0.9528282284736633
97012165,2330,radai-rosenblatt,2017-01-20T04:47:27Z,done.,0,0.9640594124794006
97282273,2330,rajinisivaram,2017-01-23T09:49:48Z,"-rosenblatt i tried running this test and the test passes for me when run on its own, but fails consistently when the whole class is run. this assertion is not safe since `ismadeprogresslastpoll()` can be true for various reasons including the key being writable - key may be writable for ssl handshake and so when the handshake completes, madeprogress is set. you could make the flag more conservative in the implementation, but not sure that is worthwhile - you could just remove this assertion from the test.",0,0.9914940595626831
97354296,2330,radai-rosenblatt,2017-01-23T16:19:05Z,"thats odd. the loop above explicitly waits for both handshakes to complete, and there should only ever be those 2 connections. i will remove the offending check, but i dont think its the handshake",-1,0.9791947603225708
97360992,2330,rajinisivaram,2017-01-23T16:44:24Z,"i think the loop waits for handshakes to complete from the client point of view, so the server has done its final writes. but kafka's ssltransportlayer code updates its handshake status a bit lazily, so there is a small window where the server has not yet updated its status after the final write.",0,0.9800467491149902
97428810,2330,rajinisivaram,2017-01-23T22:10:53Z,sslsender?,0,0.9820599555969238
97453785,2330,radai-rosenblatt,2017-01-24T00:59:21Z,fixed,0,0.9281549453735352
97744192,2330,rajinisivaram,2017-01-25T10:01:45Z,"-rosenblatt this needs to be ""tlsv1.2"" to work with java 7 since the server side properties in tests explicitly set ""tlsv1.2"" and the default tls version in java 7 is lower.",0,0.995173990726471
97749640,2330,rajinisivaram,2017-01-25T10:29:09Z,"minor typo (doesn't impact the test, but is confusing). i think you want to use `sslserverconfigs` here and remove `sslclientconfigs` setting just above since only one server channel builder is used in the test?",0,0.9157381057739258
97924111,2330,junrao,2017-01-26T02:43:40Z,this seems never used?,0,0.8500399589538574
97924116,2330,junrao,2017-01-26T02:43:46Z,does oomtimesensor need to be volatile?,0,0.9906277656555176
97924129,2330,junrao,2017-01-26T02:43:54Z,sizebytes = > sizeinbytes maxsingleallocationsize => maxsingleallocationbytes?,0,0.9934819340705872
97924148,2330,junrao,2017-01-26T02:44:08Z,"probably better with ""requested size "" + sizebytes + "" <=0 ""?",0,0.9937641620635986
97924251,2330,junrao,2017-01-26T02:45:33Z,"in the case when the memory pool is full for a long time, we may not be able to update oomtimesensor for a long period of time, which can make metric inaccurate. we could probably update the sensor periodically (e.g., based on the window size of sensor) when the allocation is unsuccessful?",0,0.9780147075653076
97924265,2330,junrao,2017-01-26T02:45:45Z,could we just iterate explicitlymutedchannels directly?,0,0.9934231638908386
97924301,2330,junrao,2017-01-26T02:45:58Z,perhaps we can use a better name for keyswithbytesfromsocket since selectedkeys() include keys ready for writes too.,0,0.9949613809585571
97924332,2330,junrao,2017-01-26T02:46:38Z,"when will keyshandled and selectionkeys have different size? if that happens, it seems that we still need to remove all keys in selectionkeys to clear the ""ready for selection table"" in the nio selector. also, do you know if selectionkeys.clear() clears the ""ready for selection table""?",0,0.9911602139472961
98138485,2330,junrao,2017-01-27T03:01:49Z,this constructor seems never used?,0,0.9131143689155579
98138501,2330,junrao,2017-01-27T03:01:59Z,"not very clear on the above comment. is ""do we do not"" a typo? is the comment in the right place?",0,0.8657445907592773
98138532,2330,junrao,2017-01-27T03:02:26Z,"is the check (madeprogresslastpoll && datainbuffers) necessary? datainbuffers is caused by no memory in the memory pool. it seems that it's simpler to wait for the default selector poll time, which is what we do when the pool is out of memory in other cases.",0,0.9941644072532654
98138539,2330,junrao,2017-01-27T03:02:32Z,could we just clear the set to avoid recreation overhead?,0,0.991044282913208
98138545,2330,junrao,2017-01-27T03:02:40Z,"is this test needed? if a channel is explicitly muted, it won't be selected by the selector, right?",0,0.9877551198005676
98138556,2330,junrao,2017-01-27T03:02:52Z,is the change needed since it seems memorypool is never null from the caller?,0,0.993061363697052
98138581,2330,junrao,2017-01-27T03:03:15Z,"since this is a server side metric, it's probably better to use a yammer metric to be consistent. currently, we try only using the client metric on the server side if it needs additional functionality from the client metric (e.g., quota).",0,0.9932422041893005
98138585,2330,junrao,2017-01-27T03:03:18Z,would memorypoolused be better?,0,0.9928566217422485
98138605,2330,junrao,2017-01-27T03:03:33Z,"we are not blocking the network threads, right?",0,0.92942214012146
98138611,2330,junrao,2017-01-27T03:03:38Z,"this is optional. so, it probably should be of medium instead of high?",0,0.9868867993354797
98791618,2330,radai-rosenblatt,2017-01-31T22:53:09Z,probably yes.,0,0.9819378852844238
98792151,2330,radai-rosenblatt,2017-01-31T22:56:07Z,"i dont understand. the sensor is updated on every single tryallocate call - successful or not. only way for the sensor to stop being updated is if the server id idle, in which case there should be plenty of memory available? if you want better accuracy i could update the sensor when calling release() - this by definition means we have memory, so i could zero-out the oom time",0,0.8581965565681458
98793590,2330,radai-rosenblatt,2017-01-31T23:04:19Z,"there's a (hypothetical) corner case where there's data in the ssl app buffer but the underlying socket is done. this means the socket will never come back from a poll call, and you may wait 300ms for no reason instead of servicing the buffer immediately. this is why datainbuffers exists. i agree its simpler to just wait a whole poll cycle, but this is an attempt to shave off the latency. the made progress flag exists because the downside of the above condition is you may be stuck in a tight loop trying to service the buffer and so we dont try if no progress was made previous attempt.",0,0.965323269367218
98794090,2330,radai-rosenblatt,2017-01-31T23:07:31Z,"explicitlymutedchannels are channels muted because they already have an outstanding request in progress. we never want to service them until they are (explicitely) unmuted and taken out of the set ? so this loop iterates over _all_ channels, unmuting anything that _isnt_ in explicit.",0,0.9737545251846313
98794457,2330,radai-rosenblatt,2017-01-31T23:09:53Z,renamed int readykeys --> numreadykeys and keyswithbytesfromsocket to readykeys,0,0.9920559525489807
98795499,2330,radai-rosenblatt,2017-01-31T23:16:41Z,"not really - because then topoll would be a copy ctr. i need to iterate over keys with buffered data i also need to record keys that (still?) have buffered data these have to be different sets or i would be forced to use a thread-safe collection, as i'll be modifying the structure im iterating over? this set gets ""cycled"" only when under memory pressure, so this is not expected to happen very often. i could pre-allocate both sets as instance variables on the class, if you want",0,0.936006486415863
98797148,2330,radai-rosenblatt,2017-01-31T23:26:50Z,"a channel can be in explicitelymuted and in keyswithbytesbuffered at the same time - ssl may try and read several requests at once into stagedreceives. if it reads once request and then has no memory for the next the channel will be in keyswithbytesbuffered. the 1st request out of staged will be moved to completed, causing the channel to be muted when socketserver picks it up (still on the same thread). under this condition channel.hasbytesbuffered() == true and also !hasstagedreceive(channel), causing data to be read for a channel that already has a request in progress",0,0.9845053553581238
98800869,2330,radai-rosenblatt,2017-01-31T23:52:08Z,"the sizes will differ only if some uncaught exception terminates the loop early (so never, unless bug?). the code path for different sizes is there to try and match what the previous code would produce under those conditions (which are, again, a bug). under ""normal"" operating conditions the sizes should always be the same, which i think makes the clear() calls a faster implementation (n * arraylist.add() + 2*clear() < n * set.iterator.remove()). what do you mean by ""ready for selection table""? looking at the code for openjdk 8 selectors use a normal set, wrapped to disallow external add() calls. all selectors do is call add() on the set of keys, there's no special ""hook"" to react to removes/clears",0,0.9871991276741028
98805695,2330,radai-rosenblatt,2017-02-01T00:30:15Z,"i was trying to be safe, so i ""support"" nulls by translating them to none. if you want me to choose either null or none (instead of both) - just choose which.",0,0.962481677532196
98806646,2330,radai-rosenblatt,2017-02-01T00:38:25Z,would be much simpler if i could :-d,1,0.9316761493682861
98813839,2330,radai-rosenblatt,2017-02-01T01:38:35Z,"the memorypool interface and implementations are in clients, which has no dep. on yammer. i could either add a dep on yammer (probably bad idea) or introduce an intermediary interface ?",0,0.941789448261261
98814575,2330,radai-rosenblatt,2017-02-01T01:44:32Z,also updated the kip doc,0,0.990003228187561
115627162,2330,junrao,2017-05-09T23:40:23Z,madeprogressthispoll seems unused?,0,0.9742961525917053
115627211,2330,junrao,2017-05-09T23:40:51Z,"selector is shared between client and server. so, it's better not to mention server here.",0,0.9866060614585876
115627311,2330,junrao,2017-05-09T23:41:34Z,is the comment accurate? it seems that the underlying socket may still have bytes when there is buffered data.,0,0.9925131797790527
115627435,2330,junrao,2017-05-09T23:42:31Z,keyswithbytesbuffered => keyswithbufferedread?,0,0.9939842820167542
115627563,2330,junrao,2017-05-09T23:43:35Z,previous message => previous receive,0,0.9751023054122925
115627970,2330,junrao,2017-05-09T23:47:05Z,"so it seems the only reason for this method is to optimize iterator.remove (by using keyshandled .clear())? if so, i am not sure if it's worth doing this optimization since this makes the code a bit harder to read.",0,0.9538536667823792
115859559,2330,junrao,2017-05-10T21:39:58Z,"would it be simpler to check channel.ismuted() instead of channel.isinmutablestate()? then, the latter can be a private method in kafkachannel.",0,0.9950920343399048
115883466,2330,junrao,2017-05-11T00:30:42Z,"i am wondering if we really need madeprogresslastpoll. in general, if the selector runs out of memory, selector.poll will just block for 300ms in socketserver. if datainbuffers is true, it's due to out of memory. so, it seems that it's more consistent and simpler to just wait for the default 300ms in socketserver?",0,0.9592868685722351
115891794,2330,junrao,2017-05-11T01:58:19Z,"hmm, not sure if this is very reliable since the bytes may still be in the client socket buffer. perhaps a more reliable way is to do a waituntil wrapping selector.poll() on the server side.",0,0.7282453775405884
115892226,2330,junrao,2017-05-11T02:03:23Z,& => && ?,0,0.9741683006286621
115892482,2330,junrao,2017-05-11T02:06:25Z,"since this is only called in testmuteonoom, which is overridden in sslselectortest, perhaps the method can just be private?",0,0.9949578642845154
116027427,2330,junrao,2017-05-11T15:47:43Z,could we track this at nano sec level and pass the value as double in ms for better accuracy?,0,0.9910023808479309
116027727,2330,junrao,2017-05-11T15:48:49Z,could we just set oomperiodsensor in the constructor and get rid of this method?,0,0.9951410293579102
116772044,2330,radai-rosenblatt,2017-05-16T15:13:48Z,:+1:,0,0.9166757464408875
116772303,2330,radai-rosenblatt,2017-05-16T15:14:37Z,:+1: left over from testing,0,0.9813443422317505
116776829,2330,radai-rosenblatt,2017-05-16T15:29:45Z,"- the progress indicator was added to prevent a tight looping schenarion that spotted at jan 18 (see above discussion on an old version of selector, cant find a way to link to it). i believe the issue is that there may be bights in an underlying ssl buffer that would cause timeout = 0",0,0.9812565445899963
116777012,2330,radai-rosenblatt,2017-05-16T15:30:22Z,:+1:,0,0.9166757464408875
116777231,2330,radai-rosenblatt,2017-05-16T15:31:08Z,no because a channel can be muted for 2 reasons - 1 request at a time or memory pressure.,0,0.9805583357810974
116778212,2330,radai-rosenblatt,2017-05-16T15:34:34Z,we subtract the ready set from keyswithbufferedread and to topoll (set of keys we poll from under this condition) ends up being the set of keys for which there is data in buffers but not from the underlying socket (else they would be in the ready set),0,0.993502676486969
116781172,2330,radai-rosenblatt,2017-05-16T15:44:42Z,:+1:,0,0.9166757464408875
116781268,2330,radai-rosenblatt,2017-05-16T15:45:04Z,:+1:,0,0.9166757464408875
116781973,2330,radai-rosenblatt,2017-05-16T15:47:30Z,"the sender only terminates after it completely flushes its output stream, so i would expect everything to have been written out? also, we accept() both incoming connections before the call to poll so that we know that at least handshaking has been done at that point. given that this is all local networking i think the timing is loose enough (also i've not see this fail in all the times that i've rebased and retested this branch).",0,0.9788985848426819
116783226,2330,radai-rosenblatt,2017-05-16T15:52:21Z,:+1:,0,0.9166757464408875
116784228,2330,radai-rosenblatt,2017-05-16T15:56:04Z,this assignment operator is defined differently for boolean operands (so it doesnt perform a bitwise operation) and so there is no &&=. i'll refactor the code to avoid this (as its rather obscure),0,0.9274386167526245
116801727,2330,radai-rosenblatt,2017-05-16T17:09:41Z,:+1:,0,0.9166757464408875
128666574,2330,junrao,2017-07-21T01:26:26Z,"since dispose() can be called by both network threads and request handler threads, should we make buffer volatile?",0,0.9949648976325989
128906634,2330,junrao,2017-07-22T22:54:57Z,it seems that we can just check !keyswithbufferedread.isempty?,0,0.9932042360305786
128906636,2330,junrao,2017-07-22T22:55:15Z,"hmm, it seems that madeprogresslastpoll needs to be set to false somewhere?",0,0.9737066030502319
128906639,2330,junrao,2017-07-22T22:55:28Z,"since there is no guarantee when the server will receive those bytes, should we put this code block in a waituntil loop?",0,0.9917805790901184
128906644,2330,junrao,2017-07-22T22:55:49Z,"since there is no guarantee when the server will receive those bytes, should we put this code block in a waituntil loop?",0,0.9917805790901184
128906645,2330,junrao,2017-07-22T22:55:56Z,memorypoolavgdepletedpercent => memorypoolutilization?,0,0.9878296852111816
128906650,2330,junrao,2017-07-22T22:56:02Z,memorypoolavgdepletedpercent-avg => memorypoolavgdepletedpercent,0,0.9914360642433167
128906668,2330,junrao,2017-07-22T22:56:13Z,"would it be better to name this queued.max.request.bytes? otherwise, it's not obvious what queued bytes are for.",0,0.9569511413574219
128906671,2330,junrao,2017-07-22T22:56:21Z,"instead of defaulting it to null, should we default it to defaults.queuedmaxbytes?",0,0.993283748626709
129095498,2330,radai-rosenblatt,2017-07-24T17:07:51Z,will fix,0,0.9097051620483398
129099716,2330,radai-rosenblatt,2017-07-24T17:23:54Z,will fix,0,0.9097051620483398
129099747,2330,radai-rosenblatt,2017-07-24T17:24:04Z,will fix,0,0.9097051620483398
129107398,2330,radai-rosenblatt,2017-07-24T17:53:14Z,"the test asserts on the state of the progress flag, meaning we cant call poll() more than once (2nd+ call will wipe the progress flag). will do",0,0.9906256198883057
129107452,2330,radai-rosenblatt,2017-07-24T17:53:26Z,will do,0,0.9571817517280579
129147307,2330,radai-rosenblatt,2017-07-24T20:39:15Z,will do,0,0.9571817517280579
129147337,2330,radai-rosenblatt,2017-07-24T20:39:21Z,will do,0,0.9571817517280579
129147672,2330,radai-rosenblatt,2017-07-24T20:40:48Z,will do,0,0.9571817517280579
129148372,2330,radai-rosenblatt,2017-07-24T20:43:47Z,the null was the validator. i've simply removed it now,0,0.9884752035140991
129403649,2330,junrao,2017-07-25T19:35:22Z,could we add a comment to explain why madereadprogresslastpoll is used for?,0,0.9852922558784485
129403695,2330,junrao,2017-07-25T19:35:36Z,is there a need to set madereadprogresslastpoll here? it seems we only need to set when doing reads?,0,0.9919344186782837
129403711,2330,junrao,2017-07-25T19:35:43Z,is there a need to set madereadprogresslastpoll here? it seems we only need to set when doing reads?,0,0.9919344186782837
129408331,2330,junrao,2017-07-25T19:55:20Z,"since on the server side, we release memory through requestchannel.dispose(). however, memory is also released here through kafkachannel.close(). will this cause the same memory to be released more than once in certain cases?",0,0.9950972199440002
129412615,2330,radai-rosenblatt,2017-07-25T20:14:00Z,will do,0,0.9571817517280579
129412879,2330,radai-rosenblatt,2017-07-25T20:15:14Z,"i was being cautious. but youre right, given the progress flag is only used in combination with datainbuffers its probably impossible for a poll() round to involving the progress flag to consist solely of handshaking and connecting operations.",0,0.7347567677497864
129412922,2330,radai-rosenblatt,2017-07-25T20:15:26Z,removed (see above comment),0,0.9904584884643555
129419356,2330,radai-rosenblatt,2017-07-25T20:40:32Z,"kafkachannel.receive is a receive _in progress_. once its compete its read out (field is nulled) and the buffer passed to a requestchannel.request. so any given buffer exists either as part of an in-progress receive or as part of a completed receive (that was transferred to request channel). given the transition happens on the same thread that would close a kafkachannel, i dont think this would be a problem?",0,0.9902875423431396
311655316,7170,mjsax,2019-08-07T16:46:14Z,nit: `creates` -> `create`,0,0.9918742775917053
311655490,7170,mjsax,2019-08-07T16:46:41Z,"nit: `deserializers, [and] producer's`",0,0.9880532026290894
311657543,7170,mjsax,2019-08-07T16:51:17Z,"nit: `the number of partitions is determined based on the upstream topics partition numbers.` one may use `merge()` and there may be multiple upstream topic[s] -- for this case, we use max-partitions over all upstream topics. hence, i would be a little bit more fuzzy and avoid ""inherit"" as it implies it's the same number of partitions, but that only holds for the case of a single upstream topic. i would also use ""upstream"" instead of ""input"" because there might be an upstream repartition topic, too.",0,0.9915910959243774
311658732,7170,mjsax,2019-08-07T16:54:06Z,"do we need to have those two lines? we use `` usually to point to similar method, but not to point to overloads. for example, `map()` points to `mapvalues()`, but `map()` would not point to another variant of `map()`. the idea is to point people to different functionality, but if one know about `repartition` we assume they consider all overloads they can use.",0,0.9939634203910828
311658960,7170,mjsax,2019-08-07T16:54:33Z,nit: `creates` -> `create`,0,0.9918742775917053
311659340,7170,mjsax,2019-08-07T16:55:31Z,"nit: `partitions[,] and`",0,0.9920554757118225
311660226,7170,mjsax,2019-08-07T16:57:20Z,"nit: `name[,] and` why ""if repartitioning is required"" ? from my understanding, calling `repartition()` should always repartition, ie, enforce it. that's why we included `groupby()` in the kip -- if one does not want to force repartitioning, but want to control repartition topic properties, one can pass in `repartitioned` into `groupby` but would not use `kstream#repartition`. at least, that was my understanding of the kip?",0,0.9934456944465637
311660448,7170,mjsax,2019-08-07T16:57:52Z,why `(and potentially repartitioned)` ? should be removed imho,0,0.9918183088302612
311660775,7170,mjsax,2019-08-07T16:58:39Z,as above. my comments form above also apply to the third overlaod. not repeating them again.,0,0.9881100654602051
311661094,7170,mjsax,2019-08-07T16:59:23Z,this will not render as expected in the javadocs. you need to you html markup to define bullet points.,0,0.9871973991394043
311661405,7170,mjsax,2019-08-07T17:00:04Z,nit: remove empty lines between members,0,0.9597874879837036
311661640,7170,mjsax,2019-08-07T17:00:37Z,"nit: remove ""if required"" nit: `{ repartitioned}` -> `{ repartitioned}` (no need to link to itself -- it's considered bad practice). both nits apply to other javadocs, too. will not comment on the other ones, but please fix everywhere.",0,0.9902610182762146
311663095,7170,mjsax,2019-08-07T17:04:09Z,should we add an import to avoid the long package name?,0,0.9903310537338257
311668500,7170,mjsax,2019-08-07T17:16:53Z,why not `repartitioned.as(null)` ? this way we can remove `empty()` -- it would align with the pattern we apply in existing code.,0,0.9956119060516357
311670840,7170,mjsax,2019-08-07T17:22:03Z,"compare my other comment: from my understanding, we would always repartition.",0,0.9748423099517822
311672777,7170,mjsax,2019-08-07T17:26:27Z,nit: keep existing formatting or more `.withkeyserde(...)` into its own line.,0,0.9907622933387756
311674136,7170,mjsax,2019-08-07T17:29:29Z,"as the parent class contains the corresponding member, both method should be added there",0,0.9894047975540161
311677453,7170,mjsax,2019-08-07T17:36:40Z,seems do don't need `namedinternal namedinternal` as it's own variable?,0,0.9933903217315674
311693215,7170,mjsax,2019-08-07T18:12:47Z,we should extend existing `addinternaltopic` instead of having two method.,0,0.9931290149688721
311696457,7170,mjsax,2019-08-07T18:20:30Z,updating `repartitiontopicconfig` in this method may not be the best pattern. could we pass the number of partitions into the constructor of `repartitiontopicconfig` instead?,0,0.9944928884506226
311708461,7170,lkokhreidze,2019-08-07T18:48:18Z,"yeah, that was something i wanted to verify actually. for example with dsl, user can do something like: `stream(...).mapvalues().repartition()`. in this case repartition topic doesn't make much sense. so i chose to guard against situations like that. open to suggestions.",0,0.9775719046592712
311713308,7170,lkokhreidze,2019-08-07T18:59:38Z,"i added integration test to verify that repartition topic won't be created if key-changing operation isn't performed. if number of partitions is specified, repartition topic will be created though.",0,0.9950248599052429
311803123,7170,mjsax,2019-08-07T23:27:48Z,"if we don't repartition if user calls `repartition()` what is the purpose of the operation? the new operator is similar to `through()`, with the difference that kafka streams manages the topic. note, that one motivation for adding `repartition()` was, to allow users to repartition data before `transform()`. atm, this in only possible via `through()` forcing users to create the corresponding topic manually what is cumbersome. if a user does `stream(...).mapvalues().repartition()` i agree that repartitioning is not really required, but i would see this as a user error. at the same time, i see the potential to address this in the optimization layer: if we detect this case, we could remove the `repartition()` operator. it seems to be a subtle difference, but it's semantically two different approaches ihmo -- what you suggest is to keep the operator but to make it a no-op, while i suggest to _remove_ the operator. this would result in the same topology but the code how it is achieve is different and i believe it's an important difference.",0,0.9917610883712769
311879654,7170,lkokhreidze,2019-08-08T06:54:26Z,i like the idea of addressing this on optimization layer. i think this depends on how end implementation would look like and what we gonna agree on in our main discussion thread on this pr. if we gonna have only `repartitioned` operator i guess it make sense to always force repartitioning. if we gonna go with `groupby` and potentially `join` - optimization layer should be smarter about this in that case. i'll wait for an outcome of our discussion and update this accordingly.,1,0.9118934273719788
312410620,7170,lkokhreidze,2019-08-09T09:58:28Z,"i've removed this check from here, but i'll investigate if we can do this in optimization layer as suggested in this thread: [a link]",0,0.987525224685669
312427351,7170,lkokhreidze,2019-08-09T10:51:54Z,"none of the other members have corresponding methods in parent class. do you think it's still okay to move only this two members? if that's the case, i would prefer moving all of the accessor methods there. i guess accessors are added only to `optimizablerepartitionnode` because accessing members is needed only in case of optimization (`internalstreamsbuilder#getfirstrepartitiontopicname`)",0,0.9928027987480164
312732526,7170,lkokhreidze,2019-08-11T10:18:23Z,"based on comments from i've removed `repartition` operations from optimization logic altogether. now, when calling `repartition` operations, corresponding repartition topic will be always created.",0,0.9923960566520691
316772010,7170,vvcephei,2019-08-22T16:24:53Z,"just as a general note, i 100% sympathize with the impulse to clean stuff up alongside your changes, but it would really help the reviewers if you made a pass over the pr and just removed all changes that aren't related to kafka-8611. it's not a big deal with small changes, but when the pr is over a thousand lines of code, it really adds a lot of distraction when reviewers have to consider cleanup alongside substantial changes.",0,0.8068860173225403
316781727,7170,vvcephei,2019-08-22T16:48:13Z,"i was looking at how this is used, and there are only two usages. in both cases, we create the builder, then call a method that populates the builder, then call `build()`. maybe we can just ditch the builder and invoke the constructor from that static method?",0,0.984738826751709
316783992,7170,vvcephei,2019-08-22T16:53:45Z,"this invocation has the side effect of incrementing the ""topology name counter"". in other words, this means that inserting a ""repartition"" node with a name will cause all the other processors, stores, and repartition topics in the topology to get renamed anyway. to clarify (because it's confusing) this method increments the counter even if it's not generating a name. should we consider instead making it like suppression, which does not increment the counter if you provide a name?",0,0.9548672437667847
316790193,7170,vvcephei,2019-08-22T17:09:02Z,it seems this method is unused. are we missing test coverage?,0,0.8050705194473267
316790517,7170,vvcephei,2019-08-22T17:09:48Z,"likewise, this one is unused.",0,0.9417877197265625
316790765,7170,vvcephei,2019-08-22T17:10:29Z,thanks for avoiding mutable state in this class!,1,0.8031809329986572
316794184,7170,vvcephei,2019-08-22T17:18:57Z,"it seems like this might be able to just replace `internaltopicnames`. we only add to `internaltopicnames` in one place, where we also (maybe) add to this map. we can't (shouldn't) make the value `null`, but i noticed that `internaltopicproperties` allows its parameter (`numberofpartitions`) to be null, which seems like it should have the same effect as a null `internaltopicproperties`... what do you think about requiring `iternaltopicproperties` to be non-null in `addinternaltopic`, although it might have a null number of partitions. then, we can get rid of `internaltopicnames` and just use `internaltopicnameswithproperties.keyset()`?",0,0.9916394352912903
316795023,7170,vvcephei,2019-08-22T17:21:08Z,"if we add this to `equals`, we *must* add it to `hashcode` as well, and we _should_ also add it to `tostring()`.",0,0.9934316277503967
316795418,7170,vvcephei,2019-08-22T17:22:03Z,should be final,0,0.9673837423324585
316795547,7170,vvcephei,2019-08-22T17:22:24Z,these three fields should be final as well.,0,0.988520085811615
316796336,7170,vvcephei,2019-08-22T17:24:14Z,generics can be inferred here.,0,0.9920584559440613
316796825,7170,vvcephei,2019-08-22T17:25:17Z,"variable can be final. i won't comment on final-able variables anymore. do the tests pass? there should be a check that fails on variables that aren't final, but could be.",0,0.9701753854751587
316796993,7170,vvcephei,2019-08-22T17:25:43Z,method should be static,0,0.9872879981994629
316797085,7170,vvcephei,2019-08-22T17:25:55Z,"likewise, this one can be static",0,0.9859942197799683
316798314,7170,vvcephei,2019-08-22T17:28:41Z,"not sure what the intent is here, to increment the number between each test, or between each instance of this integration test class within the jvm... it actually does the latter.",0,0.8719453811645508
316798925,7170,vvcephei,2019-08-22T17:30:02Z,"this can (and should) be a unit test, since we don't need to produce data or run kafka to build and verify the topology.",0,0.9943702816963196
316802639,7170,vvcephei,2019-08-22T17:38:10Z,"maybe consider: [code block] then, this method won't return until streams is actually started, which we've seen can increase test stability.",0,0.9936750531196594
317388374,7170,lkokhreidze,2019-08-25T08:46:32Z,"interesting... yup, checkstyletests pass. i think checkstyle don't cover `try with resources` usage. anyway, it should be final yes, will update this everywhere. thanks.",1,0.9904671311378479
317389525,7170,lkokhreidze,2019-08-25T09:19:55Z,"i can change it, sure. but personally i would prefer to have the builder here because 1) it follows same standard as other `baserepartitionnode` implementations 2) static factory method for the `unoptimizablerepartitionnodebuilder` will have a lot of parameters and it'll make code uglier. wdyt?",0,0.647132933139801
317390219,7170,lkokhreidze,2019-08-25T09:41:47Z,so that each individual test has its own input/output topics. there's code in `` that increments `test_num`,0,0.9949846267700195
317412260,7170,lkokhreidze,2019-08-25T19:50:33Z,done,0,0.8974218964576721
317412281,7170,lkokhreidze,2019-08-25T19:51:11Z,added `streamsgraphtest#shouldnotoptimizewhenrepartitionoperationisdone`,0,0.9941082000732422
317412296,7170,lkokhreidze,2019-08-25T19:51:32Z,done,0,0.8974218964576721
317412304,7170,lkokhreidze,2019-08-25T19:51:38Z,done,0,0.8974218964576721
317412334,7170,lkokhreidze,2019-08-25T19:52:23Z,done,0,0.8974218964576721
317412354,7170,lkokhreidze,2019-08-25T19:53:02Z,added tests.,0,0.9870906472206116
317412360,7170,lkokhreidze,2019-08-25T19:53:11Z,added tests,0,0.9808875322341919
317412366,7170,lkokhreidze,2019-08-25T19:53:23Z,done.,0,0.9640594124794006
317412373,7170,lkokhreidze,2019-08-25T19:53:30Z,done,0,0.8974218964576721
317412377,7170,lkokhreidze,2019-08-25T19:53:38Z,done,0,0.8974218964576721
317412381,7170,lkokhreidze,2019-08-25T19:53:44Z,done,0,0.8974218964576721
317412451,7170,lkokhreidze,2019-08-25T19:55:45Z,"very fair point, totally agree. sorry about that. there're not many changes related to ""cleanup"" in this pr, but if you think it creates noise and makes it harder to do the review, i'll revert all cleanup related code.",-1,0.9392730593681335
320850937,7170,vvcephei,2019-09-04T16:17:30Z,fair enough. thanks for the reply.,1,0.9194083213806152
320859172,7170,vvcephei,2019-09-04T16:35:57Z,"thanks for your understanding. i just mentioned it because it seemed like there wasn't a ton of review activity. just thought i'd share the tactic with you, since rightly or wrongly, the large ""diff"" numbers in the pr can scare off reviewers. for myself, i didn't have trouble overlooking it.",1,0.9716593027114868
320859948,7170,vvcephei,2019-09-04T16:37:42Z,"ah, yeah, there are some limitations to the linter. thanks for taking care of it.",1,0.6532086730003357
320861613,7170,vvcephei,2019-09-04T16:41:31Z,"i see. but even though the number gets incremented after each test method, the string `inputtopic` is already fixed when the class is constructed, so it won't automatically get incremented. i think you need to make this a method to achieve the effect you intended.",0,0.9865700602531433
320868518,7170,lkokhreidze,2019-09-04T16:57:19Z,hi thanks for the comment. sorry if i'm missing something... but junit creates new instance of the class before each test case. since those are non-static fields they'll be initialized during each test run with incremented `test_num`. i've verified it one more time and during each individual test topic number gets incremented. here are the screenshots just for the sake of clarity:,-1,0.6739751696586609
321099321,7170,lkokhreidze,2019-09-05T06:51:57Z,"makes total sense, thanks for sharing. i will definitely take this into account for the future prs.",1,0.8470370769500732
321394898,7170,vvcephei,2019-09-05T17:41:10Z,"ok, i'm convinced :) thanks for clearing up my confusion.",1,0.9949493408203125
329290021,7170,mjsax,2019-09-28T01:10:35Z,should we explain the difference to `through()`? something like: [code block] we might also update the docs for `through()` and point to the new operator. we should also cross-link using `` tags,0,0.9940102100372314
329290382,7170,mjsax,2019-09-28T01:18:11Z,"while i agree that immutability is great, i am wondering about consistency. the other configuration classes are mutable. do we think that might be of any concern? should we just update all other configuration classes an make them immutable, too? (of course not in this pr...) \cc",0,0.5104858875274658
329290536,7170,mjsax,2019-09-28T01:21:53Z,"nit: remove `this.` (we only use `this` is we must -- applies to other parts, too)",0,0.9936588406562805
329290692,7170,mjsax,2019-09-28T01:25:27Z,"this method share a lot of code with `repartition(repartitioned)` -- we should create `private dorepartition(keyvaluemapper, repartitioned)` and all 4 public method should call it and just have a block [code block]",0,0.9929038882255554
329291018,7170,mjsax,2019-09-28T01:33:09Z,"seems we should add this to the parent class? and also use `optimizablerepartitionnode` and `groupedtableoperationrepartitionnode`. as a side cleanup, we should remove the `get` prefix -> `keyserializer()` -- we should also remove the `get` from `baserepartitionnode#getkeyserializer()` (same for value)",0,0.9953486323356628
329291182,7170,mjsax,2019-09-28T01:37:28Z,not sure why we need this? couldn't we use `internaltopicconfig`?,0,0.9788706302642822
329291498,7170,mjsax,2019-09-28T01:45:23Z,wondering if we should treat `numberofpartitions` as a regular config and add to `map topicconfigs` instead using `num.partitions` as parameter name? \cc,0,0.9930663108825684
329291593,7170,mjsax,2019-09-28T01:48:31Z,it seems also a little inconsistent with `internaltopicconfig` that uses `optional` but not `int`...,0,0.9458933472633362
329291663,7170,mjsax,2019-09-28T01:50:38Z,the whole method could be simplified to (and hence removed and embedded): [code block] if we let `#getnumberofpartitions()` return an `optional`.,0,0.994655966758728
329311990,7170,lkokhreidze,2019-09-28T14:19:49Z,"thought about it, but it felt more natural to introduce separate class rather than using `repartitiontopicconfig` in current design. `repartitiontopicconfig` potentially can be package-private (haven't touched this in current pr) and i wanted to avoid leaking it through other packages. it felt like best to leave construction of `repartitiontopicconfig` in `internaltopologybuilder` class since `internaltopologybuilder` ""knows the best"" how to construct it. idea of this class is to provide bare minimum configs of internal topic properties. hope my way of thinking around this makes sense. wdyt?",1,0.7715016603469849
329329123,7170,lkokhreidze,2019-09-28T22:01:50Z,done.,0,0.9640594124794006
329329133,7170,lkokhreidze,2019-09-28T22:02:31Z,done,0,0.8974218964576721
329329200,7170,lkokhreidze,2019-09-28T22:06:17Z,"fixed, `numberofpartitions` is now optional",0,0.9939129948616028
329329236,7170,lkokhreidze,2019-09-28T22:07:25Z,"did what you suggested. `baserepartitionnode` now has following methods: [code block] i've refactored `groupedtableoperationrepartitionnode`, `optimizablerepartitionnode` and `unoptimizablerepartitionnode` accordingly.",0,0.991381824016571
329329258,7170,lkokhreidze,2019-09-28T22:08:26Z,done,0,0.8974218964576721
329329268,7170,lkokhreidze,2019-09-28T22:08:51Z,done and added more javadocs,0,0.9802844524383545
361869452,7170,lkokhreidze,2019-12-29T20:02:17Z,i've created jira ticket for it: [a link],0,0.9127859473228455
368248756,7170,mjsax,2020-01-18T21:11:21Z,nit: you need to insert ` ` markup if you want to get a new paragraph.,0,0.9871507883071899
368248926,7170,mjsax,2020-01-18T21:15:07Z,i don't think that `{ #through}` is correct markup. should be `{ #through(string)}`,0,0.9836528301239014
368249035,7170,mjsax,2020-01-18T21:16:57Z,`created topic` -> `[the] created topic is considered [an] internal topic` ?,0,0.9943273663520813
368249068,7170,mjsax,2020-01-18T21:18:01Z,"as above -> ` ` (seems other comment from above apply here, too -- won't repeat them)",0,0.9850152730941772
368249232,7170,mjsax,2020-01-18T21:21:51Z,nit: `selector` -> `keyselector` (we recently did a cleanup pr that uses `keyselector` as name is all other method that set a new key -- would be nice to align the names),0,0.9889756441116333
368249741,7170,mjsax,2020-01-18T21:33:51Z,"nit: in other classed, we just add `` tags instead of mentioning it in the text. should we do the same here for consistency?",0,0.989896297454834
368250067,7170,mjsax,2020-01-18T21:41:06Z,"we can do all `null` checks in a single place within `dorepartition()` -- also, all other methods just say ` can't be null` (ie, please remove `parameter` for consistency)",0,0.9950626492500305
368250271,7170,mjsax,2020-01-18T21:46:00Z,"i don't think we can use `this.keyserde` that should align to the type of the input key, ie, type ` ` -- instead, we should set `keyserde` to `null` if not specified by `repartitioned` and fall back to the default key serde from `streamsconfig` during runtime. (this issue is also indicated by the ""unchecked"" warning that you suppress...)",0,0.992905855178833
368250370,7170,mjsax,2020-01-18T21:48:15Z,comment seems redundant,0,0.681433379650116
368250670,7170,mjsax,2020-01-18T21:54:42Z,not sure if i understand why we need this? it seems also to be tricky to understand the code if one calls `repartitiontopicconfig#setnumberofpartitions` and nothing happens because the actual object is of type `immutablerepartitiontopicconfig`.,0,0.930310070514679
368251040,7170,mjsax,2020-01-18T22:02:16Z,"should be better throw here as this should never be called? what raised the question (we you actually do check the type already: should be flip the hierarchy as being mutable is a superset of being immutable and thus it should be `repartitiontopicconfig extends immutablerepartitiontopicconfig` -- for this case, `immutablerepartitiontopicconfig` would not have this method at all what seems to be cleaner)",0,0.9898751378059387
368251147,7170,mjsax,2020-01-18T22:05:25Z,to what extent is this check different from the check above when we call `validateandgetnumofpartitionsofimmutabletopics` -- or can we remove it here as it's redundant?,0,0.993682861328125
368251683,7170,mjsax,2020-01-18T22:16:36Z,"i am wondering, if we should really throw an exception for this case? why do we not create this repartition topic with the same number of partitions as specified on the second input topic instead? iirc, for the following case we would also adjust the number of partitions: [code block] this code above is very similar to: [code block] in both cases, the number of partitions of one topic is fixed, while the second one has key-changing operation and thus we can just create a reparition topic that matches the number of partitions of the first topics?",0,0.9819560647010803
368421799,7170,lkokhreidze,2020-01-20T08:40:38Z,thanks for the suggestion. we can do null check in `dorepartition` for `repartitioned` parameter. null check for `selector` parameter should be on upper level since in some cases we do pass selector as `null`. for example: [code block] will update the error msg as well.,1,0.7223140001296997
368425477,7170,lkokhreidze,2020-01-20T08:49:46Z,good call. done.,1,0.9732537269592285
369771654,7170,lkokhreidze,2020-01-22T19:56:18Z,"interesting point. i guess in that case idea would be if in the `copartitiongroup` there's one `immutablerepartitiontopicconfig` and rest are repartition topics, we will enforce number of partitions from `immutablerepartitiontopicconfig`. in cases when there're more than one `immutablerepartitiontopicconfig` we would still throw an exception. does this make sense?",0,0.9824202060699463
369775730,7170,lkokhreidze,2020-01-22T20:05:04Z,"this check covers the case when number of partitions do not match between immutable repartition topics (aka created via `repartition` operation) and _ordinary_ repartition topics. but considering your comment below, different logic is needed here.",0,0.9943029880523682
369784339,7170,lkokhreidze,2020-01-22T20:24:25Z,"originally i've implemented this method with throwing an exception. but it seems like this method is being called from various places, like `streamspartitionassignor#preparetopic`. my thinking was - instead of each individual caller checking if `internaltopicconfig` supports setting number of partitions, it makes more sense to delegate this to the ""builder"" that chooses appropriate implementation based on some logic. `setnumberofpartitions` is part of `internaltopicconfig` so even i flip the hierarchy, i can't avoid `setnumberofpartitions` method. so i don't think it gives any benefit if we flip the hierarchy. i also thought instead of adding new class, i could maybe enhance `repartitiontopicconfig` to support ""immutability"" in cases when topics are for `repartition` operation, but in that case i have to add a flag to the class to indicate that this `repartitiontopicconfig` is actually for `repartition` operation which seems a bit worse compared to introducing new class. thoughts?",0,0.9820735454559326
369788818,7170,lkokhreidze,2020-01-22T20:35:33Z,"not ideal, agree. but tbh whole repartition topic management is complicated and is built around the idea of updating the number of partitions during different phases of kafka streams lifecycle. seems like adding new concrete class that indicates ""immutability"" the easiest and safest solution for now without changing current implementation and logic too much. would appreciate your ideas around this. not sure how to accommodate and guarantee immutability of partitions in some other (without introducing some major changes current internal topic management logic. maybe followup ticket is in order?)",1,0.7589044570922852
373849243,7170,lkokhreidze,2020-02-02T14:14:32Z,"hi this is now implemented. logic is the following: if `repartitiontopicconfig`s which have enforced number of partitions have the same value, non-enforced repartition topics (like for mapper) will be created with the num of partitions specified via `repartition` operation. `shoulddeductnumberofpartitionsfromrepartitionoperation` integration tests verifies this case.",0,0.9916896820068359
373849898,7170,lkokhreidze,2020-02-02T14:23:47Z,"hi gave it a bit more thought and decided to ditch this class altogether. `repartitiontopicconfig` and `immutablerepartitiontopicconfig` are exactly the same, just one wouldn't allow setting num of partitions. also, considering your comment about it being tricky to understand when num of partitions can be set or not (which is very valid concern) i've decided to encapsulate necessary logic into `repartitiontopicconfig` and `internaltopicconfig` classes. `internaltopicconfig` now can accept in the constructor `enforcenumberofpartitions` boolean flag: [code block] if `enforcenumberofpartitions` is set as `true`, and somebody decides to call `setnumberofpartitions` method, exception will be raised. i think this should make things much more clear. looking forward to your feedback.",0,0.9847164154052734
373849925,7170,lkokhreidze,2020-02-02T14:24:14Z,this class was removed. check my comment here: [a link],0,0.9899070262908936
373863902,7170,lkokhreidze,2020-02-02T18:02:01Z,update: i've added `numberofpartitions` as int this constructor overload to indicate that passing `numberofpartitions` is mandatory when one wants to use this constructor. corresponding internaltopicconfig constructor also uses int.,0,0.9928150177001953
392608571,7170,vvcephei,2020-03-14T18:24:49Z,"looking at this again with fresh eyes, i can't remember what advantage this has over `selectkey(keyvaluemapper).repartition(repartitioned)`. can you remember why we decided to add this, ?",0,0.9743998050689697
397650119,7170,lkokhreidze,2020-03-25T07:24:30Z,"hi as far as i remember we didn't have any specific discussion around this operation. main reason why we have added it i think is because of the convenience (merging selectkey and repartition into single operation). similarly how `groupby(final keyvaluemapper selector, final grouped grouped)` does it.",0,0.9835233092308044
398113069,7170,vvcephei,2020-03-25T19:25:52Z,"i see. iirc, your initial thought was to replace `groupby` with `repartition`, but we've gotten away from that design. now, it's more like a managed-topic version of `through` (in fact, this is what the javadoc for the method says). maybe this is why i was confused to see this overload, since it makes less sense to think of changing the key at the last minute before `though` or `to`. are you particularly attached to this convenience overload? i'm just thinking it's a safer bet to add it later if people really want it than to add it now and never really know if it's useful or not.",0,0.934163510799408
398366211,7170,lkokhreidze,2020-03-26T07:36:34Z,"i can't say i am particularly attached to it, but i think it's useful one. from personal experience, we, at our company, often write topologies similar to this: [code block] here we need to explicitly use through in order to trigger repartitioning by selecting key (and we have to manage topic that we create in advance for `through` operation) new way of doing same thing is quite nice i think: [code block] for us, it's quite common use-case. and.my _guess_ is it will be common use-case for anyone using complex `transform` operations in dsl. does this make sense? on the other hand, if you believe that it's safer to remove `keyvaluemapper` overloads, i'll definitely do it.",1,0.8663151860237122
398927435,7170,vvcephei,2020-03-26T22:20:37Z,"i certainly agree that it would be common to do a `selectkey` before a `repartition`. there's a trade-off to strike between the number of different operations you need and the number of options on a single operation you have to choose from. i guess my hesitation is that it's still two different operations. for example, it also seems like it would be common to do a `map` before a `repartition`, but it's clearly now too much piled on if we have a fourth `repartition` overload also folding in the `map` operation. when i imagine coming to the api as a user, especially for the first time, i worry that i'd already have a lot of documentation to read to understand the implications of `repartition`, and each new overload adds linearly to the amount i have to learn to use the api. plus, i just feel like i would be puzzled about the exact same question i asked above: is this overload just the same as `selectkey().repartition()`, or does it do something subtly different? as you can tell, i worry quite a bit about how we can make sure the api stays as simple as possible while we still add new functionality. i guess this is just a long-winded way of saying that, yes, i would prefer to remove it :) hopefully, this isn't too disappointing for you, since the main motivation was to save on managing the `through` topic, not necessarily to save on that extra `selectkey` operator.",0,0.9688947200775146
399058852,7170,lkokhreidze,2020-03-27T06:30:00Z,"thanks john, that's a valid point. agree, i'll remove it.",1,0.9763627648353577
399067977,7170,lkokhreidze,2020-03-27T06:59:31Z,done. i'll resolve this conversation.,0,0.9379945397377014
401253268,7170,vvcephei,2020-03-31T22:30:12Z,[code block] looks like an accidental formatting change.,0,0.9677928686141968
401349352,7170,mjsax,2020-04-01T04:28:23Z,typo: `producer's`,0,0.9934885501861572
401349473,7170,mjsax,2020-04-01T04:28:51Z,`[c]reated`,0,0.9890122413635254
401349644,7170,mjsax,2020-04-01T04:29:27Z,`by [the] current`,0,0.9889814853668213
401349985,7170,mjsax,2020-04-01T04:30:58Z,`explicitly` -> `automatically` ? (not sure which one is better),0,0.9911385178565979
401350251,7170,mjsax,2020-04-01T04:32:09Z,`[c]reated` `by [the] current`,0,0.9917466640472412
401350309,7170,mjsax,2020-04-01T04:32:27Z,`automatically` ?,0,0.9897946715354919
401350867,7170,mjsax,2020-04-01T04:34:46Z,nit: do we need to add the `` tag to every method? seems somewhat redundant (it's already mentioned in class javadocs above)? (similar below for other methods),0,0.9690282344818115
401351951,7170,mjsax,2020-04-01T04:39:27Z,why would we not use an upstream `keyserde` (similar to `valueserde = valserde` l584 above) if `repartitioninternal` has a `null` key serde?,0,0.9955933690071106
401352615,7170,mjsax,2020-04-01T04:42:42Z,why do we need to duplicate this method? might it be better to have just a single one and let caller set a `null` `streampartitioner` is they can't set it?,0,0.9916399717330933
401354459,7170,mjsax,2020-04-01T04:50:33Z,"for a `groupedtableoperationrepartitionnode` we should never have a customized `internaltopicproperties` object, but it should always be `internaltopicproperties.empty()` -- can we simplify this and not pass this parameter at all?",0,0.9953668117523193
401354751,7170,mjsax,2020-04-01T04:51:55Z,similar as above: can we avoid this parameter?,0,0.9937279224395752
401355550,7170,mjsax,2020-04-01T04:55:00Z,"`this.name = objects.requirenonnull(name, ""name can't be null"");` ? also, i believe `topicconfig` should not be `null` either -- can we add a check (also for the existing constructor above?",0,0.9943650960922241
401358667,7170,mjsax,2020-04-01T05:08:44Z,"with parallel test runners, would it be better to call this as first line in `before()` method (and use the returned value instead of calling `get()` in addition -- otherwise, we might get multiple different numbers per test run)? also wondering if we should assign the topic names that use the counter within before? for a clean isolation, it might also be good to add the test number to the `application.id`",0,0.993857204914093
401359192,7170,mjsax,2020-04-01T05:10:53Z,should we setup all topics name within `before`?,0,0.9944055080413818
401360195,7170,mjsax,2020-04-01T05:14:55Z,"for this particular test, it seems we could detect the issue during topology `build()` already? ie, we could do an additional early check? if we think it's worth doing, we should do it in follow up pr to not drag this pr any longer. \cc (if yes, we could change this test from an integration test to a unit test)",0,0.9504024982452393
401361948,7170,mjsax,2020-04-01T05:21:56Z,"why do we have a `map()` step here? wouldn't this imply a repartition topic that would match whatever number of partitions is used on the other stream? ie, only without the map(), we guarantee that `topicbstream` has a certain number of partitions? with the `map()` step it seems to be the same test `shoulddeductnumberofpartitionsfromrepartitionoperation` as above?",0,0.9950211048126221
401362636,7170,mjsax,2020-04-01T05:24:32Z,"do we need an integration test for this? using `topology#describe()`, i think we could verify this with a unit test.",0,0.9908514618873596
401362888,7170,mjsax,2020-04-01T05:25:34Z,not sure why we need this test?,0,0.8813730478286743
401363128,7170,mjsax,2020-04-01T05:26:37Z,"nit: in test code, the signature can always be simplified to `throws exception` (there is no value to list exceptions) -- same for all test methods in this class (and maybe somewhere else?)",0,0.9939020872116089
401364227,7170,mjsax,2020-04-01T05:30:40Z,similar to above: we should be able to test with via unit tests using `topology#describe()`,0,0.9929357171058655
401364387,7170,mjsax,2020-04-01T05:31:15Z,seems to be unit-test able via `topology#describe()` ?,0,0.9928426742553711
401364523,7170,mjsax,2020-04-01T05:31:46Z,"not sure what this test is about, ie, how does is relate to the `repartition()` feature?",0,0.9676623940467834
401365280,7170,mjsax,2020-04-01T05:34:11Z,not sure what this test actually verifies?,0,0.764275074005127
401365442,7170,mjsax,2020-04-01T05:34:48Z,using `mockprocessorsupplier` is an old test pattern -- we should use the new `testoutputtopic` instead.,0,0.9943403005599976
401368679,7170,mjsax,2020-04-01T05:46:09Z,"i realize that this contradicts a previous review comment, but i think that the older comment was incorrect, because `repartition()` might be called to just scale out without a key changing operation and thus for this case we should reuse the upstream `keyserde` (note that if there was an upstream key changing operation, `keyserde` would be set to `null` and we would still fall back to the default serdes from the config).",0,0.9936783909797668
401369054,7170,mjsax,2020-04-01T05:47:16Z,why do we introduce a new type ` `? the key type of the input and output kstream does not change during repartitioning.,0,0.9805850386619568
401372458,7170,mjsax,2020-04-01T05:58:29Z,"can you update the kip wiki page accordingly and send an follow up email to the vote thread of the kip to highlight the change as an fyi that the kip was modified (just in case somebody would have an objection, what i don't expect -- it's just custom in the community to do this).",0,0.9883479475975037
402561217,7170,lkokhreidze,2020-04-02T19:32:00Z,"i've followed same standard as other configurations classes (produced, grouped, etc). to keep things consistent maybe worth cleaning up all the config classes with redundant `` tags? (in the follow up pr maybe) wdyt?",0,0.9915648698806763
403061232,7170,lkokhreidze,2020-04-03T14:51:10Z,`application.id` already has test number. will do as you suggested.,0,0.9896726608276367
403097472,7170,lkokhreidze,2020-04-03T15:44:39Z,you're right. this test is redundant. removed it.,0,0.9219062924385071
403098661,7170,lkokhreidze,2020-04-03T15:46:32Z,"wanted to verify that key changing operation with `repartition` works as expected. i think it adds value, especially considering the fact that we've removed `repartition(keyselector` overloads.",0,0.9911819696426392
403109967,7170,lkokhreidze,2020-04-03T16:05:00Z,"this was the ""easiest"" way i could figure out to verify that custom partitioner is invoked when it's set",0,0.938849151134491
403372355,7170,lkokhreidze,2020-04-03T22:48:53Z,it's related to this comment [a link],0,0.9879232048988342
403374045,7170,lkokhreidze,2020-04-03T22:54:37Z,"thought about that, but somehow it felt ""safer"" with integration tests. mainly because i was more comfortable verifying that topics actually get created when using repartition operation.",1,0.5047615170478821
403374128,7170,lkokhreidze,2020-04-03T22:54:55Z,"thought about that, but somehow it felt ""safer"" with integration tests. mainly because i was more comfortable verifying that topics actually get created when using repartition operation.",1,0.5047615170478821
403374331,7170,lkokhreidze,2020-04-03T22:55:41Z,i'll create followup ticket on that.,0,0.9875324368476868
403374552,7170,lkokhreidze,2020-04-03T22:56:35Z,"yes, thanks for reminding me. was meaning to do it.",1,0.6683349013328552
403449003,7170,lkokhreidze,2020-04-04T09:36:26Z,done,0,0.8974218964576721
404993384,7170,vvcephei,2020-04-07T17:39:46Z,"yeah, i'd agree with checking as early as possible in the special cases where we can know the partition counts statically. but also agree with doing it in a follow-on ticket, since it's kind of a nice-to-have.",0,0.7050922513008118
404994770,7170,vvcephei,2020-04-07T17:42:00Z,"i had a similar thought, that it looks like good fodder for unit testing, but i did like the safety blanket of verifying the actual partition counts. i guess i'm fine either way, with a preference for whatever is already in the pr ;)",1,0.984830379486084
406532074,7170,mjsax,2020-04-09T23:34:00Z,"yeah. was just a general inquire and we don't really have a guideline for it... if you are interested, it would be great to draft some guidelines (maybe just for kafka streams first, and we could propose them for other client apis, later) as a wiki page and we could discuss them on the dev mailing list?",0,0.9412493109703064
406532691,7170,mjsax,2020-04-09T23:36:34Z,cool. did you create a ticket already? (just want to make sure we don't drop this on the floor.),1,0.8093809485435486
406532989,7170,mjsax,2020-04-09T23:37:44Z,ok. thanks for clarifying.,1,0.8854160904884338
406533537,7170,mjsax,2020-04-09T23:39:49Z,i guess that is fair. (i just try to keep test runtime short if we can -- let's keep the integration test.),0,0.529929518699646
406533774,7170,mjsax,2020-04-09T23:40:52Z,thanks for clarifying!,1,0.9050725698471069
406535443,7170,mjsax,2020-04-09T23:47:20Z,"seems unnesseary complex? a simple [code block] would do, too :) (feel free to ignore the comment.)",1,0.9942610263824463
406535968,7170,mjsax,2020-04-09T23:49:15Z,"a simple [code block] would be sufficient instead of adding a constructor and those lines could go into `before()`. (as above, feel free to ignore this comment.)",0,0.9918557405471802
406839201,7170,lkokhreidze,2020-04-10T16:39:43Z,"yes, here it is [a link]",0,0.9902695417404175
406899069,7170,mjsax,2020-04-10T19:04:51Z,thank you!,1,0.9148550629615784
365485878,7884,junrao,2020-01-11T01:08:13Z,"ltc => logtoclean ? also, do we need to use another local val since ltc is only used once?",0,0.989949107170105
365486280,7884,junrao,2020-01-11T01:12:19Z,need to change the javadoc above to currenttime.,0,0.9873364567756653
365486311,7884,junrao,2020-01-11T01:12:45Z,could we add the new param to javadoc?,0,0.9921905398368835
366049275,7884,junrao,2020-01-13T21:55:01Z,"we should make it clear the difference btw retaindeletesandtxnmarkers and tombstoneretentionms. also, it's probably better to put they as adjacent params.",0,0.9949760437011719
366061210,7884,junrao,2020-01-13T22:23:48Z,"hmm, iscontrolbatchempty is a bit misleading since batch is not always a control batch.",-1,0.8205664157867432
366064567,7884,junrao,2020-01-13T22:32:30Z,retaintxnmarkers is no longer used in shoulddiscardbatch().,0,0.9887765049934387
366085895,7884,junrao,2020-01-13T23:36:42Z,"it's a bit awkward to have to pass in the same batch to two different methods iscontrolbatchempty and checkbatchretention, during filtering. i was thinking that perhaps that we could just combine them into a single method checkbatchretention(), which returns (batchretention, shouldsethorizon). we could then extend shoulddiscardbatch() to sth like the following. the result of shoulddiscardbatch() can then be used to build the result for checkbatchretention(). [code block]",-1,0.7310600876808167
366086360,7884,junrao,2020-01-13T23:38:16Z,"we probably need to do the check based on the batch magic. if magic is >=v2, check based on the new deletehorizonms. otherwise, check based on the old approach.",0,0.9932736158370972
366090028,7884,junrao,2020-01-13T23:51:19Z,"it's probably better to have the logic to determine if deletehorizonms should be set here instead of memoryrecords since it's log cleaner specific logic. i was thinking that we could extend checkbatchretention() to return (boolean, shouldsethorizon).",0,0.9924801588058472
366093839,7884,junrao,2020-01-14T00:05:55Z,"hmm, if deletehorizonset is not set, we shouldn't be deleting the tombstone. so, not sure what newbatchdeletehorizonms is intended for.",0,0.7615774869918823
366093991,7884,junrao,2020-01-14T00:06:30Z,"hmm, why are we passing in containstombstonesormarker, which is always false?",0,0.957457423210144
366095048,7884,junrao,2020-01-14T00:10:34Z,"since deletehorizonms can be obtained from batch, it's not clear why we need to pass that in as a param.",0,0.9919008612632751
366098944,7884,junrao,2020-01-14T00:25:10Z,"i am not sure about this. a round of cleaning can be expensive since we need to read in all existing cleaned segments. that's why by default, we only trigger a round of cleaning if the dirty portion of the log is as large as the cleaned portion. not sure if it's worth doing cleaning more aggressively just to remove the tombstone. so, perhaps we can leave it outside of this pr for now.",0,0.7782438397407532
367151238,7884,ConcurrencyPractitioner,2020-01-15T22:56:48Z,"yep, done so.",0,0.9507519602775574
367151276,7884,ConcurrencyPractitioner,2020-01-15T22:56:54Z,done.,0,0.9640594124794006
367152424,7884,ConcurrencyPractitioner,2020-01-15T23:00:16Z,"oh, this is used as a means to help the tests in logcleanertest.scala pass. logcleanertest usually wants the tombstones removed in a single pass (but that pass is usually used for setting the delete horizon ms, which means without doing the above, we would be unable to remove tombstones). therefore, by adding the [code block] argument (which is passed in by memoryrecords), whenever logcleaner calls clean log with the current time marked as [code block], we will be able to remove the tombstones / control records in one pass.",0,0.9910354614257812
367152628,7884,ConcurrencyPractitioner,2020-01-15T23:00:52Z,"oh, i can remove that.",0,0.9718338251113892
367153616,7884,ConcurrencyPractitioner,2020-01-15T23:03:46Z,"oh, look in comment above. this delete horizon is used for the case where we want to remove the tombstones in a single pass. on the first iteration of log cleaner, we are unable to remove the tombstone because no delete horizon has not been set yet. therefore, when we compute the delete horizon, we need to pass the delete horizon back into [code block] so that tombstones can be removed in one iteration. on second thought, i think we don't need to add an extra parameter to the [code block] method. such logic would only need to be restricted to logcleaner. i.e. we store the delete horizon in another variable in the record filter we implemented in logcleaner.",0,0.9873588681221008
367154887,7884,ConcurrencyPractitioner,2020-01-15T23:07:25Z,"i did some thinking about this. the integration test i added does not pass without this part. because what happens is that in logs with tombstones, there is the possibility that without further throughput, the cleanable logs will always be empty. therefore, as i mentioned in the comment, since we are in a low throughput situation, logcleaner's workload is relatively light anyways. in that case, we can clean tombstones since we don't have much else to do.",0,0.965349018573761
367675732,7884,junrao,2020-01-16T22:08:25Z,tombstoneretentionms is duplicated in the javadoc.,0,0.9925554394721985
367675858,7884,junrao,2020-01-16T22:08:39Z,could we add currenttime to the javadoc?,0,0.9934806823730469
367679076,7884,junrao,2020-01-16T22:17:04Z,this seems never used?,0,0.8500399589538574
367692941,7884,ConcurrencyPractitioner,2020-01-16T22:57:49Z,"there is a way to figure out whether if log cleaner has a heavy workload or not. if cleanable logs has remained empty for a long period of time (for a set threshold), then we can safely say that the log cleaner thread isn't busy since there is no logs to clean. after that threshold has passed, we can start processing logs with tombstones and removing them. this should help us know exactly when we can go back and remove tombstones.",0,0.9891757369041443
367711171,7884,junrao,2020-01-17T00:02:22Z,"perhaps, we can keep track of the largest deletehorizonms in the cleaned portion. we can then trigger a round of cleaning when the current time has passed the largest deletehorizonms.",0,0.9904476404190063
367731735,7884,junrao,2020-01-17T01:29:55Z,"i am not sure that i understand the need for overloading this and the other method. it seems that this is just so that we can remove the tombstone in one pass in the test? if so, could we just design/fix the test accordingly?",0,0.9605984091758728
367732948,7884,junrao,2020-01-17T01:35:23Z,"hmm, i am still not sure why we need to remove a tombstone in one pass. if a tombstone's delete horizon is not set, it can't be removed in this round of cleaning.",-1,0.7965520024299622
371018776,7884,ConcurrencyPractitioner,2020-01-26T18:08:45Z,"yep, i realized that was probably unnecessary, so i removed it.",0,0.9020175337791443
371018800,7884,ConcurrencyPractitioner,2020-01-26T18:08:57Z,"yeah, will get rid of that.",0,0.9760826826095581
371019104,7884,ConcurrencyPractitioner,2020-01-26T18:14:07Z,"alright, acknowledged. i think thats a good point.",1,0.923902690410614
372143661,7884,ConcurrencyPractitioner,2020-01-29T01:09:37Z,"yeah, i found that this approach probably is a lot better.",0,0.922400176525116
374441552,7884,junrao,2020-02-04T02:08:37Z,deletehorizonms in the next line is no longer present.,0,0.9805208444595337
374442122,7884,junrao,2020-02-04T02:11:12Z,could we move this up to below retaindeletesandtxnmarkers?,0,0.9952371120452881
375562926,7884,junrao,2020-02-05T23:18:14Z,it's probably better to name writeoriginalbatch here to sth like recordsfiltered since we combine other information to determine writeoriginalbatch later on.,0,0.9941290616989136
375565104,7884,junrao,2020-02-05T23:24:38Z,it seems that the logic can be simplified a bit. it seems that we can do this branch if writeoriginalbatch is true and needtosetdeletehorizon is false (`needtosetdeletehorizon = (batch magic >= v2 && containstombstonesormarker && batch's deletehorizon not set)`).,0,0.9925116300582886
376105398,7884,junrao,2020-02-06T21:58:24Z,"this may not be the best place to track latestdeletehorizon. perhaps we can return the largest deletehorizon in memoryrecords.filterto() and keep track of latestdeletehorizon in the while loop in line 713. if we do that, i am not sure if we need retrievedeletehorizon() since memoryrecords.filterto() can obtain whether deletehorizon is set from the batch and calculate the new deletehorizon if needed.",0,0.9894299507141113
376109770,7884,junrao,2020-02-06T22:08:23Z,"hmm, it seems that we only want to pass in deletehorizonms if `containstombstonesormarker && deletehorizon is not set`.",0,0.991206705570221
376111679,7884,junrao,2020-02-06T22:12:46Z,islatestversion => supportdeletehorizon?,0,0.9939524531364441
376120400,7884,junrao,2020-02-06T22:34:58Z,could we put the common logic into a shared method to avoid duplicating most of the code below?,0,0.9943385720252991
376122666,7884,junrao,2020-02-06T22:41:04Z,this method seems unused?,0,0.9242547154426575
376122878,7884,junrao,2020-02-06T22:41:37Z,this method seems unused?,0,0.9242547154426575
376124221,7884,junrao,2020-02-06T22:45:04Z,it seems that we need to reinitialize this value at the start of each round of cleaning.,0,0.9853602051734924
376138391,7884,ConcurrencyPractitioner,2020-02-06T23:23:32Z,"oh, that's a good catch! otherwise, we might end up cleaning the logs over and over again.",1,0.9206452369689941
376142170,7884,ConcurrencyPractitioner,2020-02-06T23:35:23Z,"oh, sure, that's fine. but we also still need to account for the control batch and check whether or not it is empty yet.",0,0.9731647372245789
376147542,7884,junrao,2020-02-06T23:53:27Z,"for a control batch, it's only removed at the batch level. so, if the batch can be deleted at the batch level, we won't get in here. if the batch can't be deleted at the batch level, the record within the batch will always be retained.",0,0.992211103439331
378016120,7884,ConcurrencyPractitioner,2020-02-12T02:54:11Z,"by current logic, this would actually break the code. since we don't pass a [code block] boolean flag into the memoryrecordsbuilder constructor, the memoryrecordsbuilder class's current logic actually relies on the passed in argument to tell if the delete horizon has been set or not. i.e. (if deletehorizonms > 0l, then we set delete horizon, else we assume that it has not been set). should i change the code correspondingly to accomadate your comment?",0,0.9930964112281799
378017124,7884,ConcurrencyPractitioner,2020-02-12T02:58:14Z,"is this always the case? if i remember correctly in the kip, control batches, if it contains only tombstones, will be persisted in the logs for a set period of time i.e. we need to at some point remove the tombstones first _before_ the control batches can be deleted. therefore, i think it would be very much possible that we need to check for [code block] here.",0,0.9894998669624329
378019351,7884,ConcurrencyPractitioner,2020-02-12T03:08:21Z,"well, i think there is multiple problems we might need to think about: 1. we don't know what the current time is since memoryrecords doesn't have access to a [code block] instance. 2. for control batches, [code block] serves a critical function: we call [code block] there to determine if we can set a delete horizon for our batch. in summation, i think that there are multiple dependencies (located in logcleaner) which must be called from [code block]. it would be more of a hassle i think if we need to figure out a way how to call all these methods from filterto as well.",0,0.923599362373352
378046269,7884,junrao,2020-02-12T05:26:10Z,": a control batch has only a single marker record (either a commit or abort). when all records before the control batch are removed, we set the deletehorizon for the control batch. when the time passes the deletehorizon, the control batch is removed. a control batch never contains a tombstone.",0,0.9928378462791443
379089454,7884,junrao,2020-02-13T20:03:44Z,"good point on #2. my concern is that the batch could be filtered after retrievedeletehorizon() is called. then, the latestdeletehorizon maintained here won't be very accurate.",0,0.5548538565635681
379094481,7884,junrao,2020-02-13T20:14:36Z,"yes, it's just that in this pr, retrievedeletehorizon() returns deletehorizonms > 0 even for batches where deletehorizonms doesn't need to be set. then, we will be setting deletehorizonms for those batches unnecessarily.",0,0.976880669593811
381024939,7884,junrao,2020-02-19T01:06:47Z,this batch could be filtered later in memoryrecords.filterto(). so if we maintain latestdeletehorizon here. it may not be accurate.,0,0.9932696223258972
381031162,7884,junrao,2020-02-19T01:29:53Z,"you were correct earlier that for a control marker, deletehorizon should only be set after transactional records before the marker have already been removed. so, we can't just set needtosetdeletehorizon based on containstombstonesormarker. also, i still feel that retrievedeletehorizon() is a bit weird since it mixes deletehorizonms that's already set with the deletehorizonms to be set. so, perhaps it's clearer if we instead have a method containemptymarker() that simply passes along the return value of shoulddiscardbatch(). then `needtosetdeletehorizon = batch.magic() >= 2 && (containemptymarker || containstombstones) && !batch.deletehorizonset())`. if we need to set deletehorizon, deletehorizonms can be computed off tombstoneretentionms, which can be passed into filterto().",0,0.8177942633628845
381031270,7884,junrao,2020-02-19T01:30:19Z,it seems we should check needtosetdeletehorizon ?,0,0.9936683773994446
381454797,7884,ConcurrencyPractitioner,2020-02-19T18:15:32Z,"alright, sounds cool. this actually makes sense. i got it done.",1,0.9689924120903015
381551654,7884,junrao,2020-02-19T21:21:55Z,this check seems redundant since the caller has verified it already. we can just always return the expected deletehorizon.,0,0.9884771108627319
381552110,7884,junrao,2020-02-19T21:22:56Z,this should now be named containstombstones.,0,0.992815375328064
381554557,7884,junrao,2020-02-19T21:27:44Z,these two lines are awkward. could we pass them through the constructor of recordfilter?,-1,0.954643726348877
381598053,7884,junrao,2020-02-19T23:03:08Z,"i am not sure that i follow the logic here. to me, the easiest way is to reset log.latestdeletehorizon at the beginning of each round of cleaning. then, we update it with the latestdeletehorizon remaining in each cleaned segment.",0,0.877528190612793
381599279,7884,junrao,2020-02-19T23:06:12Z,"could we just fold containsemptymarker() into this method and let checkbatchretention() return (batchretention, containsemptymarker)?",0,0.9956874251365662
382869365,7884,junrao,2020-02-22T01:00:22Z,"cleansegments() just cleans a portion of the log. so, we need to reset log.latestdeletehorizon in the caller doclean().",0,0.9924157857894897
383572781,7884,junrao,2020-02-24T23:20:23Z,this seems to be only used in tests. could we just create a util method in test?,0,0.9932524561882019
383572822,7884,junrao,2020-02-24T23:20:32Z,firstclean is unused.,0,0.9675813317298889
383573289,7884,junrao,2020-02-24T23:21:50Z,"it would be useful to indicate that trackedhorizon is to cover tombstones in legacy message format. so, perhaps we could name it sth like legacydeletehorizonms?",0,0.9952903985977173
383574205,7884,junrao,2020-02-24T23:24:38Z,discarding tombstones => discarding legacy tombstones ?,0,0.9914032816886902
383575250,7884,junrao,2020-02-24T23:27:41Z,deletion horizon => legacy deletion horizon ?,0,0.9919881820678711
383576155,7884,junrao,2020-02-24T23:30:28Z,no need for space before (.,0,0.8734682202339172
383577646,7884,junrao,2020-02-24T23:34:52Z,containsemptymarker => containsmarkerforemptytxn ?,0,0.9933235049247742
383578258,7884,junrao,2020-02-24T23:36:54Z,we can just do [code block],0,0.9888290762901306
383579725,7884,junrao,2020-02-24T23:41:45Z,this can be [code block],0,0.9925453066825867
383580041,7884,junrao,2020-02-24T23:42:55Z,it seems this can be simplified to the following? `shouldretaindeletes = !batch.deletehorizonset() || currenttime < batch.deletehorizonms()`,0,0.9953464865684509
383580335,7884,junrao,2020-02-24T23:43:50Z,retaindeletes => retaindeletesforlegacyrecords ?,0,0.9926039576530457
383581756,7884,junrao,2020-02-24T23:48:20Z,batchretentionandemptymarker => batchretentionresult ?,0,0.9927687644958496
383582417,7884,junrao,2020-02-24T23:50:19Z,the tombstones => the tombstones or txn markers,0,0.9901006817817688
383585273,7884,junrao,2020-02-24T23:59:07Z,"not sure if we need these comments. if we do need them, it seems they should be added to the implementation in logcleaner.",0,0.9880829453468323
383585606,7884,junrao,2020-02-25T00:00:14Z,"hmm, this comment seems out of place.",0,0.7729041576385498
383619974,7884,junrao,2020-02-25T02:02:28Z,this doesn't look right. we need to track not only newly generated deletionhorizon but also existing one if the batch is kept.,0,0.695047914981842
383620136,7884,junrao,2020-02-25T02:03:11Z,batch and containsemptymarker are unused.,0,0.982909083366394
384268522,7884,ConcurrencyPractitioner,2020-02-26T04:25:16Z,aren't we already keeping track of each individual delete horizon in each batch's first timestamp? my impression was that this result would just return the biggest delete horizon seen so far.,0,0.9826449751853943
384284272,7884,junrao,2020-02-26T05:41:46Z,": if we get into the else branch in line 210, it seems that we still need to call filterresult.updatelatestdeletehorizon() since the batch may contain deletehorizon?",0,0.9949443936347961
384597604,7884,ConcurrencyPractitioner,2020-02-26T16:10:30Z,"oh, i see. makes sense. i misunderstood what the comment was suggesting.",-1,0.8936409950256348
384611807,7884,ConcurrencyPractitioner,2020-02-26T16:30:59Z,"just a note, i actually did resolve this comment with my previous push. turns out i spotted this error while running over the code previously. just didn't realize that it actually resolved this one as well.",0,0.9372520446777344
384793024,7884,junrao,2020-02-26T21:59:46Z,retaindeletesandtxnmarkers => retainlegacydeletesandtxnmarkers ?,0,0.9920297861099243
384795228,7884,junrao,2020-02-26T22:04:17Z,batchretentionandemptymarker => batchretentionresult ?,0,0.9927687644958496
384804732,7884,junrao,2020-02-26T22:24:41Z,"if we get in here, it could be that this batch already has deletehorizon set. if we pass in recordbatch.no_timestamp to buildretainedrecordsinto(), we will lose the deletehorizon. so, we need to pass in the existing deletehorizon to buildretainedrecordsinto() and also reflect that deletehorizon in filterresult.",0,0.9916057586669922
384806582,7884,junrao,2020-02-26T22:28:41Z,typo thoroughput,0,0.9578234553337097
384810439,7884,junrao,2020-02-26T22:37:28Z,we probably don't need to assert this since we explicitly inserted some tombstones.,0,0.9832867383956909
384810766,7884,junrao,2020-02-26T22:38:17Z,"to avoid transient failures, we probably want to give long enough maxwaitms, sth like 5 secs.",0,0.9730826616287231
384811017,7884,junrao,2020-02-26T22:38:53Z,this seems unnecessary since we are waiting in cleaner.awaitcleaned() already later.,0,0.9865438342094421
384811420,7884,junrao,2020-02-26T22:39:55Z,this seems to be a complicated way of getting latestoffset. we could just do log.logendoffset.,0,0.9401317834854126
384818440,7884,junrao,2020-02-26T22:56:55Z,"the value of the map is an offset. so, it's weird to put in deletehorizon as the value. also, there seems to be an existing issue with the test. it seems that shouldremain in line 90 should be computed before line 89.",-1,0.9275625944137573
384827619,7884,junrao,2020-02-26T23:22:15Z,"why do we need to set current time to long.maxvalue - tombstoneretentionms - 1? for verifying the removal of the tombstone, it's clearer if we set the currenttime in mocktime before the first round of cleaning and then explicit set current time to be tombstoneretentionms longer than that currenttime in a subsequent round of cleaning to verify that the tombstone is removed. ditto below.",0,0.9917056560516357
384829410,7884,junrao,2020-02-26T23:27:43Z,could we add a comment on why we need two passes?,0,0.9911072850227356
384835414,7884,junrao,2020-02-26T23:46:13Z,"since there is no marker, it seems that containsmarkerforemptytxn should be false.",0,0.9862614274024963
384835749,7884,junrao,2020-02-26T23:47:16Z,"since there is no marker, it seems that containsmarkerforemptytxn should be false.",0,0.9862614274024963
384835973,7884,junrao,2020-02-26T23:48:03Z,"since there is no marker, it seems that containsmarkerforemptytxn should be false.",0,0.9862614274024963
384837927,7884,junrao,2020-02-26T23:54:01Z,could we use recordbatch.no_timestamp instead of -1l?,0,0.9947981834411621
384848752,7884,ConcurrencyPractitioner,2020-02-27T00:28:59Z,"this was one part of the test which i had some problems with. notably, what happens is that we will try to calculate the delete horizon using long.maxvalue as the current time. inherently, an integer overflow error will occur (and we end up with some very low negative number). therefore, i thought that we can get around it by setting the delete horizon to some value which would not have problems with overflow (hence largedeletehorizon having the above value you mentioned.)",0,0.9649413824081421
384854011,7884,ConcurrencyPractitioner,2020-02-27T00:46:54Z,"yeah, it definitely is inconsistent with other tests in that there is a thread.sleep(). problem is that this test seems prone to be somewhat flaky. without the sleep, at the present state, it definitely fails.",-1,0.6136379837989807
384855964,7884,ConcurrencyPractitioner,2020-02-27T00:53:07Z,"also, about setting mock time. mock time is in fact never called in doclean. it is called in just clean(). the currenttime supplied to doclean is from clean(). so what you stated probably only applies to methods which call the regular clean() method.",0,0.9904323220252991
385391824,7884,junrao,2020-02-27T21:50:31Z,"instead of sleeping, it's more reliable to just do cleaner.awaitcleaned() and assert the return value to be true.",0,0.9918075203895569
385393585,7884,junrao,2020-02-27T21:54:21Z,"hmm, in the previous round of cleaning, the dirty offset is already moved to log.logendoffset. so, this call seems to also hit the timeout. another way is to do testutils.waituntiltrue(log.size() == 0). then, we don't need the code in line 214 to 216.",0,0.9798545241355896
385402234,7884,junrao,2020-02-27T22:13:38Z,"if we set currenttime to largedeletehorizon in the previous round of cleaning, we need to set the current time to long.maxvalue - 1 in order for the marker to be removed.",0,0.9915425777435303
385409940,7884,junrao,2020-02-27T22:31:37Z,it doesn't seem that we need to convert this to runtwopassclean().,0,0.980968713760376
385409985,7884,junrao,2020-02-27T22:31:43Z,it doesn't seem that we need to convert this to runtwopassclean().,0,0.980968713760376
385410725,7884,junrao,2020-02-27T22:33:33Z,it seems this is a case that we should use runtwopassclean().,0,0.9941558837890625
385412064,7884,junrao,2020-02-27T22:37:09Z,it seems that currenttime should be set to long.maxvalue - 1 to make sure the record still remains after the deletehorizon.,0,0.9908478260040283
385414150,7884,junrao,2020-02-27T22:42:40Z,"it's clearer if we set currenttime to largedeletehorizon here and in the second round of cleaning, set currenttime to long.maxvalue - 1. we also want to change the comment above accordingly.",0,0.9941855072975159
385414334,7884,junrao,2020-02-27T22:43:11Z,"in this case, it seems that one round of doclean() is enough.",0,0.9901195764541626
385416143,7884,junrao,2020-02-27T22:48:06Z,"similar here. if we set currenttime to largedeletehorizon in the first round cleaning, we can just do one round of cleaning with currenttime set to long.maxvalue - 1 and the first marker should be removed.",0,0.9942353367805481
385418628,7884,junrao,2020-02-27T22:55:11Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9917101263999939
385419500,7884,junrao,2020-02-27T22:57:42Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9917101263999939
385419989,7884,junrao,2020-02-27T22:58:59Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9917101263999939
385420266,7884,junrao,2020-02-27T22:59:48Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9917101263999939
385420579,7884,junrao,2020-02-27T23:00:44Z,no need for this change since recovery point is not related to deletehorizon.,0,0.9912238121032715
385420800,7884,junrao,2020-02-27T23:01:15Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9917101263999939
385420835,7884,junrao,2020-02-27T23:01:21Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9917101263999939
385420853,7884,junrao,2020-02-27T23:01:26Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9917101263999939
385422158,7884,junrao,2020-02-27T23:05:04Z,"perhaps it's clearer with ""on the first run, set the delete horizon in the batches with tombstone or markers with empty txn records.""",0,0.9953462481498718
385429375,7884,junrao,2020-02-27T23:27:13Z,"with this pr, we can set currenttime to largedeletehorizon and the marker should still be preserved. we can change the comment above accordingly.",0,0.9901459813117981
385841515,7884,junrao,2020-02-28T18:03:18Z,let's assert that the return value is true.,0,0.9870193004608154
385841874,7884,junrao,2020-02-28T18:04:07Z,this is unnecessary given the waituntiltrue() below.,0,0.9901238083839417
385843938,7884,junrao,2020-02-28T18:09:10Z,"we can be more generous with waittimems. so, using the defaults for both waittimems and pause is probably fine.",0,0.9857755899429321
385848945,7884,junrao,2020-02-28T18:20:20Z,"this is still a bit confusing. could we define 2 vals, beforedeletehorizon and afterdeleteionhorizon? the former takes long.maxvalue - tombstoneretentionms - 1 and the latter takes long.maxvalue. the comment can be changed to sth like ""current time is still before deletehorizon"". it would be useful to do this consistently across other tests.",0,0.6401466727256775
385851682,7884,junrao,2020-02-28T18:26:00Z,the previous comment was not addressed. it doesn't seem that we need to convert this to runtwopassclean().,0,0.9845172762870789
385854943,7884,junrao,2020-02-28T18:32:59Z,"in this case, it seems that one round of doclean() is enough as long as we set currenttime to postdeletehorizon.",0,0.9931917786598206
385855310,7884,junrao,2020-02-28T18:33:46Z,"similar here. if we set currenttime to largedeletehorizon in the first round cleaning, we can just do one round of cleaning with currenttime set to long.maxvalue - 1 and the first marker should be removed.",0,0.9942353367805481
386758173,7884,junrao,2020-03-03T01:56:04Z,"could we add the following comment above? ""the deletehorizon for {producer2: commit} is still not set yet.""",0,0.9951334595680237
386758582,7884,junrao,2020-03-03T01:57:36Z,"could we add the following comment above? ""in the first pass, the deletehorizon for {producer2: commit} is set. in the second pass, it's removed.""",0,0.9936378598213196
388490888,7884,junrao,2020-03-05T18:49:32Z,"could we add the following comment? ""in the first pass, deletehorizon is set for the abort marker. in the second pass, the abort marker is removed.",0,0.9938850998878479
388507941,7884,junrao,2020-03-05T19:18:44Z,we could just use one pass of cleaning with currenttime = long.maxvalue.,0,0.9917995929718018
388509040,7884,junrao,2020-03-05T19:20:36Z,"could we add the following comment? ""in the first pass, the deletehorizon for the commit marker is set. in the second pass, the commit marker is removed, but the empty batch is retained for preserving the producer epoch.""",0,0.9955055713653564
388511801,7884,junrao,2020-03-05T19:25:20Z,"could we change the comment to the following? ""aborted records are removed, but the abort marker is still preserved.""",0,0.9948627352714539
388512379,7884,junrao,2020-03-05T19:26:18Z,"could we change the comment to the following? ""in the first pass, the delete horizon for the abort marker is set. in the second pass, the abort marker is removed.""",0,0.9943065047264099
388514252,7884,junrao,2020-03-05T19:29:45Z,"could we change the comment to the following? ""in the first pass, the delete horizon for the first marker is set. in the second pass, the first marker is removed.""",0,0.9948187470436096
388516416,7884,junrao,2020-03-05T19:34:06Z,this can just be one pass cleaning with currenttime = largetimestamp.,0,0.993077278137207
388517353,7884,junrao,2020-03-05T19:35:57Z,"could we add the following comment? ""in the first pass, the delete horizon for the abort marker is set. in the second pass, the abort marker is removed.""",0,0.9931938648223877
391180372,7884,hachikuji,2020-03-11T18:32:07Z,why don't we move these into `abstractlegacyrecordbatch`?,0,0.9930011034011841
391184841,7884,hachikuji,2020-03-11T18:40:03Z,nit: can we use `hasdeletehorizonms`. another option would be to make `deletehorizonms` return an optional long.,0,0.9946358799934387
391187776,7884,hachikuji,2020-03-11T18:45:22Z,"hmm.. it seems a bit brittle to rely on documentation for this. i'm considering if we should change names to better reflect this. for example, maybe we should call this `basetimestamp` and add a new method for `firstrecordtimestamp` or something like that.",-1,0.9257388710975647
391189939,7884,hachikuji,2020-03-11T18:49:05Z,nit: why don't we initialize the variables here? e.g. [code block],0,0.9932867884635925
391190505,7884,hachikuji,2020-03-11T18:50:08Z,nit: no need for parenthesis,0,0.9760258197784424
391194791,7884,hachikuji,2020-03-11T18:57:46Z,why do we pass `writeoriginalbatch` here? its value is always `true`.,0,0.9936354160308838
391198263,7884,hachikuji,2020-03-11T19:04:26Z,"if we are not retaining this record, then records have been filtered, so shouldn't `recordsfiltered` be true? the original code used `writeoriginalrecord` instead of `recordsfiltered`, which seems clearer to me. even `batchiterationresult` still preserves the original name.",0,0.9937716126441956
391199350,7884,hachikuji,2020-03-11T19:06:43Z,i think we can name this more specifically to its usage in filtering. perhaps call it `batchfilterresult` or something.,0,0.9908543825149536
391199694,7884,hachikuji,2020-03-11T19:07:21Z,nit: fix alignment,0,0.618681013584137
391200796,7884,hachikuji,2020-03-11T19:09:30Z,maybe we can call this `filterbatch`,0,0.9941679239273071
391203869,7884,hachikuji,2020-03-11T19:15:37Z,"i guess this should take into account the magic version? if the magic version is older than v2, i think this should return false?",0,0.9894545078277588
391204835,7884,hachikuji,2020-03-11T19:17:28Z,not sure why current time needs to be passed through here. are you trying to save an extra call to `time.milliseconds()` or something?,0,0.9622775912284851
391205039,7884,hachikuji,2020-03-11T19:17:53Z,i think `deleteretentionms` would be a better name since it is more general than tombstone cleanup.,0,0.9905319213867188
391224340,7884,hachikuji,2020-03-11T19:54:15Z,i'm trying to understand why we need to collect this from `checkbatchretention`. why don't we collect this in `iterateoverbatch` as we do for `containstombstones`?,0,0.9927113056182861
391228346,7884,hachikuji,2020-03-11T19:58:33Z,we are only updating `firsttimestamp` when a record gets appended. does that mean we cannot create an empty batch with the delete horizon set? i would expect that the constructor would initialize `firsttimestamp` to `deletehorizonms` if it is greater than 0.,0,0.9943299293518066
391239196,7884,hachikuji,2020-03-11T20:10:52Z,"note that `batchretention` is an enum. if there is some state that it is not sufficient to capture, then we can add a new state.",0,0.9911931157112122
391331852,7884,ConcurrencyPractitioner,2020-03-11T23:46:09Z,"yeah, record filter seemed to be the most convenient medium through which we can pass the current time. i don't want to pass in the time instance, so i just passed the time here.",0,0.9545173645019531
391334367,7884,ConcurrencyPractitioner,2020-03-11T23:54:47Z,"ah, perhaps i should've some comments to indicate what is going on. if you would look through the [code block] implementation, you would note that [code block] must be called to determine if the control batch is empty. and the content of that call is stored in containsmarkerforemptytxn. furthermore, this value is crucial for [code block] to function correctly (as it needs to know if the control batch can be removed). therefore, what we decided to do, is that we call oncontrolbatchread at the beginning of checkbatchretention and return it along with the batchretention enum (as we will need to use containsmarkerforemptytxn later for checking whether or not we retain individual records.)",0,0.9891672134399414
391335870,7884,ConcurrencyPractitioner,2020-03-12T00:00:22Z,acknowledged. the name is a bit contradictory with its value assignments.,-1,0.714394748210907
391336806,7884,ConcurrencyPractitioner,2020-03-12T00:03:40Z,"if i am understanding this correctly, an empty batch does not contain tombstones, right? if we append a tombstone as the first record, then the delete horizon will be set. but if there isn't any tombstones, there isn't any delete horizon to set. so how would we set a delete horizon for an empty batch?",0,0.9828039407730103
393876656,7884,ConcurrencyPractitioner,2020-03-17T18:12:54Z,"oh, sorry about the misunderstanding. i see what you mean by that now. you're right. i should take this into account.",-1,0.9910988211631775
393880203,7884,ConcurrencyPractitioner,2020-03-17T18:18:41Z,"good point, version checking would be needed.",0,0.6476560235023499
108020004,2735,hachikuji,2017-03-24T23:58:22Z,i think we should consider turning off `parameternumber` check if we're just going to keep increasing it.,0,0.9813545346260071
108020604,2735,hachikuji,2017-03-25T00:07:22Z,the name seems like it could be a source of confusion. i wonder if we should rename this to something like `pidstate` or `produceridstate` and maintain the actual transaction state separately? do you think the coupling will be so tight that they will need to be tracked in the same class?,0,0.9678557515144348
108021095,2735,hachikuji,2017-03-25T00:15:06Z,i think this comment is out of date.,0,0.9133625030517578
108021197,2735,hachikuji,2017-03-25T00:16:57Z,"i wonder if we should require the string to be null or non-empty. in guozhang's current tc patch, we treat the empty string the same as null, but maybe we shouldn't actually allow the client to send an empty string? seems doing so would be more likely to cause problems than not.",0,0.9389863014221191
108027736,2735,apurvam,2017-03-25T04:24:37Z,"yes. we should not allow empty strings imo. my transactional producer patch treats an empty transactionalid as being 'unset', and i think it makes sense to enforce that across the board.",0,0.9782533049583435
108027961,2735,apurvam,2017-03-25T04:39:37Z,"i don't know what a good name is for this. it currently maintains the `pidandepoch` and the pid->sequence number mappings. eventually, it will also store the transactional id, whether there is an active transaction, and the partitions belonging to the currently active transaction. there is no real coupling between the latter transactional state and the sequence number tracking except for the `pidandepoch`. as such, if we want to separate them, then a clean separation would require 3 classes. my preference would be to keep them all together, and just call it `transactionstate` or `transactionalstate`.",0,0.9614755511283875
108027985,2735,apurvam,2017-03-25T04:40:57Z,"i think there is still some value in keeping this check. the reason the number is being bumped here is because the sender constructor has added an argument. the solution would be to have a builder, but then a builder doesn't make sense for the sender. it may make sense to just exempt the `sender` for this check, but i am not sure if that is possible.",0,0.9531643390655518
108027989,2735,apurvam,2017-03-25T04:41:04Z,"i think we should modify this check and throw an `illegalstateexception` if we try to set producer state after the batch is closed, as that should never happen with the current code.",0,0.9903193712234497
108296196,2735,hachikuji,2017-03-27T22:29:39Z,"this should either be `>` or `>= 0`. we could also move this check to the caller. either way, we probably need a test case.",0,0.9939547181129456
108311921,2735,apurvam,2017-03-28T00:32:34Z,this is now fixed.,0,0.9744982719421387
108311947,2735,apurvam,2017-03-28T00:32:54Z,i have addressed this.,0,0.9625789523124695
108320177,2735,hachikuji,2017-03-28T02:00:26Z,we seem to have lost this comment.,-1,0.5417160391807556
108558825,2735,ijuma,2017-03-28T23:06:29Z,"hmm, are we going to remove these methods before we merge this pr?",0,0.9652877449989319
108558953,2735,ijuma,2017-03-28T23:07:18Z,this seems unused?,0,0.824500560760498
108559235,2735,apurvam,2017-03-28T23:08:55Z,"yes.. i am about to push changes that removes these, here and in other places.",0,0.953965961933136
108559389,2735,apurvam,2017-03-28T23:10:03Z,good catch. it was added during the initial implementations to generate pids before the server side code was ready.,1,0.8867000341415405
108571037,2735,junrao,2017-03-29T00:43:59Z,it doesn't seem time is being used.,0,0.8992624878883362
108571055,2735,junrao,2017-03-29T00:44:11Z,"log entry => record batch. perhaps it's clearer to say records received in the follower, instead of replication.",0,0.9929601550102234
108571063,2735,junrao,2017-03-29T00:44:17Z,"hmm, not sure why we need to expire the ids before the dirty offset.",0,0.5479786992073059
108571083,2735,junrao,2017-03-29T00:44:25Z,"it seems that the snapshots are created under a dir named topic-partition. so, it seems we don't need to include ${topicpartition.topic}-${topicpartition.partition} here?",0,0.9948195815086365
108571107,2735,junrao,2017-03-29T00:44:31Z,is this needed since we already did that during initialization of the class?,0,0.9946454763412476
108571120,2735,junrao,2017-03-29T00:44:35Z,"it doesn't seem that we are returning a value. if so, we want to remove =.",0,0.8788315653800964
108571134,2735,junrao,2017-03-29T00:44:41Z,probably log initpidrequest too?,0,0.9943821430206299
108571140,2735,junrao,2017-03-29T00:44:43Z,we will need to check if the request is authorized.,0,0.9852264523506165
108577375,2735,junrao,2017-03-29T01:54:04Z,"in replicafetcherthread, we probably want to log a warning if logappendinfo.isduplicate is true after the append() call since it's not expected.",0,0.9903725385665894
108577383,2735,junrao,2017-03-29T01:54:12Z,do we need this? it seems that we already validate this in producerequest.validaterecords() when the broker receives the produce request.,0,0.9936687350273132
108577397,2735,junrao,2017-03-29T01:54:23Z,could we make it clear that the latter epoch is the server epoch?,0,0.9939888715744019
108577429,2735,junrao,2017-03-29T01:54:37Z,should we do the same check for expiration when loading a snapshot?,0,0.9947686195373535
108577433,2735,junrao,2017-03-29T01:54:41Z,what is a base name?,0,0.9907776117324829
108577476,2735,junrao,2017-03-29T01:55:14Z,it doesn't seem that we have the logic to take snapshots periodically since this method is only called from tests?,0,0.989983081817627
108577487,2735,junrao,2017-03-29T01:55:18Z,remove after?,0,0.9889664053916931
108593416,2735,apurvam,2017-03-29T05:23:32Z,"it is actually the producer epoch which is stale in this case, but will clarify the exception message.",0,0.9850162267684937
108593532,2735,apurvam,2017-03-29T05:24:58Z,"good catch, will add a periodic cleaner task.",1,0.8620608448982239
108593569,2735,apurvam,2017-03-29T05:25:31Z,i added a jira to track this in a future pr: [a link],0,0.9746900796890259
108730187,2735,junrao,2017-03-29T16:57:16Z,"it would be inconvenient for a user to have to configure 2 other properties after enabling idempotence. perhaps we could set these 2 values to a reasonable default (e.g., 3 retries) if the user doesn't configure these properties explicitly. if the user explicitly set those properties with an incorrect value, we can then throw an exception.",0,0.697480320930481
108730238,2735,junrao,2017-03-29T16:57:24Z,"hmm, in sendandawaitinitpidrequest(), we just initiate a pid request w/o checking if we actually can send to the node. not sure if this is safe. networkclient also sends internal metadata request. so, it's possible that an ongoing metadata request is still pending on the same node and the send of pid request will hit an illegalstateexception in networkclient.dosend().",0,0.979060709476471
108746944,2735,hachikuji,2017-03-29T18:07:27Z,nit: `is true` seems redundant.,0,0.885569155216217
108747353,2735,hachikuji,2017-03-29T18:09:15Z,discussed offline. we agreed it's not actually necessary to block here since the sequence number is not assigned until the batch is ready to be sent anyway.,0,0.9863564968109131
108751964,2735,apurvam,2017-03-29T18:28:51Z,it seems to be called from `kafkaserver.scala:236`,0,0.9942376613616943
108758172,2735,apurvam,2017-03-29T18:53:31Z,not sure i follow. the `producerequest.validaterecords` just checks that the right message format goes with the right version. this check further validates that there is exactly one `recordbatch` in a produce request with the new message format. seems to me that the checks complement each other.,0,0.9875332117080688
108763087,2735,junrao,2017-03-29T19:15:17Z,"producerequest.validaterecords() has the following, right? [code block]",0,0.9910075068473816
108763450,2735,junrao,2017-03-29T19:16:51Z,"apply() is being called, but is time actually being used?",0,0.9854534268379211
108764029,2735,apurvam,2017-03-29T19:19:39Z,you are right. will delete this check.,0,0.6639959812164307
108764889,2735,apurvam,2017-03-29T19:23:53Z,"ah. so this is a reduced version of the class in the transactions branch. `time` is used in the `transactionstatemanager`, which is instantiated in the apply method.",0,0.9806892275810242
108766424,2735,apurvam,2017-03-29T19:31:23Z,good catch. deleted.,1,0.9845325350761414
108783378,2735,hachikuji,2017-03-29T20:49:21Z,this is no longer used.,0,0.9741581082344055
108784158,2735,hachikuji,2017-03-29T20:52:32Z,"now that we've merged the crc32c patch, we may as use that.",0,0.9895409941673279
108788282,2735,apurvam,2017-03-29T21:10:42Z,i think this comment is outdated. i updated with the actual logic. the snapshot files will be located inside a `pid-mapping` subdirectory of the log directory. the files themselves will be named with the pattern `$lastoffset.snapshot`.,0,0.9822892546653748
108793143,2735,junrao,2017-03-29T21:34:12Z,"not sure if we strictly needs to iswriteable. currently, during append(), if the current producerbatch is full, we just create a new batch.",0,0.964970052242279
108822679,2735,apurvam,2017-03-30T01:09:32Z,"actually, i undeleted these lines as they are needed. the `loadsnapshot` can be called in two cases: during initial start, and also when the log is truncated. in the latter case, if there is no previous snapshot, we need to reset to the start offset, which is what this code does.",0,0.9930877089500427
108841803,2735,apurvam,2017-03-30T05:05:10Z,"i have implemented this. the silght modification is that since the only invalid retries config is 0, which is the default, i just override the default to 3 when idempotence is enabled.",0,0.9864761233329773
108842422,2735,apurvam,2017-03-30T05:14:16Z,i just deleted this block from the producer.,0,0.9849287867546082
108844057,2735,apurvam,2017-03-30T05:35:50Z,"hmm. you may be right. the reason i introduced `iswritable` is because we can no longer close a batch when it is full. we can only close it at the point of sending in order to set the right sequence number. so i introduced `iswritable` to denote the state where it can no longer take appends, but is not closed. your point is valid: once a batch is considered full for a particular append, no future appends should go to it since there will be another batch at the tail which should get the new appends.",0,0.9273300170898438
108844701,2735,apurvam,2017-03-30T05:42:24Z,"so, looking over it a bit more, i now know why i introduced `iswritable`. the `isfull` method is not only used during append. it is also used to wake the sender up: if the deque is of size one and the only batch in there is not full, the sender will not be woken up to drain until it hits the linger ms. by introducing `iswritable` we can get the batch to be drained slightly quicker. not sure if the extra state is worth that optimization though.",0,0.9725322723388672
108957136,2735,junrao,2017-03-30T15:26:11Z,"hmm, in recordaccumulator.append(), we return the following. so if the current batch doesn't have enough space, we will create another one. then dq.size() will be > 1 and isfull will be true anyway. `return new recordappendresult(future, dq.size() > 1 || batch.isfull(), true);`",0,0.988520622253418
108990172,2735,apurvam,2017-03-30T17:40:56Z,yes. that makes sense. i will drop `iswritable`.,0,0.9440979957580566
108999545,2735,apurvam,2017-03-30T18:18:17Z,i have added this log line.,0,0.9311678409576416
109008262,2735,apurvam,2017-03-30T18:53:33Z,"synced offline, and we agreed this isn't a real problem since both `getreadynode` and `sendandawaitinitpidrequest` call poll. this will mean than any outstanding requests will get a chance to be processed there will be no deadlock.",0,0.9762099385261536
109035640,2735,junrao,2017-03-30T20:57:34Z,a more reliable way to check if a user explicitly sets the config is to check from config.originals(). ditto for configureretries().,0,0.9903629422187805
109035825,2735,junrao,2017-03-30T20:58:23Z,should we add the comment for isduplicate too?,0,0.991601288318634
109035966,2735,junrao,2017-03-30T20:58:57Z,perhaps we should default to 2 to increase the chance that we can rebuild from a snapshot after truncation?,0,0.993556797504425
109036428,2735,junrao,2017-03-30T21:01:07Z,it seems this method is never called?,0,0.9704369902610779
109036442,2735,junrao,2017-03-30T21:01:10Z,"lasttimestamp => maxtimestamp? also, probably add some comments to make it clear that firstseq, lastseq lastoffset and lasttimestamp refer to what's in the last appended batch?",0,0.9949061870574951
109036449,2735,junrao,2017-03-30T21:01:12Z,remove () to be consistent with how we call other methods?,0,0.994128942489624
109045847,2735,hachikuji,2017-03-30T21:46:55Z,we should probably mention in the docs that enabling idempotence will change the default configurations for retries and in-flight requests. i think it might also be worth adding at least a `debug` level log message in the code that we are overriding the defaults.,0,0.9927428960800171
109046583,2735,hachikuji,2017-03-30T21:51:11Z,do we have a test case for this?,0,0.992117702960968
109047045,2735,hachikuji,2017-03-30T21:53:33Z,"nit: we might want to spell out ""producerid"" in log messages, so there's no potential for confusion.",0,0.9907566905021667
109047372,2735,hachikuji,2017-03-30T21:55:32Z,"given that this class will be used to maintain transactional state as well, perhaps we should use a more explicit name. for example, `resetproducerid`, or maybe `invalideproducerid`.",0,0.9942692518234253
109047769,2735,hachikuji,2017-03-30T21:57:49Z,we shouldn't need a placeholder for the exception unless the intention is to not print the stack trace.,0,0.960902988910675
109048485,2735,hachikuji,2017-03-30T22:01:48Z,maybe we can add the pids to the exception message?,0,0.9940475225448608
109048510,2735,hachikuji,2017-03-30T22:01:59Z,nit: move to previous line,0,0.9383642077445984
109048622,2735,hachikuji,2017-03-30T22:02:28Z,nit: this could be `else if`?,0,0.9924715757369995
109049954,2735,hachikuji,2017-03-30T22:10:34Z,"we don't have to do it here, but we should make these messages a bit more user-friendly. for example, here we should mention the fact that an old epoch means that this process is probably a zombie and another producer has taken over.",0,0.9826268553733826
109050497,2735,hachikuji,2017-03-30T22:13:57Z,replace log entries with record batches,0,0.990261971950531
109050709,2735,ijuma,2017-03-30T22:15:09Z,"i don't have all the context, but isn't `3` pretty low? we don't do exponential back-offs, so the recommendation for no data loss is typically higher.",0,0.9430240392684937
109050957,2735,apurvam,2017-03-30T22:16:37Z,what is the recommendation for no data loss?,0,0.9902302622795105
109051026,2735,hachikuji,2017-03-30T22:17:01Z,can we list the possible errors in a comment like we do for other responses?,0,0.9940751791000366
109051149,2735,hachikuji,2017-03-30T22:17:52Z,"we can assert the epoch also? also, this is backwards: the expected value should be listed first.",0,0.9917608499526978
109051741,2735,hachikuji,2017-03-30T22:21:48Z,"i was looking for a test case which verified that the producer pid, epoch, and sequence number are set correctly in the records included with the produce request (e.g. using a `requestmatcher`). do we have one?",0,0.9926082491874695
109051933,2735,hachikuji,2017-03-30T22:22:54Z,what are we aborting? can you clarify in the name?,0,0.965205192565918
109052070,2735,hachikuji,2017-03-30T22:23:48Z,missing a test case for `reset`?,0,0.9934473633766174
109052173,2735,hachikuji,2017-03-30T22:24:29Z,nit: the convention we're using elsewhere is `pid`. same below.,0,0.9900017976760864
109052264,2735,hachikuji,2017-03-30T22:25:01Z,nit: we could probably `import networkclientutils._`,0,0.9945705533027649
109052858,2735,hachikuji,2017-03-30T22:28:31Z,might be a good idea to keep this private. we could add an `increment` method instead of writing to the field directly from external classes.,0,0.9929199814796448
109053045,2735,hachikuji,2017-03-30T22:29:47Z,nit: can we make this `producerid manager`?,0,0.9927102327346802
109053126,2735,hachikuji,2017-03-30T22:30:15Z,nit: no need for the type on the left-hand side.,0,0.9843652248382568
109054302,2735,hachikuji,2017-03-30T22:37:56Z,nit: no need for type on lhs.,0,0.9834752082824707
109054659,2735,hachikuji,2017-03-30T22:40:34Z,nit: we can assign `batch.lastoffset - batch.baseoffset +1` to a local variable so it's easier to understand.,0,0.9854789972305298
109054856,2735,hachikuji,2017-03-30T22:41:57Z,why was the comment moved here?,0,0.9788781404495239
109054973,2735,hachikuji,2017-03-30T22:42:36Z,probably we should add something to the comment above about doing pid validation.,0,0.9920165538787842
109055788,2735,hachikuji,2017-03-30T22:47:51Z,"might be worth mentioning that the loop will only iterate once for a duplicate client request to be clear that the values below will not be overwritten. would be nice if we could just break, but alas.",0,0.8504053354263306
109055870,2735,hachikuji,2017-03-30T22:48:25Z,`warn` seems a bit high. could this be `debug`?,0,0.926828920841217
109056087,2735,apurvam,2017-03-30T22:49:50Z,"actually, this is called from `produceridmappingtest.checkandupdate`. not sure why the ide doesn't find the usage, but the compiler definitely does!",0,0.980801522731781
109056104,2735,apurvam,2017-03-30T22:49:57Z,changed the name and added a comment.,0,0.9892811179161072
109056127,2735,hachikuji,2017-03-30T22:50:08Z,is this config part of the kip? do we really need it? i know we had discussed at one point just using a reasonable default.,0,0.9733529686927795
109056174,2735,apurvam,2017-03-30T22:50:31Z,good point. i think an `info` level log would be even more appropriate.,1,0.9047687649726868
109056729,2735,hachikuji,2017-03-30T22:54:13Z,"not clear what a ""valid"" entry is. maybe the check should be inverted and phrased as `hasentryexpired`?",0,0.9851352572441101
109057025,2735,hachikuji,2017-03-30T22:56:19Z,seems this loop would be a little clearer if we just built a list of the snapshot files sorted by offset and iterated over it?,0,0.984782874584198
109057203,2735,hachikuji,2017-03-30T22:57:30Z,"one thing i was thinking about (for another patch) is whether we should have like a minimum number of messages before it's worth doing another snapshot. if only 5 messages have been written since the last snapshot, for example, maybe we can just skip the new snapshot.",0,0.9822133779525757
109057493,2735,hachikuji,2017-03-30T22:59:29Z,was this intentional?,0,0.9558133482933044
109057570,2735,hachikuji,2017-03-30T23:00:02Z,not sure why the variable name was changed: `error` is more accurate.,0,0.9853776693344116
109058568,2735,hachikuji,2017-03-30T23:06:48Z,nit: you can use `fail` instead,0,0.9923461675643921
109058879,2735,hachikuji,2017-03-30T23:09:10Z,nit: seems convention is to have spaces before and after `=`?,0,0.9891026020050049
109062426,2735,ijuma,2017-03-30T23:38:20Z,"i don't think we should split the logic between this and `shouldretainmessage`. for example, the latter already checks `record.iscontrolrecord`.",0,0.9873578548431396
109065402,2735,apurvam,2017-03-31T00:05:33Z,just added one.,0,0.9847589135169983
109065473,2735,apurvam,2017-03-31T00:06:10Z,ok will update as and when i see them. updated this one.,0,0.9857871532440186
109066830,2735,apurvam,2017-03-31T00:20:04Z,"in this case, we want to swallow the exception and try again, since we can't do anything without a pid when idempotence is enabled.",0,0.9780657887458801
109067904,2735,apurvam,2017-03-31T00:32:14Z,"hmm. the only real error codes are when there are transactions, ie. `coordinatornotavailable`, `invalidtransactiontimeout`, and `notcoordinatorfortransactionalid`. i wonder if it makes sense to add these in this patch, or wait till we add transactions.",0,0.9571881294250488
109070585,2735,apurvam,2017-03-31T01:03:23Z,i just added this test.,0,0.9570648074150085
109071152,2735,apurvam,2017-03-31T01:09:52Z,i actually prefer to avoid wildcard imports.,0,0.9468599557876587
109086998,2735,apurvam,2017-03-31T04:42:24Z,not sure how that moved around like that. i think it must have been a fat fingered cut/paste from last night. moved it back now.,-1,0.7937065362930298
109087940,2735,apurvam,2017-03-31T04:58:38Z,"i'll bump it down to info. debug seems too low, since this should happen fairly rarely.",0,0.9450345635414124
109088180,2735,apurvam,2017-03-31T05:02:32Z,"not sure if it would be more clear, but probably more efficient. i made the change this way so that we retain the existing logic for picking the latest snapshot less than the given offset.",0,0.9830665588378906
109088358,2735,apurvam,2017-03-31T05:05:11Z,nope. seems to have been there since fpj's time. i fixed it.,0,0.948727011680603
109088745,2735,apurvam,2017-03-31T05:10:57Z,"hmm. it is not part of the kip. we agreed that 2 would be a good static value, i think. will update.",0,0.8043858408927917
109089311,2735,apurvam,2017-03-31T05:19:20Z,"the reason to choose a positive name is that we use it to retain unexpired entries. if we choose something like `hasentryexpired` we would have to negate the usage everywhere. seems like both have their tradeoffs, so i would prefer to leave it as is.",0,0.9892187714576721
109090712,2735,apurvam,2017-03-31T05:37:14Z,added the comment.,0,0.9853179454803467
109090729,2735,apurvam,2017-03-31T05:37:25Z,added the comment.,0,0.9853179454803467
109090769,2735,apurvam,2017-03-31T05:37:42Z,added a test case.,0,0.9892928600311279
109090797,2735,apurvam,2017-03-31T05:38:10Z,added a line for `isduplicate`,0,0.99345463514328
109092828,2735,apurvam,2017-03-31T06:02:38Z,i consolidated all the logic into `shouldretainmessage`.,0,0.9930821657180786
109131783,2735,ijuma,2017-03-31T10:27:02Z,wouldn't `awaitleastloadednodeready` be a clearer name?,0,0.9944196343421936
109132404,2735,ijuma,2017-03-31T10:31:37Z,nit: it's a bit nicer if we return `long` here.,0,0.861394464969635
109132472,2735,ijuma,2017-03-31T10:32:05Z,"for my benefit, when we do we use `producer_id` and when do we use `pid`?",0,0.9904065728187561
109133247,2735,ijuma,2017-03-31T10:36:33Z,"we can avoid the `currenttimemillis` if `timestamptype` is `create_time`. in that case, we can simply use `no_timestamp`. the same applies for a couple of other methods.",0,0.9947555065155029
109134063,2735,ijuma,2017-03-31T10:41:54Z,it would probably be useful to include some data in this message. maybe the existing pid/epoch/basesequence and the new proposed values?,0,0.9918515086174011
109134528,2735,ijuma,2017-03-31T10:45:09Z,please add a simple unit test in byteutilstest for this.,0,0.9910577535629272
109134743,2735,ijuma,2017-03-31T10:46:43Z,nit: long line.,-1,0.8998382687568665
109135119,2735,ijuma,2017-03-31T10:49:23Z,"hmm, but this same file has been changed to use wildcard imports at the top (e.g. `import org.apache.kafka.common.network._`)?",0,0.9884463548660278
109135874,2735,ijuma,2017-03-31T10:54:46Z,the 5 lines above can be written as: [code block],0,0.9905776977539062
109136849,2735,ijuma,2017-03-31T11:01:42Z,simpler perhaps: [code block],0,0.9902746677398682
109137853,2735,ijuma,2017-03-31T11:09:11Z,"nit: it seems odd to have ""added this test"" as a test comment. something like ""verify behaviour of zkutils.createsequentialpersistentpath since pidmanager relies on it"" seems like the expected style.",-1,0.5649547576904297
109137937,2735,ijuma,2017-03-31T11:09:45Z,why do we have this at error level?,0,0.93353670835495
109139892,2735,ijuma,2017-03-31T11:22:44Z,"great question. :) infinite is often what is said in talks. but that may not be the right value either. i think it's worth thinking about what the retries help us recover from and how long would we want to keep retrying for. because with the default retry backoff of 100ms, 3 retries get used pretty fast. say that we wanted to keep retrying for 10 seconds, that would be roughly 100 retries. the other side of the coin is: what is the cost of having a high retry number?",1,0.9945071339607239
109161698,2735,ijuma,2017-03-31T13:41:03Z,"nit: i personally find comments that just repeat what the code is doing not so useful. however, if we explained why we need to reset the pid in this case, that would be pretty useful.",0,0.781953752040863
109162930,2735,ijuma,2017-03-31T13:46:52Z,have we done any performance tests to see the impact of this change? the change i made to close the memory records here made a huge difference to the amount of memory used by the producer due to temporary compression buffers.,0,0.9712345600128174
109163235,2735,ijuma,2017-03-31T13:47:58Z,nit: this could just be `recordsbuilder`. we generally avoid the `get` prefix in kafka.,0,0.9944825172424316
109261455,2735,apurvam,2017-03-31T22:29:59Z,"so i thought about this a bit more. i think it still make sense to validate this on the server side. i assume that the librdkafka clients may not have the request side validation, so it would be good to have server side validation before we write to the log.",0,0.9426909685134888
109266099,2735,apurvam,2017-03-31T23:19:18Z,i added this documentation to the `transactionstate.resetproducerid` method.,0,0.9931079149246216
109266180,2735,apurvam,2017-03-31T23:20:06Z,was used during debugging. reverted to debug level.,0,0.9786559343338013
109267210,2735,apurvam,2017-03-31T23:33:57Z,"i think it is a bit arbitrary. it started with pid everywhere, but then started changing gradually to producerid or producer_id.",0,0.7411673069000244
109269845,2735,apurvam,2017-04-01T00:10:55Z,"actually, the whole error message is out dated. we should not be calling `setproducerstate` on a closed batch any more. doing so is a bug on the client. updated the message to indicate that.",0,0.9288650155067444
109270153,2735,apurvam,2017-04-01T00:16:23Z,done.,0,0.9640594124794006
109277377,2735,junrao,2017-04-01T04:26:50Z,"similar to this, it seems the default acks=1 doesn't make sense when idempotence is enabled. this is because with acks=1, acked messages could be lost during leader change. then, the producer will be out of sequence. perhaps if idempotence is enabled, we should enforce acks=all.",0,0.9848921298980713
109290030,2735,apurvam,2017-04-01T17:45:08Z,"sounds good. of course, we also depend on some topic level settings like: replication.factor >= 3, min.isr >= 2, unclean.leader.election=false. but i agree, we should do what we can on the client.",1,0.8774775266647339
109290465,2735,apurvam,2017-04-01T18:06:22Z,i added the override for acks. will make a note to update the kip as well.,0,0.9847434759140015
109333086,2735,junrao,2017-04-03T02:43:38Z,entry => record,0,0.9854384660720825
109333094,2735,junrao,2017-04-03T02:43:48Z,i thought we agreed that this check is unnecessary given the check in producerequest?,0,0.9908292293548584
109481971,2735,apurvam,2017-04-03T17:52:20Z,"we did, initially, but then i followed up on that thread (which is now impossible to find on github). here is what i wrote:",0,0.9660133719444275
109488221,2735,junrao,2017-04-03T18:18:32Z,"hmm, producerrequest.validaterecords() is called on the broker side when converting bytes from socket to a request object. so, even if librd client has an issue, the broker should still be able to capture this when constructing producerrequest.",0,0.9909851551055908
36813449,130,hachikuji,2015-08-11T23:46:46Z,can you add some documentation for some of these interfaces?,0,0.9913668036460876
37058213,130,ijuma,2015-08-14T08:32:18Z,"since this class is used a lot, making the name short would help (as long as clarify is maintained). how about calling it `pair`?",0,0.9933140873908997
37058443,130,ijuma,2015-08-14T08:36:39Z,this makes `compareto` inconsistent with `equals`. is that intentional?,0,0.9664652347564697
37058480,130,ijuma,2015-08-14T08:37:14Z,maybe explain why?,0,0.9344130158424377
37058865,130,ijuma,2015-08-14T08:43:02Z,wouldn't this be better as `return new hashset<>(arrays.aslist(elems))`?,0,0.9942798614501953
37059011,130,ijuma,2015-08-14T08:45:43Z,there is already a `join` method in this class. can you not use that?,0,0.9932148456573486
37059086,130,ijuma,2015-08-14T08:47:15Z,rely on auto-boxing for less verbosity?,0,0.9748664498329163
37146536,130,rhauch,2015-08-16T14:46:09Z,"do you mean ""better"" to be more readable? or more efficient? the current code is does less work than `new hashset<>(arrays.aslist(elems))`.",0,0.9911265969276428
37147003,130,rhauch,2015-08-16T15:37:38Z,"the `run()` and `close()` methods should not be synchronized. because they are, then once `run()` is called it will block any other synchronized method, including `close()`, and because `run()` only completes when `close()` is called, `run()` will never complete. in other words, the thread will never stop. you should be able to simply remove the `synchronized` keywords with the current code and maintain thread safety of the `running` volatile boolean field: the only method that reads that field is the private `stillrunning()` (called via private `runloop()` which is called via public `run()`), while the only method that writes to the field is `close()`.",0,0.9940367937088013
37147025,130,rhauch,2015-08-16T15:40:33Z,"this `recordsprocessed` field is never changed. if it were, it'd probably need to be made volatile, or better yet changed to be `final atomiclong` so that operations are atomic.",0,0.9945599436759949
37147089,130,rhauch,2015-08-16T15:44:05Z,add `lastcommit = now' as a last line in this method?,0,0.9947924017906189
37169892,130,ijuma,2015-08-17T09:13:30Z,", i meant both. by passing the collection to the copy constructor of the `hashset`, the initial size of the internal array is big enough to contain the elements of the collection. this avoids reallocation and rehashing. note that `arrays.aslist` doesn't copy elements, it's just a view over the array. if this view is deemed too expensive (seems doubtful), we could keep the existing code, but then we should pass the correct sizing parameters to the `hashset` constructor.",0,0.9915254712104797
37339719,130,rhauch,2015-08-18T19:05:31Z,"the `producerrecord` class has a constructor that takes the partition number, yet that doesn't appear to be exposed in these two `send(...)` methods. am i missing how to specify the partitioning logic for each of the sent messages? update: okay, it's pretty obvious you can set the `partitioner.class` property in the producer's configuration to the name of the `partitioner` implementation class. doing this makes the `kafkaproducer` pass the message key to the `partitioner` to determine the partition number. is this a best practice, or is it still logical for our `processor` implementation to determine the partition, perhaps based upon something other than they key. if so, then it'd be great to have additional `send(...)` methods that take the partition number.",0,0.9867616891860962
37673148,130,rhauch,2015-08-21T20:09:58Z,"the `createsensor(...)` method called on lines 68-75 uses the `this.metrics` field, and because `this.metrics` is not set until line 76 the result is a `nullpointerexception`. to fix, simply move the `this.metrics = context.metrics();` line before the first call to `createsensor(...)`.",0,0.9941228032112122
37675103,130,rhauch,2015-08-21T20:32:23Z,these two lines should get the **de**serializer from the context: [code block],0,0.9922313690185547
37711404,130,rhauch,2015-08-23T22:38:16Z,"this would be easier to implement if the parameter to this method were an `iterable >` than a `list >`. for example, the current `rocksdbkeyvaluestore` uses `byte[]` for the keys and values, and it's pretty easy to wrap that with a parameterized class that uses provided `serializer` and deserializer`instances for the keys and values -- except that the`putall`method cannot be easily implemented as a delegate if it takes a`list`. (in essence, the list has to be fully-copied before the delegation can be made. i'd be happy to provide a patch with this fix.",0,0.9839694499969482
38231414,130,guozhangwang,2015-08-28T18:47:48Z,ack.,0,0.5038502812385559
38231825,130,guozhangwang,2015-08-28T18:51:45Z,"does compareto have to be consistent with equals? i though compareto is supposed to be used as comparable for priorityqueue, etc while equals is for identity matching in map, etc?",0,0.9936572909355164
38232147,130,guozhangwang,2015-08-28T18:54:20Z,ack.,0,0.5038502812385559
38232260,130,guozhangwang,2015-08-28T18:55:31Z,ack.,0,0.5038502812385559
38232422,130,guozhangwang,2015-08-28T18:57:01Z,ack.,0,0.5038502812385559
38232732,130,guozhangwang,2015-08-28T19:00:00Z,"not sure if we can use auto-boxing here, since need to explicitly transform string to integer here.",0,0.9833155870437622
38234637,130,guozhangwang,2015-08-28T19:21:50Z,ack.,0,0.5038502812385559
38237786,130,ijuma,2015-08-28T19:55:28Z,"my bad, i misread.",-1,0.9897112846374512
38237961,130,ijuma,2015-08-28T19:56:57Z,it's generally a good idea. the documentation for `comparable` says: [code block],1,0.7930170893669128
38252600,130,guozhangwang,2015-08-28T23:00:23Z,"ok makes sense, however after a second thought i feel by ""consistency"" we want: 1) if compareto() returns none-zero, equals() should return false; 2) if equals() returns true, compareto() should return zero. but: 3) if equals() returns false, compareto() does not necessarily returns none-zero. 4) if compareto() returns zero, equals() does not necessarily returns true. if we enforce 3) and 4) as well, it means sorted set / map will not allow two records who are comparably same to each other as the docs stated; but for our case, we actually want two stamped objects with the same timestamp to still be stored at the same time as keys if we ever want to do so.",0,0.966529369354248
38252639,130,guozhangwang,2015-08-28T23:01:09Z,ack.,0,0.5038502812385559
38252646,130,guozhangwang,2015-08-28T23:01:20Z,ack.,0,0.5038502812385559
38252729,130,guozhangwang,2015-08-28T23:02:51Z,ack.,0,0.5038502812385559
38252996,130,guozhangwang,2015-08-28T23:07:55Z,i think we can wrap the producer / consumer configs in the streaming / processor congis as you mentioned.,0,0.9788909554481506
38253008,130,guozhangwang,2015-08-28T23:08:11Z,ack.,0,0.5038502812385559
38589091,130,rhauch,2015-09-02T21:48:22Z,"when a `processor` instance is started, the framework calls `init(processorcontext)`, but with the most recent changes it is no longer possible for a `processor` implementation to get the configuration from the `processorcontext`. how can one pass in the configuration into the `processor`? for example, my processor implementation might require several configuration properties to control or alter the default behavior. using the same configuration sure seemed like a natural way to do this. one option is to pass the `streamingconfig` object into the `processordef` constructor, which would change line 94 to be something like: [code block] the `processdef` could then pass the configuration into the constructor of the `processor` implementation. while that works, it seems like this would then require the `topologybuilder` to contain objects that are dependent upon a configuration, and that might not be the same configuration passed into `new kafkastreaming(builder, config);` (line 98 above). it sure seems better and far simpler to instead allow `processor.init(processorcontext)` access to the same configuration that kafkastreaming has when it is initializing the processor. iow, either change `processorcontext` to expose the configuration (as before), or (better yet imo) add a second parameter to `processor.init(...)` so it then becomes: [code block] thoughts? am i missing something more obvious?",0,0.9941747784614563
38593399,130,rhauch,2015-09-02T22:31:44Z,"can `addsource`, `addsink`, and `addprocessor` be changed to return `topologybuilder` instance so that the builder's methods can be chained together. if so, then this: [code block] becomes: [code block] might not be useful in all situations, but in some cases it works quite beautifully. i'd be happy to submit a pull-request for this. update: here's the very simple pr: [a link]",1,0.9800882935523987
38677576,130,guozhangwang,2015-09-03T18:11:44Z,"that is a good point, will review the pr.",1,0.6183438301086426
38678884,130,guozhangwang,2015-09-03T18:21:45Z,"streamingconfig is supposed to only include config values that are used by the kafkastreaming runtime but not in the user logic, if users do want to modify the behavior of their processors based on some streamingconfig values they can either do: [code block] or they can also pass-in the whole streamingconfig object, which of course can be different from the one they passed into kafkastreaming, into their instantiated processordef constructors, although i personally would not recommend this way. generally i think streamingconfig should not be exposed to the processor interface layer, since it is designed to be used only at the runtime level.",0,0.9894982576370239
38683389,130,rhauch,2015-09-03T19:00:04Z,"okay, that sounds reasonable.",0,0.9144694209098816
38684688,130,rhauch,2015-09-03T19:12:28Z,"the casting done on line 53 from `processorcontext` to `processorcontextimpl` makes testing difficult, as the tests would require a `processingcontextimpl` rather than an alternative. (see how `kstreamtestdriver` uses a `mockprocessorcontext` for an example.) i assume that `recordcollector()` was removed from `processorcontext` to hide it from `processor` implementations, so this cast can either be kept and the test classes required to use a subclass of `processorcontextimpl`, or the `processorcontextimpl` implements another internal interface that `sinknode` can use here when casting and the test classes can choose to implement. thoughts? (it looks like tests that use `kstreamtestdriver` do so by implementing a tail-end mock processor. i'm trying to create a similar test driver for testing a `processor` and a `topology`. right now the only problem is that the `sinknode` throws a classcastexception on line 53.)",0,0.9957268238067627
38686619,130,rhauch,2015-09-03T19:30:48Z,"another option might be to break the current `processorcontextimpl` into two classes: one that holds the objects that all impls would need (e.g., the (de)serializers, the `recordcollector`, the `streamingconfig`, the `arraydeque `, and maybe the `metrics`), and a subclass that adds `streamtask` and `processorstatemanager`. the `sinknode` could cast to the base impl, and the test drivers could have impls that extend the base impl. if this sounds interesting, let me know and i'll create a pr for easier evaluation and comparison.",0,0.9746690392494202
38795321,130,rhauch,2015-09-04T21:21:44Z,"the fact that the `processorcontextimpl` class is creating its own consumer turns out to be a fairly significant problem for test cases, especially those that directly use `streamtask`. i'd love to introduce a `consumersupplier` (in java 8 it'd simply be `supplier `, but alas) and pass an implementation into this constructor and actually into the `streamtask` constructor. this would then move the creation of this `consumersupplier` into the `streamthread`, which is already creating the `kafkaproducer` and `kafkaconsumer` instances used to consume records to pass to the `streamtask`. and if this is acceptable, is it still desirable to use a _separate_ `kafkaconsumer` instance for the `processorstatemanager`?",0,0.8833712339401245
38795471,130,rhauch,2015-09-04T21:24:00Z,"i've been able to work around this problem by directly using `streamtask`, which internally creates its `processorcontextimpl` instance. however, the only roadblock i have is that the `processorcontextimpl` is explicitly creating a `kafkaconsumes`. see the details in [a link].",0,0.9898397922515869
38967999,130,guozhangwang,2015-09-08T19:20:06Z,"yeah i agree this is kinda awkward. the reason we need a separate consumer for restoring state is that the other consumer is 1) created for the thread and shared among its tasks, and 2) its subscribed topics is determined by the topology statically. while for local state the topic name is defined dynamically and the restoration is only one-time: once it is done you do not need to keep subscribing to it anymore. i think one thing we can do here is to move the creation of the restoration consumer into the processor-state-manager, and set a flag into the processor-state- manager's constructor indicating whether we need to create this consumer (set to false for unit tests, for example).",-1,0.9424416422843933
38968103,130,guozhangwang,2015-09-08T19:21:12Z,"btw are you working on adding some unit test classes? since i am also working on some of them, would like to avoid any duplicate work or conflicts :)",1,0.954618513584137
38974963,130,rhauch,2015-09-08T20:22:45Z,"actually, i've written a `processingtopologytestdriver` class under `src/test` that takes a topologybuilder and will make it very easy for projects that use kafka streams to test their topologies with unit tests that do not use a real kafka. each test method can set up the driver, pass one or more methods to the driver (which then forwards them to the appropriate source), and finally check the messages output by the sinks. it's pretty simple, and it uses mock consumers and producers along with a single `streamtask` to do all the heavy lifting. (this has the benefit of also testing the bulk of the `streamtask` implementation.) so, it'd be great if this test driver could pass the consumer for state manager into the `streamtask` constructor took a consumer (or consumer supplier) so that the tests can inject mocks instead; the `streamtask` constructor already takes a consumer and producer, so taking a second consumer for state management seems consistent. right now `streamtask` is the only thing that constructs a `processingcontextimpl`, so passing the consumer down also seem reasonable. this approach also seems to have minimal impact on other code, and imo is better than passing a flag into the processor state manager's constructor or calling a method on the processor state manager, since right now the the `processorstatemanager` is constructed within the `processingcontextimpl` class which itself is constructed within the `streamtask` constructor. btw, the test driver class and a unit test is ready for a pr, except that the tests that use state management are failing right now because it's trying to create a real consumer for state management. i'll go ahead and make the aforementioned change to pass in the consumer, fix my tests, and submit a pr for review first thing tomorrow.",0,0.706994891166687
39053621,130,rhauch,2015-09-09T15:00:22Z,the pr is now available: [a link],0,0.9400354027748108
39055740,130,rhauch,2015-09-09T15:16:23Z,", how should i proceed with new unit tests. any suggestions so we don't duplicate effort? is there a better way to coordinate other than comments in this pr?",0,0.9644980430603027
39055851,130,rhauch,2015-09-09T15:17:13Z,added a pr with the simple correction: [a link],0,0.9805167317390442
39056201,130,rhauch,2015-09-09T15:19:40Z,"with this configuration of `stream`, the test jars are not build and uploaded to maven. i created a pr ([a link] that corrects this so that the test jars are created and uploaded similarly to how `client` does it.",0,0.9916819930076599
39059471,130,eribeiro,2015-09-09T15:44:26Z,"see, here you should evaluate what is the semantic that `paused` should have. if we want to return a **snapshot** of the paused `topicpartition` then it's better to do: [code block] if we want to return a **dynamic** view of the `paused` then it's better to use: [code block] in either case, we should return an unmodifiable view of the set, because it's not very nice to expose a mutable field directly to callers as above.",0,0.9888325929641724
39059935,130,eribeiro,2015-09-09T15:47:34Z,nit: rename this method to `remove` or `delete`,0,0.9932110905647278
39060300,130,eribeiro,2015-09-09T15:50:39Z,"""returns an empty collection if this list is empty or null""",0,0.9882459044456482
39060354,130,eribeiro,2015-09-09T15:51:00Z,"it is best practice to use `collections.emptylist()` instead of `collections.empty_list` also, would make a difference to return `collections.emptylist()` if the `other` is empty? i mean, like this: ` return other == null || other.isempty() ? collections.emptylist() : other; `",0,0.994024932384491
39061914,130,eribeiro,2015-09-09T16:02:27Z,private **final**?,0,0.9847299456596375
39062322,130,eribeiro,2015-09-09T16:05:23Z,"why not use `((long) key);` or even `((integer) key)`. no need to call `longvalue()` as the autoboxing is called automatically, afaik.",0,0.9938934445381165
39062772,130,eribeiro,2015-09-09T16:08:56Z,nit: can remove this blank line.,0,0.9854300022125244
39062866,130,eribeiro,2015-09-09T16:09:42Z,it's nice to expose those as: ``public final list keys = new arraylist<>()` same for line 35,0,0.8334869146347046
39062965,130,eribeiro,2015-09-09T16:10:20Z,it's nice to expose those as: `public final list processed = new arraylist<>() same for line 29,0,0.7579827308654785
39063280,130,eribeiro,2015-09-09T16:12:57Z,"paraphrasing joshua bloch, prefer collections to arrays so i would use: [code block]",0,0.9862842559814453
39063561,130,eribeiro,2015-09-09T16:15:18Z,better to make `state` volatile too.,0,0.9929022192955017
39063741,130,eribeiro,2015-09-09T16:16:51Z,"still in this mood, this method could be rewritten as: [code block]",0,0.9935247898101807
39064142,130,eribeiro,2015-09-09T16:20:17Z,"if `state` is different from `created` then lines l#93 and l#94 are unreachable. therefore, why not move them to end of the `if` block? [code block]",0,0.9933117628097534
39064231,130,eribeiro,2015-09-09T16:20:52Z,same as above: lines 121 and 123 can be moved to inside the if block.,0,0.9939970970153809
39065910,130,eribeiro,2015-09-09T16:35:20Z,nit: `private list list = new linkedlist ();`,0,0.9928030371665955
39067165,130,eribeiro,2015-09-09T16:47:24Z,"as all the methods synchronize on the whole body why not make all the methods `synchronized`, like: `public synchronized void close() {` ?",0,0.993486225605011
39067236,130,eribeiro,2015-09-09T16:48:12Z,formatting: break line as: [code block],0,0.9915796518325806
39067357,130,eribeiro,2015-09-09T16:49:14Z,nit: prefer interfaces on field declaration as: `private final deque nodestack = new arraydeque ();`,0,0.9931179285049438
39067577,130,eribeiro,2015-09-09T16:51:20Z,"tip: you can rewrite as `final int[] expectedkeys = {1, 10, 100, 1000};`",0,0.9924484491348267
39067625,130,eribeiro,2015-09-09T16:51:56Z,"tip: you can rewrite as final `string[] expected = {""1:1"", ""10:2"", ""100:3"", ""1000:4""};`",0,0.9915286302566528
39067732,130,eribeiro,2015-09-09T16:52:53Z,"tip: you can rewrite as `string[] expected = {""0:v0"", ""0:v0"", ""1:v1"", ""1:v1"", ""2:v2"", ""2:v2"", ""3:v3"", ""3:v3""};`",0,0.9911066889762878
39067794,130,eribeiro,2015-09-09T16:53:25Z,"tip: you can rewrite as `final int[] expectedkeys = {0, 1, 2, 3};`",0,0.9927769899368286
39089821,130,guozhangwang,2015-09-09T20:11:31Z,i am working on calling for a review round and push the first patch to os now. once that is done further prs can be submitted directly to apache/kafka. could you hold the current changes and rebased them to the apache trunk once this patch is checked in?,0,0.986724317073822
39090342,130,guozhangwang,2015-09-09T20:16:00Z,ack.,0,0.5038502812385559
39090441,130,guozhangwang,2015-09-09T20:16:43Z,ack.,0,0.5038502812385559
39090503,130,guozhangwang,2015-09-09T20:17:14Z,ack.,0,0.5038502812385559
39090892,130,guozhangwang,2015-09-09T20:20:34Z,"good point, changed to `collections.emptylist()`. the semantics is only to return an empty list if `other` is null, if it is empty then we will still return itself.",0,0.9416589736938477
39090991,130,guozhangwang,2015-09-09T20:21:28Z,ack.,0,0.5038502812385559
39091129,130,guozhangwang,2015-09-09T20:22:51Z,the value integer cannot be cast directly to long.,0,0.9658873677253723
39091209,130,guozhangwang,2015-09-09T20:23:27Z,ack.,0,0.5038502812385559
39091297,130,guozhangwang,2015-09-09T20:24:14Z,ack.,0,0.5038502812385559
39091428,130,guozhangwang,2015-09-09T20:25:18Z,ack.,0,0.5038502812385559
39092030,130,guozhangwang,2015-09-09T20:30:19Z,ack.,0,0.5038502812385559
39092290,130,guozhangwang,2015-09-09T20:32:35Z,since the start() / close() are synchronized the states will not be accessed concurrently. so i think it is not necessary?,0,0.9903760552406311
39092328,130,guozhangwang,2015-09-09T20:32:54Z,ack.,0,0.5038502812385559
39092500,130,guozhangwang,2015-09-09T20:34:28Z,ack.,0,0.5038502812385559
39092546,130,guozhangwang,2015-09-09T20:34:53Z,ack.,0,0.5038502812385559
39092616,130,guozhangwang,2015-09-09T20:35:33Z,we used linkedlist's offerlast / etc functions later so we have to declare it as linkedlist.,0,0.9941526055335999
39092736,130,rhauch,2015-09-09T20:36:21Z,it should be volatile so that different threads see the actual value at the same time.,0,0.9918127059936523
39098298,130,eribeiro,2015-09-09T21:22:58Z,"oh, ok. excuse me for overlooking this. you right.",-1,0.7732889652252197
39197241,130,eribeiro,2015-09-10T18:40:16Z,"i would suggest to use a more modern approach that is replace int constants by enums. therefore, it becomes: [code block]",0,0.9931074976921082
39197493,130,eribeiro,2015-09-10T18:42:27Z,nit: a nifty trick to use here (reduces the scope of `iter` would be): [code block],0,0.8178935050964355
39198066,130,eribeiro,2015-09-10T18:47:38Z,using lock objects is considered a old fashioned approach. better to use a reentrantlock as below: [code block],0,0.9920008182525635
39198676,130,eribeiro,2015-09-10T18:52:36Z,"nit: maybe name this method as `of`, like `keyvalue.of(10, ""hello"")`",0,0.9936085939407349
39198875,130,eribeiro,2015-09-10T18:54:24Z,"this line and line below can be : `public final list = new arraylist<>();`, as well as line below.",0,0.9920348525047302
39199065,130,eribeiro,2015-09-10T18:56:02Z,lines 34-36 can be simplified as: `return timestamp - othertimestamp;` a nifty trick ;),1,0.9932014346122742
39199114,130,ijuma,2015-09-10T18:56:33Z,"this is not really true. there are advantages and disadvantages when it comes to choosing between `synchronized` and `reentrantlock`. for low contention cases, `synchronized` tends to do better, in fact.",0,0.989661455154419
39199275,130,eribeiro,2015-09-10T18:58:03Z,it's usually advisable to 1) make pq final; or 2) create a lock field or 3) synchronize the whole method only don't synchronize on a **non final** field.,0,0.9938045740127563
39199569,130,eribeiro,2015-09-10T19:00:44Z,"yeah, you right. my fault. for low contention synchronized is better.",-1,0.4801044166088104
39212009,130,eribeiro,2015-09-10T20:51:24Z,"i feel maybe we need a method to check the status of this class, that is: [code block] wdyt?",0,0.9880536198616028
39214847,130,eribeiro,2015-09-10T21:15:09Z,typo: 'coresponds' should be `correponds`,0,0.9932831525802612
39215090,130,eribeiro,2015-09-10T21:17:13Z,"nit: **i** would name this method as `nulltoempty` to let it clear what it does, but up to you. :)",1,0.9918985366821289
39215276,130,eribeiro,2015-09-10T21:18:57Z,"nit: **i** would name this method `newset`and make it return `set` instead of a `hashset`, but, again, up to you. :) ps: btw, once guava is incorporated into kafka project, the `sets` helper class has methods to replace this one. ;)",1,0.9955540299415588
39228036,130,eribeiro,2015-09-10T23:42:05Z,as above,0,0.9391705989837646
39228037,130,eribeiro,2015-09-10T23:42:05Z,"declare as `public final list keys = new arraylist<>();`, as well as line below",0,0.9928365349769592
39228134,130,eribeiro,2015-09-10T23:43:18Z,"i suppose this is a leftover, right?",0,0.9855436086654663
39228245,130,eribeiro,2015-09-10T23:45:08Z,declare as `private final deque nodestack = new arraydeque<>();`,0,0.992622971534729
39228751,130,eribeiro,2015-09-10T23:52:50Z,that kafka convention: ` if (condition) statement ` on the following line too.,0,0.9930550456047058
39228814,130,eribeiro,2015-09-10T23:53:34Z,**final** for `keyserializer` and `valserializer`?,0,0.99333256483078
39228849,130,eribeiro,2015-09-10T23:54:01Z,define as `private final deque fifoqueue;`,0,0.9924353957176208
39471570,130,eribeiro,2015-09-15T03:33:29Z,"hey, why don't we return a empty `iterator` here? you can do this with `collections. emptylist().iterator()`. returning null is usually a code smell. wdyt?",0,0.7731137871742249
39472217,130,eribeiro,2015-09-15T03:50:47Z,can be simplified as `for (int i : expectedkeys) {`,0,0.9943097829818726
39472298,130,eribeiro,2015-09-15T03:53:05Z,format: [code block],0,0.9913088083267212
39472324,130,eribeiro,2015-09-15T03:53:37Z,formatting: no need for curly braces here,0,0.987177848815918
39472333,130,eribeiro,2015-09-15T03:53:50Z,format: no need for curly braces,0,0.9861056208610535
39472370,130,eribeiro,2015-09-15T03:54:44Z,lines l#53 to l#55 can be simplified as: [code block],0,0.9918543100357056
39472425,130,eribeiro,2015-09-15T03:55:57Z,"i like to rewrite those if-else condition as: `return (stamped == null) ? lastknowntime : stamped.timestamp`, but up to you.",0,0.9873375296592712
39472674,130,eribeiro,2015-09-15T04:02:25Z,formatting: no need for curly braces,0,0.9892904162406921
39472691,130,eribeiro,2015-09-15T04:02:50Z,formatting: no need for curly braces.,0,0.9897779822349548
39472770,130,eribeiro,2015-09-15T04:05:04Z,that **snapshot** vs **dynamic view** intention: what do we want here? if it's the current snapshot then it's `return new hashset<>(partitionqueues.keyset());`,0,0.9948267340660095
39472806,130,eribeiro,2015-09-15T04:06:00Z,formatting: no need to curly braces,0,0.9894806146621704
39472985,130,eribeiro,2015-09-15T04:10:55Z,doesn't it need a `new hashset<>(sourcebytopics.keyset())` to return a snapshot as line 46?,0,0.9951139688491821
39473139,130,eribeiro,2015-09-15T04:14:03Z,`list result = new arraylist<>();`,0,0.9907301068305969
39473154,130,eribeiro,2015-09-15T04:14:24Z,`list expected = new arraylist<>();`,0,0.9914107322692871
39473162,130,eribeiro,2015-09-15T04:14:41Z,`list expected = new arraylist<>();`,0,0.9914107322692871
39473198,130,eribeiro,2015-09-15T04:15:47Z,can be simplified as `for (int i : expectedkeys) {`,0,0.9943097829818726
39679109,130,rhauch,2015-09-16T20:15:28Z,"it does not appear that `kafkaconsumer` (or rather the `subscriptionstate` class it uses) allows using both `subscribe(...)` and `assign(...)`. given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: [code block]",0,0.9951761960983276
39904068,130,guozhangwang,2015-09-18T21:41:29Z,ack.,0,0.5038502812385559
39904149,130,guozhangwang,2015-09-18T21:42:37Z,ack.,0,0.5038502812385559
39904467,130,guozhangwang,2015-09-18T21:46:39Z,ack.,0,0.5038502812385559
39904581,130,guozhangwang,2015-09-18T21:47:56Z,"the topology's immutable, such that the processornodes and sourcebytopics will not be modified.",0,0.9892376661300659
39904795,130,guozhangwang,2015-09-18T21:50:39Z,"yeah, it will be replaced with the unsubscribe() api introduced in [a link]",0,0.9885584115982056
39912569,130,onurkaraman,2015-09-19T00:12:25Z,so i have very little context in this kip. is there any sort of expected size for the inner iterator? you may get stuck in the constructor's call to findnext() for a long time. it might be less surprising to postpone calling findnext() in hasnext() and next().,-1,0.7804999351501465
39916442,130,rhauch,2015-09-19T05:09:32Z,"sounds good. the proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. thanks!",1,0.9955227375030518
40004856,130,guozhangwang,2015-09-21T18:12:02Z,"the iterator will be constructed at around the same time when it is used to get next() (usually in process() call), so i feel postponing findnext() would not change much. but if we encountered some cases that this did become an surprise for users we can change it then.",0,0.9605740904808044
40112156,130,onurkaraman,2015-09-22T16:58:21Z,"minor, but this can alternately be called filternot just like in scala's collections.",0,0.9893798232078552
40122437,130,ijuma,2015-09-22T18:14:01Z,we should use `$junit` here.,0,0.9943104982376099
40123138,130,ijuma,2015-09-22T18:19:27Z,there are no plans to incorporate guava by the way.,0,0.9634220004081726
40124198,130,ijuma,2015-09-22T18:26:12Z,"we may not care in this case, but nio.2 in java 7 provides a mechanism to do this in a more efficient way: [a link]",0,0.9890388250350952
40125291,130,ijuma,2015-09-22T18:33:44Z,"what is the reasoning for having different prefixes in `kafkastreaming`, `streamingconfig` and `kstream`?",0,0.9925222992897034
40126053,130,ijuma,2015-09-22T18:39:10Z,"also, is it actually useful enough? particularly if there is a `negate` method on `predicate`. in scala, one benefit of `filternot` is when using the underscore notation to make lambdas more concise. in java, that seems less useful.",0,0.9930068254470825
40126098,130,ijuma,2015-09-22T18:39:28Z,`valuesa` -> `values`,0,0.9933057427406311
40127893,130,ijuma,2015-09-22T18:51:40Z,is this actually needed?,0,0.9833340048789978
40128094,130,ijuma,2015-09-22T18:53:14Z,"some of this are private while others are public, is there a reason for that?",0,0.9869057536125183
40128168,130,ijuma,2015-09-22T18:53:46Z,is there a reason why these are not final?,0,0.9820315837860107
40128440,130,ijuma,2015-09-22T18:55:36Z,we should probably have a method that takes the name as a parameter and returns the new name using `index`. less error-prone and easier to change in the future.,0,0.9907728433609009
40128852,130,ijuma,2015-09-22T18:58:43Z,the suggestion to have a method that does this concat becomes even more appealing when seen in the light of subclasses like this one.,0,0.9472541213035583
40128890,130,ijuma,2015-09-22T18:59:07Z,"also, have we considered using an enum instead of strings?",0,0.9938526153564453
40128968,130,rhauch,2015-09-22T18:59:38Z,"currently, since kafka can't use java 8 functions nor static methods on interfaces, there is a `predicate` interface in this package that is semantically equivalent to `java.util.function.bipredicate`. unfortunately, without static methods, it's difficult to create a `not( predicate...)` method. so using `filterout` seems to be the easiest approach.",0,0.9937711358070374
40129636,130,rhauch,2015-09-22T19:04:42Z,"if the `apply` method were changed to `test`, then when kafka moves to java 8 this interface could extend `java.util.function.bipredicate `. that wouldn't really benefit anyone that simply supplied their own lambdas, but it might make it a bit easier or more obvious that existing `bipredicate` implementations could be passed in. regardless, aligning with java 8 might be a good thing in and of itself.",0,0.9842740893363953
40129686,130,ijuma,2015-09-22T19:05:10Z,"i was thinking of adding a default method to `predicate` itself, but i now realise that we can't do that in java 7 without changing it to an abstract class. fair enough.",0,0.8317539691925049
40149196,130,guozhangwang,2015-09-22T21:50:45Z,ack.,0,0.5038502812385559
40149364,130,guozhangwang,2015-09-22T21:52:36Z,"kafkastreaming / streamingconfig is aligned with kafkaproducer (kafkaconsumer) / producerconfig (consumerconfig), and kstream is just a name of the higher-level dsl api.",0,0.9952313303947449
40149430,130,guozhangwang,2015-09-22T21:53:07Z,ack.,0,0.5038502812385559
40149490,130,guozhangwang,2015-09-22T21:53:49Z,ack.,0,0.5038502812385559
40149757,130,guozhangwang,2015-09-22T21:56:22Z,ack.,0,0.5038502812385559
40149780,130,guozhangwang,2015-09-22T21:56:35Z,"some of them are used outside kstream, for example source is used in kstreambuilder, and join is in kstreamwindowed, etc.",0,0.9937613606452942
40150351,130,guozhangwang,2015-09-22T22:02:45Z,"not sure i got the motivation: when we moved to java 8 and removed this interface with bipredicate directly, even with test() existing users still need to make code change, right?",0,0.868188202381134
40167379,130,rhauch,2015-09-23T02:55:58Z,"renaming `apply` to `test` now gives us a slow, non-breaking migration path so that when moving to java 8 we could: - change `predicate ` to extend `java.util.function.bipredicate ` and remove the `apply` method from `predicate ` since it would unnecessarily override `bipredicate.test(...)`; - change `kstream` methods to use `bipredicate ` instead of this `predicate `; - deprecate `predicate ` and tell people to use `bipredicate` instead. no users would have to change their code, although anyone using `predicate ` directly would get deprecation warnings and could but would not be required to change. in a later release, we can remove `predicate `, and anyone _still_ using it would then have to change their code. otoh, if we keep `apply` as it is now, then when we moved to java 8 and change to `java.util.function.bipredicate `, all users directly using the interface would _have_ to change. of course, neither of these options affects those users who are already on java 8 and using lambdas rather than `predicate ` implementation classes.",0,0.9896923899650574
40215978,130,rhauch,2015-09-23T15:17:20Z,", why is the `rocksdbkeyvaluestore` not parameterized like `inmemorykeyvaluestore`? i have a version of this that is parameterized (yes, it does require passing in key and value serializers and deserializers), and it makes using it very similar to `inmemorykeyvaluestore`. any interest in it?",0,0.9930045008659363
40237923,130,guozhangwang,2015-09-23T18:17:30Z,"agree, do you want to create a new pr?",0,0.9912551641464233
40239203,130,rhauch,2015-09-23T18:27:47Z,", yes i will create a new pr shortly.",0,0.9776186943054199
40239945,130,ymatsuda,2015-09-23T18:32:40Z,"i am not sure if we want to migrate to `java.util.function.bifunction` at this point. but, by this change, we can maintain the source level compatibility of user code if we want to migrate. a good idea. what happens to the binary level compatibility? does a user using predicate have to recompile?",1,0.7670472264289856
40240252,130,guozhangwang,2015-09-23T18:35:25Z,i think recompilation are not avoidable anyways..,0,0.6570829749107361
40240731,130,rhauch,2015-09-23T18:39:28Z,"inserting new class or interface types in the type hierarchy is listed as a [a link] and [a link]. so if we rename the method now, then if/when `predicate ` is changed to extend `java.util.function.bipredicate ` and released clients using `predicate ` should not have to recompile.",0,0.9943923354148865
40243229,130,guozhangwang,2015-09-23T19:00:05Z,correct: [a link],0,0.9816431403160095
131572299,3621,becketqin,2017-08-07T04:52:30Z,"not sure if we want to have this interface added while we have not supported the intra broker replica move yet. also, we probably don't want to expose the implementation detail to the users about how the replicas are moved . so it would be better to not ask users to manually specify the replica dir before they do the partition reassignment. so the end state of adminclient after kip-179 and kip-113 would be having two methods for partition movement: 1. a method for partition reassignment in general, include both inter and intra broker reassignment. (e.g. `altertopics()`) 2. a method to only move replicas within a broker. (e.g. `alterreplicadir`) btw, i still feel that having (1) is sufficient. it would be useful to explore possibility of only having (1) so users don't need to deal with two different interfaces for replica movement. with that, regarding this patch, i was thinking doing the following: 1. let `reassignpartitioncommand` take new input format which includes the log dir. 2. do a sanity check in the `reassignparititioncommand` to ensure no intra broker replica movement is specified. otherwise throw `unsupportedoperationexception`. 3. in `reassignpartitioncommand`, it should just send `changereplicadirrequest` to the related brokers before the partition movement. 4. do not add `alterreplicadir()` to the adminclient until the broker supports that. would the above way be sufficient for what we want to achieve for this patch?",0,0.9868707656860352
131573994,3621,lindong28,2017-08-07T05:17:37Z,"thanks for your comment! here is what i think: - i think the interface is useful. the alterreplicadirrequest (renamed from changereplicadirrequest per ismael's comment) is used to 1) create replica in the specified log directory later and 2) move replica to the specified log directory if it has already been created yet. this patch supports the first part and thus the new api `alterreplicadir` in adminclient is useful and well-defined. if we don't add this method and its implementation in adminclient, we would have to implement it in `reassingpartitioncommand` and move the implementation to adminclient later, which seems like unnecessary work. - can you clarify a bit what implementation detail is exposed to user in this patch? - i have thought about the possibility of using only one method in adminclient to do both partition reassignment and replica -> log directory reassignment. my conclusion is that it is still better to put them into two separate methods. for example, if we do both using one method, the method would probably look like `reassignpartition(map > newpartitionassignment, map newreplicadirassignment)`. this method merges two inherently different parameters and functionality into one method, which seems less clean than using two methods. do you any suggestion on how that one method would look like if we were to use only one method for this? - i agree with the tasks 1-3. i still think it is better to put `alterreplicadir` in admclient as long as we documents it properly. but it also works for me to move this code to `reassignpartitioncommand`.",1,0.9867697954177856
131574245,3621,lindong28,2017-08-07T05:21:42Z,and good point about checking that no intra broker replica movement is specified. i will add this logic in `reassignpartitioncommand`,1,0.704566478729248
131777843,3621,lindong28,2017-08-07T22:18:18Z,discussed with offline. i will not add `alterreplicadir()` api in adminclient in this patch. i will add `alterreplicadir()` as a public method in kafkaadminclient so that this method can be used by reassignpartitionscommand in this patch.,0,0.9937100410461426
132356130,3621,becketqin,2017-08-10T03:18:39Z,we have agreed the next major version would be 1.0.0.,0,0.9898125529289246
132356186,3621,becketqin,2017-08-10T03:19:25Z,should this be `describelogdirs`? also why this method is abstract?,0,0.9925454258918762
132356414,3621,becketqin,2017-08-10T03:22:35Z,"not sure if it is worth having this query granularity. it seems that when we query a broker, the cost to query all log directories and query some particular log directories are pretty much the same. and i think typically users would have to query all log dirs in order to get the dir names first. if so, would it be simpler to just use `collection ` instead?",0,0.9799331426620483
132359600,3621,becketqin,2017-08-10T04:03:56Z,it seems a little verbose to have all these options with a timeout. it seems cleaner to merge them to a `timeoutoption` and extends from that.,-1,0.5208517909049988
132359818,3621,becketqin,2017-08-10T04:06:38Z,this method does not exist.,0,0.9673177003860474
132359891,3621,becketqin,2017-08-10T04:07:13Z,this method does not exist.,0,0.9673177003860474
132832597,3621,becketqin,2017-08-13T05:19:26Z,this comment seems a little too verbose. do we need to mention this or the api of `alterreplicadirresult` is already clear enough?,0,0.7122512459754944
132832605,3621,becketqin,2017-08-13T05:19:52Z,1.0.0,0,0.9750232696533203
132832726,3621,becketqin,2017-08-13T05:32:05Z,"hmm, in which case would the future be null?",0,0.9869323372840881
132832899,3621,becketqin,2017-08-13T05:50:43Z,logdirnotavailableexception?,0,0.9797077178955078
132833418,3621,lindong28,2017-08-13T06:36:04Z,good point. i have changed it to take `collection `.,1,0.9629737734794617
132833428,3621,lindong28,2017-08-13T06:36:38Z,thanks. i have changed it to 1.0.0.,1,0.9434948563575745
132833468,3621,lindong28,2017-08-13T06:40:22Z,"i think `logdir` may be a bit more verbose than dir. it seems ok to be use `dir` instead of `logdir` as long as logdir will be the only ""dir"". if it is necessary to use `dir` instead of `logdir`, do you think we should rename `describedirsrequest` to `describelogdirsrequest`?",0,0.9940755367279053
132833487,3621,lindong28,2017-08-13T06:41:42Z,"besides, this is an abstract method because its implementation is in adminclient. this follows the same pattern as existing apis in `adminclient`.",0,0.9945549964904785
132833512,3621,lindong28,2017-08-13T06:42:55Z,"thanks. i replaced it with `{ kafkaadminclient#alterreplicadir(map, alterreplicadiroptions)}`",1,0.8932793140411377
132833528,3621,lindong28,2017-08-13T06:44:07Z,"thanks. i replaced it with `{ kafkaadminclient#alterreplicadir(map, alterreplicadiroptions)}`",1,0.8932793140411377
132833575,3621,lindong28,2017-08-13T06:48:34Z,sure. i removed the sentence `updates are not transactional...` from this comment. does this address the problem?,0,0.9908628463745117
132833579,3621,lindong28,2017-08-13T06:48:52Z,sure. fixed now.,0,0.9868775010108948
132833626,3621,lindong28,2017-08-13T06:51:20Z,"this follows the same pattern of the implementation of other existing apis in kafkaadminclient. i don't think future will be null unless there is bug. i think it is ok for the kafkaadminclient to have extra check to protect itself form server side's bug. but if you don't like it, i can also remove it and in the worse case we just see npe if future is null.",0,0.9436032176017761
132833666,3621,lindong28,2017-08-13T06:54:21Z,sure. renamed to `logdirnotavailableexception`.,0,0.9893325567245483
132833688,3621,lindong28,2017-08-13T06:55:55Z,"and if we were to rename it to `describelogdirs`, should we also rename `describereplicadir` to `describereplicalogdirs`?",0,0.9952557682991028
132833755,3621,lindong28,2017-08-13T07:00:42Z,"how about this: i added an abstract class named `configoptions`. this class will have a timems variable and `integer timeoutms()` api. this abstract class can be used to hold all future apis that are shared among all (or most) ""*configoptions"" classes. on the other hand i also think it is ok to keep it as is given that there are is only one common api (i.e. timems()) shared among those classes.",0,0.981882631778717
132857316,3621,becketqin,2017-08-13T23:56:05Z,"if we do not expect this to happen. shouldn't we throwi illegalstateexception? in this case, if the broker returned a replica that is not in the request, the broker may have somehow misplaced a replica. we should probably alert in this case.",0,0.9740260243415833
132868453,3621,becketqin,2017-08-14T03:29:15Z,"personally i prefer avoiding the potential confusion, especially given dir is a pretty commonly used name in many places. i am not sure if in the future we will have some other dirs, but describedir() itself seem lacking some necessary context to me. and yes, i do feel `describelogdirrequest` is a better name. `describereplicadir` sounds ok though, as replicadir must be a log dir.",0,0.945026695728302
132868590,3621,becketqin,2017-08-14T03:31:37Z,i am not sure what is the best solution here either. it just feels a little silly that we have all those classes that are essentially identical except the class name.,-1,0.9884389042854309
132868863,3621,becketqin,2017-08-14T03:36:25Z,should this comment be updated?,0,0.9933410286903381
132868995,3621,becketqin,2017-08-14T03:38:36Z,ditto above.,0,0.9803552627563477
132869443,3621,becketqin,2017-08-14T03:47:23Z,"technically speaking we are query the log directory in which the replica locates. i.e. the root_log_dir, not root_log_dir/replica_dir. speaking of this, it might still be better to change the method name to `describereplicalogdir`.",0,0.9939191341400146
132871530,3621,becketqin,2017-08-14T04:24:17Z,is the left parenthesis missing?,0,0.989314079284668
132872895,3621,becketqin,2017-08-14T04:42:22Z,the default lag should probably be something like -1 and preferably a macro. it is also a little weird to allow those non-final fields to be tweaked. see the other comment in `kafkaadminclient`,-1,0.943244457244873
132873131,3621,becketqin,2017-08-14T04:44:52Z,would it be better to construct the result after the response is returned instead of create the result beforehand and modify it later?,0,0.9894591569900513
132873593,3621,becketqin,2017-08-14T04:53:18Z,"given this change, is the log dir field still needed in the `describedirrequest`? it seems that we can just leave the replica list there and remove the log dir list?",0,0.995604395866394
132874067,3621,becketqin,2017-08-14T04:59:49Z,"not found and not available seems slightly different. it would be useful to distinguish between ""exist but not available"" vs ""does not exist"".",0,0.980595588684082
132874436,3621,becketqin,2017-08-14T05:06:23Z,"by ""remaining"" do you mean ""available""?",0,0.9913129210472107
132874540,3621,becketqin,2017-08-14T05:08:34Z,"see the other comment, maybe we don't need the log dir list anymore.",0,0.9851152300834656
132876992,3621,becketqin,2017-08-14T05:44:15Z,"hmm, why are we do the validation after executing the reassignment?",0,0.950373113155365
132878069,3621,becketqin,2017-08-14T05:59:02Z,"the comment is a little confusing. maybe change to ""remove the preferred log dir since it has already been satisfied."". btw, should we remove it after the log has actually been created? otherwise if storage exception happens during the log creation we may lose the preferred log dir information.",0,0.7301512956619263
132878098,3621,becketqin,2017-08-14T05:59:27Z,can you explain the reason of these changes?,0,0.9823580384254456
132879332,3621,becketqin,2017-08-14T06:13:27Z,"i know this is in the kip, but it still seems a little weird to throw exception in this case as the request is kink of legitimate. not sure if there is a better way though.",-1,0.9710389971733093
132880098,3621,becketqin,2017-08-14T06:22:33Z,"why should this be -1 instead of 0? this is essentially caught up, right?",0,0.9776961803436279
133014020,3621,lindong28,2017-08-14T17:43:13Z,sure. good point. i have updated the patch with the following changes: - renamed describedirsrequest to describelogdirsrequest (same for response) - renamed adminclient api to describelogdirs - renamed adminclient api to describereplicalogdirs,1,0.5287423133850098
133014235,3621,lindong28,2017-08-14T17:44:04Z,i have added the class `abstractoptions` that provides apis to set and get timeoutms.,0,0.9933499693870544
133014767,3621,lindong28,2017-08-14T17:46:14Z,good point. i have updated the patch to throw illegalargumentexception if the future is not found.,1,0.7040179371833801
133015323,3621,lindong28,2017-08-14T17:48:30Z,sure. i replaced this comment with `query the information of all log directories on the given set of brokers`.,0,0.9929439425468445
133015335,3621,lindong28,2017-08-14T17:48:33Z,sure. i replaced this comment with `query the information of all log directories on the given set of brokers`.,0,0.9929439425468445
133015631,3621,lindong28,2017-08-14T17:49:36Z,good point. i have updated the protocol to remove `log_dirs` field from `describelogdirsrequest`.,1,0.7141196727752686
133015745,3621,lindong28,2017-08-14T17:50:00Z,sure. i have renamed `describereplicadir` to `describereplicalogdir`.,0,0.9932490587234497
133021670,3621,lindong28,2017-08-14T18:13:58Z,good point. i replaced `-1` with `describelogdirsresponse.invalid_offset_lag`.,0,0.697624683380127
133021896,3621,lindong28,2017-08-14T18:14:54Z,left parenthesis actually exists.,0,0.9828091263771057
133022382,3621,lindong28,2017-08-14T18:16:48Z,yeah. i have removed this field from describelogdirsrequest.,0,0.9886515140533447
133023112,3621,lindong28,2017-08-14T18:19:57Z,good point. i have renamed this exception to `logdirnotfoundexception`. i think we can assume `not found` indicates `does not exist` given that we already have `notfoundexception`.,1,0.585257351398468
133023274,3621,lindong28,2017-08-14T18:20:43Z,i removed the `remaining` from this comment since it appears unnecessary.,0,0.9892687201499939
133026257,3621,lindong28,2017-08-14T18:32:37Z,this is just an extra verification to confirm that we are only sending alterreplicadirrequest for replicas that have not been created yet.,0,0.9914594888687134
133026969,3621,lindong28,2017-08-14T18:35:29Z,good point. i have updated the comment as suggested. and it is only removed after the log has been successfully created.,1,0.9438765048980713
133027534,3621,lindong28,2017-08-14T18:37:25Z,this is because we receive logdir as a strong from alterreplicadirrequest and it is inserted into `preferredlogdirs` as a strong. when we get it from `preferredlogdirs` it will be a strong not a file. it is a minor change. alternatively i can insert preferred log directory into that map as a file. i just feel the current approach is simpler.,0,0.8807259202003479
133028201,3621,lindong28,2017-08-14T18:40:00Z,"imo it is reasonable to throw exception here. this is because it is not guaranteed that the replica will be moved to the destination log directory if the replica is not already on the broker. for example, if the broker restarts after it receives alterreplicadirrequest but before it receives the upcoming leaderandisrrequest, it will forget the cache in the memory.",0,0.990364134311676
133028267,3621,lindong28,2017-08-14T18:40:15Z,discussed offline. i have updated the patch to remove this logic.,0,0.9732751846313477
133028981,3621,lindong28,2017-08-14T18:42:54Z,"are you talking about the `futures` map or the `replicadirinfobypartition`? the former needs to be constructed in advance as does the implementation of other apis in adminclient. the latter needs to be constructed in advance because its result maybe a combination of two entries in the response, i.e. primary and temporary replica of the same partition.",0,0.9949190020561218
134098378,3621,becketqin,2017-08-19T18:52:50Z,can we add a java doc for this class?,0,0.9921271800994873
134098547,3621,becketqin,2017-08-19T19:01:19Z,version should be 1.0.0.,0,0.9928486347198486
134098552,3621,becketqin,2017-08-19T19:01:27Z,ditto.,0,0.6705162525177002
134098889,3621,becketqin,2017-08-19T19:19:36Z,should we change this name to alterreplicalogdiroptions as well?,0,0.9945849776268005
134100952,3621,becketqin,2017-08-19T21:13:57Z,do we need to have the `replicalogdirinfo` printed? it seems the output format would be pretty verbose.,0,0.758476197719574
134101186,3621,becketqin,2017-08-19T21:28:44Z,we are still not throw exception here? am i missing something?,0,0.8311182856559753
134101387,3621,becketqin,2017-08-19T21:43:08Z,this assumes the only possibility of error is partition does not exist. is this always true?,0,0.9876921772956848
134101520,3621,becketqin,2017-08-19T21:51:45Z,the class also includes the broker id.,0,0.9923475980758667
134101861,3621,becketqin,2017-08-19T22:14:29Z,alterreplicalogdirrequest?,0,0.9924222826957703
134101922,3621,becketqin,2017-08-19T22:18:15Z,alterreplicalogdirresponse?,0,0.9922356009483337
134101991,3621,becketqin,2017-08-19T22:21:31Z,nit: dir -> dir,0,0.8802464008331299
134102436,3621,becketqin,2017-08-19T22:51:34Z,i see. we probably need more comments to explain this. from the code itself it is weird that we always expect an exception from a future.,-1,0.9636255502700806
134102479,3621,becketqin,2017-08-19T22:54:52Z,we may also need to update the command help message.,0,0.9871293902397156
134102637,3621,becketqin,2017-08-19T23:08:57Z,"do we also want to look into the `preferredlogdirs`? in another word, do we want to have the preferred dir shown as temporary dir in the describelogdirresponse even if the replica has not been created yet?",0,0.9952378273010254
134102674,3621,becketqin,2017-08-19T23:13:23Z,should we also assert the log dir is non-null?,0,0.9939059615135193
134102720,3621,becketqin,2017-08-19T23:17:23Z,can we define a val for the number of log dirs?,0,0.9937536120414734
134102789,3621,becketqin,2017-08-19T23:21:43Z,"this test seems a little overlapping with the test in `adminclientintegrationtest.testalterreplicalogdirbeforetopiccreation`, do we need both?",0,0.9935460686683655
134103147,3621,lindong28,2017-08-19T23:50:04Z,sure. i added this comment `this class implements the common apis that are shared by options classes for various adminclient commands`.,0,0.9902100563049316
134103158,3621,lindong28,2017-08-19T23:50:34Z,"sorry, my bad. it is fixed now.",-1,0.9938384890556335
134103164,3621,lindong28,2017-08-19T23:50:58Z,fixed now.,0,0.9818974137306213
134103288,3621,lindong28,2017-08-20T00:00:20Z,"if we were to change it, we probably want to rename `alterreplicadirrequest` to `alterreplicalogdirreqeust`. but this seems a bit verbose to me. i think `alterreplicadirrequest` is probably ok and should not cause any confusion going forward. do you think this may cause confusion if we don't name it `alterreplicalogdirreqeust`?",0,0.9298577904701233
134103332,3621,lindong28,2017-08-20T00:04:53Z,"the current patch doesn't not print `replicalogdirinfo` anywhere to user except possibly in debug log. as far as the implementation of the `replicalogdirinfo` is concerned, i think it makes sense to print all its fields as does in the current patch. do you see any log statement that prints the `replicalogdirinfo` in an unnecessary manner?",0,0.9904137253761292
134103367,3621,lindong28,2017-08-20T00:07:38Z,oops.. i must have made some mistake such that the change is lost.. i have fixed it now.,-1,0.9304353594779968
134103401,3621,lindong28,2017-08-20T00:10:36Z,"i added this `throw new illegalargumentexception(""the partition "" + tp + "" in the response from broker "" + brokerid + "" is not in the request"");`",0,0.9920370578765869
134103422,3621,lindong28,2017-08-20T00:12:57Z,"this assumes that if `logdirinfo.error != errors.none`, then the log directory must be offline on this broker and the `replicainfos` in this `logdirinfo` will be empty. this is a valid assumption as of the current design.",0,0.9948076605796814
134103428,3621,lindong28,2017-08-20T00:13:52Z,"thanks a lot for the detailed review! i have changed it to `the topic name, partition number and the brokerid of the replica`.",1,0.984032928943634
134103435,3621,lindong28,2017-08-20T00:14:46Z,thanks! fixed now.,1,0.9865524172782898
134103699,3621,lindong28,2017-08-20T00:38:03Z,"i don't think we should do that. including this information in `describelogdirrequest` will complicates the design of related apis and expose an internal optimization detail to user. on the other hand, i don't think it provides any benefit to the user. the purpose of describelogdirrequest is to get the load distribution of log directories on the broker so that user can determine a good reassignment replicas across log directories. is there any information in `preferredlogdirs` that can help with this purpose of the `describelogdirrequest`?",0,0.9778302311897278
134103805,3621,lindong28,2017-08-20T00:50:43Z,sure. i added the following check: [code block],0,0.9878546595573425
134103834,3621,lindong28,2017-08-20T00:55:17Z,not sure if i fully understand your question. do you mean something like `protected def logdircount: int = 1` which is added by this patch in `baserequesttest.scala`? i think we only need to add this when we need to vary the logdircount based on the test. it seems ok and simpler to just set logdircount to 2 for all tests in `adminclientintegrationtest`.,0,0.990246057510376
134103883,3621,lindong28,2017-08-20T01:01:18Z,"i think it is ok to have both. if `alterreplicadirrequesttest.testalterreplicadirrequestbeforetopiccreation` passes but `adminclientintegrationtest.testalterreplicalogdirbeforetopiccreation` fails, it suggests that something is wrong in the kafkaadminclient. this seems to follow the existing pattern -- tests such as `deletetopicsrequesttest` and `createtopicsrequesttest` probably would not be needed for the same reason given that we already have tests for higher level apis that use them (if not then we should add the test for higher level apis that uses them). but i am not strong on this. i will remove this test if you think it is not necessary.",0,0.9933522939682007
134104058,3621,lindong28,2017-08-20T01:19:24Z,good point. i added the following comments in the code: [code block] and i updated the help message for option `--reassignment-json-file` to the following: [code block],1,0.897346019744873
134106014,3621,becketqin,2017-08-20T04:27:38Z,"i think we usually do not print the field name of a map value, we usually not not print the name field of the value. otherwise shouldn't we print the field name of the key as well? so for maps, it would simply be [key, value]. in this case, each entry could be printed as something like [topic-0-1, (currentlogdir=xxx, temporarylogdir=yyy, temporaryreplicaoffsetlag=zzz)], which is probably clear enough. btw, i forgot to comment that i think we should add documentation about what are the value combination of those fields mean. for example is it possible i get a currentlogdir=null, templogdir=xxx, offsetslage=-1? if so what does that mean.",0,0.9786034226417542
134124244,3621,lindong28,2017-08-20T19:32:23Z,"i see. i didn't understand the question previously. i wasn't aware that the conversion is to not print the name fild of the value. sure. i just changed both the `replicalogdirinfo.tostring()` and `replicainfo.tostring()` so that they don't print the class name in the string. btw, i assume that this conversion only applies to internal classes, which i think is reasonable. for public classes such as `alterreplicadirrequest`, the patch will still print the class name in the `tostring()` method as we do in e.g. `deletetopicsrequest`. i also added comment to fields in the `replicalogdirinfo` as show below. i think each fields can be interpreted independently and there is no need to explain how to interpret various combinations. for the example you mentioned, if currentlogdir=null, templogdir=xxx, offsetslage=-1, it means the primary replica is not found and there is only a temporary replica for this partition on the given broker, which is possible if the primary replica is in an offline log directory. [code block]",0,0.8868976831436157
134592277,3621,junrao,2017-08-22T20:26:50Z,unused import replicainfo. should we add the package name in front of describelogdirsresponse?,0,0.9920003414154053
134594816,3621,junrao,2017-08-22T20:36:53Z,would it be better to change the schema to have log_dir at the top level. sth like log_dirs => [log_dir [partitions]] partitions => [topic [int32]] this representation is more concise and is more consistent with how describe_log_dirs_response_v0 is structured.,0,0.9926798343658447
134616464,3621,junrao,2017-08-22T22:21:47Z,"in handletopicmetadatarequest(), if topics() is null, we treat it as for all topics. if topics() is empty, we just treat it as no topics. it would be useful to use the same approach here for consistency.",0,0.9944484233856201
134632381,3621,junrao,2017-08-23T00:23:26Z,"hmm, if we are representing the dir for the permanent and the temporary replica together here, shouldn't we further keep the lag for both permanent and the temporary replicas? also, it's not clear to me why we don't return the same info in describelogdirsresult.",0,0.847348153591156
134632961,3621,junrao,2017-08-23T00:28:39Z,"it's probably better to include alterreplicadir() here too. if we think the api may change, we can mark it as unstable.",0,0.9910852313041687
134633840,3621,junrao,2017-08-23T00:37:27Z,this seems no longer used?,0,0.975680947303772
134638546,3621,junrao,2017-08-23T01:21:01Z,"""on the broker ${replica.brokerid()}"" => ""on broker ${replica.brokerid()}""",0,0.9931417107582092
134639735,3621,junrao,2017-08-23T01:34:04Z,"with this, it's possible for a created log not to be in logs. then, we won't find this log in logmanager.getlog(). when serving requests like offsetbytimestamp, we will probably return unknowntopicpartitionexception, but ideally we want to return kafkastorageexception.",0,0.9904547333717346
134661753,3621,lindong28,2017-08-23T05:46:53Z,my bad. it is removed now. i will go over the patch again to look for unused import.,-1,0.9889791011810303
134662104,3621,lindong28,2017-08-23T05:50:00Z,sure. the original schema is motivated by the idea that alterreplicadir operation naturally maps a replica to a log directory. i am not very sure alterreplicadirrequest needs to be consistent with describelogdirrequest. but i think what you suggested will make the request more compact and smaller in size. i have made the change as suggested. thanks!,1,0.9915384650230408
134663181,3621,lindong28,2017-08-23T05:59:49Z,"the class `replicalogdirinfo` doesn't include that currentreplicalag because this information is not currently used in this patch. previously i think we can include `currentreplicalag` in this when it is needed, i.e. to track reassignment progress in kip-179. i have updated the patch to include `currentreplicalag` in `replicalogdirinfo`. i am not sure i fully understand the second question. what information should we add or remove from `describelogdirsresult`? i think `describelogdirsresult` and `describereplicalogdirresult` has different format because they are used to serve two different use-cases. these two classes are structured in a way that makes the respective adminclient apis easier to use.",0,0.9883400201797485
134663259,3621,lindong28,2017-08-23T06:00:48Z,sure. i have added it back to adminclient.,0,0.9866634607315063
134663285,3621,lindong28,2017-08-23T06:01:03Z,ah.. my bad. it is removed now.,-1,0.9893534183502197
134663350,3621,lindong28,2017-08-23T06:01:36Z,i have fixed this as suggested in multiple places in this method.,0,0.9842289686203003
134663939,3621,lindong28,2017-08-23T06:06:44Z,"after double checking the logic, i think we will actually return `kafkastorageexception` for `offsetbytimestamp` query if log creation failed. this logic is enforced in kip-112. more specifically, after broker receives leaderandisrrequest to create the log, if `logmanager.getorcreatelog()` throws `kafkastorageexception`, `partition.getorcreatereplica()` will also throw exception without putting this replica in the `partition.assignedreplicamap`. later we will execute the following code in `replicamanager.becomeleaderorfollower()`: [code block] this logic makes sure that this partition will map to `replicamanager.offlinepartition` when this broker receives any request from user, including requests for offsetbytimestamp. the response will return `kafkastorageexception` to the user.",0,0.994134247303009
134683583,3621,lindong28,2017-08-23T08:09:29Z,sure. i have updated the patch as suggested.,0,0.9911383986473083
134794883,3621,cmccabe,2017-08-23T15:57:43Z,"we should use an accessor function for the following fields-- for all the usual reasons we do this in java. (unlike in scala, you cannot write an accessor later to transparently switch over users.)",0,0.993308424949646
134795363,3621,cmccabe,2017-08-23T15:59:15Z,"is right-- you should handle this case. perhaps the server sent back bad data. the way to handle it is not to throw an exception, but to complete the relevant future(s) with an error. there are a few other cases where we handle bad server data by completing a future with failure in adminclient.",0,0.989173412322998
134795858,3621,cmccabe,2017-08-23T16:01:02Z,i don't think we should map zero responses to cluster_authorization_failed. what if we need to return different error codes later? we should have an error code per log dir response.,0,0.9570211172103882
134807975,3621,lindong28,2017-08-23T16:50:37Z,"currently the only request level error for describelogdirresponse is if the cluster_authorization_failed. this error will happen if and only if the error there is no log directories in the response. this is because if a broker is online and the user is authorized to describe cluster resource, then it is guaranteed that describelogdirresponse should return some log directories. also note that describelogdirresponse does include per-logdir error in the response. thus we don't need request level error for describelogdirresponse at this moment. is there any scenario that will request this error field in the future? if we don't have specific use-case for this field, can we add it only when we need it in the future?",0,0.9935727119445801
134809797,3621,lindong28,2017-08-23T16:58:18Z,good point. i have updated the code to complete all futures with illegalargumentexception when this happens.,1,0.7721325159072876
134815324,3621,lindong28,2017-08-23T17:21:46Z,i noticed that classes such as `updatemetadatarequest.partitionstate` makes its fields public instead of using accessor fields. are accessor fields needed by replicalogdirinfo because it is exposed to user via `adminclient.describereplicalogdir()`?,0,0.9955615997314453
135162431,3621,junrao,2017-08-25T00:33:41Z,should we guard the case that the same partition or the same log dir is specified more than once and error out?,0,0.9856613874435425
135165084,3621,junrao,2017-08-25T01:01:20Z,getpermanentreplicalogdir seems to match gettemporaryreplicalogdir better. ditto on getcurrentreplicaoffsetlag.,0,0.9912248253822327
135166115,3621,junrao,2017-08-25T01:12:42Z,"instead of using (_._2), could we use case to define named variables to make it clear? ditto on line 233.",0,0.9952593445777893
135167112,3621,junrao,2017-08-25T01:22:57Z,"hmm, intuitively, if a replica doesn't exist, setting a log dir for it should succeed, instead of getting an error. perhaps we should return success if the replica doesn't exist or is in the right dir, and throw an unsupported exception for now otherwise.",0,0.9447417855262756
135167447,3621,junrao,2017-08-25T01:26:43Z,do you mean broker 101?,0,0.9876997470855713
135167654,3621,junrao,2017-08-25T01:29:04Z,do you mean broker 102?,0,0.9894497990608215
135168551,3621,junrao,2017-08-25T01:38:48Z,is the comment accurate? it seems the test has invalid log dir.,0,0.938507080078125
135168609,3621,junrao,2017-08-25T01:39:23Z,is the comment accurate?,0,0.9855098724365234
135168812,3621,junrao,2017-08-25T01:41:35Z,"could we add a test case that the length of ""log_dirs"" doesn't match that in ""replicas""?",0,0.9947413206100464
135168953,3621,junrao,2017-08-25T01:42:54Z,unused import,0,0.9524969458580017
135169300,3621,junrao,2017-08-25T01:46:53Z,"hmm, the event will be processed asynchronously after this call returns. should we guarantee that this event is processed before sending describe_log_dirs request?",0,0.9907179474830627
135182887,3621,lindong28,2017-08-25T04:45:59Z,"i think we don't need to add this logic in `alterreplicadirrequest` because the current implementation will always provide unique partition and log when instantiating `alterreplicadirrequest`. `alterreplicadirrequest` will only be instantiated in `adminclient.alterreplicadir()`. because `adminclient.alterreplicadir()` takes `map replicaassignment` as input, it guarantees that the partition in the `alterreplicadirrequest` will be specified only once. also, `alterreplicadirrequest.tostruct()` will group `topicpartitionreplica` by logdir and thus the logdir in the `alterreplicadirrequest` will be specified only once.",0,0.9910339713096619
135183018,3621,lindong28,2017-08-25T04:48:13Z,i am bit concerned that `getpermanentreplicalogdir` may mislead user into thinking log directory of this partition will never change. how about we rename `gettemporaryreplicalogdir` to `getfuturereplicalogdir`?,0,0.721551239490509
135183254,3621,lindong28,2017-08-25T04:51:51Z,sure. i replaced them with the following: [code block],0,0.9893808364868164
135184008,3621,lindong28,2017-08-25T05:03:03Z,"i think it depends on the semantics of alterreplicadirrequest. in my understanding ""alter"" means ""change the proper of something that already exists"". thus broker should not create replica for this partition if this replica does not already exist. and it is reasonable to throw exception to user because user requested to alter log directory of a replica that doesn't exist. does this make sense?",0,0.9876325130462646
135184035,3621,lindong28,2017-08-25T05:03:35Z,my bad. fixed now. thanks.,-1,0.9397218823432922
135184065,3621,lindong28,2017-08-25T05:04:11Z,ah.. fixed now. thanks!,1,0.994716227054596
135184249,3621,lindong28,2017-08-25T05:07:10Z,my bad.. i replaced the comment with `when we execute an assignment that specifies an invalid log directory`.,-1,0.9871366024017334
135184640,3621,lindong28,2017-08-25T05:13:13Z,no... i have replaced the comment with the following: [code block],0,0.9834905862808228
135184811,3621,lindong28,2017-08-25T05:16:04Z,good point. i have changed the code to do `servers.head.replicamanager.handlelogdirfailure(offlinedir)`.,1,0.6697262525558472
135193414,3621,lindong28,2017-08-25T06:48:56Z,sure. i have added test `shouldfailifproposedhasinconsistentreplicasandlogdirs` for this.,0,0.9934490323066711
135372907,3621,junrao,2017-08-25T23:51:52Z,"yes, the java client behaves as you described. i was mostly concerned about how the broker handles requests from non-java clients.",0,0.9518217444419861
135372918,3621,junrao,2017-08-25T23:52:05Z,perhaps use getcurrentreplicalogdir and get getnewreplicalogdir?,0,0.992610514163971
135372984,3621,junrao,2017-08-25T23:53:05Z,"hmm, i think alterreplicadirrequest just means the intention to alter the dir. it doesn't mean the change has to be completed. as long as the intention is remembered by the broker, it seems it's reasonable to return success. the weird thing right now is that in reassignpartitionscommand, the happy path is actually based on an exception in the response of alterreplicadirrequest. normally, the happy path should be when the response has no error.",0,0.9454213976860046
135374404,3621,lindong28,2017-08-26T00:14:00Z,"thanks for the comment ! by non-java clients, do you mean the clients written by third-party and not maintained by in apache kafka repository? here is my thought: - if a thirty party client constructs the `alterreplicadirrequest` using the api `alterreplicadirrequest.builder(map partitiondirs)`, we still guarantee that both log directory and the topicpartition in the resulting `alterreplicadirrequest` will be unique. thus server doesn't have to worry about it. - if a third party client constructs `alterreplicadirrequest` without using our builder, and it constructs `alterreplicadirrequest` with duplicated topicpartition by mistake, the server won't be affected by this. this is because the `alterreplicadirrequest(struct struct, short version)` will generate the `map partitiondirs` which contains well-defined and unique partition to logdir mapping. also, since user constructs `alterreplicadirrequest` without using our builder, we won't help user detect this mistake by changing the code here. btw, this issue seems to also exist in `alterconfigsrequest`, which may contain duplicated entries for the same resource type and resource name. it may be reasonable to handle them in the same way as this patch does. does it make sense?",1,0.9550700783729553
135374956,3621,lindong28,2017-08-26T00:23:36Z,"i agree it doesn't have to be completed as long as it is remembered. however, currently this is only remembered in the memory which may be lost if broker restarts after it receives alterreplicadirrequest but before it receives leaderandisrrequest to create the replica. i think we probably don't want to return success to user and create replica is a different log directory later (if restart happens in the above case). has similar comment regarding the weirdness that we expect response to throw exception. but this weirdness exists only because this patch represents the first part of kip-113. after we fully implement the kip-113, we won't expect to see exception in the happy path. the logic in the reassignment will look like this: - call `adminclient.alterreplicadirrequest(replicaassignment)` without waiting for response - create the reassignment znode so that controller can start replica reassignment across brokers. - call `adminclient.alterreplicadirrequest(replicaassignment)` and verify that there is no error in the response. the implementation of `adminclient.alterreplicadirrequest` will treat `replicanotavailableexception` as a retriable error and retry up to the user-specified timeout. i think it is ok for this weirdness to exist for a short period of time before kip-113 is fully implemented. user won't be affected by this weirdness. does this make sense?",0,0.9742385745048523
135375065,3621,lindong28,2017-08-26T00:25:20Z,sure. i will update the patch to use `getnewreplicalogdir` and rename other fields as appropriate.,0,0.9931144118309021
135376799,3621,lindong28,2017-08-26T01:08:36Z,"after discussing with , i think it may be better to use `getfuturereplicalogdir`. if we were to use `getnewreplicalogdir`, do you think we should rename `is_temporary` field in `describe_log_dirs_response_v0` to `is_new`? if so, it kinds of collide with the `is_new` field in `leader_and_isr_request_partition_state_v1`. it seems a bit confusing. also, if we were to use `getfuturelogdir`, are you ok with renaming the field `is_temporary` to `is_future` in `describe_log_dirs_response_v0`?",0,0.9547843933105469
135377833,3621,junrao,2017-08-26T01:36:04Z,"ok, if doesn't do harm on the server, we can punt on this.",0,0.8476361036300659
135377868,3621,junrao,2017-08-26T01:37:01Z,"ok, future is fine then. changing is_temporary to is_future also sounds good.",0,0.7067692279815674
135377870,3621,junrao,2017-08-26T01:37:03Z,"hmm, i thought for verification, we want to use describelogdirs not alterreplicadirrequest? also, for the first adminclient.alterreplicadirrequest(), i am not sure that we want to completely ignore the response. for example, if the request fails with authentication error, we probably want to error out, right? overall, are you saying that alterreplicadirrequest only returns no error if the log dir is in the target log dir? that means most of the time, the request will return error. this seems unintuitive since error should be the exception, not the norm.",0,0.7218567728996277
135378158,3621,lindong28,2017-08-26T01:47:38Z,"yes, we only use `describelogdirs` for verification. in the current patch, `reassignpartitionscommand` only checks for `replicanotavailableexception` using `alterreplicadirrequest` during execution (i.e. when --execute is specified). you are right. i simplified the logic of the first `adminclient.alterreplciadir()` in my previous response. more specifically, after kip-113 is fully implemented, the `reassignpartitionscommand` should use `adminclient.alterreplciadir()` to send `alterreplicadirrequest` without retry. and it should verify that either there is no error or the error is `replicanotavailableexception`. the second `adminclient.alterreplciadir()` should retry `alterreplicadirrequest` upon `replicanotavailableexception` until timeout. `alterreplicadirrequest` can also return no error even if the log directory is not the target log directory, as long as replica already exists on the broker. this is because if the replica already exists on the broker, the broker will create a directory for the temporary replica in the destination log directory. because this information is persisted on the disk rather than in memory, broker will continue to move replica to the destination log directory after restart.",0,0.9680743217468262
136207465,3621,junrao,2017-08-30T22:37:28Z,"the name of the method seems a bit confusing. it's not really clear what withoutdedup really means. could it be just named parsepartitionreassignmentdata()? also, could we document the return value?",-1,0.7339923977851868
136208723,3621,junrao,2017-08-30T22:45:52Z,"ok, thanks for the explanation. this is fine then. could we document the error code/exception in alterreplicadirresult?",1,0.5514994859695435
136209635,3621,lindong28,2017-08-30T22:52:06Z,"this name is used following the name of the existing method `zkutils.parsepartitionreassignmentdatawithoutdedup`. if we name it `parsepartitionreassignmentdata` in `reassignpartitionscommand`, should we also rename the method in `zkutils` for consistency? note that there is an existing method `parsepartitionreassignmentdata(jsondata: string): map[topicandpartition, seq[int]]` in zkutils which justifies the use of `parsepartitionreassignmentdatawithoutdedup` in zkutils.",0,0.9938390851020813
136210274,3621,lindong28,2017-08-30T22:56:29Z,sure. previously the error is only documented in `alterreplicadirresponse`. just now i added the error code documentation in `alterreplicadirresult` as follows: [code block],0,0.9938114285469055
136211210,3621,junrao,2017-08-30T23:03:06Z,perhaps we can just get rid of zkutils.parsepartitionreassignmentdatawithoutdedup since the only caller is zkutils.parsepartitionreassignmentdata?,0,0.9949997663497925
136211869,3621,lindong28,2017-08-30T23:08:07Z,sure. i have updated the patch as suggested. thanks for taking time to review the patch!,1,0.9305791258811951
136690443,3621,becketqin,2017-09-02T06:25:28Z,"can we add a comment here for this? also, if the only possible error is log dir offline, would it be clearer to only check for that error and log an error message or throw exception in other cases?",0,0.9929183125495911
136703340,3621,becketqin,2017-09-02T20:31:09Z,"maybe worth adding a comment? also usually the clients do not infer an error code while the broker did not return it. maybe it is better to let the server to return cluster_authorization_failed. we are doing the same for `describeaclsrequest`. if we do that we will need to add response level error code, which probably makes sense.",0,0.9943093061447144
136710394,3621,ijuma,2017-09-03T07:28:17Z,", jun was referring to clients that don't use our code at all. librdkafka, kafka-python, etc.",0,0.972671389579773
136711246,3621,ijuma,2017-09-03T08:21:42Z,"sorry for being late on this. why is this `alterreplicadir` instead of `alterreplicadirs` (or some other version that indicates the batch nature)? this is a batch api like every other api so it should indicate that via the name, right?",-1,0.981941819190979
136711278,3621,lindong28,2017-09-03T08:23:58Z,i see. thanks for the information.,1,0.7446192502975464
136711440,3621,lindong28,2017-09-03T08:32:55Z,"i think one reason to use alterreplicadir is that it presents a map from replica -> dir. it is probably a bit different from other names such as describeconfigs, which represents a collection of configs. do you like me to submit a patch to change it to a different name? what do you think about this name?",0,0.9756655097007751
136711492,3621,ijuma,2017-09-03T08:36:14Z,why did we remove this?,0,0.9763801097869873
136711557,3621,ijuma,2017-09-03T08:39:15Z,"thanks for the quick reply. right, it's a map from replica to dir instead of a single replica to dir. the name sounds like the latter to me. before doing a pr, let's see if we get consensus amongst yourself and the reviewers.",1,0.9805868864059448
136711582,3621,lindong28,2017-09-03T08:40:42Z,originally i added a similar comment to the new api. commented that this is unnecessary. i agree with this is unnecessary because `alterconfigsresult` returns `map >` which suggests that some configs may be updated successfully while others fail. thus there is no need to have extra comment in the api documentation to specify this. does this make sense?,0,0.9748603701591492
136712129,3621,ijuma,2017-09-03T09:10:32Z,"while i understand the sentiment, we have to remember that these apis will be used by people who are not familiar with kafka in the same way we are. we often get support questions because things that seem obvious to us are not clear to users. i disagree that we should remove clarification comments like the above in public apis.",-1,0.6816929578781128
136712322,3621,lindong28,2017-09-03T09:20:39Z,"i see. sure, i can submit a minor patch tomorrow for this (or please feel free to just commit a minor patch if you prefer). to keep the api document consistent and for the same reason you described, maybe we should have this comment (i.e. api is not transactional) for all those apis in the adminclient which may partially succeed, e.g. deletetopics?",0,0.9915088415145874
136712993,3621,ijuma,2017-09-03T09:58:32Z,"yes, i think that's a good idea. if you are ok with submitting a pr, that would be great. it's not urgent, we should aim to do it before 1.0.0 is released.",1,0.9214745163917542
136741892,3621,tedyu,2017-09-04T04:16:18Z,is illegalstateexception more approriate for this situation ?,0,0.937818706035614
136742443,3621,tedyu,2017-09-04T04:27:46Z,nit: the 'else' can be omitted.,0,0.9900130033493042
136772853,3621,lindong28,2017-09-04T08:52:23Z,thanks much for catching this . you are right. i will fix this in [a link],1,0.9845162630081177
136772976,3621,lindong28,2017-09-04T08:53:01Z,originally i think the if/else may be better. the difference is very minor to me. i will remove `else` in [a link],0,0.9223148226737976
399149713,7898,OneCricketeer,2020-03-27T09:54:44Z,"imo, why not rewrite against `org.slf4j`?",0,0.9929434657096863
399149940,7898,OneCricketeer,2020-03-27T09:55:09Z,"based on the comments, how about `2.13.x`?",0,0.9944151639938354
399333888,7898,dongjinleekr,2020-03-27T15:08:24Z,"yes, i am now working with `2.13.1` and it seems like good.",1,0.7870643138885498
399335778,7898,dongjinleekr,2020-03-27T15:11:10Z,"`log4jcontroller` provides a dynamic `logger` querying functionality, not logging itself. it is why it uses log4j `logger`s directly. in contrast, the streams module does not provide those kinds of functionality so it uses slf4j fascade.",0,0.9938177466392517
400595313,7898,OneCricketeer,2020-03-31T01:48:42Z,"is zookeeper duplicated here?? also, does zookeeper transitively bring in log4j anywhere?",0,0.976897120475769
400595736,7898,OneCricketeer,2020-03-31T01:50:16Z,it seems `org.apache.kafka.*` imports used to be first,0,0.9942576885223389
400596128,7898,OneCricketeer,2020-03-31T01:51:49Z,is the `.map()` needed? [code block],0,0.9938228130340576
400596367,7898,OneCricketeer,2020-03-31T01:52:44Z,"also, `collectors.tocollection(treeset::new)` might be useful",0,0.9931392073631287
400596620,7898,OneCricketeer,2020-03-31T01:53:34Z,can `logger == null`?,0,0.9925690293312073
400597136,7898,OneCricketeer,2020-03-31T01:55:15Z,it seems these imports used to be first,0,0.9867432117462158
400597441,7898,OneCricketeer,2020-03-31T01:56:30Z,"personally, rather than rely on src/test/resources, i would pull from the classpath... `loggingresourcetest.class.getclassloader().getresource(""log4j2.properties"")`",0,0.9954003691673279
400598244,7898,OneCricketeer,2020-03-31T01:59:26Z,remove this?,0,0.9845433831214905
400598312,7898,OneCricketeer,2020-03-31T01:59:40Z,remove this?,0,0.9845433831214905
400598447,7898,OneCricketeer,2020-03-31T02:00:11Z,this pattern looks different,0,0.6496142745018005
400598659,7898,OneCricketeer,2020-03-31T02:00:56Z,nit: these got rearranged,0,0.8083396553993225
401709877,7898,dongjinleekr,2020-04-01T15:35:11Z,fixed. please have a look at [a link]. :),1,0.9936421513557434
401713158,7898,dongjinleekr,2020-04-01T15:39:40Z,"this duplication has been addressed in [a link]. since this setting contols only direct imports only, it does not bring `log4j` transitively.",0,0.9939839243888855
401713391,7898,dongjinleekr,2020-04-01T15:39:59Z,great. i will apply it. :),1,0.9960446357727051
401713720,7898,dongjinleekr,2020-04-01T15:40:27Z,no. log4j2 does not allow `logger == null`.,0,0.9839471578598022
401714074,7898,dongjinleekr,2020-04-01T15:40:58Z,agree. i will have a try.,0,0.9208131432533264
401714449,7898,dongjinleekr,2020-04-01T15:41:30Z,not yet. `log4j-appender` is still using log4j; `log4j2-appender` is under progress. :),1,0.9885721206665039
401714669,7898,dongjinleekr,2020-04-01T15:41:48Z,ditto :smiley:,1,0.7166439294815063
401715288,7898,dongjinleekr,2020-04-01T15:42:40Z,"yes, but the reason is that it follows deleted `quickstart/java/src/main/resources/archetype-resources/src/main/resources/log4j.properties`; it has different pattern so i followed it.",0,0.9918007254600525
497371849,7898,tombentley,2020-09-30T09:30:32Z,shouldn't `connect.log.pattern` actually be something like this: [code block] ?,0,0.9934373497962952
497376858,7898,tombentley,2020-09-30T09:38:53Z,is the `policies` really necessary if we're only using a single triggering policy? i t_hink_ you could just say [code block],0,0.9929317235946655
497378983,7898,tombentley,2020-09-30T09:42:20Z,use a `\` escaped newline to avoid the very long line.,0,0.9660428762435913
497380746,7898,tombentley,2020-09-30T09:45:17Z,"also since log4j2 i think it's often unnecessary to have to specify` loggers` and `appenders` upfront, they can be determined during parsing. unfortunately the docs don't bother saying when it _is_ necessary, but it would be easy for users to add their `logger....name` and `logger....level` properties only to find it didn't work because they forgot about adding the name to `loggers`, so it would be good to only specify `loggers` if we really need to. same applies to appenders and the other log4j config files too, of course.",0,0.9877782464027405
497381662,7898,tombentley,2020-09-30T09:46:48Z,why was `log4j.rootlogger=off` before but `warn` now?,0,0.9943302869796753
497385774,7898,tombentley,2020-09-30T09:53:23Z,"collect has a overload which takes a supplier of empty maps (i think you also have to provide a lamda for duplicate keys, annoyingly). that would allow you to avoid needing the `new treemap` in the `return`. alternatively just use `foreach` as previously.",0,0.9647819995880127
497387063,7898,tombentley,2020-09-30T09:55:23Z,you can avoid the `if` using `found.orelse(null)`,0,0.9936022162437439
497387624,7898,tombentley,2020-09-30T09:56:17Z,was changing the parameter name really necessary? it makes the diff noisier and the old name wasn't _so_ bad.,-1,0.6115416288375854
497391073,7898,tombentley,2020-09-30T10:02:20Z,"it's a pre-existing issue, but i think this is slightly incorrect since it would tread `com.foo` as an ancestor of `com.foobar`. really we should be using `startswith` with a logger name that we know ends with a `.`.",0,0.9550394415855408
497392952,7898,tombentley,2020-09-30T10:05:18Z,"this is the second time you've got a `.equals("""")`. it might be worth factoring into a `isrootlogger(logger)` method.",0,0.9943037629127502
497393514,7898,tombentley,2020-09-30T10:06:13Z,why was this necessary?,0,0.977853000164032
497396302,7898,tombentley,2020-09-30T10:11:25Z,"the default when the level is not set should be the ancestor logger's level, rather than the root logger level, but i guess you're waiting for my pr to be merged, right?",0,0.9886358976364136
497400286,7898,tombentley,2020-09-30T10:18:56Z,"we probably need better coverage in the alter case (`testincrementalalterconfigsforlog4jloglevels()`, below). it tests inheritance from the root logger, but not an ancestor logger. but i guess this is something i should add to my pr.",0,0.9878641963005066
497402528,7898,tombentley,2020-09-30T10:23:06Z,"`s""${classof[controllerintegrationtest]}#testcontrollermoveontopiccreation""`, and if not then there should be no need for the `tostring`",0,0.9946761131286621
497402639,7898,tombentley,2020-09-30T10:23:18Z,same comment.,0,0.9625935554504395
497402786,7898,tombentley,2020-09-30T10:23:37Z,same comment.,0,0.9625935554504395
497402868,7898,tombentley,2020-09-30T10:23:48Z,same comment,0,0.957730233669281
497410244,7898,tombentley,2020-09-30T10:37:28Z,"it's a shame about the new asynchrony here, but i don't see an obvious we of avoiding it.",-1,0.9893175959587097
497412007,7898,tombentley,2020-09-30T10:40:48Z,again it's not really clear to me why this is added,0,0.6138514876365662
497413476,7898,tombentley,2020-09-30T10:43:42Z,"i can see this being a source of difficult to maintain tests, if you have to tweak the latch every time logging statements are added or removed.",0,0.9371286630630493
497415319,7898,tombentley,2020-09-30T10:47:28Z,"do we really need the caller to supply a `name`? it seems to force you to have to construct a unique name each time you want to use it, based on the test class and method name. but all that's needed is uniqueness and the removal of the appender at the end of the test, afaics. so just using a uuid or similar generated name would be sufficient and make call sites rather easier to read.",0,0.9910857081413269
497416562,7898,tombentley,2020-09-30T10:50:02Z,"i wonder if it would simplify the tests if this had methods for asserting the existence of messages (optionally within a timeout) rather than having to use the `setlatch(), await(), getmessages()` pattern in every test.",0,0.9900408387184143
497417343,7898,tombentley,2020-09-30T10:51:31Z,was this really necessary?,0,0.987857460975647
500806583,7898,dongjinleekr,2020-10-07T07:50:01Z,"oh, i don't know why it is shown as a modification in diff view. in `config/tools-log4j.properties ` root logger level is `warn` by `log4j.rootlogger=warn, stderr`.",0,0.9615448713302612
500807752,7898,dongjinleekr,2020-10-07T07:51:52Z,great. i will improve the formatting and lining. let me see.,1,0.9951052665710449
500821253,7898,dongjinleekr,2020-10-07T08:14:05Z,no. `connect.log.pattern` is get referenced at the lines below: [code block],0,0.9945900440216064
500829824,7898,dongjinleekr,2020-10-07T08:27:30Z,"is this possible? all examples i saw explicitly state `policies`, like: - [a link] - [a link]",0,0.9922499656677246
500830940,7898,dongjinleekr,2020-10-07T08:29:14Z,"oh, i thought making it consistent with `loggingresource#setlevel` would be better.",0,0.9766232967376709
500838684,7898,dongjinleekr,2020-10-07T08:41:15Z,"it is related to a issue between log4j2 2.13.x and powermock; in short, it causes `java.lang.linkageerror` as of present. please see: - [a link] - [a link]",0,0.9943063855171204
500840081,7898,dongjinleekr,2020-10-07T08:43:23Z,right. fixed.,0,0.9658468961715698
500849730,7898,dongjinleekr,2020-10-07T08:58:12Z,"oh my, your approach is much simpler and more clear. okay, i will take this approach.",1,0.5915355086326599
500870442,7898,dongjinleekr,2020-10-07T09:30:27Z,"as you can see below, `new streamsconfig(props);` is called in every test method of this suite. so, this line is redundant. more importantly, it generates duplicated log messages and makes log message related test cases hard to validate.",0,0.9755194783210754
500882458,7898,dongjinleekr,2020-10-07T09:49:59Z,"good proposal. actually, it is the first approach i have taken. however, while running the tests repeatedly, i found that the log messages are not forwarded in designated timeout properly, and the tests go so flaky. each test runs correctly when i run them individually, but 3 ~ 5 tests were randomly failed when i run them in bulk, with `./gradlew :streams:test`. it seems like this symptom is related to the busy wait implementation of `listappender#getmessages` but i can't certain yet. after numerous trial and error, i found that the current approach is a little bit verbose but makes the test suites sustainable. it is the background of this api design.",1,0.4850543141365051
501043518,7898,dongjinleekr,2020-10-07T14:09:17Z,"exactly. however, i thought introducing randomness to the test cases is worse than some verbosity. let's wait for others' opinions.",0,0.5591474771499634
501046635,7898,dongjinleekr,2020-10-07T14:13:18Z,agree. let's add a additional test about that case.,0,0.9804019331932068
501048158,7898,dongjinleekr,2020-10-07T14:15:19Z,exactly.,0,0.9699188470840454
501054972,7898,dongjinleekr,2020-10-07T14:23:52Z,"agree. i am now thinking about a utility class that determines whether a given logger name is a child, descendent, parent, or ancestor of another logger.",0,0.9275083541870117
501060061,7898,dongjinleekr,2020-10-07T14:30:04Z,"well, i found a similar method to what you described in `collectors`, not in `stream#collect`. is this what you mean? [code block]",0,0.9927327036857605
769044309,7898,rafalmag,2021-12-14T21:04:51Z,please use 2.15.0 instead to avoid noise about cve-2021-44228,0,0.9934090375900269
769083607,7898,amuraru,2021-12-14T22:07:30Z,actually 2.16 please,0,0.9886443614959717
769193981,7898,showuon,2021-12-15T02:24:53Z,"we should say, please use the **latest** release of log4j2, please! :)",1,0.9947054982185364
779703586,7898,ispringer,2022-01-06T17:05:23Z,can this be bumped to `2.17.1` ([a link],0,0.99176424741745
780114085,7898,dongjinleekr,2022-01-07T08:59:50Z,"yes, i did [a link] for [a link] and it will be also applied to this pr. :+1:",1,0.981821596622467
783853620,7898,viktorsomogyi,2022-01-13T11:03:14Z,i think renaming in this case makes the code a bit clearer and consistent.,0,0.9754752516746521
783871962,7898,viktorsomogyi,2022-01-13T11:29:10Z,nit: instead of `.map(_._2)` you could use `.values`,0,0.9934592247009277
785830903,7898,viktorsomogyi,2022-01-17T10:32:27Z,i think i would also prefer generating a name in the `apply()` method. if someone uses the same name twice it might introduce an error but it's indeed easier to read without the `name` as tom proposed.,0,0.9926252961158752
785843643,7898,viktorsomogyi,2022-01-17T10:48:28Z,ran the tests and it seems like the powermock class loader isn't able to load these classes (as they have previously been loaded?). it doesn't cause a test failure but it's ugly and deferring to the system classloader fixes the issue. maybe has a more specific answer but i think it's fine to have this annotation here. [code block],0,0.794915497303009
786045157,7898,dongjinleekr,2022-01-17T14:14:41Z,"got it. i will update the pr to generate the context name automatically, like `logcapturecontext-xxxxxx`.",0,0.9902800917625427
786067964,7898,dongjinleekr,2022-01-17T14:41:52Z,"oh yes, initially `kafkastreamstest` needed `({""javax.management.*"", ""org.apache.log4j.*""})` like `workersourcetasktest` but, it does not need it anymore. it would be better to remove this annotation.",0,0.9941685199737549
788006560,7898,viktorsomogyi,2022-01-19T17:58:25Z,"why don't you change this (and all the similar cases) to the log4j2 property? if i get it right then after the upgrade `-dlog4j.configuration` won't work anyway so while i see the value of notifying the user, i think we should just use the log4j2 property outright. or is there a backward compatibity, so does `log4j.configuration` work under log4j2?",0,0.9759282469749451
788034050,7898,rgoers,2022-01-19T18:34:38Z,"yes, if you set log4j.configuration to reference a log4j.xml (log4j 1 configuration) and you have log4j-1.2-api on the classpath then log4j 2 will process the log4j 1 configuration. we improve this support with every release. substantial improvements will be in 2.17.2 which should come out by the end of the month.",0,0.9903924465179443
788207067,7898,dongjinleekr,2022-01-19T22:42:42Z,thanks for the clarification. it seems like we also have to upgrade to log4j 2.17.2 soon.,1,0.8627434968948364
793571163,7898,dongjinleekr,2022-01-27T12:48:30Z,"for `level#tolevel` semantics, see: - [a link] - [a link] - [a link] as you can see here, all of above follows the same semantics - they fallback to `debug` with unknown level.",0,0.9946004152297974
794332702,7898,dongjinleekr,2022-01-28T09:24:29Z,fyi: [a link] cc/,0,0.8915337920188904
797627738,7898,mimaison,2022-02-02T13:53:12Z,nit: can we get rid of the extra spaces and have `name=value` for all these lines like in the other files?,0,0.9925850033760071
803805924,7898,mimaison,2022-02-10T15:36:58Z,is the plan to remove this and use the log4j2 file by default in the next major release?,0,0.9949989318847656
803816355,7898,mimaison,2022-02-10T15:46:17Z,nit: this is not aligned,0,0.7247671484947205
815384279,7898,showuon,2022-02-27T03:54:18Z,nit: can be simplified to: [code block],0,0.9890809059143066
815400322,7898,showuon,2022-02-27T07:36:10Z,+1,0,0.7702900171279907
815400528,7898,showuon,2022-02-27T07:38:25Z,"is the additional ending ""space"" expected? and why?",0,0.9923418760299683
815400630,7898,showuon,2022-02-27T07:39:32Z,is the catch block expected?,0,0.9936984777450562
815401329,7898,showuon,2022-02-27T07:47:35Z,nice refactor,1,0.9871834516525269
815401515,7898,showuon,2022-02-27T07:49:17Z,"again, why additional ending space?",0,0.9365158081054688
815401739,7898,showuon,2022-02-27T07:52:04Z,why did we need these 2 supplier? i didn't see them get used in this test.,0,0.9558444023132324
815402457,7898,showuon,2022-02-27T07:59:29Z,"i'm thinking that we should add a clear javadoc in `logcapturecontext`, to explain when we should add `setlatch`, and when we should do `await`. i can see sometimes we don't set latch, but sometimes we set, and sometimes we do `await`, but sometimes not. could you help other developer with it?",0,0.9850118160247803
815403276,7898,showuon,2022-02-27T08:07:11Z,"since we only care about `warn` level in this test, we could create `ktablesource.class` with `warn` log as before, right?",0,0.9945032596588135
815403282,7898,showuon,2022-02-27T08:07:20Z,ditto,0,0.9222367405891418
815403425,7898,showuon,2022-02-27T08:08:34Z,any reason why we change the expected log message here?,0,0.9711001515388489
815404230,7898,showuon,2022-02-27T08:16:29Z,why can't we verify whole messages?,0,0.970371663570404
815404252,7898,showuon,2022-02-27T08:16:46Z,ditto,0,0.9222367405891418
815404272,7898,showuon,2022-02-27T08:16:53Z,ditto,0,0.9222367405891418
815404434,7898,showuon,2022-02-27T08:18:21Z,nit: could we create log with warn only?,0,0.9900722503662109
815404547,7898,showuon,2022-02-27T08:19:35Z,+1,0,0.7702900171279907
815404639,7898,showuon,2022-02-27T08:20:46Z,"and, also please add docs for what latch size should be set.",0,0.9886397123336792
815407543,7898,showuon,2022-02-27T08:47:35Z,why did we remove `finally` block for `rocksdbstore.close()`? is there possible that we have resource leak here?,0,0.9944169521331787
815407744,7898,showuon,2022-02-27T08:50:03Z,ditto: potential resource leak?,0,0.9627520442008972
829746139,7898,dongjinleekr,2022-03-18T07:22:54Z,because of `streams/src/test/resources/log4j2.properties`: [code block],0,0.9926989674568176
829748108,7898,dongjinleekr,2022-03-18T07:26:53Z,no. this is a debris from the old code. removed.,0,0.9410552382469177
829777640,7898,dongjinleekr,2022-03-18T08:19:44Z,documentaton on `logcapturecontext` added.,0,0.9921017289161682
830011584,7898,dongjinleekr,2022-03-18T13:42:48Z,the try block with `logcaptureappender` resource was removed; that's the reason.,0,0.99444580078125
461887873,9039,ableegoldman,2020-07-28T21:23:12Z,"not sure if you did this or your ide did it automatically, but nice :thumbs_up:",1,0.9950684309005737
462625072,9039,ableegoldman,2020-07-29T22:24:57Z,nit: call this `timedifferencems` to be in sync with `gracems`. also it can be private,0,0.9921942949295044
462626773,9039,ableegoldman,2020-07-29T22:29:17Z,nit: also rename the method `timedifferencems` to be consistent with `graceperiodms`,0,0.9948930740356445
462627186,9039,ableegoldman,2020-07-29T22:30:26Z,i think we can remove this suppression (and all the ones below),0,0.9614248871803284
462627276,9039,ableegoldman,2020-07-29T22:30:39Z,nit: extra space after `return`,0,0.9915245175361633
462640050,9039,ableegoldman,2020-07-29T23:06:31Z,"seems like this should have also had a check for `sessionwindows != null`, right? can we add that as well?",0,0.993724524974823
462646319,9039,ableegoldman,2020-07-29T23:26:36Z,nit: alignment is off by one on the parameters,0,0.984596312046051
462647029,9039,ableegoldman,2020-07-29T23:29:01Z,"i think it's ok to skip this; since it's a new operator, there's no old topology to be compatible with",0,0.9801174998283386
462647656,9039,ableegoldman,2020-07-29T23:30:52Z,i wonder why we have to do this for `count` but not for `aggregate` and `reduce`? is this intentional or an oversight? cc,0,0.8667970895767212
462653088,9039,ableegoldman,2020-07-29T23:48:39Z,"can we add an `else` here with `builder.withcachingdisabled()`? it doesn't make a difference logically, it just seems easier to understand (again, also in `slidingwindowedcogroupedkstreamimpl`)",0,0.9939042925834656
462653237,9039,ableegoldman,2020-07-29T23:49:12Z,you should be able to remove this suppression and comment (here and in `slidingwindowedcogroupedkstreamimpl`),0,0.9934095144271851
462653505,9039,ableegoldman,2020-07-29T23:50:01Z,let's just remove this comment since it's the only style retention here (also in `slidingwindowedcogroupedkstreamimpl`),0,0.9939010143280029
462653753,9039,ableegoldman,2020-07-29T23:50:47Z,we can remove this,0,0.986793577671051
462655858,9039,ableegoldman,2020-07-29T23:58:03Z,"i was wondering what this method is actually used for so i checked out the callers of `kstreamwindowaggregate#windows`. there's a method called `extractgraceperiod` in `graphgracesearchutil` where we might actually need to make a small addition to include the new sliding window processor. i think it's for suppression, which needs to figure out the grace period of the upstream operator since grace period doesn't get passed in directly to `suppress`",0,0.9914805889129639
462658903,9039,ableegoldman,2020-07-30T00:08:03Z,"do you think we actually need to enforce that the retention period be a little longer for sliding windows? i was just thinking that since the range scan starts at `timestamp - 2 * windows.timedifference()`, maybe we should actually enforce that the retention period be >= `2 * timedifference + graceperiod` in case we need to get the aggregate value from some older window that has technically expired. haven't checked the math so i'm not sure that's the correct value exactly, but it seems like it might need to be a little bigger. any thoughts?",0,0.9178134799003601
462660320,9039,ableegoldman,2020-07-30T00:13:10Z,"in general it's better to use a more descriptive variable name than a shorted one with a comment. it's not always possible to describe a variable exactly in a reasonable length, but i think in this case we can say `curleftwindowalreadyexists` or `curleftwindowalreadycreated` or something might be better to use `alreadycreated` when we're specifically talking about whether or not a window already exists in the window store, and can use `exists` when we're talking about whether a window is possible regardless of whether it currently has been created or not",0,0.9926548004150391
462661922,9039,ableegoldman,2020-07-30T00:19:14Z,"does that make sense? in particular i feel like we're using `exists` to mean one thing for `left/rightwindowexists`, and then we mean another thing entirely in `prevrightwindowexists`. ie `prevrightwinalreadycreated` is more similar to what we mean by the `left/rightwindowexists` variables",0,0.9876306653022766
462662132,9039,ableegoldman,2020-07-30T00:19:57Z,this comment doesn't seem quite correct,0,0.5366456508636475
462662498,9039,ableegoldman,2020-07-30T00:21:20Z,can we also name this variable a bit more clearly instead of the comment? like `foundcloseststarttimewindow` or something. same with `foundfirstendtime`,0,0.9947997331619263
462663297,9039,ableegoldman,2020-07-30T00:24:13Z,maybe add a comment saying that this condition will only be hit on the very first record. or it might be reasonable to pull this one condition out of the loop and just handle it before entering the loop,0,0.9904305338859558
462663911,9039,ableegoldman,2020-07-30T00:26:22Z,"actually maybe `foundright/leftwindowaggregate` would be good, since that's what ""the window with the closest start/end time to the record"" actually means to us",0,0.9831657409667969
462667387,9039,ableegoldman,2020-07-30T00:38:53Z,"should this be inside the `if (!foundfirst)` condition above? we only want to save the aggregate of the first window we find with a start time less than the timestamp right? also, i think we might need to check that the max timestamp of this window is greater than the current record's timestamp. if not, then the right window will be empty. for example, we have a record a at 10 and a record b at 11 and then process a record at 15. obviously, the new right window will be empty. but the first window we'll find with a start time less than 15 will be [11, 21] with agg b.",0,0.9835962057113647
462667988,9039,ableegoldman,2020-07-30T00:40:56Z,nit: put each parameter on its own line,0,0.9827684760093689
462669250,9039,ableegoldman,2020-07-30T00:45:20Z,"seems like we're aggregating with the new value twice; we call `aggregator.apply` once in this if/else branch but then also call it again in `putandforward`, right?",0,0.9902350902557373
462677427,9039,ableegoldman,2020-07-30T01:16:27Z,can we add a comment to clarify that we're checking whether it's a left window because that tells us there was a record at this window's end time,0,0.9929524064064026
462677774,9039,ableegoldman,2020-07-30T01:17:55Z,"i feel like i'm just way overthinking this, but i keep getting these variables confused. maybe we could call this guy `prevrightwindowcanexist`? does that seem to get at its underlying purpose?",-1,0.8644496202468872
462678777,9039,ableegoldman,2020-07-30T01:21:38Z,can we remove this and just `break` out of the loop immediately at the end of the `isleftwindow` condition block?,0,0.9953349232673645
462679991,9039,ableegoldman,2020-07-30T01:26:22Z,"i think we need to pass in the new maximum window timestamp here, not the window start time",0,0.9859527349472046
462682266,9039,ableegoldman,2020-07-30T01:32:45Z,ok i may have lost the trail of logic here...are we just checking `prevrightwinexists` as an indicator of whether we actually found any records to the left of our record within range? could/should we check `foundfirstendtime` instead?,0,0.9760958552360535
462682718,9039,ableegoldman,2020-07-30T01:34:10Z,"since it's a left window, the max timestamp should always be `timestamp`, right?",0,0.9921815395355225
462683258,9039,ableegoldman,2020-07-30T01:36:00Z,can we put this condition into a method and give it a clear name to describe what this means? eg [code block],0,0.9924808740615845
463026843,9039,lct45,2020-07-30T14:13:34Z,"the original just had the check for `sessionmerger != null`, are there scenarios where the sessionmerger would be null but the sessionwindows wouldn't? i did think it was kind of inconsistent to check 'sessionmerger' just that one time and check 'sessionwindows' the other times so maybe it was a mistake",0,0.9802123308181763
463036048,9039,lct45,2020-07-30T14:26:20Z,done!,0,0.6890168786048889
463039985,9039,lct45,2020-07-30T14:31:32Z,"that's a good point. i think that `>= 2* timedifference + graceperiod` makes sense. adding graceperiod is just to help with out-of-order records, right? since for a normal record we won't need anything beyond 2*timedifference",0,0.7822118997573853
463046306,9039,lct45,2020-07-30T14:40:00Z,"yeah this makes sense, the boolean naming has definitely been a struggle. i think it's clearer actually if i change `prevrightwinexists` to `prevrightwinpossible` since that's what we're saying. i agree that for `leftwinexists` and `rightwinexists`, `alreadycreated` makes more sense.",0,0.953924834728241
463047237,9039,lct45,2020-07-30T14:41:16Z,"yeah that's much clearer, and differentiates between the other bools better",0,0.9373235702514648
463056420,9039,lct45,2020-07-30T14:53:37Z,"i'm not sure if it can be moved out of the loop unless we also move a check for if the first is a window whose aggregate we need to update, which is easy to do but gets back to the redundant code that the algorithm had before having one while loop. i did update the comment though",0,0.9496775269508362
463063406,9039,lct45,2020-07-30T15:03:02Z,"yeah i think you're right that the aggregate should be in the `if()`, good catch. we could check max timestamp, but this scenario should be covered already. before we create a right window we do the boolean checks and since any in-order-record won't have either a `foundleftwinfirst` or the `prevrightwinalreadycreated` and one of them needs to be true for the right window to get created after the `while()`. i haven't fully thought through checking with maxtimestamp but it seems like that would work, if that way seems clearer i can alter the algorithm and run through the examples to make sure that covers everything",0,0.747951865196228
463073842,9039,lct45,2020-07-30T15:17:48Z,"aha, i thought there was a scenario where the `putandforward` function wouldn't be so simple. yeah you're right, i updated it so the value of the record is only added in `putandforward`",0,0.8322610259056091
463076565,9039,lct45,2020-07-30T15:21:23Z,"updated above! changed to `prevrightwindowpossible` , lmk if that still seems confusing. i definitely kept getting them all mixed up so i think this will help",-1,0.8993442058563232
463077196,9039,lct45,2020-07-30T15:22:21Z,100%,0,0.8904232382774353
463078058,9039,lct45,2020-07-30T15:23:36Z,good catch,1,0.981269359588623
463083346,9039,lct45,2020-07-30T15:31:00Z,"yeah that's what `prevrightwinexists` is doing right now, we could store the full `valueandtimestamp` for `foundfirstendtime` and check to see if the max timestamp is within the range of recordtime-timedifference",0,0.9917421340942383
463083821,9039,lct45,2020-07-30T15:31:38Z,yes!,1,0.7005663514137268
463088582,9039,lct45,2020-07-30T15:38:57Z,"changed to ` if (leftwinagg.timestamp() < timestamp && leftwinagg.timestamp() > timestamp - windows.timedifferencems()) { valueandtime = valueandtimestamp.make(leftwinagg.value(), timestamp); } else { //left window just contains the current record valueandtime = valueandtimestamp.make(initializer.apply(), timestamp); }`",0,0.9920862317085266
463091437,9039,lct45,2020-07-30T15:42:56Z,"to go with your above comment about the maxtimestamp, i changed this to be `if (!rightwinalreadycreated && rightwinagg.timestamp() > timestamp)` is this clearer or should it still be in a new method?",0,0.9938209652900696
463092579,9039,lct45,2020-07-30T15:44:41Z,"changing both of the `if()` for creating new windows cut down like half of the booleans too, which i think is good",0,0.8718107342720032
464728426,9039,mjsax,2020-08-04T00:19:22Z,"the build should actually fail on wildcard imports... do we have some checkstyle gaps? can you maybe look into that (if not, also ok).",0,0.9664551019668579
464728901,9039,mjsax,2020-08-04T00:21:03Z,this pr is rather larger. would it maybe make sense to split it into 2 and add co-group in it's own pr?,0,0.9782674312591553
464729126,9039,mjsax,2020-08-04T00:21:44Z,nit: double `/**`,0,0.9685659408569336
464729311,9039,mjsax,2020-08-04T00:22:28Z,"nit: if you want to have a new paragraph, you need to insert ` ` tag -- otherwise, the empty line is just ignored all it's going to be one paragraph. -- if you don't want a paragraph, please remove the empty line.",0,0.9892886877059937
464729348,9039,mjsax,2020-08-04T00:22:35Z,as above.,0,0.9878018498420715
464729534,9039,mjsax,2020-08-04T00:23:14Z,type `[w]indows`,0,0.9917906522750854
464729743,9039,mjsax,2020-08-04T00:23:56Z,`and [a] given` ?,0,0.9881019592285156
464730686,9039,mjsax,2020-08-04T00:26:58Z,"we must use html list markup to get bullet points rendered, ie, ` ` and ` ` (cf [a link]",0,0.9936957955360413
464731092,9039,mjsax,2020-08-04T00:28:25Z,"`are processed` -> sounds like processing time semantics; maybe better `occur in the stream (i.e., event timestamps)`",0,0.9893131852149963
464731554,9039,mjsax,2020-08-04T00:29:58Z,reference to `cogroupedkstream` is missing,0,0.993571400642395
464731762,9039,mjsax,2020-08-04T00:30:46Z,as above (won't comment on this again) -- please address throughput the whole pr.,0,0.9856908917427063
464732204,9039,mjsax,2020-08-04T00:32:24Z,`timedifference (timedifference)` (redundant) should be `time difference (timedifference)` `must be larger than zero.` -> `must not be negative.`,0,0.9924505352973938
464732462,9039,mjsax,2020-08-04T00:33:30Z,i guess a `timedifference` of zero should be allowed to define a sliding window of size `1ms`,0,0.9864513874053955
464732572,9039,mjsax,2020-08-04T00:33:53Z,as above -> should be `timedifferencems < 0`,0,0.9885050654411316
464733014,9039,mjsax,2020-08-04T00:35:30Z,"for consistency: `grace period (grace) must` ? frankly, i am not sure if we need to have ""natural language"" and the parameter name in those error messages -- also above. but we should do it in a consistent manner imho.",0,0.976769208908081
464734041,9039,mjsax,2020-08-04T00:39:23Z,i agree with sophie that his check seems a little weird. we should check that either both (sessionwindows and sessionmerger) are null or not null.,-1,0.9572706818580627
464735173,9039,mjsax,2020-08-04T00:43:50Z,"i think we should do this check in `init` and use a `runnable` that we just call blindly (ie, depending on the check, we instantiate the one or other `runnable` and each `runnable` implements a different algorithm.",0,0.9918137788772583
464735252,9039,mjsax,2020-08-04T00:44:11Z,why do we suppress instead of fix the issue? (or add an exception to the `suppress.xml` file if we really need it),0,0.9935465455055237
464736052,9039,mjsax,2020-08-04T00:47:16Z,"i think we should also drop if `value == null` ? (it seem this `null` check is missing in the existing time/session-window aggregate processors, too)",0,0.9934226870536804
464736550,9039,mjsax,2020-08-04T00:49:24Z,"maybe we have the same issue in other processors, too (we might even have a ticket for it?) but won't we need to preserve `observedstreamtime` across restarts? it's transient atm... (just want to confirm -- maybe it's ok as other processor do it the same way and we need to fix if for all of them at once?)",0,0.9789209961891174
464736969,9039,mjsax,2020-08-04T00:51:12Z,the comment seems redundant -- it just says exactly what the next line of code says.,0,0.961256742477417
464737602,9039,mjsax,2020-08-04T00:53:54Z,"no need to pass in an `instant` -- we should just pass in the `long` directly. it might not be clear from the type hierarchy, but the overloads that accept `long` are only deprecated for the `readonlyxxx` store, but are still available on the ""read/write"" stores to avoid unnecessary runtime overhead.",0,0.9948140382766724
464738212,9039,mjsax,2020-08-04T00:56:11Z,why `+ 1` ?,0,0.9915717840194702
464738932,9039,mjsax,2020-08-04T00:59:18Z,"as above. (also, this code seems to be duplicated; we should move it into `process()` before we call the the actual `processreverse` or `processinorder` methods.",0,0.9924108982086182
464739084,9039,mjsax,2020-08-04T00:59:53Z,as above,0,0.9391705989837646
464739153,9039,mjsax,2020-08-04T01:00:07Z,nit: move `key` to the next line,0,0.9924457669258118
464739977,9039,mjsax,2020-08-04T01:03:19Z,why `* 2` ?,0,0.9913313388824463
464740108,9039,mjsax,2020-08-04T01:03:51Z,why `* 2` ?,0,0.9913313388824463
464740325,9039,mjsax,2020-08-04T01:04:45Z,why this?,0,0.8648593425750732
464740712,9039,mjsax,2020-08-04T01:06:18Z,we should not use this annotation (even if we still have code that used it... we are working on migrating test away lazily). we should instead use `assertthrows` and also verify the exception error message. same below.,0,0.9922182559967041
464740960,9039,mjsax,2020-08-04T01:07:06Z,"beside the fact, that zero should be valid imho, what do we gain by testing `0` and `-1` ?",0,0.9908214807510376
464741103,9039,mjsax,2020-08-04T01:07:51Z,this line seems to be unnecessary for this test?,0,0.972817599773407
464741202,9039,mjsax,2020-08-04T01:08:16Z,this is also a pattern we try to move off. use `assertthrows` instead.,0,0.9911942481994629
464741688,9039,mjsax,2020-08-04T01:10:08Z,"why do we need three tests? if you want to ""randomize"" it, maybe just use `random` to generate `difference` and `grace` input instead of hard coding them?",0,0.9925364255905151
464741801,9039,mjsax,2020-08-04T01:10:33Z,as above.,0,0.9878018498420715
464741983,9039,mjsax,2020-08-04T01:11:13Z,what is the difference between `verifyinequality` and `assertnotequals` ?,0,0.9936257600784302
464742330,9039,mjsax,2020-08-04T01:12:30Z,this should be two test: - `shouldnotbeequalfordifferenttimedifference` - `shouldnotbeequalfordifferentgraceperiod`,0,0.9920859932899475
464744504,9039,mjsax,2020-08-04T01:20:48Z,why is `endtime = long.max_value`? should it not be `firstbatchtimestamp` ?,0,0.9933103322982788
464744963,9039,mjsax,2020-08-04T01:22:32Z,`firstbatchleftwindow` -> `firstbatchleftwindowstart` maybe also introduce `firstbatchleftwindowend = firstbatchtimestamp`,0,0.9943285584449768
464746013,9039,mjsax,2020-08-04T01:26:26Z,maybe add comment to clarify which input should trigger which output: [code block],0,0.9928408861160278
464746981,9039,mjsax,2020-08-04T01:30:05Z,"we should add a fourth batch with ts like 10k to get the windows when the second batch drops outs, too.",0,0.9928855299949646
465073439,9039,lct45,2020-08-04T14:02:56Z,"would checking both be redundant? it looks like the method that ultimately calls this one will check that sessionmerger is not null for session windows, so i think either both of these will be null or neither will be null",0,0.9903931021690369
465079294,9039,lct45,2020-08-04T14:10:57Z,"we want to be able to find the furthest window for which we can create a corresponding right window, so for any record the furthest window we will ever need will start at `timestamp - 2 * timedifference`, but we will need to have these around to calculate new windows, hence the longer retention time.",0,0.9890074729919434
465094963,9039,lct45,2020-08-04T14:30:49Z,"because the windows are sorted, the windows created by each record aren't consecutive, so i added comments describing each window, but only did it for a since all the other keys are processed the exact same way. sample comment: `// a @ secondbatchtimestamp left window created when a @ secondbatchtimestamp processed`",0,0.990433931350708
465097558,9039,mjsax,2020-08-04T14:34:22Z,"well, yes and no. we can follow two strategies: (1) we rely on the user to only set all `null` (for the non-windowed aggregation case) or either one of `windows`, `slidingwindow`, or `sessionwindow+sessionmerger` and we don't do any verification if the method is called correctly or not. however, for this case, we don't need to do any redundant not-null check and we could just write: [code block] or, (2) we do not ""trust"" the caller and do a proper check that the provided arguments make sense. and the existing code already has such a safe guard and does checks that not multiple windows are passed in and throws an `illegalargumentexception` if the caller makes a mistake. i personally prefer to have a safe guard (especially on the non-hot code path) as it may prevent bugs. however, the current check is not complete, as it does not verify that `sessionmerger` must be not-null when `sessionwindows` is not-null; this may lead to a potentially cryptic `nullpointerexception` later that is harder to understand. if we do the check and throw a proper `illegalargumentexception(""sessionmerger cannot be null for sessionwindows"")` and `illegalargumentexception(""unexpected sessionmerger parameter: should be null because sessionwindows is null"");` help to identify the issue quickly.",0,0.9902585744857788
465099913,9039,mjsax,2020-08-04T14:37:23Z,"ack. makes sense. might be worth to add a comment why we need an ""unexpected"" large retention time.",0,0.5144731402397156
465101059,9039,mjsax,2020-08-04T14:39:00Z,with regard to above: the error message to does align to the required minimum retention time. it says `must be no smaller than its window time difference plus the grace period.`...,0,0.9930524230003357
465111665,9039,lct45,2020-08-04T14:53:23Z,"good catch, will do",1,0.9784483909606934
465191505,9039,lct45,2020-08-04T16:51:54Z,"there seems to be a bug in `timewindoweddeserializer` related to [a link] that ends up setting the windowsize to `long.max_value`. for the purposes of testing, i don't think having it as the max value is totally awful (just somewhat awful) and the window end calculations are all tested in a different set of tests done through topology driver. i'll make a ticket for this bug and try to get it fixed when i'm done with testing",-1,0.9840707778930664
465193735,9039,lct45,2020-08-04T16:55:32Z,"i think just confirming that the correct error will be thrown when someone sets a `timedifference` we don't want. i'll update all the `windowsize` to be `timedifference` and i agree, no need to check that it isn't 0",0,0.9740493893623352
465194845,9039,lct45,2020-08-04T16:57:19Z,"re-examining the test, it looks like it does the same thing as `graceperiodmustnotbenegative()` so i think the test can be removed entirely",0,0.9874096512794495
465205088,9039,lct45,2020-08-04T17:15:08Z,"whoops, not on purpose. thanks for the check",1,0.9337495565414429
465219522,9039,lct45,2020-08-04T17:40:13Z,"to clarify, are you wanting to add records that would fall after the third batch _outside_ of all the existing windows, or so that it will fall into the third batch's windows but not the second batch's windows?",0,0.9931105375289917
465334577,9039,lct45,2020-08-04T21:15:01Z,"we could, but it would only pull out 3ish classes and not very many lines, so i don't think it would make this pr feel much smaller",0,0.9025413393974304
465336976,9039,lct45,2020-08-04T21:20:12Z,so we can check to see if the record that is being processed has an already existing right window (that would start at timestamp+1) without doing another call to the store,0,0.9923537969589233
465339322,9039,lct45,2020-08-04T21:25:19Z,fixed for both,0,0.9737132787704468
465348679,9039,lct45,2020-08-04T21:46:37Z,"they look to be fairly similar, and it seems like the tests use both consistently. `verifyinequality` seems to be more thorough, and to be consistent with the above `equalsandhashcodeshouldbevalidforpositivecases` i think i'll use `verifyinequality` for this test, unless someone has an objection",0,0.9156001806259155
465369865,9039,ableegoldman,2020-08-04T22:40:42Z,"why do we have a single method that accepts all three window types and then checks them all individually to enforce that only one type of window is actually ""set""? seems like we could enforce this implicitly by having a separate method for time, session, and non-windowed aggregates and then just calling the correct signature. ie `sessionwindowedcogroupedkstreamimpl` calls `build(...sessionwindows, sessionmerger) and so on. maybe i'm missing something here because i wasn't following the cogroup kip that closely, but is this even exposed to the user in any way? my understanding is that there's no way for this check to be violated by any kind of user input, because this method is only ever called directly by streams internal code with `null` hardcoded for the unused window types. i think it's more of an internal consistency check for streams than an input validation for the user (and it seems unnecessary: see above)",0,0.9664372801780701
465371635,9039,ableegoldman,2020-08-04T22:45:29Z,"seems like the cogroup stuff makes up a pretty small amount of the overall pr, but up to leah",0,0.801904559135437
465374004,9039,ableegoldman,2020-08-04T22:52:21Z,"we definitely have the issue in all processors right now lol. it's not any more of a problem for this sliding windows algorithm as for any other operator that defines a grace period, at least. we might end up not dropping a late record that we should have; for sliding windows we'd get one extra window (with this record at the window end) whereas for a hopping/tumbling window we'd get n extra windows (however many overlaps there are)",1,0.9545533061027527
465379071,9039,ableegoldman,2020-08-04T23:07:35Z,not saying all this needs to be cleaned up in this pr. if we check one thing (eg `sessionmerger`) then we should check everything (eg `sessionmerged != null && sessionwindows != null`). we can decide whether we really need to check anything as followup,0,0.9911008477210999
465379566,9039,ableegoldman,2020-08-04T23:09:14Z,maybe we can add this answer as a comment in the code for future readers,0,0.9906777143478394
465380753,9039,ableegoldman,2020-08-04T23:13:03Z,"just to clarify, we don't get any additional output when the stream time is advanced and older windows drop out of the grace period. we've already forwarded their final state when the last record to update that window was processed. not sure if that's what you meant by ""get the windows when the batch drops out"" or not?",0,0.9645731449127197
465382189,9039,ableegoldman,2020-08-04T23:17:51Z,"not sure, i think `and given window grace` makes grammatical sense. but either way",0,0.8951912522315979
465382663,9039,ableegoldman,2020-08-04T23:19:29Z,"it took me a second to understand the structure of this sentence, can we insert an `and` after the `record's timestamp`?",0,0.9905654191970825
465399031,9039,ableegoldman,2020-08-05T00:13:33Z,extra `/*` here,0,0.9906628131866455
465399853,9039,ableegoldman,2020-08-05T00:16:39Z,technically this is an `xor` not an `or` :face_with_tongue:,0,0.9891506433486938
465400403,9039,ableegoldman,2020-08-05T00:18:42Z,"can you revert the line changes here and below? nothing wrong with them, but the fewer lines/classes changed in the pr, the better",0,0.9821375608444214
465401189,9039,ableegoldman,2020-08-05T00:21:40Z,"think you missed changing this in the cogrouped class, this should be 2*timedifference right?",0,0.9670764803886414
465402473,9039,ableegoldman,2020-08-05T00:26:16Z,i think we need a null check here like we have down in `slidingwindowedkstreamimpl#materialize`,0,0.9914161562919617
465407448,9039,ableegoldman,2020-08-05T00:45:26Z,+1 to add a comment on the extra retention (here and in slidingwindowedcogroupedkstreamimpl),0,0.9801133871078491
465407638,9039,ableegoldman,2020-08-05T00:46:16Z,should be `no smaller than twice its window time difference...`,0,0.9896920323371887
465408876,9039,ableegoldman,2020-08-05T00:50:59Z,"+1 to using a random number instead of multiple lines. if it does happen to fail on a specific random number, we should be sure to print that number for reproducing it later. see taskassignorconvergencetest#runrandomizedscenario for example",0,0.9870563745498657
465409330,9039,ableegoldman,2020-08-05T00:52:44Z,"took me a second to understand this test, ""negativecases"" made me think the timedifference/grace were supposed to be negative. +1 to matthias's suggestion for naming (and splitting into two tests)",0,0.9532812237739563
465412482,9039,ableegoldman,2020-08-05T01:03:59Z,"can you leave a todo here to make sure we remember to change this to `reversefetch`? seems unlikely we'd forget, but you never know",0,0.9823452830314636
465414316,9039,ableegoldman,2020-08-05T01:11:09Z,"which check? i was just thinking that, since the window starting at record.timestamp + 1 is basically a special case, we can just pull it out of the loop completely. we don't have to update anything since the record doesn't fall into this window, right? basically just before entering the loop we check `if next.key.window().start() == timestamp + 1` and if so set `rightwinalreadycreated` and then skip to the next record",0,0.9639628529548645
465414863,9039,ableegoldman,2020-08-05T01:13:02Z,"we don't technically need `continue` at the end of each condition, right?",0,0.9762685298919678
465416585,9039,ableegoldman,2020-08-05T01:19:27Z,"awesome! i might still recommend pulling the `rightwinagg != null && rightwinagg.timestamp() > timestamp` check out into a method called `rightwindowisnonempty` or something, but it's definitely a lot easier to understand now even without that :grinning_face_with_smiling_eyes:",1,0.9932335019111633
465418942,9039,ableegoldman,2020-08-05T01:28:01Z,"we need to check `leftwinagg` for null, right? also, is it ever possible for `leftwinagg` to be non-null but not satisfy this condition? maybe we can just check `leftwinagg != null` and if so, then assert that `leftwinagg.timestamp() < timestamp && leftwinagg.timestamp() > timestamp - windows.timedifferencems()` is always true (eg throw an `illegalstateexception` if it's not)",0,0.9939337372779846
465419531,9039,ableegoldman,2020-08-05T01:30:09Z,can we remove the `math.max` thing for now and just drop records that are too early for us to process for now?,0,0.9915137887001038
465421190,9039,ableegoldman,2020-08-05T01:36:28Z,"just a note to other reviewers: we're planning to revisit the issue of ""early"" records later and are just dropping them for now to make the general algorithm easier to review and understand. it needs some special handling for the edge case of records that arrive earlier than the full sliding window due to the inability to store windows with negative start times",0,0.9862986207008362
465421265,9039,ableegoldman,2020-08-05T01:36:42Z,nit: put this on one line,0,0.9461385011672974
465421657,9039,ableegoldman,2020-08-05T01:38:18Z,comment doesn't seem to match the query bounds (missing a +1?),0,0.9847201108932495
465421880,9039,ableegoldman,2020-08-05T01:39:08Z,is there any reason this wouldn't just be `window.start + timedifferencems`?,0,0.9916837215423584
465424346,9039,ableegoldman,2020-08-05T01:48:06Z,"same here, let's not pin the start time to 0 for now and just drop the early records",0,0.9635621309280396
465425090,9039,ableegoldman,2020-08-05T01:50:32Z,"yeah especially since we use the same condition for both the forward and reverse case, let's just pull the `rightwinagg != null && rightwinagg.timestamp() > timestamp` out into a separate method",0,0.9894160628318787
465725011,9039,lct45,2020-08-05T13:26:48Z,"yeah that works unless the first window isn't the right window, in which case we would need to process it (save as the rightwinagg, update its aggregate if the current record falls into it, etc) before going to the next record at the top of the while loop. it definitely works and is what we had before, it just makes the code a little less clean.",0,0.9546871781349182
465751597,9039,lct45,2020-08-05T14:05:28Z,"hmmmm yeah, i think if there's something in the left window then we will always initialize `leftwinagg` to something other than null, good catch. we essentially check `leftwinagg.timestamp() < timestamp` in the while loop, so i don't think that should cause a problem, and `leftwinagg.timestamp() > timestamp - windows.timedifferencems()` will never be true because that window would be out of range, right? and we only take the first left agg. long way of saying, i think we can do the null check and nothing else but will know slightly more when we can test it",1,0.5592365860939026
465756356,9039,lct45,2020-08-05T14:12:12Z,"nope, since we aren't storing truncated windows",0,0.9627467393875122
466026007,9039,mjsax,2020-08-05T21:54:05Z,the ticket is already fixed. you need to pass in the `windowsize` into the the constructor of `timewindowdeserializer` to get rid of the problem.,0,0.9939939379692078
466028866,9039,mjsax,2020-08-05T22:00:39Z,"i guess testing both cases would be good. even if testing the former (fall outside of all existing windows) was my original intent. and thank for comment sophie: i tend to forget that we should produce all (non-empty) right windows already upfront/eagerly (and not delayed/lazily when stream-time advances beyond window-end time). in any case, it seems to be a good test case to make sure we don't (re-)emit an (unexpected) window if stream-time jumps ahead?",1,0.9588153958320618
466029116,9039,mjsax,2020-08-05T22:01:14Z,ack. was just a thought.,-1,0.9446491003036499
466032331,9039,mjsax,2020-08-05T22:09:37Z,"we pass in all parameter to sharing to code that creates the `statefulprocessornode` -- not sure if it's the best way to structure the code and i am happy to split it up into multiple methods call (as long as we avoid code duplication). and yes, you are right, it's internal and the checks are just for us to avoid programming errors. users should never be exposed to it. i personally tend to make a lot of mistakes and the more checks we have in place the better imho :) if want's she can just do a side cleanup pr to fix it, and rebase this pr after the cleanup pr was merged? or we do it as follow up. whatever works best for you.",1,0.9928945899009705
466032804,9039,mjsax,2020-08-05T22:10:51Z,thanks for confirming. let keep this issue out for this pr than.,1,0.9353839159011841
466033381,9039,mjsax,2020-08-05T22:12:25Z,i am not a native speaker... don't ask me... mr.john should know -- he has the proper education for it.,-1,0.7125169038772583
466042505,9039,lct45,2020-08-05T22:38:04Z,"that should be covered in `kstreamslidingwindowaggregatetest`, which goes through more of the edge cases using the `topologytestdriver` which is a little easier to manipulate than this set up",0,0.9937445521354675
466050097,9039,ableegoldman,2020-08-05T23:00:38Z,"well, if the first window isn't the right window then we just wouldn't call `iterator.next` again, right? so we wouldn't have to do anything at all",0,0.9913557171821594
466051779,9039,ableegoldman,2020-08-05T23:05:45Z,"ok cool, just checking. either `endtime = window.start + timedifferencems` or `endtime = window.end` is fine as long as we're consistent (i guess we only define it in two places, the forward and reverse algorithms?)",0,0.5317910313606262
466052825,9039,ableegoldman,2020-08-05T23:08:41Z,"sounds good. we definitely need the null check just to avoid getting an npe, but whether we _only_ need the null check is something we should put to the test",1,0.7351725101470947
466063583,9039,ableegoldman,2020-08-05T23:42:35Z,"no she's right, this problem is not resolved at all. you can pass in `windowsize` to the constructor for `timewindoweddeserializer` all you want but it just gets ignored because the actual deserializer object you instantiate is thrown away. whether you're reading in records through a java consumer or the console consumer (for some reason this test does both), the actual deserializer is always constructed within the consumer based on the configs. there's a config for the windowed inner class which is properly set in `timewindoweddeserializer#configure` but no config for the `windowsize` so there's no way to set it at the moment. tl;dr there's no point in having serde constructors accept parameters, they need to be set through `configure`",0,0.9913452863693237
466070317,9039,lct45,2020-08-06T00:05:50Z,created a ticket for this here: [a link] let me know if the description isn't clear,0,0.9877275228500366
466425932,9039,lct45,2020-08-06T13:49:17Z,"i'm happy to do a pr! looking into it now though, `getstatefulprocessornode` is called by `build`, so i think to really separate it by type we'd need a different `build` _and_ `statefulprocessornode`, otherwise we'd be moving the null checks into `build` and then calling the correct `getstatefulprocessornode`, which does't seem to really fix anything. thoughts? it's easy to create new `build` functions but i figured this might fall under not avoiding code duplication :)",1,0.9956498742103577
466618450,9039,ableegoldman,2020-08-06T18:52:07Z,"i do think we'd need separate `build` methods, since that's where we originally accept multiple windows as arguments (where all but one type is set to null in each caller). but most of `build` doesn't touch the windows arguments so you could probably factor out all the window-independent code into a single method and just have each `build` method call that",0,0.9929459691047668
467231847,9039,mjsax,2020-08-07T19:33:46Z,thanks. i missed the point that this trick to pass in the windowsize only works for kafkastreams when we pass in `serdes` object that are used as provided...,1,0.9769465327262878
467260318,9039,lct45,2020-08-07T20:44:35Z,"sounds good, i'll change that when i implement the reverse iterator in the next pr",0,0.5702214241027832
467296111,9039,ableegoldman,2020-08-07T21:50:49Z,clearly kafka streams is superior to the plain consumer :smiling_face_with_horns:,0,0.9839107990264893
468214782,9039,vvcephei,2020-08-10T22:11:47Z,"haha, my specialty! the distillation of this sentence is ""windows are defined based on a record's timestamp, window size, and window grace period."" i think the meaning is pretty clear, so no need to change anything. just to point it out, there's structural ambiguity about whether the sentence is saying ""a record's (timestamp, window size, window grace period)"" (i.e., three properties of the record), or whether there are three top-level things that define the window. the latter was intended. i think actually inserting ""the"" before ""window"" both times would clear it up: ""windows are defined based on a record's timestamp, the window size, and the window grace period."" another note is that because the second item in the list is so long, the structure of the list gets a little lost. it would be better in this case to use the oxford comma to clearly delineate the boundary between the second and third items. so, although i think this is fine as-is, if you want me to break out the red pen, i'd say: [code block]",1,0.9835270047187805
468216620,9039,ableegoldman,2020-08-10T22:16:48Z,comment on the reverse case left behind,0,0.9909802079200745
468217437,9039,ableegoldman,2020-08-10T22:19:00Z,nit: extra line breaks,-1,0.5187911987304688
468217987,9039,ableegoldman,2020-08-10T22:20:29Z,you should check to make sure all of these are still needed. in particular i bet we can get rid of the cogroupedstreamaggregatebuilder suppression once your cleanup pr is merged and this one is rebased,0,0.9842674136161804
468218540,9039,ableegoldman,2020-08-10T22:22:02Z,i think we usually leave the arguments on the same line as the method declaration (even if that line ends up way too long),0,0.9799602627754211
468219113,9039,ableegoldman,2020-08-10T22:23:34Z,"kind of hard to tell, but is the alignment in this method a bit off? might be good to just highlight and auto-indent everything, intellij will take care of any issues if it's configured properly",0,0.7204611301422119
468290069,9039,ableegoldman,2020-08-11T02:28:07Z,nit: extra spaces after the `->`,0,0.9870584607124329
468291563,9039,ableegoldman,2020-08-11T02:34:01Z,"the input is the same for each test so the output is too, right? maybe we can we pull all the output verification into a single method",0,0.9893765449523926
468292711,9039,ableegoldman,2020-08-11T02:38:04Z,"can we add some tests to verify the other materialized properties, specifically the retention? you can just pick a single operator (eg `reduce`) and write a test to make sure data is available (only) within the retention period. also, do you think we can write a test to verify that the default retention is as expected when we don't specify it?",0,0.9930603504180908
468293244,9039,ableegoldman,2020-08-11T02:40:05Z,"this comment needs to be updated, looks like we do allow a grace period of zero in the code/tests",0,0.9917171597480774
468293930,9039,ableegoldman,2020-08-11T02:42:39Z,`assertthrows` :slightly_smiling_face:,0,0.9784705638885498
468294181,9039,ableegoldman,2020-08-11T02:43:41Z,"awesome, thanks for cleaning up some of these older tests :grinning_face_with_smiling_eyes:",1,0.9941447377204895
468653951,9039,lct45,2020-08-11T15:07:03Z,"i pulled it out for all except one, because there's one call to `windowstore` that returns a ` , long>` and the other calls to `windowstore` return a ` , string>`",0,0.9848981499671936
468690429,9039,lct45,2020-08-11T15:58:35Z,"i'm not sure if i'm just missing something, but it doesn't look like there's a way to check what retention is. i created a test to make sure anything lower than our bound throws an exception, but i can't find anywhere the retention time is exposed for me to check what it's set to",0,0.5243645310401917
468796354,9039,lct45,2020-08-11T18:53:42Z,update: the windows themselves are the same but the value is different for each test,0,0.9864245057106018
468814368,9039,ableegoldman,2020-08-11T19:27:39Z,"yeah sorry i should have been more clear, i just meant push some data through and try to query the store to make sure it is/isn't there according to the retention period. you're right, it's not directly exposed anywhere",-1,0.9823175668716431
471797422,9039,ableegoldman,2020-08-17T21:57:26Z,do we still need this one after the cleanup you did?,0,0.9927290081977844
471798256,9039,ableegoldman,2020-08-17T21:59:31Z,"[code block] also i think this set is pretty clearly named, so we probably don't need a comment for it",0,0.9636445641517639
471798801,9039,ableegoldman,2020-08-17T22:00:50Z,nit: can we use the full word `window` in method names at least,0,0.9925651550292969
471801743,9039,ableegoldman,2020-08-17T22:08:09Z,"nit: you could use the version of `fetch` that just takes a single key instead of a key range, since there's only one key here",0,0.9938387274742126
471820115,9039,ableegoldman,2020-08-17T23:01:12Z,"can we insert one that's like right on the border of the retention period? so if the streamtime at the end is 2,000 then the window cut off is 800 (or start time of 700), and verify that anything starting before 699 is gone and everything after that is there.",0,0.9938649535179138
471823061,9039,ableegoldman,2020-08-17T23:09:53Z,"for readability, could we mark the final results for each window? we want to make sure all the intermediate results are as expected, but what we really care about is what we got in the end. it would just help to have the critical output easier to find and get oriented in the tests",0,0.9850428104400635
471824209,9039,ableegoldman,2020-08-17T23:13:31Z,it might be nice to use different values for each record (at least within the same key). i don't think there are really any edge cases we should worry about when records have the same value so we may as well use a distinct one to make the tests a bit easier to read,0,0.9833569526672363
471825457,9039,ableegoldman,2020-08-17T23:17:24Z,"i still don't exactly understand why we have a join test in the `kstreamxxwindowaggregatetest`, but thanks for adding it for sliding windows. i'm sure there was a good reason for it, probably long ago",0,0.8611606359481812
471827371,9039,ableegoldman,2020-08-17T23:23:35Z,"sorry that i only just got to looking through this class :disappointed_face: . the tests here look good but can we add some more test coverage of possible edge cases? i know we can't test early records until the next pr, but we should probably have more than just the one test of the core functionality. i know it's really annoying to have to think through all the intermediate output, so maybe you can write a helper method that just grabs the final result of each window in the output? then we could have a number of tests that go through a larger number of input records without you having to spend all day manually processing them yourself :grinning_face_with_smiling_eyes:",-1,0.9938111901283264
472436400,9039,lct45,2020-08-18T19:41:02Z,we don't!,0,0.4029281437397003
472440045,9039,lct45,2020-08-18T19:48:20Z,"that `fetch` only returns a `windowstoreiterator` instead of a `keyvalueiterator`, which i don't think is a huge deal but we wouldn't get the start/end time of the window which is nice to have for the test",0,0.8316823840141296
472441802,9039,ableegoldman,2020-08-18T19:51:48Z,"oh right, forgot that it doesn't have the window times either. nevermind then",-1,0.6732460856437683
474966465,9039,ableegoldman,2020-08-21T20:59:10Z,"can we actually wrap the whole `testprocessorrandominput` test in the try-catch? or at least, everything after the initial setup? would be nice to have the seed in case something weird happens during the processing itself",0,0.9908992052078247
474977836,9039,ableegoldman,2020-08-21T21:28:42Z,"just a minor note, can we order the expected results by window timestamp?",0,0.9907664060592651
475919413,9039,ableegoldman,2020-08-24T22:02:05Z,"nit: can you call this something a bit more direct, eg `verifyrandomtestresults` ?",0,0.9897368550300598
475922761,9039,ableegoldman,2020-08-24T22:10:32Z,nit: `testaggregaterandominput` to match up with other test names,0,0.9940235018730164
475923788,9039,ableegoldman,2020-08-24T22:13:19Z,can you leave a brief comment here explaining why we're doing something slightly more complicated in the aggregator for this test,0,0.979347288608551
478518760,9039,vvcephei,2020-08-27T15:45:49Z,"i'm reviewing this whole pr as-is, so there's no need to do anything now, but 's specific suggestion is beside the point. the general feedback is that this pr is too large, which it is. we shoot for under 1k, and it's the pr author's responsibility to figure out the best way to break it up. this policy isn't just ""reviewers complaining,"" it's an important component of ensuring ak's quality. long prs overwhelm any reviewer's cognitive capacity to pay attention to every detail, so oversights are more likely to slip through into the codebase, and once they're there, you're really at the mercy of the testing layers to catch them. when the oversights are very subtle, they wind up getting released and then surface as user-reported bugs. reviewers can't guarantee to notice every problem, but our capacity to notice problems is inversely proportional to the length of the pr.",0,0.5778418183326721
478627800,9039,vvcephei,2020-08-27T18:53:31Z,"is this condition supposed to be checking whether records are ""early"" with respect to now? it looks like it should be: [code block]",0,0.9918658137321472
478664149,9039,vvcephei,2020-08-27T20:03:13Z,minor: this could be declared `final` at the assignment on line 161,0,0.993790328502655
478669986,9039,vvcephei,2020-08-27T20:14:32Z,might not be a bad idea to have an assertion here that the timestamp is actually in the window boundaries.,0,0.9238643646240234
478671190,9039,vvcephei,2020-08-27T20:16:55Z,"is it already guaranteed that this window actually contains the current record? it doesn't look like we're checking that `endtime >= timestamp` anywhere, and it seems like the start of the range (`timestamp - 2 * windows.timedifferencems()`) could give back a window that starts and ends before the current record's timestamp.",0,0.9919105172157288
478702517,9039,vvcephei,2020-08-27T21:20:46Z,"the achilles heel of implementing new ktable features has historically been that we forgot to test them in a context that required the valuegetter to work properly, of which join is a notable use case. i'd actually say it should be required for every ktable operator to have a test where it's the source of a join. for stateless operators, we should test both with and without a materialized argument on the operator.",0,0.988175630569458
478703452,9039,vvcephei,2020-08-27T21:22:51Z,"i'd normally say we should have a test also to verify we log properly on early records, but you already opened the pr to add early record handling, so we're good.",0,0.9378497004508972
478704359,9039,vvcephei,2020-08-27T21:24:45Z,awesome test. thanks!,1,0.995972216129303
478705942,9039,vvcephei,2020-08-27T21:28:18Z,"aside from join, forgetting to test new operators in front of suppress has also been an issue. it's great to see this test here!",1,0.992281973361969
478707997,9039,vvcephei,2020-08-27T21:32:52Z,"coming back to this after completing the review, i'd say the biggest advice i'd share is to avoid whitespace changes and cleanups on the side when the pr is so long already. in fact, for my own super-complex prs, i tend to go back over the whole diff and back out anything that's not critically important, just to lighten the load on the reviewers. cleanups are nice to have, but it's better to keep them in their own prs or in more trivial ones.",0,0.8441809415817261
478715664,9039,ableegoldman,2020-08-27T21:50:34Z,"no, the condition is correct. in this context ""early"" just means ""within timedifferencems of the zero timestamp"". we need some special handling to cover this full range of all record timestamps due to the inability to store negative timestamps. this algorithm works correctly for all records outside of this regardless of ""now""",0,0.9889095425605774
478716769,9039,ableegoldman,2020-08-27T21:53:00Z,"to be honest, it might not be so bad to just leave things as is and drop early records, since any sensible timestamps are unlikely to be that close to the epoch. but i do believe users may want to use lower timestamps in their unit testing (`1598565116374` is not a very human readable number) and would be surprised to see these records just dropped.",0,0.8118953108787537
478717127,9039,ableegoldman,2020-08-27T21:53:52Z,"aha, so there was a good reason for it :grinning_face_with_smiling_eyes:",1,0.5596401691436768
478726427,9039,lct45,2020-08-27T22:17:40Z,is that possible? it's reassigned for every iteration of the `while()`,0,0.9940845370292664
478728829,9039,lct45,2020-08-27T22:24:19Z,"while the range might give a window that starts and ends before the current record's timestamp, the current record would fall into the right window of the records _within_ those windows. ex: timedifference = 10, record @ 30, range from (10,31). the earliest start time of a window we can have is 10, so the earliest `lefttypewindow` we can find is from [10,20]. if there's a record at 2, it's right window would be [21,31], which our record @ 30 would fall within. because this is true for the furthest possible record, it'll be true for the others that we find.",0,0.9894974231719971
478730796,9039,lct45,2020-08-27T22:29:46Z,"i don't think that would be true all the time, since the current record's right window wouldn't contain the current record and is created through this method. if it helps for clarity, i can add a check that if we're _not_ creating the right window then the timestamp needs to be within the window, and otherwise confirm that we're creating the right window",0,0.9885071516036987
478751787,9039,ableegoldman,2020-08-27T23:35:06Z,"i think he means, instead of declaring it once up here and then reassigning it every iteration, we can just do `final keyvalue<> next = iterator.next()` down on line 161. we don't need it outside the loop",0,0.9870854020118713
478753568,9039,lct45,2020-08-27T23:41:39Z,"aha, that makes sense",0,0.5633538365364075
478756346,9039,ableegoldman,2020-08-27T23:51:15Z,"now that you bring it up, that's kind of a weird case for this method, and it's currently handled in a pretty subtle way. for example down on line 233 we are effectively checking for this case, and line 234 just happens to work correctly for it. but it's not at all obvious that we're even handling this case. can we avoid the ternary operator when setting `newagg` and `newtimestamp` and just use a normal if/else to explicitly set both of these for the special case? (ie `if (windowstart == timestamp + 1)`...)",-1,0.7883846163749695
479344784,9039,vvcephei,2020-08-28T14:32:35Z,"thanks. from the other thread, it sounds like i misunderstood `putandforward` as adding the `value` to the `window`.",1,0.7331112623214722
479362665,9039,lct45,2020-08-28T15:01:33Z,"yeah it's definitely vague, i'll update",-1,0.8727350234985352
480429410,9039,vvcephei,2020-08-31T22:16:28Z,thanks for the confirmation! i agree with your thinking.,1,0.9358517527580261
1655160528,16456,apoorvmittal10,2024-06-26T16:15:11Z,is it possible to use `default_client_rack` already defined in configs?,0,0.9954177141189575
1655173636,16456,apoorvmittal10,2024-06-26T16:25:12Z,nit: [code block],0,0.9847351312637329
1655178863,16456,apoorvmittal10,2024-06-26T16:27:31Z,query: can you please help what issue actually occurs and why we need to update the cache i.e. how can the cache eviction be prevented with the cache update?,0,0.9927839040756226
1655181963,16456,apoorvmittal10,2024-06-26T16:28:54Z,query: is it always guranteed that a non-null share session will exist?,0,0.9928684830665588
1655189309,16456,apoorvmittal10,2024-06-26T16:31:53Z,nit: should we declare the helper methods post `handle` methods?,0,0.9939070343971252
1655198343,16456,apoorvmittal10,2024-06-26T16:35:14Z,nit: do we need this or can work with existing `randombytes`?,0,0.9941991567611694
1655203506,16456,apoorvmittal10,2024-06-26T16:37:46Z,where does this mocked version used later? if we don not define the setter of sharpartitionmanager then ll it make a difference?,0,0.9934595823287964
1656904716,16456,chirag-wadhwa5,2024-06-27T10:37:57Z,it should not make a difference. i removed the mock and passed optional.empty() in setsharepartitionmanager method. did the same in metadatarequestbenchmark.java as well,0,0.9944608211517334
1656905232,16456,chirag-wadhwa5,2024-06-27T10:38:27Z,"didn't realise the existence of randombytes. made the amends, thanks for the review",1,0.8326153755187988
1660544030,16456,chirag-wadhwa5,2024-07-01T06:40:32Z,"upon going through the code again, i guess with the new changes it doesn't make sense at all to update the cache here at all. with no asynchronous process happening between the 2 updates, the second update could be removed altogether. i have made the required changes in the most recent commit. thanks",1,0.8393118381500244
1660544678,16456,chirag-wadhwa5,2024-07-01T06:41:12Z,removed this method in the latest commit. pls refer to the reply for above comment for further context. thanks !,1,0.9592530131340027
1662479127,16456,apoorvmittal10,2024-07-02T13:04:06Z,"time is already defined in the class, can we please re-use that: [code block]",0,0.9896892309188843
1662482911,16456,apoorvmittal10,2024-07-02T13:06:44Z,i don't see `option` suffix for other optionals in this class: [code block],0,0.984485387802124
1662487187,16456,apoorvmittal10,2024-07-02T13:09:35Z,should we be relying on this config for `share groups`?,0,0.994789719581604
1662490711,16456,apoorvmittal10,2024-07-02T13:11:53Z,"are we introducing this config to ak, i do not see the config in the kip `group.share.enable`. cc:",0,0.9936368465423584
1662494555,16456,apoorvmittal10,2024-07-02T13:14:08Z,can we move this line after checking whether `sharepartitionmanageroption` has a value?,0,0.992154061794281
1662497106,16456,apoorvmittal10,2024-07-02T13:15:51Z,"do we need `()` or can work without them as like elsewhere, can we please be consistent. [code block]",0,0.9923906922340393
1662497519,16456,apoorvmittal10,2024-07-02T13:16:09Z,same as above and elsewhere.,0,0.9890658855438232
1662550023,16456,apoorvmittal10,2024-07-02T13:39:36Z,can we delay the fetch of this when actually it's required later?,0,0.9908480644226074
1662556294,16456,apoorvmittal10,2024-07-02T13:42:22Z,"it's odd to see that we need to expose `cachedtopicidpartitionsinsharesession` externally. we should not have the release api to have `list topicidpartitions`, only `string groupid, string memberid` should be sufficient. can we please change the `releaseacquiredrecords` api to below, and use `cachedtopicidpartitionsinsharesession` internally only? cc: [code block]",-1,0.5786890387535095
1662566850,16456,apoorvmittal10,2024-07-02T13:47:01Z,"i hardly see much of `breakable` usage in entire `kafka` repository. how does the other part of code `breaks` in scala, any idea?",0,0.928335964679718
1662638990,16456,apoorvmittal10,2024-07-02T14:26:48Z,any advise what's the best way to write such code in scala and kafka?,0,0.9915591478347778
1662644808,16456,apoorvmittal10,2024-07-02T14:29:43Z,"can we declare variables when needed. it's anyways tough to read scala code with `def` inside `def`, declaration of variables without order makes it harder.",0,0.5559571385383606
1662653794,16456,apoorvmittal10,2024-07-02T14:34:04Z,"i am not sure what does this case means i.e. is this check required? if yes, then what handling is done when `sharefetchresponse` is not returned by the method call i.e. how it further gets handled? shouldn't we complete the request and return right away?",0,0.9446356296539307
1662666354,16456,apoorvmittal10,2024-07-02T14:40:39Z,"why the validation of the request is done later prior initializing context and other processing, shouldn't that be the first step?",0,0.9933405518531799
1662673852,16456,apoorvmittal10,2024-07-02T14:44:40Z,query: why do we only authorize in subsequent request i.e. when acknowledge data is present?,0,0.9928848147392273
1662675191,16456,apoorvmittal10,2024-07-02T14:45:14Z,shouldn't this be an `async` call?,0,0.992756187915802
1663148002,16456,apoorvmittal10,2024-07-02T20:43:48Z,can i get review on this please: [a link],0,0.9417942762374878
1663964233,16456,chirag-wadhwa5,2024-07-03T10:26:58Z,"hi, thanks for the review. yes this check is required here, because `sharepartitionmanager.newcontext` might throw errors during its execution. initially, `sharefetchresponse` is defined as a null there. if an error is thrown, then its value is set as an error response. after this check, the acknowledging and fetching only proceeds if `sharefetchresponse` is null. if it is not null, then a final `sharefetchresponse` object is prepared with the error code and appropriate values for the acknowledgements and sent back to the user",0,0.5059151649475098
1663972187,16456,chirag-wadhwa5,2024-07-03T10:33:18Z,"hi, thanks for the review. according to my knowledge, this auth check is only required for acknowledgement and not for fetching. so, if there's nothing to acknowledge, there won't be any need for this auth check.",1,0.9128297567367554
1663976290,16456,chirag-wadhwa5,2024-07-03T10:36:55Z,"thanks for the review. `handleacknowledgements` would internally call `acknowledge` in `sharepartitionmanager`, which is an asyn function returning a future. according to the code that we already have in kip-932 branch, `handleacknowledgements` method returns the value by waiting for the future to execute completely. so, this piece is synchronous. we can maybe return a future from `handleacknowledgements` and wait for its completion here here, but i'm not sure how would that help us in any way.",0,0.5424670577049255
1664101522,16456,apoorvmittal10,2024-07-03T12:21:03Z,"are these intended changes, if yes then we shall have it in separate pr.",0,0.9916097521781921
1664119319,16456,chirag-wadhwa5,2024-07-03T12:34:51Z,"yes, the commit history got changed a bit. it should be fine now with the latest push in place",0,0.9498053789138794
1664122712,16456,apoorvmittal10,2024-07-03T12:37:31Z,is this method being used anywhere now?,0,0.9917782545089722
1664131801,16456,apoorvmittal10,2024-07-03T12:44:00Z,"my concern is on below code, should we complete the api call if `errorresponse` is constructed? ``` case e: exception => sharefetchresponse = sharefetchrequest.geterrorresponse(abstractresponse.default_throttle_time, e) match { case response: sharefetchresponse => response case _ => null",0,0.9859764575958252
1664144313,16456,chirag-wadhwa5,2024-07-03T12:53:07Z,"nope, already taken care of in the latest commit. thanks",1,0.7345473170280457
1664178535,16456,adixitconfluent,2024-07-03T13:17:19Z,"i agree with , seeing the `newcontext` function, the possible errors are `invalid_request`, `share_session_not_found` and `invalid_share_session_epoch`. in all such cases, we should be completing the api call with a top level error code there itself.",0,0.9935975074768066
1664193628,16456,adixitconfluent,2024-07-03T13:27:03Z,we can remove this check if we return the api response with top level error code wherever it occurs. wdyt -wadhwa5 ?,0,0.9932610392570496
1664202015,16456,adixitconfluent,2024-07-03T13:32:33Z,"comment should say ""share"" instead of ""regular""",0,0.9940886497497559
1664266986,16456,adixitconfluent,2024-07-03T14:14:03Z,"can we not club all of this ""if"" and the below ""if"" conditions into a single if?",0,0.9908429384231567
1664271714,16456,adixitconfluent,2024-07-03T14:17:13Z,not sure if these dummy values are the ones we want to go ahead. perhaps / would know better which values to use here?,0,0.9817558526992798
1664273428,16456,adixitconfluent,2024-07-03T14:18:21Z,"nit: instead of partitions.size, maybe use partitions size",0,0.9927090406417847
1664275271,16456,adixitconfluent,2024-07-03T14:19:23Z,"nit: add a ""."" at the end of comment. can you do this for other added comments as well?",0,0.9898264408111572
1665550477,16456,AndrewJSchofield,2024-07-04T11:08:41Z,"i think so, at least for now. the eventual switch will be `group.version=2` as the second version of the new group coordinator feature. unfortunately, `group.version` has been backed out and will not be re-introduced until 4.0. this is an internal (undocumented) config for the broker. it does the necessary thing, which is to enable the new gc, so it seems like a safe temporary answer here.",0,0.99115389585495
1665552665,16456,AndrewJSchofield,2024-07-04T11:10:49Z,"it's an internal (undocumented) configuration. as mentioned above, the configuration we are using is temporary for now. i'm happy with it being used until we get the real configs in place.",0,0.6769076585769653
1665590294,16456,chirag-wadhwa5,2024-07-04T11:45:24Z,"that makes sense. thanks for the review, will make the changes in the next commit",1,0.91538006067276
1665592992,16456,chirag-wadhwa5,2024-07-04T11:47:48Z,"thanks for the review ! yes we can but i did that for better readability, without affecting the execution at all.",1,0.9833202958106995
1665594694,16456,chirag-wadhwa5,2024-07-04T11:49:18Z,"yes, i wanted to have a discussion regarding these dummy values with as well",0,0.9785125255584717
1665597002,16456,chirag-wadhwa5,2024-07-04T11:51:28Z,thanks for the review. i think i copied this comment from the regular fetch request implementation. but yeah its very trivial. i will make the change in the next commit.,1,0.9647291302680969
1665633847,16456,apoorvmittal10,2024-07-04T12:22:03Z,"i find following line from the kip which says following, hence shouldn't we authorize for read on fetch as well? ``` operations which change information about a share group (such as consuming a record) need permission to perform the read action on the named group resource",0,0.9909111857414246
1665637301,16456,apoorvmittal10,2024-07-04T12:25:03Z,"also, do we need to re-authorize on every request in session? what behaviour we have on regular fetch? does it authorize everytime or once in session? if we do it only at session establishment, i do get that if an api key is unauthorized then existing session might continue reading/acknowledging, but re-authorization is taxing as well. hence checking what's the flow looks like on regular fetch. cc:",0,0.9203320741653442
1665642977,16456,apoorvmittal10,2024-07-04T12:29:40Z,"hmmm, this is not clean. why can't we have `handleacknowledgements` api to receive `mutable.map[topicidpartition, util.list[shareacknowledgementbatch]]`? then `sharefetch` and `shareacknowledgerequest` can send respective data to `handleacknowledgements` method and we need not to use `asinstanceof` or any type casting.",0,0.8338438868522644
1665645855,16456,apoorvmittal10,2024-07-04T12:32:05Z,isn't the `sharepartitionmanager.acknowledge` already implemented?,0,0.9947210550308228
1665661239,16456,apoorvmittal10,2024-07-04T12:44:44Z,"i do not see any futures handled here hence this maked the processing synchronous, irrespective if other api calls to sharepartitionmanager are async. moreover i am failed to understand the behaviour of `handleacknowledgements` method i.e. i do see `shareacknowledgeresult` is returned right away but there might be a delay in getting reposne from `sharepartitionmanager.acknowledge` method hence how that's handled?",0,0.9856805801391602
1665668978,16456,apoorvmittal10,2024-07-04T12:51:03Z,"should we throw an exception here of complete the request by unsupported version error? what's followed in other apis? for kip-714, i added something below: ``` case none => info(""received get telemetry client request for zookeeper based cluster"") requesthelper.sendmaybethrottle(request, subscriptionrequest.geterrorresponse(errors.unsupported_version.exception))",0,0.9930086135864258
1665672326,16456,apoorvmittal10,2024-07-04T12:53:41Z,i see this is a copy from `fetch` but do we need to define same functionality again or create a common `def/method` for both?,0,0.994845986366272
1665676287,16456,apoorvmittal10,2024-07-04T12:56:43Z,shouldn't this be like below? [code block],0,0.9917851686477661
1665689981,16456,apoorvmittal10,2024-07-04T13:07:43Z,"do you need `asjava` conversion just ofr iteration? if yes, then aren't there better way in scala? [code block]",0,0.9930468201637268
1665702943,16456,apoorvmittal10,2024-07-04T13:18:08Z,"isn't the response is already returned and this is async call, what does `requesthelper.handleerror(request, throwable)` does then?",0,0.99338299036026
1665708594,16456,apoorvmittal10,2024-07-04T13:22:52Z,"hmm the whole processing is `synchronous`, why can't we work with callbacks i.e. when complete?",0,0.9771534204483032
1665714440,16456,apoorvmittal10,2024-07-04T13:27:37Z,can you please write comment regaridng what exaclty is happening and why we are going to modify the `sharefetchresponse` later? i am not sure if there is a better way of combinig 2 responses and construct `sharefetchresponse` just once rather first generating it in fetch and then modifying same.,0,0.9833887815475464
1665777016,16456,chirag-wadhwa5,2024-07-04T14:18:10Z,"as per my knowledge the regular fetch does not authorize for read operation on the named group. only the topics from where data is to fetched, are authorized for read operation",0,0.9881184697151184
1665987792,16456,apoorvmittal10,2024-07-04T18:19:48Z,should it be in `error`?,0,0.9944487810134888
1665988915,16456,apoorvmittal10,2024-07-04T18:22:26Z,should it be `private def`?,0,0.99359130859375
1665990669,16456,apoorvmittal10,2024-07-04T18:26:06Z,"i am not sure how costly the api for `asscala` on map is, but should have some cost, so do you want to have conversion in foreack loop?",0,0.8111235499382019
1665993309,16456,apoorvmittal10,2024-07-04T18:31:49Z,"does `topicidnames` seems better? it was hard to relate later in the code what this variable holds, seems more like just name of topics.",0,0.9879568219184875
1665994321,16456,apoorvmittal10,2024-07-04T18:33:51Z,do we validate somewhere that partition index exists for the topic i.e. what if client request for partition 5 when there exists only 4 partitions for topic?,0,0.9946001768112183
1665995004,16456,apoorvmittal10,2024-07-04T18:35:15Z,what exception is being thrown?,0,0.9288676977157593
1665995891,16456,apoorvmittal10,2024-07-04T18:37:21Z,"yeah it's much readable this way, i agree.",1,0.6635327339172363
1665996271,16456,apoorvmittal10,2024-07-04T18:38:21Z,will it not be better to mock `sharepartitionmanager`?,0,0.9934065341949463
1665997840,16456,apoorvmittal10,2024-07-04T18:41:18Z,"this change will be not needed if we use mock, that we should.",0,0.9877572059631348
1665998426,16456,apoorvmittal10,2024-07-04T18:42:41Z,nit: would it better to have these methods defines later when used in tests?,0,0.9918002486228943
1666000193,16456,apoorvmittal10,2024-07-04T18:46:23Z,"seems the methods are same as defined in `sharepartitiontest`, shall we move them to common test utils (in java)?",0,0.9956931471824646
1666000611,16456,apoorvmittal10,2024-07-04T18:47:18Z,"i see we are using mock here, why not to define it on the top itself?",0,0.9898679256439209
1666001021,16456,apoorvmittal10,2024-07-04T18:48:11Z,is `asjava` required? isn't it already a java api?,0,0.9936000108718872
1666723067,16456,chirag-wadhwa5,2024-07-05T12:00:46Z,i think it should be just return. `completablefuture.completedfuture[unit](())` shouldn't be there at all because return type of `handlesharefetchrequest` is `unit` and not `completablefuture[unit]`,0,0.9927065968513489
1666735395,16456,chirag-wadhwa5,2024-07-05T12:14:10Z,"yep, this doesn't make sense. if there is an error here, the broker will send out 2 responses for that. i have changed this to the following logic - 1) if throwable is not null, it will simply throw the throwable. 2) i have surrounded the call of `combinesharefetchandshareacknowledgeresponses` with a try catch. if error is not thrown then `requestchannel.sendresponse` with appropriate arguments. if error is thrown, then `requesthelper.handleerror(request, throwable)` with appropriate arguments. also change the log from debug to error here.",0,0.9248948693275452
1668159303,16456,chirag-wadhwa5,2024-07-08T07:55:34Z,"this was a mistake, will remove the try catch block. thanks!",1,0.9917886853218079
1668342690,16456,chirag-wadhwa5,2024-07-08T09:55:53Z,"thanks for the review. actually yes it is required, since the list() is a scala list. there are other ways that do not use asjava, but they span over multiple lines, and would require new variable initialisations, reducing the code readability.",1,0.9120776653289795
1669768302,16456,chirag-wadhwa5,2024-07-09T05:47:45Z,hi thanks for reviewing. i think the first occurrence of these methods is in the test just underneath them. isn't that what you mean here ?,1,0.9056746959686279
1669815168,16456,chirag-wadhwa5,2024-07-09T06:31:01Z,"yep, the true place for these methods should be in testutils file, but both sharepartitiontest and kafkaapistest import separate testutils files. sharepartitiontest use the java one and kafkaapistest use the scala one. as far as i know, java does not support aliasing and neither do the older versions of scala.",0,0.9776001572608948
1669817534,16456,chirag-wadhwa5,2024-07-09T06:33:40Z,not currently. i think that can be done using the metadatacache which is accessible in the kafkaapis. i will create a separate jira for this. thanks !,1,0.981510579586029
1672098926,16456,apoorvmittal10,2024-07-10T11:24:59Z,i raised a query earlier regaridng why we only want to authorize when acknowledgements exist?,0,0.9878876209259033
1672102704,16456,apoorvmittal10,2024-07-10T11:28:08Z,why do we require `.get` here? will it not block the calls?,0,0.983306884765625
1672103745,16456,apoorvmittal10,2024-07-10T11:28:57Z,why this exception is only about `release`?,0,0.9809751510620117
1672106900,16456,apoorvmittal10,2024-07-10T11:31:48Z,i can find this comment is yet not addressed. i think we discussed that the code shall be asynchronous. in case we are finding it difficult in this pr then please log a jira and work on it post merge of this pr.,0,0.9724186062812805
1672107334,16456,apoorvmittal10,2024-07-10T11:32:14Z,again we have a blocking call here.,0,0.9810448884963989
1672108309,16456,apoorvmittal10,2024-07-10T11:33:07Z,-wadhwa5 did you get a chance to work on this?,0,0.9835308194160461
1672109076,16456,apoorvmittal10,2024-07-10T11:33:49Z,why do we need `breakable` here?,0,0.9925640225410461
1672111524,16456,apoorvmittal10,2024-07-10T11:36:00Z,it's not that important but generally the helper method will come post the usage i.e. test -> helper method.,0,0.9846836924552917
1672112684,16456,apoorvmittal10,2024-07-10T11:37:11Z,so why not to have either in java or scala test utils which can be used by both?,0,0.9924601912498474
1672113400,16456,apoorvmittal10,2024-07-10T11:37:47Z,do we have the jira now? can we please link here?,0,0.9881349802017212
1672117974,16456,apoorvmittal10,2024-07-10T11:41:46Z,yeah but kip-932 defines the behaviour for auth during fetch.,0,0.9441843628883362
1675361989,16456,chirag-wadhwa5,2024-07-12T06:05:25Z,"i think this log is not in the right place. the only thing that throws an exception in the try block is the releasing the acquired records part, moved this log to that position.",0,0.9394673109054565
1675585257,16456,chirag-wadhwa5,2024-07-12T09:30:47Z,created a separate jira to track this - [a link],0,0.9908456206321716
1675597142,16456,chirag-wadhwa5,2024-07-12T09:40:35Z,"hey yep, the jira has been created - [a link]",1,0.8660687804222107
1675597743,16456,chirag-wadhwa5,2024-07-12T09:41:04Z,created a jira - [a link],0,0.9867730736732483
1690482997,16456,junrao,2024-07-24T21:37:14Z,fetchoncomplete => onfetchcomplete?,0,0.992457389831543
1690501820,16456,junrao,2024-07-24T21:54:18Z,"for consistency, could we remove `this`?",0,0.9939915537834167
1690504262,16456,junrao,2024-07-24T21:56:13Z,this only happens in zk mode. we probably want to improve logging to reflect that.,0,0.9886800050735474
1690509290,16456,junrao,2024-07-24T22:00:30Z,we could get rid of {}.,0,0.9869124889373779
1690510398,16456,junrao,2024-07-24T22:01:36Z,we could get rid of {}. ditto in a few other places.,0,0.9897792935371399
1690517906,16456,junrao,2024-07-24T22:08:19Z,"instead of foreach, perhaps you could do `sharefetchrequest.data.topics.stream().anymatch` ?",0,0.9939476251602173
1690528671,16456,junrao,2024-07-24T22:24:41Z,the convention is to have no space before `:`. ditto in a few other places below.,0,0.9911600947380066
1690529065,16456,junrao,2024-07-24T22:25:21Z,space after `if`. ditto in a few other places below.,0,0.9928284287452698
1690566819,16456,junrao,2024-07-24T23:13:41Z,"hmm, should we get the partitions for fetch from sharefetchcontext instead from the request? the request may not include all partitions in the session since it can be incremental.",0,0.9916833639144897
1690594851,16456,junrao,2024-07-24T23:46:04Z,could this be private?,0,0.9903441071510315
1690595889,16456,junrao,2024-07-24T23:47:38Z,this comment seems out of place.,0,0.9153379201889038
1690596169,16456,junrao,2024-07-24T23:48:07Z,datas is weird since data is already the plural form of datum.,-1,0.9853353500366211
1690599349,16456,junrao,2024-07-24T23:53:51Z,interestingwithmaxbytes => interestedwithmaxbytes ?,0,0.9888317584991455
1690612220,16456,junrao,2024-07-25T00:14:57Z,could this block of code be replaced with sth like the following using lamda? [code block],0,0.9934993982315063
1691763015,16456,junrao,2024-07-25T16:17:40Z,sharefetch is implemented on the latest version of the client and understands all versions of the message format. why do we need to down convert here?,0,0.9907438158988953
1691773793,16456,junrao,2024-07-25T16:25:50Z,should we use consumer_replica_id?,0,0.9942374229431152
1691814103,16456,junrao,2024-07-25T16:45:35Z,"could this code just be `requesthelper.throttle(quotas.fetch, request, maxthrottletimems)`?",0,0.9950271248817444
1691823423,16456,junrao,2024-07-25T16:53:11Z,"if the response is not ready immediately, `combinesharefetchandshareacknowledgeresponses()` needs to be called asynchronously, right?",0,0.9944830536842346
1691825148,16456,junrao,2024-07-25T16:54:42Z,we could get rid of {} here.,0,0.9872136116027832
1691839730,16456,junrao,2024-07-25T17:06:48Z,we are doing this check for fetching already. do we need to do this again?,0,0.9876925349235535
1691841163,16456,junrao,2024-07-25T17:08:02Z,combine with the previous line?,0,0.9939411878585815
1691841383,16456,junrao,2024-07-25T17:08:12Z,topicidnames and clientid seem unused?,0,0.9833765625953674
1691842743,16456,junrao,2024-07-25T17:09:17Z,we can get rid of {}.,0,0.9864288568496704
1693588726,16456,junrao,2024-07-26T20:42:20Z,merge with previous line?,0,0.9909785985946655
1693601483,16456,junrao,2024-07-26T20:59:28Z,merge with previous line?,0,0.9909785985946655
1693602221,16456,junrao,2024-07-26T21:00:34Z,space after `if`,0,0.9921362400054932
1693628707,16456,junrao,2024-07-26T21:41:26Z,this is an existing issue. why do we need to pass in both interestingtopicpartitions and interestingwithmaxbytes? they have the same keyset. could we just pass in interestingwithmaxbytes?,0,0.9713094234466553
1693631675,16456,junrao,2024-07-26T21:45:46Z,"hmm, i am not sure that i understand the logic here. the partition set for topicpartitionacknowledgements is a subset of that for sharefetchresponse, right? if so, there is no remaining acknowledgements.",0,0.5547091364860535
1695140156,16456,apoorvmittal10,2024-07-29T12:37:56Z,yeah as per suggestion here: [a link] if we have it consistent across other logs then it would be good: [code block],0,0.8654167056083679
1695145736,16456,apoorvmittal10,2024-07-29T12:42:08Z,is `()` required or we can just write `if(tp.partition == partition) {`,0,0.9942212104797363
1695595126,16456,junrao,2024-07-29T17:23:53Z,`thenapply` => `.thenapply` ?,0,0.992567777633667
1695660706,16456,junrao,2024-07-29T18:09:47Z,"`isinvalidsharefetchrequest()` checks `ispartitionpresent`. if there is a partition level error, we should send a errors.unknown_topic_or_partition at the partition level, instead of errors.invalid_request at the request level.",0,0.9947299957275391
1695831694,16456,junrao,2024-07-29T20:30:49Z,why do we need `partitiondatas`? could we just iterate `erroneousandvalidpartitiondata.validtopicidpartitions` directly?,0,0.9944135546684265
1695851702,16456,junrao,2024-07-29T20:37:31Z,this can a bit simpler like the following. [code block],0,0.9839150905609131
1695877000,16456,junrao,2024-07-29T20:44:46Z,the convention is to combine with the previous line.,0,0.9917774200439453
1695885553,16456,junrao,2024-07-29T20:47:08Z,could this be private?,0,0.9903441071510315
1695923179,16456,junrao,2024-07-29T20:57:29Z,it seems cleaner if we just create `erroneous` inside `handleacknowledgements()`?,0,0.994118332862854
1695953996,16456,junrao,2024-07-29T21:05:50Z,indentation,0,0.822169840335846
1695961725,16456,junrao,2024-07-29T21:08:14Z,why does this return a mutable map? ditto for `handleacknowledgements()`.,0,0.9912043213844299
1695973614,16456,junrao,2024-07-29T21:15:32Z,why do we need to copy the entries to `partitions`? we could just keep using `responsepartitiondata`?,0,0.9941148161888123
1696012525,16456,junrao,2024-07-29T21:59:12Z,could this be private?,0,0.9903441071510315
1696053083,16456,junrao,2024-07-29T22:51:55Z,there is some validation inside `sharepartitionmanager.newcontext`. should we just fold this logic there?,0,0.99503493309021
1696057694,16456,junrao,2024-07-29T22:59:49Z,why is this request invalid?,0,0.9284924268722534
1696066333,16456,junrao,2024-07-29T23:14:22Z,this seems unnecessary since we already tested that the array is empty above.,0,0.9830721616744995
1696077755,16456,junrao,2024-07-29T23:20:21Z,should we set records to `memoryrecords.empty`?,0,0.9946647882461548
1696078584,16456,junrao,2024-07-29T23:21:26Z,merge into previous line?,0,0.9921535849571228
1696079560,16456,junrao,2024-07-29T23:22:33Z,this is not the first request.,0,0.9779434204101562
1696081720,16456,junrao,2024-07-29T23:24:45Z,"is this test useful? in both cases, we mock `sharepartitionmanager.newcontext` to return errors.share_session_not_found regardless whether there is a wrong member id or group id. should we mock `sharepartitionmanager.newcontext` to return a sharesessioncontext with the wrong group/member id?",0,0.9941627383232117
1696083957,16456,junrao,2024-07-29T23:27:07Z,"merge into previous line? also, should we mock sharepartitionmanager.newcontext to return a sharesessioncontext with the wrong epoch instead of directly throwing an exception?",0,0.9947081804275513
1696094681,16456,junrao,2024-07-29T23:35:48Z,"hmm, the expected epoch should be 2 for the last call, right?",0,0.9704649448394775
1696108097,16456,junrao,2024-07-30T00:00:53Z,this is not the first fetch request.,0,0.9843138456344604
1696112503,16456,junrao,2024-07-30T00:09:07Z,`sharefetchdata` seems unused?,0,0.9918487071990967
1696113299,16456,junrao,2024-07-30T00:10:46Z,sharefetchdata seems unused?,0,0.9518650770187378
1696113985,16456,junrao,2024-07-30T00:12:00Z,quite a long name. could it be sth like `testhandlesharefetchfetchmessagesreturnerrorcode`?,0,0.9629004597663879
1696114858,16456,junrao,2024-07-30T00:13:37Z,sharefetchdata seems unused?,0,0.9518650770187378
1696116555,16456,junrao,2024-07-30T00:17:09Z,merge with previous line?,0,0.9909785985946655
1696116942,16456,junrao,2024-07-30T00:17:53Z,could this be private?,0,0.9903441071510315
1696116973,16456,junrao,2024-07-30T00:17:58Z,could this be private?,0,0.9903441071510315
1696118317,16456,junrao,2024-07-30T00:20:55Z,"i understand the logic better now. so, this is fine.",0,0.8156484365463257
1696118888,16456,junrao,2024-07-30T00:22:11Z,i understand the code better now. this is fine.,0,0.7521555423736572
1696517878,16456,chirag-wadhwa5,2024-07-30T08:07:31Z,"thanks a lot for the review. i actually had some unit tests in place for this method, that is why left it as public. should i add a comment saying `//visible for testing` ?",1,0.9795270562171936
1696558877,16456,chirag-wadhwa5,2024-07-30T08:33:53Z,"hi, thanks a lot for the review. i guess this comment refers to the code before the last commit. i believe all the issues with asynchronous code have been resolved with that. let me know if you find any other gaps. thanks !",1,0.9918763637542725
1696677665,16456,chirag-wadhwa5,2024-07-30T09:50:14Z,"thanks for the review ! with the new code in place, i believe this problem has also been resolved.",1,0.986990749835968
1697309981,16456,chirag-wadhwa5,2024-07-30T17:10:39Z,"thanks for the review. actually the code does not down convert anything, its just the variable names and the comments that suggest that. made the required changes",1,0.9267292022705078
1697405173,16456,chirag-wadhwa5,2024-07-30T18:33:05Z,"thanks for the review. you are correct here. but the code actually has that check already, i think this is not needed at all. i will remove this in the next commit",1,0.9655838012695312
1697422741,16456,chirag-wadhwa5,2024-07-30T18:48:42Z,"thanks for the review. actually, the upcoming pr for shareacknowledgerequest would make it clear why it has been one this way. the acknowledgement data sent to `handleacknowledgements` is retrieved using different methods in case of a fetch request and an acknowledge request. these methods can themselves identify some erroneous topic partitions, so that is why the map is being passed on to the method",1,0.8242367506027222
1697447600,16456,chirag-wadhwa5,2024-07-30T19:07:17Z,"thanks for the review. given that a single fetch from a partition can sometimes contain significant amount of data, copying the entire map again whenever a new element is added could be a little extensive. but i don't think this choice of using a mutable.map or simply a map would make a huge difference. do you have any better suggestions though ?",1,0.9174538254737854
1697502447,16456,chirag-wadhwa5,2024-07-30T19:53:44Z,"thanks for the review. yes we could use the same, but the definition of some methods of sharefetchcontext require a util.linkedhashmap, so we would anyways require a new variable to store the converted map as it is required as an argument to multiple methods. talking about why do we need a util.linkedhashmap altogether, maybe we could change those method signatures to use a scala map as well, but i think that would out of scope for this pr as it would include making changes to others code as well.",1,0.7943933606147766
1697672536,16456,junrao,2024-07-30T22:29:09Z,"it seems that we never add/remove elements in the returned mutable.map? if the map doesn't need to be mutated, returning just map reduces potential side effect.",0,0.9889716506004333
1697988104,16456,chirag-wadhwa5,2024-07-31T06:48:01Z,"thanks for the review. the logic dictates, that a final share fetch request should only be sent for acknowledging previously fetched records, and not for fetching new records (the new records wouldn't be acknowledged since this is the final request). so, if the the partition max bytes field is non zero for any share partition in the request, that mens the client expects records as a result, which should not be the case, since it is a final fetch request. hence this is an invalid request. i know it is very trivial, but in the long run, the final epoch would be sent via a shareacknowledge request and not a sharefetch request, thereby resolving this altogether",1,0.8539974093437195
1698763204,16456,junrao,2024-07-31T16:03:31Z,thanks for the explanation. make sense. could we add a comment about this?,1,0.8619369268417358
1699474736,16456,chirag-wadhwa5,2024-08-01T06:05:14Z,"thanks for the review. i'm sorry but i don't understand how returning a sharesessioncontext with the wrong group/member id will help. the entire logic to handle the groupid/memberid is in newcontext and if a wrong groupid/memberid is provided in the request, an newcontext throws an error, which is what this test tries to mimic. pls let me know if my understanding is wrong anywhere, thanks !",1,0.8839260935783386
1699483505,16456,chirag-wadhwa5,2024-08-01T06:09:02Z,"thanks for the review. again, i'm sorry but i don't see how that is going to help. the expected behaviour is that the newcontext method should throw an exception in case of wrong epoch. if it successfully returns a sharesessioncontext, then the fetching would proceed without any issues, because that does not care about epochs at all. i have tried to simulate the expected behaviour in the test. pls let me know if my understanding is wrong anywhere, thanks !",1,0.9210219383239746
1699487912,16456,chirag-wadhwa5,2024-08-01T06:10:20Z,"thanks for the review. yes, you are right. actually, the sharefetchmetadata would include the current epoch in the request, but the sharesession would contain the next epoch, as the epoch is bumped in the newcontext method. i have made the change here, as well as in the other functions. thanks again for pointing it out !",1,0.9929221868515015
1699568098,16456,chirag-wadhwa5,2024-08-01T07:22:47Z,"thanks for the review. i already changed this piece of code in the last commit, it does not use any breakable now.",1,0.9679189324378967
1699569869,16456,chirag-wadhwa5,2024-08-01T07:24:21Z,thanks for the review. i think there is a difference between both the if and else cases. i actually used the code from the normal fetch request and the throttling logic is the same as it is there.,1,0.9487969279289246
1699572051,16456,chirag-wadhwa5,2024-08-01T07:26:11Z,"thanks for the review. i think this comment was addressing an issue in the previous version of the pr. i pushed a commit later, which i believe resolved all issues related to asynchronous code. if you find any other gaps, pls let me know. thanks !",1,0.9885151982307434
1700521738,16456,junrao,2024-08-01T17:01:25Z,move the statement to a separate line since this case has multiple statements.,0,0.989328920841217
1700530866,16456,junrao,2024-08-01T17:09:57Z,could we make `fetchresult` a val by calling `handlefetchfromsharefetchrequest` here?,0,0.9954067468643188
1700533859,16456,junrao,2024-08-01T17:11:42Z,merge into previous line,0,0.9683384895324707
1700558567,16456,junrao,2024-08-01T17:32:45Z,is the todo still needed?,0,0.9899000525474548
1700562536,16456,junrao,2024-08-01T17:35:39Z,this can be a bit simpler like [code block],0,0.9919188618659973
1700566242,16456,junrao,2024-08-01T17:39:01Z,no space before (,0,0.6641305685043335
1700574089,16456,junrao,2024-08-01T17:46:10Z,interesting => interested ?,0,0.9638218283653259
1700580952,16456,junrao,2024-08-01T17:50:48Z,shareacknowledgeresult seems unused?,0,0.9819934368133545
1700583206,16456,junrao,2024-08-01T17:52:10Z,this can be a bit simpler like [code block],0,0.9919188618659973
1700589809,16456,junrao,2024-08-01T17:55:30Z,merge into previous line,0,0.9683384895324707
1700595263,16456,junrao,2024-08-01T18:00:08Z,"there is no conversion, right? so `converted` is inaccurate.",0,0.9170315265655518
1700596185,16456,junrao,2024-08-01T18:01:01Z,add an extra new line below.,0,0.9780858159065247
1700596862,16456,junrao,2024-08-01T18:01:27Z,there is no down conversion.,0,0.9179158210754395
1700603141,16456,junrao,2024-08-01T18:06:24Z,"throttling is done inside this method. so, `invoked before throttling` is inaccurate.",0,0.9789204001426697
1700604916,16456,junrao,2024-08-01T18:08:13Z,could this be private?,0,0.9903441071510315
1700605031,16456,junrao,2024-08-01T18:08:20Z,indentation,0,0.822169840335846
1700609451,16456,junrao,2024-08-01T18:12:26Z,this can be a bit simpler like [code block],0,0.9919188618659973
1700619173,16456,junrao,2024-08-01T18:17:45Z,could this be private?,0,0.9903441071510315
1700620774,16456,junrao,2024-08-01T18:19:16Z,could we add the new param to javadoc?,0,0.9921905398368835
1700655193,16456,junrao,2024-08-01T18:42:27Z,we could use a mutable map locally for better efficiency and return it as `map`.,0,0.9895766973495483
1700657160,16456,junrao,2024-08-01T18:43:49Z,we could use a mutable map locally for better efficiency and return it as `map`.,0,0.9895766973495483
1700662501,16456,junrao,2024-08-01T18:48:30Z,"i mean that since we mock `sharepartitionmanager.newcontext` to return errors.share_session_not_found, we are not really testing whether `sharepartitionmanager.newcontext` could handle incorrect group/member id properly. we are just testing if the caller can behave properly when `sharepartitionmanager.newcontext` returns an error. so, testing just one of incorrect group/member id seems enough.",0,0.9929817914962769
1700679813,16456,junrao,2024-08-01T18:59:08Z,"why is isacknowledgedatapresent true? there is no acknowledgement, right? ditto in a few other cases below.",0,0.9618183970451355
1701337300,16456,chirag-wadhwa5,2024-08-02T06:19:08Z,"understood, thanks a lot",1,0.9813898205757141
1701341077,16456,chirag-wadhwa5,2024-08-02T06:23:02Z,it's not. i have removed it. thanks !,1,0.9939762353897095
1701409939,16456,chirag-wadhwa5,2024-08-02T07:22:33Z,"thanks for the review ! during the invocation of `sharepartitionmanager.newcontext` we don't pass any acknowledgements, so there's no way to know whether acknowledgements are present or not, only the variable `isacknowledgedatapresent` provides that information. my understanding says that in the general case, only the first fetch request (with request epoch 0) will not contain any acknowledgements, but all the subsequent requests would. going by that logic, i have set this variable to false in case request epoch is 0, and true in all the other cases.",1,0.9408185482025146
1702138634,16456,junrao,2024-08-02T17:37:00Z,this should be [code block],0,0.9912989735603333
1702139817,16456,junrao,2024-08-02T17:38:28Z,indentation,0,0.822169840335846
1702140987,16456,junrao,2024-08-02T17:39:53Z,merge with previous line?,0,0.9909785985946655
1702141861,16456,junrao,2024-08-02T17:40:47Z,extra new line,0,0.9711894392967224
1702159875,16456,junrao,2024-08-02T17:59:37Z,"`sharefetchmetadata(uuid.zero_uuid, -1)` could just be `newreqmetadata`?",0,0.9957361221313477
1702169187,16456,junrao,2024-08-02T18:09:59Z,this is fine. we can leave it as it is.,0,0.9657648205757141
1704485591,16456,junrao,2024-08-05T18:24:21Z,this is unnecessary since `sharepartitionmanager.close()` already calls `persister.stop()`.,0,0.9923741221427917
1704494394,16456,chirag-wadhwa5,2024-08-05T18:33:45Z,"ohh yes, you are right, missed it. thanks. i have pushed the change",1,0.989540159702301
1325138384,14364,philipnee,2023-09-13T22:32:26Z,just to create a coherent format,0,0.9653396010398865
1325368170,14364,philipnee,2023-09-14T05:21:01Z,we should submit a patch to combine groupstate into memberstate.,0,0.9910407662391663
1325381139,14364,philipnee,2023-09-14T05:41:03Z,"it might be helpful to read the test: `public void testheartbeatresponse_errorhandling(final errors error, final boolean isfatal)`",0,0.9910658001899719
1325382420,14364,philipnee,2023-09-14T05:43:03Z,i wonder if this can be moved to the memberstatemanager.,0,0.9812036156654358
1325383326,14364,philipnee,2023-09-14T05:44:36Z,current i'm unable to reference the assignor config in memberstatemanager because it is always null.,0,0.9613176584243774
1325999433,14364,lianetm,2023-09-14T13:59:12Z,"totally, but is there a reason why we couldn't just use the `membershipmanager` here already? i though that was the point of unblocking the state pr that includes all that's needed here.",0,0.9919684529304504
1326031428,14364,lianetm,2023-09-14T14:21:24Z,makes sense. let's move it on this same pr i would suggest,0,0.9536310434341431
1326089090,14364,lianetm,2023-09-14T14:56:57Z,"it's null here simply because it wasn't defined when creating the `membershipmanager` in the defaultbackgroundthread. my understanding is: - if the client specifies an assignor (client or server), we should make sure to set it in the `membershipmanager` when creating it in the defaultbackgroundthread [a link]. this will ensure that it is available here to send it on the heartbeatrequest. - if the client did not specified any assignor, then it will be ok to have null here, and we don't need to include anything for it in the heartbeatrequest. we let the group coordinator on the server select the default assignor for the member from the `group.consumer.assignors` config. correct me here if i'm missing something.",0,0.9909817576408386
1326105802,14364,dajac,2023-09-14T15:08:30Z,"that's right. the (server) assignor should be null be default as defined in the [a link]. when null, the server uses the first one in the list on the server side.",0,0.9937716126441956
1326205537,14364,philipnee,2023-09-14T16:14:48Z,thanks for the clarification.,0,0.7415633201599121
1326228037,14364,philipnee,2023-09-14T16:28:49Z,actually - my bad: i think we can just get rid of the groupstate.,-1,0.9875576496124268
1326232358,14364,philipnee,2023-09-14T16:31:52Z,"there's a bit of refactoring needed, to keep things in scope for this pr - i will be submitting another pr to address this.",0,0.9851425290107727
1326463429,14364,lianetm,2023-09-14T20:09:54Z,"the subscription state already has it, and it is a component that is all over, so i would try to keep the regex in that single place",0,0.9902771711349487
1326478655,14364,lianetm,2023-09-14T20:24:07Z,"just for the record, that regex that we keep in the client (now on the subscriptionstate), will need to be updated to move away from the java `pattern` and use the new `subscriptionpattern` defined in the protocol i expect.",0,0.9927682876586914
1327513916,14364,philipnee,2023-09-15T16:09:28Z,"sounds good thanks! fwiw, a bit out of the scope here: we discussed the plan to split subscriptionstate to remove (some of) the synchronization locks. as users don't need to access the regex pattern directly (aside from submitting one), it might just live in the background thread once this refactor happens.",1,0.994036078453064
1329227271,14364,lianetm,2023-09-18T20:14:47Z,this is not using the state from params so i expect the `else` part will never be executed (member should be always in the default unjoined). is it missing mocking the state value using the param i guess?,0,0.9902833700180054
1329251065,14364,philipnee,2023-09-18T20:34:22Z,you are right! i will rewrite this test just mocking the notingroup response.,1,0.8385137319564819
1329477649,14364,philipnee,2023-09-19T02:12:01Z,"i wonder if we could just call this ""shouldheartbeat"" as the server side protocol is tight to the heartbeat",0,0.9608316421508789
1330246922,14364,lianetm,2023-09-19T14:38:43Z,"sure, sounds good to me",1,0.6228525638580322
1330274787,14364,dajac,2023-09-19T14:57:39Z,nit: i think that we usually use `()` instead of `{}` in to strings.,0,0.9870997667312622
1330275873,14364,dajac,2023-09-19T14:58:23Z,"should we add javadoc to attributes, classes and methods? i think that we usually do it for all the new java code these days.",0,0.9876339435577393
1330276646,14364,dajac,2023-09-19T14:58:52Z,this is incorrect. the heartbeat interval comes is provided in the response.,0,0.7608366012573242
1330277639,14364,dajac,2023-09-19T14:59:37Z,nit: let's add javadoc to be consistent with the other methods.,0,0.9885337948799133
1330280744,14364,dajac,2023-09-19T15:01:22Z,"i am not sure to follow the `membershipmanager.notingroup()` part here. if we are not in the group, shouldn't we heartbeat to join (or rejoin) it?",0,0.9094094038009644
1330281420,14364,dajac,2023-09-19T15:01:42Z,nit: we could use `ifpresent`.,0,0.9933176040649414
1330282085,14364,dajac,2023-09-19T15:02:04Z,nit: this empty line could be removed.,0,0.985887348651886
1330286961,14364,dajac,2023-09-19T15:04:58Z,"when we transition to failed in updatestate, i think that it analogous to a non retriable error. is our plan to capture all the non-retriable errors before we reach this? we also do some error handling in updatestate. the responsibilities are not clear here.",0,0.9489578604698181
1330288247,14364,dajac,2023-09-19T15:05:56Z,nit: the naming does not respect our conventions here. we should use camel case.,0,0.8936473727226257
1330319691,14364,lianetm,2023-09-19T15:27:08Z,"agree that we need to better define responsibilities. as i see it for now, the membershipmgr should only come into play here when it's time to `updatestate`, and that would be : - when no errors in hb response (to extract relevant state info from the response and transition to `stable`) - when there is a non-retriable error (to transition to `failed`) any retriable error received in the hb response would be handled in the heartbeat manager here, while the state remains unchanged (ex. unjoined). with this approach, there would error handling in both, the heartbeat manager and the membership manager but for different purposes: - heartbeatmanager handles errors to continue retrying the request if needed (until it gets a success or fatal error, in which case it would stop retrying and call `updatestate`) - membershipmanager `updatestate` internally handles fatal errors only, just to update state info accordingly (ex. reset epoch on fence) and do the right transition. thoughts?",0,0.9929242134094238
1330451339,14364,philipnee,2023-09-19T17:04:22Z,i see - i think we've been consistently using { in the refactor. maybe we should change that,0,0.9794741272926331
1330458175,14364,philipnee,2023-09-19T17:11:10Z,will do. sorry for completely missing this part.,-1,0.9934671521186829
1330460386,14364,philipnee,2023-09-19T17:13:24Z,"thanks, just note it here: `group.consumer.heartbeat.interval.ms is defined on the server side and the member is told about it in the heartbeat response.`",0,0.5671319961547852
1330475695,14364,philipnee,2023-09-19T17:25:35Z,"as previously commented, maybe let's use `shouldheartbeat` to be more explicit",0,0.99442058801651
1330480862,14364,philipnee,2023-09-19T17:28:37Z,i've seen it in quite a few places so i thought we don't have a conventions :grinning_face_with_sweat:,0,0.9786979556083679
1330940223,14364,philipnee,2023-09-20T03:45:13Z,"thanks, i made some update to the manager, in particular, i split the fatal error out of the updatestate, lmk if you like the change, or we could do better.",1,0.6815344095230103
1331809403,14364,lianetm,2023-09-20T15:26:35Z,"this `onfatalerror` does update the state for the member, so separating it from the `updatestate` leads to having the update logic and transitions in 2 places (which i think is harder to follow/troubleshoot). what about we go back to a single `updatestate` responsible for updating state (aka. member info and transitions) . and if we make this single `updatestate` return the optional that it may find in the response, then we could leave the error handling only in the membershipmanager, and the heartbeatmanager could be much simplified. take a look at [a link] draft pr and let me know your thoughts",0,0.987278938293457
1331811249,14364,lianetm,2023-09-20T15:27:56Z,this whole func would completely disappear if we agree on the something like the draft pr [a link],0,0.9836304187774658
1331828912,14364,lianetm,2023-09-20T15:40:02Z,"again brainstorming based on the [a link], this would be much simplified with the move of the error handling more into the membershipmanager i expect. here, instead of having to paths to update state (now there are 2 calls, one to membershipmanager.updatestate and another for all the error handling), we could simply have something like: [code block]",0,0.9881199598312378
1331895217,14364,philipnee,2023-09-20T16:21:45Z,"why don't we let the heartbeat request manager to handle all the errors? technically, these are heartbeat errors, and it would be more centralized to handle them on the manager. the membershipmanager really could just ensure if the transition is valid.",0,0.9911406636238098
1331944957,14364,lianetm,2023-09-20T17:05:56Z,"sounds good, actually better to move it all to the heartbeat manager, given that it is the more concerned about the hb errors. the membershipmgr in the end only needs to know about what affects the state (success, fencing and fatal failures)",0,0.5506501793861389
1331948509,14364,lianetm,2023-09-20T17:09:14Z,"this could still be simplified a lot like i was suggesting in the comment above. not handling all errors, only the fencing/fail ones. for all the rest is a common action that could be done with a single `nonretriableerrorhandler.handle(error.get().exception());`",0,0.9913164377212524
1331997791,14364,lianetm,2023-09-20T17:56:41Z,this will be invoked on any non-retriable error i expect (not only the unreleased_member_id),0,0.9873523712158203
1332028195,14364,lianetm,2023-09-20T18:27:58Z,this could be final now,0,0.9903392195701599
1332033298,14364,lianetm,2023-09-20T18:33:35Z,nit nit: i find it a better format to read the code if adding the separators at the end of the previous line for better alignment (having all the added `propid=` at the beginning of each line),0,0.9784196615219116
1332033928,14364,lianetm,2023-09-20T18:34:17Z,indentation,0,0.822169840335846
1332038622,14364,lianetm,2023-09-20T18:39:21Z,indentation? (i guess it shouldn't be the same as in the requestmanager down below),0,0.9880181550979614
1332041024,14364,lianetm,2023-09-20T18:41:52Z,this is only needed when there is a groupid defined so i would move it completely to the `if (groupstate.groupid != null)` block,0,0.9952377080917358
1332064354,14364,lianetm,2023-09-20T19:06:17Z,"i think we should explain a bit here about the timing of the heartbeat requests, which is also managed by this class. it would be good to explain the timing logic based on the interval as max waiting time, but also mentioning that the manager may send out a hb request without waiting for the interval, ex. when completing processing an assignment.",0,0.989484965801239
1332069325,14364,lianetm,2023-09-20T19:11:45Z,"given that the `cansendrequest` checks the heartbeat interval, this means that we'll be only sending heartbeats on the interval (heartbeattimer.isexpired()), but we also need to have a mechanism for sending heartbeat requests ""on-demand"" (ex. when rebalance callbacks execution finishes, we should send a hb request right away , without waiting for the interval timer to expire)",0,0.9941680431365967
1332077647,14364,lianetm,2023-09-20T19:20:50Z,do we need this at the class level? seems to only be needed in the constructors for initializing the heartbeattimer,0,0.9936872124671936
1332093119,14364,lianetm,2023-09-20T19:38:01Z,final,0,0.9202145934104919
1332115559,14364,lianetm,2023-09-20T20:03:05Z,"i think we should still validate here that the response contains no error (and throw illegalargument if so), as this func now is only expected to be called on successful responses. without such validation, an erroneous call to this func in the case of an error would end up going unnoticed and transition the member to stable.",0,0.9912785887718201
1332177568,14364,kirktrue,2023-09-20T21:00:24Z,can we resolve the error code to an `errors` object via `errors.forcode()`?,0,0.9946098327636719
1332178673,14364,kirktrue,2023-09-20T21:01:15Z,"same question here, can we use and compare errors based on `errors` (which we can get via `errors.forcode()`)?",0,0.9948635697364807
1332183105,14364,kirktrue,2023-09-20T21:04:48Z,same request here: use `errors` to remove unnecessary use of raw error `code`.,0,0.9930035471916199
1332190917,14364,kirktrue,2023-09-20T21:11:24Z,can we rename `failmember` to be more descriptive?,0,0.9934481978416443
1332191970,14364,kirktrue,2023-09-20T21:12:39Z,"per the related comment, can we rename `failmember` something that is more descriptive of what action _happened_ vs. that action's _result_?",0,0.992432713508606
1332443272,14364,philipnee,2023-09-21T04:40:54Z,"this is a pretty common pattern to override tostring. do you mean making it doing? [code block] currently everything is in a single line. though - this can be used for logging, so i wonder what would it look like it if we add line separator.",0,0.9081057906150818
1332444068,14364,philipnee,2023-09-21T04:41:41Z,:person_facepalming:,0,0.9871838092803955
1332446857,14364,philipnee,2023-09-21T04:44:25Z,make sense.,0,0.9810715317726135
1332454913,14364,philipnee,2023-09-21T04:54:32Z,i thought it would be more clear on how to implement this after the revocation is implemented or implement it with the assignment logic - can we punt it to a separated pr?,0,0.9837326407432556
1332455723,14364,philipnee,2023-09-21T04:55:43Z,"this is left non-final intentionally - as sometimes we might want to spy the membership class, so the test function can override it.",0,0.9887775778770447
1332466756,14364,philipnee,2023-09-21T05:11:46Z,maybetransitiontofailure ?,0,0.9786809086799622
1333624789,14364,lianetm,2023-09-21T21:33:13Z,"agree with the pattern, i was only referring to having the nit of having props aligned : [code block]",0,0.9691573977470398
1333629206,14364,lianetm,2023-09-21T21:39:58Z,"ok with having it in a separate pr but let's maybe add a comment/todo here, and think about how to define the interaction between the assignmentreconciler and this hb manager. they need to somehow communicate to trigger a hb request when the callbacks complete successfully (exactly what came out in the assignmentreconciler pr review [a link]",0,0.9871852993965149
1334626047,14364,lianetm,2023-09-22T16:57:01Z,typo membershipmanager,0,0.9834563136100769
1334633010,14364,lianetm,2023-09-22T17:04:49Z,i think this is not only for revocation. i expect members should send a heartbeat request as soon as they complete processing an assignment without waiting for the interval (for both cases: new partitions being added and partitions being revoked). let's double check with,0,0.9862378835678101
1334636930,14364,lianetm,2023-09-22T17:09:23Z,unused since the class level var was removed,0,0.9908972382545471
1334645635,14364,lianetm,2023-09-22T17:19:05Z,"i find it a bit confusing to say that the member won't send hb when it left the group. agree that it holds true when a member intentionally leaves a group (ex. when the consumer is closed), but it's not true for when a member is left out of the group by the server (ex. all fencing scenarios). when left out of a group because of a fencing situation, the member will release its assignment and send hb again to rejoin.",0,0.6770275831222534
1334652824,14364,lianetm,2023-09-22T17:27:10Z,"i think we're still missing important info in the doc about the hb interval and how it is applied. (the heartbeat sent on the heartbeat interval, that is received from the server on the first hb response. if the member finishes processing an assignment (partitions assigned/revoked) the interval is not honored and the hb request is sent out right away)",0,0.9908541440963745
1334657428,14364,lianetm,2023-09-22T17:32:14Z,uhm we're using a 0 as default `heartbeatintervalms` here. this will only get updated when we get the value from the server in the first hb response. thinking about the case where we send an initial hb request but never get a response...does this 0 then mean that we'll continue to send a hb on every poll iteration?,0,0.880608320236206
1334659219,14364,lianetm,2023-09-22T17:34:12Z,nit: review punctuation marks usage,0,0.9816845059394836
1334668800,14364,lianetm,2023-09-22T17:45:30Z,"agree that we'll ""update the timer when the response is received"", but i see here that the timer is only used on the case where it is not time to send hb yet (if block above, ln 112). in the case of this return, which is the case when the hb request manager is polled and notices it is time to send the hb, we're always passing `long.max_value` as `timemstillnextpoll`. shouldn't we use the timer here too (that will have its default value if this is a first req, or the one provided by the server in a previous hb response)?",0,0.9940829873085022
1334734541,14364,philipnee,2023-09-22T19:08:25Z,"the cansendrequest should take care of the inflight request. if the request has been sent w/o a response/error, it won't try to send again. for the initial state, i really just need to set to a specific number as we get the hb response from the server. i set to 0 because i think the client should quickly poll the manager against to see if it can send a heartbeat. another alternative is to use `backoffs` to prevent a tight loop there. wdyt?",0,0.9829710125923157
1335289660,14364,lianetm,2023-09-25T01:02:54Z,"got it, seeing that the `cansendrequest` considers inflight requests then it makes sense to set an initial value of 0 i would say, so that we send the first hb as soon as the hm manager starts. i would only suggest to add some tests for the interval, including this case where we might not get a response to our first hb request.",0,0.9910785555839539
1335295791,14364,lianetm,2023-09-25T01:20:46Z,`shouldsendheartbeat` returning false when unjoined does not seem right. we do need to send hb when unjoined to be able to join the group. i would say failed is the only state we we shouldn't send hb.,0,0.9894986152648926
1335297785,14364,lianetm,2023-09-25T01:27:16Z,"given that the current `shouldsendheartbeat` returns false when unjoined, i expect the second part of this condition will be true when a members starts for the first time and we'll return a pollresult with empty request list, so we'll never be sending the first hb request?",0,0.9932159781455994
1335304701,14364,lianetm,2023-09-25T01:46:06Z,"this is a non-retriable exception, so i expect we should be calling `membershipmanager.transitiontofailure()`? (same for all other fatal exceptions up to the `unreleased_instance_id`, which is properly doing the transition)",0,0.9934138655662537
1335307959,14364,lianetm,2023-09-25T01:55:36Z,"from the hb request manager point of view, this means that when polled, it won't return any request right? could we assert that to ensure that the request manager is actually not generating requests at this point?",0,0.9918466806411743
1335309021,14364,lianetm,2023-09-25T01:58:34Z,"if we agree on the [a link] regarding missing transitions when handling fatal errors, i expect this will be updated to reflect align with it and check transition to failed on all fatal errors other than the 2 fencing ones.",0,0.9907820820808411
1336389075,14364,philipnee,2023-09-25T21:06:06Z,i think you are right.,0,0.781706690788269
1336390801,14364,philipnee,2023-09-25T21:08:17Z,the updated pr should invoke maybetransitiontofailurestate() on a few fatal exceptions.,0,0.9807460308074951
1336429379,14364,philipnee,2023-09-25T22:03:13Z,"so when we startup the manager, the timer will be set to 0 until the first heartbeatinterval response is received. which means, we will get a heartbeat request on the first poll. i added a test for this.",0,0.9901884198188782
1337234985,14364,lianetm,2023-09-26T13:42:35Z,wrong placeholder {},0,0.7107240557670593
1337235694,14364,lianetm,2023-09-26T13:43:05Z,ditto,0,0.9222367405891418
1337238424,14364,lianetm,2023-09-26T13:44:57Z,"tries ""to"" rejoin",0,0.9721090793609619
1337239851,14364,lianetm,2023-09-26T13:45:54Z,"and ""try""",0,0.9781768321990967
1337258265,14364,lianetm,2023-09-26T13:57:51Z,"this format won't show as a proper list in the java doc, we should use ` ` tags (similar for the empty lines)",0,0.9932885766029358
1337263803,14364,lianetm,2023-09-26T14:00:56Z,"true, but the poll is much more than just determining the wait time, so i would add to this something like "" it builds the heartbeat request, including the logic for handling the responses""",0,0.9808681607246399
1337265790,14364,lianetm,2023-09-26T14:02:19Z,comma after expired,0,0.9401113390922546
1337269007,14364,lianetm,2023-09-26T14:04:32Z,these empty lines won't show as such in the java doc so let's add tags to ensure we have the separation we want,0,0.9879186749458313
1337275381,14364,lianetm,2023-09-26T14:08:55Z,"just for my understanding, what's the idea behind this todo? i thought we had inflight req handling in the parent `requeststate`, that already identifies `log.trace(""an inflight request already exists for {}"", this);`. and what would be the concurrent scenario if there is a single background thread sending heartbeats and it is not resending while there is one inflight?",0,0.9882304668426514
1337278130,14364,lianetm,2023-09-26T14:10:40Z,extra space after state.,0,0.980688214302063
1337278315,14364,lianetm,2023-09-26T14:10:47Z,ditto,0,0.9222367405891418
1337282271,14364,lianetm,2023-09-26T14:13:22Z,final,0,0.9202145934104919
1337282860,14364,lianetm,2023-09-26T14:13:46Z,extra line,0,0.9711664915084839
1337295428,14364,lianetm,2023-09-26T14:20:46Z,seems we're not using `memberassignment` in the test anymore? let's remove if unused,0,0.9935460686683655
1337309504,14364,lianetm,2023-09-26T14:28:25Z,"high level comment, i do see this test covering the timing logic for sending, and the response handling on error, but nothing for the successful hb response handling (important to ensure that it is updating the target assignment so that it can be processed by other components). also it would be helpful to have some tests around hb timeouts, mainly to validate the retry logic around that. (just suggestions for better coverage of core actions, ok for me if we prefer to target that in a separate pr)",0,0.9304308295249939
1337418980,14364,philipnee,2023-09-26T15:37:20Z,this is just for comment formatting.,0,0.9798243045806885
1337420489,14364,philipnee,2023-09-26T15:37:58Z,"i think it was a note from before, removed.",0,0.9837599992752075
1337423659,14364,philipnee,2023-09-26T15:39:35Z,we don't make these var final in tests because we could change them later,0,0.9927396178245544
1337428627,14364,lianetm,2023-09-26T15:43:11Z,"ok, that's fine but not enough. i think here we also need the tags. if you look at the java doc it shows as a giant block, which i expect it is not what we want.",0,0.9370502829551697
1337639317,14364,lianetm,2023-09-26T18:42:23Z,"agree, with the fix for the `shouldsendheartbeat` this should now work as expected.",0,0.9922584891319275
1340176254,14364,lianetm,2023-09-28T13:40:51Z,seems this is still wrong? same for the following comment,0,0.7060050964355469
1340351740,14364,philipnee,2023-09-28T15:44:05Z,for some reason the change didn't get pushed.,0,0.898719072341919
1341528842,14364,dajac,2023-09-29T15:42:23Z,i actually missed this in the other pr but the assignor selection should be based on the new `group.remote.assignor` config which should be null by default. null means that the server selects the assignor.,0,0.9945473670959473
1341531725,14364,dajac,2023-09-29T15:44:30Z,don't we need to rejoin with epoch 0 when the member is kicked out of the group? we should actually remove all partitions and trigger the partition lost callback as well before doing so.,0,0.9922950267791748
1341532755,14364,dajac,2023-09-29T15:45:21Z,what's the delay for the next event loop?,0,0.9901948571205139
1341535159,14364,dajac,2023-09-29T15:47:25Z,i wonder if we really need this. i would expect retriable exception to inherit from `retriableexception` and the fatal ones to not inherit from it. is it possible to leverage this somehow?,0,0.8269890546798706
1341535814,14364,dajac,2023-09-29T15:47:51Z,should we have javadoc for all those attributes?,0,0.993401825428009
1341539358,14364,dajac,2023-09-29T15:50:34Z,"when the reconciliation of the local assignment is completed, we need to send the heartbeat request immediately to ack it. is this going to be another condition here?",0,0.9928613305091858
1341540248,14364,dajac,2023-09-29T15:51:17Z,this answers my previous comment :). note that we also need to do this when partitions are assigned.,1,0.8833508491516113
1341547285,14364,dajac,2023-09-29T15:56:40Z,"most of the fields in the consumergroupheartbeat req/rsp are optional. our aim was to avoid having to send unnecessary information when the group is stable. in this case, the request/response should be as lightweight as possible. there are basically three requires fields: groupid, memberid, memberepoch. those must be set all the time. i am also debating whether groupinstanceid should also be. for all the others, they should only be set if they have changed. we should also send out a full request when we recover from a recoverable error (e.g. fenced, network issues, timeouts, etc.).",0,0.9908369779586792
1341548905,14364,dajac,2023-09-29T15:57:54Z,"on the regex topic, keep in mind that we will support both the java regex and the new sever side one for a while. when the java regex is used, the resolution must be done locally. when the server side regex is used, we must pass it to the server.",0,0.9923194050788879
1341588720,14364,dajac,2023-09-29T16:40:07Z,i don't really get the value of this map given that we handle all (known) errors anyway. should we just move `transitiontofailure` to there?,0,0.9746111631393433
1341590757,14364,dajac,2023-09-29T16:42:44Z,"the name `onfatalerrorresponse` is incorrect here, isn't it? we handle recoverable errors (e.g. fenced_member_epoch). personally, i would prefer to re-group all errors in `onerrorresponse` and have a `switch` covering all of them there. this would simplify the code and avoid repetition such as `errors.forcode(response.data().errorcode())` which is in both places. thoughts?",0,0.9891735315322876
1341591777,14364,dajac,2023-09-29T16:44:00Z,we also pass the `errormessage` to `exception()` here in order to give it back to the user.,0,0.9922922849655151
1341592473,14364,dajac,2023-09-29T16:44:54Z,don't we need to propagate those unknown errors to the user as well? what's our strategy here?,0,0.9881811141967773
1341592782,14364,dajac,2023-09-29T16:45:16Z,nit: we usually declare final attributes before the others.,0,0.9897463321685791
1341593245,14364,dajac,2023-09-29T16:45:51Z,nit: couldn't it be final as well?,0,0.9741597175598145
1341596109,14364,dajac,2023-09-29T16:49:23Z,"why do we need this try catch here? if we remove it, where would the exception be caught?",0,0.9879029393196106
1341597457,14364,dajac,2023-09-29T16:50:52Z,nit: `transitiontofenced` to be aligned with the other one?,0,0.9950202703475952
1341597673,14364,dajac,2023-09-29T16:51:08Z,nit: should it be `transitiontofailed`?,0,0.9919438362121582
1341662210,14364,lianetm,2023-09-29T18:00:53Z,"agree, i missed this too. we agreed that we would have no default on the client side, and would let the server choose.",0,0.9854204058647156
1341666380,14364,lianetm,2023-09-29T18:06:37Z,"agree too. it's only when the member leaves the group intentionally (ex. when consumer closes) that i expect this applies, no more hb. (addressed also on [a link] comment)",0,0.9863036274909973
1341669179,14364,philipnee,2023-09-29T18:10:28Z,"yeah possible - but i'll need to encode the 2 exceptions, i.e. unknown member id and fenced epoch, somewhere",0,0.8719189763069153
1341690694,14364,philipnee,2023-09-29T18:37:33Z,"it is a little bit tricky here, because the background thread loop is blocked until either it receives some responses, or the timer of the minimum of the heartbeat, metadata, or request timeout is expired. what we would do is to reset the heartbeatrequeststate so that we could ensure the next event loop will trigger a heartbeat. the timing, however, is a little tricky here, because it can be non-deterministic of when the next heartbeat will be sent.",0,0.7843754887580872
1341699215,14364,philipnee,2023-09-29T18:49:09Z,left a todo. will have a separated pr to fix this.,0,0.9575890898704529
1341767013,14364,philipnee,2023-09-29T20:27:16Z,"actually i think we should, thanks for the catch.",0,0.6793782711029053
1341775832,14364,philipnee,2023-09-29T20:41:42Z,"we don't, it is purely for logging purposes. for the case of this exception, maybe we should fail the request and retry.",0,0.9797693490982056
1341778036,14364,philipnee,2023-09-29T20:45:03Z,we probably don't need it after all. because error is thrown when an error is presented in the response.,0,0.9917308688163757
1342665614,14364,dajac,2023-10-02T13:03:52Z,"my understanding is that we basically retry on all exceptions here. am i correct? it seems to me that we could also get non-retriable exceptions here (e.g. unsupportedversionexception, etc.). how do we handle those?",0,0.9692453145980835
1342666388,14364,dajac,2023-10-02T13:04:24Z,"we also need to handle `unsupportedversionexception` error, i think.",0,0.9906280040740967
1342667683,14364,dajac,2023-10-02T13:05:20Z,"would it make sense to just call `membershipmanager.transitiontofailed();` in all errors instead of having this one? at the movement, the handling is a little inconsistent.",0,0.7638382315635681
1342669966,14364,dajac,2023-10-02T13:06:52Z,nit: we usually put an empty line between cases. it makes it a bit more readable.,0,0.9603660106658936
1342674863,14364,dajac,2023-10-02T13:10:14Z,"when we get this one, i understand that we will mark the coordinator as unknown to rediscover it. is it going to apply the exponential backoff after that?",0,0.9789556264877319
1342677484,14364,dajac,2023-10-02T13:12:26Z,this message is not consistent with the others. should it also start with `groupheartbeatrequest failed due to...`? i would also replace `retrying` by something like `will attempt to find the coordinator again and retry`.,0,0.986861526966095
1342678720,14364,dajac,2023-10-02T13:13:33Z,"nit: this one is also inconsistent. `+ ""retrying""` could be merged with the previous string. a space misses between `loading.` and `retrying`.",0,0.9781203866004944
1342681301,14364,dajac,2023-10-02T13:15:56Z,"i don't really understand how the error message is handled here. is it going to be added as the message of the exception later on? when i mentioned this in my earlier comment, i means doing this `errors.invalid_request.exception(errormessage)`. this uses the provided error message.",0,0.9395016431808472
1342682876,14364,dajac,2023-10-02T13:17:24Z,does the :thumbs_up_light_skin_tone: mean that you will add it?,0,0.9940156936645508
1342683440,14364,dajac,2023-10-02T13:17:54Z,should we also log something here?,0,0.9930939674377441
1342689429,14364,dajac,2023-10-02T13:23:06Z,i also wonder if having a tailored error message for each error is needed. an alternative would be to group errors and have a generic message for the fatal ones for instance. what do you think?,0,0.9773063063621521
1342694336,14364,dajac,2023-10-02T13:27:18Z,i also noticed that we have the following in the current implementation: [code block],0,0.9823770523071289
1342778930,14364,philipnee,2023-10-02T14:37:07Z,"the heartbeat request depends on the state of the state machine, so for most of the non-retriables, it should transition the state to a failure state to prevent additional requests being sent. the non-retriable also send an error to the handler (`nonretriableerrorhandler`) to send the error to the user to handle the failure case.",0,0.9907066226005554
1342781938,14364,philipnee,2023-10-02T14:39:25Z,"but we don't want errors like `coordinator_not_available` to be fatal, no?",0,0.8194653391838074
1342783380,14364,philipnee,2023-10-02T14:40:41Z,really? :grinning_face_with_sweat: most cases i see don't have an empty line. but i'll add a line anyway.,0,0.8637552857398987
1342785385,14364,philipnee,2023-10-02T14:42:21Z,yap - `this.heartbeatrequeststate.onfailedattempt(currenttimems);` basically markets the `lastreceivedms` as the response receive time. then it would trigger the backoff mechanism in the requeststate. i think expo backoff was tested in the test.,0,0.9936423301696777
1342899010,14364,philipnee,2023-10-02T16:14:38Z,yap that's a good idea to make the code easier to follow. we do want to provide some context such as group id or group instance id to group_authorization_failed and unreleased_instance_id respectively. so i'm grouping the following 4 errors [code block],0,0.5004833936691284
1342910020,14364,philipnee,2023-10-02T16:25:52Z,"added some comments directly above the var - is this enough or you actually want this to be presented in the ""javadoc"" of the class section?",0,0.9950982928276062
1342915079,14364,philipnee,2023-10-02T16:31:09Z,i understand the concern about inconsistency but different errors can put the member in a different state,0,0.8861758708953857
1342920121,14364,philipnee,2023-10-02T16:36:57Z,"yap i see the disconnectexception handling, it is implemented by all requests going to the coordinator. here we handle them independently in the request mangers. maybe we could modularize these reaction to make it more unified.",0,0.9775582551956177
1344205855,14364,dajac,2023-10-03T14:29:18Z,my point was that the `exception` received here may not be re-triable (e.g. unsupportedversionexception) and that we may have to take actions on them (e.g. disconnectexception). are you saying that we handle those in another component? my current understanding is that we don't update the state machine based on those exceptions at the moment because `onerrorresponse` is not called. do we understand all the exceptions that we could receive here? we need to handle them all appropriately.,0,0.9901783466339111
1344221907,14364,dajac,2023-10-03T14:36:18Z,it seems that we could get the following ones: [code block] + `timeoutexception`,0,0.9940313696861267
1344230989,14364,dajac,2023-10-03T14:38:36Z,"sorry, i was not clear. i was trying to say that we should just call `membershipmanager.transitiontofailed();` in the relevant errors in the switch.",-1,0.9893675446510315
1344232148,14364,dajac,2023-10-03T14:39:14Z,"do we want to backoff in this case though? it seems to me that we want to retry immediately when the new coordinator is discovered, no?",0,0.9604159593582153
1344236644,14364,dajac,2023-10-03T14:42:12Z,could we please file a jira for this?,0,0.9937667846679688
1344336463,14364,philipnee,2023-10-03T15:50:54Z,i see. sure we could certainly do that.,0,0.9620012044906616
1344462484,14364,philipnee,2023-10-03T17:17:27Z,"i think we might want to refactor the coordinator requests per what you indicated above. a jira is filed: [a link] otherwise, in the onfailure() method, i added the logic to fail the state machine and propagate the error when the error is non-retriable",0,0.9902186989784241
1344497810,14364,philipnee,2023-10-03T17:43:27Z,see `testheartbeatonstartup` in the test. the first poll returns a request.,0,0.9935654997825623
1344512748,14364,philipnee,2023-10-03T17:56:32Z,here you go david: [a link],0,0.9402735233306885
1344515152,14364,philipnee,2023-10-03T17:58:41Z,"thanks - the seems like the right way to do this to only backoff for coordinator_load_in_progress error. onfailedattempt is removed. in the test `testheartbeatresponseonerrorhandling`: next heartbeat is verified ` assertequals(0, heartbeatrequeststate.nextheartbeatms(mocktime.milliseconds()));`",1,0.6240611672401428
1344560113,14364,lianetm,2023-10-03T18:40:40Z,duplicated above,0,0.9703942537307739
1344567777,14364,lianetm,2023-10-03T18:47:54Z,"i expect this will be the place where we'll need to make sure to release any assignment we may have, right? whenever a transitiontofailed/fence occurs, the hb manager should call the reconciler to trigger the onpartitionslost/revoked as needed. let's add a todo just as we did for the missing bit of triggering the hb before the interval.",0,0.9907954335212708
1344589907,14364,philipnee,2023-10-03T19:03:45Z,this is actually invalid because the response can be null in this case. i filed a jira kafka-15278 to propagate the time from the networkclientdelegate,0,0.9903197884559631
1344603478,14364,philipnee,2023-10-03T19:08:57Z,i added a test for the heartbeat timeout. see `testbackoffonheartbeattimeout`,0,0.9942507743835449
1345652576,14364,dajac,2023-10-04T11:38:27Z,i would add real javadoc to all attributes or none of them. this is what we have been doing for all the new java code recently.,0,0.9880158305168152
1345661869,14364,dajac,2023-10-04T11:46:16Z,nit: it would be good to be consistent in the log messages. they almost all start with `groupheartbeatrequest failed due...`. why don't we do the same here? i think that this is important to know that the groupheartbeatrequest failed in this case as well. the same applies to coordinator_load_in_progress. `groupheartbeatrequest failed because the group coordinator %s is incorrect. will attempt to find the coordinator again and retry`.,0,0.9856449365615845
1345662992,14364,dajac,2023-10-04T11:47:13Z,nit: `groupheartbeatrequest failed because the group coordinator %s is still in the process of loading state. will retry`.,0,0.9794138073921204
1345667909,14364,dajac,2023-10-04T11:51:33Z,it would be great to split those two in order to have separate error messages. fenced_member_epoch: `groupheartbeatrequest failed because member epoch %s is invalid. will abandon all partitions and rejoin the group` unknown_member_id: `groupheartbeatrequest failed because member id %s is invalid. will abandon all partitions and rejoin the group`,0,0.9930376410484314
1345669627,14364,dajac,2023-10-04T11:53:03Z,should we revert this? it seems that we don't need it anymore.,0,0.9814981818199158
1345670931,14364,dajac,2023-10-04T11:54:19Z,nit: constants are usually formatted as follow: `heartbeat_interval_ms`.,0,0.9930260181427002
1345680555,14364,dajac,2023-10-04T12:01:21Z,nit: we can remove empty line here.,0,0.9853572249412537
1345683631,14364,dajac,2023-10-04T12:03:20Z,so by default `heartbeatrequeststate` is a mock but we don't prefix it with `mock`. this is inconsistent...,0,0.9092432260513306
1345684050,14364,dajac,2023-10-04T12:03:37Z,could we use `createmanager()` here?,0,0.994036078453064
1345687969,14364,dajac,2023-10-04T12:06:18Z,nit: bring back on previous line.,0,0.9020149111747742
1345688824,14364,dajac,2023-10-04T12:07:04Z,nit: final to be consistent with the others?,0,0.988694965839386
1345689109,14364,dajac,2023-10-04T12:07:21Z,nit: remove `this.` to be consistent with the others.,0,0.9920608997344971
1345692568,14364,dajac,2023-10-04T12:10:13Z,should we have a test which verifies that fatal errors update the state machine?,0,0.9925419092178345
1345695035,14364,dajac,2023-10-04T12:12:10Z,should we add a unit which verifies the generated request? we have none doing this...,0,0.9840753674507141
1345696189,14364,dajac,2023-10-04T12:13:08Z,nit: `manually...`. could you please verify all the other comments as well? i don't really care if they start with a capital letter or not but i do care about consistency...,0,0.8997541666030884
1345697251,14364,dajac,2023-10-04T12:14:00Z,nit: is this really needed? it seems that using `code` would work as well.,0,0.9912571907043457
1345703205,14364,dajac,2023-10-04T12:18:13Z,"it is a bit weird to statically import those two but not the others (also used in this class), no?",-1,0.9828291535377502
1345704121,14364,dajac,2023-10-04T12:18:58Z,nit: could we align `errorcode` on `errorcode`?,0,0.9922836422920227
1345704966,14364,dajac,2023-10-04T12:19:40Z,should we add unsupported version as well?,0,0.9905778169631958
1345951445,14364,philipnee,2023-10-04T14:55:54Z,pretty sure i reverted in the previous commit....hmm,-1,0.5847082138061523
1346233433,14364,philipnee,2023-10-04T17:32:22Z,"thanks, i'll just get rid of the mock there. probably unnecessary.",0,0.6541739106178284
1346244285,14364,philipnee,2023-10-04T17:41:57Z,i refactored the if else block using switch. i think it should make it a bit more readable.,0,0.9576243162155151
1346245842,14364,philipnee,2023-10-04T17:43:22Z,see above - this section is refactored into swtich.,0,0.9919520020484924
1346258637,14364,philipnee,2023-10-04T17:54:40Z,`ensurefatalerror()` already ensure the transitiontofailed is invoked. `testtransitiontofailure` in the membershipmanagerimpltest also verifies the state transition.,0,0.9943969249725342
1346463825,14364,philipnee,2023-10-04T21:05:36Z,added `testvalidateconsumergroupheartbeatrequest` - which validate the fields in the the requestbuilder.build(version) - is that what do you mean?,0,0.9929043650627136
1347439165,14364,dajac,2023-10-05T13:38:54Z,nit: sorry but i missed those yesterday. could we also align those log messages to the other format used: `groupheartbeatrequest failed....`?,-1,0.9869948029518127
1347441115,14364,dajac,2023-10-05T13:40:12Z,nit: empty line.,0,0.783897340297699
1347441582,14364,dajac,2023-10-05T13:40:31Z,nit: empty line.,0,0.783897340297699
1347447016,14364,dajac,2023-10-05T13:44:05Z,hum... i don't follow. my point was that we don't have any tests verifying that we actually update the state machine when a fatal __exception__ is received [a link]. or did i miss it?,-1,0.7958491444587708
1347448120,14364,dajac,2023-10-05T13:44:49Z,"yep, thanks.",1,0.850009024143219
1347449738,14364,dajac,2023-10-05T13:45:50Z,should we verify all the fields? we also set others [a link].,0,0.9924478530883789
1347455966,14364,dajac,2023-10-05T13:49:46Z,nit: assure...,0,0.891474723815918
1347728174,14364,philipnee,2023-10-05T16:57:22Z,done - i left a todo to verify client and server side assignors and pattern regex.,0,0.9885494112968445
1348690378,14364,dajac,2023-10-06T12:58:35Z,"i am not really satisfied by the logging on failures: * when there is a fatal error, it logs a warning follower by an error. * the messages don't really follow the format of the other messages. should we just drop the warning on top? could we update the remaining debug message to follow the structure of the other log messages?",0,0.7705836892127991
1348885178,14364,philipnee,2023-10-06T15:35:26Z,"thanks, let's drop the warn. i also updated the debug message.",1,0.8358418941497803
1788067718,17373,mumrah,2024-10-04T17:36:06Z,these (and other similar `testruntimeonly`) should be put into the `runtimetestlibs` definition,0,0.9949005246162415
1788068473,17373,mumrah,2024-10-04T17:36:26Z,what's this dependency for?,0,0.9898118376731873
1788082764,17373,mumrah,2024-10-04T17:47:01Z,"this could break some existing kafka installations. if users are extracting in place or copying previous config files to a new installation directory, they will be expecting the log4j.properties to still work.",0,0.9771956205368042
1788846414,17373,frankvicky,2024-10-06T03:28:54Z,hi i add this to fix the warning during build: [code block],0,0.9855034351348877
1810596051,17373,showuon,2024-10-22T12:04:05Z,"we should remove this file, right?",0,0.9868674278259277
1810598884,17373,showuon,2024-10-22T12:06:12Z,"is this right? it's still possible it runs with log4j 1.x, right?",0,0.9878876209259033
1810600249,17373,showuon,2024-10-22T12:07:15Z,we still need reload4j here?,0,0.9929377436637878
1810616327,17373,showuon,2024-10-22T12:18:04Z,"in[a link], we also set the pattern to connectappender, right?",0,0.9942436814308167
1810618105,17373,showuon,2024-10-22T12:19:08Z,should we remove them?,0,0.9907585382461548
1810618615,17373,showuon,2024-10-22T12:19:30Z,should we remove them?,0,0.9907585382461548
1810625227,17373,showuon,2024-10-22T12:23:44Z,i don't understand the changes in the file. we move a log4j.properties in `connect/runtime` to `connect/mirror`? why?,0,0.8409846425056458
1810705740,17373,frankvicky,2024-10-22T13:13:55Z,"yes, there are still some modules (like `tools`) that directly depend on `reload4j`, which we can't remove at the moment. removing it would cause build errors. [code block]",0,0.9904629588127136
1810711392,17373,frankvicky,2024-10-22T13:17:09Z,"yes, we should. however, i'm thinking that removing the zk configurations might be better handled as a follow-up pr, since this one is already quite large. wdyt ?",0,0.9311067461967468
1810722170,17373,frankvicky,2024-10-22T13:23:19Z,hmm... i think it's just an issue with github detection. i modified these two files in place. :thinking_face:,0,0.783300518989563
1810744889,17373,frankvicky,2024-10-22T13:35:57Z,"yes, i think the `connectappender` setting in log4j1 is equivalent to the following, if i haven't misunderstood: [a link]",0,0.9839695692062378
1811786044,17373,showuon,2024-10-23T03:53:04Z,"it looks like it's our test depends on reload4j. in this case, we should try to fix it.",0,0.9868932962417603
1811787630,17373,frankvicky,2024-10-23T03:54:44Z,i see. i will try to deal with this issue.,0,0.948646605014801
1811789962,17373,showuon,2024-10-23T03:57:47Z,"oh, i missed that! thanks.",1,0.979458749294281
1811959867,17373,showuon,2024-10-23T06:31:13Z,"i'm not familiar with log4j2, so i don't understand the empty name here. why can't we use `getrootlogger` as above?",-1,0.502252459526062
1811961770,17373,showuon,2024-10-23T06:33:03Z,is this behavior change expected?,0,0.991806149482727
1811968367,17373,showuon,2024-10-23T06:39:10Z,this is for which method?,0,0.977033257484436
1811977005,17373,showuon,2024-10-23T06:45:28Z,we don't need `resolvelevel` now because log4j2 will do that for us? do we have test for it?,0,0.9945226907730103
1811982931,17373,showuon,2024-10-23T06:48:50Z,this change is for zk removal?,0,0.9941543936729431
1811990279,17373,showuon,2024-10-23T06:53:19Z,why can't we change the root log level now?,0,0.9886632561683655
1811993482,17373,showuon,2024-10-23T06:54:51Z,"ok, this is replaced with `reconfigure()`, right?",0,0.993685781955719
1811996534,17373,showuon,2024-10-23T06:56:07Z,"i think our goal in this pr, is to remove the reload4j above. thanks for looking into how we can completely remove it!",1,0.8824815154075623
1812025899,17373,showuon,2024-10-23T07:12:23Z,"i'm not familiar with log4j2, just want to confirm will it confuse the setting?",0,0.5664821267127991
1812137033,17373,frankvicky,2024-10-23T08:08:49Z,"yes, exactly. `reconfigure()` provides a more convenient way to hot reload log4j configurations. :grinning_cat:",0,0.9849676489830017
1812147748,17373,frankvicky,2024-10-23T08:14:04Z,"yes, the name `r` might be confusing. my intention was to purely transform from log4j1 to log4j2 without making any further unnecessary changes. however, it can definitely be renamed if needed.",0,0.9595713019371033
1812168338,17373,frankvicky,2024-10-23T08:23:53Z,"yes, i intentionally made this change to align with the removal of zk tests.",0,0.9860531091690063
1812209524,17373,frankvicky,2024-10-23T08:40:17Z,"we could, but to make the test more precise, we should avoid having the test depend on the root logger. we are now focusing on changing the log level of the `kafka` logger, which acts as the top-level logger for the `kafka.server.controllerserver`, `kafka.log.logcleaner`, and `kafka.server.replicamanager` components. this change ensures that we can still control kafka's logging behavior without relying on the root logger.",0,0.9934558272361755
1812297584,17373,frankvicky,2024-10-23T09:12:49Z,"in this test case, we focus on setting the level for the root logger. imho, it would be ideal if we could have a ""clean"" configuration to conduct this test case. if i understand correctly, we can create a new configuration programmatically at the beginning in this way to ensure that the test case is not affected by existing log4j configurations.",0,0.9862748384475708
1812309503,17373,frankvicky,2024-10-23T09:17:09Z,"yes. in log4j2, the `getlevel` method returns either the explicitly set level or the effective level. we can roughly think of it as a combination of two methods (`getlevel` and `geteffectivelevel`) from log4j1.",0,0.9939842820167542
1812370163,17373,showuon,2024-10-23T09:49:10Z,i see. but i still want to see if we can change the root logger to make sure we didn't break existing behavior. maybe we can create one more test for it?,0,0.9782404899597168
1812371827,17373,frankvicky,2024-10-23T09:50:14Z,"yes, log4j2 will do it for us. in log4j2, when we retrieve a logger instance from the `loggercontext`, the `getlevel` method returns the effective log level, which includes any levels inherited from parent loggers up to the root logger. this means that if a logger doesnt have an explicit level set, `getlevel` will provide the inherited level, so we dont need to manually traverse the logger hierarchy as we did in the `resolvelevel` method.",0,0.9939259886741638
1812372018,17373,showuon,2024-10-23T09:50:22Z,"ok, could we add some comments for these changes?",0,0.9893833994865417
1812372375,17373,frankvicky,2024-10-23T09:50:36Z,"sadly, we don't have a test for it",-1,0.9915025234222412
1812372794,17373,frankvicky,2024-10-23T09:50:55Z,"oops, i will do some clean-up",-1,0.9404423832893372
1812374332,17373,frankvicky,2024-10-23T09:51:54Z,"sure, i will do that.",0,0.9767084717750549
1812375243,17373,frankvicky,2024-10-23T09:52:28Z,sure. :grinning_cat:,0,0.9685050845146179
1812406378,17373,showuon,2024-10-23T10:10:40Z,let's add some tests for this class. thanks.,1,0.9686755537986755
1812696648,17373,frankvicky,2024-10-23T12:54:26Z,"ah, i have just found that we already have test cases for it. [a link]",0,0.8502287864685059
1813031963,17373,frankvicky,2024-10-23T15:24:28Z,"[a link] since `log4j-appender` is depending on `clients`, we will need to delete `log4j-appender` module if we want to entirely get rid of `log4j`. [a link] cc.",0,0.9940376281738281
1813405127,17373,mimaison,2024-10-23T19:17:30Z,the link also needs updating (as well as the line number),0,0.9907591342926025
1813427142,17373,mimaison,2024-10-23T19:36:09Z,"i'm not convinced we need that dependency. also it seems to complain about an annotation so at least we should not need it at runtime, so we should not include it in our distribution package. currently it's included in the artifact generated by `releasetargz`.",0,0.689576268196106
1813429859,17373,mimaison,2024-10-23T19:38:40Z,let's keep the newline,0,0.9701692461967468
1813430705,17373,mimaison,2024-10-23T19:39:25Z,we probably don't need this zookeeper logger,0,0.9696700572967529
1814229869,17373,frankvicky,2024-10-24T04:31:35Z,"fair enough, i will try to solve this one.",0,0.9435627460479736
1814232672,17373,frankvicky,2024-10-24T04:36:33Z,"yes, we need to clean up the zk-related configurations. i plan to split this into a separate jira and pr, as previously discussed with . wdyt ? [a link]",0,0.9879143834114075
1814233350,17373,frankvicky,2024-10-24T04:37:34Z,i have opened a pr for it #17588,0,0.9764249324798584
1814236919,17373,frankvicky,2024-10-24T04:43:17Z,"since this line is directly linked to a file in the `trunk` branch, a better solution might be to modify the document after this pr gets merged. i can file a jira to track this modification if you agree. wdyt?",0,0.981984555721283
1819719894,17373,ppkarwasz,2024-10-28T20:35:35Z,"the bnd annotations are intentionally in the `provided` maven scope of all log4j artifacts, so that these annotations with `class` retention do not end up in the runtime classpath. you can do the same and add them as `compileonly` in gradle. the compiler warnings should disappear once [a link] is fixed. untile then we will remove the outdated ones (see apache/logging-log4j2#3133) in the next log4j release, which should remove the warning on `level`.",0,0.9948527216911316
1819769400,17373,ppkarwasz,2024-10-28T21:12:45Z,the switch from the legacy to the new configuration format can be based on the presence of specific files: [code block],0,0.994067907333374
1819834263,17373,ppkarwasz,2024-10-28T22:07:16Z,"have you considered switching to a structured configuration format like xml or yaml? the properties configuration format is not the default one and is not even one of the original ones (it appeared in version 2.4). it has [a link] to make it easier to read, but also harder to understand. the xml format does not require additional dependencies. yaml only requires [a link] that will only take an additional 400 kib in kafka's distribution. in yaml the configuration file would look like: [code block]",0,0.9935725927352905
1820021534,17373,frankvicky,2024-10-29T03:08:13Z,"hi , thanks for your feedback! :grinning_face_with_smiling_eyes: as you mentioned, the `.properties` file format indeed has a drawback of understand. i actually struggled when trying to transform the `.properties` file from log4j1 to log4j2 -- it was really painful to understand its meaning and transform them at same time. the yml format looks nice and is more readable, but changing the configuration format might require further discussion, especially since it would introduce additional dependencies to the project. i will file a jira to initiate a discussion on this.",1,0.977349579334259
1820025144,17373,frankvicky,2024-10-29T03:14:32Z,[a link] c.c.,0,0.9891133308410645
1820029662,17373,frankvicky,2024-10-29T03:22:31Z,thanks for the information. i have already changed its scope to compile time. ptal :grinning_face_with_smiling_eyes:,1,0.9398409724235535
1820546264,17373,mimaison,2024-10-29T10:36:02Z,"as long as we still support the old properties format, we can consider switching to a new format if users provide a log4j2 configuration file. i think it's worth starting a thread on the dev list to explain our options and gather some feedback.",0,0.9832573533058167
1820760649,17373,ppkarwasz,2024-10-29T13:06:21Z,", to be precise, users will **always** be able to use the configuration format of their choice, regardless of the format adopted by kafka. the choice of the configuration file format mostly concerns the **default** configuration files shipped in the `*.tar.gz` archive. if kafka ships with a `log4j2.properties` file, users will feel forced to use that one and that is imho a terrible format to work with. i have opened a [a link] to start a discussion about the subject. **ps**: there is currently a primitive [a link] that allows users to automatically convert a `log4j.properties` files into a `log4j2.xml` file. i am currently working on extending the list of formats that can be automatically converted (cf. [a link] but i will probably not have time to support the quirky `log4j2.properties` format.",0,0.7088701725006104
1820849781,17373,mimaison,2024-10-29T13:52:44Z,"i understand what you mean. my point was that some users may have built custom `log4j.properties` files and run clusters with those, and we want that to continue working. for the new log4j2 files, then yes it makes sense to evaluate the different formats. thanks for opening a thread, it's very useful to get input from an apache logging pmc member to help us make decisions.",1,0.8297156095504761
1820856701,17373,frankvicky,2024-10-29T13:55:50Z,i have file a jira for it. [a link],0,0.8340385556221008
1824026165,17373,ppkarwasz,2024-10-31T07:51:37Z,"this looks pretty much as a maintenance headache for the apache kafka team. what will happen if the user switches logging implementation (at least 3 logging implementations are supported by the log4j api, see [a link]? it looks to me that you only use this for jmx. if that is the case, log4j core provides an [a link]. you just need to enable it, since jmx is a potential source of security problems and is disabled by default. if you need to get and set the levels for other reasons, please open a thread on `dev`. users like to change logger levels programmatically so often, that we'd better offer an implementation independent api for that.",0,0.891487181186676
1824185851,17373,mimaison,2024-10-31T10:00:05Z,this is used by kafka connect. we have a rest api that allows changing the log level of all instances in a kafka connect cluster. see [a link] for the details.,0,0.9925661087036133
1824901568,17373,ppkarwasz,2024-10-31T17:41:09Z,"we can probably reach a consensus in the logging pmc to release a new log4j configuration api, that you can use to abstract from the internals of the logging implementation (see [a link]. what is the planned release date for kafka 4.x? if you wait until the end of the year, this class might not be necessary.",0,0.9944625496864319
1825368063,17373,frankvicky,2024-11-01T02:42:16Z,"hi currently, ak 4.0 release is scheduled at january 29th 2025. for further details, you can refer to the release plan: [a link]",0,0.9539442658424377
1832983990,17373,ppkarwasz,2024-11-07T16:26:28Z,"[code block] by default log events are mutable and bound to one thread. they are cleared as soon as the logging call exits. there is a [a link] that you can store in a [a link] on the test classpath, but it is easier to just take an immutable snapshot. you can also replace `logcaptureappender` with [a link] from the [a link]. you can set it up with a config like: ```xml",0,0.9941808581352234
1833659727,17373,frankvicky,2024-11-08T03:51:30Z,"very appreciate! i have applied it and tested it locally; it works like a charm. as for replacing `logcaptureappender`, i think it's a great idea. imho, leveraging an existing tool is better than building our own. i will file a jira to initiate a discussion on this.",1,0.9954350590705872
1843386874,17373,showuon,2024-11-15T08:39:46Z,nit: i thought we'll honor log4j2.properties when both log4j2.properties and log4j.properties exist. no?,0,0.9892576336860657
1843393551,17373,frankvicky,2024-11-15T08:45:31Z,"make sense. yes, we can change the order of the if-case to achieve that. i will update it in a follow-up pr.",0,0.9822351336479187
1843491362,17373,ppkarwasz,2024-11-15T09:44:53Z,"i think that `log4j.properties` should have a higher priority than `log4j2.properties`: - fresh installations of kafka 4.x will only have a `log4j2.properties` file. - if we find a `log4j.properties` file, it means that it is either an upgraded installation of kafka or the user copied their customized configuration.",0,0.9946672916412354
1843502542,17373,showuon,2024-11-15T09:51:16Z,"hmm... it makes sense. already, let's keep the log4j.properties as the highest priority. thanks.",1,0.9850624799728394
1843597095,17373,mimaison,2024-11-15T11:01:29Z,why do you want to do it in a separate pr? if we merge as is we instruct users to go check `clients/src/test/resources/log4j2.properties` but instead link to another file. if we update the comment we need to update the link.,0,0.9946590065956116
1843599782,17373,mimaison,2024-11-15T11:04:00Z,why do we recommend creating an xml file? should we point to the migration guide and to the log4j2 example file kafka will have under `config`,0,0.9951671361923218
1843600763,17373,mimaison,2024-11-15T11:05:00Z,same in the other scripts,0,0.9783695340156555
1843603382,17373,mimaison,2024-11-15T11:07:32Z,would `connectconfig` be a better name?,0,0.9929555654525757
1843606711,17373,mimaison,2024-11-15T11:10:35Z,we since removed zookeeper from the existing log4j properties files in trunk ([a link] so let's not re-add zookeeper stuff to remove it again later.,0,0.9934949278831482
1843610478,17373,mimaison,2024-11-15T11:14:24Z,let's keep the newline,0,0.9701692461967468
1843613244,17373,mimaison,2024-11-15T11:17:00Z,we can remove this new line to make it clearer the comment applies to both `org.apache.kafka.consumer` and `org.apache.kafka.coordinator.group`,0,0.9936136603355408
1843628839,17373,mimaison,2024-11-15T11:26:47Z,why are we adding this method? this looks like a rebase issue.,0,0.9353145360946655
1843629078,17373,mimaison,2024-11-15T11:27:02Z,let's keep the new line.,0,0.968391478061676
1843630758,17373,mimaison,2024-11-15T11:28:36Z,is this file still used?,0,0.9909734129905701
1843631728,17373,mimaison,2024-11-15T11:29:38Z,can we import `logmanager`?,0,0.991958498954773
1843633651,17373,mimaison,2024-11-15T11:31:29Z,nit: i know dependencies are not fully ordered but can we insert it roughly where it should be in the list instead of appending at the end.,0,0.9782509803771973
1843640613,17373,mimaison,2024-11-15T11:38:23Z,let's keep the new line. same in a few other files,0,0.9874380230903625
1843652254,17373,mimaison,2024-11-15T11:50:16Z,do we really need this as `implementation`? this is make it part of our release artifact.,0,0.9943094253540039
1843962004,17373,mimaison,2024-11-15T15:02:54Z,"this effectively changes the behavior of the `/admin/loggers` endpoint of the connect rest api. the endpoints accept the logger name in the path `/admin/loggers/{name}`. if the root logger is the empty string, it's not possible to query it anymore. i wonder if we should still expose the root logger as `root` (i assume it's possible to rename it somewhere here or in `loggingresource`). cc wdyt",0,0.9872213006019592
1843981241,17373,frankvicky,2024-11-15T15:14:27Z,i will see if we could avoid it be included in release artifact,0,0.9905200004577637
1844010558,17373,frankvicky,2024-11-15T15:24:06Z,"yes, it looks have a module name prefix is a little bit silly.",-1,0.9824385046958923
1844089662,17373,frankvicky,2024-11-15T15:51:09Z,make sense. i will apply it in next commit,0,0.970808744430542
1844097109,17373,frankvicky,2024-11-15T15:56:43Z,yes... it seems that this method has been removed in `trunk`. i will remove it in next commit.,0,0.9892428517341614
1844099567,17373,frankvicky,2024-11-15T15:58:30Z,it seems that it's not in use based on ide hint. i will remove it and build to see if we could remove this one.,0,0.982611358165741
1845315012,17373,dongjinleekr,2024-11-17T07:20:30Z,"**we should retain the root logger's name as `root`, against log4j2's naming change.** here is the comment from [a link]: to maintain compatibility with kafka connect's rest api, we need to use `root` to indicate the root logger. since the log4j2 logger names are generally `{package}.{class}` form, defining a `root` named logger is almost not reasonable. so, we don't need to be concerned about it. long time no see :smiley: since it is not mentioned in the [a link], so i will add a subsection explaining this design decision. i got some vacation this week! :smiling_face_with_halo:",1,0.8867872357368469
1845315796,17373,frankvicky,2024-11-17T07:24:38Z,very appreciate your explanation. i will modify it in the next commit. :grinning_cat:,1,0.9887366890907288
1846332278,17373,mimaison,2024-11-18T10:31:56Z,should we remove connect-log4j.properties?,0,0.9948195815086365
1846332506,17373,mimaison,2024-11-18T10:32:07Z,should we remove log4j.properties?,0,0.993724524974823
1846355549,17373,frankvicky,2024-11-18T10:43:48Z,i think it's fine now since our script has sufficient protection. it should work well when upgrading from the old version. i will delete these two configurations in the next commit.,0,0.8647885322570801
1846417125,17373,mimaison,2024-11-18T11:20:49Z,yes because otherwise we default to the log4j file so you get the warning everytime you run a command: [code block],0,0.9937022924423218
1846550136,17373,chia7712,2024-11-18T13:04:11Z,we don't need to recreate collection - [code block],0,0.9782097935676575
1846556605,17373,chia7712,2024-11-18T13:09:17Z,"why don't we keep the `root` compatibility here? after this pr, users can't set 'root=warn' to change the root level.",0,0.9912563562393188
1846632146,17373,chia7712,2024-11-18T13:55:54Z,we need to keep the null handle to avoid npe,0,0.9795254468917847
1847704612,17373,chia7712,2024-11-19T06:20:06Z,do they use the same reference? or we should use `!equals` instead of `!=`?,0,0.9937368631362915
1847704673,17373,chia7712,2024-11-19T06:20:11Z,ditto,0,0.9222367405891418
1847752728,17373,chia7712,2024-11-19T07:11:00Z,please fix the `connect.py` [a link] [a link],0,0.9927011728286743
1847767385,17373,chia7712,2024-11-19T07:24:24Z,`compileonly` is good enough i think as we don't use the annotation in runtime,0,0.975145161151886
1847776149,17373,chia7712,2024-11-19T07:28:48Z,could you please remove this method also?,0,0.993198037147522
1847864958,17373,chia7712,2024-11-19T08:12:33Z,`replicationquotastestrig` has similar code [a link] could we delete it in this pr too?,0,0.9944526553153992
1847870812,17373,chia7712,2024-11-19T08:17:09Z,do we really need `log4j1bridge2api`?,0,0.9942078590393066
1847872407,17373,chia7712,2024-11-19T08:18:21Z,please remove it from [a link] too,0,0.9930635094642639
1847873077,17373,chia7712,2024-11-19T08:18:50Z,ditto [a link],0,0.9786297678947449
1847874109,17373,chia7712,2024-11-19T08:19:37Z,please add it to `license-binary` file,0,0.993901252746582
1847964777,17373,frankvicky,2024-11-19T09:21:34Z,"some apis rely on it, such as `propertyconfigurator`. however, since we are removing it, we might not need the log4j bridge anymore. i will test this locally.",0,0.9920874238014221
1848323271,17373,dongjinleekr,2024-11-19T13:03:22Z,"when i worked on this issue last, it was required to support the log4j 1.x configuration file.",0,0.9920206665992737
1848672753,17373,chia7712,2024-11-19T16:23:18Z,"in the e2e we could run kafak on different version, so we must check the version before applying the config file.",0,0.9911676645278931
1848672880,17373,chia7712,2024-11-19T16:23:22Z,ditto,0,0.9222367405891418
1848672960,17373,chia7712,2024-11-19T16:23:25Z,ditto,0,0.9222367405891418
1850373880,17373,chia7712,2024-11-20T14:02:53Z,"it seems connect e2e does not run different version for workers, so you can just change them to `connect_log4j2.yaml`. however, please change the `-dlog4j.configuration` to `-dlog4j2.configurationfile`",0,0.9950807094573975
1850375006,17373,chia7712,2024-11-20T14:03:41Z,please noted that the previous version should use `-dlog4j.configuration` and trunk version should use `-dlog4j2.configurationfile`,0,0.9939984083175659
1850378575,17373,chia7712,2024-11-20T14:05:59Z,please add `filepattern`,0,0.9925755262374878
1850514477,17373,ppkarwasz,2024-11-20T15:21:56Z,"since there is only one triggering policy, there is no need to wrap it in a [a link]. btw: there is a typo in the plugin name: it should be `policies`, instead of `polices`.",0,0.994784414768219
1850545236,17373,frankvicky,2024-11-20T15:35:32Z,thanks for information :grinning_face_with_smiling_eyes:,1,0.528317391872406
1850570634,17373,frankvicky,2024-11-20T15:50:47Z,it seems that tons of code needs to apply this change. i will prepare it asap.,0,0.8994085192680359
1860858017,17373,mimaison,2024-11-27T15:23:24Z,"with the current code, updating connect loggers does not work. for example, i get: [code block] we should not return an unmodifiablelist here. in the `loggers()` method above we call `add()` on the `list`. here is the stack trace: [code block]",0,0.9934710264205933
1864432648,17373,chia7712,2024-11-30T18:52:38Z,"`get_log4j_config_for_connect(node)` does not point to the ""full"" path, so all related services can't start up as it fails to find the log4j2 config. please use `os.path.join(self.persistent_root, get_log4j_config_for_connect(node))` instead",0,0.9942939877510071
1864432755,17373,chia7712,2024-11-30T18:53:07Z,"ditto. `get_log4j_config_for_connect(node)` is a file name rather than full path. please use `os.path.join(self.persistent_root, get_log4j_config_for_connect(node))` instead",0,0.9945002794265747
1864432782,17373,chia7712,2024-11-30T18:53:14Z,ditto,0,0.9222367405891418
1864435374,17373,chia7712,2024-11-30T19:03:51Z,i don't think those configs file are existent. please remove it,0,0.9265279769897461
1864435870,17373,chia7712,2024-11-30T19:06:10Z,"ditto. use `os.path.join(self.persistent_root, get_log4j_config(node))` instead",0,0.9911473393440247
1864435899,17373,chia7712,2024-11-30T19:06:25Z,"ditto. use `os.path.join(self.persistent_root, get_log4j_config(node))` instead",0,0.9911473393440247
1864456124,17373,chia7712,2024-11-30T19:42:15Z,why do we override the config path? it breaks all e2e since the custom log4j config can't be used.,0,0.9533147215843201
1864456149,17373,chia7712,2024-11-30T19:42:24Z,ditto,0,0.9222367405891418
1864456157,17373,chia7712,2024-11-30T19:42:27Z,ditto,0,0.9222367405891418
1864457267,17373,chia7712,2024-11-30T19:46:59Z,"im not sure why we override the `kafka_log4j_opts` here. we typically allow users to define custom `kafka_log4j_opts`. moreover, overriding `kafka_log4j_opts` can break many end-to-end tests, as they often create log4j configurations dynamically and pass them through `kafka_log4j_opts` noted that we do not require users to strictly use the path `$base_dir/../config/log4j2.xml`.",0,0.9903179407119751
1864898855,17373,chia7712,2024-12-01T13:45:14Z,please update it as well. the path is incorrect,0,0.7661750316619873
1893936536,17373,ijuma,2024-12-20T13:23:56Z,why did we do this in many files instead of kafka-run-class?,0,0.9922829270362854
1893938757,17373,ijuma,2024-12-20T13:25:55Z,how come these are `implementation` while `slf4jlog4j` is `testimplementation`?,0,0.9942994117736816
1893939705,17373,ijuma,2024-12-20T13:26:48Z,why is this needed?,0,0.9731205701828003
1893947193,17373,ijuma,2024-12-20T13:34:14Z,"two questions: 1. have we tested that this log configuration results in the same output as the previous one? in particular, we should avoid anything that requires collecting a stacktrace to log (we made sure of that for the previous configuration). 2. have we benchmarked the system to make sure there aren't any regressions due to the new logging library? i saw a jira/pr saying that log4j2 has a particularly costly `getlogger` implementation.",0,0.990239143371582
1894092841,17373,chia7712,2024-12-20T15:45:05Z,[a link] needs it to configure the log level at runtime,0,0.9919413328170776
1894121803,17373,frankvicky,2024-12-20T16:12:03Z,"i added `spotbugs` to address the compiler warnings. while we could suppress these warnings using `-xlint:all,-classfile`, i prefer not to relax compiler checks. ideally, we should avoid depending on core-specific methods altogether. however, that would require thorough pass to our code. i suggest we create a separate jira ticket to track this architectural improvement as a future enhancement. for further details: [a link]",0,0.9840096831321716
1894124425,17373,chia7712,2024-12-20T16:14:07Z,"`jacksondatabindyaml` is required to parse yaml config - see [a link] however, it seems we can do a bit cleanup for `jacksondatabindyaml` as not all modules need to add explicit reference",0,0.9930186867713928
1894164970,17373,chia7712,2024-12-20T16:50:29Z,"i will use log4j-2 transform tool to check the config later ([a link] could you please share the commit to me? i trace the history ([a link] and fails to see the fix about ""avoid anything that requires collecting a stacktrace"". according to official docs ([a link] the performance of ""logging"" has no obvious regression. it seems the story is about `getlogger` - [a link] and [a link] - there is already a pr to fix it #17896 - we can discuss the improvement on it.",0,0.9779797792434692
1894238151,17373,ppkarwasz,2024-12-20T18:05:23Z,"at apache logging we had several other issue reports regarding our usage of annotations in the `provided` scope (see [a link] for example). regarding the [a link] that causes this particular problem: - imho the compiler should not issue any warnings if it is missing, since the annotation has a retention of `class` and is totally invisible at runtime. i submitted [a link] to change the compiler's behavior. - log4j core could theoretically move spotbugs annotations from the `provided` to the `compile` scope, but this could cause legal problems, since the annotation library is licensed under lgpl and this can not be changed (see [a link] this is one of the reasons we keep the library in the `provided` scope, so it does not propagate to consumers.",0,0.9887500405311584
1894553541,17373,ijuma,2024-12-21T04:35:02Z,"yeah, the licensing issue is the reason i wanted to avoid using this library at all. can we use a different library for annotations, one that is apache licensed?",0,0.9226869344711304
1894553658,17373,ijuma,2024-12-21T04:36:54Z,"we should perhaps bite the bullet and just make the slf4jlog4j choice for the server (i.e. include it as `implementation`). after all, unless you choose this, some functionality won't work.",0,0.980215311050415
1898304621,17373,ppkarwasz,2024-12-27T06:48:34Z,"imho the `kafka_ ` artifact should not have these dependencies, these dependencies should be added **only** to the binary kafka distribution. otherwise kafka will leak the log4j core dependencies to its consumers, similarly to what was happening with zookeeper (see [a link]. to add dependencies only to the binary distribution, you could use something similar to apache/eventmesh#4719, i.e. a separate `distonly` gradle configuration. `log4jcontroller` can be rewritten to use log4j core if present or a no-op implementation otherwise, so the log4j core can be declared as an [a link]. **note**: i am working on a `org.apache.logging:logging-admin` artifact (see [a link] that would provide the same functionality as `log4jcontroller`, but in a logging implementation independent way. unfortunately i have a long todo list before i can publish it, so probably it won't be ready for kafka 4.",0,0.9952632188796997
1898313661,17373,chia7712,2024-12-27T07:06:32Z,"`log4jcontroller` is used exclusively by the server, so exposing its dependencies should be acceptable.",0,0.9932721257209778
1898356316,17373,ppkarwasz,2024-12-27T08:27:49Z,"in kafka 3.9.0, the dependency on `ch.qos.reload4j:reload4j` is declared `compileonly`: [a link] the dependency is added to the binary distribution in a separate task: [a link] these dependencies should probably be handled in a similar way.",0,0.9954025745391846
1898357031,17373,ppkarwasz,2024-12-27T08:29:30Z,"**note**: no modern library uses log4j 1 in code (they use jcl, slf4j or log4j api), so my guess is that `libs.log4j1bridge2api` could be dropped entirely.",0,0.9927664995193481
1898365578,17373,chia7712,2024-12-27T08:44:31Z,"yes, we can declare them as compileonly and then add them to the distribution. however, the flexibility of replacing the slf4j provider at runtime may break the functionality of log4jcontroller (similar to [a link]. kip-1064 is attempting to use slf4j2's system variable to choose the provider more effectively. pardon me, in the #18290 we decide to allow users to use log4j.properties - so we still need `log4j-1.2-api`, right?",0,0.9875696301460266
1898478552,17373,ppkarwasz,2024-12-27T12:16:27Z,"as far as i can tell, this is the way `log4jcontroller` worked in kafka 3.x: if the optional `ch.qos.reload4j` dependency was absent, the class didn't work. sorry, my mistake.",-1,0.9893368482589722
1898534270,17373,chia7712,2024-12-27T14:12:27Z,"yes, you're right. perhaps we should consider offering similar functionality for other popular slf4j providers, such as logback and jul. wdyt?",0,0.9380914568901062
1898950768,17373,ijuma,2024-12-28T16:39:13Z,"it is true that we previously tried hard to avoid making the logging choice for the maven artifact while making it for the distributed binaries. however, this is brittle and only worked partially. when i tried to fix it in #12148, it caused problems and it was partially reverted (#16260, #16559). also, it's actually bad to silently not support the dynamic logging functionality for the broker (this is _incredibly_ useful in production). so, i think the simplest thing is to make the logging choice explicit for the server modules (the rare user who doesn't want that can still override it with exclusions via their build file) and leave it up to the applications for the client modules. in the future, if there is a way to address these issues, we can change it again. there are two promising and complementary paths: 1. your logging admin library. 2. slf4j2 makes it possible to choose the logging library dynamically instead of via classpath tricks.",0,0.5111755132675171
1898983229,17373,ppkarwasz,2024-12-28T20:04:38Z,"i pushed the draft to apache logging ([a link] and i'll start to actively work on it. probably you can expect a release by end of january/february. in the meantime i can make a pr for kafka, so that `log4jcontroller` fails softly if log4j core is not present. note that choosing the slf4j implementation does not really tell you which logging implementation is being used: except logback, all the other slf4j implementation are bridges between logging apis. if you use `slf4j-jdk14` you don't know which jul implementation is being used and if you use `log4j-slf4j2-impl` you don't know which log4j api implementation is being used.",0,0.983159601688385
1899049780,17373,chia7712,2024-12-29T02:16:54Z,"yes, it would be great to display accurate error messages!",1,0.6858112812042236
1166622209,13561,divijvaidya,2023-04-14T09:56:51Z,"should this operation be performed in a separate thread pool which can have a defined quota? (similar to how we perform cleaning for local log using separate cleaner/background threads). i am concerned that this may impact the rate of copy to remote if amount of cleaning is large. also, it's perhaps better to have different scaling characteristics for cleaning from remote vs. copying. copying maybe considered urgent since slowness in copying can potentially fill up disk whereas cleaning from remote may be a lower priority activity.",0,0.9885463714599609
1166661016,13561,divijvaidya,2023-04-14T10:28:00Z,"the current logic may cause deletion of more data than anticipated. this is because it is possible to have remote segments satisfying this condition which are not part of the current leadership epoch chain. calculation of totalsizeearliertolocallogstartoffset may include these segments as well and hence, the calculation of totalsize will include local segments + all remote segments (< local log start offset). the calculated totalsize will be actually larger than the actual total size (where actual total size = size of remote + local log for the active epoch chain). this will lead to higher value of remainingbreachedsize than actual and hence, more data gets deleted than necessary. is this making sense? else i can provide an example to explain it better.",0,0.9912249445915222
1166767890,13561,divijvaidya,2023-04-14T12:20:05Z,"we don't need to calculate this for time based retention. right? if yes, can we refactor the code here so that we perform size calculation (since it requires a full scan over all log segments) only when it's required i.e. for size based retention.",0,0.9924319982528687
1166839800,13561,divijvaidya,2023-04-14T13:30:56Z,we are only interested in segments in state copy_segment_finished or delete_segment_started here. right? (delete_segment_started to clean up any stragglers) can we make this more explicit by filtering on them?,0,0.9933964014053345
1166850232,13561,divijvaidya,2023-04-14T13:40:18Z,could we check for `if (iscancelled() || !isleader())` here again please to short circuit this expensive loop during shutdown.,0,0.993798553943634
1166854317,13561,divijvaidya,2023-04-14T13:44:11Z,"`iscancelled() || !isleader()` also, please add a log which can help operator understand that this was actually cancelled.",0,0.9941745400428772
1166856223,13561,divijvaidya,2023-04-14T13:45:51Z,please guard this update with `isleader()`,0,0.9927056431770325
1166868212,13561,divijvaidya,2023-04-14T13:56:20Z,"unreferenced segments are not only the ones which have a lower epoch that earliest known epoch, they could also be ones which have an epoch that is not part of active epoch chain. how are we handling that?",0,0.9779777526855469
1166876777,13561,divijvaidya,2023-04-14T14:03:57Z,"i would appreciate your response on [a link] where we discussed that even with caching mechanism, warm up of the cache is going to slow down the copying. i agree that this can be discussed outside the scope of this pr but adding the above thread as fyi.",1,0.7397468686103821
1166892667,13561,divijvaidya,2023-04-14T14:13:29Z,do we need this at a warn level?,0,0.9908384680747986
1166896440,13561,divijvaidya,2023-04-14T14:17:00Z,i would suggest to have address local retention in a separate pr. we can limit this pr to handling remote log retention only.,0,0.9927878975868225
1167074461,13561,Hangleton,2023-04-14T16:53:04Z,"hmm, i don't think it is enough to evict the data for epochs < than the current leader's smallest epoch. with unclean leader election, it is possible to have divergence in-between a log prefix and suffix shared by two replicas.",0,0.6542236804962158
1167086128,13561,Hangleton,2023-04-14T17:01:09Z,"hmm, it seems we are iterating over all remote segment metadata every time the expiration task is executed. this could become costly if the rlmm implementation does not cache the said metadata. that could be an explicit implementation constraint for plugin providers. maybe we could also add a small layer a memoization here to avoid traversing the log metadata every time.",0,0.919241189956665
1180118575,13561,showuon,2023-04-28T08:50:56Z,"good suggestion. but we don't include this part in the original kip, we need another kip to improve it.",1,0.8786540627479553
1180121259,13561,showuon,2023-04-28T08:53:12Z,"we might need to add logs here to describe why we need to update highest offset in remote storage for followers. i think that's for fetch from follower replica feature, right?",0,0.9929260015487671
1180123353,13561,showuon,2023-04-28T08:55:09Z,nit: assume that segments contain size >= 0,0,0.9832119345664978
1180137735,13561,showuon,2023-04-28T09:06:15Z,i agree this could be costly if the rlmm implementation doesn't cache the metadata. but i don't think there's an implementation constraint for plugin providers. they can always cache them in the plugin. i'm thinking it should be enough if we add something about it in the rlmm#listremotelogsegments javadoc.,0,0.9721240401268005
1180254846,13561,divijvaidya,2023-04-28T10:41:45Z,"that is fair. as i mentioned in the [a link], i am fine (and would actually prefer) with creating jiras and tackling the perf related comments outside this pr. with this comment, i wanted to make sure we are aware and are tracking things that need fixing in this code.",1,0.9018761515617371
1181520975,13561,satishd,2023-05-01T11:24:07Z,"this is different from local log deletion. it requires the deletion of segments from local storage which need to really delete the files. but incase of remote storages, it does not wait for the data to be deleted but it marks the file or object for deletion in their respective metadata stores. respective garbage collectors in those storages will take care of deleting the data asynchronously. there is no perf impact for these delete calls as they take a much shorter time than copying segments. it is very unlikely that copying segments get affected because of the deletion of segments. deletion checks are happening in every iteration so there will not be many segments that need to be deleted. anyways, we can discuss this separately in a separate jira. on another note, all this logic will go to unifiedlog in future.",0,0.9890567660331726
1181526976,13561,satishd,2023-05-01T11:41:52Z,"log.retention.<> configs indicate the total amount of log segments that can be stored in remote storage. so, it is not just about the segments only related to the current leader epoch lineage. we need to be careful of removing any unreferenced segments and also should not have any segment leaks in the remote storage incase of unclean leader elections. so, it cleans up any unreferenced segments beyond the earliest leader epoch that are also available for retention checks.",0,0.9916472434997559
1181527119,13561,satishd,2023-05-01T11:42:21Z,we do not need any specific check here as we want to clean up any segment that is not yet deleted including copy_segment_started,0,0.9910418391227722
1181528820,13561,satishd,2023-05-01T11:46:37Z,unreferenced segments within the current leader epoch chain will eventually move earlier to the earliest epoch of the current leader epoch chain after a few retention checks. that will take care of those kinds of segments.,0,0.9926517605781555
1181529149,13561,satishd,2023-05-01T11:47:19Z,"sure, let us discuss this out side of this pr.",0,0.9900651574134827
1181532348,13561,satishd,2023-05-01T11:56:03Z,unreferenced segments within the current leader epoch chain will eventually move earlier to the earliest epoch of the current leader epoch chain after a few retention checks. that will take care of those kinds of segments.,0,0.9926517605781555
1181545427,13561,showuon,2023-05-01T12:31:09Z,"it's confusing we update `_locallogstartoffset` twice with different value. i think the one in l982 should be removed, right?",-1,0.7666757702827454
1182338603,13561,Hangleton,2023-05-02T09:53:16Z,"hmm, i am not sure this is the right thing to do, because including segments which are not part of a log yields a size which is not truly that of the log. it is possible to design scenarios with a log chronology which allows for premature deletion of data under size-based retention. while i understand that deleting unreferenced segments is consistent with the local log use case, where some data can be lost too, a key difference here between this approach and the current retention semantics applied for local logs is that in the latter case, all segments belong to the current log when the log size is calculated, so that the size-based retention policy always apply to the current log. eviction of unreferenced segments/data in the local case happens via truncation separately from the enforcement of retention policies. but here, both are retention-based and truncation-driven eviction are _de facto_ combined. what are the benefits of diverging from these semantics with tiered segments?",0,0.7177785038948059
1197648143,13561,Hangleton,2023-05-18T10:16:16Z,"i see, yes that's right those segments will eventually fall out of the range of active leader epochs. that should be fine, as long as users know there is no specific enforcement on the time those unreferenced segments will be cleaned up.",0,0.969139039516449
1203191600,13561,junrao,2023-05-24T00:10:33Z,unnecessary semicolon. ditto in kafkaserver.,0,0.9535902142524719
1203192234,13561,junrao,2023-05-24T00:11:04Z,missing javadoc for new param.,0,0.9848532676696777
1203194554,13561,junrao,2023-05-24T00:12:15Z,should we exit the loop the first time a remote segment offset passes locallogstartoffset?,0,0.9939789772033691
1203195682,13561,junrao,2023-05-24T00:12:59Z,what about overlapping segments between remote and local? do we double count them?,0,0.9797245264053345
1203196737,13561,junrao,2023-05-24T00:13:53Z,are we iterating the same remote segment multiple times since a segment could have multiple epochs?,0,0.9828178882598877
1203197683,13561,junrao,2023-05-24T00:14:43Z,"loggering uses $ notation, which is for scala.",0,0.9887679219245911
1203198445,13561,junrao,2023-05-24T00:15:23Z,"hmm, not sure that i follow the comment.",-1,0.5688490271568298
1203200216,13561,junrao,2023-05-24T00:16:50Z,"hmm, logstartoffset could be larger than base offset of the first local segment. so, it seems that we can't just switch to the base offset of the first local segment if remote log is not enabled.",0,0.8673282265663147
1203200822,13561,junrao,2023-05-24T00:17:24Z,should we return here to actually ignore?,0,0.9771335124969482
1203201676,13561,junrao,2023-05-24T00:18:10Z,"yes, agreed. not sure why we need to update _locallogstartoffset here again.",0,0.9494045376777649
1203202960,13561,junrao,2023-05-24T00:19:13Z,"hmm, local retention needs to be bound by last tiered offset, right?",0,0.9805319905281067
1203204099,13561,junrao,2023-05-24T00:20:07Z,"retention time depends on remote storage being enabled, right? ditto in line 2284.",0,0.9910106658935547
1205425110,13561,showuon,2023-05-25T12:13:00Z,"debug(""update {} with remotelogstartoffset: {}"", topicpartition, remotelogstartoffset)",0,0.9927922487258911
1205437354,13561,showuon,2023-05-25T12:20:51Z,additional `$` sign: remote log segment [$]{} ...,0,0.9929007291793823
1209013637,13561,showuon,2023-05-29T07:33:46Z,nit: less than,0,0.7558476328849792
1213100593,13561,satishd,2023-06-01T12:47:30Z,`listremotelogsegments(topicidpartition topicidpartition)` are not returned in any specific order.,0,0.9938369393348694
1213102668,13561,satishd,2023-06-01T12:49:15Z,"`totalsizeearliertolocallogstartoffset` computes only the log segments in remote storage beyond local-log-start-offset. the remaining local log segments size is computed separately. so, there will be no overlapping segments.",0,0.9942692518234253
1213107255,13561,satishd,2023-06-01T12:51:17Z,"no, it is taken care of. when we remove a remote log segment, it also updates that entry in rlmm in synchronous manner. so, rlmm store will remove the entry from respective epoch states.",0,0.9932424426078796
1213107956,13561,satishd,2023-06-01T12:51:51Z,updated the comment to make it more clear.,0,0.9816639423370361
1213112946,13561,satishd,2023-06-01T12:55:34Z,"we already set the locallogstartoffset as max of passed logstartoffset and the first segment's base offset. when remote log is not enabled, `logstartoffset` is set as `locallogstartoffset` as computed above.",0,0.9951677322387695
1213113458,13561,satishd,2023-06-01T12:56:00Z,this is addressed with the latest commits.,0,0.9909663200378418
1222183059,13561,junrao,2023-06-07T21:12:47Z,extra new line,0,0.9711894392967224
1222183119,13561,junrao,2023-06-07T21:12:51Z,extra new line,0,0.9711894392967224
1222183188,13561,junrao,2023-06-07T21:12:57Z,extra new line,0,0.9711894392967224
1222189063,13561,junrao,2023-06-07T21:20:34Z,"let's say there is a remote segment with startoffset 100 and endoffset 200. if the locallogstartoffset is 150, we exclude the remote segment. this means that we are undercounting the size, right?",0,0.9860295653343201
1222205974,13561,junrao,2023-06-07T21:43:25Z,"hmm, why do we need a separate retention based on leader epochs? is that not already covered by size/time/startoffset based retention?",0,0.9800312519073486
1222283938,13561,junrao,2023-06-07T23:42:27Z,this is already done in `updatelogstartoffset`. do we need to do it here again?,0,0.9945719838142395
1222315217,13561,junrao,2023-06-08T00:38:00Z,we already log the completion of the load loading in logmanager. could we fold this there to avoid double logging?,0,0.994164764881134
1223300322,13561,junrao,2023-06-08T16:35:58Z,"hmm, this logic doesn't look right. if a client calls `deleterecords`, we call `maybeincrementlogstartoffset` with onlylocallogstartoffsetupdate=false. so, we will go through this branch and update _locallogstartoffset. this will be incorrect if remote log is enabled.",0,0.8503967523574829
1223303905,13561,junrao,2023-06-08T16:39:51Z,is highestoffsetinremotestorage inclusive or exclusive? it would be useful to document that.,0,0.9917293190956116
1223312004,13561,junrao,2023-06-08T16:47:45Z,extra new line,0,0.9711894392967224
1224374293,13561,divijvaidya,2023-06-09T14:22:38Z,please add a debug log here (and other places where we are exiting this function) so that we know while debugging where did we exit the function from.,0,0.9883184432983398
1224420683,13561,divijvaidya,2023-06-09T14:57:29Z,please add an info log on why we exited the function prior to it's completion. it greatly helps debugging when we don't have to guess where the return point was.,0,0.9784595966339111
1226259513,13561,divijvaidya,2023-06-12T08:15:09Z,please add the following check. we don't want to construct an object for retentionsizedata if not required. [code block],0,0.9843931794166565
1226261499,13561,divijvaidya,2023-06-12T08:16:47Z,"please perform an argument validation here. if retentionsize < remainingbreachedsize, then illegalargumentexception. same for retentiontimedata",0,0.9923563003540039
1226268535,13561,divijvaidya,2023-06-12T08:21:09Z,this comment has been addressed in the latest code,0,0.9892364144325256
1226280821,13561,divijvaidya,2023-06-12T08:31:03Z,nit unnecessary else,-1,0.8457072973251343
1226315828,13561,divijvaidya,2023-06-12T08:53:45Z,we need to restore the original value of remainingbreachedsize when remainingbreachedsize < 0? may i suggest re-writing this entire predicate here as: [code block] note that remainingbreachedsize is a member of the class and you don't need to do `retentionsizedata.get().remainingbreachedsize`. also the earlier `if (retentionsizedata.get().remainingbreachedsize > 0) {` is made redundant by the code i suggested.,0,0.993503987789154
1226433742,13561,divijvaidya,2023-06-12T10:25:03Z,nit s/log size after deletion/local log size after deletion asking so that the reader can disambiguate between log size (which is tiered + local) and local log size.,0,0.9907922744750977
1226467554,13561,divijvaidya,2023-06-12T10:50:38Z,should we ensure that we have acquired the partition `lock` first?,0,0.9945047497749329
1226471102,13561,divijvaidya,2023-06-12T10:53:59Z,this should probably be a error level log because we don't expect to call this method when remote storage is disabled. isn't that right?,0,0.974224865436554
1226517527,13561,divijvaidya,2023-06-12T11:33:37Z,"we are assuming that the state of local log will remain same from this point to the time we use the information computed here (i.e. totalsizeearliertolocallogstartoffset ) to delete the segments. but that is not true since local retention threads are running concurrently and might have moved the locallogstartoffset by the time we use the `totalsizeearliertolocallogstartoffset` computed here. as an example: ### time instant: t1 locallso = 10 lso = 0 lse = 20 tieredeo = 15 in this case we will calculate `totalsizeearliertolocallogstartoffset` as the size from 0-10. ### time instant: t2 local log retention thread deletes some stuff and updates the locallso=14 ### time instant: t3 when we calculate `long totalsize = log.validlocallogsegmentssize() + totalsizeearliertolocallogstartoffset;` at `buildretentionsizedata`, validlocallogsegmentssize returns data from 14-20 and we say that the total size = totalsizeearliertolocallogstartoffset ( i.e. 0-10) + validlocallogsegmentssize (i.e. 14-20). this leads to data from 11-13 not being counted anywhere. this looks like a bug! we need to re-use the values stores at the beginning of the retention calculation otherwise other threads (local retention threads) may change the values behind the scenes. thoughts?",0,0.9937066435813904
1226536841,13561,divijvaidya,2023-06-12T11:50:51Z,"sorry, i am a bit confused here. earlier in the comment [a link] you mentioned that retention size/time configuration applies across all epochs. i.e. if i say retention is 3gb and the total log as per current epoch is 2 gb, but the total data stored in remote +local = 7gb, then i will delete (7-3) = 4gb of data as part of this cleanup. is my understanding correct? if yes, then we seem to be deleting only the current leadership chain here but we are using the breached size from all the epochs calculated earlier. isn't this contradictory?",-1,0.9842947721481323
1226538752,13561,divijvaidya,2023-06-12T11:52:40Z,"even if we are not the leader at this stage, we have deleted the logs in remote. shouldn't we still update the metadata?",0,0.9899657964706421
1234978872,13561,satishd,2023-06-20T09:12:40Z,"it is inclusive, updated with the doc describing about the variable.",0,0.9815874695777893
1234980098,13561,satishd,2023-06-20T09:13:45Z,i guess that is fine as retention size is more about the minimum size available in the topic partition. that segment will be deleted when the local-log-start-offset moves in later cycles.,0,0.9844216108322144
1234980957,13561,satishd,2023-06-20T09:14:25Z,"it was updated based on log-start-offset with `updatelogstartoffset`, but local-log-start-offset can be more than that and it will be updated if needed.",0,0.9937822222709656
1246792402,13561,jeqo,2023-06-29T15:29:31Z,"i also find it strange to repeat the mutations of hwm and local log recovery point in both updates, we can pull those two updates into a single method and call it once?",0,0.9588996767997742
1246831654,13561,jeqo,2023-06-29T15:52:44Z,"is it correct to update locallogstartoffset directly, but use updatelogstartoffset method to also update related values (hwm and local log recovery)?",0,0.9951764345169067
1247609605,13561,jeqo,2023-06-30T08:46:28Z,"found this a bit confusing. in main operation `onlylocallogstartoffsetupdate` is false by default, but here we are overriding with `onlylocallogstartoffsetupdate` as true, and methods signature are mainly the same. wouldn't be clearer to use the default method with `onlylocallogstartoffsetupdate=true` instead of creating this private method?",0,0.4991641938686371
1247799637,13561,jeqo,2023-06-30T12:19:02Z,nit: [code block],0,0.9847351312637329
1247807726,13561,jeqo,2023-06-30T12:28:17Z,"if i'm reading the call path correctly, this is not the case. `handlelogstartoffsetupdate` function is called only at the end of `cleanupexpiredremotelogsegments` that filters out calls from followers. i guess we could either remote the `isleader` validation here, or move this logic within the lambda itself?",0,0.9951164722442627
1247839591,13561,jeqo,2023-06-30T13:03:12Z,maybe worth adding a log message here stating why cleanup is not happening? or maybe just a comment explaining why this scenario may never happen given the low prob that recordversion < 2 is used.,0,0.9871719479560852
1247868877,13561,jeqo,2023-06-30T13:30:32Z,could we add a log info here similar to copy? [code block],0,0.9929078817367554
1247878833,13561,jeqo,2023-06-30T13:40:08Z,", could you elaborate a bit more what do you mean by ? is this relying on some specific storage backend implementation?",0,0.9867647886276245
1281564595,13561,showuon,2023-08-02T08:20:58Z,", what satish meant, is in most remote storage case, the deletion api won't wait until data deleted in remote storage, instead, it'll mark file as deleted and return immediately. and run background gc in remote storage to delete the deleted flagged file.",0,0.9896522164344788
1281568519,13561,showuon,2023-08-02T08:24:15Z,"i agree with 's suggestion. in this scenario: 1. replica 1 is the leader, and doing remote log segment deletion 2. leadership changed to replica 2 3. replica 1 entering this `handlelogstartoffsetupdate` method under current implementation, we won't update log start offset since it is not the leader anymore. but we should update it! , thoughts?",1,0.88916015625
1281575922,13561,showuon,2023-08-02T08:30:07Z,"+1, or at least a debug level.",0,0.9826108813285828
1281648556,13561,showuon,2023-08-02T09:28:21Z,"as commented above, there might be chances that the leadership change during the segment deletion, i think we should update the log start offset before exiting the `cleanupexpiredremotelogsegments` method since if there's no deletion happened, the `logstartoffset` will be empty. wdyt?",0,0.9921634197235107
1281657244,13561,showuon,2023-08-02T09:35:36Z,should we log partition info as below did here?,0,0.9948192238807678
1281660832,13561,showuon,2023-08-02T09:38:41Z,"the comment is not clear: `// segment's first epoch's offset [should] be more than or equal to the respective leader epoch's offset.` the log is not correct: `""[{}] remote segment {}'s first epoch {}'s offset is [less] than leader epoch's offset {}."",`",0,0.9913302659988403
1281664514,13561,showuon,2023-08-02T09:41:56Z,+1,0,0.7702900171279907
1281667417,13561,showuon,2023-08-02T09:44:36Z,why don't we log `reason` here?,0,0.9902640581130981
1281671130,13561,showuon,2023-08-02T09:47:59Z,nit: it's weird to see `local log retention size` when user is not enabled the tiered storage. could we add a if check to see if remote storage is enabled or not and print the log accordingly?,-1,0.9732186794281006
1281672320,13561,satishd,2023-08-02T09:48:59Z,"all the size/time/startoffset handlers run based on the current leaders leader epochs. here, we are removing the segments which have leader epochs earlier to the lowest leader epoch on this broker(partition leader).",0,0.9936583638191223
1281675518,13561,showuon,2023-08-02T09:51:35Z,nice test!,1,0.9956727027893066
1281844159,13561,satishd,2023-08-02T12:37:14Z,good point! addressed in the latest commits to keep the logic simpler.,1,0.9862980842590332
1283024088,13561,satishd,2023-08-03T10:50:15Z,it is not mandatory to update it when this node becomes a follower as the existing follower fetch protocol makes sure that the follower truncates their log-start-offset based on the leader's log-start-ffset.,0,0.9944188594818115
1284241897,13561,satishd,2023-08-04T10:10:50Z,this is not required as the updated code does not use this method.,0,0.9930127263069153
1284278935,13561,satishd,2023-08-04T10:54:02Z,good catch.,1,0.9815194606781006
1284280124,13561,satishd,2023-08-04T10:55:05Z,replied in the [a link].,0,0.989623486995697
1287757841,13561,junrao,2023-08-08T22:37:26Z,identation doesn't match other places in this file.,0,0.960460901260376
1287764297,13561,junrao,2023-08-08T22:50:50Z,"since newlocallogstartoffset is larger than locallogstartoffset(), could we just assign newlocallogstartoffset to _locallogstartoffset?",0,0.9954980611801147
1288778006,13561,junrao,2023-08-09T15:52:12Z,"hmm, i still don't quite understand this part. the leader's epoch chain only gets trimmed from the beginning when segments are deleted due to retention or the advancement of the startoffset by `deleterecord()` call. these are covered by the size/time based retention and logstartoffset based retention. so what additional cases does the following code cover?",0,0.7465651035308838
1288852233,13561,junrao,2023-08-09T16:18:28Z,"here is a corner case. let's say remote log is enabled, but there is no remote segment (all have been deleted due to retention). the new logic will do retention based on `localretentionbytes`, but it should actually do the retention based on `retentionsize`. if that happens, we need to advance logstartoffset, in addition to locallogstartoffset.",0,0.9940882921218872
1288860833,13561,junrao,2023-08-09T16:25:57Z,"hmm, this should be false, right? do we have a test case to cover that?",0,0.940203845500946
1288884433,13561,junrao,2023-08-09T16:41:47Z,this is an existing issue. but there is one direct reference to `_locallogstartoffset` in `fetchoffsetbytimestamp()`. should we change that to use `locallogstartoffset()` instead?,0,0.9912770986557007
1288898898,13561,junrao,2023-08-09T16:54:23Z,"this doesn't look right. if remote log is not enabled, it seems that we should delete based on logstartoffset, not locallogstartoffset.",0,0.8610590696334839
1289488513,13561,satishd,2023-08-10T03:08:13Z,"no, this should be true if the remote storage is not enabled as this segment should be eligible based on other checks like `highwatermark >= upperboundoffset && predicate(segment, nextsegmentopt)`. existing tests in `unifiedlogtest`, `logoffsettest`, `logloadertest`, `logcleanertest` already cover those scenarios.",0,0.9953973889350891
1289566534,13561,satishd,2023-08-10T05:25:05Z,local log size is based on the local retention configs and those are always less than or equal to the complete log retention. i'm unclear about the rationale behind retaining data in local storage using an overall retention size where there are no remote log segments. please provide clarification.,0,0.8272865414619446
1289577612,13561,satishd,2023-08-10T05:42:01Z,nice catch! missed it while merging the conflicts.,1,0.9885961413383484
1289595441,13561,satishd,2023-08-10T06:03:07Z,"this covers scenarios where unclean leader election happens and the remote storage contains segments that are earlier to the current leader's leader-epoch-lineage. for ex: the current leader has the current leader-epoch-cache. [code block] but the earlier broker which got replaced with a new broker which has the current leader's leader-epoch lineage. [code block] but these segments did not expire retention and they were not deleted in the remote storage. but these leader epochs are not there in the current leader's leader epoch as it was chosen with unclean leader election. in this case, we need to remove the segments, that exist beyond the current leader epoch lineage. otherwise, they will never be cleaned up and will continue to accumulate in remote storage.",0,0.9932680726051331
1291679491,13561,junrao,2023-08-11T18:47:15Z,"while you are here, could you also add the missing javadoc for brokertopicstats?",0,0.9936695694923401
1291681393,13561,junrao,2023-08-11T18:49:53Z,thanks for the explanation. it makes sense to me. could you add a comment that this is needed for unclean leader election?,1,0.8586457967758179
1291690729,13561,junrao,2023-08-11T19:02:54Z,"here is what i mean. ideally, the retention behavior should be unchanged with remote storage. consider the following case without remote storage. let's say retentionsize is 100mb and we have only 1 segment of 90mb. the retention logic won't trigger the deletion of the last segment. now, consider the same situation with remote storage enabled, but no remote segments. if localretention is 20mb, the retention logic will delete last segment of 90mb. since the data is not in remote storage. we have deleted the data a bit earlier than expected. a similar issue exists for time-based retention. if remote storage is enabled, but no remote segments, the time-based retention is now based on localrentiontime, not retentiontime. since the former can be smaller than the latter, it means that we could delete the data earlier than expected.",0,0.9925254583358765
1291693299,13561,junrao,2023-08-11T19:06:35Z,"in that case, the name `issegmenttieredtoremotestorage` is a misnomer. if remote storage is disabled, there shouldn't be any segment tiered to remote storage, yet we are setting this val to true.",0,0.9937669038772583
1291698612,13561,junrao,2023-08-11T19:14:23Z,"space after `if`. also, this logic still doesn't look quite right. if remote log is enabled, it seems that we still want to delete local segments whose offset is smaller than logstartoffset.",0,0.9575722813606262
1292935520,13561,showuon,2023-08-14T03:23:22Z,nice catch!,1,0.9950374960899353
1292967294,13561,satishd,2023-08-14T04:41:20Z,"when remote log is enabled, it deletes the local segments whose offset is <= local-log-start-offset. the existing condition without tiered storage is to delete the local log segments <= log-start-offset.",0,0.9927854537963867
1292967405,13561,satishd,2023-08-14T04:41:39Z,it was implicit from the condition that it is relevant only when remote storage is enabled. i removed the value and added a condition and the respective comments for better clarity.,0,0.9890919923782349
1293066497,13561,showuon,2023-08-14T07:23:37Z,good point! i think it's worth filing a bug in jira. wdyt ?,1,0.9928379654884338
1293071660,13561,showuon,2023-08-14T07:29:21Z,"so you mean, all the segment deletion will happen again in the new leader, and update the log start offset there. ok, make sense.",0,0.893617570400238
1293081560,13561,kamalcph,2023-08-14T07:39:13Z,"in the fetch response, the leader-log-start-offset will be piggy-backed. but, there can be a scenario: 1. leader deleted the remote log segment and updates it's log-start-offset 2. before the replica-2 update it's log-start-offset via fetch-request, the leadership changed to replica-2. 3. there are no more eligible segments to delete from remote. 4. the log-start-offset will be stale (referring to old log-start-offset but the data was already removed from remote) 5. if the consumer starts to read from the beginning of the topic, it will fail to read. i realised the case mentioned by and this one is different. both of them can be handled by the new leader gracefully. we can take this task in a follow-up pr if required.",0,0.9936726093292236
1293086543,13561,kamalcph,2023-08-14T07:44:56Z,"to ensure consistency, similar to local, which marks the segment for deletion (renames the file to .delete) and deletes it after 1 minute. (segment.delete.delay.ms). should we move the log-start-offset before the remote log segment deletion? one way to do this is not to delete the remote log segments in `deleteretentiontimebreachedsegments` and `deleteretentiontimebreachedsegments` and only move the `logstartoffset`. in the next iteration, those remote-log-segments will be removed via `deletelogstartoffsetbreachedsegments`. wdyt?",0,0.9948425889015198
1293158752,13561,kamalcph,2023-08-14T08:31:22Z,statements in l1065 and l1057 are same. typo error?,0,0.983530580997467
1293179175,13561,satishd,2023-08-14T08:50:26Z,the case mentioned by you can be addressed in a followup pr. please file a jira.,0,0.9874064326286316
1293185679,13561,kamalcph,2023-08-14T08:56:07Z,nit: [code block],0,0.9847351312637329
1293189650,13561,kamalcph,2023-08-14T08:58:39Z,`optional` is not recommended as parameter in java: [a link],0,0.9923756718635559
1293224397,13561,divijvaidya,2023-08-14T09:28:33Z,can you please address this comment. multiple folks have asked me why this code of line exists which makes me believe that a comment explaining the purpose here would be nice.,0,0.7767705917358398
1293244517,13561,divijvaidya,2023-08-14T09:46:56Z,could we please store the value of log.logendoffset() at the beginning of clean up process and use the stored value for all calculations? asking because endoffset may move behind the scenes while we are processing cleaning. the overall idea is that this cleanup should be executing on a snapshot of log state.,0,0.9937525391578674
1293286722,13561,divijvaidya,2023-08-14T10:26:10Z,"isn't it possible for older epoch chain to become the current chain after another unclean election? for example: time t1: leader epoch chain [code block] time t2: unclean leader election occurs where the new leader loses all existing data and starts with new leader epoch [code block] time t3: unclean leader election occurs again but the old leader from t1 becomes new leader (epoch 8). in this case, the current epoch chain will be 0->1->2->8. but we have deleted data from remote already pertaining to 0,1 and 2, even if it was not eligible for deletion based on retention. to remedy this situation, may i suggest that we delete the unreferenced segments ""only"" if we definitely know that they can be cleaned i.e. when they have exceeded the retention time or when the size in remote itself is greater than retention size. i have to check but i believe that local log solves it in a similar manner.",0,0.9878972768783569
1293305304,13561,divijvaidya,2023-08-14T10:43:56Z,"note that same segment may span across multiple epochs. hence, same segment id will be returned multiple times here and we will count it's size multiple times. may i suggest: [code block] also, if you agree that this was a bug, please add a unit test that should have failed.",0,0.9888954162597656
1293325721,13561,divijvaidya,2023-08-14T11:06:09Z,you need to use this to correctly filter out segments at `findoffsetbytimestamp` method as well please.,0,0.9936380982398987
1293327365,13561,divijvaidya,2023-08-14T11:08:05Z,"i believe we already have public accessor functions in logconfig for these. see logconfig.localretentionms(), logconfig.localretentionbytes() and logconfig.remotestorageenable()",0,0.9896340370178223
1293329291,13561,divijvaidya,2023-08-14T11:10:27Z,you can instead use similar methods already present in logconfig. see logconfig.localretentionbytes() and logconfig.localretentionms() (you will probably have to modify them to add new case of `if (config.remotelogconfig.remotestorageenable)`,0,0.995070219039917
1293332177,13561,divijvaidya,2023-08-14T11:14:01Z,the code in this pr still uses this method. no? what am i missing?,-1,0.5938382744789124
1293336126,13561,divijvaidya,2023-08-14T11:19:06Z,the current code uses the leader epoch chain to calculate the size. this comment is resolved in latest code.,0,0.9945759773254395
1293345266,13561,satishd,2023-08-14T11:29:59Z,"let me rephrase what you mentioned here retention.bytes= 100mb segment1 - 90mb when remote storage is not enabled, then this segment is not deleted from local log segments becuas eof the retention size check. retention.bytes= 100mb local.retention.bytes= 20mb segment1 - 90mb when remote storage is enabled, and there are no segments uploaded to remote storage. that means it will not allow this segment to be deleted as it is not yet copied to remote storage based on the introduced check in this pr. if it is copied to remote storage, that means it is not an active segment and there are one or more local segments after this segment. this segment will be eligible for deletion based on the local retention policy as it is already copied to remote storage earlier. am i missing anything here?",0,0.992254376411438
1293402836,13561,nikramakrishnan,2023-08-14T12:36:13Z,+1. we should add this check to [a link] to ensure we select the segment with correct leader lineage.,0,0.9615523815155029
1293823449,13561,junrao,2023-08-14T18:24:26Z,should we do the same for retentionmsbreach to log whether the retention time is for local retention or not?,0,0.9938458800315857
1293851913,13561,junrao,2023-08-14T18:55:48Z,"we want to be a bit careful of using this method. leaderepochcache is mostly derived from the data in the log. however, on new leader epoch from a leader change, the new leader also appends the new epoch to leaderepochcache before any record is appended for the epoch. this could cause a slight mis-match between the epoch chain in the remote segment and leaderepochcache. for example, it's possible for a leaderepochcache to have 10 100 11 200 //no record appended for epoch 11 12 200 where a segment's epoch chain only has 10 100 12 200 we don't want to prevent the remote segment from being deleted through the retention logic because of this slight mismatch on leader epoch chain. does the code allow for this?",0,0.9638704657554626
1293857043,13561,junrao,2023-08-14T19:00:04Z,"yes, it just means that the segment won't be deleted until it's uploaded to the remote store. but this is probably ok.",0,0.9813348054885864
1293857107,13561,junrao,2023-08-14T19:00:09Z,": sorry, i didn't give the right example. this is the case. without remote storage, retention.bytes= 100mb segment1 - 200mb we will delete segment1 (even if it's the active segment). with remote storage, retention.bytes= 100mb local.retention.bytes= 20mb segment1 - 200mb if segment1 is the active segment, it won't be deleted until it rolls and is uploaded to the remote store. it's a very subtle difference.",-1,0.9904111623764038
1294602887,13561,satishd,2023-08-15T13:33:11Z,"i do not find a strong reason not to use optional as an argument. :) in the same so link, few other opinions on why it is a weak argument. optional as an argument is used in several other places within this project. i do not have strong opinions and i am fine if we decide to go with that rule across the project when there is a consensus. we can revisit it when we do that.",1,0.9923413991928101
1294603142,13561,satishd,2023-08-15T13:33:25Z,good catch!,1,0.9947227239608765
1294604024,13561,satishd,2023-08-15T13:34:15Z,what is the rationale for this suggestion?,0,0.9886640906333923
1294618085,13561,jeqo,2023-08-15T13:45:28Z,"could we elaborate what's the purpose of this validation? iiuc `(totalsize - retentionsize) > retentionsize`, are we validating that totalsize is not higher than 2 times `retentionsize`?",0,0.9943671822547913
1294843843,13561,satishd,2023-08-15T16:25:07Z,this method is used only from `locally` block and it does not require taking any lock. we moved this method inside the locally block to avoid any confusion and future usage outside of that.,0,0.9941984415054321
1295387916,13561,satishd,2023-08-16T05:15:50Z,"good catch! it was changed while refactoring, added uts to cover that in the latest commits.",1,0.9915496110916138
1295394486,13561,kamalcph,2023-08-16T05:28:16Z,filed kafka-15351 and kafka-15352 to track the cases.,0,0.9939852356910706
1295402786,13561,kamalcph,2023-08-16T05:42:48Z,"for clean code, it creates an anonymous extra class at every usage and we should try to avoid this pattern. [a link]",0,0.9911977648735046
1295607067,13561,satishd,2023-08-16T09:09:02Z,"thanks for the clarification. in the above case with remote storage enabled, it will eventually be deleted from local and remote storages, and updates log-start-offset and local-log-start-offset respectively.",1,0.8051033616065979
1295670320,13561,satishd,2023-08-16T10:02:58Z,"thanks for the clarification, good to know about that.",1,0.9396205544471741
1295701347,13561,satishd,2023-08-16T10:33:17Z,"thanks jun for pointing it out. currently, segment epochs are created from leader epoch cache truncated with start and end offsets. but i added defensive checks to filter the epoch with empty records as they will not have any records/messages in the segments. these changes with uts added in the latest commits.",1,0.9639222025871277
1295713103,13561,satishd,2023-08-16T10:45:11Z,follower replicas do truncation based on leader epoch lineage and catch up with the leader. it is hard to know whether a particular lineage can exist in any of the replicas as replicas can fail and it is hard to say whether a particular replica can come back with in a specific duration. that may cause leakages in remote storage. follower replicas can not delete the remote segments as these may be part of the current leader and it may delete the data that is expected by the leader. the tradeoff taken in case of unclean leader election here is to clean up the epoch lineage earlier to the current leader epoch instead of creating segment leakages in remote storage.,0,0.9594584703445435
1296218455,13561,junrao,2023-08-16T17:19:11Z,this can be simplified a bit to `.foreach{ log => ...}`. ditto for the same code in brokerserver.,0,0.9934476017951965
1296221075,13561,junrao,2023-08-16T17:22:01Z,"yes, i agree that it's not a large and common issue. so, we can leave it as it is for now.",0,0.9718855023384094
1296264710,13561,divijvaidya,2023-08-16T18:04:46Z,"correct, that is why we should not be deleting data that we are unsure about. it's a durability loss! in a trade-off situation, wouldn't we want to trade-off in favour of durability instead of remote storage leak (which can be gc'ed by rsm implementation for such cases). one way to solve is it is to delete the data that we know for sure is ready for deletion, e.g. if we have 10mb of data in remote store for non-active lineage and retention size is 2mb, then we can safely delete the rest of the 8mb. this is because even if this leadership chain becomes active, it will adhere to retention size. in other words, i am not saying that we should not delete non-active lineage data in remote store. i am saying that the non-active lineage data should only be deleted if it when it is violating the retention policies. if we have time based retention, this will ensure that there are no leaks. if we have size based retention, then we can do what you are suggesting. i will not consider this comment as blocking to merge this pr since this is in early access but we should document this risk of data loss as part of release notes and try to arrive at a conclusion before production release. thoughts ?",0,0.9019644856452942
1296731885,13561,satishd,2023-08-17T06:27:15Z,it is hard or impossible to find the non-active lineage deterministically as the failed host can have any subset of the non active lineage. determining which epoch/segments can be marked for deletion under such circumstances is not feasible.,0,0.8756695985794067
1296732476,13561,satishd,2023-08-17T06:27:58Z,"in case of unclean leader election, there is already a durability loss when a non in-sync replica needs to be chosen as a leader and given preference to availability. the approach taken in this pr uses the current tradeoff of durability loss and avoids remote log segment leaks. this is slightly different from local log cleanup which we can clarify in the release notes. retention/cleanup logic spread across multiple layers(outside of kafka) poses significant risks and could lead to more extensive problems. so, it is better that to be handled by kafka's retention mechanism. we will discuss further on finalizing the approach before we make this feature production ready.",0,0.9903601408004761
1297576757,13561,junrao,2023-08-17T18:11:51Z,"hmm, should we use `remotelogenabled()` instead of `config.remotelogconfig.remotestorageenable`? ditto for `localretentionsize`.",0,0.9930001497268677
1297580311,13561,junrao,2023-08-17T18:15:41Z,"has a good point. when doing unclean leader election, the new leader (even if unclean) should still have access to the remote data. so, it probably should never lose that portion of the data?",0,0.9205471873283386
1298029817,13561,satishd,2023-08-18T05:47:39Z,"that is a fair point. if we want to take that approach, we should not delete any segments beyond the current leader's leader epoch lineage. we need to take the risk of rsm plugins having cleanup mechanisms for the segment leaks in the remote storage. these leaks may accumulate over time and create operational issues. it is hard even for rsm plugin owners to deterministically find out whether a segment is unreferenced when there are out-of-sync/offline replicas. i filed [a link] to continue the discussion and take a final call later before productionizing it.",0,0.9584583640098572
1298640349,13561,junrao,2023-08-18T16:25:11Z,what's the impact to 3.6.0? do we need to outline any limitation with unclean leader election in the release notes?,0,0.9944860339164734
1299184981,13561,satishd,2023-08-19T13:09:53Z,this is only applicable with tiered storage enabled topics. we will add that in the release notes of tiered storage section about the change in the behavior.,0,0.9923183917999268
1299185257,13561,satishd,2023-08-19T13:12:33Z,good point. added the required filtering check `findoffsetbytimestamp` api.,0,0.5442191362380981
1299221576,13561,junrao,2023-08-19T16:58:45Z,what's the behavior of unclean leader election when tiered storage is enabled?,0,0.9913918972015381
1299640804,13561,satishd,2023-08-21T05:55:11Z,"the remote storage retention cleanup mechanism considers cleaning up the remote log segments that have all the records that are created with a leader epoch precedes to the earliest leader epoch in the current leader's leader epoch lineage. in case of unclean leader election, the earlier leader replica may delete the segments that are copied to remote storage but those are not part of its leader epoch lineage but they may be part of out-of-sync or offline follower replicas and they will not be available for consumption.",0,0.9925159811973572
1299988151,13561,jeqo,2023-08-21T11:33:03Z,"similar to the previous comment on rentetionsizedata: `cleanupuntilms` represents a point in time (`now - retentionms`), while `retentionms` represents a duration (e.g. 1 week in millis). is this comparison correct/needed? if i'm reading this right, this will always be true.",0,0.9897806644439697
1300055517,13561,divijvaidya,2023-08-21T12:39:26Z,"this takes an assumption that the partition has continuous monotonically increasing offsets. but it is not true for a topic that was historically compacted (i.e. compaction is turned off now, that is why ts is enabled). i would suggest to read the next segment and set the startoffset as the start offset of the next segment.",0,0.9929919242858887
1300176481,13561,satishd,2023-08-21T14:16:28Z,good point. i think we discussed this earlier also. let us address this in a followup pr covering topics changing their retention from compaction to delete only retention. filed [a link],1,0.9396186470985413
1300178242,13561,satishd,2023-08-21T14:17:49Z,this check will be true when using system time. but added this defensive check if we have tests setting the mock time to set any long values.,0,0.9925612807273865
1300199098,13561,divijvaidya,2023-08-21T14:32:48Z,sure. we can address this separately but i think that should be a blocker jira for 3.6. otherwise we are shipping this pr with a known bug which i am not very comfortable with. this bug is also not very edge case-y as others for which we have started jira items such as bugs related to performance instead this bug impacts correctness. do you agree?,0,0.5420309901237488
1300279331,13561,satishd,2023-08-21T15:23:52Z,"yes, this is planned for 3.6.0. i did not want to block this pr with that as we want to unblock other dependent prs, especially integration test prs.",0,0.9844688773155212
1300314011,13561,jeqo,2023-08-21T15:52:59Z,"yeah, but the part i'm missing is why should we throw an exception when this is true. if retention is 1 hour, and `cleanupuntil` is at any point in system time, we are throwing an exception.",0,0.824286937713623
1300372620,13561,junrao,2023-08-21T16:40:19Z,"hmm, i was just asking about how unclean leader election with tiered storage is handled in 3.6.0. it seems that this pr has removed the logic for retention by leader epoch. in that case, when an unclean leader is elected, does it just use its logendoffset to start writing new data? in that case, do we just hide those remote segments with offsets higher than the new leader's starting logendoffset? will those hidden remote segments be cleaned up eventually?",0,0.9677221179008484
1301361619,13561,satishd,2023-08-22T09:38:39Z,"right, i fixed the validation check. thanks.",1,0.970563530921936
1304597735,13561,satishd,2023-08-24T16:34:49Z,"syncedup with jun to understand the comment here and clarified them. the retention logic deletes the segments with leader epochs preceding the earliest leader epoch in the current leader. any epochs/offsets which are not there in the current leader epoch lineage but they are within the range, those will be eventually deleted when the current leader's earliest leader epoch moves beyond that. right, it will start writing with its logendoffset with the new epoch. right, they will be eventually removed.",0,0.992384672164917
1307788374,13561,dopuskh3,2023-08-28T18:52:30Z,"it seems i'm reaching that codepath when running reassignments on my cluster and segment are deleted from remote store despite a huge retention (topic created a few hours ago with 1000h retention). it seems to happen consistently on some partitions when reassigning but not all partitions. my test: i have a test topic with 30 partition configured with 1000h global retention and 2 minutes local retention i have a load tester producing to all partitions evenly i have consumer load tester consuming that topic i regularly reset offsets to earliest on my consumer to test backfilling from tiered storage. my consumer was catching up consuming the backlog and i wanted to upscale my cluster to speed up recovery: i upscaled my cluster from 3 to 12 brokers and reassigned my test topic to all available brokers to have an even leader/follower count per broker. when i triggered the reassignment, the consumer lag dropped on some of my topic partitions: later i tried to reassign back my topic to 3 brokers and the issue happened again. both times in my logs, i've seen a bunch of logs like: [code block] looking at my s3 bucket. the segments prior to my reassignment have been indeed deleted.",0,0.8686233162879944
1308148879,13561,showuon,2023-08-29T03:14:54Z,", thanks for reporting this issue. i've created [a link] for this issue. let's discuss it in jira.",1,0.9318299293518066
1308153773,13561,satishd,2023-08-29T03:26:59Z,thanks for bringing the observed issue here. there are a few more pending changes to be merged which are in review/planned related to this change. i will followup on [a link].,1,0.7575545310974121
1433944692,13561,iit2009060,2023-12-21T11:26:05Z,"i gone through the specific code and realised this is actually not impacting the logic 1. while copying the remote segments , remotelogsegmentmetadata stores endoffset using value from the nextsegment base offset. [a link] 2. in my understanding it will be safe to use same logic for historically compacted topics. let me know if my analysis is correct or not ?",0,0.9546869397163391
1434040959,13561,divijvaidya,2023-12-21T12:52:59Z,yes that is correct. copying functionality is not impacted as discussed in [a link] it's only the read-from-remote that is impacted for the historically compacted topic.,0,0.9905624985694885
194783912,5201,bbejeck,2018-06-12T15:27:28Z,"this class is created to contain common information for repartition operations. there are two types of repartitioning currently. when changing a key in a `kstream`s method (`map`, `flatmap` `selectkey` etc) or when performing a `ktable.groupby` operation. the former is eligible for optimization, while the `ktable.groupby` is not.",0,0.9941516518592834
194784561,5201,bbejeck,2018-06-12T15:28:57Z,there are 2 difference between the repartition operations the first is the `serializer` and `deserializer` required,0,0.9937059283256531
194784918,5201,bbejeck,2018-06-12T15:29:54Z,the second difference between repartition operations is the name used to wire up the repartitioning processor.,0,0.9912121891975403
194785793,5201,bbejeck,2018-06-12T15:32:15Z,this class was created to represent the _**non optimizable**_ repartition resulting from a `ktable.groupby` operation,0,0.9943943023681641
194786010,5201,bbejeck,2018-06-12T15:32:50Z,same class just moved to `graph` package,0,0.9938740134239197
194786478,5201,bbejeck,2018-06-12T15:33:53Z,this class represents a repartition operation that _**is eligible**_ to get optimized away.,0,0.9906196594238281
194787418,5201,bbejeck,2018-06-12T15:36:26Z,"the class is the same just moved to a new package. this is the same for all graph objects, so i won't continue to repeat this comment.",0,0.9835039377212524
194790053,5201,bbejeck,2018-06-12T15:43:10Z,"created to represent `ktable` operations (`filter`, `transformvalues`, `mapvalues`)",0,0.9937623143196106
194791681,5201,bbejeck,2018-06-12T15:47:39Z,"for now, this includes the recent changes from (pr #5163) for optional re-use of source topic as changelog topic. this optimization will get folded into this pr in a follow-up push.",0,0.9939140677452087
198283461,5201,vvcephei,2018-06-26T20:18:55Z,it seems like this is happening twice; once inside `addchildnode` and once outside it. (also applies to other occurrences),0,0.9907738566398621
198285554,5201,vvcephei,2018-06-26T20:26:02Z,nit: could be final ;),1,0.9901368618011475
198287289,5201,vvcephei,2018-06-26T20:31:43Z,i think these are never referenced. is there still more to do?,0,0.9219268560409546
198289563,5201,vvcephei,2018-06-26T20:39:02Z,"this is a bit beside the point, but do we actually need this? it's unused in our codebase. do we expect users to subclass `abstractstream`? i think the question is applicable; i'm still hoping we could finish disentangling the internaltopologybuilder from the streamsgraph and internalstreamsbuilder.",0,0.9740810990333557
198289936,5201,vvcephei,2018-06-26T20:40:14Z,"also, on line 76, we're taking note of which nodes need to be copartitioned. do we need to capture this information in the streamsgraph as well?",0,0.994010329246521
198290842,5201,vvcephei,2018-06-26T20:43:08Z,"aside from these two usages, the only other purpose that the internaltopologybuilder serves in the streamsbuilder hierarchy is to add state stores. i think that if we add this to the logical plan first, then we could completely decouple the internaltopologybuilder from the internalstreamsbuilder.",0,0.9921370148658752
198291738,5201,vvcephei,2018-06-26T20:45:53Z,"might be nice to throw an exception if this check fails. it would clearly be a mistake, and it might be nicer for it to break than to do nothing. (i'm specifically thinking if the builder is created, built, modified, and built again; the second modification would just be lost.)",0,0.9576579928398132
198293629,5201,vvcephei,2018-06-26T20:52:24Z,nit: many variables in here can be final.,0,0.9651493430137634
198294005,5201,vvcephei,2018-06-26T20:53:34Z,this field is never used.,0,0.9588500261306763
198294951,5201,vvcephei,2018-06-26T20:56:39Z,"i wasn't sure why the `nodeidcomparator` implements `serializable`. if it doesn't need to, then you can get rid of that class and that field and just do: [code block]",0,0.9897197484970093
198294955,5201,mjsax,2018-06-26T20:56:39Z,"if we remove the `null` check, should we add one in the constructor?",0,0.9948486089706421
198295985,5201,mjsax,2018-06-26T21:00:04Z,why remove `final`?,0,0.9887428283691406
198297056,5201,mjsax,2018-06-26T21:04:17Z,nit: add `final`,0,0.9897833466529846
198298276,5201,mjsax,2018-06-26T21:08:19Z,don't understand the log statement? something missing there?,0,0.9206839203834534
198298348,5201,mjsax,2018-06-26T21:08:34Z,nit: add `final`,0,0.9897833466529846
198298794,5201,mjsax,2018-06-26T21:10:23Z,nit: add `final` (seems some more in the next lines),0,0.9906303286552429
198299478,5201,mjsax,2018-06-26T21:12:21Z,nit: move after the following `if` (we not' need to get the `keychangingnode` if we `continue`,0,0.9886576533317566
198299936,5201,mjsax,2018-06-26T21:14:03Z,"which ""streamsgraphnode"" ?",0,0.993411123752594
198301439,5201,vvcephei,2018-06-26T21:19:52Z,super minor nit: i thought the code style says to always put arguments on a new line when splitting args over multiple lines. i only bring this up because i've been doing it that way...,0,0.4793558120727539
198302388,5201,vvcephei,2018-06-26T21:23:31Z,final?,0,0.9744627475738525
198304292,5201,mjsax,2018-06-26T21:30:43Z,why do we need this here?,0,0.9626767039299011
198306976,5201,mjsax,2018-06-26T21:41:28Z,nit: can we use variable instead of getting the names multiple times?,0,0.98968106508255
198307864,5201,mjsax,2018-06-26T21:45:01Z,why this renaming?,0,0.9315958619117737
198308379,5201,mjsax,2018-06-26T21:47:18Z,"nit: simplify `multipleparentnames` -> `parentnames` (`names` is already plural, should be good enough). im wondering, it it might be better to track the parents in `streamsgraphnode` ?",0,0.991228461265564
198308755,5201,mjsax,2018-06-26T21:49:00Z,when could this be `null`?,0,0.9909537434577942
198308922,5201,mjsax,2018-06-26T21:49:33Z,when would this be not empty?,0,0.9791474938392639
198310099,5201,mjsax,2018-06-26T21:54:40Z,"why doe we assume, that a stateful operator has always one parent? what about a materialized table-table join?",0,0.9848900437355042
198310662,5201,mjsax,2018-06-26T21:57:09Z,nit: remove empty line,0,0.9540706276893616
198311099,5201,mjsax,2018-06-26T21:59:19Z,nit: introduce variable to get name only once?,0,0.9797396063804626
198311844,5201,mjsax,2018-06-26T22:02:37Z,"this is done for both join, right? (ie, update comment?)",0,0.9941154718399048
198312036,5201,mjsax,2018-06-26T22:03:28Z,nit: `steam - table join [only]`,0,0.9932364821434021
198312756,5201,mjsax,2018-06-26T22:06:45Z,"why do we need this check? it seem that `parentnode` cannot be `null`, and that it would be `this` always, too? (assuming one parent node, what is not generic)",0,0.9914264678955078
198312832,5201,mjsax,2018-06-26T22:07:10Z,as above.,0,0.9878018498420715
198313052,5201,mjsax,2018-06-26T22:08:18Z,"why not extend `statefulprocessornode` ? why remove the generic type? can't it be windowed, too? what about custom stores in `transform()` ?",0,0.9935804605484009
198313486,5201,mjsax,2018-06-26T22:10:19Z,nit: add `final`,0,0.9897833466529846
198314691,5201,mjsax,2018-06-26T22:15:52Z,"would it be better to put a generic ` ` her and change to `tablesourcenode `? also, should we take `builder.windowedtable()` into account already? pretty sure the kip will be accepted.",0,0.992972731590271
198319640,5201,mjsax,2018-06-26T22:40:51Z,nit: `final`,0,0.9873613119125366
198320164,5201,mjsax,2018-06-26T22:43:53Z,as above,0,0.9391705989837646
198368837,5201,guozhangwang,2018-06-27T05:14:07Z,"this is added for users that want to extend `abstractstream`, one use case of it is [a link] regarding `internaltopologybuilder` and `internalstreamsbuilder`: we need to pass in `internaltopologybuilder` into the `streamsgraphnode` because their `writetotopology` (this is the one that translates the logical node into one or more physical nodes) needs it, and those graph nodes are accessed from the `internalstreamsbuilder`, so i think we still need to let it hold a reference of the `internaltopologybuilder` anyways.",0,0.9928879141807556
198368989,5201,guozhangwang,2018-06-27T05:15:10Z,+1,0,0.7702900171279907
198369331,5201,guozhangwang,2018-06-27T05:18:00Z,"if they are used for the optimization rules that are to be added later, we should remove them from this pr. i'm now not so sure if wants to add the optimizations in this pr, but i'd suggest we do it in a forth one given the current pr is pretty large already.",0,0.9731019735336304
198369849,5201,guozhangwang,2018-06-27T05:22:25Z,"if users call `streamsbuilder#build()` multiple times, which we cannot forbid programmatically, we should still only call this function once; on the other hand, if users add a few more operations into the streams topology and then call `build()` again we should probably re-run optimization and generate a new topology, i.e.: [code block]",0,0.9938932657241821
198369989,5201,guozhangwang,2018-06-27T05:23:37Z,"+1, if we are not going to write / serialize the logical plan anywhere we do not need to do that.",0,0.9809169173240662
198370646,5201,guozhangwang,2018-06-27T05:29:03Z,kgroupedtableimpl also have a duplicated `createrepartitionnode`.,0,0.9914513230323792
198370821,5201,guozhangwang,2018-06-27T05:30:05Z,may need some more explanation of this optimization rule.,0,0.9824976325035095
198370939,5201,guozhangwang,2018-06-27T05:31:08Z,"meta comment: if we are going to add more optimization rules in `optimize()`, should we keep this pr as a plain one that do not enforce any optimizations, so that we can then consider each function separately, that helps more concentrated reviews and reduce large pr burdens.",0,0.9929244518280029
198371994,5201,guozhangwang,2018-06-27T05:38:31Z,this is nice cleanup.,1,0.9933376312255859
198372212,5201,guozhangwang,2018-06-27T05:40:13Z,meta comment: seems we have migrated the node classes in a previous pr so could you update the description of this pr to remove the statement that we changed the package here?,0,0.9946573376655579
198372226,5201,guozhangwang,2018-06-27T05:40:20Z,+1,0,0.7702900171279907
198372742,5201,guozhangwang,2018-06-27T05:44:19Z,should we override this for all the subclasses so that we can have a more informative intermediate logical plan representation for debugging purposes?,0,0.9883285760879517
198372787,5201,guozhangwang,2018-06-27T05:44:40Z,+1.,0,0.9498199820518494
198372943,5201,guozhangwang,2018-06-27T05:45:50Z,"i cannot tell how this includes the source topic reuse logic, could you explain a bit?",0,0.9233913421630859
198933994,5201,bbejeck,2018-06-28T18:04:46Z,ack,0,0.8596508502960205
198937951,5201,bbejeck,2018-06-28T18:18:14Z,ack,0,0.8596508502960205
198938045,5201,bbejeck,2018-06-28T18:18:33Z,ack merge mistake,-1,0.8767724633216858
198938944,5201,bbejeck,2018-06-28T18:21:36Z,ack. removed for now as part 3 is for writing physical plan using graph. part 4 will contain optimization only,0,0.9884214401245117
198939184,5201,bbejeck,2018-06-28T18:22:19Z,same as above will clean up in part 4,0,0.9908841252326965
198939337,5201,bbejeck,2018-06-28T18:22:47Z,same as above,0,0.965356171131134
198939460,5201,bbejeck,2018-06-28T18:23:08Z,"ack, will clean up in part 4",-1,0.5460984110832214
198940600,5201,bbejeck,2018-06-28T18:26:37Z,"the repartition node just created, will clarify in part 4",0,0.9919163584709167
198941179,5201,bbejeck,2018-06-28T18:28:21Z,ack removed,0,0.9719715118408203
198942912,5201,bbejeck,2018-06-28T18:33:21Z,ack,0,0.8596508502960205
198944739,5201,bbejeck,2018-06-28T18:39:12Z,"during work on this pr, i started to consider this name was a better fit if you insist i can revert.",0,0.9732046127319336
198945962,5201,bbejeck,2018-06-28T18:43:21Z,"ack on the name. for now, i'd prefer to leave `parentnames` in the `processornode` as we specifically add multiple parent names in `kstream#merge`. or maybe refactor always to take a list `parentnames` that would simplify the logic edit: i take that back, we want to rely on getting the parent name for the current graph node by calling `parentnode.name()` the multiple parent names comes from the case mentioned above and are needed for the `internalstreamsbuilder` to complete the merge processor, so i'll leave as is for now.",0,0.9938056468963623
198950446,5201,bbejeck,2018-06-28T18:57:39Z,"i've removed this line, left over from a previous refactoring.",0,0.9845831394195557
198951509,5201,bbejeck,2018-06-28T19:00:48Z,"only used for merge node, so it's empty most of the time. i'll look to see if i can refactor internally.",0,0.9822591543197632
198952083,5201,bbejeck,2018-06-28T19:03:02Z,"table-table joins are represented in a separate node, `ktablektablejoinnode`. i used a specific node for this case imho there is too much information needed in the table-table join to generalize.",0,0.982939600944519
198952415,5201,bbejeck,2018-06-28T19:04:17Z,ack,0,0.8596508502960205
198954002,5201,bbejeck,2018-06-28T19:10:24Z,ack,0,0.8596508502960205
198955006,5201,bbejeck,2018-06-28T19:14:43Z,ack,0,0.8596508502960205
198955044,5201,bbejeck,2018-06-28T19:14:52Z,ack,0,0.8596508502960205
198955718,5201,bbejeck,2018-06-28T19:17:29Z,"since the optimization is pushed out to a 4th pr, this method is removed. i'll clean up in 4th pr. the original idea was to prevent any errors by calling `clearchildren` _*after*_ the children of a given parent node have migrated to another parent. probably better to eliminate the checks and document the calling order when updating the graph.",0,0.9929469227790833
198955766,5201,bbejeck,2018-06-28T19:17:40Z,same comment from above,0,0.9780504703521729
198960187,5201,bbejeck,2018-06-28T19:33:56Z,ack,0,0.8596508502960205
198963636,5201,bbejeck,2018-06-28T19:47:40Z,"i removed the generic type from the class definition and changed the `materializedinternal` from `s` to `keyvaluestore<bytes, byte[]` as it matches the `materializedinternal` parameter used in `ktable#filter`, `ktable#mapvalues`, `ktable#transformvalues`. i can revert that if you want. looking at `statefulprocessornode` it's only used from `kstream` for `process` and `transform`, but those methods never pass a strore builder or materialized, just store names. what makes sense to me is to refactor `statefulprocessornode` to remove the store builder then have `tableprocessornode` extend `statefulprocessornode` . wdyt? i'm not sure what you mean custom stores in `transform()`, `kstream#transform` takes a list of store names which is captured in the `statefulprocessornode` is that what you are referring to?",0,0.9909223914146423
198964111,5201,bbejeck,2018-06-28T19:49:32Z,ack,0,0.8596508502960205
198970765,5201,bbejeck,2018-06-28T20:14:03Z,"ack, required some other minor changes, you'll have to let me know what you think",-1,0.6058844923973083
198972710,5201,bbejeck,2018-06-28T20:20:48Z,"edit: i've put the generic type back, but requires a cast internally, you have to let me know what you think",0,0.9508534669876099
198976922,5201,bbejeck,2018-06-28T20:35:09Z,removed from this pr and delayed to 4th pr with optimization,0,0.9929239749908447
198977076,5201,bbejeck,2018-06-28T20:35:46Z,ack,0,0.8596508502960205
198977160,5201,bbejeck,2018-06-28T20:36:09Z,removed until 4th pr with optimization,0,0.9931040406227112
198977315,5201,bbejeck,2018-06-28T20:36:42Z,this is required by findbugs.,0,0.9910827875137329
198977471,5201,bbejeck,2018-06-28T20:37:15Z,ack,0,0.8596508502960205
198981153,5201,bbejeck,2018-06-28T20:49:36Z,"that was the intent, build once then subsequent calls return the same physical plan from rebuilding. as for updates, i'm thinking the use case would be to build the topology incrementally and call build at the end versus incremental calls to build, in which case the current approach still works.",0,0.9889029860496521
198982348,5201,bbejeck,2018-06-28T20:53:43Z,"this is intentional. today, when a repartition is required, the `internaltopologybuilder` creates a repartition operation and immediately writes it to the physical plan. so we need to capture the repartition as a graph node and pass the new node to the `internalstreamsbuilder` for possible metadata collection for optimization. in other cased graph nodes are created in classes that don't subclass the `abstractstream`.",0,0.9921667575836182
198982978,5201,bbejeck,2018-06-28T20:56:08Z,ack removed optimization in favor of pushing a 4th pr with optimizations only once 3rd pr is merged.,0,0.993630588054657
199006843,5201,bbejeck,2018-06-28T22:31:33Z,"ack will try to collapse the two in 4th pr, but for now, the `createreparitionnode` is removed from `internalstreamsbuilder` until 4th pr",0,0.9936879277229309
199012496,5201,guozhangwang,2018-06-28T23:02:02Z,"hmm.. for step 4) / 5), now the `topologybuilt` would still be true and hence we would return the same topology, but that is incorrect right?",0,0.9786675572395325
199014145,5201,guozhangwang,2018-06-28T23:12:05Z,"could you explain to us a bit more? i'm still scratching my head now on when do we call `abstractstream#addgraphnode` v.s. `parentnode.addchildnode; builder.maybeaddnodeforoptimizationmetadata(repartitionnode);` because their logic are just the same, right?",0,0.6575160622596741
199272791,5201,mjsax,2018-06-29T20:30:11Z,"i am 51:49 to keep the old name (so, i don't insist in reverting). \cc wdyt?",0,0.7887724041938782
199274082,5201,mjsax,2018-06-29T20:36:06Z,ack. makes sense that `transform` does not apply here as this is a `*table*processornode`.,0,0.9590867161750793
199282205,5201,bbejeck,2018-06-29T21:16:21Z,"yep, i'll have to put some thought into what's relevant without being too spammy",-1,0.897328794002533
199286587,5201,bbejeck,2018-06-29T21:40:26Z,ack updated,0,0.9719058871269226
199288962,5201,bbejeck,2018-06-29T21:53:38Z,"what i was thinking of was the developer would build an initial topology with the last statement being the `builder.build()...` then at that point execute the program and observe the printed topology. then go back and update the topology again and run the program a separate time and watch the results. but thinking about it more, that is an opinionated/subjective view of how to develop, and we should not restrict to one style. i'll put something to detect if the topology has changed then rebuild if true.",0,0.7853291630744934
199289400,5201,bbejeck,2018-06-29T21:56:25Z,"i try to follow that as well, but maybe i'm missing something because i thought the args were all on one line here.",0,0.9691281914710999
199291907,5201,bbejeck,2018-06-29T22:11:22Z,"yes, the logic is the same. but `groupedstreamaggregatebuilder` does not subclass `abstractstream` so we need to make those two calls separately. secondly, in the example above we are building 2 graph nodes. the repartition node and the stateful processor node for the aggregation. today when we need to repartition for an aggregation, the `internaltopologybuilder` creates a repartition operation and it becomes the parent of the aggregation operation. so the repartition node needs to be a child of the current `streamsgraphnode` in the `groupedstreamaggregatebuilder` but it must be the parent of the aggregation graph node. does this make sense?",0,0.9933444261550903
205591823,5201,bbejeck,2018-07-26T20:28:02Z,"for removing the restriction of only building topology once, i've decided on the ""traditional"" approach when traversing a graph to only visit (in this case write its contents to the `internaltopologybuilder`) graph nodes not already visited. i feel a similar approach should work with optimization. but since this pr does not include the optimization, i'd prefer to defer any discussions on what will and won't work for multiple `build()` calls until we have the pr for applying the optimization pushed.",0,0.9862631559371948
206391213,5201,guozhangwang,2018-07-31T04:22:32Z,nit: you can configure the ide to turn auto-newline-beyond-column-limit off :),1,0.9393067955970764
206392683,5201,guozhangwang,2018-07-31T04:36:58Z,nit: this.streamsgraphnode can be replaced with parentnode.,0,0.9903886914253235
206393083,5201,guozhangwang,2018-07-31T04:40:49Z,why change collection to set? the former is more generalized right?,0,0.9866043925285339
206393265,5201,guozhangwang,2018-07-31T04:42:32Z,the `streamsgraphnode#internalstreamsbuilder()` seems not used anywhere?,0,0.9935628175735474
206393456,5201,guozhangwang,2018-07-31T04:44:33Z,"ack, lgtm.",0,0.937690258026123
206395841,5201,guozhangwang,2018-07-31T05:06:50Z,"i know it is cherry-picked from 's pr, but it seems we drops this type information in the logical streamsgraphnode anyways. maybe can comment whether we still need this?",0,0.988857626914978
206395968,5201,guozhangwang,2018-07-31T05:07:45Z,why we pass `null` before and now we need to pass in the `transformnode`? was it a bug before and we fixed it here?,0,0.9940769672393799
206396093,5201,guozhangwang,2018-07-31T05:08:34Z,nit: `processnode`.,0,0.9872769713401794
206397008,5201,guozhangwang,2018-07-31T05:16:05Z,"the comments here are a bit confusing: line 63 is for both globaltable-stream join and table-stream join, and line 66 is for table-stream join only.",0,0.690901517868042
206397146,5201,guozhangwang,2018-07-31T05:17:28Z,nit: selectkeymapnode.,0,0.989329993724823
206397274,5201,guozhangwang,2018-07-31T05:18:43Z,"we did not add a new logical node here anymore in this pr, is this intentional?",0,0.9911370277404785
206397509,5201,guozhangwang,2018-07-31T05:20:37Z,nit: rename to `parentgraphnode`.,0,0.9933932423591614
206398136,5201,guozhangwang,2018-07-31T05:26:19Z,"these four graph nodes: thiswindowedstreamsnode, thisstreamsgraphnode, otherwindowedstreamsnode, otherstreamsgraphnode, seems not needed any more since we now use an ""umbrella"" joingraphnode that contains all the information, right? ditto for other join implementations. if it is indeed the case, then i'm wondering why our unit test does not fail, as it will unnecessarily add more processor nodes, and hence should cause some unit test to fail.",0,0.9170949459075928
206399370,5201,guozhangwang,2018-07-31T05:36:22Z,nit: groupbymapnode.,0,0.9678170084953308
206399786,5201,guozhangwang,2018-07-31T05:39:58Z,should be `optimizablerepartitionnode{ + super.tostring() + }`?,0,0.9939371347427368
206400130,5201,guozhangwang,2018-07-31T05:42:46Z,ditto here.,0,0.9378204345703125
206400597,5201,guozhangwang,2018-07-31T05:46:48Z,nit: since we have another class named `processornode` already could we still name it `statelessprocessornode`?,0,0.9941319823265076
206401093,5201,guozhangwang,2018-07-31T05:50:22Z,"the `streamsgraphnode#parentname` and here `parentnames` relationship is a bit awkward, as the only difference is for `merge`. could we just use `parentnames` on the `list streamsgraphnode` directly, and replace `setparentnode` with `addparentnode`. and in all other nodes we just call `addparentnode` only once, while for `merge` we call it twice for each fo the merging streams.",0,0.837709367275238
206401149,5201,guozhangwang,2018-07-31T05:50:49Z,see my other comment above: we can replace this logic with the `addparentnode`.,0,0.9869588017463684
206401318,5201,guozhangwang,2018-07-31T05:52:07Z,i think this coding restyle is really not necessary.,0,0.731914758682251
206401445,5201,guozhangwang,2018-07-31T05:53:16Z,"just to be general enough, we should just loop over all parent nodes from the list and add all their node names here.",0,0.9878119826316833
206401533,5201,guozhangwang,2018-07-31T05:53:56Z,why changing collection to list?,0,0.9861764311790466
206401753,5201,guozhangwang,2018-07-31T05:55:37Z,for line 35 above: see my other comment: `internalstreamsbuilder` seems not used anywhere.,0,0.9886295795440674
206402166,5201,guozhangwang,2018-07-31T05:58:28Z,"ditto above: if we take the underlying `streamsgraphnode` to have `list of parentnodes`, then for all such callers we will generalize to loop over all parent nodes and add their node names. although for now we will only have two parents for `merge`, and one parent for any other types.",0,0.9920233488082886
206402321,5201,guozhangwang,2018-07-31T05:59:35Z,the `storebuilder` should be templated as `storebuilder `. ditto elsewhere.,0,0.9946841597557068
206402481,5201,guozhangwang,2018-07-31T06:00:44Z,same here.,0,0.9755119681358337
206402673,5201,guozhangwang,2018-07-31T06:02:11Z,should we just do `final processortopology topology = builder.build();` and remove the line below? same elsewhere.,0,0.9950214624404907
206402910,5201,guozhangwang,2018-07-31T06:03:58Z,nit: add final.,0,0.9831699728965759
206566399,5201,vvcephei,2018-07-31T15:06:46Z,nit: alignment is off.,0,0.7400301694869995
206566569,5201,vvcephei,2018-07-31T15:07:13Z,nit: alignment is off.,0,0.7400301694869995
206567717,5201,vvcephei,2018-07-31T15:10:00Z,nit: alignment is off.,0,0.7400301694869995
206567780,5201,vvcephei,2018-07-31T15:10:10Z,nit: alignment is off.,0,0.7400301694869995
206571206,5201,vvcephei,2018-07-31T15:18:46Z,nit: alignment is off.,0,0.7400301694869995
206571401,5201,vvcephei,2018-07-31T15:19:13Z,nit: alignment is off.,0,0.7400301694869995
206574955,5201,bbejeck,2018-07-31T15:28:16Z,ack,0,0.8596508502960205
206575220,5201,vvcephei,2018-07-31T15:28:59Z,"yeah, in this case, the type parameter is unused, and we're also suppressing warnings. i think we can either ditch the parameter or remove the suppression. fwiw, i have a todo after this pr is merged to make another pass to eliminate warnings and unnecessary suppressions, so feel free to just drop the type parameter, and i'll figure out whether the suppression is necessary later on. so as to not expand this pr further.",0,0.9669793844223022
206576264,5201,vvcephei,2018-07-31T15:31:34Z,"we were never actually using the graph before, right? so a missed node might go unnoticed until now, when we actually build the topology from the graph.",0,0.9844473600387573
206576886,5201,vvcephei,2018-07-31T15:33:19Z,this is (and was) a weird line break.,-1,0.9753389954566956
206577284,5201,vvcephei,2018-07-31T15:34:10Z,`notnullkeypredicate`?,0,0.9932489395141602
206586295,5201,bbejeck,2018-07-31T15:57:32Z,ack,0,0.8596508502960205
206586526,5201,bbejeck,2018-07-31T15:58:11Z,"can't recall, i think it was related to changes for optimization implementation, i'll revert for now.",0,0.9735795855522156
206587699,5201,bbejeck,2018-07-31T16:01:11Z,"ack, removed edit: put back for now to avoid findbugs error.",0,0.9752485156059265
206591585,5201,bbejeck,2018-07-31T16:13:05Z,looking from the history looks like it was a bug but fixed here.,0,0.8817655444145203
206591870,5201,bbejeck,2018-07-31T16:14:02Z,ack,0,0.8596508502960205
206596270,5201,bbejeck,2018-07-31T16:27:39Z,"ack, updated",0,0.9443120360374451
206597007,5201,bbejeck,2018-07-31T16:29:54Z,ack,0,0.8596508502960205
206597490,5201,vvcephei,2018-07-31T16:31:23Z,"if so, then this comment would apply to all the other nodes as well.",0,0.9892086386680603
206599239,5201,vvcephei,2018-07-31T16:37:04Z,"i thought it was a little weird previously that `statefulprocessornode` extends `statelessprocessornode`, since subclassing is generally an ""is a"" relationship. so it was previously saying ""statefuprocessornode is a statelessprocessornode"", which is silly of course. maybe we can call it `processorgraphnode` to avoid a collision?",-1,0.9789695739746094
206600066,5201,vvcephei,2018-07-31T16:39:49Z,:+1: i think this was from my misinterpretation of the code style.,0,0.9363816976547241
206601158,5201,bbejeck,2018-07-31T16:43:32Z,"yes, it's intentional. what i found during testing is that we don't need to create a node here. i initially had a logical node at this point, but it never rendered any details for the physical plan, as it's methods on the `kgroupedstreamimpl` that provide details for the next operation of the physical plan, thus we only need to create a new logical node when one of those operations are specified. when i did create a new logical plan node here, it contained no details to render, so i needed to put in checks for `null` `processorparameters`. having a placeholder node was somewhat probalmatic, so instead of a ""dummy"" node which i found to be confusing as well, i removed creating a new node at this point, and imho is better off this way.",0,0.9885304570198059
206603371,5201,vvcephei,2018-07-31T16:50:47Z,duplicate test line?,0,0.9702877402305603
206613580,5201,bbejeck,2018-07-31T17:21:48Z,ack,0,0.8596508502960205
206616617,5201,bbejeck,2018-07-31T17:30:27Z,ack,0,0.8596508502960205
206620359,5201,bbejeck,2018-07-31T17:41:30Z,"ack, reverted",-1,0.762721836566925
206620751,5201,bbejeck,2018-07-31T17:42:42Z,ack,0,0.8596508502960205
206640577,5201,guozhangwang,2018-07-31T18:41:11Z,"actually, my point is that the private `internalstreamsbuilder` field is not used anywhere either, so we can remove both this field as well as the getter function.",0,0.9912841320037842
206640980,5201,guozhangwang,2018-07-31T18:42:26Z,thanks for confirming :) just want to make sure it is not a regression.,1,0.9943906664848328
206641195,5201,guozhangwang,2018-07-31T18:43:13Z,thanks!,1,0.9051083922386169
206672496,5201,bbejeck,2018-07-31T20:28:50Z,"hmm, i'm not sure. while i agree with you that the `streamsgraphnode#parentname` and here `parentnames` relationship is a bit awkward but i think changing `setparentnode` to `addparentnode` can be equally as awkward. while i'm up for changing this in some way i'd prefer to leave how we establish the parent-child relationship the same, as we'd be making a cross-cutting change for just the `merge` case, and here it's isolated for just `merge`. edit: i get what you are saying, i'll try to change and see if i can get it to work. edit part ii: updated and implemented as you suggested, good call.",-1,0.912983775138855
206672618,5201,bbejeck,2018-07-31T20:29:12Z,replied above,0,0.9650270938873291
206674028,5201,bbejeck,2018-07-31T20:33:46Z,ack. but i think we need to come together on this as a team.,-1,0.9671012163162231
206729312,5201,bbejeck,2018-08-01T01:15:36Z,"ack, done",0,0.4990619122982025
206729719,5201,bbejeck,2018-08-01T01:19:01Z,"out of convenience, reverted",0,0.9507657289505005
206729744,5201,bbejeck,2018-08-01T01:19:15Z,"ack, updated",0,0.9443120360374451
206730023,5201,bbejeck,2018-08-01T01:21:47Z,"i think it's needed for optimization pr, but i'll remove here and will add back if necessary",0,0.9847166538238525
206731569,5201,bbejeck,2018-08-01T01:34:23Z,ack,0,0.8596508502960205
206732565,5201,bbejeck,2018-08-01T01:41:57Z,"actually, we still need both the `streamsbuilder.build()` call returns a `topology` while the `internaltopologybuilder.build()` returns a `processorytopology`. while the method names seem to be a bit overloaded, the terminology and methods pre-date this pr, so maybe we can do a follow-up pr to look at renaming and clarifying things some.",0,0.9923615455627441
206733189,5201,bbejeck,2018-08-01T01:47:36Z,ack,0,0.8596508502960205
206737233,5201,bbejeck,2018-08-01T02:20:55Z,"the graph node is indeed required, and the tests are passing correctly. implementing the join for optimization was possibly the most ""intricate"" detail to get correct. previously when we generated the entire physical plan upfront, the parent names for the two `kstreamjoinwindow` instances were generated inside the `kstreamimpljoin.join` method and passed to the internalstreamsbuilder to wire up the processors. the first pass of the `streamstreamjoinnode` followed this approach, and everything was wired together in one operation. but the problem is with that approach we lose the ability to optimize any join nodes much for the same reason as before, we write everything required for the join to the `internaltopologybuilder` and lose any concept if optimization has occurred and what the new parent node is. either stream involved in a join can be eligible for optimization concerning repartitioning. in that case, we need to be able to use the updated parent node names for either or both of the `kstreamjoinwindow` instances involved in the join. so what has been done here is to add the two `kstreamjoinwindow` instances explicitly as child nodes of the two `kstream` instances passed as parameters from the `dojoin` method. the key point here is that one or both of the original `kstream` instances may have required a repartitioning. this fact requires us to explicitly attach the `kstreamjoinwindow` as a child node of the passed in `kstream` instance so if a repartition optimization does occur; the correct parent name is used by the `kstreamjoinwindow` when the physical plan is written. as for your question of adding too many processors, when traversing the graph the nodes representing the `kstreamjoinwindow` processors have their details written, but in the `streamstreamjoinnode` the previous calls writing the details for the `kstreamjoinwindow` processors out for the physical plan have been removed. thus the number of processors written out in the physical plan is correct.",0,0.9909447431564331
206737456,5201,bbejeck,2018-08-01T02:22:56Z,ack,0,0.8596508502960205
206737468,5201,bbejeck,2018-08-01T02:23:04Z,ack,0,0.8596508502960205
206737593,5201,bbejeck,2018-08-01T02:24:13Z,ack,0,0.8596508502960205
206737755,5201,bbejeck,2018-08-01T02:25:41Z,ack,0,0.8596508502960205
206737805,5201,bbejeck,2018-08-01T02:26:04Z,ack,0,0.8596508502960205
206737992,5201,bbejeck,2018-08-01T02:27:35Z,ack,0,0.8596508502960205
206738254,5201,bbejeck,2018-08-01T02:29:41Z,"ack fixed, need to update intellij formatting",0,0.9771883487701416
206738426,5201,bbejeck,2018-08-01T02:30:29Z,ack,0,0.8596508502960205
206739044,5201,bbejeck,2018-08-01T02:33:00Z,ack,0,0.8596508502960205
206750808,5201,guozhangwang,2018-08-01T04:13:11Z,"ack, thanks for clarifying.",1,0.7578068375587463
206751900,5201,guozhangwang,2018-08-01T04:24:07Z,"my question is that, in this function we call the following `addgraphnode` calls: [code block] and in the returned `kstreamimpl` we passed in `joingraphnode`. note the `parentgraphnode` is passed as the latest node added to the topology for now, and hence it looks like although `thisstreamsgraphnode` and `otherstreamsgraphnode` each added a child, they do not have any parents, and hence these two ""branches"" are sort-of dangling as they are not connected to the topology graph at all.. could you maybe explain a bit more on this logic?",0,0.9899100661277771
206930443,5201,bbejeck,2018-08-01T15:38:42Z,"great question. in building the topology graph, it's not possible for a graph node to not have a parent. it is easier for me to explain the logic best with some examples. first, let's consider no repartitioning [code block] in this case we a repartition did not occur in `dojoin`, so the `thisstreamsgraphnode` and `otherstreamsgraphnode`, from the `lhs` and `other` `kstream` instances respectively, represent the graph nodes for `streama` and `streamb` and the parent node is `root`. anything created directly from the `streambuilder` always has the parent node of `root`. if a `kstream` instance is created by another upstream operation like `builder.stream(""topicb"").filter(...)` , then its parent would be the graph node representing the `filter` operation. in this case in the `thisstreamsgraphnode` and `parentgraphnode` are the same instance, and it ends up with two child nodes, the `thiswindowedstreamsnode` and the `joingraphnode`. i prefer to keep these two nodes separate as we don't need to keep track of repartitioning, i find the logic more clear to use the graph nodes from the `lhs` and `other` `kstream` instances. next repartitioning is required: [code block] now a repartition occurred in `dojoin` and the `thisstreamsgraphnode` is now a repartition graph node, with its parent being the `selectkey` graph node and the grandparent node is the original `streama` graph node. if `streamb` had required a repartition the parent-child structure would be the same, the `otherstreamsgraphnode` would be a repartition node with the parent being the graph node representing the key changing operation and the grandparent node representing the original `streamb` graph node. so at all times the `thisstreamsgraphnode` and `otherstreamsgraphnode` have parents of either `root` or some other upstream `kstream` operation and the `thisstreamsgraphnode` and `otherstreamsgraphnode` need to add the respective window stream processor graph nodes as children, so the physical plan is rendered correctly. does this make sense?",1,0.946773886680603
1187976451,13639,jeffkbkim,2023-05-08T23:11:16Z,will this be changed to all groups once we begin implementing the old apis?,0,0.9928673505783081
1187980069,13639,jeffkbkim,2023-05-08T23:19:59Z,"nit: ""at least a subset""",0,0.9649246335029602
1187980194,13639,jeffkbkim,2023-05-08T23:20:15Z,"nit: ""the member""",0,0.9702838063240051
1187981608,13639,jeffkbkim,2023-05-08T23:23:38Z,i'm wondering if this would hide the fact that ownedtopicpartitions should not be null.,0,0.7268429398536682
1187987623,13639,jeffkbkim,2023-05-08T23:38:27Z,"nit: ""has a larger member epoch"" a bug in setting the member epoch in the client side or in storing the epoch in the server side would result in the consumer never finding a coordinator right? if the client is expected to update its member epoch only from server side response then it seems that a server side bug would be more likely.",0,0.979981005191803
1187994938,13639,jeffkbkim,2023-05-08T23:56:47Z,(adding comment to this line since it's related) might be confusing things but shouldn't we include the partitions to revoke in the heartbeat response? i think i remember something along the lines that the consumer will calculate the diff from its view of the owned partitions vs. this heartbeat response and will try to revoke.,0,0.9555421471595764
1188015174,13639,jeffkbkim,2023-05-09T00:50:17Z,aren't these thrown in `throwifconsumergroupheartbeatrequestisinvalid` if it's not the first heartbeat request?,0,0.9937280416488647
1188024098,13639,jeffkbkim,2023-05-09T01:14:37Z,"i think adding what reconciliation we're doing at this stage would be helpful. also to confirm, target assignment records are actual diffs from a previous state whereas current assignment record holds the entire state right?",0,0.9323918223381042
1190415641,13639,jolshan,2023-05-10T21:35:49Z,maybe we can explain the mapping here.,0,0.9838341474533081
1190416089,13639,jolshan,2023-05-10T21:36:34Z,(i guess it is just name and assignor though),0,0.987360417842865
1190417026,13639,jolshan,2023-05-10T21:38:00Z,or will we have another method for generic groups?,0,0.9930667877197266
1190428691,13639,jolshan,2023-05-10T21:56:05Z,what happens if we send an unsupported assignor on any request besides the first?,0,0.9454762935638428
1190433019,13639,jolshan,2023-05-10T22:03:23Z,"maybe slightly off topic, but just for my understanding topicpartitions is a data structure that contains topic id + partitions for that topic? reading this name, it was not immediately clear that these all belonged to the same topic. not a huge deal, but maybe something in naming that we missed and can think about amending in the future.",0,0.8658822178840637
1190436747,13639,jolshan,2023-05-10T22:10:11Z,could we also say we don't match if there is one or more owned partition that is not in the target set?,0,0.987458348274231
1190445435,13639,jolshan,2023-05-10T22:26:47Z,i'm also a bit concerned by saying this error because it assumes we got a bump from another coordinator and could obscure bugs. it's good the thrown error at least mentions the epoch though.,0,0.9255282878875732
1190447106,13639,jolshan,2023-05-10T22:30:17Z,how do we continue from this state? do we eventually get a bumped epoch response?,0,0.967074453830719
1190454574,13639,jolshan,2023-05-10T22:46:37Z,it should be null on every request besides the first one right? this method handles both the first heartbeat and future ones though right? so it needs to handle null and non null fields?,0,0.9904808402061462
1190455545,13639,jolshan,2023-05-10T22:48:44Z,do we expect these changes to happen fairly often? is info a bit high of a log level?,0,0.975374162197113
1190477811,13639,jolshan,2023-05-10T23:38:47Z,"is the incrementing on line 497 the only way groupepoch will be greater than the targetassignmentepoch? this is a little confusing to me since i would expect the target to be higher. i think saying generic ""groupepoch"" also confuses me about the source of the data.",-1,0.7945361137390137
1192164806,13639,clolov,2023-05-12T09:55:14Z,"i am most certainly missing a crucial piece of information, but the only mention i could find of a partition epoch is in the rejected alternatives of [a link]. has the need for this been discussed someplace else so i can have a further read?",0,0.9727051258087158
1192170321,13639,dajac,2023-05-12T10:00:38Z,"in this case, i need a method which returns a consumergroup. if we can reuse it, i am fine with this. otherwise, we can use another method and extracts some logic from this one.",0,0.9805693626403809
1192173471,13639,dajac,2023-05-12T10:03:46Z,reworked the comment.,0,0.9399853944778442
1192174161,13639,dajac,2023-05-12T10:04:29Z,`ownedtopicpartitions` can be null.,0,0.9904212951660156
1192179523,13639,dajac,2023-05-12T10:10:14Z,"this scenario could happen if a zombie coordinator is kept around. the consumer could get a higher epoch from the new coordinator and end up talking to the zombie by mistake (based on stale metadata). we did something similar in the controller in the part so i used the same approach here. this seems safe to me as the consumer should only learn a new epoch from the coordinator. of course, in case of a bug, this could become an issue. the alternative would be to be defensive and to fence the member in this case and force it to restart at epoch 0. the benefits of this option is that it is more robust but also more disruptive. should we be conservative in this case?",0,0.9778510928153992
1192180394,13639,dajac,2023-05-12T10:11:09Z,"i think that providing the expected assigned partitions is actually more robust because it forces the consumer to revoke all the other partitions, even the ones that we would not know about on the server side.",0,0.973199725151062
1192180723,13639,dajac,2023-05-12T10:11:31Z,correct. those could be `null` here as well.,0,0.9880805015563965
1192182531,13639,dajac,2023-05-12T10:13:24Z,reworked the comment.,0,0.9399853944778442
1192184441,13639,dajac,2023-05-12T10:15:39Z,good point. it should be checked there as well.,1,0.8598277568817139
1192188074,13639,dajac,2023-05-12T10:19:34Z,"correct. `topicpartitions` contains a topic id and a list of partition ids. sure, we could consider renaming this.",0,0.9907941222190857
1192194658,13639,dajac,2023-05-12T10:27:10Z,right. the member will get a response with the correct epoch.,0,0.9868469834327698
1192195549,13639,dajac,2023-05-12T10:28:12Z,they should be occasional. we log similarly in the current protocol and those logs are really helpful. we can lower them down in the future if they become an issue.,1,0.7626673579216003
1192198495,13639,dajac,2023-05-12T10:31:30Z,"at the moment, this is the only way but other ways will come. i think that it is safe to trigger the computation whenever the group epoch is larger than the target assignment epoch. we bump the group epoch when the group has changed (e.g. new members, new subscriptions, etc.). then, we update the target assignment when we detect that it is older than the group metadata. however, the member epoch should always be lower or equals to the target assignment epoch. regarding ""groupepoch"", i am not sure to understand your point. are you saying that the name is confusing?",0,0.6135903000831604
1192204200,13639,dajac,2023-05-12T10:37:34Z,this is indeed not in the kip because this is an implementation detail. we need to track epoch of partitions in order to know if they are free or not. an epoch with an old epoch basically means that the partition has not been revoked yet.,0,0.98039311170578
1194138883,13639,jeffkbkim,2023-05-15T17:24:33Z,that's a great point. thanks,1,0.9949729442596436
1194141365,13639,jeffkbkim,2023-05-15T17:27:01Z,maybe topicandpartitions? topic partitions generally is used to refer to topic-partition tuples,0,0.9945818781852722
1194145192,13639,jeffkbkim,2023-05-15T17:31:00Z,"maybe it would be good to include a comment on the relationship between the group, target assignment, and member epochs.",0,0.989267885684967
1194151379,13639,jeffkbkim,2023-05-15T17:37:05Z,"actually the consumergroup fields, groupepoch and assignmentepoch, already have comments",0,0.9939160943031311
1194171285,13639,jeffkbkim,2023-05-15T17:55:33Z,is there a reason we use expectedsize = 1?,0,0.9931035041809082
1194188439,13639,jolshan,2023-05-15T18:10:17Z,i think the comment makes things a little clearer. but i guess my confusion was it seems like this should always cause the assignment to change. i think i also got a bit confused because on earlier prs i thought that the target assignment epoch was the epoch we get we at at when the assignment is complete. but maybe i am confused somewhere.,0,0.8016365170478821
1194189770,13639,jeffkbkim,2023-05-15T18:10:57Z,should we throw an illegal state exception if new member is null?,0,0.9896528124809265
1194198701,13639,jolshan,2023-05-15T18:17:35Z,is this still a todo? ditto to above.,0,0.97135990858078
1194201125,13639,jolshan,2023-05-15T18:19:32Z,this method is a bit long and complicated. in the comments (and maybe the javadoc for the method) could we break it up into logical chunks.,0,0.8768723607063293
1194201173,13639,jeffkbkim,2023-05-15T18:19:34Z,"""an"" immutable map",0,0.965941309928894
1194207204,13639,jeffkbkim,2023-05-15T18:24:06Z,"nit: ""or -1 if the partition does not exist.""",0,0.9380102753639221
1194218869,13639,jolshan,2023-05-15T18:36:19Z,could we be a bit more specific in what each of these replays do? ie. for this one we update or remove a member depending on if the value is null. others set subscription metadata etc. i don't think the class names are enough to explain what each is doing -- especially since the names are so similar.,0,0.9327759742736816
1194225263,13639,jolshan,2023-05-15T18:42:15Z,"when we are in the state between making the assignment and installing it, how do we guard against generating new assignments? is this part of the state transitions?",0,0.988707423210144
1194246241,13639,jolshan,2023-05-15T18:58:27Z,nit: an,0,0.5793663859367371
1194249412,13639,jolshan,2023-05-15T18:59:35Z,"can we say ""keyed by __""",0,0.9919058084487915
1194251237,13639,jolshan,2023-05-15T19:01:20Z,"this is ""updated"" because the member had changes and we want to use the assignor to make a new assignment?",0,0.9941135048866272
1194252036,13639,jolshan,2023-05-15T19:02:16Z,"nit ""replaces""",0,0.9848446249961853
1194368824,13639,jolshan,2023-05-15T21:13:28Z,i thought the java doc for timelinehashmap doesn't allow null values.,0,0.975907027721405
1194380191,13639,jolshan,2023-05-15T21:28:27Z,can we reuse computesubscriptionmetadata here?,0,0.9950557947158813
1194394646,13639,jeffkbkim,2023-05-15T21:47:43Z,nit: replaces,0,0.9143931269645691
1194394856,13639,jolshan,2023-05-15T21:48:02Z,are the topic partitions not empty here? (like empty is different than null?),0,0.9917421340942383
1194395409,13639,jeffkbkim,2023-05-15T21:48:58Z,"how's ""computes a new subscription metadata with a member's updated topic subscriptions""?",0,0.993180513381958
1194397156,13639,jolshan,2023-05-15T21:51:41Z,i see we check for null or !empty.,0,0.984211266040802
1194404457,13639,jeffkbkim,2023-05-15T21:58:32Z,nit: memberid is more readable for me. also from [a link] have we looked into this?,0,0.9700964093208313
1194427256,13639,jeffkbkim,2023-05-15T22:38:09Z,nit: javadoc on params,0,0.9884784817695618
1194427427,13639,jeffkbkim,2023-05-15T22:38:29Z,nit: javadoc on params,0,0.9884784817695618
1194427551,13639,jeffkbkim,2023-05-15T22:38:45Z,nit: javadoc on params,0,0.9884784817695618
1194427668,13639,jeffkbkim,2023-05-15T22:38:59Z,ditto on javadoc,0,0.982284426689148
1194427886,13639,jeffkbkim,2023-05-15T22:39:21Z,nit: we can remove this,0,0.9795973896980286
1194430597,13639,jeffkbkim,2023-05-15T22:44:50Z,nit: does this have to be in its own line?,0,0.907904863357544
1194432103,13639,jeffkbkim,2023-05-15T22:47:50Z,(not completely related) older record types i.e. groupmetadatavalue have camelcase field names. when did we change the format to upper camelcase?,0,0.9916222095489502
1194435189,13639,jeffkbkim,2023-05-15T22:54:06Z,"nit: ""it does not""",-1,0.7621383666992188
1194437607,13639,jeffkbkim,2023-05-15T22:58:42Z,what happens if the member id is not empty but the member epoch is 0 to indicate it's a new member? does this mean that the client can choose its member id? i don't think it should right?,0,0.9034624099731445
1194440425,13639,jeffkbkim,2023-05-15T23:04:18Z,nit: i think we should differentiate the member from the memberepoch. the member points to the existing member stored in the consumer group whereas the memberepoch points to the epoch of the member from the heartbeat request,0,0.9885482788085938
1194446025,13639,jeffkbkim,2023-05-15T23:16:30Z,nit: can we add a newline between the if statement and updatedmember?,0,0.9934247732162476
1194447475,13639,jeffkbkim,2023-05-15T23:19:39Z,can we do `for (consumergroupmember member : members.values()) {`?,0,0.9940177202224731
1194449829,13639,jeffkbkim,2023-05-15T23:25:01Z,"more of a comment for `consumergroup.preferredserverassignor()`, but we're iterating through all members to get the preferred assignor, every time we need bump the target assignment epoch. have we considered saving the count?",0,0.9921855330467224
1194455250,13639,jeffkbkim,2023-05-15T23:37:27Z,"we don't perform a reconciliation phase on leave group because once the existing members heartbeat, the metadata manager will notice the bumped groupepoch (l619) and so targetassignmentepoch < groupepoch will trigger the reconciliation. is this correct? why do we need to create target assignment records here then?",0,0.9930436611175537
1194457005,13639,jeffkbkim,2023-05-15T23:41:03Z,"i think targetassignments size does represent the number of members but shouldn't this be ""assignments"" or ""target assignments""?",0,0.9933249354362488
1194459578,13639,jeffkbkim,2023-05-15T23:46:13Z,i think we would want at least a way to detect that something is wrong since with the current approach the bug could go unseen.,0,0.9672320485115051
1194463847,13639,jeffkbkim,2023-05-15T23:56:59Z,"what's ""this""? that's right. the target assignment epoch is what every member will try to converge to by revoking/assigning partitions. once we build the target assignment, we bump the target assignment epoch (l532)",0,0.9885805249214172
1194464178,13639,jeffkbkim,2023-05-15T23:57:46Z,i also think that would be very helpful,1,0.5862324237823486
1194465375,13639,jeffkbkim,2023-05-16T00:00:46Z,david can correct me but the coordinator will continue to compute new target assignments even if we're in the process of installing an existing one and the group would try to converge to the latest assignment,0,0.967651903629303
1194477394,13639,jolshan,2023-05-16T00:27:22Z,"when we bump the group epoch, it seems like we will also always reassign. so i guess i was just trying to figure out if there is a case where the group epoch is different from the assignment epoch.",0,0.9816228151321411
1194479029,13639,jolshan,2023-05-16T00:31:08Z,ok. that's what i was expecting to happen. so if that's expected it is fine. i just wonder if it is extra work.,0,0.9592894315719604
1200087476,13639,dajac,2023-05-22T07:39:20Z,"yes, it is. this is part of another pr.",0,0.9864956140518188
1200129689,13639,dajac,2023-05-22T08:15:50Z,ack. let me expand the comments.,-1,0.9402990341186523
1200134115,13639,dajac,2023-05-22T08:18:37Z,ack. i plan to rename those records but this will come when my main prs are merged.,-1,0.6299514770507812
1200138816,13639,dajac,2023-05-22T08:22:14Z,that's correct.,0,0.9792349338531494
1200143037,13639,dajac,2023-05-22T08:25:37Z,"right. this is ""updated"" because the member may have been updated so we need to use the latest (non-persisted) information from the member to select the correct assignor.",0,0.9935500621795654
1200145207,13639,dajac,2023-05-22T08:27:19Z,right but `compute` gives you `null` if the key is not present.,0,0.9884595274925232
1200149162,13639,dajac,2023-05-22T08:30:23Z,`computesubscriptionmetadata` is slightly different so i can't reuse it directly here.,0,0.9693361520767212
1200149897,13639,dajac,2023-05-22T08:30:59Z,the topic partitions should be an empty list when joining or re-joining.,0,0.987894594669342
1200153306,13639,dajac,2023-05-22T08:33:53Z,i think that i should use `assignedpartitions.size()`.,0,0.9865655303001404
1200154967,13639,dajac,2023-05-22T08:35:12Z,we could.,0,0.9847006797790527
1200227960,13639,dajac,2023-05-22T09:12:37Z,`exist` is a bit misleading here as `-1` is returned if the partition does not have an epoch set.,0,0.9144019484519958
1200233059,13639,dajac,2023-05-22T09:16:45Z,i put it like this to follow the style of the other methods in this file.,0,0.9850580096244812
1200233985,13639,dajac,2023-05-22T09:17:32Z,i think that we have always been using upper camelcase in requests/responses. groupmetadatavalue is likely wrong here.,0,0.7503188848495483
1200235936,13639,dajac,2023-05-22T09:19:07Z,epoch equals to zero does not only indicate a new member. it also indicates a rejoining member. the member could indeed set the member id when it joins but it is not supposed to. it is a small quirk in the protocol.,0,0.9837400317192078
1200237262,13639,dajac,2023-05-22T09:20:08Z,that makes sense. let me use `receivedmemberepoch`.,0,0.9858831763267517
1200239503,13639,dajac,2023-05-22T09:21:58Z,let me put the condition on one line.,0,0.9882696866989136
1200293273,13639,dajac,2023-05-22T10:07:04Z,`memberid` is already used... let me check if keeping a map is worth it.,0,0.98497074842453
1200402995,13639,dajac,2023-05-22T11:47:16Z,"i think that keeping a map of topicmetadata to member ids does not work because the content of topicmetadata could change as well. however, we could keep a map of topic name to number of subscribers. that would reduce the computation. i did the change. let me know what you think.",0,0.9327663779258728
1200415899,13639,dajac,2023-05-22T11:58:51Z,that's fair. we could remove it.,1,0.9521684646606445
1200462722,13639,dajac,2023-05-22T12:41:30Z,that makes sense. done.,0,0.8258633613586426
1200467372,13639,dajac,2023-05-22T12:45:37Z,it may be better to not do this after all. let me remove it for now in order to be on the safe side. we can always bring it back if we find it useful in the future.,0,0.9865445494651794
1202837929,13639,jolshan,2023-05-23T18:36:53Z,"so across all types of groups (generic, consumer) we can only have one type of group with a given name. we can't have a foo consumer group and a foo generic group. are we also enforcing this when we create groups? looks to be the case if we only create groups via getormaybecreateconsumergroup",0,0.9900261163711548
1202846284,13639,jolshan,2023-05-23T18:43:31Z,i see in the json comments for instance id: `null if not provided or if it didn't change since the last heartbeat; the instance id otherwise.` but this seems inconsistent with what we are saying here. it should only be provided in the first request?,0,0.9927666187286377
1202846585,13639,jolshan,2023-05-23T18:43:45Z,ditto for rack id,0,0.9354502558708191
1203077539,13639,jolshan,2023-05-23T22:08:38Z,"i'm not sure i follow `note the member is the persisted member anytime in this method` are we saying that the member is written to disk? or something else? i think the word ""anytime"" is confusing me.",-1,0.6061391234397888
1203079411,13639,jolshan,2023-05-23T22:10:12Z,do we want a log message for the first time joining the group?,0,0.9923685193061829
1203083017,13639,jolshan,2023-05-23T22:13:51Z,do we add a newmembersubscriptionrecord when the member is updated (not new) too?,0,0.993486225605011
1203084630,13639,jolshan,2023-05-23T22:15:36Z,"i suppose the naming here with ""new"" and the usage below for `newgroupsubscriptionmetadatarecord` confused me.",0,0.8853728175163269
1203119594,13639,jolshan,2023-05-23T22:52:09Z,"rereading this and the kip -- is the only time we have a different assignment epoch from the group epoch is when assignment fails? i also assume that other members should learn about this assignment. i think i'm missing how that is done -- is this through the records methods? so for the next heartbeat request of another member, line 552 would see updatedmember.nextmemberepoch() != targetassignmentepoch as true since the group epoch and assignment epoch would be equal, but the member epoch would still be behind?",0,0.8456617593765259
1203132909,13639,jolshan,2023-05-23T23:08:24Z,would it be useful to have a helper method to delete a member?,0,0.9950150847434998
1203150079,13639,jolshan,2023-05-23T23:29:41Z,if the partition did not exist it would also be -1 though right? there's just two possible cases?,0,0.9772302508354187
1203152667,13639,jolshan,2023-05-23T23:32:36Z,"should we also mention in the java doc that we update the assignors here. i know we say in method, but maybe good to mention at the top too. (i was a little confused earlier why we needed both the new and the old members as parameters when this was called in the other class)",0,0.9896307587623596
1203158830,13639,jolshan,2023-05-23T23:40:12Z,is there a reason we use this method instead of put? shouldn't each topic name be absent?,0,0.9929674863815308
1203181594,13639,jolshan,2023-05-24T00:01:53Z,"if we compute and return null, isn't that trying to set null values? or am i missing something.",0,0.9308055639266968
1203184877,13639,jolshan,2023-05-24T00:04:45Z,i guess i'm also wondering why we don't use empty set. unless this is because we want to overload null as mentioned in the getepoch method.,0,0.8834432363510132
1203192959,13639,jolshan,2023-05-24T00:11:42Z,ok so null is not ok -- it must be explicitly empty.,0,0.9613416790962219
1203222949,13639,jolshan,2023-05-24T00:35:51Z,do we also test that the other members also update their assignments?,0,0.9940016865730286
1203224577,13639,jolshan,2023-05-24T00:37:10Z,nit: member 2?,0,0.9836931824684143
1203225900,13639,jolshan,2023-05-24T00:38:17Z,i guess we sort of duplicate the code and test in testreconciliationprocess,0,0.9850038290023804
1203578132,13639,dajac,2023-05-24T07:17:06Z,that's right. we enforce this in `getormaybecreateconsumergroup`.,0,0.9908738136291504
1203601651,13639,dajac,2023-05-24T07:33:47Z,good catch. let me fix this.,1,0.9858093857765198
1203610206,13639,dajac,2023-05-24T07:39:48Z,i wanted to callout that `member` is different from `updatedmember` in this method but i think that the names are clear. let me remove that comment. it is more confusing than anything else.,0,0.7377448081970215
1203610761,13639,dajac,2023-05-24T07:40:12Z,epoch 0 means that a new member joins or an existing member rejoins. let me update the log.,0,0.9905428290367126
1203611994,13639,dajac,2023-05-24T07:41:02Z,`new` means that a new record is created. a new record is created when the member is created or updated.,0,0.9927722811698914
1203615232,13639,dajac,2023-05-24T07:43:16Z,"we already have `consumergroup.removemember(memberid)` but it does not apply here. in this case, we really want to update the member with sentinel values.",0,0.9948683977127075
1203623275,13639,dajac,2023-05-24T07:46:37Z,i have clarified the javadoc.,0,0.9765966534614563
1203625806,13639,dajac,2023-05-24T07:47:54Z,it is a mistake. we can use `put` as you suggested.,0,0.584786593914032
1203627084,13639,dajac,2023-05-24T07:48:37Z,that's right.,0,0.973717451095581
1204465047,13639,jeffkbkim,2023-05-24T16:15:47Z,nit: the number of members supporting each server assignor name. is more readable to me,0,0.9430224299430847
1204467377,13639,jeffkbkim,2023-05-24T16:17:36Z,nit: the metadata associated with each subscribed topic name,0,0.9777469038963318
1204468514,13639,jeffkbkim,2023-05-24T16:18:36Z,nit: the target assignment per member,0,0.9783717393875122
1204471728,13639,jeffkbkim,2023-05-24T16:21:27Z,"nit: it removes its partition epochs from this map. when a member gets a partition, it adds the epoch to this map.",0,0.9921460747718811
1204475716,13639,jeffkbkim,2023-05-24T16:25:01Z,"for this line and the following couple lines, does expected size of 0 create a hash table with size 1 as it's a power of 2? i'm confused because the expected size intuitively should not be 0.",-1,0.6140682101249695
1204477868,13639,jeffkbkim,2023-05-24T16:27:01Z,"i think justine or someone else may have mentioned in another pr but for getters, just having the ` the current group epoch` makes more sense. i'm not sure if this line adds much value as well as for other getter methods",0,0.9500846266746521
1204492401,13639,jolshan,2023-05-24T16:40:28Z,"ok -- so the idea is member stays the same from when it is first ""gotten"", but updatedmember is the one we change through the method?",0,0.9919431209564209
1204493167,13639,jolshan,2023-05-24T16:41:11Z,i slowly figured this out as i read the pr. :grinning_face_with_sweat: did we also say earlier we were changing the record names?,0,0.9542685151100159
1204494016,13639,jolshan,2023-05-24T16:42:05Z,"yeah, i suppose i was meaning a method to add the sentinel values. but if it is only done here, maybe it is not useful.",0,0.9114046096801758
1204494893,13639,jeffkbkim,2023-05-24T16:42:57Z,nit: returns the existing,0,0.9806832671165466
1204509686,13639,jeffkbkim,2023-05-24T16:54:37Z,do you think we should log something if topicimage == null? can both the topicsimage and/or subscribed topic names be outdated here?,0,0.9931046366691589
1204522037,13639,dajac,2023-05-24T17:06:23Z,"yeah, let me try to re-explain it with my words. basically, we have three epochs: the group epoch, the assignment epoch, and each member has its own epoch. - when the group changes (e.g. new member, updated subscription, etc), the group epoch is bumped in order to note that the topology of the group has changed. - when the assignment epoch is smaller than the group epoch, it means that the assignment for the group is stable so we need to recompute it. we generate a new assignment with the epoch matching the group epoch in order to note that the assignment is for the latest group topology. - when a member has a smaller epoch than the assignment epoch, it means that its assignment is stale so we need to reconcile it to converge it to that epoch. all the epochs are equal when the group is stable. this means that all the members have converged to the desired assignment. so for the next heartbeat request of another member, line 552 would see updatedmember.nextmemberepoch() != targetassignmentepoch as true since the group epoch and assignment epoch would be equal, but the member epoch would still be behind? yeah, we could have a difference between the assignment epoch and the group epoch when the assignment is not computed immediately. in the current implementation, we almost never have this but keep in mind that we will support client side assignors. in this case, the computation will take some time so we will see it more. the member learn about their assignment when they heartbeat. this is when we do the reconciliation process. we reconcile a member in two cases: 1) the member is not stable; 2) the target assignment has changed since the last time we reconciled the member. this is done [a link].",0,0.9687228202819824
1204523103,13639,dajac,2023-05-24T17:07:24Z,that's right.,0,0.973717451095581
1204523524,13639,dajac,2023-05-24T17:07:52Z,i will do this but only when all my code is merged. it will create a mess otherwise...,-1,0.9311379790306091
1204535515,13639,jolshan,2023-05-24T17:19:36Z,i assume if we just got member1's partitions we would still be in assigning state.,0,0.9882593154907227
1204538473,13639,jolshan,2023-05-24T17:22:14Z,or i guess can we just get member1's partitions while member2 is still revoking?,0,0.9907947182655334
1204556978,13639,jolshan,2023-05-24T17:38:55Z,"just for my understanding, we will send the same request again when we receive the error. we will already have a group id and member id server side, and we will reuse them. ideally, the assignment works and we continue. is this correct?",0,0.9748135805130005
1204564082,13639,jolshan,2023-05-24T17:46:03Z,would it be helpful to use a new epoch here to see that it changes?,0,0.9913574457168579
1204571671,13639,jeffkbkim,2023-05-24T17:52:01Z,"after updating member 1 in l315, we have [code block] in serverassignors. preferredserverassignor() in l317 decrements ""range"" so the copy should have [code block] shouldn't this be `asserttrue(assignor.equals(optional.of(""uniform"")));`?",0,0.995559811592102
1204579244,13639,jolshan,2023-05-24T17:58:03Z,is there ever a time the next member epoch is not the same as the member epoch?,0,0.986716628074646
1204582235,13639,jolshan,2023-05-24T18:00:53Z,"would it make sense to also check member states here? i know we had something similar in the other file, but we are also testing the group states here.",0,0.9919060468673706
1204597635,13639,jolshan,2023-05-24T18:17:53Z,"if we have more than one assignor with the same max value, we choose one randomly (based on map iteration order). is this intended?",0,0.9902211427688599
1204599222,13639,jolshan,2023-05-24T18:19:39Z,ah i see this below.,0,0.94837486743927
1204607029,13639,jolshan,2023-05-24T18:26:24Z,preferredserverassignor not modifying the state was really throwing me off here. not sure if comments will help.,0,0.5607004761695862
1204613085,13639,jolshan,2023-05-24T18:32:41Z,we aren't actually removing member1 here but computing what would happen if we did. this is a bit confusing to follow.,-1,0.9623327255249023
1204613762,13639,jolshan,2023-05-24T18:33:21Z,did we mean to have null instead of member3 here?,0,0.9916045069694519
1204623123,13639,jolshan,2023-05-24T18:43:16Z,we have member 2 as range and member 3 as uniform so that's why it is 50/50,0,0.9926196932792664
1204872093,13639,jeffkbkim,2023-05-25T00:13:04Z,i am curious as well. i notice 3 places [code block] that both set member epoch and next member epoch to `targetassignmentepoch`,0,0.7473496198654175
1204874200,13639,jeffkbkim,2023-05-25T00:18:00Z,"i'm confused because i was referring to member 2 here: range: 1 (member 2) uniform: 1 (member ~~1~~ 3) after `consumergroup.updatemember(updatedmember1);` in l315. in l317, we call `preferredserverassignor()` which gets a copy, then will decrement the count of ""range"" since member1 (range) is passed in as the oldmember argument. so shouldn't the count for ""range"" be 0? i think i'm missing something",0,0.745219349861145
1204875457,13639,jeffkbkim,2023-05-25T00:21:10Z,are we using this variable?,0,0.9895204305648804
1204877037,13639,jeffkbkim,2023-05-25T00:25:13Z,are we using this?,0,0.9785451889038086
1204878528,13639,jeffkbkim,2023-05-25T00:29:01Z,"can we use `targetassignment` and explain the mapping of member id to its assignment? ""assignments"" is ambiguous since we also have current assignments throughout the new protocol.",0,0.9936134219169617
1204879910,13639,jeffkbkim,2023-05-25T00:32:29Z,"btw, i was wondering if we could name this targetassignmentepoch. similar to my comment on `assignments`.",0,0.987682044506073
1204881034,13639,jeffkbkim,2023-05-25T00:35:20Z,i think we can use put here too right?,0,0.989592432975769
1204882557,13639,jeffkbkim,2023-05-25T00:39:25Z,are we using this?,0,0.9785451889038086
1204882590,13639,jeffkbkim,2023-05-25T00:39:32Z,are we using this?,0,0.9785451889038086
1204883474,13639,jeffkbkim,2023-05-25T00:41:49Z,"should these be `epoch`s? to me, offset seems more partition related.",0,0.9871587157249451
1204883836,13639,jeffkbkim,2023-05-25T00:42:51Z,i'm noticing a bunch of unused methods. are we planning to use these in the following prs?,-1,0.5990750193595886
1204885916,13639,jeffkbkim,2023-05-25T00:48:17Z,we use a record key's raw version in recordhelpers. should we choose a convention to follow?,0,0.9936079978942871
1204889028,13639,jeffkbkim,2023-05-25T00:56:16Z,i think adding a comment above this line to indicate we're now testing a non-new/rejoining member will be helpful. and maybe a comment when we first start testing new/rejoining member's heartbeat requests,0,0.9832190871238708
1204889641,13639,jeffkbkim,2023-05-25T00:57:56Z,this is `topicsimage.empty` right?,0,0.9935336112976074
1204903807,13639,jeffkbkim,2023-05-25T01:29:38Z,"curious, what happens if the member acknowledges but does not actually revoke i.e. a buggy client? would that member and the new owner of the partition fetch from the same partition? i'm guessing there's no guards against that",-1,0.7791749238967896
1204907417,13639,jeffkbkim,2023-05-25T01:38:31Z,shouldn't the metadata manager respond with `assignedtopicpartitions`? what happens if the previous heartbeat respond was lost?,0,0.9901939034461975
1204909101,13639,jeffkbkim,2023-05-25T01:42:27Z,ditto on assignedtopicpartitions (and pendingtopicpartitions for member3),0,0.9920715689659119
1204909313,13639,jeffkbkim,2023-05-25T01:42:58Z,the revocation is acknowledging the new assigned partitions revoked from member 1 right?,0,0.9893476963043213
1204910503,13639,jeffkbkim,2023-05-25T01:45:42Z,why is the topic id ordering different here?,0,0.9815178513526917
1204914720,13639,jeffkbkim,2023-05-25T01:55:28Z,i think i'm getting confused here - do we create a new current assignment record whenever we respond back to a member? i might be remembering incorrectly but i thought the current assignment was created when the member transitions to stable (after revoking partitions and acknowledging assigned partitions),0,0.679075300693512
1205093788,13639,dajac,2023-05-25T07:16:03Z,"from the javadoc of `compute`: [code block] we don't keep the empty set because we want to clean the map. otherwise, it would keep sets for non-existing partitions for instance.",0,0.9946664571762085
1205138023,13639,dajac,2023-05-25T07:57:02Z,right.,0,0.9793882369995117
1205155041,13639,dajac,2023-05-25T08:11:49Z,sure.,0,0.9664214849472046
1205155348,13639,dajac,2023-05-25T08:12:06Z,right.,0,0.9793882369995117
1205156348,13639,dajac,2023-05-25T08:12:57Z,that's correct. -1 is returned when the partition is not in the map. this could be because the partition does not exist or because the partition does not have an epoch yet.,0,0.9890228509902954
1205157172,13639,dajac,2023-05-25T08:13:38Z,"as it is used only once here, it is not worth it in my opinion.",0,0.812229573726654
1205165820,13639,dajac,2023-05-25T08:21:08Z,"correct. yes, we can. member 3 gets member 1's partitions when the are available but it does not have to wait on member 2.",0,0.9840390086174011
1205169546,13639,dajac,2023-05-25T08:23:21Z,correct. the request will be retried with the group id and the member id (if the member already has one).,0,0.9936880469322205
1205178313,13639,dajac,2023-05-25T08:30:26Z,"that's right. there is only one case where it is not. when a member must revoke partitions, it stays in its current epoch so member epoch is different from the next epoch in this case. the rational of keeping track of the next epoch here is to basically prevent recomputing the state while the member is in revoking state. without it, we would have to recompute it on every heartbeat.",0,0.9838157296180725
1205203837,13639,dajac,2023-05-25T08:51:33Z,make sense.,0,0.9810715317726135
1205211076,13639,dajac,2023-05-25T08:57:20Z,the capacity will be 2 (the min capacity).,0,0.9910741448402405
1205218229,13639,dajac,2023-05-25T09:03:13Z,"i would not because it could be common to not have metadata about a topic yet. this will spam the logs. we will always use the latest topics image that we have got. the subscribed topic names is never outdated as it always represent the subscriptions provided by the consumer. however, it may not be known/exist yet.",0,0.9840748310089111
1205219753,13639,dajac,2023-05-25T09:04:28Z,correct.,0,0.857904851436615
1205238390,13639,dajac,2023-05-25T09:20:29Z,updated the test. i had a mistake in these.,-1,0.6535111665725708
1205239034,13639,dajac,2023-05-25T09:21:03Z,i have renamed it to `computepreferredserverassignor`. now `preferredserverassignor` only returns what the group has.,0,0.9939640164375305
1205239532,13639,dajac,2023-05-25T09:21:29Z,i have put more comments. i hope it helps.,1,0.9433726072311401
1205247698,13639,dajac,2023-05-25T09:25:36Z,nope. let me remove it.,0,0.9445849657058716
1205248818,13639,dajac,2023-05-25T09:26:06Z,nope. removed.,0,0.9158164858818054
1205252133,13639,dajac,2023-05-25T09:28:54Z,nope.,0,0.9007224440574646
1205252262,13639,dajac,2023-05-25T09:29:01Z,nope.,0,0.9007224440574646
1205253148,13639,dajac,2023-05-25T09:29:44Z,right but this is what they are in the end in our context. keeping offset is better here.,0,0.9863964319229126
1205254844,13639,dajac,2023-05-25T09:31:08Z,i have removed all of them but this one. i will use it in the future.,0,0.9852898716926575
1205256385,13639,dajac,2023-05-25T09:32:26Z,"using the constants is fine here. in recordhelpers, i did not use them in order to not change the version by mistake.",0,0.9881960153579712
1205264178,13639,dajac,2023-05-25T09:39:07Z,added comments.,0,0.9876770377159119
1205264648,13639,dajac,2023-05-25T09:39:30Z,right.,0,0.9793882369995117
1205266764,13639,dajac,2023-05-25T09:41:24Z,"that's right. this is basically a violation of the protocol. note that the previous owner won't be allowed to commit offsets. we can't do much at this protocol level. however, we could imagine passing the member epoch while fetching so the leader could reject stale member epoch. that would strengthen the overall protocol.",0,0.914373517036438
1205271089,13639,dajac,2023-05-25T09:45:14Z,"the assignment is only provided in the following cases: 1. the member reported its owned partitions; 2. the member just joined or rejoined to group (epoch equals to zero); 3. the member's assignment has been updated. in the case of a lost response, the client would hit a timeout/network error. in this case, the client is expected to send a ""full"" heartbeat with the owned partitions set so it will get a ""full"" response.",0,0.9943968057632446
1205271405,13639,dajac,2023-05-25T09:45:29Z,see my previous reply.,0,0.9869557619094849
1205273140,13639,dajac,2023-05-25T09:46:58Z,"member 3 has nothing to revoke here. this comment is wrong, let me update it.",0,0.8843865394592285
1205275881,13639,dajac,2023-05-25T09:49:21Z,hmm.. i don't know. let me check this.,-1,0.8484266996383667
1205278404,13639,dajac,2023-05-25T09:51:27Z,it is the other way around. we persist the current assignment when it changes based on the reconciliation. we provide the assignment to the client when the current assignment change.,0,0.992172360420227
1206048854,13639,jolshan,2023-05-25T22:10:08Z,clarified offline -- null returned in compute removes the entry.,0,0.9907277822494507
1206050414,13639,jolshan,2023-05-25T22:13:07Z,that's totally fair. just confirming :),1,0.995576024055481
1206053946,13639,jolshan,2023-05-25T22:19:58Z,is nextmemberepoch a bit confusing here? it seems more like a target epoch.,0,0.6802634596824646
1206060783,13639,jeffkbkim,2023-05-25T22:33:47Z,nit: group size,0,0.9541861414909363
1206063165,13639,jeffkbkim,2023-05-25T22:39:03Z,"do we have a test case for this? i expect that when we accept a request with the previous epoch, we compute the diff from the request's owned partitions and the target assignment and respond to the consumer (assignedtopicpartitions, pending assignment if exists). which would be identical to what we do for the expected member epoch.",0,0.992703914642334
1206064411,13639,jolshan,2023-05-25T22:41:41Z,this and the server assignor test are much more readable. thanks!,1,0.9954758286476135
1206066309,13639,jeffkbkim,2023-05-25T22:45:49Z,nit: existing and the new target assignment,0,0.9727884531021118
1206317753,13639,dajac,2023-05-26T07:02:21Z,"yeah, i agree. let me use `targetmemberepoch`.",0,0.9836277961730957
1206322259,13639,dajac,2023-05-26T07:07:55Z,"this is covered in `testconsumergroupmemberepochvalidation`. if the member comes with the previous epoch and its owned partitions is a subset of its assigned partitions, we accept it and it goes through the regular process. if nothing has changed since the last heartbeat, it will just receive the current assignment/epoch.",0,0.9932956099510193
178980194,4812,guozhangwang,2018-04-03T22:27:42Z,"i think you can still use the log4j format here, e.g. [code block] with four parameters, the last one is auto interpreted as the exception; maybe we can validate if this is the case.",0,0.9918789863586426
178981229,4812,guozhangwang,2018-04-03T22:32:42Z,"if it is a per-thread metric, i'd suggest we pre-register them at the beginning of the application. this way some other tools like `jmxtool` do not need to wait for the object name to show up. wdyt?",0,0.9901942610740662
179188828,4812,vvcephei,2018-04-04T15:42:45Z,"sounds good. i meant to make a comment before you read this to say that there had been a concern in the discussion about having metrics reported from processor nodes (when the proposal was at the node level) that would never actually skip records, thereby polluting the metrics. i thought i'd throw the lazy registration pattern in just to see what you all thought. i'll switch it back to pre-registration.",0,0.5360546708106995
179312182,4812,vvcephei,2018-04-04T23:24:35Z,"confirmed, switching to the variant you mentioned still prints: [code block]",0,0.9883171916007996
179586187,4812,guozhangwang,2018-04-05T20:09:33Z,"same here, we can get rid of `string.format`.",0,0.9915682673454285
179587232,4812,guozhangwang,2018-04-05T20:13:34Z,"we are stripping the prefix for this sensor: is it intentional? note that for jmx reporter, the sensor name would not be included in any fields.",0,0.9919610619544983
179587354,4812,guozhangwang,2018-04-05T20:13:59Z,"`skippedrecordssensor` should not be null, right?",0,0.9897698163986206
179589855,4812,guozhangwang,2018-04-05T20:24:03Z,"nit: flattening to a very long single line, is it intentional?",-1,0.7466568946838379
179589896,4812,guozhangwang,2018-04-05T20:24:11Z,ditto below and in other tests like `testpauseresume`,0,0.9930018782615662
179590319,4812,guozhangwang,2018-04-05T20:25:54Z,nit: alignment.,0,0.6476569175720215
179590486,4812,guozhangwang,2018-04-05T20:26:32Z,ditto here.,0,0.9378204345703125
179590561,4812,guozhangwang,2018-04-05T20:26:52Z,ditto here.,0,0.9378204345703125
179590584,4812,guozhangwang,2018-04-05T20:26:58Z,here.,0,0.9832085967063904
179591415,4812,guozhangwang,2018-04-05T20:30:09Z,why do we remove this sensor?,0,0.9691113829612732
179592552,4812,guozhangwang,2018-04-05T20:34:32Z,should we record the thread-level `skipped record` sensor here?,0,0.9949317574501038
179592840,4812,guozhangwang,2018-04-05T20:35:43Z,"hmm.. i did not see we have recorded the sensor for deserialization error here, why this test passed?",0,0.8986406922340393
179626142,4812,vvcephei,2018-04-05T23:17:50Z,"heh, what a coincidence! i think so, and that's actually part of the motivation for this change i'm proposing to the metrics.",1,0.5839318633079529
179627246,4812,vvcephei,2018-04-05T23:26:31Z,"i disabled these tests because part of their function is to verify the number of metrics we register. this currently fails because we're registering a lot more metrics. if we decide to go with this overall strategy, i'll rethink these tests.",0,0.9673839211463928
179627503,4812,guozhangwang,2018-04-05T23:28:22Z,"just `implements internalstreamsmetrics` should be sufficient, since `internalstreamsmetrics` extends `streamsmetrics`?",0,0.995267391204834
179771434,4812,bbejeck,2018-04-06T14:16:43Z,for `testlatencymetrics` and `testthroughputmetrics` maybe use `` instead ? not a big deal but by getting an `ignored` test count there's a better chance these two tests won't fall through the cracks.,0,0.9761097431182861
179774999,4812,bbejeck,2018-04-06T14:28:05Z,for the `task.addrecords` with a long list of `consumerrecord<>` seems like the only difference with each record is the offset. maybe create a method that takes an `int[]` with offsets and returns a `list `?,0,0.9945145845413208
179775146,4812,vvcephei,2018-04-06T14:28:31Z,"ah, yeah, in an earlier pass they were independent interfaces.",0,0.9655353426933289
179828056,4812,mjsax,2018-04-06T17:42:13Z,nit: remove `this`,0,0.9891441464424133
179828169,4812,mjsax,2018-04-06T17:42:41Z,nit: move `topology` to next line,0,0.9926348328590393
179830023,4812,mjsax,2018-04-06T17:49:58Z,"nit: add `final` to the parameters to cleanup code ""on the side""",0,0.9938033819198608
179830080,4812,mjsax,2018-04-06T17:50:08Z,nit: add `final`,0,0.9897833466529846
179830701,4812,mjsax,2018-04-06T17:52:31Z,"when would `skippedrecordssensor` be `null`? (i know this is just ""move"" code but still wondering why we need this)",0,0.988335371017456
179831780,4812,vvcephei,2018-04-06T17:56:31Z,"ah, that's how you do it. i tried `(ignore=true)` like testng, but that obviously doesn't work...",-1,0.6883279085159302
179833851,4812,mjsax,2018-04-06T18:04:32Z,"because `info` level is default, should we remove `sensor.recordinglevel.info` in the above calls?",0,0.9956834316253662
179835194,4812,mjsax,2018-04-06T18:09:51Z,nit: is this suppression necessary? i don't think that gradle builds put a warning -- might be your local ide setting only?,0,0.9532601237297058
179835363,4812,mjsax,2018-04-06T18:10:36Z,nit: do we need this? (cf. my other comment about `suppresswarnings`),0,0.9913190007209778
179835676,4812,mjsax,2018-04-06T18:11:38Z,as above.,0,0.9878018498420715
179835819,4812,mjsax,2018-04-06T18:12:14Z,as above.,0,0.9878018498420715
179836521,4812,mjsax,2018-04-06T18:15:06Z,nit: `topic` -> `partitionsfortopic`,0,0.9931178092956543
179836693,4812,mjsax,2018-04-06T18:15:47Z,nit: `partitions` -> `partitionsforchangelog`,0,0.9937403202056885
179838008,4812,mjsax,2018-04-06T18:20:42Z,very nice!,1,0.9942394495010376
179872407,4812,vvcephei,2018-04-06T20:49:38Z,it won't. that's an artifact that i need to fix.,0,0.9613593220710754
179872830,4812,vvcephei,2018-04-06T20:51:34Z,"meh. i personally favor explicit settings, so if anything, i'd actually add it here, but i'm happy to do whichever you all prefer.",1,0.9831984639167786
179873240,4812,vvcephei,2018-04-06T20:53:25Z,"yeah, i have my ide set on paranoid mode. i can disable this inspection if you don't want to see supressions like this. or i can inline the parameter value, which is what the inspection was complaining about.",-1,0.6633403897285461
179873711,4812,vvcephei,2018-04-06T20:55:39Z,"double-brace initialization is actually not great for a number of reasons. i've been terrraforming it whenever i encounter it, but for some reason i decided to suppress this one instead. i'll plan to remove the suppression and the double-brace initialization in the final draft.",0,0.5714933276176453
179873858,4812,vvcephei,2018-04-06T20:56:24Z,thanks!,1,0.9051083922386169
179885340,4812,vvcephei,2018-04-06T21:56:56Z,"during `thread.runonce(-1);`, it'll encounter an exception ""asdfasdfasdf"" as an integer and increment the metric.",0,0.9919983744621277
179885776,4812,vvcephei,2018-04-06T21:59:23Z,it was not. i've fixed it.,0,0.9768058061599731
179886374,4812,vvcephei,2018-04-06T22:03:30Z,fixed.,0,0.979083240032196
179886390,4812,vvcephei,2018-04-06T22:03:38Z,it was when i made it lazy. i've fixed it.,0,0.9571006298065186
179893704,4812,mjsax,2018-04-06T22:56:44Z,"i am fine with removing the overload that has a default and add info explicitly here. (to me, it's more about consistency---i immediately assume that this sense is different to the others, even if it's not if the code pattern is different).",0,0.9516897201538086
179893837,4812,mjsax,2018-04-06T22:58:03Z,"i personally would prefer getting rid of the annotation -- to me, annotations are noise in the code and distracting.",-1,0.5984540581703186
179893976,4812,mjsax,2018-04-06T22:59:10Z,for my own education: why? refactoring is fine with me.,0,0.6553550958633423
179929221,4812,mjsax,2018-04-07T22:12:01Z,why this change?,0,0.9617691040039062
179929312,4812,mjsax,2018-04-07T22:17:23Z,nit: do we need to `[]` around each value? `[]` is used for collections or list -- might be confusing to add them?,0,0.9800075888633728
179929318,4812,mjsax,2018-04-07T22:17:38Z,as above.,0,0.9878018498420715
179929326,4812,mjsax,2018-04-07T22:18:01Z,as above.,0,0.9878018498420715
179929377,4812,mjsax,2018-04-07T22:18:23Z,nit: remove space,0,0.845366895198822
179929389,4812,mjsax,2018-04-07T22:19:24Z,nit: indention,0,0.7825920581817627
179929538,4812,mjsax,2018-04-07T22:26:03Z,"nit: move `new file` to new line for consistent formatting (note, that `processorstatemanager.checkpoint_file_name)` is second parameter of `file` constructor.",0,0.9946650266647339
179929549,4812,mjsax,2018-04-07T22:26:46Z,as above.,0,0.9878018498420715
179929590,4812,mjsax,2018-04-07T22:28:52Z,did this slip? or did you leave it intentionally?,0,0.9690975546836853
179929609,4812,mjsax,2018-04-07T22:29:56Z,did this slip?,0,0.9809085130691528
179929657,4812,mjsax,2018-04-07T22:33:29Z,"adding this implies, that we have to maintain the same code twice. should we extract this into some internal method that we can call here to avoid code duplication? what about other thread-level metrics?",0,0.9808971881866455
179929685,4812,mjsax,2018-04-07T22:35:09Z,for my own education: what is this? (btw: can we remove `this` below?),0,0.9588800668716431
180160009,4812,bbejeck,2018-04-09T16:50:49Z,"nit: i realize this was pre-existing in a single line, but since there are several parameters, maybe put each param on its own line.",0,0.9685219526290894
180167095,4812,bbejeck,2018-04-09T17:16:08Z,"super nit: what about `asserttrue((double)metrics.metric(skippedratemetric).metricvalue() > 0.0);` however, i don't have a strong opinion in this one.",0,0.8270466327667236
180172747,4812,vvcephei,2018-04-09T17:35:53Z,it's a private method with an unused return value. making it void helps the reader to understand the code without having to trace through usages.,0,0.9812621474266052
180176820,4812,vvcephei,2018-04-09T17:50:26Z,"good question. i have developed the habit of delimiting variables in log messages, as it disambiguates the structure of the message for the reader. without delimiters, there are several edge cases that would make the log message difficult to read. for example, if the key were `""value""` and the value were `""""` with the old format, you get: [code block] whereas, if the key were `""""` and the value were `""value""`, you get [code block] the only difference between these strings is where the extra space is. with delimiters, you have: [code block] it's the kind of thing that saves people from #1 making a bad assumption about the nature of the problem and burning hours before they realize their mistake, or #2 being unable to clearly understand the error message and having to load it in a debugger just to understand what the values of the arguments actually are. it sounds like your concern is about the ambiguity of `[]` as delimiters, since they already indicate a list. can we keep delimiters but pick a different character? other paired delimiters are `<>` and `{}`, and `""""` and `''` also come to mind. wdyt?",1,0.792602002620697
180180359,4812,vvcephei,2018-04-09T18:02:43Z,"i've been mulling over the same thing, and that was part of what i was trying to achieve with my experiment before. i think i have a better solution now, so maybe you can take another look after my next update and see what you think.",0,0.9190527200698853
180183446,4812,vvcephei,2018-04-09T18:13:40Z,"that also works, but `assertnotequals` is a little nicer in that it'll print the actual value on failure, whereas `asserttrue` only tells you that it was `false` on failure. i suppose i could add a utility method `assertgreater` that prints the values on failure, but in this case, i'm really just making sure that the metric got moved. i don't care that much to assert what it got moved to, or i would override the time implementation and assert the exact expected value.",0,0.9355713725090027
180183779,4812,vvcephei,2018-04-09T18:14:53Z,"we can remove `this` below. the weakeraccess inspection tells you that it's possible to restrict the access scope of `cancel()`. i think this particular case was warning me that `cancel()` could be package-private instead of public. but the static analyzer can only look at the code in the project. we know that we do want the method to be public, so i added a supression for this inspection. an alternative would be to write black-box tests in a different package (just like real user tests would be), and the static analyser wouldn't warn us anymore, since it would have an example of a usage requiring public access.",0,0.9873418211936951
180195011,4812,mjsax,2018-04-09T18:54:07Z,"i personally thank, that having `=` (without `[]`) is good enough as the `=` makes it clear: [code block] thus, it's not ambiguous to me (i agree that having no delimiter at all would be bad). it's just that i like uniform formatting, and this would introduce a new style -- i am fine with change to this style, but we should agree on one style and rewrite code (on the side) if it does not fit the 'style guide'. \cc",1,0.9627256393432617
180196390,4812,mjsax,2018-04-09T18:59:05Z,"will do, after you pushed an update :)",1,0.9806820154190063
180238210,4812,guozhangwang,2018-04-09T21:34:54Z,"i'm do not feel very comfortable to define the metrics name in scattered places, because it means whenever we'll update the name we have to remember to update all the places (for this sensor the other place we declared it is [code block] so which line gets called first, it will create the sensor, while keeping the other just as an no-op. ), and that's why i liked 's proposal for wrapping the sensor names in the leveled metrics, and passing those metrics across different modules than re-declaring the sensors in different places. this makes me feel more urgent to do the refactoring of the metrics hierarchy.",1,0.9461379051208496
180239208,4812,guozhangwang,2018-04-09T21:39:14Z,"i tend to prefer `key=[value]`, but i do not have a scientific reason for that: i just feel it is more ""vivid"" :p",1,0.9747024774551392
180239876,4812,guozhangwang,2018-04-09T21:41:57Z,"again, if we could pass around the `threadmetrics` here, it will make the code more readable: we can make it very clear at which places we record some task metrics like `taskmetrics.sensora.record()` and where do we record thread-level metrics like `threadmetrics.skippedrecordssensor.record()`. but i think it is better to be left as a follow-up pr as this one is already pretty big.",0,0.9766868352890015
180240234,4812,guozhangwang,2018-04-09T21:43:20Z,nice improvement,1,0.9881332516670227
180243194,4812,vvcephei,2018-04-09T21:56:21Z,"yeah, i keep getting wrapped around the axle thinking about stuff like this. hopefully, i'll be able to deliver a reasonable implementation for this pr, and i'll continue to mull about a way to pass the right metric context around the code base.",-1,0.8249539732933044
180243791,4812,vvcephei,2018-04-09T21:59:20Z,"i'm about to push a commit to put the skipped-records sensor in particular in a common place, since it winds up getting accessed from so many different places in the code. i'm hoping that will be good enough for now, and we can seek an elegant enclosing-scope metrics implementation in the future.",0,0.8944465517997742
180246639,4812,vvcephei,2018-04-09T22:12:53Z,"i can dig the desire to have uniform style on log messages. i'll also point out that the logs are part of the public api, so we can't just go terraform them willy-nilly, but instead we'd have to change them only in scope of the relevant kips, which makes it difficult to change, or even establish, a log style. nevertheless, if we don't already have a clear style for streams logs, i'll advocate for some kind of enclosing delimiter on substitutions. i continue to agree that square brackets are confusing w.r.t. common `list#tostring()` formats, so i think we should agree on a different enclosing delimiter. i agree that `=` is better than nothing, but it's still ambiguous when the substitution is 0 or more whitespace characters, while `[]` vs `[ ]` gives you more of a clue. no choice here is going to be perfect, but my experience is that this format saves enough debugging time to be worth the visual noise.",0,0.9325969815254211
180576030,4812,guozhangwang,2018-04-10T21:39:40Z,"what's the purpose of keep track of the metric names? if it is for preventing double-registering, i think relying on maintaining the metrics name inside the sensor would not always work, since multiple sensors would be added into the `metrics` registry, and we still cannot prevent different sensors trying to register the same metrics.",0,0.9736413955688477
180576708,4812,guozhangwang,2018-04-10T21:42:38Z,we do not need the non-arg constructors since it will be defined by default.,0,0.9915090799331665
180577126,4812,guozhangwang,2018-04-10T21:44:29Z,no callers seem to provide any non-empty `tags`?,0,0.9897450804710388
180577282,4812,guozhangwang,2018-04-10T21:45:10Z,ditto here.,0,0.9378204345703125
180577454,4812,guozhangwang,2018-04-10T21:45:56Z,"if we always create the skipped record sensor upon creating the thread, then we should always get the sensor right? if that case, should we simply throw if the `getsensor` returns null?",0,0.995144784450531
180578491,4812,guozhangwang,2018-04-10T21:50:26Z,"this is a meta comment: i think we have seen two approaches here: 1. pass along the metrics objects across different modules (in some classes, we will pass multiple metrics objects for different levels, like threadmetrics and taskmetrics) in order to record their sensors. 2. in the current pr: only pass alone the metrics registry (i.e. the `metrics` object) along different modules, but standardize the sensor name construction, and get the sensor by its raw name directly whenever necessary to record the sensor. i am slightly in favor of the second one since we could pass long fewer parameters, i.e. only a single `metrics` object which can be accessed 1) from processorcontext, 2) in multiple internal classes.",0,0.9753511548042297
180578769,4812,guozhangwang,2018-04-10T21:51:35Z,this is a detailed comment: what's the rantionale of naming it `commonstreamsmetrics`? is it for thread-level metrics only? i.e. should we just move this static function into `threadmetrics`?,0,0.985406756401062
180607694,4812,mjsax,2018-04-11T00:47:33Z,"we never discussed this explicitly; it's just a matter of fact that we use `key=value` so far from what i can remember. the question is, how much we gain if we start to rewrite to a different format and how much work it it. with regard to ambiguity: you can always construct an (academic?) example for which any formatting strategy ""break"" and is ambiguous... if we agree on `key=[value]` i am fine with it. still not sure, if we gain much (but if you think we do, it's fine with me to change)",0,0.877066433429718
180815261,4812,vvcephei,2018-04-11T16:20:42Z,"i have pulled this change into a separate pr: [a link] the intent is to make it a no-op if you add the same metric to the same sensor twice, as opposed to the current behavior, in which the `registry.registermetric(metric)` throws an exception if the metric is already registered. with this change, you'll still get an exception if the metric is already registered in another sensor, but if it's already in the same sensor, you just get a no-op success.",0,0.9915243983268738
180815535,4812,vvcephei,2018-04-11T16:21:38Z,"this privatizes the constructor, guaranteeing that the class cannot be instantiated. it's a way of enforcing that the class be used only for its static members.",0,0.9653780460357666
180815880,4812,vvcephei,2018-04-11T16:22:44Z,"it's laying the groundwork for a future change in callers can compose thread-level tags, task-level tags, etc.",0,0.9866048693656921
180816071,4812,vvcephei,2018-04-11T16:23:20Z,"to do this properly, though, the class should also be final. i'll make that change.",0,0.9902361035346985
180816181,4812,vvcephei,2018-04-11T16:23:38Z,same rationale.,0,0.977933943271637
180817574,4812,vvcephei,2018-04-11T16:28:17Z,"this method is used to idempotently create or retrieve the sensor. in other words, the mechanism by which we create the sensor when we create the thread is that it calls this method, and the sensor is null, so it creates it. you're correct in that if we do that, then all other usages will just return the existing sensor. i'm not sure i see the value in separating creation from retrieval so that we can throw an exception if you retrieve it without creating it first.",0,0.9650156497955322
180824861,4812,vvcephei,2018-04-11T16:51:39Z,"yeah, i'm still undecided on whether approach 1 or 2 is better. but i did decide that i don't want to make a call on it in this pr. if you'd like me to resolve this sooner rather than later, i can follow up immediately with another pr to reorganize the metrics. the reason i pulled skipped-records out into a commonstreamsmetrics class is that that metric is common across all components in streams. it's accessed by both our framework-level code and also by the user-space dsl-provided processors. thus, it needs to live in a spot where all those components have visibility on it. there's a distinction between metrics that are aggregated at the thread level and metrics that belong to `streamthread`. it'll be difficult to really do a good job in this pr with that distinction, though, without refactoring the whole metrics hierarchy. since we're already over 2,000 loc, i'd really like to move such a refactoring to another pr. what i have done in this pr is as minimal as i can manage to expose the skipped-records sensor to our processors.",0,0.8367538452148438
180866308,4812,bbejeck,2018-04-11T19:09:05Z,"i also prefer `key=[value]`, but can't say it's for any specific reason other than personal preference.",0,0.9738091230392456
180870195,4812,bbejeck,2018-04-11T19:23:52Z,is this line intentional?,0,0.9578090906143188
180870791,4812,bbejeck,2018-04-11T19:26:16Z,"the `hasitem` matcher is new to me, nice one!",1,0.9953085780143738
180876468,4812,bbejeck,2018-04-11T19:47:38Z,"do we need a separate class for this? we could add the `getmetricbyname` method to `streamstestutils` instead, additionally, it doesn't access anything package private so it should be fine to make the method public",0,0.9932647943496704
180878303,4812,bbejeck,2018-04-11T19:54:39Z,"meant to say this before, nice addition!",1,0.9926674962043762
180930916,4812,vvcephei,2018-04-11T23:50:42Z,oops. i put it there when i needed a place for a breakpoint. sorry!,-1,0.9935739636421204
180931250,4812,vvcephei,2018-04-11T23:53:06Z,"thanks! it's predicated on us using log4j as the implementation for slf4j in the unit tests, so if that changes, we'll have to put in a different log appender. but that seems unlikely, and it's handy to have this in the mean time.",1,0.9523523449897766
180932520,4812,vvcephei,2018-04-12T00:01:29Z,"i can move it to streamtestutils if you like. i made `getmetricbyname` package-private to prevent other code from calling it, since it's intended for these tests only. making it public would open this method up to be called beyond the intended scope. i'd rather defer that until we have a use case we think calls for broadening the scope.",0,0.9886693358421326
181250474,4812,guozhangwang,2018-04-12T23:26:24Z,"thanks for the explanation, that makes sense.",0,0.5711849927902222
181250828,4812,guozhangwang,2018-04-12T23:28:41Z,"i had another meta question while discussing offline, and i'll leave it here for discussion: since different meters belong to the different metrics levels, should we move these static functions to the corresponding `xxmetrics` instead? i'm thinking about that since we have some meters that exist in multiple levels, like commit rate. in the future if we move them all to this class then we need to get one function for each level as their tags naming conventions are different, and hence it is not really `common` streams metrics.",0,0.9527227878570557
181251041,4812,guozhangwang,2018-04-12T23:30:03Z,similar to my other comment on `commonstreamsmetrics`: could we move these static functions to the corresponding level metrics class?,0,0.9949829578399658
181252004,4812,guozhangwang,2018-04-12T23:36:39Z,"i'd suggest in the future try to only piggy-back different changes into the same pr if we think they are either correlated or if they are really trivial. having a single pr mingled with multiple changes has several drawbacks: 1. it makes git history a bit harder to trace: think, ""git blame"" would be tricker to reason. 2. it tends to generate bigger prs than necessary, making reviewer less willing to start working on them :p 3. if multiple rounds of reviews are needed, even requiring major code refactoring, it will surprisingly introduce regressions during those iterations as by-products of the multiple changes.",0,0.6752909421920776
181252540,4812,guozhangwang,2018-04-12T23:40:36Z,i'm not sure why we need to pass around `streamsmetricsimpl` from streamthread to everywhere else now?,0,0.8110589981079102
181410527,4812,vvcephei,2018-04-13T14:43:21Z,"previously, we passed around the interface only to cast it back to `streamsmetricsimpl` in line 80 of this file. all i did was make taskmetrics declare that it really does want a `streamsmetricsimpl` instead of a `streamsmetrics` explicitly. if we're going to cast it anyway, why not just use the type system?",0,0.9919912219047546
181412307,4812,vvcephei,2018-04-13T14:49:06Z,"i thought it would be nice if the metrics naming conventions were all in one place, to help us maintain consistency. right now, we have one (internal) naming convention enforced via our (public) metrics api: `streamsmetrics`, but we also have a bunch of metrics with no defined naming convention declared, e.g., in `streamsmetricsthreadimpl`. i think it'll be simpler for people to use the metrics if we maintain consistency throughout the whole streams code-base, and it'll be simpler to maintain consistency if we keep all the naming conventions in one file.",0,0.9722331166267395
181424139,4812,vvcephei,2018-04-13T15:25:18Z,"there are two different concepts of belonging in play here. 1. grouping: a metric ""belongs"" to the thread level if it's aggregated at that level 2. ownership: a metric ""belongs"" to the thread level if streamthread needs a reference to it. grouping and ownership are orthogonal here. there are several metrics that are aggregated at the thread level and are also owned by streamthread, like the committimesensor. grouping is easy to determine; all you have to do is look at the metric name. to tell that committimesensor is owned by streamthread, you can trace the references to the sensor. it's never passed outside of streamthread, so it's owned by streamthread. other metrics are still grouped by thread but owned by other classes, such as the taskcreatedsensor. all of streamthread, abstracttaskcreator, taskcreator, and standbytaskcreator have references to this metric, so they all share the ownership. now that i'm looking at it, streamthread never uses the reference, so it could be owned only by abstracttaskcreator and its children. finally, we get to the skippedrecordssensor. this metric is still grouped by thread, but ownership is shared among 14 classes. two of them are framework classes (globalstreamthread and streamthread), and 12 of them are user-space processor classes. since ownership for skippedrecordssensor is so dispersed, i decided to just make its ownership global, aka common. anything in the entire streams codebase can get a reference to the skippedrecordssensor. i wouldn't move all the metrics into the global ownership space just because i moved one, and i wouldn't give streamthread a reference to a metric just because that metric happens to be aggregated by thread. am i making sense?",0,0.9827479720115662
182273476,4812,guozhangwang,2018-04-17T23:43:48Z,"i understand the separation of ownerships of metrics, my question is: right now the `skippedrecordsmeter` assumes this metric is grouped at the thread-level, and hence the second parameter is a `threadname`. what if in the future we add a per-task level `skippedrecordsmeter(final metrics, final taskid)`? would that be put in this `commonstreamsmetrics` as well? practically speaking either is fine, and i think i was originally leaning towards not having a `commonstreamsmetrics` conceptually since that for each meter, it is going to be aggregated at a specific layer anyways. but if people think that it is better of having a `commonstreamsmetrics` where we put these metrics so that all dependent classes would just depend on `o.a.k.streams.processor.internal.metrics`, i'm fine with it as well.",0,0.9619503021240234
182274054,4812,guozhangwang,2018-04-17T23:47:54Z,ditto.,0,0.6705162525177002
182274130,4812,guozhangwang,2018-04-17T23:48:31Z,"since we will have a different kstreamwindowreduceprocessor for each topology, each task, each thread, the thread.currentthread() will always be the same; it is okay to get the meter at the constructor and cache it, than trying to search for it in the registry each time. ditto below.",0,0.9371857643127441
182274177,4812,guozhangwang,2018-04-17T23:48:46Z,ditto.,0,0.6705162525177002
182274189,4812,guozhangwang,2018-04-17T23:48:53Z,ditto.,0,0.6705162525177002
182274204,4812,guozhangwang,2018-04-17T23:49:00Z,ditto.,0,0.6705162525177002
182274440,4812,guozhangwang,2018-04-17T23:50:36Z,ditto.,0,0.6705162525177002
182274531,4812,guozhangwang,2018-04-17T23:51:12Z,ditto.,0,0.6705162525177002
182274558,4812,guozhangwang,2018-04-17T23:51:21Z,ditto.,0,0.6705162525177002
182275004,4812,guozhangwang,2018-04-17T23:54:24Z,ditto.,0,0.6705162525177002
182275021,4812,guozhangwang,2018-04-17T23:54:31Z,ditto.,0,0.6705162525177002
182275061,4812,guozhangwang,2018-04-17T23:54:41Z,ditto.,0,0.6705162525177002
182275088,4812,guozhangwang,2018-04-17T23:54:53Z,ditto.,0,0.6705162525177002
182275337,4812,guozhangwang,2018-04-17T23:56:46Z,do we need to pass the sensor all the way down here? could we fetch it from the `commonstreamsmetrics` directly as well? note that each thread will create its own `recorddeserializer` objects that are exclusively owned by the thread itself.,0,0.9948704242706299
182275382,4812,guozhangwang,2018-04-17T23:57:02Z,please see my comment in `recorddeserializer`,0,0.983910322189331
182275534,4812,guozhangwang,2018-04-17T23:58:07Z,this import is not needed?,0,0.9682802557945251
182275652,4812,guozhangwang,2018-04-17T23:58:50Z,"similar as above, do we still need to pass this sensor along, than getting it from `commonstreamsmetrics` directly?",0,0.9952995777130127
182275731,4812,guozhangwang,2018-04-17T23:59:27Z,as above in `recorddeserializer`.,0,0.9917274713516235
182275826,4812,guozhangwang,2018-04-18T00:00:09Z,ah right. thanks.,1,0.9838197827339172
182275969,4812,guozhangwang,2018-04-18T00:01:17Z,"same as above, could we just get it from `commonstreamsmetrics` now?",0,0.9954739212989807
182276400,4812,guozhangwang,2018-04-18T00:04:31Z,could you point to me where do we remove this sensor upon shutting down now?,0,0.9874488711357117
182276649,4812,guozhangwang,2018-04-18T00:06:46Z,why passing `threadclientid` twice?,0,0.9837484359741211
182277627,4812,guozhangwang,2018-04-18T00:14:01Z,actually i've been thinking .. could we move the construction of the `taskmanager` and its `taskcreators` into the constructor of `streamthread` directly from `create` call? then we can get the threadname from `currentthread.name()` directly and do not need to pass this parameter around any more.,0,0.9879457950592041
182278148,4812,guozhangwang,2018-04-18T00:18:07Z,"for test util classes, they are usually put in `org.apache.kafka.test` package. this allows a larger scope of utilization by non-streams unit tests.",0,0.9949653744697571
182278220,4812,guozhangwang,2018-04-18T00:18:37Z,and you can put them in `streams.test.o.a.k.test` folder.,0,0.9914945363998413
182278443,4812,guozhangwang,2018-04-18T00:20:20Z,this looks like a general test util function than a streams-specific test util function. how about moving it to `org.apache.kafka.test.testutils`?,0,0.9939018487930298
182826571,4812,vvcephei,2018-04-19T17:34:08Z,"using the interface is really only useful in our public processorcontext interface. using the streamsmetrics interface in our internals just forces us to cast it back to streamsmetricsimpl all over the place. i've changed it to s.m.i. here and elsewhere to cut down on the casting. the only things that should need to cast now are components that get the metrics via processorcontext, and they should always perform that cast as early as possible to prevent post-initialization runtime exceptions.",0,0.9862804412841797
182827178,4812,vvcephei,2018-04-19T17:36:18Z,override to refine the type from streammetrics to streammetricsimpl in support of internal usages.,0,0.992732584476471
182829844,4812,vvcephei,2018-04-19T17:45:17Z,"it's used by the nodemetrics implementation (it might have been unused when you made this comment, though)",0,0.9938971400260925
182830330,4812,vvcephei,2018-04-19T17:46:54Z,"i've removed commonstreamsmetrics, so we need either to pass the sensor or the whole streamsmetricsimpl. the sensor is smaller scope, so i just did the sensor for now.",0,0.9915796518325806
182830606,4812,vvcephei,2018-04-19T17:47:51Z,the same rationale from `recordcollectorimpl` applies.,0,0.9939213991165161
182834003,4812,vvcephei,2018-04-19T17:58:48Z,"this is an internal class, and this javadoc doesn't say anything that the method signature doesn't say. i added a new constructor and changed the existing one, so i just removed the doc rather than updating it.",0,0.9748850464820862
182834401,4812,vvcephei,2018-04-19T18:00:09Z,"this existed only so a test could override it. instead, i added a constructor arg for the test to pass and removed this method.",0,0.9921919703483582
182837476,4812,vvcephei,2018-04-19T18:10:55Z,"i refactored these to flatten the metric definition, since it was super hard to figure out what metrics were actually being created. maybe you can forgive me for this because i actually found a bug: the description of the total metrics say that it counts the number of calls, but it previously summed the recorded values. (was via createmeter -> new meter -> new total)",-1,0.6325393915176392
182840375,4812,vvcephei,2018-04-19T18:20:40Z,"i'd like to add tasklevel names and tags, but it doesn't work with the current way most of the corresponding sensors get created. ultimately, i'd like to flatten all the metrics definitions like i did with streamthreadmetricsimpl, which would make it possible to define the task and node level conventions here as well. but i don't want to do that in this pr.",0,0.9502323269844055
182840948,4812,vvcephei,2018-04-19T18:22:39Z,"defining and providing skippedrecordssensor here now, since it's now needed in contexts where the implementation is not a streamthreadmetricsimpl.",0,0.9944209456443787
182843117,4812,vvcephei,2018-04-19T18:30:00Z,"similar to the metrics in streamthread, by getting rid of the meter and flattening these metrics, i realized that the total computation was incorrectly a total rather than a count.",0,0.984307587146759
182843558,4812,vvcephei,2018-04-19T18:31:36Z,these metrics never get removed. is that ok?,0,0.9304730296134949
182845636,4812,vvcephei,2018-04-19T18:38:54Z,"this is required per the docs, but we previously only added it in production code paths. now we add it in all code paths.",0,0.9939712882041931
182846028,4812,vvcephei,2018-04-19T18:40:13Z,"this is required per the docs, but we previously only added it in production code paths. now we add it in all code paths.",0,0.9939712882041931
182846606,4812,vvcephei,2018-04-19T18:42:13Z,"the skipped records metrics are now always present. rather than updating the hard-coded value, i did this to make the test less brittle.",0,0.9880437254905701
182847809,4812,vvcephei,2018-04-19T18:46:25Z,"i can move them there. the reason i put them here was to restrict the scope in which log4j was an allowed import (i had to add an exception). co-locating this class in any other package will allow other code to accidently depend on log4j when it should depend on slf4j instead. i was also uncertain about whether it would be a good idea to expose this class for general use in kafka tests... wdyt? if you're not concerned about supporting this class for the whole project, maybe `o.a.k.test.log4jappender` package would be the best of both worlds?",0,0.8968712091445923
182849325,4812,vvcephei,2018-04-19T18:51:39Z,i replaced the override-with-capture strategy in this test with just a regular streamsmetrics and verifying the invocation by checking that the total metric is == 1.,0,0.9930320978164673
182850930,4812,vvcephei,2018-04-19T18:57:02Z,"""virtual"" just in case people go looking for the actual thread in the thread dump. i also thought about using `thead.currentthread()`, but it wouldn't necessarily be the same thread when the tests run.",0,0.986965537071228
182851149,4812,vvcephei,2018-04-19T18:57:37Z,"same thinking regarding ""virtual""",0,0.9733402132987976
182914835,4812,guozhangwang,2018-04-19T23:45:56Z,"ah i see, overlooked `log4j` dependency; let's keep it as is then.",0,0.9754208922386169
182915655,4812,guozhangwang,2018-04-19T23:51:21Z,why this need to be public now?,0,0.9795567989349365
182915744,4812,guozhangwang,2018-04-19T23:52:01Z,"good point, let's add a todo marker and remove them in a follow-up pr: so we do not drag too long on this one.",0,0.5328900218009949
182916297,4812,guozhangwang,2018-04-19T23:56:06Z,sounds good!,1,0.9947521686553955
182916817,4812,guozhangwang,2018-04-20T00:00:03Z,"i guess my previous comment was a bit misleading :p actually i'm not against the `commonstreamsmetrics` and `threadmetricsconventions` classes, but i think we could have one such class for each different layer than having a `common` class, for the reason i mentioned before. but since you have removed it i'm also fine with passing along the sensors as well. we can consider which one is better in the near future and if we can do another code refactoring, but let's not block on this pr for too long.",-1,0.63920658826828
182917077,4812,guozhangwang,2018-04-20T00:02:10Z,sounds good!,1,0.9947521686553955
182917552,4812,guozhangwang,2018-04-20T00:06:12Z,good call!,1,0.9947137236595154
182917825,4812,guozhangwang,2018-04-20T00:08:20Z,cool.,1,0.9499436020851135
182918255,4812,guozhangwang,2018-04-20T00:11:55Z,"hmm.. why we create the sensor in `streamsmetricsmpl` while removing it in `streamsmetricsthreadimpl`? it seems a bit inconsistency.. could we still create in `streamsmetricsthreadimpl`, and let `streamsmetricsimpl` to get a hold of the sensor object assuming it is already created then (i.e. set `sensor == null` in constructor, and in `skippedrecordssensor(): if (sensor == null) try get it from the metrics`)?",0,0.8710618019104004
182918502,4812,guozhangwang,2018-04-20T00:14:29Z,not sure i understand this comment: it was indeed defined as a `count()` before as well right?,0,0.9568743109703064
183065396,4812,vvcephei,2018-04-20T14:18:25Z,"no, it was previously: [code block] but the `count` there is only used for updating the rate. here's the metric constructor: [code block] you can see that it's using `total` for the ""total"" metric, which i guess makes sense given the parameter name. but according to the description of our ""total"" metric, what we really wanted to do was keep a count of occurrences, which should be a `count` stat.",0,0.9905546307563782
183075990,4812,vvcephei,2018-04-20T14:52:56Z,"ok, when i took another look, i found that `hitratiosensor` does get removed, but its parent doesn't. also neither sensors have scoped names, so every `record()` will actually update *all* hit ratio metrics for *all* caches. that seems like a bigger deal, so i've already prepared a follow-up pr. i'll send it next once this one is merged.",0,0.9615890979766846
183081167,4812,vvcephei,2018-04-20T15:08:22Z,"because i moved streamsmetricsimpl to the `...internal.metrics` package, but i took a look, and it was only used (properly) by `processornode`. `streamtask` also used it, but only by specifically wrapping the operation in a `runnable` and passing it to the metric to immediately be run. i've added [a link] to simplify `streamtask`'s usage to not need this method, and move the method to `processornode`.",0,0.9827373623847961
183091285,4812,vvcephei,2018-04-20T15:40:35Z,"i tried that, but it wound up making things messier than i expected (because there are other callers to streamsmetricsimpl, and because it makes the ownership of this sensor ambiguous). instead, i added [a link] which gives smi the ability to remove its own sensors, and then i called to it from the two places (streamthread and globalstreamthread) that actually need to unload metrics when they shut down. wdyt?",0,0.5361908078193665
183114250,4812,guozhangwang,2018-04-20T17:09:29Z,"i see. that makes sense. i think it was not introducing any issue only because we only call that `sensor.record()` not `sensor.record(n)` so `count` and `total` are actually the same: `record()` is the same as `record(1)`, but i agree that it should really be `count`, to avoid any potential bugs.",0,0.9475797414779663
183114732,4812,bbejeck,2018-04-20T17:11:29Z,nit: just thinking if this change is necessary as `nodemetrics` is an internal class so a cast here from `processorcontext` to `internalprocessorcontext` should not be a big deal and keeps `processornode` more generic. edit: nm read a comment below about using type system and i agree.,0,0.9737480878829956
183116528,4812,bbejeck,2018-04-20T17:18:41Z,why remove this?,0,0.9619809985160828
183130635,4812,guozhangwang,2018-04-20T18:13:14Z,"i did not completely get your explanation re: `because there are other callers to streamsmetricsimpl, and because it makes the ownership of this sensor ambiguous`. could you elaborate a bit more?",0,0.9302666783332825
183161064,4812,bbejeck,2018-04-20T20:27:06Z,nit: `shouldlogandmeteronskippedrecords` -> `shouldlogandmeteronskippedrecordswithnullvalue` ?,0,0.9947156310081482
183164652,4812,bbejeck,2018-04-20T20:43:09Z,line 503 the javadoc should change as the constructor for `streamsmetricsimpl` only takes `metrics` and a `string` parameter.,0,0.9941061735153198
183166451,4812,bbejeck,2018-04-20T20:51:34Z,maybe consider replacing `stack` with `deque` as `stack` is synchronized and `ownedsensors` only adds in the constructor and removes values in `synchronized` block already.,0,0.995908260345459
183182512,4812,vvcephei,2018-04-20T22:29:21Z,"this is just used in one spot. it's easier to read the code if the log message is located at the spot where it gets logged rather than at the top of the file. in earlier versions of java, code like this was beneficial for performance, since the string is an object that can just get allocated and instantiated once statically, rather than dynamically on every invocation. but nowadays, the compiler and jit compiler are smarter than that, so there really no benefit to coding this way, and you still pay the comprehensibility cost of having to follow the indirection. i didn't want to make it a ""thing"", though, so i only inlined the message i needed to change.",0,0.837428629398346
183182785,4812,vvcephei,2018-04-20T22:31:55Z,"ah, good eye. i might just ditch the javadoc, since it's an internal class and its function is pretty obvious.",1,0.9875178933143616
183182905,4812,vvcephei,2018-04-20T22:33:10Z,"ooh, good call. i will do that and probably avoid using stack again.",1,0.7938079833984375
183185297,4812,vvcephei,2018-04-20T22:54:13Z,"sorry; i misread your suggestion. i thought you wanted the streamsmetricsimpl to take the sensor as a constructor argument. aside from the streamthread (via streamthreadmetricsimpl), several other classes directly invoke the streamsmetricsimpl constructor and thus obtain a streamsmetricsimpl that is not a streamthreadmetricsimpl. namely, globalstreamthread, mockprocessorcontext, and topologytestdriver. when the code paths downstream of these points need to record a skipped record, they will get a null sensor back. it wouldn't be possible to get it from the metrics registry at that point, though, because the skipped records sensor is scoped by thread (or ""virtual"" thread for the test-utils), and the sensor would never have been created for globalstreamthread, mockprocessorcontext, or topologytestdriver. so the only way to get it at that point is to have either the caller of the smi constructor or the smi itself create the sensor (either at construction or at call-time). the previous implementation with the public static getter was effectively saying that the one who wants it in a particular context first creates it, but it's problematic because no-one owns it. and indeed, in my implementation, the sensor never got destroyed. in practice i think it's not a huge deal because i'm sure it's rare for a streams app to shut down and start up again with the same metrics registry, and i think the threads live as long as the app. but still, we have this model of unloading metrics when they're out of scope, and i think it's a good one. so that brings us to the current implementation. in the current implementation, the skipped records metric is clearly owned by the streamsmetricsimpl, which it may as well be, since that is the smallest scope in which it's needed. it's the first metric to be owned by smi, so i had to create a removeall method, and make sure it's invoked in the right places. but that seems appropriate; every other scope that owns metrics has such a method.",-1,0.9893711805343628
329311213,7378,jukkakarvanen,2019-09-28T13:57:09Z,this is still using deprecated pipeinput because there is partition verification. can we drop here partition verification which is null here?,0,0.987973690032959
329311302,7378,jukkakarvanen,2019-09-28T14:00:55Z,this is still using deprecated pipeinput because there is partition verification. can we skip partition assertion here or do we need some other way to get producerrecord?,0,0.9849596619606018
330105303,7378,vvcephei,2019-10-01T14:55:39Z,"yes, it seems to be not what this test is checking on. i think we can drop it here.",0,0.8603465557098389
330108688,7378,vvcephei,2019-10-01T15:01:12Z,"it seems like the purpose of this test class is to verify the test driver. since the partition is effectively not part of the test driver's (non-deprecated) api, i think we can drop it. technically, as long as the deprecated interface is still in the public api, we should still exercise it, but i think in this case it's extremely unlikely we would break the partition field in the future, and it's probably not that risky anyway. i'd vote just to skip the partition assertion here.",0,0.9711092710494995
330248099,7378,jukkakarvanen,2019-10-01T20:01:43Z,moved to use testoutputtopic and partition assertion removed.,0,0.9929874539375305
330248275,7378,jukkakarvanen,2019-10-01T20:02:10Z,moved to use testoutputtopic and partition assertion removed.,0,0.9929874539375305
330345901,7378,vvcephei,2019-10-02T01:55:47Z,"note: the unused suppression indicates that we're missing test coverage. if we want to add test coverage, we can at the same time address the weakeraccess warning by putting the test in a different package than this class. i.e., a true test of a class's public api should be located outside that class's package, so it wouldn't have access to package-private members.",0,0.9916336536407471
330346143,7378,vvcephei,2019-10-02T01:57:20Z,"it might be a good idea to note that this only advances the _stream_ time, not the wall-clock time, and therefore doesn't trigger punctuations.",0,0.9869861006736755
330346457,7378,vvcephei,2019-10-02T01:59:28Z,"would it be handy to also print out the other constructor argument fields here? (serializers in particular, not sure if the times are that interesting)",0,0.981930673122406
330346561,7378,vvcephei,2019-10-02T02:00:05Z,should we also require non-null deserializers?,0,0.9936904907226562
330347517,7378,vvcephei,2019-10-02T02:07:04Z,"i'm curious why these suppressions were necessary. i'd have thought that the package-private members would all have been here because they were needed by the i/o topic classes. is it because idea thinks that protected is ""stronger"" than package-private?",0,0.7730462551116943
330347991,7378,vvcephei,2019-10-02T02:10:28Z,"you should double-check, but i think java will automatically do this in string concatenation. (it was news to me when i learned it a couple of months back)",0,0.9458267092704773
330348273,7378,vvcephei,2019-10-02T02:12:15Z,probably should use a (slf4j) logger instead of stdout here.,0,0.9938010573387146
330348480,7378,vvcephei,2019-10-02T02:13:29Z,these tests are beautiful,1,0.9950686693191528
330348611,7378,vvcephei,2019-10-02T02:14:17Z,there seems to be a lot of overlap between these and the input tests. could they just be one test class that covers both?,0,0.9822745323181152
330348785,7378,vvcephei,2019-10-02T02:15:25Z,[code block] thanks for keeping the test coverage for deprecated methods.,0,0.7800313234329224
330369097,7378,jukkakarvanen,2019-10-02T04:37:38Z,suppresswarnings removed and comment clarified,0,0.9868139028549194
330369142,7378,jukkakarvanen,2019-10-02T04:37:54Z,added,0,0.9267084002494812
330369166,7378,jukkakarvanen,2019-10-02T04:38:07Z,added,0,0.9267084002494812
330369686,7378,jukkakarvanen,2019-10-02T04:42:09Z,not sure the reason.,-1,0.5462582111358643
330369748,7378,jukkakarvanen,2019-10-02T04:42:38Z,replaced with another style tostring,0,0.9863762259483337
330369769,7378,jukkakarvanen,2019-10-02T04:42:49Z,dobe,0,0.9220252633094788
330369794,7378,jukkakarvanen,2019-10-02T04:43:02Z,thanks,0,0.5400217771530151
330370023,7378,jukkakarvanen,2019-10-02T04:44:51Z,merged,0,0.9814774394035339
330370105,7378,jukkakarvanen,2019-10-02T04:45:29Z,typo fixed,0,0.9734578132629395
331089257,7378,bbejeck,2019-10-03T14:59:10Z,"nit: i **_think_** that streams convention now is to mark methods as `` now vs. using ``. my reasoning for this is that these test methods will go away once the deprecated method under test is removed. this applies here and other deprecated tests below. however, this is a minor point. \cc",1,0.6114031076431274
331091087,7378,bbejeck,2019-10-03T15:02:10Z,super nit: `deprecatd` -> `deprecated` here and below,0,0.9768004417419434
331099773,7378,bbejeck,2019-10-03T15:18:38Z,nit: `configure topic` -> `configure the topic`,0,0.9935122132301331
331122381,7378,bbejeck,2019-10-03T16:02:51Z,why did we eliminate the partition check in the `assertnextoutputrecord` method?,0,0.9951457381248474
331124616,7378,bbejeck,2019-10-03T16:07:47Z,nit: `you need to have own testinputtopic object` -> `you need a testinputtopic object`,0,0.9907888770103455
331125926,7378,bbejeck,2019-10-03T16:10:37Z,as above,0,0.9391705989837646
331126553,7378,bbejeck,2019-10-03T16:12:02Z,nit: `send` -> `sent`,0,0.9925010800361633
331131776,7378,bbejeck,2019-10-03T16:23:46Z,"do we still need this comment? seems to me the other topic is expecting a `string` as well, but i could be missing something.",0,0.9766031503677368
331134784,7378,bbejeck,2019-10-03T16:30:39Z,"a minor point, but isn't this supposed to swap the key and value on output?",0,0.9727636575698853
331189754,7378,vvcephei,2019-10-03T18:33:18Z,"ah, yes, good catch, . adding the deprecation annotation will also satisfy the compiler, and it is indeed better. as you say, it documents that this method will also be removed when the other one is removed. it's not such a concern for a test, but the other big benefit is that it prevents ""deprecation laundering"": suppressing would make it ok for another method to call this one, whereas deprecating this method would also notify all callers that _this_ method is using deprecated functionality.",1,0.5081677436828613
331191034,7378,vvcephei,2019-10-03T18:36:17Z,"partitions are not part of the `testrecord` api in the kip, so it's not possible to make assertions on it in the new api. we can add the field later on if requested. i don't remember offhand why we didn't include it; maybe something to do with the symmetry of the api.",0,0.9898500442504883
331212689,7378,jukkakarvanen,2019-10-03T19:27:54Z,"ok, modified",0,0.9617083668708801
331212945,7378,jukkakarvanen,2019-10-03T19:28:27Z,fixed,0,0.9281549453735352
331214169,7378,jukkakarvanen,2019-10-03T19:31:26Z,added,0,0.9267084002494812
331215421,7378,jukkakarvanen,2019-10-03T19:34:39Z,fixed,0,0.9281549453735352
331215484,7378,jukkakarvanen,2019-10-03T19:34:49Z,fixed,0,0.9281549453735352
331216194,7378,jukkakarvanen,2019-10-03T19:36:24Z,removed,0,0.9801433682441711
331225577,7378,jukkakarvanen,2019-10-03T20:00:01Z,there are two stream. this is using this: builder.stream(input_topic).to(output_topic); output_topic_map is where values are swapped,0,0.9927185773849487
331226741,7378,jukkakarvanen,2019-10-03T20:02:58Z,fixed,0,0.9281549453735352
331233340,7378,jukkakarvanen,2019-10-03T20:19:25Z,"i removed all unnecessary field from testrecord compared to producerrecord and consumerrecord to keep it simple. this way we can utilize standard assertions and do not need to ignore the partition and use outputverifier kind of contructions. i don't see many use cases in normal stream application verification where partion is needed as we see here where this is only test class checking partition. if there are need to verify partition, i would add for example extra method readproducerrecord and use deprecated method until this is possible added if there is need for it.",0,0.990451455116272
331344364,7378,mjsax,2019-10-04T05:22:30Z,nit: `inputtopic` -> `rightinputtopic`,0,0.9932221174240112
331344534,7378,mjsax,2019-10-04T05:23:36Z,"why do we need to pass `null` as third parameter? saw this in some other tests, too.",0,0.991664707660675
331344660,7378,mjsax,2019-10-04T05:24:33Z,nit: `inputtopicright`,0,0.992918074131012
331345200,7378,mjsax,2019-10-04T05:27:59Z,nit: add `asserttrue(outputtopic2.isempty());` (as done in the original test code),0,0.9951730370521545
331345336,7378,mjsax,2019-10-04T05:28:48Z,as above,0,0.9391705989837646
331345361,7378,mjsax,2019-10-04T05:28:57Z,as above,0,0.9391705989837646
331346249,7378,mjsax,2019-10-04T05:35:02Z,nit: `final instant initialwallclocktime = instant.ofepochmilli(0)`,0,0.9934358596801758
331346966,7378,mjsax,2019-10-04T05:39:36Z,nit: [code block],0,0.9847351312637329
331347564,7378,mjsax,2019-10-04T05:43:28Z,nit: `create [a new instance via]`,0,0.9929423332214355
331347785,7378,mjsax,2019-10-04T05:44:37Z,nit: `message` -> `record` nit: `{ keyvalue} pairs.` (not add `.` at the end.,0,0.9920503497123718
331347943,7378,mjsax,2019-10-04T05:45:33Z,"nit: `if you have multiple source topics, you need to create a { testinputtopic} for each.`",0,0.9869300127029419
331348093,7378,mjsax,2019-10-04T05:46:36Z,`kafka` -> `record` (same next line for value),0,0.9908493757247925
331348378,7378,mjsax,2019-10-04T05:48:14Z,nit: `messages` -> `records`,0,0.9906312823295593
331348642,7378,mjsax,2019-10-04T05:49:54Z,"we can omit javadocs for non-public methods -- similar below -- wondering if we need this constructor? it's internal and hence, topologytestdriver can always use the one with all parameters.",0,0.9934172630310059
331349765,7378,mjsax,2019-10-04T05:56:06Z,"topologytestdriver supports event/stream time punctuations -- hence, this comment is a little bit miss leading. i would suggest: [code block]",0,0.9881789684295654
331349882,7378,mjsax,2019-10-04T05:56:40Z,"in the kip, the method is still called `advancetimems` -- can you update the kip?",0,0.9950903654098511
331351096,7378,mjsax,2019-10-04T06:02:48Z,"nit `send input record to the topic and then commit the record.` (note, in kafkastreams we use the abstractions of records, that are typed, while messages are untyped lower lever `byte[]` arrays). similar below.",0,0.9950141310691833
331351274,7378,mjsax,2019-10-04T06:03:41Z,`key` -> `value`,0,0.9887329339981079
331351440,7378,mjsax,2019-10-04T06:04:44Z,"should we add ""may auto advance topic time"" to the other methods?",0,0.9951449036598206
331351655,7378,mjsax,2019-10-04T06:05:49Z,nit: `{ keyvalue}` nit: remove double whitespace (2 times -- also more below),0,0.9932635426521301
331351999,7378,mjsax,2019-10-04T06:07:47Z,"`time will auto advance` -- well, only if the advance is not zero. should we be more precise?",0,0.9820773601531982
331352367,7378,mjsax,2019-10-04T06:09:56Z,`keyserializer.getclass().getsimplename()` (similar for value),0,0.9926848411560059
331352477,7378,mjsax,2019-10-04T06:10:34Z,nit: `{ testoutputtopic}` nit `from [a] topic`,0,0.9940202236175537
331352569,7378,mjsax,2019-10-04T06:10:58Z,nit: `create [a new object via]`,0,0.9927464127540588
331352610,7378,mjsax,2019-10-04T06:11:17Z,nit: `message` -> `record`,0,0.9903560876846313
331352696,7378,mjsax,2019-10-04T06:11:46Z,same as for input topic,0,0.966005802154541
331352981,7378,mjsax,2019-10-04T06:13:21Z,nit: [code block],0,0.9847351312637329
331353098,7378,mjsax,2019-10-04T06:13:57Z,nit: [code block],0,0.9847351312637329
331353157,7378,mjsax,2019-10-04T06:14:19Z,`kafka` -> `record` (same for value),0,0.9914258718490601
331353208,7378,mjsax,2019-10-04T06:14:39Z,we can omit javadocs here,0,0.9907365441322327
331353431,7378,mjsax,2019-10-04T06:15:48Z,nit `[r]ecord` nit `from [the] output topic and return the record's value.`,0,0.9934326410293579
331353468,7378,mjsax,2019-10-04T06:15:58Z,i think we can omit this,0,0.9153618216514587
331354197,7378,mjsax,2019-10-04T06:19:42Z,`read one record from the output topic and return its key and value as pair.`,0,0.9928213953971863
331354239,7378,mjsax,2019-10-04T06:20:00Z,nit: `{ keyvalue}`,0,0.9916700124740601
331355498,7378,mjsax,2019-10-04T06:26:03Z,`kafka` -> `{ topologytestdriver}`,0,0.9931061863899231
331355674,7378,mjsax,2019-10-04T06:26:53Z,"`a key/value pair, including timestamp and record headers, to be sent...`",0,0.9933962821960449
331355924,7378,mjsax,2019-10-04T06:28:09Z,`if [a] record does` `{ testinputtopic} will auto advance it's time when the record is piped.`,0,0.994996190071106
331356123,7378,mjsax,2019-10-04T06:29:01Z,remove `with a specific instant` (unclear what this means).,0,0.988244891166687
331356208,7378,mjsax,2019-10-04T06:29:26Z,the key of the record,0,0.9872241020202637
331356259,7378,mjsax,2019-10-04T06:29:38Z,the value of the record,0,0.9840449094772339
331356323,7378,mjsax,2019-10-04T06:29:55Z,the record headers,0,0.9856399297714233
331356516,7378,mjsax,2019-10-04T06:30:54Z,remove `as instant` (that is clear from the parameter type). nit `if { null}`,0,0.9941640496253967
331356647,7378,mjsax,2019-10-04T06:31:29Z,it's unclear when `now()` or internally tracked time is used -- we should be more specific?,0,0.9860724210739136
331357009,7378,mjsax,2019-10-04T06:33:10Z,`with specified timestamp` -> sounds is if there would not be anything else specified. simply to `create a new record.`?,0,0.9931227564811707
331357212,7378,mjsax,2019-10-04T06:34:07Z,nit: `timestampms` ? nit: `since [the beginning of the] epoch` ? nit: `{ null`},0,0.9922482967376709
331357301,7378,mjsax,2019-10-04T06:34:32Z,as above: explain when which case is used?,0,0.9928469061851501
331357761,7378,mjsax,2019-10-04T06:36:36Z,nit: add braces,0,0.9535678625106812
331357774,7378,mjsax,2019-10-04T06:36:40Z,nit: add braces,0,0.9535678625106812
331358003,7378,mjsax,2019-10-04T06:37:37Z,similar comments as above -- also applies to other constructors,0,0.9916480779647827
331358093,7378,mjsax,2019-10-04T06:38:00Z,`with { null} key`,0,0.9911155700683594
331358460,7378,mjsax,2019-10-04T06:39:30Z,should we add: `objects.requirenonnull(record)`?,0,0.9952479004859924
331358507,7378,mjsax,2019-10-04T06:39:43Z,as above,0,0.9391705989837646
331358629,7378,mjsax,2019-10-04T06:40:15Z,nit: `create a { testrecord} from a { consumerrecord}.`,0,0.9932859539985657
331358675,7378,mjsax,2019-10-04T06:40:26Z,as above.,0,0.9878018498420715
331359572,7378,mjsax,2019-10-04T06:44:10Z,"nit: `{ #createinputtopic(string, serializer, serializer) create}` (make `create` the link directly)",0,0.9934715032577515
331359756,7378,mjsax,2019-10-04T06:44:55Z,`and use the` -> `and use a` `to supply input records` (plural),0,0.9919541478157043
331359883,7378,mjsax,2019-10-04T06:45:33Z,as above -> make `create` the link `and use a`,0,0.9913996458053589
331359975,7378,mjsax,2019-10-04T06:45:52Z,`any output records of the topology`,0,0.9916286468505859
331360311,7378,mjsax,2019-10-04T06:47:19Z,`outputtopic2`,0,0.9905046820640564
331361415,7378,mjsax,2019-10-04T06:52:06Z,"if `key == null`, size should be `consumerrecord.null_size` (same for value)",0,0.9938942790031433
331361500,7378,mjsax,2019-10-04T06:52:31Z,as above,0,0.9391705989837646
331362053,7378,mjsax,2019-10-04T06:54:47Z,seems we encoded the size incorrectly...,0,0.5825628638267517
331364079,7378,mjsax,2019-10-04T07:02:53Z,nit: add braces (preferred for all blocks),0,0.9915454983711243
331364419,7378,mjsax,2019-10-04T07:04:17Z,remove,0,0.9477053284645081
331365084,7378,mjsax,2019-10-04T07:06:48Z,"if `time == null && record.timestamp() == null` we pass `timestamp==0`; is this intended? sounds like an error case to me (should we throw an exception, or can this never happen anyway?)",0,0.9665871858596802
331365575,7378,mjsax,2019-10-04T07:08:41Z,why do we handle this case differently?,0,0.9651867747306824
331366050,7378,mjsax,2019-10-04T07:10:41Z,"i know the context of the kip, but i think it's hard to understand for users what this means. `this method can be used if the result is considered a stream. if the result is considered a table, the list will contain all updated, ie, a key might be contained multiple times. if you are only interested in the last table update (ie, the final table state), you can use { #readkeyvaluestomap()} instead.`",0,0.9657078981399536
331366098,7378,mjsax,2019-10-04T07:10:51Z,`map` ?,0,0.9889705181121826
331366171,7378,mjsax,2019-10-04T07:11:05Z,as above,0,0.9391705989837646
331367846,7378,mjsax,2019-10-04T07:17:13Z,"we should point out in the javadocs, that null-values don't have delete semantics! ie, if the last update to a key is a delete/tombstone, the key will still be in the map (with null-value). also, i think we should not allow `null` keys, but throw an exception for this case.",0,0.9895177483558655
331368233,7378,mjsax,2019-10-04T07:18:39Z,`keydeserializer.getclass().getsimplename()` (same for value),0,0.9927534461021423
331368853,7378,mjsax,2019-10-04T07:20:50Z,we can omit javadoc for non-public methods,0,0.9864346981048584
331368920,7378,mjsax,2019-10-04T07:21:02Z,we can omit javadoc for non-public methods,0,0.9864346981048584
331368970,7378,mjsax,2019-10-04T07:21:14Z,we can omit javadoc for non-public methods,0,0.9864346981048584
331369932,7378,mjsax,2019-10-04T07:24:27Z,use `final illegalargumentexception exception = assertthrows(...)` instead of try-catch,0,0.9907224178314209
331554734,7378,jukkakarvanen,2019-10-04T15:16:23Z,renamed,0,0.9798321723937988
331556004,7378,jukkakarvanen,2019-10-04T15:19:02Z,"reason for those null parameter in testrecord contructor is limited variation of constructors with long. it would not require header parameter (null) if instant would be used, which is the prefered way for the future.",0,0.9942097663879395
331557898,7378,jukkakarvanen,2019-10-04T15:23:07Z,renamed,0,0.9798321723937988
331559215,7378,jukkakarvanen,2019-10-04T15:25:51Z,fixed,0,0.9281549453735352
331559316,7378,jukkakarvanen,2019-10-04T15:26:05Z,fixed,0,0.9281549453735352
331560205,7378,jukkakarvanen,2019-10-04T15:28:05Z,fixed and order aligned,0,0.9864320158958435
331561533,7378,jukkakarvanen,2019-10-04T15:31:12Z,changed,0,0.9270829558372498
331562321,7378,jukkakarvanen,2019-10-04T15:33:02Z,changed,0,0.9270829558372498
331562657,7378,jukkakarvanen,2019-10-04T15:33:48Z,changed,0,0.9270829558372498
331568443,7378,jukkakarvanen,2019-10-04T15:47:06Z,done,0,0.8974218964576721
331568499,7378,jukkakarvanen,2019-10-04T15:47:14Z,done,0,0.8974218964576721
331568797,7378,jukkakarvanen,2019-10-04T15:47:54Z,fixed,0,0.9281549453735352
331570268,7378,jukkakarvanen,2019-10-04T15:51:22Z,this is removed,0,0.9836457967758179
331570450,7378,jukkakarvanen,2019-10-04T15:51:47Z,removed contructor and javadoc,0,0.9925421476364136
331571591,7378,jukkakarvanen,2019-10-04T15:54:24Z,changed,0,0.9270829558372498
331572126,7378,jukkakarvanen,2019-10-04T15:55:35Z,updated,0,0.968669593334198
331573167,7378,jukkakarvanen,2019-10-04T15:57:47Z,replaced all messages,0,0.9350199103355408
331573595,7378,jukkakarvanen,2019-10-04T15:58:46Z,fixed,0,0.9281549453735352
331578731,7378,jukkakarvanen,2019-10-04T16:11:15Z,changed,0,0.9270829558372498
331578775,7378,jukkakarvanen,2019-10-04T16:11:21Z,removed,0,0.9801433682441711
331578924,7378,jukkakarvanen,2019-10-04T16:11:44Z,removed,0,0.9801433682441711
331579069,7378,jukkakarvanen,2019-10-04T16:12:06Z,removed,0,0.9801433682441711
331580264,7378,jukkakarvanen,2019-10-04T16:14:56Z,changed,0,0.9270829558372498
331582622,7378,jukkakarvanen,2019-10-04T16:21:05Z,added,0,0.9267084002494812
331585568,7378,jukkakarvanen,2019-10-04T16:28:45Z,fixed,0,0.9281549453735352
331585636,7378,jukkakarvanen,2019-10-04T16:28:58Z,clarified,0,0.9818080067634583
331585726,7378,jukkakarvanen,2019-10-04T16:29:12Z,changed,0,0.9270829558372498
331587844,7378,jukkakarvanen,2019-10-04T16:34:56Z,to my understanding null can happen either topic does not exist or no input piped to that topic. this is to able to throw error if topic does not exist at all.,0,0.9746622443199158
331590978,7378,jukkakarvanen,2019-10-04T16:43:40Z,i needed to modify like that to get some old test to work. it might be some non valid test.,0,0.9053056240081787
331591058,7378,jukkakarvanen,2019-10-04T16:43:55Z,removed,0,0.9801433682441711
331591666,7378,jukkakarvanen,2019-10-04T16:45:28Z,added,0,0.9267084002494812
331592830,7378,jukkakarvanen,2019-10-04T16:48:43Z,fixed,0,0.9281549453735352
331592861,7378,jukkakarvanen,2019-10-04T16:48:50Z,fixed,0,0.9281549453735352
331593078,7378,jukkakarvanen,2019-10-04T16:49:29Z,", what this means, is actions needed from my side",0,0.9766814112663269
331593792,7378,jukkakarvanen,2019-10-04T16:51:26Z,changed record2 to read from outputtopic2,0,0.9941602945327759
331594180,7378,jukkakarvanen,2019-10-04T16:52:29Z,changed,0,0.9270829558372498
331596166,7378,jukkakarvanen,2019-10-04T16:57:43Z,done,0,0.8974218964576721
331596244,7378,jukkakarvanen,2019-10-04T16:57:54Z,done,0,0.8974218964576721
331596343,7378,jukkakarvanen,2019-10-04T16:58:10Z,done,0,0.8974218964576721
331596809,7378,jukkakarvanen,2019-10-04T16:59:24Z,done,0,0.8974218964576721
331596839,7378,jukkakarvanen,2019-10-04T16:59:29Z,done,0,0.8974218964576721
331598905,7378,jukkakarvanen,2019-10-04T17:05:12Z,added,0,0.9267084002494812
331598928,7378,jukkakarvanen,2019-10-04T17:05:16Z,added,0,0.9267084002494812
331599147,7378,jukkakarvanen,2019-10-04T17:05:53Z,replaced,0,0.9598139524459839
331600525,7378,jukkakarvanen,2019-10-04T17:09:46Z,changed,0,0.9270829558372498
331600579,7378,jukkakarvanen,2019-10-04T17:09:54Z,done,0,0.8974218964576721
331603570,7378,jukkakarvanen,2019-10-04T17:17:58Z,replaced in all places,0,0.9899219870567322
331604119,7378,jukkakarvanen,2019-10-04T17:19:22Z,"i removed time generator logic text, it is functionality of testinputlogic, not needed here.",0,0.9798557758331299
331604682,7378,jukkakarvanen,2019-10-04T17:20:59Z,done,0,0.8974218964576721
331604752,7378,jukkakarvanen,2019-10-04T17:21:08Z,done,0,0.8974218964576721
331604866,7378,jukkakarvanen,2019-10-04T17:21:25Z,same as above,0,0.965356171131134
331604966,7378,jukkakarvanen,2019-10-04T17:21:43Z,same as above,0,0.965356171131134
331605927,7378,jukkakarvanen,2019-10-04T17:24:12Z,changed,0,0.9270829558372498
331606011,7378,jukkakarvanen,2019-10-04T17:24:23Z,changed,0,0.9270829558372498
331606681,7378,jukkakarvanen,2019-10-04T17:26:01Z,changed multiple occurences,0,0.9432281255722046
331607233,7378,jukkakarvanen,2019-10-04T17:27:15Z,removed,0,0.9801433682441711
331608046,7378,jukkakarvanen,2019-10-04T17:29:11Z,replaced,0,0.9598139524459839
331608817,7378,jukkakarvanen,2019-10-04T17:31:05Z,changed,0,0.9270829558372498
331610034,7378,jukkakarvanen,2019-10-04T17:34:27Z,done,0,0.8974218964576721
331610133,7378,jukkakarvanen,2019-10-04T17:34:42Z,done,0,0.8974218964576721
331610298,7378,jukkakarvanen,2019-10-04T17:35:10Z,removed,0,0.9801433682441711
331610965,7378,jukkakarvanen,2019-10-04T17:36:58Z,changed,0,0.9270829558372498
331611197,7378,jukkakarvanen,2019-10-04T17:37:26Z,removed,0,0.9801433682441711
331611349,7378,jukkakarvanen,2019-10-04T17:37:50Z,done,0,0.8974218964576721
331612150,7378,jukkakarvanen,2019-10-04T17:39:42Z,changed,0,0.9270829558372498
331612202,7378,jukkakarvanen,2019-10-04T17:39:49Z,changed,0,0.9270829558372498
331612485,7378,jukkakarvanen,2019-10-04T17:40:27Z,replaced,0,0.9598139524459839
331613185,7378,jukkakarvanen,2019-10-04T17:42:15Z,instance as in inputtopic,0,0.9750974178314209
331613689,7378,jukkakarvanen,2019-10-04T17:43:33Z,done,0,0.8974218964576721
331613912,7378,jukkakarvanen,2019-10-04T17:44:03Z,done,0,0.8974218964576721
331614099,7378,jukkakarvanen,2019-10-04T17:44:31Z,done,0,0.8974218964576721
331615408,7378,jukkakarvanen,2019-10-04T17:47:52Z,clarified,0,0.9818080067634583
331615881,7378,jukkakarvanen,2019-10-04T17:49:09Z,done,0,0.8974218964576721
331617799,7378,jukkakarvanen,2019-10-04T17:53:54Z,added,0,0.9267084002494812
331621072,7378,mjsax,2019-10-04T18:02:07Z,ack.,0,0.5038502812385559
331622341,7378,mjsax,2019-10-04T18:05:40Z,"no -- i just acknowledged that you basically move code that was already ""wrong"", so not your fault to use `0` instead of `consumer.null_size` :) -- no action needed.",1,0.987092912197113
331623203,7378,mjsax,2019-10-04T18:08:08Z,ack.,0,0.5038502812385559
331634638,7378,mjsax,2019-10-04T18:36:08Z,this must be `output_topic_2`,0,0.9928118586540222
331638698,7378,jukkakarvanen,2019-10-04T18:46:45Z,i don't understand the original test. why it is checking output_topic_2 if it is not in topology at all.,0,0.600754976272583
331643505,7378,jukkakarvanen,2019-10-04T18:59:40Z,i pushed the version with outputtopic2 removed,0,0.9925385117530823
331648099,7378,mjsax,2019-10-04T19:12:52Z,"well. overwriting the timestamp is fine, however, if we don't pass in `final instant time`, we should just pass `record.timestamp()` into `piperecord()` -- i checked out the code applied the following change an run test (and they passed---hence, i think it fine to be more strict) [code block]",0,0.9801384210586548
331654063,7378,mjsax,2019-10-04T19:30:36Z,"the original intent of the test was to ensure, we don't write into non-exiting topics, ie, create a topic out of nowhere -- but with the new abstraction that cannot happen anyway i guess.",0,0.9750298857688904
331659853,7378,jukkakarvanen,2019-10-04T19:47:53Z,some tests failing if making change like this.,0,0.6027564406394958
221138500,5709,bbejeck,2018-09-28T04:25:41Z,added for access to contents of `grouped`. i added this class to follow the pattern we currently use for configuration classes.,0,0.9931474328041077
221138726,5709,bbejeck,2018-09-28T04:28:29Z,i did this to be consistent with `sessionwindowedkstreamimpl`,0,0.9938309192657471
221138924,5709,bbejeck,2018-09-28T04:30:40Z,needed to change the topology as we now use the topic name of the first merged/replaced repartition topic when performing repartition topic optimization.,0,0.9943912625312805
221138954,5709,bbejeck,2018-09-28T04:31:00Z,same as above,0,0.965356171131134
221139121,5709,bbejeck,2018-09-28T04:32:38Z,same here and below needed to update the expected topology as now we use the topic name of the **_first_** merged repartition topic for the new optimized repartition topic.,0,0.994157075881958
221139255,5709,bbejeck,2018-09-28T04:34:12Z,"most of the loc in this class are boilerplate to create the topologies for the tests, and the expected optimized and non-optimized topologies.",0,0.9896766543388367
221141350,5709,bbejeck,2018-09-28T04:58:47Z,required to keep the merge nodes in the same order as they are added to the graph. they may be used later when performing an optimization if the merged node represents key-changing operations up-stream.,0,0.9943698048591614
221141409,5709,bbejeck,2018-09-28T04:59:37Z,keep `optimizablerepartitonnodes` in the same order as they are added.,0,0.9893865585327148
221141573,5709,bbejeck,2018-09-28T05:01:13Z,now grab the topic name from the first existing repartition topic that will get merged/replaced.,0,0.992944061756134
221142005,5709,bbejeck,2018-09-28T05:05:25Z,keep the key-changing parent nodes for the merge node in order.,0,0.9899402260780334
221142221,5709,bbejeck,2018-09-28T05:07:11Z,keep the `optimizablerepartitionnode`s in order as they are mapped to merge nodes,0,0.9946684241294861
221284385,5709,vvcephei,2018-09-28T15:03:18Z,"maybe a nit: you could alternatively return `return new grouped<>(name, keyserde, valueserde);` from this and the following methods and then make the three variables `final`. personally, i'd feel more comfortable making them `protected` (for `groupedinternal`'s access) if they were final.",0,0.9688317179679871
221284484,5709,vvcephei,2018-09-28T15:03:37Z,"i assume this is in reference to [a link] just jotting down some thoughts: if this were iface/impl, all the state would be private, and there'd be no need for the `protected` copy constructor. but if we decide we like kafka-7435, we'd apply it to all the config objects, and converting this one would be low incremental cost. i'm :+1: for defaulting to the common pattern.",0,0.7924641370773315
221287987,5709,vvcephei,2018-09-28T15:13:45Z,nit: maybe just call this `name` for consistency?,0,0.991583526134491
221288250,5709,vvcephei,2018-09-28T15:14:23Z,nit: formatting,0,0.5919891595840454
221288991,5709,vvcephei,2018-09-28T15:16:34Z,"hmm. i failed to notice this in the kip... should this be `named` like `grouped.named`? seems like a minor kip update that would be ok at this point, but valuable to establish consistency now.",0,0.9198479652404785
221289641,5709,vvcephei,2018-09-28T15:18:32Z,"nit: maybe just call the constructor. the other static method doesn't apply any defaults, so there's no benefit to the chained method call.",0,0.9790489673614502
221291992,5709,vvcephei,2018-09-28T15:25:33Z,"""xxx"" could also be configured via `grouped`, right?",0,0.9951528310775757
221293611,5709,vvcephei,2018-09-28T15:30:39Z,"did you mean to also insert a ` ` here, so the html would be formatted the same as this javadoc?",0,0.9929394721984863
221294337,5709,vvcephei,2018-09-28T15:32:58Z,"maybe we can also add note to the javadoc, like ` since 2.1. use { groupbykey(grouped)} instead.` ?",0,0.9949421286582947
221294537,5709,vvcephei,2018-09-28T15:33:25Z,ditto on the deprecation notice in the javadoc.,0,0.9853862524032593
221295115,5709,vvcephei,2018-09-28T15:35:12Z,i didn't follow: it seems like there's no restriction that `kr` is the same as `k`. or did you mean something else?,0,0.9723033905029297
221295243,5709,vvcephei,2018-09-28T15:35:40Z,similar question re: ` `,0,0.987068772315979
221295702,5709,vvcephei,2018-09-28T15:36:53Z,"similar question re: ""xxx"" and `grouped.named`",0,0.9946976900100708
221296087,5709,vvcephei,2018-09-28T15:38:09Z,nit: missing the `` for `grouped`,0,0.9926952123641968
221296127,5709,vvcephei,2018-09-28T15:38:16Z,nit: missing the `` for `grouped`,0,0.9926952123641968
221296539,5709,vvcephei,2018-09-28T15:39:41Z,"this one should be ``, right?",0,0.9796692728996277
221296735,5709,vvcephei,2018-09-28T15:40:24Z,similar comment re: ` `,0,0.9843570590019226
221296798,5709,vvcephei,2018-09-28T15:40:37Z,super nit: alignment ;),1,0.9945165514945984
221297424,5709,vvcephei,2018-09-28T15:42:48Z,similar question about:,0,0.9796978235244751
221299721,5709,vvcephei,2018-09-28T15:50:08Z,"similar questoin re ""xxx""",0,0.9867706298828125
221299939,5709,vvcephei,2018-09-28T15:50:52Z,similar question re: `` javadoc,0,0.9886919260025024
221301291,5709,vvcephei,2018-09-28T15:55:07Z,"sounds good. if this is an important semantic property of `mergenodes`, perhaps we should declare the variable as a `linkedhashset` as well?",1,0.5109959840774536
221301788,5709,vvcephei,2018-09-28T15:56:52Z,"similar to my question about `mergenodes`, should we go ahead and declare `keychangingoperationstooptimizablerepartitionnodes` as a `linkedhashmap >` to document that the insertion order is preserved at both levels?",0,0.9944559931755066
221303796,5709,vvcephei,2018-09-28T16:03:59Z,ditto,0,0.9222367405891418
221303825,5709,vvcephei,2018-09-28T16:04:07Z,ditto,0,0.9222367405891418
221304091,5709,vvcephei,2018-09-28T16:05:09Z,"would you be ok with renaming ""name"" to ""nodename"" to disambiguate?",0,0.9941278696060181
221304694,5709,vvcephei,2018-09-28T16:07:18Z,did we want to give priority to the explicitly named repartition topics?,0,0.9942854046821594
221304981,5709,vvcephei,2018-09-28T16:08:16Z,nit: alignment,0,0.9538867473602295
221305467,5709,vvcephei,2018-09-28T16:09:52Z,"nit: since the `groupedstreamaggregatebuilder` needs to know everything that's in `groupedinternal`, maybe we can just pass the whole config object in to cut down on the param list?",0,0.9944434762001038
221305778,5709,vvcephei,2018-09-28T16:10:58Z,"thanks! i just noticed this yesterday, and it did trip me up a little.",1,0.9832828044891357
221307699,5709,vvcephei,2018-09-28T16:18:09Z,what's the code path that leads to `repartitiontopicbasename.endswith(repartition_topic_suffix)`? i couldn't find it.,0,0.989382266998291
221309541,5709,vvcephei,2018-09-28T16:24:52Z,"i think if you mark this method as `` as well, it will also suppress the warnings, which might be better because it preserves the deprecation notice from the interface.",0,0.9880814552307129
221309956,5709,vvcephei,2018-09-28T16:26:13Z,ditto,0,0.9222367405891418
221310171,5709,vvcephei,2018-09-28T16:27:05Z,ditto to `kstreamimpl`,0,0.9918261766433716
221310476,5709,vvcephei,2018-09-28T16:28:07Z,ditto to `kstreamimpl`: it might be better to mark this class ``,0,0.9842548370361328
221310586,5709,vvcephei,2018-09-28T16:28:31Z,thank you!,1,0.9148550629615784
221314587,5709,vvcephei,2018-09-28T16:44:00Z,should this be `shouldkeeprepartitiontopicnameforgroupbykeynowindows`?,0,0.9953699707984924
221353167,5709,bbejeck,2018-09-28T19:06:35Z,ack,0,0.8596508502960205
221356038,5709,bbejeck,2018-09-28T19:18:35Z,"i can but this change isn't specific to the semantics of merge nodes themselves, it's more about bookkeeping and keeping them in the same order as they are added when building the graph. since this is private variables i'll make the change.",0,0.9809750318527222
221356652,5709,bbejeck,2018-09-28T19:21:19Z,"ack, same as above",0,0.7042319178581238
221356700,5709,bbejeck,2018-09-28T19:21:33Z,"ack, same as above",0,0.7042319178581238
221356733,5709,bbejeck,2018-09-28T19:21:46Z,"ack, same as above",0,0.7042319178581238
221358640,5709,bbejeck,2018-09-28T19:29:32Z,ack,0,0.8596508502960205
221361859,5709,bbejeck,2018-09-28T19:43:47Z,ack,0,0.8596508502960205
221361903,5709,bbejeck,2018-09-28T19:43:55Z,ack,0,0.8596508502960205
221369563,5709,bbejeck,2018-09-28T20:15:44Z,"ack, copy-paste error",-1,0.792664647102356
221369692,5709,bbejeck,2018-09-28T20:16:16Z,i'll add but i believe that was pre-existing,0,0.9751173853874207
221369921,5709,bbejeck,2018-09-28T20:17:13Z,ack,0,0.8596508502960205
221370454,5709,bbejeck,2018-09-28T20:19:29Z,ack,0,0.8596508502960205
221371198,5709,bbejeck,2018-09-28T20:22:39Z,"pre-existing, fixed",0,0.9841344952583313
221371933,5709,bbejeck,2018-09-28T20:25:25Z,"pre-existing, you'll notice the other java doc has the same thing, i'll update though",0,0.9825567603111267
221373333,5709,bbejeck,2018-09-28T20:30:45Z,fixed,0,0.9281549453735352
221378081,5709,bbejeck,2018-09-28T20:51:02Z,ack,0,0.8596508502960205
221378533,5709,bbejeck,2018-09-28T20:52:52Z,ack,0,0.8596508502960205
221379140,5709,bbejeck,2018-09-28T20:55:35Z,ack,0,0.8596508502960205
221379486,5709,bbejeck,2018-09-28T20:57:04Z,ack,0,0.8596508502960205
221379642,5709,bbejeck,2018-09-28T20:57:43Z,ack,0,0.8596508502960205
221380525,5709,bbejeck,2018-09-28T21:01:54Z,"legacy comments, fixed",0,0.9709374308586121
221380620,5709,bbejeck,2018-09-28T21:02:14Z,ack,0,0.8596508502960205
221380780,5709,bbejeck,2018-09-28T21:03:07Z,ack,0,0.8596508502960205
221382112,5709,bbejeck,2018-09-28T21:09:24Z,ack,0,0.8596508502960205
221383257,5709,bbejeck,2018-09-28T21:15:18Z,"i had the same thought, but so far we've only discussed grabbing the first repartition topic name. i'm inclined to leave as is because 1) users don't care about the name as much as it doesn't change and break the topology and 2) imho will add some complexity without a significant benefit",0,0.9414713978767395
221383379,5709,bbejeck,2018-09-28T21:15:47Z,"i had the same thought, i think this just slipped.",0,0.7645087242126465
221386486,5709,bbejeck,2018-09-28T21:32:45Z,"it comes from the `repartitiontopicnameprefix` passed as a parameter when calling `createrepartitionedsource`. since we may get an existing repartition topic name, we don't want to append `-repartition` at the end and change it. for example, we may get `kstream-aggregate-state-store-0000000005-repartition` for a repartition topic name resulting from an optimization operation and appending another `-repartition` would break the topology. as the java docs and our other docs state, we append as single `-repartition` to the repartition topic name we wouldn't want to double append. but i'll update this with a comment explaining why we do this check.",0,0.9946672916412354
221386734,5709,bbejeck,2018-09-28T21:33:53Z,ack,0,0.8596508502960205
221386797,5709,bbejeck,2018-09-28T21:34:13Z,ack,0,0.8596508502960205
221387336,5709,bbejeck,2018-09-28T21:36:49Z,ack,0,0.8596508502960205
221387515,5709,bbejeck,2018-09-28T21:37:46Z,"yeah, especially as `serialized` is deprecated, good catch!",1,0.9656231999397278
221388695,5709,bbejeck,2018-09-28T21:44:18Z,good catch actually `shouldkeeprepartitiontopicnameforgroupbynowindows`,1,0.8345038294792175
221431415,5709,vvcephei,2018-09-29T15:28:25Z,ack. it's probably also likely that the user who names some repartition topics names them all; another reason the extra complexity wouldn't buy anything.,-1,0.8202502131462097
221431492,5709,vvcephei,2018-09-29T15:31:49Z,i agree we shouldn't append multiple suffixes. it just wasn't clear where the pre-suffixed string could come from. thanks for the clarification!,1,0.9490788578987122
221442359,5709,mjsax,2018-09-29T23:12:46Z,"this is ok, because not part of 2.0, right?",0,0.9728240370750427
221442399,5709,mjsax,2018-09-29T23:15:37Z,"missing `, or ` and missing space before `operations`",0,0.9923765063285828
221442444,5709,mjsax,2018-09-29T23:18:45Z,`set the name` -- the specified name is part of the topic name -- think we should be more precise (note: i would not describe the used naming pattern in javadocs though) similar below in method javadocs.,0,0.9925605654716492
221442610,5709,mjsax,2018-09-29T23:30:15Z,nit: missing `.` at the end,0,0.9686048626899719
221442612,5709,mjsax,2018-09-29T23:30:21Z,nit: missing `.` at the end,0,0.9686048626899719
221442618,5709,mjsax,2018-09-29T23:30:47Z,"nit: missing `.` at the end oxford comma? nit: `{ name}, { keyserde}, and { valueserde}.` (similar below)",0,0.9932568073272705
221442626,5709,mjsax,2018-09-29T23:31:33Z,nit: `{ grouped}` similar below.,0,0.9930588006973267
221442659,5709,mjsax,2018-09-29T23:34:34Z,agreed with john. we should keep immutability. existing code also creates new objects. (similar below) also update javadocs `return this` above.,1,0.6249560117721558
221442678,5709,mjsax,2018-09-29T23:36:03Z,nit: fix indention,0,0.788091242313385
221442709,5709,mjsax,2018-09-29T23:38:20Z,return `new joined(...)`,0,0.9927258491516113
221442733,5709,mjsax,2018-09-29T23:40:00Z,nit: missing space,0,0.5110288262367249
221442771,5709,mjsax,2018-09-29T23:43:03Z,nit: update `xxx` to ` ` (or `<name>` to be more precise),0,0.9933759570121765
221442809,5709,mjsax,2018-09-29T23:46:11Z,"`the name for a repartition topic`: it's not the name, but part of the name only",0,0.9941164255142212
221442824,5709,mjsax,2018-09-29T23:47:42Z,"nice catch! (can you double check other javadocs, too. could be c&p error.)",1,0.9903280138969421
221442832,5709,mjsax,2018-09-29T23:48:24Z,nit: missing space,0,0.5110288262367249
221442841,5709,mjsax,2018-09-29T23:49:16Z,nit: missing space,0,0.5110288262367249
221442855,5709,mjsax,2018-09-29T23:50:04Z,nit: remove one space before `and the name...`,0,0.9735985398292542
221442858,5709,mjsax,2018-09-29T23:50:29Z,remove `<`,0,0.9922083020210266
221442872,5709,mjsax,2018-09-29T23:51:51Z,`maybe being` sounds a little odd to me... (not a native speaker though),-1,0.7056414484977722
221442895,5709,mjsax,2018-09-29T23:54:38Z,nit: why does left hand side needs to specify classed instead of interface?,0,0.9620010852813721
221442905,5709,mjsax,2018-09-29T23:55:17Z,why is `set` not sufficient?,0,0.9779160618782043
221442912,5709,mjsax,2018-09-29T23:55:43Z,why not `set` left hand side?,0,0.9880720376968384
221442930,5709,bbejeck,2018-09-29T23:57:12Z,"yes, that's correct. i checked out the `2.0` branch to confirm.",0,0.955470621585846
221442957,5709,mjsax,2018-09-29T23:59:41Z,"nit: this is the user specified name, that is part of the repartition topic name -- we should rename this",0,0.9929403066635132
221442960,5709,mjsax,2018-09-30T00:00:39Z,nit: the use specified name is part of the repartition topic only -- we should rename this to `name` or `username`?,0,0.9953567385673523
221443004,5709,mjsax,2018-09-30T00:04:03Z,could we set `name` instead of `null` here and simplify other code (cf. my comments below) ?,0,0.9931835532188416
221443009,5709,mjsax,2018-09-30T00:04:28Z,remove `name` parameter ? (cf. comment above),0,0.9902713298797607
221443020,5709,mjsax,2018-09-30T00:05:18Z,i think we can remove `repartitiontopicbasename` entirely (cf. my comments from above),0,0.9868707060813904
221443050,5709,mjsax,2018-09-30T00:07:57Z,"cannot follow here... do you aim for existing topologies with generated names, and user update code to ""pin"" names? for this case, user would pass it name, without `-repartition` suffix? user, would also need to drop ` ` prefix in the name she passed to `grouped`.",0,0.9930834770202637
221443054,5709,mjsax,2018-09-30T00:08:40Z,nit: remove empty lines,0,0.8863405585289001
221443072,5709,mjsax,2018-09-30T00:09:37Z,"do we need this annotation again? though we would need a `(""deprecation"")` here instead?",0,0.9943335056304932
221443096,5709,mjsax,2018-09-30T00:10:07Z,nit: 4 space indention only,0,0.9878403544425964
221443107,5709,mjsax,2018-09-30T00:10:22Z,as above,0,0.9391705989837646
221443114,5709,mjsax,2018-09-30T00:10:54Z,nit: 4-space indention plus move `builder` down one line,0,0.9907523393630981
221443122,5709,mjsax,2018-09-30T00:11:19Z,as above,0,0.9391705989837646
221443126,5709,mjsax,2018-09-30T00:11:37Z,nit: 4-space indention,0,0.9848935008049011
221443137,5709,mjsax,2018-09-30T00:12:20Z,"no need to deprecate an internal class imho. maybe add `(""deprecation"")` instead?",0,0.9840587973594666
221443198,5709,mjsax,2018-09-30T00:16:18Z,should this not fail here in `groupbykey()` already? maybe use `try-fail-catch` pattern here.,0,0.9943172335624695
221443199,5709,mjsax,2018-09-30T00:16:39Z,nit: missing `t`,0,0.9836214780807495
221443236,5709,mjsax,2018-09-30T00:20:43Z,"not sure why this should not be allowed? to be more precise: i understand why the code fails, however, it's very unintuitive for the user why this would fail -- looks like valid code and imho, users should be allowed to write this code: both operations can reuse the same repartition topic anyway (and with optimization turned on, they will, if i don't miss anything). not sure if we can fix this easily to be honest, but accepting this as ""by design"" would not be user friendly. maybe we can merge both repartition topics into one for this case, too?",0,0.6487709283828735
221461753,5709,vvcephei,2018-09-30T14:39:15Z,"i suggested this. while it is normally better to use an interface on the lhs, it should only be done if the interface provides the correct semantics. i.e., you should be able to swap out any two implementations of the interface and maintain correct behavior. normally, when we work with maps or sets, we do indeed need just the semantics they promise (i.e., a k/v mapping, or the set property), and we could in theory use any implementation without changing the correctness of the program. but in this case, it seemed like the correct behavior of this class depends on maintaining these collections in insertion order. unfortunately, java does not have an interface for an ordered map or set. therefore, the most general ""interface"" that provides the correct semantics is actually just the implicit interface of linkedhashmap/set itself.",0,0.981755256652832
221461770,5709,vvcephei,2018-09-30T14:39:48Z,this is also my fault... see [a link],-1,0.9351471066474915
221461780,5709,vvcephei,2018-09-30T14:40:14Z,this is also my fault... see [a link],-1,0.9351471066474915
221462040,5709,vvcephei,2018-09-30T14:51:38Z,"imho, it's better to pass along the deprecation instead of suppressing it. they both cause the compiler not to issue warnings about the use of deprecated apis in the method body. this difference is that if we suppress it here, then any `groupby` calls on a `kstreamimpl` reference *will not* issue a warning, whereas calls on a `kstream` reference will issue the warning as desired.",0,0.989500105381012
221462114,5709,vvcephei,2018-09-30T14:54:50Z,this is the same thinking as [a link] .,0,0.9828448295593262
221470735,5709,guozhangwang,2018-09-30T19:41:53Z,"also we should indicate that it is for setting the repartition topic ""if necessary: streams will not always create the repartition topic for grouped operation"".",0,0.9942132830619812
221470841,5709,guozhangwang,2018-09-30T19:44:56Z,this just occurred to me that `grouped.named()` is a bit weird when writing it down. could we rename it to `grouped.as()` or `grouped.for`? wdyt,-1,0.8465755581855774
221471094,5709,guozhangwang,2018-09-30T19:51:00Z,`will be` -> `may need to be created in kafka if a later operator depends on the newly selected key.` ditto elsewhere.,0,0.9932137727737427
221471436,5709,guozhangwang,2018-09-30T20:00:14Z,"`repartitiontopicname` and `repartitiontopic` is a bit confusing. i'd suggest just keeping the `groupedinternal` as a field to replace key/valueserde and `repartitiontopicname` in the constructor and retrieve its fields later. ditto for other internal class's constructors (you already replaced serdes with the object in some classes, just trying to suggest consistency here).",-1,0.7205514311790466
221471570,5709,guozhangwang,2018-09-30T20:03:37Z,"i cannot follow here too.. the `createrepartitionedsource` should always be called before the optimization kicks in, so the passed in name should always be the raw names right?",0,0.9817423224449158
221471689,5709,guozhangwang,2018-09-30T20:07:31Z,+1,0,0.7702900171279907
221471765,5709,guozhangwang,2018-09-30T20:09:21Z,not clear what is this test used for?,0,0.8624674677848816
221471837,5709,guozhangwang,2018-09-30T20:11:46Z,"i think the reason is that we do not check for unique names at grouped / joined, and hence only when later when the repartition topics are indeed going to be created the exception will be thrown. this looks fine to me.",0,0.7210414409637451
221471891,5709,guozhangwang,2018-09-30T20:14:32Z,"seems for joined we do not have a test to check for naming uniqueness yet, could we add one?",0,0.991855263710022
221476261,5709,mjsax,2018-09-30T22:37:37Z,"i don't think that suppress works for any callers of `kstreamimpl#groupby` -- from my understanding, there will be a warning for all callers independently of a suppress annotation -- callers would need to add their own annotation to suppress the warning for them. a `suppresswarning` only suppressed warning from the body/implementation of this method (ie, if we would call any other deprecated method). i also don't think we need `` as this annotation is inherited anyway. however, this is an internal class anyway, and thus, not public. thus, i don't have a strong opinion on this.",0,0.96383136510849
221476305,5709,mjsax,2018-09-30T22:39:26Z,ack. thanks for clarification.,1,0.7938598990440369
221476351,5709,mjsax,2018-09-30T22:41:33Z,that's a good point. `grouped.as()` sounds ok (`grouped.for()` sounds weird to me though).,1,0.5854344367980957
221476723,5709,bbejeck,2018-09-30T22:56:31Z,ack,0,0.8596508502960205
221477923,5709,bbejeck,2018-09-30T23:41:23Z,ack,0,0.8596508502960205
221477926,5709,bbejeck,2018-09-30T23:41:26Z,"ack, changed the suggested order a bit, but imho the message is the same.",0,0.9785351157188416
221477927,5709,bbejeck,2018-09-30T23:41:28Z,ack,0,0.8596508502960205
221477928,5709,bbejeck,2018-09-30T23:41:30Z,ack,0,0.8596508502960205
221477929,5709,bbejeck,2018-09-30T23:41:32Z,ack,0,0.8596508502960205
221477932,5709,bbejeck,2018-09-30T23:41:35Z,ack,0,0.8596508502960205
221477934,5709,bbejeck,2018-09-30T23:41:37Z,ack,0,0.8596508502960205
221477937,5709,bbejeck,2018-09-30T23:41:40Z,"ack, updated other methods as well.",0,0.971310555934906
221477940,5709,bbejeck,2018-09-30T23:41:43Z,ack,0,0.8596508502960205
221477941,5709,bbejeck,2018-09-30T23:41:46Z,ack,0,0.8596508502960205
221477959,5709,bbejeck,2018-09-30T23:41:52Z,ack,0,0.8596508502960205
221477965,5709,bbejeck,2018-09-30T23:41:55Z,ack,0,0.8596508502960205
221477967,5709,bbejeck,2018-09-30T23:41:57Z,ack,0,0.8596508502960205
221477968,5709,bbejeck,2018-09-30T23:42:01Z,ack,0,0.8596508502960205
221477969,5709,bbejeck,2018-09-30T23:42:03Z,ack,0,0.8596508502960205
221477999,5709,bbejeck,2018-09-30T23:43:22Z,"yeah i agree, updated.",0,0.9167231321334839
221478087,5709,bbejeck,2018-09-30T23:46:58Z,"additionally, i would in most circumstances agree with specifying the interface, but since these are private variables on an internal class, there is no ""leaking"" of an implementation.",0,0.9924853444099426
221478133,5709,bbejeck,2018-09-30T23:49:12Z,ack,0,0.8596508502960205
221478190,5709,bbejeck,2018-09-30T23:50:40Z,ack,0,0.8596508502960205
221482476,5709,bbejeck,2018-10-01T01:40:31Z,ack,0,0.8596508502960205
221482479,5709,bbejeck,2018-10-01T01:40:35Z,ack,0,0.8596508502960205
221483107,5709,bbejeck,2018-10-01T01:51:12Z,ack already done,0,0.8601624369621277
221483292,5709,bbejeck,2018-10-01T01:54:33Z,ack,0,0.8596508502960205
221483725,5709,bbejeck,2018-10-01T02:02:28Z,ack,0,0.8596508502960205
221484247,5709,bbejeck,2018-10-01T02:11:42Z,ack,0,0.8596508502960205
221484591,5709,bbejeck,2018-10-01T02:17:43Z,ack,0,0.8596508502960205
221485045,5709,bbejeck,2018-10-01T02:24:39Z,"as pointed out, the error does not occur until we go to build the topology and the duplicate topic name is detected and at that point, the error is thrown. i can update with the `try-fail-catch` pattern, but have we established this as a convention of unit tests vs using the `(expected=...)` approach?",0,0.9941304326057434
221485076,5709,bbejeck,2018-10-01T02:25:06Z,ack,0,0.8596508502960205
221490175,5709,bbejeck,2018-10-01T03:40:05Z,"just asserting that the different repartition topic base names resulted in successfully building the topology, but this is covered from other tests, so i'll remove it",0,0.9909949898719788
221490839,5709,mjsax,2018-10-01T03:48:48Z,"i personally highly prefer the try-fail-catch pattern, because it allows to narrow down which operation throws the exception. the current test would pass if the same exception is thrown one line above. imho, the `expected` annotation should only be used, if no other part in the test code could potentially throw the same exception (what is rarely the case).",0,0.9214146733283997
221490975,5709,bbejeck,2018-10-01T03:50:34Z,ack,0,0.8596508502960205
221491369,5709,bbejeck,2018-10-01T03:55:57Z,"ack, i believe i've cleaned this up.",0,0.6735163331031799
221492650,5709,bbejeck,2018-10-01T04:14:00Z,"ack, `grouped.as` is better, i'll update.",0,0.9596376419067383
221496830,5709,bbejeck,2018-10-01T05:12:28Z,"i agree, but imho it's exposing some unintuitive behavior with respect to creating multiple repartition topics. and yes with optimizations turned on users will be able to write code in this form. but as it stands now, by explicitly naming a repartition i don't see how we can re-use a single `kgroupedstream` instance, as before we relied on the auto-generated names to handle the creation of multiple repartition topics. i'm not sure i follow, do you mean in this case we do an automatic optimization and merge repartition topics ""in-line""? if so, i'm inclined to say yes we can, but i'm thinking this may be done best in a follow-on pr. wdyt?",0,0.8200007677078247
221509793,5709,mjsax,2018-10-01T07:08:07Z,"something like this -- the idea would be to set a ""flag"" on the `kgroupedstream` (same for `kgroupedtable`?) after the first `count()/reduce()/aggregate()` is executed and to remember the created repartition topic. and for this case, consecutive `count()/reduce()/aggregate()` would skip creating a new changelog topic but reuse the already created one. for backward compatibility, we would only do this if `grouped.as` is specified. it might be a little bit hacky, but might be worth it... thoughts?",0,0.9797113537788391
221629926,5709,bbejeck,2018-10-01T14:29:31Z,"i like the idea; i'll try and implement that now edit: looking at this i have some more thoughts. why limit to just when people name the repartition topic? since we have a graph now, we can keep a reference to the repartition graph node and at this point in the code always re-use this node for repartitioning. but this could be tricky as this will still affect an existing topology. for example, consider a user with multiple `kgroupedstream` calls where a repartition is required. while this means we have created multiple repartition topics, this also means that we have incremented the processor counter n times (n being the number of repartition topics). if we adopt this approach, and the user names the repartition topic, and we reuse the first created repartition topic, we'll change the number of all downstream operations including changelog topics and any other repartition topics. this ""skipping incrementing"" is similar to what happened when re-using a source topic for source `ktable` changelogs. while i realize most users will probably name all repartition topics, by doing so, they'll have to ensure they name any changelog topics as well if we reuse the repartition topics in-line. with the current optimization approach the numbering isn't affected, we move the nodes around. additionally, i""m not sure how this will affect the current optimization approach (maybe change it, as i think if we keep repartition node references as we go we could have ""automatic"" partial merging ?) i'm thinking this approach is could worth looking into, but as an immediate follow-on pr to this one as this requires some thought. wdyt?",1,0.9581137895584106
221679349,5709,mjsax,2018-10-01T16:47:28Z,"for backward compatibility. for new topologies, we should not need to care, because i would assume that users turn on optimization.",0,0.9868744015693665
221817992,5709,mjsax,2018-10-02T03:36:39Z,nit: `create [a] repartition topic` -- or `create repartition topic[s] for`,0,0.9954190254211426
221818181,5709,mjsax,2018-10-02T03:38:51Z,nit `uses [as] part` ?,0,0.994082510471344
221818570,5709,mjsax,2018-10-02T03:42:41Z,`for` -> `as` ?,0,0.9912657141685486
221818628,5709,mjsax,2018-10-02T03:43:25Z,`@{grouped}` -> `{ grouped}` or `{ grouped}`,0,0.9936590790748596
221818784,5709,mjsax,2018-10-02T03:45:18Z,`{ grouped}` and `{ grouped}` is mixed comparing different methods -- we should unify.,0,0.992192804813385
221819043,5709,mjsax,2018-10-02T03:48:20Z,"comparing javadocs with `joined`: there we point out that `null` is ok for `serdes` and the usage from config `serdes` -- we should do this here, too.",0,0.9949916005134583
221819137,5709,mjsax,2018-10-02T03:49:40Z,"comparing javadocs with `joined`: there we point out that `null` is ok for `serdes` and the usage from config `serdes` -- we should do this here, too. also for `` docs -- check other methods, too, please.",0,0.9918047189712524
221819376,5709,mjsax,2018-10-02T03:52:36Z,nit: `..` -> `.`,0,0.9881920218467712
221819613,5709,mjsax,2018-10-02T03:55:02Z,`xxx` -> ` `,0,0.990332305431366
221820266,5709,mjsax,2018-10-02T04:02:10Z,nit: remove var `newjoined` (also not used for left-hand-side code),0,0.994560182094574
221820519,5709,mjsax,2018-10-02T04:05:01Z,"was this a bug, to pass in `null` as value serde? did guozhang's pr introduce this?",0,0.9834082126617432
221820603,5709,mjsax,2018-10-02T04:06:08Z,similar here?,0,0.9758977293968201
221820654,5709,mjsax,2018-10-02T04:06:39Z,nit: remove `this.`,0,0.991038978099823
222098442,5709,bbejeck,2018-10-02T20:22:58Z,ack,0,0.8596508502960205
222099260,5709,bbejeck,2018-10-02T20:25:29Z,ack,0,0.8596508502960205
222099946,5709,bbejeck,2018-10-02T20:27:48Z,ack,0,0.8596508502960205
222102316,5709,bbejeck,2018-10-02T20:35:30Z,ack,0,0.8596508502960205
222103740,5709,bbejeck,2018-10-02T20:40:05Z,"ack, going with `{ grouped}`",0,0.9564847946166992
222110689,5709,bbejeck,2018-10-02T21:01:45Z,ack,0,0.8596508502960205
222115262,5709,bbejeck,2018-10-02T21:16:56Z,ack,0,0.8596508502960205
222115412,5709,bbejeck,2018-10-02T21:17:29Z,ack,0,0.8596508502960205
222115625,5709,bbejeck,2018-10-02T21:18:15Z,ack,0,0.8596508502960205
222117740,5709,bbejeck,2018-10-02T21:26:03Z,"we need this right now to work with generics as the `repartitionforjoin` signature is ` repartitionforjoin(final joined ` but the right-hand side is ` ` and the left-hand side is ` `. i know it's a bit of a hack, but i think it's worth the trade-off for being able to pass a single `joined` parameter, vs. all of the required components of `joined`. having the single `joined` parameter was introduced from the serdes inheritance pr. if you insist i can revert to what it was before.",0,0.9697536826133728
222117869,5709,bbejeck,2018-10-02T21:26:26Z,introduced by the serdes inheritance pr,0,0.9913691878318787
222117907,5709,bbejeck,2018-10-02T21:26:35Z,same as above,0,0.965356171131134
222118272,5709,bbejeck,2018-10-02T21:27:49Z,ack,0,0.8596508502960205
222129874,5709,mjsax,2018-10-02T22:15:53Z,ack. makes sense.,0,0.8879295587539673
51845565,812,xiaotao183,2016-02-04T09:11:53Z,sasl_callback_handler_class must be part of `addclientsaslsupport` in order to take effect,0,0.995186984539032
52296579,812,rajinisivaram,2016-02-09T11:36:07Z,"yes, of course. thank you, will add the missing line.",1,0.902423083782196
54384085,812,ijuma,2016-02-29T09:11:37Z,don't we have to update this to have a separate `loginmanager` per mechanism?,0,0.9943884015083313
54396485,812,rajinisivaram,2016-02-29T11:11:12Z,"the implementation uses a single login context with multiple login modules to support multiple mechanisms. since login is associated with login context rather than login module, one loginmanager per login type is sufficient.",0,0.9931865930557251
58483193,812,junrao,2016-04-05T03:44:57Z,could we just use configs.getstring and avoid casting? there are a few other places like that.,0,0.9928823709487915
58483211,812,junrao,2016-04-05T03:45:09Z,"in the server mode, should we even check haskerberos since saslconfigs.gssapi_mechanism is for the client?",0,0.995328426361084
58483235,812,junrao,2016-04-05T03:45:26Z,"it seems that we have an existing issue in the handling of case initial. if we can't completely write all bytes of the sasl token, we have to rely on the next call of authenticate() to finish writing the remaining bytes. however, when the write completes, we will go to the initial state and try to send the token again. it seems that we should be transitioning to the intermediate state after the write completes. the same issue seems to exist when transitioning from send_mechanism to receive_mechanism_response, if we can't write all bytes in saslmechanismrequest in one send call.",0,0.9936835765838623
58483242,812,junrao,2016-04-05T03:45:35Z,should we always return the enabled mechanism list?,0,0.9937959909439087
58483259,812,junrao,2016-04-05T03:45:51Z,could we handle an explicit exception due to the first packet not being a mechanismrequest? i was thinking that we can catch all exceptions from saslmechanismrequest(bytebuffer buffer) and convert that to a schemaexception.,0,0.9891020655632019
58483268,812,junrao,2016-04-05T03:46:00Z,"hmm, the client may not understand mechanismresponse if it doesn't send mechanismrequest in the first place.",0,0.7186209559440613
58483270,812,junrao,2016-04-05T03:46:09Z,"similar to saslclientauthenticator, it seems that we need to deal with the case that not all bytes in netoutbuffer can be sent in a single authenticate() call.",0,0.9872264266014099
58483294,812,junrao,2016-04-05T03:46:39Z,"could you update the security section of the documentation on the support of new mechanism, how to specify and plug in plainloginmodule, and what it takes to enable multiple mechanisms on the broker side?",0,0.9947394728660583
58537309,812,ijuma,2016-04-05T13:30:28Z,"this is just a `map`, so we can't use `getstring`. i wanted to change `configure` to take a `config` type for this reason, but it would break api classes unfortunately.",0,0.8900672793388367
58747063,812,rajinisivaram,2016-04-06T17:28:42Z,"you are right, server doesn't need to check the sasl mechanism. but it can disable kerberos if gssapi is not included in `enabledmechanisms`. have updated the check.",0,0.9836509823799133
58747189,812,rajinisivaram,2016-04-06T17:29:29Z,"thank you, i have fixed setting of sasl state.",1,0.9489251971244812
58747357,812,rajinisivaram,2016-04-06T17:30:17Z,have updated to include enabled mechanisms in response for successful response.,0,0.9828558564186096
58747425,812,rajinisivaram,2016-04-06T17:30:35Z,done.,0,0.9640594124794006
58747950,812,rajinisivaram,2016-04-06T17:33:26Z,"yes, i wasn't sure whether to send the response in this case. but i thought it would be useful to send it before the connection is closed since it may be useful if you are looking at the bytes returned for debugging purposes.",0,0.9669538736343384
58747999,812,rajinisivaram,2016-04-06T17:33:41Z,"done, same as before.",0,0.9777984023094177
58748697,812,rajinisivaram,2016-04-06T17:38:14Z,i have opened another jira (kafka-3517) to update the docs. will submit a pr.,0,0.9869547486305237
59741966,812,ijuma,2016-04-14T15:51:06Z,`apikeys.forid` (which is called by `getrequest` and by ourselves) throws `illegalargumentexception` if the api key is not within range. should we be catching that and throwing a more informative error?,0,0.9879847764968872
59842206,812,rajinisivaram,2016-04-15T08:30:30Z,"thank you for the review. since the first gssapi token starting with 0x60 (when handshake request is omitted) can also be an invalid api key (unlikely since `requestheader.parse` will probably throw `schemaexception`, but still possible i suppose), i changed the code to revert to gssapi for `illegalargumentexception` as well.",1,0.7999252676963806
60461201,812,junrao,2016-04-20T18:21:17Z,could we add the place-holder for those two error codes in errormapping?,0,0.9927183389663696
60461220,812,junrao,2016-04-20T18:21:22Z,should we also add the illegalsaslsate error code?,0,0.99227374792099
60461542,812,junrao,2016-04-20T18:23:15Z,should we include throws kafkaexception in the signature of configure() and close()? it's uncaught exception anyway.,0,0.9835492372512817
60461708,812,junrao,2016-04-20T18:24:18Z,"it seems that for both client and server, login uses the same clientcallbackhandler. the existing code works like that. is that correct? if so, perhaps we should rename clientcallbackhandler to sth more generic?",0,0.9887557625770569
60461752,812,junrao,2016-04-20T18:24:33Z,"hmm, it's a bit weird that we instantiate a clientcallbackhandler here and also in defaultlogin. could we just create it once and reuse?",-1,0.9793664813041687
60461827,812,junrao,2016-04-20T18:24:56Z,"hmm, should we do that? so for, we only guarantee old version of java client can talk to new version of server. but there is no guarantee that new version of java client can talk to old version of server. so, it seems simpler to always let the new client send saslhandshakerequest. this also makes it easier to add apiversionrequest in the future (kip-35).",0,0.9912856221199036
60461839,812,junrao,2016-04-20T18:25:02Z,would it be better to rename this to receiveresponseortoken()?,0,0.9950839877128601
60461878,812,junrao,2016-04-20T18:25:14Z,"since we can receive both sasl tokens or a response, perhaps we should rename servertoken to sth more general?",0,0.9949048757553101
60461893,812,junrao,2016-04-20T18:25:19Z,"for consistency, should we rename clientcallbackhandler to saslclientcallbackhandler?",0,0.9953203797340393
60461901,812,junrao,2016-04-20T18:25:24Z,the comment seems obsolete.,0,0.593178391456604
60461930,812,junrao,2016-04-20T18:25:30Z,should we change init to sth like handshake_request to match what's in the client?,0,0.9937898516654968
60461969,812,junrao,2016-04-20T18:25:41Z,could we rename the above to plainsaslproducer and plainsaslconsumer to distinguish from plain text port?,0,0.9953639507293701
60499829,812,rajinisivaram,2016-04-20T22:37:50Z,done.,0,0.9640594124794006
60499881,812,rajinisivaram,2016-04-20T22:38:21Z,"yes, added.",0,0.9730209112167358
60499925,812,rajinisivaram,2016-04-20T22:38:42Z,removed exception from signature.,0,0.989084780216217
60500580,812,rajinisivaram,2016-04-20T22:43:47Z,"yes, it was like that with kerberos, and i imagine the class was reused to avoid code duplication. but actually i think it is better to use a different class for login to make the logic clearer and more readable. i have added a different callback handler in defaultlogin with just the callbacks for login. there is some overlap with the client callback handler. let me know what you think.",0,0.9641311168670654
60500774,812,rajinisivaram,2016-04-20T22:45:22Z,see note above.,0,0.9878610968589783
60501307,812,rajinisivaram,2016-04-20T22:49:28Z,"we need this for rolling upgrade from 0.9.0.x to 0.10.0 when sasl is used for inter-broker communication. we can remove this in the release that follows (the next minor release perhaps), thus providing a non-disruptive upgrade path. will that be ok?",0,0.9933668971061707
60501331,812,rajinisivaram,2016-04-20T22:49:37Z,done.,0,0.9640594124794006
60501345,812,rajinisivaram,2016-04-20T22:49:46Z,done.,0,0.9640594124794006
60501397,812,rajinisivaram,2016-04-20T22:50:17Z,"renamed and moved to top-level class, consistent with saslservercallbackhandler.",0,0.9949186444282532
60501417,812,rajinisivaram,2016-04-20T22:50:28Z,removed comment.,0,0.9729099869728088
60501435,812,rajinisivaram,2016-04-20T22:50:34Z,done.,0,0.9640594124794006
60501449,812,rajinisivaram,2016-04-20T22:50:44Z,done.,0,0.9640594124794006
60517713,812,junrao,2016-04-21T02:13:03Z,"very good point. for backward compatibility, we can probably just guard that by inter.broker.protocol version. if the version is >= 0.10.0, we will use the new protocol. otherwise, use the old one.",1,0.8535700440406799
60558377,812,rajinisivaram,2016-04-21T10:25:56Z,"thank you, that makes sense. i have updated the code and the kip. since the version comparison code is in `core`, to avoid duplicating too much logic in `clients`, i am checking for 0.9.0 rather than 0.10.0. hope that is ok.",1,0.9923301339149475
60589714,812,junrao,2016-04-21T14:27:50Z,"hmm, we want to check inter.broker.protocol.version >= 0.10.0. this is easier if we can use the case object in core. since we only need to use the old protocol when saslclientauthethicator is used at the broker side. perhaps, we can check inter.broker.protocol.version in the broker code and pass a flag into inter.broker.protocol.version. the places where we use saslclientauthethicator are in replicafetcherthread, controllerchannelmanager, and kafkaserver (for controlled shutdown). when used in clients (producer/consumer), saslclientauthethicator will always use the new protocol.",0,0.9900205135345459
60611214,812,rajinisivaram,2016-04-21T16:16:29Z,thank you for the review. i have moved the version check to `core`.,1,0.9048052430152893
60831292,812,ijuma,2016-04-23T16:54:18Z,"i wonder if we should be adding server-only configs here, it doesn't seem like there is much benefit (although i understand that we may have done that for some configs in the past).",0,0.9612521529197693
60831331,812,ijuma,2016-04-23T16:55:54Z,is it worth mentioning the following as a reference for mechanism names in a comment? [a link],0,0.989514946937561
60831526,812,ijuma,2016-04-23T17:06:02Z,"nevermind, we do actually need this because we use this property in `common` classes.",0,0.9572221040725708
60831568,812,ijuma,2016-04-23T17:10:29Z,why do we need these as fields?,0,0.9807712435722351
60831627,812,ijuma,2016-04-23T17:13:32Z,nit: is there a `the` missing between `supported` and `requested`?,0,0.994191586971283
60831641,812,ijuma,2016-04-23T17:14:15Z,nit: replace `in` with `given`?,0,0.9942845702171326
60831687,812,ijuma,2016-04-23T17:17:28Z,nit: `the` missing before `mechanism`?,0,0.9912059903144836
60831696,812,ijuma,2016-04-23T17:17:52Z,this should be final.,0,0.988955557346344
60831745,812,ijuma,2016-04-23T17:20:01Z,this should be final and the `arraylist` should be assigned only after it's fully constructed (this ensures thread-safety).,0,0.9925621151924133
60831757,812,ijuma,2016-04-23T17:20:46Z,nit: space missing before `:`,0,0.9878371357917786
60831862,812,ijuma,2016-04-23T17:28:38Z,"would this not be slightly better if we used `errors.forcode` and then did a switch on the enum? also, we should not compare to `0`, we should use `errors.none`.",0,0.9914828538894653
60831892,812,ijuma,2016-04-23T17:30:51Z,this is the same code that is in `networkclient.correlate`. maybe we can make that a static public method and reuse it.,0,0.9944076538085938
60831968,812,ijuma,2016-04-23T17:34:26Z,can we please group final fields first and then the non final fields? it makes easier to understand what gets set during construction versus mutable fields.,0,0.9927364587783813
60832031,812,ijuma,2016-04-23T17:36:29Z,"i think suggested that we should send the enabled mechanisms in the successful case, but i don't understand the purpose. this bloats the response for the common case without any benefit that i can see. thoughts ?",0,0.6292794346809387
60832070,812,ijuma,2016-04-23T17:38:14Z,"nit: for fields that are initialised during `configure`, i think it's better to keep them `null` until `configure` is called. it makes it easier to debug if something goes wrong.",0,0.9904555678367615
60832315,812,ijuma,2016-04-23T17:54:52Z,i'm wondering if this is really necessary. could we instead add the sasl properties to the properties returned by this method via a utility method that added them only if necessary? it seems like we don't gain much by doing it this way and it adds one more parameter to a very large number of parameters already.,0,0.9407836198806763
60832411,812,ijuma,2016-04-23T18:02:18Z,did you really mean to have different indenting between lines? i think it would be nicer if these 3 lines were at the same indentation. we can change `jaassection.tostring` if it's relying on the current behaviour.,0,0.9901374578475952
60833139,812,ijuma,2016-04-23T18:50:31Z,maybe we don't need `option` here. `option` is useful when we want the behaviour of `none` to be different than the empty case.,0,0.9929589033126831
60833170,812,ijuma,2016-04-23T18:52:29Z,"it's more readable if we write this as `map { case (user, password) => (s""user_$user"" -> password }` or something like that.",0,0.9918826222419739
60833256,812,ijuma,2016-04-23T18:58:26Z,you can do something like [code block],0,0.9914138317108154
60833263,812,ijuma,2016-04-23T18:59:29Z,it's generally preferable to use `getorelse` with an appropriate message for the case when one passes a `none` when a `some` is expected.,0,0.9941263198852539
60833297,812,ijuma,2016-04-23T19:02:24Z,"hmm, maybe the way you did is better since subsequent lines are a continuation of previous lines.",0,0.964432418346405
60833355,812,ijuma,2016-04-23T19:07:30Z,it seems that this is used for inter-broker communication. shouldn't we be using the same pattern we used for `interbrokersecurityprotocol`?,0,0.9922628402709961
60833773,812,ijuma,2016-04-23T19:39:34Z,not worth having an empty `return` annotation.,0,0.9494096040725708
60833788,812,ijuma,2016-04-23T19:40:57Z,i think it would be nicer if we had a separate `abstractlogin` that `kerberoslogin` inherits from. inheritance from concrete classes is good to avoid as it tends to be brittle.,0,0.9805749654769897
60834053,812,ijuma,2016-04-23T19:56:47Z,"because these tests take a while to run, would it make sense to only have `saslmultimechanismconsumertest`?",0,0.9937149882316589
60834178,812,ijuma,2016-04-23T20:05:49Z,do we need some negative tests (eg clients connects with unsupported mechanism and client tries sasl handshake after connection is established).,0,0.9888496994972229
60847448,812,junrao,2016-04-24T16:37:46Z,"could we add some comments here and saslclientcallbackhandler to distinguish between the two (e..g, which callbacks are expected in each handler)? also, it seems that passwordcallback is never supposed to be called during login?",0,0.9946634769439697
60847587,812,junrao,2016-04-24T16:45:41Z,"my feeling is that always returning enabledmechanisms makes the protocol a bit simpler. also, the client can always know what the available mechanisms are.",0,0.9073802828788757
60852892,812,ijuma,2016-04-24T22:07:27Z,we have `auth` and `authenticator` packages. what's the thinking regarding when to use one versus the other?,0,0.9883688688278198
60853278,812,ijuma,2016-04-24T22:42:18Z,is the plan to allow users to provide their own `login`? is that why we have a `configure` method instead of passing the parameters via the constructor?,0,0.9954569339752197
60853355,812,ijuma,2016-04-24T22:46:25Z,nitpick: is it worth having this as a field? seems like we could just create it and pass it to the `logincontext` constructor.,0,0.9913641214370728
60853535,812,ijuma,2016-04-24T23:01:36Z,"this should be in the ""assigned in `configure`"" section of fields.",0,0.99471515417099
60853576,812,ijuma,2016-04-24T23:05:17Z,i think i'd configure this right after creating the callback handler instead of in this method.,0,0.9849722981452942
60853631,812,ijuma,2016-04-24T23:09:48Z,we should use interpolation instead of string concat here.,0,0.9884039163589478
60853650,812,ijuma,2016-04-24T23:11:20Z,"`send` is already doing this, right?",0,0.989013671875
60853663,812,ijuma,2016-04-24T23:13:41Z,"can you please add a comment on how the `pendingsaslstate` is used? it seems correct to me, but it will be helpful for others reading the code.",0,0.7880622744560242
60853704,812,ijuma,2016-04-24T23:16:52Z,i wonder if more of this code is generic and should be pushed somewhere else.,0,0.7316505312919617
60853743,812,ijuma,2016-04-24T23:21:02Z,this cast is redundant.,0,0.5319205522537231
60853821,812,ijuma,2016-04-24T23:25:22Z,"if the server is expecting gssapi, would it not disconnect the client? if we want to wrap any `schemaexception` into an `authenticationexception`, we should probably include the rest of the code in this method into the `try` block. and we would probably want to catch `illegalargumentexception` too.",0,0.9944802522659302
60853909,812,ijuma,2016-04-24T23:32:00Z,is there some other information we can provide for the non kerberos case?,0,0.9933391213417053
60853932,812,ijuma,2016-04-24T23:33:39Z,calling `getprivatecredentials` and `getpubliccredentials` twice is a bit messy. not sure if we can make it better though.,-1,0.8670386075973511
60854042,812,ijuma,2016-04-24T23:39:23Z,this can still be final right?,0,0.9891246557235718
60854807,812,ijuma,2016-04-25T00:29:16Z,does this imply that we should not ship this with our production-ready code?,0,0.9941613078117371
60855186,812,ijuma,2016-04-25T00:51:30Z,it may be worth saying that only `plain` is supported.,0,0.990725576877594
60855233,812,ijuma,2016-04-25T00:53:44Z,perhaps it would be good to include some more information (ie the number of tokens was not correct),0,0.9908657670021057
60855240,812,ijuma,2016-04-25T00:54:12Z,style nit: i think this should be `authorizationid`.,0,0.98921799659729
60855258,812,ijuma,2016-04-25T00:54:48Z,we should use `isempty` instead of `length == 0`,0,0.9944960474967957
60855285,812,ijuma,2016-04-25T00:55:58Z,is it worth concatenating the message given that we are passing the exception as the cause anyway?,0,0.9909193515777588
60855298,812,ijuma,2016-04-25T00:56:58Z,should we be returning `null` here?,0,0.9921329617500305
60855309,812,ijuma,2016-04-25T00:57:37Z,i guess it's ok to leave as is because the method that returns this needs to match the name provided by `saslserver`.,0,0.9909024834632874
60855865,812,ijuma,2016-04-25T01:12:23Z,it seems to me that this should be the other way around: [code block],0,0.9865633249282837
60856113,812,ijuma,2016-04-25T01:25:21Z,indenting.,0,0.9534419178962708
60856117,812,ijuma,2016-04-25T01:25:34Z,indenting.,0,0.9534419178962708
60856366,812,ijuma,2016-04-25T01:32:18Z,can we group final fields please?,0,0.9937824606895447
60856398,812,ijuma,2016-04-25T01:32:56Z,"as for the client, it would be good to have a comment explaining why we need a `pendingsaslstate`",0,0.9837530851364136
60856514,812,ijuma,2016-04-25T01:35:50Z,there's an extra space after `=`.,0,0.9891168475151062
60856547,812,ijuma,2016-04-25T01:37:35Z,i would configure the callback handler after creating it.,0,0.9834096431732178
60856567,812,ijuma,2016-04-25T01:38:38Z,"not sure about this magic, i don't think we do that for inter-broker communication. it may be better to add some validation to `kafkaconfig` for consistency.",0,0.6880792379379272
60856584,812,ijuma,2016-04-25T01:39:18Z,i think it would be better to leave this as `null` until it is initialised in `configure`.,0,0.9892191290855408
60856700,812,ijuma,2016-04-25T01:43:58Z,we should use interpolation instead of string concatenation.,0,0.987406313419342
60857015,812,ijuma,2016-04-25T01:55:44Z,do we actually need this `removeinterestops`? it seems to me that we remove it in `flushnetoutbufferandupdateinterestops` before we reach here.,0,0.9936880469322205
60857041,812,ijuma,2016-04-25T01:56:04Z,can you please explain why we need this now? it may be worth a comment.,0,0.9778410792350769
60894701,812,rajinisivaram,2016-04-25T10:48:10Z,done.,0,0.9640594124794006
60894764,812,rajinisivaram,2016-04-25T10:48:51Z,removed fields.,0,0.9717671871185303
60894790,812,rajinisivaram,2016-04-25T10:49:00Z,added.,0,0.9822506308555603
60894807,812,rajinisivaram,2016-04-25T10:49:10Z,added.,0,0.9822506308555603
60894823,812,rajinisivaram,2016-04-25T10:49:21Z,done.,0,0.9640594124794006
60894837,812,rajinisivaram,2016-04-25T10:49:33Z,done.,0,0.9640594124794006
60894885,812,rajinisivaram,2016-04-25T10:49:48Z,added space.,0,0.9872720837593079
60894913,812,rajinisivaram,2016-04-25T10:50:01Z,done.,0,0.9640594124794006
60895052,812,rajinisivaram,2016-04-25T10:51:30Z,couldn't find a good place for the common code. added a static method in `networkclient` for use in both `networkclient` and `saslclientauthenticator`.,0,0.9923391342163086
60895106,812,rajinisivaram,2016-04-25T10:52:03Z,leaving as is as-per jun's suggestion.,0,0.9902200102806091
60895309,812,rajinisivaram,2016-04-25T10:54:01Z,"agree that there are too many parameters already. but a similar pattern is used for producers and consumers as well. rather than change them all to call additional methods, leaving as-is for now. this keeps it consistent with the way ssl properties are set.",0,0.9886993765830994
60895385,812,rajinisivaram,2016-04-25T10:54:42Z,updated.,0,0.9856141209602356
60895402,812,rajinisivaram,2016-04-25T10:54:53Z,done.,0,0.9640594124794006
60895427,812,rajinisivaram,2016-04-25T10:55:06Z,done.,0,0.9640594124794006
60895436,812,rajinisivaram,2016-04-25T10:55:15Z,done.,0,0.9640594124794006
60895583,812,rajinisivaram,2016-04-25T10:56:36Z,"since the property is used by common code rather than broker-specific code, the same property is used for both clients and broker.",0,0.9943327903747559
60895608,812,rajinisivaram,2016-04-25T10:56:48Z,removed.,0,0.9782117605209351
60895633,812,rajinisivaram,2016-04-25T10:56:59Z,done.,0,0.9640594124794006
60895764,812,rajinisivaram,2016-04-25T10:58:19Z,i think it is useful to have at least one test for sasl/plain that doesn't use gssapi since some codepaths are not enabled when gssapi is disabled. i have removed one of the sasl/plain tests and left one in.,0,0.9875749945640564
60895960,812,rajinisivaram,2016-04-25T11:00:26Z,i have another changeset with unit tests for sasl in the `clients` project. i will rebase and submit that once this is committed.,0,0.98887699842453
60896246,812,rajinisivaram,2016-04-25T11:03:27Z,"i have added comments. `passwordcallback` shouldn't be called with the standard login modules during login. but since you may want to plugin custom login modules, especially for plain, it makes sense to throw an appropriate exception if it was called.",0,0.992979109287262
60896528,812,rajinisivaram,2016-04-25T11:06:31Z,"is probably the best person to answer the question. since `auth` already contained interfaces, i added interfaces to that package (the new ones are currently not exposed externally, but we may want to make these externally configurable at some point). `authenticator` contained sasl authentication implementation and it continues to hold the same.",0,0.9834571480751038
60896686,812,rajinisivaram,2016-04-25T11:07:58Z,"yes, the original kip was proposing to expose `login` to plugin new authentication mechanisms. the cut-down kip no longer needs that, but it made sense to keep it configurable for the future.",0,0.9908097982406616
60896698,812,rajinisivaram,2016-04-25T11:08:13Z,removed.,0,0.9782117605209351
60896709,812,rajinisivaram,2016-04-25T11:08:22Z,done.,0,0.9640594124794006
60896753,812,rajinisivaram,2016-04-25T11:08:45Z,done.,0,0.9640594124794006
60896777,812,rajinisivaram,2016-04-25T11:08:54Z,done.,0,0.9640594124794006
60896799,812,rajinisivaram,2016-04-25T11:09:07Z,"yes, removed.",0,0.9815766215324402
60896815,812,rajinisivaram,2016-04-25T11:09:16Z,done.,0,0.9640594124794006
60896823,812,rajinisivaram,2016-04-25T11:09:26Z,removed.,0,0.9782117605209351
60896983,812,rajinisivaram,2016-04-25T11:11:18Z,"client would get disconnected, but i am not sure if gssapi includes an error response in that case. catching exception from the whole block now.",0,0.8944612145423889
60897075,812,rajinisivaram,2016-04-25T11:12:25Z,can't think of anything that is generic and useful for other mechanisms in this case.,0,0.8156983256340027
60897383,812,rajinisivaram,2016-04-25T11:15:28Z,"could move it into another variable, but it adds more code, so leaving as is.",0,0.9864667057991028
60897403,812,rajinisivaram,2016-04-25T11:15:38Z,"yes, updated.",0,0.9654455780982971
60897700,812,rajinisivaram,2016-04-25T11:18:42Z,"rewrote the comment. it is simlar to digest-md5 implementation in zookeeper where clear passwords are stored on disk. it can be used in production, but you may want to write your own.",0,0.9938738346099854
60897719,812,rajinisivaram,2016-04-25T11:18:54Z,done.,0,0.9640594124794006
60897732,812,rajinisivaram,2016-04-25T11:19:03Z,done.,0,0.9640594124794006
60897762,812,rajinisivaram,2016-04-25T11:19:21Z,done.,0,0.9640594124794006
60897773,812,rajinisivaram,2016-04-25T11:19:30Z,removed.,0,0.9782117605209351
60898494,812,rajinisivaram,2016-04-25T11:27:33Z,empty response indicates to the client that the authentication has completed successfully. null response would possibly need changes to the client code.,0,0.9895758628845215
60898519,812,rajinisivaram,2016-04-25T11:27:51Z,updated.,0,0.9856141209602356
60898535,812,rajinisivaram,2016-04-25T11:28:01Z,done.,0,0.9640594124794006
60898552,812,rajinisivaram,2016-04-25T11:28:08Z,done.,0,0.9640594124794006
60898566,812,rajinisivaram,2016-04-25T11:28:17Z,done.,0,0.9640594124794006
60898573,812,rajinisivaram,2016-04-25T11:28:24Z,done.,0,0.9640594124794006
60898589,812,rajinisivaram,2016-04-25T11:28:34Z,removed space.,0,0.9824569821357727
60898751,812,rajinisivaram,2016-04-25T11:30:11Z,"it was written this way when callback handler class was configurable in the original kip. since it is no longer configurable, i have moved the construction to `createsaslserver` when the mechanism is known.",0,0.9952889680862427
60898799,812,rajinisivaram,2016-04-25T11:30:35Z,replaced with error check and validation in `kafkaconfig`.,0,0.9927454590797424
60898811,812,rajinisivaram,2016-04-25T11:30:44Z,done.,0,0.9640594124794006
60898835,812,rajinisivaram,2016-04-25T11:30:54Z,removed.,0,0.9782117605209351
60900182,812,rajinisivaram,2016-04-25T11:46:04Z,"have added a comment. `saslserverauthenticator.complete()` used to check `saslserver.iscomplete` earlier and didn't rely on the sasl state. it is useful to keep the state up-to-date for debug anyway, and now that it is kept uptodate, `saslserverauthenticator.complete()` can use it too.",0,0.9919169545173645
60916629,812,ijuma,2016-04-25T13:57:25Z,thanks.,1,0.5804154276847839
60916703,812,ijuma,2016-04-25T13:57:50Z,"ok, fine.",0,0.8634459376335144
60917166,812,ijuma,2016-04-25T14:00:30Z,thanks. i guess what i was trying to say is that i don't know if we will ever get the schema exception since the server will just disconnect us. but it would be good to verify that via tests. it can be done in a separate pr though.,1,0.8975869417190552
60917208,812,ijuma,2016-04-25T14:00:43Z,"ok, fine.",0,0.8634459376335144
60917226,812,ijuma,2016-04-25T14:00:49Z,ok.,0,0.9740158319473267
60917392,812,ijuma,2016-04-25T14:01:46Z,ok.,0,0.9740158319473267
60917610,812,ijuma,2016-04-25T14:03:10Z,"my comment was based on: [code block] however, if our code expects an empty byte array, it's fine to leave as is.",0,0.9911320805549622
60917684,812,ijuma,2016-04-25T14:03:45Z,sounds good.,1,0.9417163729667664
60917800,812,ijuma,2016-04-25T14:04:27Z,sounds good.,1,0.9417163729667664
60917907,812,ijuma,2016-04-25T14:05:16Z,thanks.,1,0.5804154276847839
60918260,812,ijuma,2016-04-25T14:07:32Z,"can you please file a jira for that and also think about system tests that we need? some of it is just a matter of using the plain mechanism in some tests. the other important case is testing upgrades and different broker/client versions. we already have many of these tests, so it may just be a matter of expanding them.",0,0.9900026321411133
60918411,812,ijuma,2016-04-25T14:08:23Z,the fact that it's common code is an implementation detail. we can pass the parameter via `channelbuilders` to deal with that. let's see what thinks.,0,0.9907771348953247
60918481,812,ijuma,2016-04-25T14:08:48Z,ok.,0,0.9740158319473267
60918614,812,ijuma,2016-04-25T14:09:37Z,rajini did this.,0,0.9907968044281006
60918664,812,ijuma,2016-04-25T14:09:55Z,"looks good, thanks.",1,0.9901825785636902
60919159,812,ijuma,2016-04-25T14:13:13Z,"this may seem a bit nitpicky, but it makes a difference from a java memory model perspective, the assignment to the final field should happen after the list has been populated.",0,0.5076836943626404
60919232,812,ijuma,2016-04-25T14:13:39Z,would it make sense to move this down to `defaultlogin`?,0,0.9950868487358093
60919291,812,ijuma,2016-04-25T14:13:57Z,maybe we don't need this here either (subclasses can implement it).,0,0.9881183505058289
60919588,812,ijuma,2016-04-25T14:16:03Z,nitpick: there should be a space before `{`.,0,0.9916418790817261
60919616,812,ijuma,2016-04-25T14:16:13Z,nitpick: there should be a space before `{`.,0,0.9916418790817261
60949617,812,ijuma,2016-04-25T17:06:25Z,this doesn't seem to be changed?,0,0.9493194222450256
60956336,812,rajinisivaram,2016-04-25T17:48:32Z,done,0,0.8974218964576721
60956492,812,rajinisivaram,2016-04-25T17:49:28Z,"sorry, there were two sets of code changes here, i had missed one, but have updated now.",-1,0.9908473491668701
60957054,812,rajinisivaram,2016-04-25T17:52:45Z,"agree. i suppose it depends on whether sasl mechanism is treated as a property of the sasl protocol or a higher level protocol itself. there are other instances of client-side properties (eg. service name) which don't have an ""inter.broker"" prefix when used in the broker. i am happy with either, so will wait and see what thinks.",0,0.7965918779373169
60957655,812,ijuma,2016-04-25T17:56:06Z,good point about service name.,1,0.890374481678009
60957839,812,rajinisivaram,2016-04-25T17:57:03Z,will add a test in kafka-3617 along with the other unit tests.,0,0.9930822849273682
60958025,812,rajinisivaram,2016-04-25T17:58:09Z,done.,0,0.9640594124794006
60958055,812,rajinisivaram,2016-04-25T17:58:19Z,moved.,0,0.9757053256034851
60958076,812,rajinisivaram,2016-04-25T17:58:28Z,done.,0,0.9640594124794006
60958107,812,rajinisivaram,2016-04-25T17:58:40Z,done.,0,0.9640594124794006
60959856,812,rajinisivaram,2016-04-25T18:09:05Z,done.,0,0.9640594124794006
60963638,812,ijuma,2016-04-25T18:30:32Z,i asked offline about this and he suggested the `sasl.mechanism.inter.broker.protocol`. the reason why i think this is different than `sasl.kerberos.service.name` is that it's easy to be confused when one sees `sasl.mechanism` and `sasl.enabled.mechanisms`.,0,0.9779323935508728
60993752,812,rajinisivaram,2016-04-25T21:36:01Z,"ok, makes sense. i have added updated the pr.",0,0.7776446342468262
61186244,812,harshach,2016-04-27T00:14:38Z,authenticator for pluggable authenticator that we use.,0,0.9875960350036621
37835370,165,onurkaraman,2015-08-25T06:09:30Z,`votes.maxby(_._2)._1`,0,0.9940756559371948
37835755,165,onurkaraman,2015-08-25T06:18:59Z,`allmembermetadata.tomap` converts to an immutable map,0,0.9936628341674805
37836136,165,onurkaraman,2015-08-25T06:27:03Z,"given that the session timeouts are defined per member, should this instead be: [code block]",0,0.994966447353363
37836633,165,onurkaraman,2015-08-25T06:38:14Z,"another minor point, but i think it's cleaner to keep all group-specific checks in dojoingroup similar to how it was before.",0,0.9689413905143738
37842937,165,onurkaraman,2015-08-25T08:21:18Z,"i think we can replace collect with the less obscure map: `supportedprotocols.find{ case (p, d) => protocol == p }.map{ case (p, d) => d }`",0,0.9878709316253662
37890199,165,onurkaraman,2015-08-25T16:58:37Z,`return metadata != null ? metadata.equals(that.metadata) : that.metadata == null;`,0,0.992314875125885
37895582,165,onurkaraman,2015-08-25T17:44:30Z,`def candidateprotocols = {`,0,0.9923514723777771
37895610,165,hachikuji,2015-08-25T17:44:46Z,"i was thinking that ""member"" at the root seemed a little vague in configuration.",-1,0.5029592514038086
37895692,165,hachikuji,2015-08-25T17:45:28Z,agreed.,0,0.9005043506622314
37895693,165,onurkaraman,2015-08-25T17:45:28Z,"same as above: `def currentmembermetadata: map[string, array[byte]] = {`",0,0.9931046366691589
37896333,165,hachikuji,2015-08-25T17:50:59Z,intellij generated this line! wonder why their template is so weird...,-1,0.9850819110870361
37898046,165,onurkaraman,2015-08-25T18:05:02Z,"your addgroup change now takes in (groupid, protocoltype). it probably won't change the outcome of the tests, but better for clarity to match up with the intended usage.",0,0.9878151416778564
37901060,165,onurkaraman,2015-08-25T18:27:58Z,"github annoyingly picked the diff window for me. just to clarify, i was only suggesting you move the following check: `else if (group.protocoltype != protocoltype)`",-1,0.7609413266181946
37904617,165,ewencp,2015-08-25T18:56:51Z,this confused me a bit since previously this class was purely additive wrt the set of topics. is there a case where you can actually lose a subscription by doing this? i'm thinking if the user does something to the subscriptions during a callback?,-1,0.8864670991897583
37904628,165,ewencp,2015-08-25T18:56:54Z,"nit, but since this is a nested class that will probably always be referred to by `metadata.metadatalistener`, `listener` would probably be more concise/less redundant.",0,0.9870122075080872
37904632,165,ewencp,2015-08-25T18:56:57Z,"i think this is the right default assignor, but just to be clear this is changing a default. we're still ok with this since we haven't released this yet, but are there any concerns with inconsistency with the old consumer?",0,0.9788540601730347
37904642,165,ewencp,2015-08-25T18:57:03Z,this comment doesn't seem useful...,-1,0.875536322593689
37904654,165,ewencp,2015-08-25T18:57:07Z,we could make this private since the `success` and `failure` methods seem to be the preferred way of constructing these objects and ensure you construct a valid combination (i.e. guarantees the right fields are null depending on the value of `succeeded`).,0,0.9912692308425903
37904666,165,ewencp,2015-08-25T18:57:11Z,"can we may be document what `groupsubscription` is more clearly somewhere else, maybe even just on this class's javadoc? it took me a bit of digging to figure out what it was -- i was confused why we were getting (and using) something called group subscription when a join group had failed. maybe a bit of renaming could also help? aggregategroupsubscription or aggregaterequestedgroupsubscription?",0,0.9395492672920227
37904681,165,ewencp,2015-08-25T18:57:16Z,this doesn't currently build for me because iterator's `remove()` method is not implemented.,0,0.9523372054100037
37904688,165,ewencp,2015-08-25T18:57:21Z,"is there a reason for this extra level that just contains the subscription struct field? i get that other implementations might want subscription info + other metadata, but does abstractpartitionassignor need this?",0,0.9920286536216736
37904699,165,ewencp,2015-08-25T18:57:23Z,this could be a static final -- doesn't need to be a separate object for every call to `schema()`,0,0.9886420369148254
37904706,165,ewencp,2015-08-25T18:57:25Z,"i'm not sure i understand how versioning will work for this data format. do we need to also include a schema version number as part of this `write()` call? otherwise, how would we introduce a v1? it doesn't look like this is handled in partitionassignmentprotocol since the version of the schema isn't exposed anywhere in this interface.",0,0.8796529173851013
37904713,165,ewencp,2015-08-25T18:57:29Z,why not just `subscription.toarray()`,0,0.9821171164512634
37904720,165,ewencp,2015-08-25T18:57:32Z,"same question, why not `topics.toarray()`",0,0.9823733568191528
37904726,165,ewencp,2015-08-25T18:57:36Z,"any other ideas besides controller for naming these classes? this is a different part of the code, but we've already got kafkacontroller on the broker.",0,0.9911477565765381
37916318,165,hachikuji,2015-08-25T20:38:44Z,"i don't think it's possible since we await all pending requests to the coordinator before sending a new join group request, but i'll have to look into it. this is definitely one of the messier aspects of this patch. it may get easier after kafka-2388 since subscriptions are no longer additive, but the hard part is ensuring that the metadata topic list matches the union of all topics subscribed by the group. one option might be to only update the metadata topic list based on the subscriptions defined in the join group response. that would mean we'd always need two rounds of the rebalance when subscriptions change, which seems unfortunate. i'll see if there are any nicer options.",0,0.8694818019866943
37917400,165,hachikuji,2015-08-25T20:47:58Z,"as long as we document the difference, it's probably fine. i can't imagine any cases where users would have a hard dependence on the range assignor. and since a lot of users probably won't override the default, i think we should have it set to the better strategy.",0,0.9336968660354614
37917723,165,hachikuji,2015-08-25T20:50:41Z,"yep, i didn't catch it locally because java 8 provides a default implementation.",0,0.8473494648933411
37918344,165,ewencp,2015-08-25T20:55:35Z,"not a big deal, but `collections.singletonmap` is a nice shortcut for building maps like this.",0,0.7386650443077087
37918767,165,hachikuji,2015-08-25T20:58:29Z,"initially i was trying to include a generic byte array in the protocol which extensions could provide a schema to support their own custom metadata. that got a little too complex to manage, so i decided to leave it up to custom assignors to define the full metadata schema (including subscriptions) that they depend on. in short, the extra level can be removed now.",0,0.9801436066627502
37919217,165,hachikuji,2015-08-25T21:02:08Z,manager?,0,0.9831505417823792
37919626,165,ewencp,2015-08-25T21:05:40Z,test for inconsistent metadata? or are we just assuming the other test is good enough since that's handled in abstractpartitionassignor?,0,0.9943634271621704
37922433,165,ewencp,2015-08-25T21:32:02Z,"so this basically means that not only do we enable rolling upgrades where you add a new protocol, restart everything, and can then later remove the new protocol, but we actually require it (unless you shut down the entire group and then start again from scratch)?",0,0.9890655279159546
37922449,165,hachikuji,2015-08-25T21:32:13Z,"this has probably not been thought all the way through, but any version embedded in the metadata itself cannot really be leveraged in the protocol. new versions of an assignor can support old versions of the metadata, but the opposite won't generally work. if the user wants to have a change to the metadata without bringing the cluster down, then they'd have to provide separate assignors supporting the different metadata versions. the protocol allows each assignor to provide a single version which the coordinator can use to ensure compatibility. i think the question is whether this version should identify the version of the metadata, the version of the assignor, or whether we need an additional version field to be able to express both. in general, the only thing the coordinator can do with these versions is check that they match for all members, so it would seem a little unfortunate to have to add another. it is also possible to use the name of the assignor to communicate version differences. for example, instead of ""roundrobin,"" this should be ""roundrobin-v0."" then if we need to change the metadata, we would implement abstractpartitionassignorv1 and a roundrobinassignorv1 which uses the name ""roundrobin-v1.""",0,0.990931510925293
37924821,165,hachikuji,2015-08-25T21:57:27Z,"that is right. if you attempt to upgrade the protocol without providing both versions, then the new group members (with the new protocol) would be rejected until all old members have left. this is consistent with the current implementation. i proposed previously to have the coordinator choose the protocol which the largest number of members support, but you seemed concerned that this would effectively halve the group's capacity for a short duration in a rolling upgrade. i still think that might be a more useful update mechanism in practice, but the implementation might be tricky since rejected members would have to retry at a later time which could lead to unnecessary (and costly) rebalancing. the advantage of the approach implemented here is that the code is simple.",0,0.9637967944145203
37927101,165,ewencp,2015-08-25T22:23:44Z,"i think this is fine -- the rolling upgrade with 2 protocols should be the common and suggested path if you need to do this anyway. since this is only an issue if you don't configure your consumers for a seamless upgrade, i actually don't think it's bad to have pretty harsh behavior like this. if someone screws up and misconfigures something, they'll figure it out a lot faster if they bounce consumers and they can't even get back into the group, whereas the majority vote would work but halve the capacity. i think either way is fine, but i agree this code is simpler and has reasonable results.",0,0.6063616871833801
37927178,165,ewencp,2015-08-25T22:24:43Z,"that works. we have a ton of xmanager classes on the broker, but it's a generic enough name component that it shouldn't be confusing.",0,0.9256576895713806
37927752,165,ewencp,2015-08-25T22:31:56Z,"sorry, i think we've already discussed this like 3 times and i just keep getting confused about it. the reason this code confused me is because we have `consumer_metadata_v0`, which implies at some point we could add `consumer_metadata_v1` to this class and support both/upgrading. i think i see now how we could actually still (potentially) only have `abstractpartitionassignor`, but then versioned concrete classes.",-1,0.9843968749046326
37927905,165,ewencp,2015-08-25T22:33:48Z,do we even want the range assignor anymore then? is it needed for anything that the other assignors we'd want to implement wouldn't?,0,0.9935163259506226
37929097,165,hachikuji,2015-08-25T22:48:28Z,"haha, it still confuses me too. i think i sort of blindly applied the same pattern that was used for schema definitions in the protocol class. i can drop the v0, but the trouble with assignor versioning won't go away quite that easily. one concrete suggestion might be to make the protocol version a string instead of an int to allow more information to be embedded in the version. we could then use it to track both the protocol and metadata versions. i can also add some documentation on the groupprotocol and partitionassignor interfaces to try to make intended usage clearer.",1,0.7493535280227661
37929523,165,hachikuji,2015-08-25T22:53:56Z,"yeah, that's a good point. maybe we leave it for now and address it in a separate jira? i can default to rangeassignor for consistency with the current version.",0,0.9272220134735107
37932986,165,ewencp,2015-08-25T23:40:09Z,"yeah, i think that's fine. we probably need a jira for any other built-in assignors we want to ship with 0.8.3 anyway, e.g. i assume we'll have a copartitioning implementation for kstreams.",0,0.9402153491973877
38051685,165,guozhangwang,2015-08-27T00:29:55Z,which version did you use and which edit feature did you turn on? your intellij is definitely overly-smart ;),1,0.9867276549339294
38051966,165,guozhangwang,2015-08-27T00:35:56Z,"i would prefer defaulting to range just for consistency. we have seen similar cases in the producer where the behavior of partitioner's hashing function changes a bit, causing offset manager migrated for mirror-makers and hence resetting offset and data duplicates.",0,0.9883341789245605
38602589,165,ewencp,2015-09-03T00:32:28Z,"why are we splitting the handling of metadata between both `metadata` and `fetcher` now? is this just so that this topic-partition metadata is not persistent in `metadata` since calling `partitionsfor` doens't really imply anything about whether you'll continue to need updated metadata for the topics passed in here? even so, this split seems less than ideal...",0,0.8063779473304749
38602592,165,ewencp,2015-09-03T00:32:32Z,"any reason for using an empty list here rather than `null` as a sentinel? the empty list approach seems like it could lead to confusing results if you have a programmatically generated list which can sometimes be empty. right now it's not a problem since we only expose `listtopics` and `partitionsfor(onetopic)`. but wasn't there a proposal for something like `partitionsfor(string... topics)`, in which case this could affect the public api.",0,0.9883108139038086
38602607,165,ewencp,2015-09-03T00:32:44Z,"does this really make sense? for this to occur, we'd need to have everyone agree on the metadata since that was checked above, but then they'd have to be missing metadata on one of those topics. wouldn't at least the one consumer that included that topic have metadata for it? is the goal here that we continue processing the ones we have metadata for so we can at least make progress? if we do this, is there anything that's forcing the metadata to be refreshed (like the inconsistentmetadata result does)? if not, wouldn't this cause us to sometimes knowingly ignore some topics which we might be able to make progress on immediately if we refreshed and rejoined the group?",0,0.9579298496246338
38602625,165,ewencp,2015-09-03T00:33:07Z,"you might want to rename this for clarity. i saw `hashsets` being passed into the `metadatasnapshot` constructor in `consumergroupcontroller` and since i knew `hash()` is called on that, i was worried the `hashsets` might have been a mistake. they're not, and that makes sense given the protocol we came up with, but the current method names aren't clear about what's being hashed. my first thought was `metadatahash()`, but that doesn't exactly help... maybe `topicmetadatahash()`?",0,0.9682022333145142
38602735,165,ewencp,2015-09-03T00:35:35Z,we can always go the `max.in.flight.requests.per.second` route with maximum verbosity and prefix with `group.member.`!,0,0.9872335195541382
38661233,165,hachikuji,2015-09-03T15:46:57Z,"since we depend on the metadata matching the subscription set in this patch, i wanted to remove any other calls which can affect it. the alternative would be to always intersect the subscription and metadata before computing the hash sent along in the join group. either way should work, but i actually think it's a good thing not having the persistent metadata state updated by partitionsfor(). can you explain a little more why this is less than ideal?",0,0.9476871490478516
38661343,165,hachikuji,2015-09-03T15:47:56Z,fair enough. i can use null instead.,0,0.9451507329940796
38664475,165,ewencp,2015-09-03T16:15:09Z,"it's just not great having multiple paths that make the same type of request if possible. but i see why we at least want different handling of this request/response, and there was another jira to make this exact change anyway.",-1,0.5568947792053223
38664724,165,hachikuji,2015-09-03T16:17:49Z,"the case i was trying to handle is non-existing topics. the current behavior of the consumer is to keep trying to fetch metadata for the non-existing topic in the hope that it will eventually be created, and to continue consuming from other subscribed topics. if one of the consumers does have metadata (perhaps because the topic was just created), then the metadata hash will be inconsistent and members will refetch. if the topic is later created, we will discover it when we update metadata and the consumers will rejoin.",0,0.9722703099250793
38667583,165,ewencp,2015-09-03T16:46:31Z,"ok, that makes sense in that it allows consumers to make progress even if a topic needs to be created. if auto topic creation is not enabled, then this might be the only way to make progress if one of the topics doesn't yet exist. but doesn't this also mean that if you have auto topic creation enabled and the consumer group starts up before any producers, then it might have to wait an entire metadata refresh timeout before any data is consumed from that topic, even if producers start sending data to it immediately? i think this is fine (and it's a one-time delay, 5 or 10 minutes by default iirc), just want to make sure we understand the implications of doing this.",0,0.9737223386764526
38669112,165,hachikuji,2015-09-03T17:01:48Z,"yeah, that's right, and i agree it's a little unfortunate to have to wait the full refresh interval, though i assume most cases would have the topic already created or created by producers. probably the main case where this would be encountered is in testing. one thing we could try to do is stagger metadata refreshes randomly in the group so that they are not all synchronized around the join group completion. that would reduce the expected time to discover metadata changes in general. it might also make sense to set the default metadata refresh rate a little lower for client-side assignment since we can't depend any longer on the broker discovering changes for us anymore.",0,0.6436591148376465
41659964,165,ewencp,2015-10-09T18:04:02Z,"this is out of date, right? no more metadatahashes in this version?",0,0.97352534532547
41661913,165,ewencp,2015-10-09T18:20:56Z,"is this version for the consumer protocol itself? that can't be in the struct, can it? doesn't it need to prefix the struct so you can decide which schema to decode with?",0,0.994143545627594
41662735,165,ewencp,2015-10-09T18:28:24Z,"is this just temporary until we add better support in the configs for multiple assignors? i'd imagine we need to think through the exact semantics, if ordering matters at all, etc. is the plan to eventually just switch this to a comma-separated list of class names? one thing i found with copycat was that the more things that needed to be configured via the same config dictionary, the more problematic kafka's standard approach to configuration became because you could easily hit cases where there were conflicting settings. not sure if a) that'll be an issue here or b) if we even want to support assignors that have _that_ much config, but something worth thinking about before committing to this specific approach to specifying assignors.",0,0.956697404384613
41664701,165,hachikuji,2015-10-09T18:45:40Z,"yes, you are right. i wrote it that way initially, but changed it several times as i was considering compatibility implications. assuming forward compatibility, for example, you just parse blindly even if the version is higher. however, newer versions would need to check the version before doing any parsing, so it should still be parsed separately. i'll update the patch. in general, the versioning problem is complex enough to merit its own discussion, so the goal here is to keep things as simple as possible.",0,0.9557220935821533
41664757,165,ewencp,2015-10-09T18:46:10Z,seems like this comment is not true now? intentional change or are we missing a check here?,0,0.9811774492263794
41664863,165,ewencp,2015-10-09T18:47:24Z,"agreed. as long as we address it in a blocker follow up patch, i'm happy to defer that discussion until after this patch.",1,0.963591456413269
41665659,165,ewencp,2015-10-09T18:55:06Z,"nice. it took me a minute to figure out how the combination of join group and sync were working, but the futures made this work out very nicely. this is quite a bit cleaner than i thought it was going to be.",1,0.962195634841919
41666054,165,ewencp,2015-10-09T18:58:56Z,can probably remove this comment since #290 is addressing this as part of kafka-1843.,0,0.994510293006897
41666648,165,ewencp,2015-10-09T19:05:01Z,"minor, but it'd be good to document the `m` and `s` type parameters. the current javadoc doesn't explain what ""state"" means here.",0,0.9863225221633911
41666750,165,ewencp,2015-10-09T19:06:01Z,"what does `gen` in `gentype` stand for? this is a very minor naming issue, but since i understand the generalized group functionality and am unsure what is trying to be communicated with this name, i imagine it might confuse others as well.",0,0.7705992460250854
41670166,165,hachikuji,2015-10-09T19:40:29Z,"haha, gen is short for generic. awful name, i know. i'll take any suggestions. basically i just wanted to have the type information ride along with the schema. maybe generictype? paramtype?",-1,0.9422299265861511
41671402,165,ewencp,2015-10-09T19:54:43Z,"minor cleanup, but there seem to be a few cases like this where the response to two cases is identical and you could collapse them into one conditional block.",0,0.9535597562789917
41671988,165,ewencp,2015-10-09T20:00:59Z,"yeah, i was going to suggest `validatedtype`, but i see that validate is already part of `type` and you've just refined the return type. it's unfortunate that `type` isn't already generic. i'd just expand the name to `generictype`.",-1,0.7122185230255127
41674067,165,hachikuji,2015-10-09T20:23:43Z,"honestly, type could probably be made generic without a huge impact. the usage kind of suggests that intention anyway. that might be worthwhile refactoring for a follow-up patch, but probably not a good idea to jam in here. i'll change to generictype for now.",0,0.5962209701538086
41676221,165,guozhangwang,2015-10-09T20:46:53Z,nit: rename assignors to assignorsmap? it's a bit misleading to have two variables with the same name here.,-1,0.773490846157074
41678401,165,guozhangwang,2015-10-09T21:10:21Z,is this indentation intentional?,0,0.9437662959098816
41678754,165,hachikuji,2015-10-09T21:14:18Z,"not intentional, just intellij getting a little aggressive trying to ""fix"" the indentation. i'll fix it in the next commit.",0,0.6369367837905884
41679809,165,guozhangwang,2015-10-09T21:26:55Z,why does consumers need to fetch the metadata for group subscription? if it is not subscribed to some topics their partitions will never to assigned to itself right?,0,0.9684349894523621
41680449,165,guozhangwang,2015-10-09T21:34:04Z,this class should be in clients/src/test instead of clients/src/main.,0,0.9945161938667297
41680691,165,hachikuji,2015-10-09T21:37:09Z,"the leader is the only member who sees the group subscription; for everyone else, groupsubscription() will just return that member's subscription. we depend on the leader's metadata in order to set assignments, so it must have metadata available for the full group's subscription. we could just issue one metadata request when the leader is preparing to do the assignment, but that opens the door to the leader missing metadata changes affecting topics it itself is not subscribed to. more concretely, suppose the leader is subscribed to [a], but one follower is subscribed to [a,b]. if the follower notices an increase in b's partitions, it can trigger a rebalance, but there's no guarantee that the partition change will be visible by the leader when it fetches topic metadata. therefore we register the leader to watch for changes to b as well. eventually, when the leader sees the change, it can rebalance. does that make sense?",0,0.9839962124824524
41682690,165,guozhangwang,2015-10-09T22:02:14Z,could this ever happen in the normal case? i think the key-set of consumerspertopic should always be a super-set of key-set of partitionspertopic?,0,0.9906383752822876
41682946,165,hachikuji,2015-10-09T22:05:44Z,"yeah, you are right.",0,0.704791784286499
41683260,165,guozhangwang,2015-10-09T22:09:55Z,this can be private; also what is the benefit of making it templated instead of using string directly?,0,0.992095410823822
41684230,165,guozhangwang,2015-10-09T22:24:14Z,there are some overlap between this gentype with org.apache.kafka.common.protocol.types.schema. but schema.validate() returns a struct instead of a generic t type. could we try to merge these two?,0,0.9915798902511597
41685576,165,guozhangwang,2015-10-09T22:47:08Z,"a related question to ewen's comment above: how will this version() function be used, for both assignment and subscription?",0,0.9918785095214844
41687689,165,hachikuji,2015-10-09T23:34:03Z,"the leader provides compatible versions of assignments given the respective versions specified in member subscriptions. for this patch, i have assumed full forwards and backwards compatibility of the embedded group protocol, which allows any member to be elected leader during an upgrade scenario and still perform correctly. there are two cases to consider: 1. the leader is on the old version: in this case, forwards compatibility allows the leader to go ahead and parse subscriptions from all members (even those on newer versions) and generate assignments corresponding to its older version. backwards compatibility ensures that the newer members will be able to parse the assignments with older versions. for example, if the leader is on version 0 and a follower is on version 1, the leader will parse the version 1 subscription as a version 0 subscription and provide it a version 0 assignment. 2. the leader is on the new version: in this case, the leader can parse both new and old subscription versions. depending on the protocol, it can choose to send assignments to members corresponding to their respective subscriptions, or it can choose the oldest version and send assignments based on it. using a similar example as above, if the leader is on version 1 and the follower is on version 0, then the leader can parse the version 0 subscription and send a version 0 assignment. obviously this strict compatibility model might be challenging to implement in practice, depending in particular on the protocol format (it would be relatively straightforward if we chose json, for example). alternatively, if we exposed version information in the joingroup protocol, then the coordinator would be able choose the member with the highest version, which would let us weaken the compatibility assumption. the tradeoff is that we'd need to complicate the protocol a bit to carry version information from each member along with their respective subscriptions and assignments. this gets even trickier if you allow assignment strategies to include their own embedded data format, so i was hoping to get a simple approach in place first before having a more complete discussion. perhaps for now i can just add some documentation on the groupprotocol class to clarify the current compatibility assumptions?",0,0.9908959269523621
41709461,165,ijuma,2015-10-11T11:44:04Z,"this seems like a generic method and not specific to strings, so it seems right to me to do it generically (unless we can implement a faster version by making it specific, which doesn't seem to be the case here). a few questions: - should it be in `utils` instead of here? - `consumers` parameter name should be `collection` probably - would ` >` be a better bound? that's what `collections.sort` uses.",0,0.993665874004364
41724298,165,guozhangwang,2015-10-12T05:24:35Z,"that makes sense, could you rephrase the above a little bit as comments to groupsubscription?",0,0.9920287728309631
41724379,165,guozhangwang,2015-10-12T05:27:38Z,"the only place sorted() is called is in the above roundrobinassignor where t is string, so i am wondering if this function is specific to roundrobinassignor only or not; if it is general i agree with you that we should keep it with generics and move it to utils, otherwise we can just make it private to roundrobinassignor and with string only.",0,0.9884514808654785
41727098,165,guozhangwang,2015-10-12T06:49:25Z,add some explanations about generic m(etadata) and s(tate).,0,0.989044189453125
41775541,165,guozhangwang,2015-10-12T16:39:54Z,i'm wondering if we can put the parse() function in a centralized place since their implementations are all similar?,0,0.9860521554946899
41778171,165,guozhangwang,2015-10-12T17:08:05Z,"could we avoid having two metadata.listener, one in kafkaconsumer and one here? if not, i would prefer to let coordinator have a variable field listener instead of letting itself implement the interface itself.",0,0.9939839243888855
41778848,165,guozhangwang,2015-10-12T17:15:34Z,what scenario would require leaderid in dosync?,0,0.9925827980041504
41781687,165,guozhangwang,2015-10-12T17:45:31Z,"a general comment: maybe we can rename groupcoordinator to coordinator, and coordinator to consumercoordinator, and the server-side consumercoordiantor to groupcoordinator. do you think the names are more clear that way?",0,0.9929032921791077
41783220,165,hachikuji,2015-10-12T18:00:32Z,"yeah, that sounds reasonable. maybe instead of coordinator, we can call it abstractcoordinator?",0,0.9684651494026184
41786233,165,guozhangwang,2015-10-12T18:29:47Z,update the comments for this function.,0,0.9885149598121643
41787479,165,guozhangwang,2015-10-12T18:41:13Z,"this metadatasnapshot is only written upon metadata update, but not read in dosync: we still use the above metadata object, and actually it seems not used anywhere. is this intentional?",0,0.9855749607086182
41791203,165,guozhangwang,2015-10-12T19:18:58Z,good catch.,1,0.9815194606781006
41791349,165,guozhangwang,2015-10-12T19:20:17Z,"if we are not assigning a different error code here, maybe we want to shift the rest error codes left? and same above for 23 / 24 / 25. edit: actually 23 and 25 are still used, scratch that part.",0,0.9866820573806763
41792646,165,guozhangwang,2015-10-12T19:36:12Z,is this still a possible error code? we may need to update the possible error codes for join / sync / commit / fetchoffset responses.,0,0.9929384589195251
41793002,165,guozhangwang,2015-10-12T19:39:52Z,add a comment pointing out this is for leader id.,0,0.9923484325408936
41793506,165,guozhangwang,2015-10-12T19:45:41Z,"this is not introduced in this patch, but why we are returning group_coordinator_not_available for offsetcommit if (!isactive.get), while return not_coordinator_for_group for offsetfetch for the same condition? do you know if there is any motivation?",0,0.9910231828689575
41793618,165,guozhangwang,2015-10-12T19:46:52Z,what are the possible error codes for this response? i ask this since moving forward we will move this into the protocol as well so it's better keep track of those for now.,0,0.98594069480896
41797594,165,hachikuji,2015-10-12T20:27:34Z,i've added a commit to clarify current versioning assumptions of the embedded metadata/assignment format. let me know if that is sufficient for now. i think we'll still want to consider this in a little more detail in a follow-up issue after this is checked in.,0,0.9750182032585144
41801442,165,hachikuji,2015-10-12T21:07:40Z,"i think i had made it generic initially because the consumer had an object representation, but i agree it's a little silly here. since it is a general function, perhaps i'll go ahead and relocate it to utils.",-1,0.944263219833374
41802182,165,guozhangwang,2015-10-12T21:16:15Z,why do we remove the check on subscriptionlistener.revoked?,0,0.9921302199363708
41802812,165,guozhangwang,2015-10-12T21:22:55Z,generation id is not incremented here?,0,0.9913582801818848
41803001,165,guozhangwang,2015-10-12T21:24:49Z,why error code is 1 instead of 0? also we probably should use errors.offset_out_of_range.code() for readability.,0,0.9904610514640808
41804236,165,guozhangwang,2015-10-12T21:38:31Z,"when we receive a join group in this state from a single member, does that mean we will transit to preparingrebalance and then immediately back to awaitingsync?",0,0.9935682415962219
41804868,165,guozhangwang,2015-10-12T21:45:30Z,do we still have this event in the fsm diagram now?,0,0.991054117679596
41805021,165,guozhangwang,2015-10-12T21:47:38Z,is syncerrorcode always none.code?,0,0.9868794083595276
41805157,165,guozhangwang,2015-10-12T21:49:32Z,update comments.,0,0.9796691536903381
41807478,165,guozhangwang,2015-10-12T22:19:36Z,"maybe we do not need to have the item here in the fsm, but just list for all possible ""input"": join, sync, heartbeat, offset-commit, offset-fetch, and events like ""member failed"", ""leader timed out while syncing""; and what are the possible ""output"" (i.e. the response) and the state-change (i.e. the transition). some input may not trigger state-change while some other may trigger, and the same input may also end in different state change (e.g. the last join-group request from the group or not). that will make the state machine diagram more clear.",0,0.9916582703590393
41808846,165,guozhangwang,2015-10-12T22:37:29Z,"i think we should, probably piggy-backing on load_balance_in_progress.",0,0.9822468161582947
41809554,165,guozhangwang,2015-10-12T22:47:44Z,"since maybepreparerebalance and proporgateassignment are all synchronized on the group, when the group is still in awaiting sync either all members still have their callback yet to trigger, or all of them should have sent the response in callback right? also the comments are not very accurate: if the group is in the awaiting sync, cancel the sync response for all of them if possible to have all its members rejoin.",0,0.9863269329071045
41809935,165,guozhangwang,2015-10-12T22:53:42Z,in the current implementation we can return the sync response multiple times to members' requests as long as they have the right generation-id and are within the group. i think it does not have any side-effects for now but just want to clarify with you.,0,0.9833396673202515
41810084,165,guozhangwang,2015-10-12T22:56:11Z,do we need to call completeandschedulenextheartbeatexpiration in both dojoin and dosync? why we need to reschedule in dosync?,0,0.9946795105934143
41810875,165,guozhangwang,2015-10-12T23:08:04Z,"and with the fsm, we can write handlexxx in coordinator in a way that is aligned with the fsm as the following (personally i feel it may make future implementation and reviews easier): handlexxx: 1. check coordinator arability and group availability, 2. if group is available call doxxx. 3. otherwise proper error code, or create group first then call doxxx. doxxx: switch (group.state) case state1: this request should not be received in this state, return some error-code. case state2: do some actions based on the group metadata, and probably transit group to another state. case statex: ... etc and similarly for events like failed consumers, call onyyy: onyyy: switch (group.state) case state1: this event should not happen in this state, throw exception. case state2: do some actions based on the group metadata, and probably transit group to another state. case statex: ... etc",0,0.9879357814788818
41822373,165,hachikuji,2015-10-13T02:47:56Z,"it looks like the offset fetch is the only request where we return not_coordinator_for_group for that case. it's a little unclear which error code should be preferred, but i would tend to think that not_coordinator_for_group would be the right one since it would force the client to rediscover the coordinator, which is probably what we want when we're shutting down. on the other hand, when we're starting up, we'd want to use group_coordinator_not_available. what do you think?",0,0.9825534224510193
41822535,165,hachikuji,2015-10-13T02:53:23Z,"woops, i'll add the assertion back. i think at one point i had added code to only invoke the revocation callback when we were leaving a valid generation, so the expected revokecount was actually zero and the check on revoked was unneeded. later on, i removed the check to be consistent with the current code, but forgot this assertion.",0,0.5092484354972839
41822701,165,hachikuji,2015-10-13T02:58:23Z,"seems like it's just testing serialization, so 1 was probably chosen for convenience. i'll change to errors.none instead.",0,0.9892192482948303
41823037,165,hachikuji,2015-10-13T03:07:32Z,"if we already transitioned to awaitingsync, then the members of the current generation have already been sent to the leader and the other members have received the generationid. if a new joingroup arrives before the leader has sent syncgroup, then we can either reject the joingroup and continue waiting, or we can just transition to preparingrebalance and have all members rejoin. i chose the latter since there didn't seem much point in stabilizing the group only to have the rejected member force a rebalance anyway after we transitioned to stable.",0,0.99162757396698
41823511,165,hachikuji,2015-10-13T03:21:59Z,i think this is a good idea. it is difficult in the existing implementation to check where each case fits and whether all cases have been covered.,1,0.6681498289108276
41895691,165,hachikuji,2015-10-13T17:14:07Z,"the transition from awaitingsync to stable happens when the leader submits the assignment for the generation in its syncgroup request. other members (followers) may submit syncgroup before or after this transition occurs. if before, we hold onto the request until the leader has synced; if after, we return immediately. an alternative would be to await all syncgroup requests before returning any of them, but that seems unnecessary since the group already synchronized in the joingroup barrier and the generation has been incremented. it is possible that some members will receive the assignment and others may crash before receiving anything, but the worst thing that happens in that case is that a rebalance is triggered. the generation protects us from inconsistent assignment.",0,0.9683734774589539
41901890,165,guozhangwang,2015-10-13T18:02:07Z,i am ok either way.,0,0.8087241053581238
41902685,165,guozhangwang,2015-10-13T18:08:32Z,"i think we would better return group_coordinator_not_available for (!isactive), and not_coordinator_for_group for (!iscoordinatorforgroup(groupid)) for all requests / conditions, but on the server side we should check the latter first before the former, so that consumers will get not_coordinator_for_group if it is ever the case and rediscover.",0,0.9936833381652832
41907724,165,guozhangwang,2015-10-13T18:46:55Z,"that is fine, then in preparingrebalance state we could get syncgroup requests from leader / followers, and need to return an error code to let them re-send the joingroup. is that the case?",0,0.9910871386528015
41908099,165,guozhangwang,2015-10-13T18:50:10Z,rep. first paragraph: yeah makes sense. rep. second paragraph: i am not favoring in adding another synchronization barrier unless we have to. let's sync up some time about the state transition again.,0,0.7546020746231079
42170845,165,guozhangwang,2015-10-15T19:45:25Z,"wondering if we can do the following: 1. assignment / subscriptions extend assignor.assignment / subscriptions interface and extend struct. 2. the schema object of assignment / subscriptions will be relying on consumer_protocol_header_schema, assignment_v0 and subscription_v0 (maybe we can move them to a consumerprotocol sub-class inside abstractpartitionassignor). 3. use schema.write / read to serialize / deserialize the assignment / subscriptions. 4. remove generictype class and subscriptionschema / assignmentschema functions. is there any blockers for that?",0,0.9947569370269775
42174780,165,hachikuji,2015-10-15T20:20:19Z,wouldn't it be a little restrictive to require all assignor implementations to use kafka structures for serialization?,0,0.9798658490180969
42175026,165,ewencp,2015-10-15T20:22:18Z,"isn't the drawback with that is that you _must_ use kafka's struct then? that seems pretty inconvenient if there's a chance your data format will change but you can guarantee compatibility, e.g. a resource-based assignor is likely to evolve the set of configs it has over time. in particular, i think this would mean that if you wanted to make any change that could be handled compatibly by your code but that doesn't fit into struct's compatibility rules, you would have to change assignor name/sub protocol name, which also means going through the multiple-assignors + 2 rolling bounces upgrade process.",-1,0.7390275001525879
42175057,165,guozhangwang,2015-10-15T20:22:33Z,i feel it is general enough. what kind of serdes are not compatible with kafka structures?,0,0.958588182926178
42176271,165,hachikuji,2015-10-15T20:32:23Z,we might be able to make that work if we change the format to something like this: [code block] then users can provide any metadata they need in the userdata field.,0,0.9921817779541016
42178482,165,ewencp,2015-10-15T20:50:20Z,"what's the real benefit of requiring kafka's structs and doing so directly? it has the drawback i mentioned and it also keeps you from being able to manually handle multiple versions if you wanted to (you could check the version number before trying to decode, but only if you have control over the deserialization process). it looks to me like it just saves a few lines of code for us, and _maybe_ is a bit simpler for implementers of assignors since generictype will be removed.",0,0.9628299474716187
42179615,165,hachikuji,2015-10-15T20:58:41Z,"one benefit of having a common serialization for subscriptions/assignment is that admin tooling can then depend on it. i think it might not be too bad if we implemented the userdata suggestion above. then we could actually keep the struct serialization hidden from users and give them control over userdata, which lets them do whatever they want.",0,0.9757736325263977
42180627,165,guozhangwang,2015-10-15T21:07:42Z,could this function ever be triggered? requestfuturecompletionhandler only have the oncomplete() api which will always trigger firesuccess().,0,0.9922842383384705
42181904,165,ewencp,2015-10-15T21:18:59Z,"i kind of buy that argument, but that tooling can't do anything useful with kafka structs that it doesn't already know the format of since the schema is only recorded in code. it might make writing the tooling simpler since it only has to deal with one format, but with kafka structs i don't think it actually enables anything that you couldn't get even with the more general form. i'm fine if we go with requiring schema/struct, i'm mostly wary because copycat is relying on this as well and i don't think we have as clear an idea of the exact requirements there as we do with a lot of the assignors -- right now its really simple, just the config topic offset that the worker is currently on, but i'm not sure what else might eventually make it in there. i personally like having the possibility to make certain incompatible schema changes without requiring config changes + rolling bounces (i.e. the possibility to keep those changes seamless for the user).",0,0.7829397916793823
42182802,165,hachikuji,2015-10-15T21:26:49Z,"this makes me want to add back the protocoltype field in the joingroup request. then if the protocol type is ""consumer,"" tools would be able to parse metadata directly by using consumerprotocol. they wouldn't be able to touch userdata, but that seems reasonable.",0,0.9856573343276978
42185251,165,hachikuji,2015-10-15T21:48:56Z,"consumernetworkclient does fail some requests before they are sent, but i don't think disconnectexception is possible.",0,0.9509913325309753
42189757,165,hachikuji,2015-10-15T22:34:12Z,"ok, so here's a summary of the changes i'm suggesting: 1. change consumer metadata schema to the following: [code block] assignment stays as it currently is (are there any cases where an assignor implementation would need to propagate additional information in the assignment)? 2. migrate the subscription/assignment schemas currently in abstractpartitionassignor back into consumerprotocol. 3. change the partitionassignor interface to look something like this: [code block] 4. add protocoltype field to joingroup request: [code block] for the consumer, the protocol type will be ""consumer"" and this will allow tools to use consumerprotocol to parse subscription/assignment metadata (assuming we will eventually expose it in describegroup or something similar). what do you think?",0,0.9885643124580383
42190485,165,ewencp,2015-10-15T22:42:19Z,"so then does that include the changes was talking about? the basic approach sounds fine, and the organization is similar to how i updated the copycat code when i rebased onto this code -- i kept a copycatprotocol class, though it ended up just holding a few static methods + inner classes. but this is a solution for making generic tooling for consumers possible. you could do all of this and still restrict the format to kafka structs as proposed, right?",0,0.9149578213691711
42193354,165,guozhangwang,2015-10-15T23:15:10Z,is this class needed?,0,0.9876177906990051
42195737,165,guozhangwang,2015-10-15T23:49:11Z,"i was originally mainly think about code simplicity, not about tooling connivence much. i am wondering for copycat, is a topics field always necessary and representative of the resource partitions? i get 's point that enforcing the whole protocol to be restricted to kafka structures would be less flexible in terms of compatibility, and if we only do that by extracting `topics` from subscriptions while keep `userdata` and `assignment` still generic types then it does not buy us much regarding code simplicity either. so i am now ok with the current approach of keeping `generictype`. the only other comment is as below: we probably can save the abstractpartitionassignor as its only `assign` function is more like a helper function, hence putting the schemas in a `consumerprotocol` class along with the helper functions, and only keep one `partitionassignor` interface for users to instantiate.",0,0.8481479287147522
42195884,165,hachikuji,2015-10-15T23:51:18Z,my suggestion is limited in scope to the new consumer. copycat can still implement metadata however it wants.,0,0.9831455945968628
42197214,165,ewencp,2015-10-16T00:11:39Z,"following up, i got a clearer explanation from offline. the change is specific to the consumer groups, copycat still has control over its serialization via its abstractcoordinator subclass since that class just deals with `byebuffer`s. so i think this plan with the extra user data makes sense.",0,0.9806040525436401
42197590,165,guozhangwang,2015-10-16T00:17:50Z,"talked to offline, my previous understanding was incorrect that other services like copycat and kafkastreams also need to implement `partitionassingor`, which is actually only gonna be used by the new consumer. hence for others they can always decide to implement their only schemas that is not restricted to kafka schema / struct.",0,0.9643698930740356
42278727,165,guozhangwang,2015-10-16T19:07:24Z,we can remove the package prefix.,0,0.9915655851364136
42281759,165,hachikuji,2015-10-16T19:40:04Z,"yes, that's right, since the generation is required, i think it should be ok. of course this implies that the coordinator keeps sync state around while in the stable state. one thing we've discussed is allowing the coordinator to discard this state some time after the group becomes stable (maybe after one session timeout). this would reduce the memory footprint of the group on the broker in the steady state. this is probably worth looking at once this patch is out of the way.",0,0.9370200037956238
42284440,165,guozhangwang,2015-10-16T20:08:39Z,totally agree.,0,0.93526291847229
42426323,165,guozhangwang,2015-10-19T21:10:14Z,"could you also update the comments here according to the discussed fsm? basically we only need the responding logic for each event within a state, and the transit logic between across states.",0,0.9923547506332397
42427091,165,guozhangwang,2015-10-19T21:17:31Z,"i think we said in this case we will also return rebalance_in_progress, and hence we can remove unknown_member_id from possible error codes in syncresponse?",0,0.9949912428855896
42427602,165,guozhangwang,2015-10-19T21:21:52Z,"in the current protocol the leader should never submit the sync request twice, or in otherwords submit a sync group request without receiving a join group response; and if they do it would be due to a re-send upon ack failed, etc. hence i think in the stable state we should not distinguish leader with others any more and just treat everyone as the same.",0,0.9882610440254211
42428212,165,guozhangwang,2015-10-19T21:27:19Z,"i think it's better the follow the same pattern as we do in handlexxx here, e.g. move the checking such as `rebalancepurgatory.checkandcomplete()` if the state is in `reparerebalance``, or``maybepreparerebalance``if state is in``awaitingsync``or``stable``. also with the current implementation we will transit from awaitingsync to preparerebalance if any of the members failed, but with my proposed protocol we could only trigger that transition if the leader fails. is there any problem doing this?",0,0.9902408123016357
42428592,165,guozhangwang,2015-10-19T21:30:37Z,"i forgot to add this event in the fsm before, it should be treated as similar to onconsumerfailure.",0,0.9779461622238159
42429156,165,guozhangwang,2015-10-19T21:36:07Z,move this condition after the first one as we want to send rebalance_in_progress before illegal_generation: they may not cause difference for now but just be careful for future updates. or just use `match case` on states and only do generation / member-id checks for `stable` state.,0,0.9933462142944336
42429312,165,guozhangwang,2015-10-19T21:37:34Z,if the state is in `preparerebalance` we can accept if generation is from the previous one?,0,0.9946815371513367
42429493,165,guozhangwang,2015-10-19T21:39:13Z,nit: onexpirerestablaize.,0,0.9532229900360107
42429521,165,guozhangwang,2015-10-19T21:39:31Z,nit: onexpireheartbeat.,0,0.9662911295890808
42429678,165,guozhangwang,2015-10-19T21:40:58Z,"also according to what we discussed offline, maybe we can rename ""restabilize"" to ""join"" since it is only for the first phase of rebalance.",0,0.9939908385276794
42437210,165,hachikuji,2015-10-19T23:02:31Z,"i think that is right. the generation is incremented after the join completes, so we allow commits from the current generation in preparerebalance.",0,0.9881298542022705
42437479,165,guozhangwang,2015-10-19T23:06:06Z,"ah right, my bad.",-1,0.9909987449645996
42469221,165,onurkaraman,2015-10-20T08:45:08Z,it may be more intuitive to return unknown_member_id when group == null.,0,0.9885983467102051
42531198,165,guozhangwang,2015-10-20T18:04:34Z,"i think i agree, it is also for consistency with hb and leave requests.",0,0.9713444113731384
42575975,165,becketqin,2015-10-21T01:50:05Z,should this be getconfiguredinstances()?,0,0.9939374923706055
42576026,165,becketqin,2015-10-21T01:51:12Z,"minor, kafka convention is not using brackets for single line statement.",0,0.9780824184417725
42576335,165,becketqin,2015-10-21T01:58:16Z,can we put some of the methods in a separate util class?,0,0.9940464496612549
42576376,165,guozhangwang,2015-10-21T01:59:01Z,"currently our configs are still going to pass-in a single partitioner which is then be used as a singleton list, hence we use `getconfiguredinstance` here.",0,0.9938063621520996
42577420,165,hachikuji,2015-10-21T02:20:40Z,i think might be right. providing multiple instances is to support changes in a rolling upgrade scenario.,0,0.9844303727149963
42578537,165,becketqin,2015-10-21T02:44:19Z,"the name is a little bit misleading here. when rebalance occurs, no one actually leaves the group, right? also, according to the comments for this method: _invoked when the group is left (whether because of shutdown, metadata change, stale generation, etc.)_ at very least it looks metadata change actually will not kick anyone out of the group, but only trigger a rebalance.",0,0.8599240183830261
42578745,165,becketqin,2015-10-21T02:47:22Z,do we have any use case in mind for this method? it looks somewhat overlapping with consumerrebalancelistener.onpartitionsassigned().,0,0.990088164806366
42578814,165,becketqin,2015-10-21T02:49:10Z,empty comments.,0,0.9670003056526184
42578959,165,hachikuji,2015-10-21T02:52:02Z,two potential use cases i know of. one is sticky partitioning where the partitioner sends the old assignment in the subscription for the next round so that the leader can keep partition movement minimal. the other is for kafka streams ( knows more about this use case).,0,0.9910479187965393
42642563,165,hachikuji,2015-10-21T15:52:10Z,"yeah, that's a fair point. perhaps beforerejoin would be more accurate?",0,0.8794946670532227
42643752,165,hachikuji,2015-10-21T16:01:01Z,actually i don't think it's too inaccurate since you are leaving the generation. perhaps onleavegeneration?,0,0.7893387079238892
42653027,165,becketqin,2015-10-21T17:15:33Z,"i'm not sure how it would work for sticky partition case. to make the leader honor the sticky partition (move as less partition as possible), the current leader needs to know the global assignment from the previous rebalance. but here we only have the assignment of this particular consumer. if we want to have sticky partition assignor perhaps we can let every consumer include their current assignment in the joingrouprequest and let the leader parse them.",0,0.9057620167732239
42653813,165,hachikuji,2015-10-21T17:21:38Z,"the idea is to have the local assignment returned in onassignment included in the user data of the next subscription. all subscriptions are forwarded to the leader, so it would be able to use the previous assignments found in the member's subscription userdata to compute the next assignments.",0,0.9943944215774536
42654165,165,guozhangwang,2015-10-21T17:24:16Z,"`onassignment` is only triggered after the syncing phase by everyone, not only by the leader. it is different from `consumerrebalancelistener.onpartitionsassigned()` such that the latter only gives the list of partitions, while the former contains extra userdata that can be associated with the assigned partitions. for kafka streams it is important to use this userdata to infer the further mapping from consumer's partitions to task's partitions.",0,0.9942848086357117
42683684,165,becketqin,2015-10-21T21:18:44Z,"i kind of think we should be careful about those terminologies. otherwise we can easily confuse people. another example is `dosync` and `performsync`, from the name it is hard to tell the difference. i suggest we do the following for abstractcoordinator: 1. rename `dosync` to `generateassignments`, and there is no need to pass in `leaderid` because it is always going to be itself. 2. separate `performsync` to `onelectedasgroupleader` and `oneelectedasgroupmemeber`. we can invoke them in joingroupresponsehandler.handle() 3. rename `onleave` to `ongroupjoinstart` 4. rename `onjoin` to `ongroupjoinfinish` 5. rename `sendjoingrouprequest` to `performgroupjoin` so the sequence becomes: 1. ongroupjoinstart 2. performgroupjoin 3. ongroupjoinfinish in performgroupjoin(): 1. sendjoingrouprequest 2. joingroupresponsehandler.handle() \* onassignedasgroupleader (only valid for leader) \* generateassignments \* sendsyncgrouprequest() with assignments or \* onassignedasgroupmember (only valid for member) \* sendsyncgrouprequest 1. syncgroupresponsehandler.handle() - getpartitionassignment and complete the future. except for that, the client side code structure looks good to me. i will continue to review the server side code.",0,0.9807099103927612
42685152,165,becketqin,2015-10-21T21:30:55Z,got it. thanks for the explanation.,0,0.49874886870384216
42689244,165,hachikuji,2015-10-21T22:05:54Z,"thanks for the suggestions! a few notes: 1. i agree with renaming dosync. initially i was thinking of this phase as ""state synchronization,"" but in the end, it seemed that the assignment terminology was easier to understand, so i did some renaming, but didn't catch all. i think, however, that leaderid is needed in the general case because the member doesn't know its own id (the copycat patch is already depending on this). 2. yeah, we can do this. maybe more concisely, we can use `onbecomeleader` and `onbecomefollower`? 3. this suggestion is equally confusing in my mind. it seems more natural to phrase this in terms of the generation. instead of `onleave`, my suggestion would be `ongenerationend`. 4. similarly, `onjoin` becomes `ongenerationbegin`. 5. i guess that's fair since it's not only sending the join group.",1,0.9813625812530518
42718108,165,becketqin,2015-10-22T07:27:54Z,"about (3) and (4), i think the confusion comes from we are reusing the term **join** here while we already have a joingrouprequest. but i am also a little concerned about exposing the concept of **generation**. **generation** is a purely implementation detail so it would be nice not to expose that to user. my original thinking was `onrebalancebegin()` and `onrebalanceend()`. it is a precise description and avoids reusing joingroup, but it exposes the concept of **rebalance** to user. that was why i switched to `ongroupjoinbegin` and `ongroupjoinend` - because it is very easy for user to understand. people who overrides those two methods don't need to have ideas about internal details such as joingrouprequest, generation, rebalance, etc. they only need to know: 1. **ongropujoinstart** - do something before taking action to join/rejoin the group. 2. **generateassignments** - run the customized resource assigning algorithm. 3. **ongroupjoinfinish** - do something after you joined the group from user's point of view they are only doing a group join (it has nothing to do with joingroupreqeust). group join looks more intuitive than names related to rebalance or generation. i just want to reason a little bit on the names. because those method names are essentially public api that user will override, i feel making them easy to understand is important.",0,0.9628947377204895
42779406,165,hachikuji,2015-10-22T17:35:35Z,"yep, totally agree on the importance of naming. this issue is clearly related to the discussion on kafka-2674. i think there are two ways we can approach this: 1. the callbacks are used to indicate phases of rebalance. there is an initial call when the rebalance begins and another call when the rebalance ends. maybe we could change the names in this case to `onjoinbegin` and `onjoinfinish`. 2. the callbacks are used to indicate group membership. in this case, the first call would always be onjoin and every onjoin would be paired with a corresponding onleave. in this case, onleave would get invoked in close if there is an active group. i think you are favoring 1., while the current rebalancelistener used by the consumer and the abstractcoordinator is suggesting 2. to the user. whichever we decide, we need to make the naming consistent. i actually don't have a strong preference either way, but i think it comes down to the following question: are there any cases where the onpartitionsrevoked() function is going to do anything different than what would be done on close(). if they always do the same thing, then we should probably make user's life easier and implement 2. if not, then we should keep 1.",0,0.9801515936851501
42831631,165,becketqin,2015-10-23T04:03:50Z,"good point about the correlation with rebalance listener methods. you are right, we should make them consistent. it looks we are trying to address two different kinds of programmers: 1. people who are using kafkaconsumer. 2. people who are developing their clients(producer/consumer/processor, etc) and extending abstractcoordinator. majority of the programmers belongs to (1). what they need to provides today are: - consumerrebalancelistener - `onparitionsrevoked()` - `onparitionsassigned()` - partitionassignor - `assign()` - `onassignment()` - `subscription()` the programmers in case (2) need to think about: - `ongroupjoinstart()` - `generateassignment()` - `ongroupjoinend()` to make everything consistent, perhaps we can change the consumerrebalancelistener interface to: - consumerrebalancelistener - `ongroupjoinstart()` - `ongroupjoinend()` as said in kafka-2674, my only concern about this approach is that if later on we want to add a `beforecommittingoffset()` to rebalance listener, that's going to be a bit weird. but there is always a workaround to turn off auto commit and let user have full control over the state when `ongroupjoinstart` is called. so i guess this is less a problem. does this approach make sense? btw, wrt **leave**, here is my understandings about onleave() if we have one. if we have an onleave(), it should only be called when a consumer has been kicked out of the group, i.e. its generation id is no longer valid. otherwise, the consumer is technically still in the group. that means onleave() should not be called during a normal rebalance because the generation id is still valid.",1,0.8094258904457092
42897321,165,hachikuji,2015-10-23T18:21:35Z,"hey , can you have a look at #354? maybe we can continue discussion there? my current position is basically to make the naming consistent with the implementation. right now, the implementation of onleave is actually closer to ongroupjoinstart (or onjoinprepare as i named it in that patch). i think it's worth discussing whether onleave would be more useful in practice, but we need to think it through. it seems to me like onjoin and onleave, if implemented according to their naming, would be a more intuitive paradigm for developers to build off of, but it is a little inconsistent with prior usage of rebalance callbacks.",0,0.939836859703064
43426682,165,becketqin,2015-10-29T18:35:45Z,what would happen if coordinator shuts down after this test passes?,0,0.9887951612472534
43427203,165,becketqin,2015-10-29T18:39:49Z,"minor, it might be slightly cleaner if we throw exception when some error occurs and catch the exception in handlejoingroup() and call responsecallback. we might also want to add error log message when exception is thrown.",0,0.9928372502326965
43428250,165,becketqin,2015-10-29T18:48:07Z,do we need to pass in member.memberid? can we simply pass in member?,0,0.9947595000267029
43442917,165,hachikuji,2015-10-29T20:54:28Z,"yep, good point.",1,0.954281747341156
43444426,165,hachikuji,2015-10-29T21:07:18Z,"nod, i was following the pattern of the other handlers. throwing exceptions might let us remove a little boilerplate, but either approach works for me. and i agree on logging.",0,0.7913113832473755
43449219,165,becketqin,2015-10-29T21:50:26Z,it seems fine. we always shutdown socketserver and kafkaapis before shutting down coordinator.,0,0.5791881680488586
43451430,165,becketqin,2015-10-29T22:12:19Z,the comments here seems not accurate.,0,0.61955726146698
43457097,165,becketqin,2015-10-29T23:24:31Z,what if the leader send syncgrouprequest late? should we start counting down after we send syncgroupresponse because the consumer only starts to heartbeat after syncgroupresponse is received.,0,0.9779881238937378
43664832,165,hachikuji,2015-11-02T18:50:00Z,"actually i think it's right. if the follower's metadata is different, then we force a rebalance.",0,0.9796589612960815
43665262,165,hachikuji,2015-11-02T18:53:14Z,"we start the clock after join group completion. if the leader fails to send syncgroup within one session timeout after the join group phase has completed, then we will transition to preparing rebalance (i think i have a test case for this). if the leader sends syncgroup after this transition, then it will be given a rebalance_in_progress error.",0,0.9876914620399475
1806596264,17539,apoorvmittal10,2024-10-18T14:25:57Z,"question for my understanding: do we need to this calculation? as i can see fetch params already has minbytes in request to replica manager hence isn't the response from replica manager should be empty if minbytes criteria is not satisfied? so the question arise that how do we differentiate between empty reponse from replica manager log read, if that's beacus of min bytes or there is no data in the log? in either case we should continue holding the request in purgatory? wdyt?",0,0.9854909181594849
1806619158,17539,adixitconfluent,2024-10-18T14:39:49Z,"hi , iiuc, minbytes is utilized in `replicamanager.fetchmessages` functionality [a link] not in `replicamanager.readfromlog`. the way it calculates the `accumulatedbytes` is the same way i have done it in my code ([a link]. i don't see the usage of `params.minbytes` in `readfromlog` functionality",0,0.9933556318283081
1806639708,17539,apoorvmittal10,2024-10-18T14:53:04Z,i think you are right. i also see only reference of param minbytes in fetchmessages and not in readfromlog. also the readfromlog says upto maximum in description and nothing about minbytes. then the pr change sounds good but i was wondering why do we accept complete fetchparams in readfromlog when we don't utilize something like minbytes there. not sure if we should have minbytes support in readfromlog itself. maybe out of scope of this pr. can help is with more context.,0,0.723019003868103
1806669871,17539,apoorvmittal10,2024-10-18T15:15:54Z,"hmmm, is this same for regular fetch operations as well?",0,0.9817487597465515
1806671945,17539,apoorvmittal10,2024-10-18T15:17:28Z,and why don't we want to release the partition locks from oncomplete?,0,0.9834725856781006
1806680209,17539,apoorvmittal10,2024-10-18T15:24:01Z,"in most scenarios the request might have minbytes, hence do you always want to initialize a hash map? mostly it will be overriden with `responsedata` map. so can't it be null? moreover can't it be simpy a boolean variable i.e. boolean minbytessatisfied = false if (accumulatedbytes.get() >= sharefetchdata.fetchparams().minbytes) replicamanagerfetchsatisfyingminbytes = responsedata; => if (accumulatedbytes.get() >= sharefetchdata.fetchparams().minbytes) minbytessatisfied = true; if (replicamanagerfetchsatisfyingminbytes.isempty() && !hasrequesttimedout) { => if (!minbytessatisfied && !hasrequesttimedout) { return replicamanagerfetchsatisfyingminbytes; => return collections.emptymap()",0,0.99213045835495
1806682789,17539,apoorvmittal10,2024-10-18T15:26:07Z,now we can come to this code path getting no result from `replicamanagerfetchdata`. hence is the log line still correct?,0,0.9931715726852417
1806685722,17539,apoorvmittal10,2024-10-18T15:28:25Z,"do you need this extra variable or can just write later, if needed? and then no need of else block below. replicamanagerfetchdatafromtrycomplete = replicamanagerfetchdata(topicpartitiondata, true);",0,0.99236661195755
1806689153,17539,apoorvmittal10,2024-10-18T15:31:10Z,"fetchresponsedata can still be empty, though processfetchresponse handles the empty check, is it intended? though no harm, just checking with you.",0,0.9788879752159119
1806690387,17539,apoorvmittal10,2024-10-18T15:32:10Z,what about if partitions were locked but no response in data aarived then will the lock be correctly released?,0,0.990461528301239
1806716182,17539,adixitconfluent,2024-10-18T15:53:21Z,"in this case, we want to call `sharefetchutils.processfetchresponse(sharefetchdata, fetchresponsedata, sharepartitionmanager, replicamanager)` before we want to release the locks. that part is in `oncomplete`, hence we don't release the lock",0,0.9949139356613159
1806722986,17539,adixitconfluent,2024-10-18T15:59:04Z,"yeah, it makes sense. i'll make the change.",0,0.9219223856925964
1806725239,17539,adixitconfluent,2024-10-18T16:01:03Z,"now that i think again, i should return a map with key as topic partition and value as `fetchpartitiondata` object containing 0 records and since we have not been able to satisfy all the fetch request criterias. your thoughts?",0,0.9692867398262024
1806729605,17539,adixitconfluent,2024-10-18T16:04:48Z,"yeah, since `processfetchresponse` can handle it, that's why i didn't add any check here",0,0.9889959096908569
1806735371,17539,adixitconfluent,2024-10-18T16:10:17Z,"for that case, even when the data is not received from replica manager, the fetchresponsedata should still have keys as the locked topic partitions and values as empty data, so it should work. am i wrong in that understanding?",0,0.9650581479072571
1807312461,17539,adixitconfluent,2024-10-19T12:35:26Z,"i can get rid of it, but then the variable name `replicamanagerfetchdatafromtrycomplete` won't make sense if it is getting some values in `oncomplete`. i just feel that the code is more readable this way.",0,0.9798494577407837
1807413812,17539,adixitconfluent,2024-10-19T16:31:47Z,"hi , i went through the code for oncomplete of `delayedfetch` ([a link], it seems that it returns whatever it gets from `replicamanager.readfromlog`, so the current code is correct in that case. please let me know if i am wrong. cc -",0,0.9638504385948181
1809360360,17539,apoorvmittal10,2024-10-21T19:07:23Z,should it be atomiclong?,0,0.9829587340354919
1809365166,17539,apoorvmittal10,2024-10-21T19:10:32Z,"info seems to be too much here, how helpful this log would be in info mode? can we move it to debug please.",0,0.7669436931610107
1809366048,17539,apoorvmittal10,2024-10-21T19:11:07Z,wouldn't this be too common? should we move it trace?,0,0.9505131244659424
1809378335,17539,apoorvmittal10,2024-10-21T19:17:15Z,will it not depend on `readfromlog` api response i.e. if you sent 3 partitions then is it guaranteed that replica manager will return all 3 partitions in response?,0,0.9945512413978577
1809417014,17539,apoorvmittal10,2024-10-21T19:44:11Z,should we maintain the order by `linkedhashmap` as earlier?,0,0.9949681162834167
1809422393,17539,adixitconfluent,2024-10-21T19:47:48Z,"reading `readfromlog` functionality, i don't see an indication where it doesn't return all the partitions sent to it, however i'll still make the change to use `topicpartitiondata` to be on the safe side.",0,0.988353967666626
1809669520,17539,junrao,2024-10-21T23:53:47Z,"1. this approach is ok, but probably not the most efficient. `replicamanager.readfromlog` is relatively expensive. to avoid calling it on every hwm change, the delayedfetch maintains the file position of the fetch offset and compares it with the file position of hwm to estimate the fetchable bytes. we could potentially do the same thing here. this requires us to maintain the file position for sharepartition.endoffset. 2. ideally, we need to take into account the size of those non-acquirable batches in sharepartition when estimating the fetchable bytes.",0,0.9902459383010864
1810373760,17539,apoorvmittal10,2024-10-22T09:40:25Z,thanks a lot for suggestion . this is good. i have aquestion on 2. though it's an ideal solution but the next fetch offset being prior to endoffset should be rare i.e. when some records are released or timedout. so i think we can avoid calculating non-acquirable and proceed to fetch anyways if our criteria from end offset to hwm meets. we can have the min bytes check after the fetch as currently in the pr. wdyt?,1,0.994097113609314
1810810655,17539,adixitconfluent,2024-10-22T14:11:40Z,"hi , agreed this is a much better approach. just one clarification - you mean the file position of the latest offset that was fetched for the share partition, right?",0,0.5155089497566223
1811067709,17539,junrao,2024-10-22T16:44:46Z,"yes, this sounds reasonable. we can just ignore the non-acquirable records for now. basically, we need to maintain endoffset as a `logoffsetmetadata`, which contains segment position. we can then use `logoffsetmetadata.positiondiff` to calculate the available bytes.",0,0.9843040108680725
1812510188,17539,apoorvmittal10,2024-10-23T11:13:22Z,can it reside in share module under `fetch`?,0,0.9942871928215027
1812512229,17539,apoorvmittal10,2024-10-23T11:14:53Z,"isn't by default it will be null, do we need to define it here?",0,0.9870865345001221
1812513907,17539,apoorvmittal10,2024-10-23T11:16:09Z,"you made a new class for this, shouldn't we pass that here?",0,0.9932899475097656
1812514360,17539,apoorvmittal10,2024-10-23T11:16:29Z,is it need to be default scoped?,0,0.9885872006416321
1812516782,17539,apoorvmittal10,2024-10-23T11:18:26Z,"so in a fetch result of 10 batches we should store the last batch info, is that correct? if yes then shouldn't name of variable be appropriately defined?",0,0.9937775135040283
1812517165,17539,apoorvmittal10,2024-10-23T11:18:45Z,merge with previous line.,0,0.9878349900245667
1812518313,17539,apoorvmittal10,2024-10-23T11:19:39Z,why do we need this?,0,0.9448511004447937
1812520317,17539,apoorvmittal10,2024-10-23T11:21:10Z,will this log line print anything meaningful? i don't see tostring in `fetchpartitiondata`. should we return what's required here?,0,0.9902060627937317
1812521637,17539,apoorvmittal10,2024-10-23T11:21:49Z,should it be default scoped? if used for tests then please write // visible for testing.,0,0.9946447610855103
1812523220,17539,apoorvmittal10,2024-10-23T11:22:45Z,how the exception will be handled with this method? do we have a test case when exception is thrown by this replica manager call?,0,0.993023157119751
1812747750,17539,adixitconfluent,2024-10-23T13:20:10Z,i've moved it to protected. it cannot be private since it is utilized in `delayedsharefetch`,0,0.9942300319671631
1812784514,17539,adixitconfluent,2024-10-23T13:36:51Z,"we store the last fetched offset's properties in `logoffsetmetadata` class like the message offset, file position etc. hence, naming it `latestfetchoffsetmetadata` makes more sense than `latestfetchbatchmetadata`. wdyt?",0,0.9944414496421814
1812833979,17539,AndrewJSchofield,2024-10-23T13:56:54Z,"nit: i hesitate to correct your greek, but the singular of ""criteria"" is ""criterion"". maybe ""isminbytessatisfied"" would be simpler than worrying about greek grammar.",-1,0.766250729560852
1812914606,17539,adixitconfluent,2024-10-23T14:33:31Z,i've added the handling and test case for this in my latest commit,0,0.9752723574638367
1813543008,17539,junrao,2024-10-23T20:50:30Z,"we need to check if the two offset metadata are on the same segment first before using `positiondiff`. also, we need to handle the case when hwm doesn't have offset metadata. we can just follow the logic in `delayedfetch`.",0,0.9948630928993225
1813549471,17539,junrao,2024-10-23T20:53:30Z,we need to check `sharefetchdata.fetchparams().isolation` to decide whether to use hwm or laststableoffset.,0,0.9942680597305298
1813657687,17539,junrao,2024-10-23T21:31:18Z,"it's kind of late to set the offset metadata here since we will acquire the fetch records and move the next fetch offset. this means the cached offset metadata doesn't match the next fetch offset. i was thinking of doing the following. in `trycomplete`, if the offset metadata doesn't exist, we call `replicamanager.readfromlog` to populate the offset metadata. we can then proceed with the minbyte estimation. if sharepartition.endoffset moves, we invalidate the offset metadata.",0,0.9823706150054932
1815509020,17539,junrao,2024-10-24T18:07:15Z,"the `acquire` call always comes after `delayedsharefetch.trycomplete`, which already updates `latestfetchoffsetmetadata`. so, it seems that we don't need to update `latestfetchoffsetmetadata` in `acquire`?",0,0.9952149391174316
1815510878,17539,junrao,2024-10-24T18:09:01Z,we need to reset `latestfetchoffsetmetadata` every time `endoffset` changes.,0,0.9900357723236084
1815515373,17539,junrao,2024-10-24T18:12:55Z,"it's possible that `maybeupdatefetchoffsetmetadatafortopicpartitions` calls `readfromlog`, which returns enough bytes. in that case, it's more efficient to reuse the fetched result instead of calling `readfromlog` again in `oncomplete`.",0,0.9952850937843323
1815520277,17539,junrao,2024-10-24T18:17:19Z,perhaps it's clearer to make sharepartition.latestfetchoffsetmetadata() an optional?,0,0.9943385720252991
1815531648,17539,junrao,2024-10-24T18:27:27Z,"in delayedfetch, if a partition no longer exists, we complete the operation immediately.",0,0.9911890029907227
1815542651,17539,junrao,2024-10-24T18:37:09Z,could this just be a `long`?,0,0.9935799837112427
1815548051,17539,junrao,2024-10-24T18:42:00Z,"hmm, we don't want to read all partitions if only one partition's offset metadata is missing, right?",0,0.5917771458625793
1815562399,17539,junrao,2024-10-24T18:55:14Z,"1. perhaps ""we maintain the latest fetch offset metadata to estimate the minbytes requirement more efficiently.""? 2. also, could we keep it together with `endoffset` since they are related.",0,0.9953150749206543
1815586235,17539,adixitconfluent,2024-10-24T19:18:47Z,"yeah, but in case there are multiple partitions for which offset metadata is missing, i thought that its better to make a single `readfromlog` call instead of multiple `readfromlog` calls. thus, using all the topic partitions in one call itself. wdyt?",0,0.9677800536155701
1815592778,17539,adixitconfluent,2024-10-24T19:25:07Z,"`updatelatestfetchoffsetmetadata()` is only called from `trycomplete` when we find that there is a share partition whose offset metadata is not present (because in that case only, we call `readfromlog`). however, for any other case, we can only update the `latestfetchoffsetmetadata` via `acquire` method only. else we'll have to call `readfromlog` from `trycomplete` in all scenarios to directly update share partition's `latestfetchoffsetmetadata`. anything wrong in that understanding?",0,0.9938437938690186
1815599413,17539,adixitconfluent,2024-10-24T19:31:09Z,"iiuc, everytime we fetch new records from `readfromlog`, i utilize the `logoffsetmetadata` object from the response to update the `latestfetchoffsetmetadata` object while doing the acquire. hence, this way i have the most recent fetched offset's metadata that i always update through `acquire` method. most of the time, it is going to be the endoffset's metadata itself, as soon as new data is produced to the topic partition. anything else that i need to do here?",0,0.988486647605896
1815731593,17539,junrao,2024-10-24T21:50:37Z,"hmm, if a previously acquired batch times out, sharepartition will change endoffset. this means that the cached latestfetchoffsetmetadata no longer matches the next fetch offset, right?",0,0.9833608865737915
1815739504,17539,junrao,2024-10-24T21:56:47Z,"hmm, to me `acquire` seems to be the wrong place to update `latestfetchoffsetmetadata`. we update `latestfetchoffsetmetadata` with the fetch offset and then acquire a few batches after the fetch offset. this typically moves the next fetch offset, which makes `latestfetchoffsetmetadata` useless for the next fetch.",0,0.8765308260917664
1815741519,17539,junrao,2024-10-24T21:59:31Z,maybe we can first make a pass to collect all partitions missing offset metadata and then make a single `readfromlog` with those partitions?,0,0.9948393702507019
1816504391,17539,apoorvmittal10,2024-10-25T11:20:03Z,wouldn't `fetchoffsetmetadataupdateresult` be a better name?,0,0.9946128129959106
1816509367,17539,apoorvmittal10,2024-10-25T11:24:10Z,do we need the variable name to have suffix `trycomplete`? i don't find the suffix is any helpful.,0,0.9394615292549133
1816510686,17539,apoorvmittal10,2024-10-25T11:25:23Z,"why to have method names with such suffix, are they helping? [code block]",0,0.9733176231384277
1816519200,17539,apoorvmittal10,2024-10-25T11:33:01Z,is it handled?,0,0.9860063791275024
1816530978,17539,apoorvmittal10,2024-10-25T11:43:00Z,"how frequent it is to see missing fetch offset information, mostly at start only right? they why to initialize this variable, can't it be lazily loaded, if required?",0,0.9869635701179504
1816619673,17539,apoorvmittal10,2024-10-25T12:46:27Z,so the update should be safe with multiple threads as we have acquired the lock on share partition which guards us from 2 threads trying to update the offset metadata. but we should write comments on the share partition update method that the caller of the method should ensure that share partition fetch lock is acquired prior invoking the updatelatestfetchoffsetmetadata.,0,0.9943142533302307
1816620754,17539,apoorvmittal10,2024-10-25T12:47:18Z,can it be in a separate method i.e. divide methods.,0,0.992165207862854
1816621221,17539,apoorvmittal10,2024-10-25T12:47:39Z,merge the lines.,0,0.9761901497840881
1816657075,17539,apoorvmittal10,2024-10-25T13:09:30Z,"so this iteration will always be executed for every share fetch when the `missingfetchoffsetmetadatatopicpartitions` will rarely be true, only when a new sharepartition is created. hence, i was thinking why not to have such update only on sharepartition initialization. though i understand that current `readfromlog` api requires fethchparams but is there an api which can supply the logoffsetmetadata when requested with topic partition and specific offset(start offset of share partition)? wdyt?",0,0.9801550507545471
1816661560,17539,apoorvmittal10,2024-10-25T13:12:17Z,can it go in a method please.,0,0.9926486611366272
1816667130,17539,apoorvmittal10,2024-10-25T13:16:10Z,why do we satisfy the min byte criteria if share partition is null?,0,0.9857901334762573
1816668262,17539,apoorvmittal10,2024-10-25T13:17:03Z,"should the varibale in sharepartition be optional? we always should have that, correct?",0,0.9926873445510864
1816670642,17539,apoorvmittal10,2024-10-25T13:18:48Z,"sorry, i didn't understand when we can have the offset in share partition > partition end offset?",-1,0.9875010251998901
1816678081,17539,apoorvmittal10,2024-10-25T13:22:04Z,again this will be rare hence shall we delay initiliazing linkedhashmap.,0,0.9824097156524658
1816687484,17539,apoorvmittal10,2024-10-25T13:25:21Z,can it be non-null and empty ever i.e. do you require your second condition?,0,0.9930287003517151
1816691162,17539,apoorvmittal10,2024-10-25T13:27:47Z,"can it ever occur that you have non-empty `logreadresponsefromtrycomplete` but `topicpartitiondata` came from fresh aquisition from line 98 (topicpartitiondata = acquirablepartitions();). i think never, can you just write comments for this.",0,0.9911019802093506
1816693860,17539,apoorvmittal10,2024-10-25T13:29:27Z,please correct the alignment of comments.,0,0.985049307346344
1816695469,17539,apoorvmittal10,2024-10-25T13:30:31Z,why it's optional?,0,0.9649257659912109
1816703702,17539,apoorvmittal10,2024-10-25T13:35:20Z,so if we are fetching from offset 0 and gets response from log for 0-1000 offsets then `logresult.info().fetchoffsetmetadata` contains information for 0 offset or 1000th offset i.e. which offset metadata does it hold?,0,0.9946618676185608
1816704806,17539,apoorvmittal10,2024-10-25T13:36:05Z,class comments please.,0,0.9834753274917603
1816705073,17539,apoorvmittal10,2024-10-25T13:36:17Z,empty line break please.,0,0.9577212929725647
1816711409,17539,apoorvmittal10,2024-10-25T13:40:35Z,that's my queustion with this comment [a link] do we ever get the lastfetchoffsetmetadata or we always update with fetchoffsetmetadata?,0,0.9911426305770874
1816800887,17539,adixitconfluent,2024-10-25T14:34:41Z,i can confirm this will return information about 0th offset.,0,0.9713305830955505
1816813489,17539,apoorvmittal10,2024-10-25T14:41:03Z,so this suggestion is not apt as we need the refreshed information [a link],0,0.9847350120544434
1816818571,17539,adixitconfluent,2024-10-25T14:44:21Z,"hi , i understand your point now. here's my proposed solution changes- 1. remove update of `latestfetchoffsetmetadata` via `acquire` method 2. in `oncomplete`, after i complete the call of `sharefetchutils.processfetchresponse`(which internally completes the call of `acquire` method), i will do a `readfromlog` for `topicpartitiondata` with their latest fetch offset and update the share partition's `latestfetchoffsetmetadata`. note this call to `readfromlog` will always happen despite the `trycomplete` `readfromlog` happens or not. please let me know what you think of this approach.",0,0.7217790484428406
1816827231,17539,adixitconfluent,2024-10-25T14:49:08Z,"hi , understood, so if there is any calls to acknowledge/acquisition lock timeout/release acquired records on session close, i should update the latestfetchoffsetmetadata to `optional.empty()`. then when the next trycomplete call comes, it will update the `latestfetchoffsetmetadata` and we will have the most recent result. or is my understanding incorrect?",0,0.9796482920646667
1816829826,17539,adixitconfluent,2024-10-25T14:50:57Z,"i did it because the value can be null, so we thought it would be better to keep it as optional [a link]",0,0.9906445741653442
1816830605,17539,adixitconfluent,2024-10-25T14:51:32Z,"you're right, i don't need it.",0,0.8228729367256165
1816832978,17539,adixitconfluent,2024-10-25T14:52:57Z,"not necessary, it can be null as well. hence, we use optional here.",0,0.9914302229881287
1816851362,17539,adixitconfluent,2024-10-25T15:02:51Z,"it might not be true ever in case we are using `fetchisolation.high_watermark`, but i think it can be true in case we use `fetchisolation.log_end` and `fetchisolation.txn_committed` which might be used in the future in share fetch requests.",0,0.9940072298049927
1817193502,17539,junrao,2024-10-25T18:39:55Z,"i was thinking about an alternative approach by maintaining `latestfetchoffsetmetadata` every time we update `endoffset`. in the common case, we move `endoffset` to `lastoffset` of an acked batch. the file position in `latestfetchoffsetmetadata` can just be updated by adding the batch size to the file position of the previous `latestfetchoffsetmetadata`. this way, in the common case, we only need to call `readfromlog` once per fetch request, instead of twice (once for getting `latestfetchoffsetmetadata` and another for getting the data) in the current approach.",0,0.9924907088279724
1817933790,17539,adixitconfluent,2024-10-26T21:36:55Z,"hi , i am not sure if i understand the approach completely. iiuc, 1. i agree with the common case where during `oncomplete` we can update the file position by directly adding the batch size. but, there are cases where we return true from `isminbytessatisfied` if `fetchoffsetmetadata` was on a different segment than the `endoffsetmetadata` ([a link]. in those case, we don't know the number of bytes that got accumulated in the response. same goes for the case `fetchoffsetmetadata.messageoffset > endoffsetmetadata.messageoffset`, how do we know whta is the number of bytes to add? 2. i am assuming that with this approach, we do not need to do any handling during acquisition lock timeout/acknowledgements/release acquired records on session close. please correct me if i am wrong. ps - thanks a lot for taking out the time to explain me and reviewing this pr.",0,0.9783040285110474
1817943465,17539,junrao,2024-10-26T22:31:36Z,": here is the rough idea. 1. if endoffset advances forward, we incrementally update its file position by the size of batches going forwarded. 2. the tricky thing is how the offset metadata picks up a new segment being rolled. as we increase the file position, endoffset will eventually reach the baseoffset of the next segment. this means that the next fetch request will be satisfied immediately since the hwm is on a different segment. when we acquire the data (for batches at the beginning of the segment), we can check if the offset metadata in the fetch data has the same offset as endoffset but on a different segment. if so, we update the offset segment of endoffset. 3. if the endoffset goes backward (due to timeout/acknowledgements/release) or endoffset is being initialized for the first time, we just call readfromlog to get the offset metadata. 4. `trycomplete` will have the same logic to deal with the uncommon cases where the offset metadata is not available or the offset metadata is on the same segment. the only difference is that it won't update latestfetchoffsetmetadata any more since the update happens when endoffset changes.",0,0.9293518662452698
1818144589,17539,junrao,2024-10-27T17:18:30Z,"while this alternative approach is more efficient, it's probably also more complicated. so, it's also ok to just take the current approach to start with. in the current approach, (1) if any call moves `endoffset`, we reset the `latestfetchoffsetmetadata` to optional.empty(). in `trycomplete`, if `latestfetchoffsetmetadata` is empty, we call `readfromlog` and update `latestfetchoffsetmetadata`.",0,0.9936351776123047
1818157944,17539,adixitconfluent,2024-10-27T18:40:29Z,"yes, it is handled here [a link]",0,0.9884964227676392
1818158187,17539,adixitconfluent,2024-10-27T18:41:37Z,the explanation is present in this conversation thread [a link],0,0.9883912801742554
1818159160,17539,adixitconfluent,2024-10-27T18:47:48Z,"hi , agreed with the simpler approach. i have made the following changes in my latest commit- i reset the `latestfetchoffsetmetadata` to optional.empty() if - 1. `acquire()` results in non-empty acquired records in `sharefetchutils`. 2. acquisition lock timeout is called. 3. release acquired records on session close is called. i haven't made the change in `acknowledge()` method of `sharepartition`, since in the common case all the `acquired` records will moved to `acknowledged` state and endoffset doesn't change then. this functionality has been added in previous commits. please review my pr whenever you can. thanks!",0,0.9105846285820007
1819587266,17539,junrao,2024-10-28T18:52:02Z,could we make fetchoffsetmetadata optional instead of relying on `null`?,0,0.9945566654205322
1819590569,17539,junrao,2024-10-28T18:54:40Z,this is getting a bit hard to track since we need to make this call in all places where endoffset changes. could we have a method for updating both `endoffset` and `latestfetchoffsetmetadata`? then we can replace all code that changes `endoffset` with this method.,0,0.6853396892547607
1819592494,17539,junrao,2024-10-28T18:55:41Z,latestfetchoffsetmetadata => fetchoffsetmetadata?,0,0.9908604621887207
1819610603,17539,junrao,2024-10-28T19:10:15Z,it's probably clearer to put those in an `else` clause?,0,0.994310736656189
1819618734,17539,junrao,2024-10-28T19:16:42Z,we could just initialize `missingfetchoffsetmetadatatopicpartitions` with `new linkedhashmap<>()`. ditto in `combinelogreadresponse`.,0,0.995171844959259
1819637938,17539,junrao,2024-10-28T19:27:56Z,"hmm, it would be better for `logreadresponse` to only be empty, but never `null`.",0,0.9909425377845764
1819645608,17539,junrao,2024-10-28T19:34:59Z,do we need this wrapper class `fetchpartitionoffsetdata`? it seems that it's simpler for `readfromlog` to `return map `. we can then convert `logreadresult` to `map ` in `oncomplete`.,0,0.9946104288101196
1819664109,17539,junrao,2024-10-28T19:48:44Z,"every passed in partition to `readfromlog` will be included in the response. so, there is no need to pass in both `missingfetchoffsetmetadatatopicpartitions` and `replicamanagerreadresponsedata`. we do want to check the error code for each partition. in regular fetch, if any partition has an error code, we send a response immediately. we can just do the same here.",0,0.993891716003418
1819665350,17539,junrao,2024-10-28T19:49:52Z,i thought we agreed that we want to send a response immediately if a sharepartition can't be found. is that handled?,0,0.990858256816864
1819666995,17539,junrao,2024-10-28T19:51:27Z,could we just make a single `sharepartitionmanager.sharepartition` call per `trycomplete` to avoid having to check null repeatedly?,0,0.9940651655197144
1819670828,17539,junrao,2024-10-28T19:54:58Z,"ideally, we need to handle the exception at the partition level in the caller.",0,0.9860135912895203
1819677154,17539,junrao,2024-10-28T20:01:02Z,"this condition seems unnecessary. we need to set `logreadresponse` as long as `fetchoffsetmetadataupdateresult.replicamanagerreadresponse` is not empty, right?",0,0.9864295721054077
1824747173,17539,adixitconfluent,2024-10-31T16:04:06Z,"hi , i had updated it at a different place but now i've added that as the first step in trycomplete ([a link]. as you had also mentioned, this prevents us from making multiple share partition null checks at different places in the code.",0,0.9887197613716125
1824903292,17539,junrao,2024-10-31T17:42:42Z,"we are still calling `sharepartitionmanager.sharepartition` in multiple places (`anysharepartitionnolongerexists`, `acquirablepartitions`, `isminbytessatisfied` and `maybeupdatefetchoffsetmetadatafortopicpartitions`), each of which needs to handle null sharepartition since the sharepartition could disappear any time. i was thinking that we could get all sharepartitions once at the beginning and pass them around to other methods. this way, the null handling is only done once.",0,0.9915319085121155
1824914771,17539,junrao,2024-10-31T17:52:44Z,maybeupdatefetchoffsetmetadatafortopicpartitions => maybereadfromlogandupdatefetchoffsetmetadata ?,0,0.9954085946083069
1824931761,17539,junrao,2024-10-31T17:59:44Z,"could we just return an empty map? this way, the caller doesn't need to do the null check.",0,0.9910562038421631
1824937560,17539,junrao,2024-10-31T18:01:45Z,topicpartitiondatafromtrycomplete => partitionstocomplete ? logreadresponse => partitionsalreadyfetched ?,0,0.9929580688476562
1824959019,17539,junrao,2024-10-31T18:09:14Z,this code can be a bit more concise. [code block],0,0.9866325259208679
1826092331,17539,adixitconfluent,2024-11-01T17:19:18Z,"hi , i have changed the exception handling to a top level exception handling in `trycomplete` to combat with this scenario.",0,0.9853698015213013
1826157479,17539,junrao,2024-11-01T18:24:00Z,there is no need to pass in `fetchoffsetmetadata` since it's always empty. updateendoffsetandfetchoffsetmetadata => updateendoffsetandresetfetchoffsetmetadata?,0,0.9944729208946228
1826160028,17539,junrao,2024-11-01T18:26:20Z,let's be consistent with the usage of `this`. most other places don't use `this`.,0,0.9918109178543091
1826160780,17539,junrao,2024-11-01T18:27:06Z,all callers hold the lock. so we could remove the locking here and add a comment that the caller is expected to hold the lock when calling this method.,0,0.991259753704071
1826166921,17539,junrao,2024-11-01T18:33:29Z,this problem is still there?,0,0.9179763197898865
1826169337,17539,junrao,2024-11-01T18:35:52Z,this check is unnecessary since partitionsalreadyfetched initializes to empty.,0,0.9919167160987854
1826174394,17539,junrao,2024-11-01T18:41:05Z,should we reset `partitionstocomplete` and `partitionsalreadyfetched` too when we release the locks?,0,0.9954720735549927
1826180030,17539,junrao,2024-11-01T18:47:20Z,should we just assign the return value to partitionstocomplete directly? we already acquired the locks for those partitions and partitionstocomplete is the only place to track them for releasing.,0,0.9927733540534973
1826183958,17539,junrao,2024-11-01T18:51:35Z,this code can be a bit simpler. [code block],0,0.9871004819869995
1826185041,17539,junrao,2024-11-01T18:52:48Z,updatefetchoffsetmetadataformissingtopicpartitions => updatefetchoffsetmetadata ?,0,0.995128870010376
1826187006,17539,junrao,2024-11-01T18:54:51Z,perhaps do this in the caller? then the purpose of the method is simpler and the method name can just be `maybereadfromlog`.,0,0.9952946305274963
1826561286,17539,adixitconfluent,2024-11-02T12:32:50Z,"hi , we can do that but then once we are in the `else` of this check -` if (anytopicidpartitionhaslogreaderror(replicamanagerreadresponse) || isminbytessatisfied(topicpartitiondata))`, after we have release the partitions lock, we also need to do `partitionstocomplete.clear()`. hence, i've tried to avoid doing this by assigning `partitionstocomplete` once we are sure that we can do a `forcecomplete()`",0,0.9817854762077332
1826562798,17539,adixitconfluent,2024-11-02T12:43:59Z,"hi , i am not actually too sure if i definitely need this check. ideally, i don't think there can be any value in `sharepartitions` which can be null, but this [a link] in `sharepartitionmanager` is confusing me, plus there is this jira [a link] where we will be refactoring share partition initialization. so, this can act as a safety check for now, and i can remove this in a future pr once the refactor is complete, and we are sure we don't send null share partitions. what do you think? cc -",0,0.8833285570144653
1828181101,17539,junrao,2024-11-04T18:14:18Z,sharefetchdata => partitionstocomplete ? partitionstocomplete => partitionsacquired ?,0,0.9910215735435486
1828190239,17539,junrao,2024-11-04T18:22:08Z,it's kind of weird for this method to return the input. it's more natural for this method to return nothing.,-1,0.9886404275894165
1828196542,17539,junrao,2024-11-04T18:26:13Z,"hmm, when we hit an exception, do we guarantee that `partitionstocomplete` has been set?",0,0.98951655626297
1828254033,17539,junrao,2024-11-04T19:14:00Z,"we need to return an optional `fetchoffsetmetadata` if the value returned from `nextfetchoffset` changes. if `findnextfetchoffset` is false, `nextfetchoffset` returns a value based on endoffset. this case is already covered in this pr. if `findnextfetchoffset` is true, `nextfetchoffset` returns a value not depending on endoffset. so, we should return empty here if `findnextfetchoffset` is true.",0,0.9954458475112915
1828280371,17539,junrao,2024-11-04T19:36:40Z,"it seems that sharepartitions is always a subset of sharefetchdata.partitionmaxbytes()? if that's the case, i agree that we don't need anysharepartitionnolongerexists. however, it would be useful to make sure that the caller passes in sharepartitions and sharefetchdata.partitionmaxbytes() with the same set of partition keys.",0,0.992425799369812
1828303188,17539,junrao,2024-11-04T19:55:05Z,this comment doesn't match the code.,0,0.932589054107666
1828307832,17539,junrao,2024-11-04T19:59:05Z,quite a long name. how about sth like testtrycompletereturnsfalsewhenminbytesnotsatisfied?,0,0.7565488815307617
1828314722,17539,junrao,2024-11-04T20:04:40Z,"hmm, not sure how this test is different from the next one. if this is testing fetching for the first time, sp0.fetchoffsetmetadata() should return empty, right?",0,0.7155392169952393
1828321808,17539,junrao,2024-11-04T20:10:46Z,"could we change `combinelogreadresponse` to also take `partitionsalreadyfetched`? this way, we can get rid of `delayedsharefetch.updatelogreadresponse`.",0,0.9957192540168762
1828532884,17539,apoorvmittal10,2024-11-04T23:28:40Z,we initialize the variable in constructor then re-assign while creating another linkedhashmap in acquirablepartitions() method. are we are initializing `partitionstocomplete` here to save null check? can't we re-use already initialized linkedhashmap()?,0,0.9930134415626526
1828533813,17539,apoorvmittal10,2024-11-04T23:30:01Z,again we reset `partitionsalreadyfetched` to response from `replicamanagerreadresponse`. why to have such instances created when anyways we have to re-assign?,0,0.9921561479568481
1828538998,17539,apoorvmittal10,2024-11-04T23:37:46Z,"we have now passed `sharepartitions` map which contains topicidpartition and sharepartition itself then why are we iterating on `sharefetchdata.partitionmaxbytes().keyset()` and doing a null check, why not to iterate in `sharepartitions` map itself? also make the map of `sharepartitions` in spm as of type linkedhashmap then.",0,0.9946527481079102
1828539471,17539,apoorvmittal10,2024-11-04T23:38:32Z,same elsewhere.,0,0.9824956655502319
1828542474,17539,apoorvmittal10,2024-11-04T23:43:20Z,"shouldn't we iterate on `sharepartitions` map passed in delayed share fetch which will guarantee that sharepartition cannot be null it can only be fenced (fenced handling has been separate), hence no null check is required. also no `anysharepartitionnolongerexists()` method call is required.",0,0.995482325553894
1828547060,17539,apoorvmittal10,2024-11-04T23:50:42Z,"nit: i personally find the code hard to read with nested if/else blocks, same is the case here. though i leave it on you. ``` if (topicpartitiondata.isempty()) { log.trace(""can't acquire records for any partition in the share fetch request for group {}, member {}, "" + ""topic partitions {}"", sharefetchdata.groupid(), sharefetchdata.memberid(), sharefetchdata.partitionmaxbytes().keyset()); return false; } // in case, fetch offset metadata doesn't exist for one or more topic partitions, we do a // replicamanager.readfromlog to populate the offset metadata and update the fetch offset metadata for // those topic partitions. map replicamanagerreadresponse = updatefetchoffsetmetadata(maybereadfromlog(topicpartitiondata)); if (!anytopicidpartitionhaslogreaderror(replicamanagerreadresponse) && !isminbytessatisfied(topicpartitiondata)) { log.debug(""minbytes is not satisfied for the share fetch request for group {}, member {}, "" + ""topic partitions {}"", sharefetchdata.groupid(), sharefetchdata.memberid(), sharefetchdata.partitionmaxbytes().keyset()); releasepartitionlocks(topicpartitiondata.keyset()); return false; } partitionstocomplete = topicpartitiondata; partitionsalreadyfetched = replicamanagerreadresponse; .... ....",0,0.9106868505477905
1828550191,17539,apoorvmittal10,2024-11-04T23:56:01Z,there are 2 checks in the if condition (anytopicidpartitionhaslogreaderror and isminbytessatisfied) but the log says that minbytes criteria is not satified. i this correct log statement?,0,0.991188645362854
1828552140,17539,apoorvmittal10,2024-11-04T23:59:15Z,we are re-assigning the already initalized variables in constructor. i would say we should have null check handling in `oncomplete` rather creating resources which never gets utilized.,0,0.9937072396278381
1828561128,17539,apoorvmittal10,2024-11-05T00:14:37Z,so did we not chose to implement [a link] rather initialize with linkedhashmap which will hardly be filled?,0,0.9933905601501465
1828563750,17539,apoorvmittal10,2024-11-05T00:18:54Z,shouldn't the name be `maybeupdatefetchoffsetmetadata` as it depends on the log read result?,0,0.9949499368667603
1828564729,17539,apoorvmittal10,2024-11-05T00:20:32Z,nit: will `foreach` be more convenient here then you don't need to call entry.getkey and entry.getvalue?,0,0.9911240339279175
1828566030,17539,apoorvmittal10,2024-11-05T00:23:01Z,isn't the log incorrect as it says the the log does not contain topicidpartition rather the response exists but it errored. also do you need to log `replicamanagerlogreadresult` or complete `replicamanagerreadresponsedata`? shouldn't we be logging former which corresponds to topic id partition?,0,0.9902927875518799
1828571399,17539,apoorvmittal10,2024-11-05T00:31:55Z,seems an incorrect error handling of release acquired partitions to me. say line 155 acquires partitions and `topicpartitiondata` is set. and we get an exception in `isminbytessatisfied` method (which anyways call getpartitionorexception method) or elsewhere then the locks released at line 193 will not release any locks as they are invoked on `partitionstocomplete` which is not yet set. moreover if forcecomplete call is successful then the acquired partitions will anyways not be released.,0,0.9471081495285034
1828573589,17539,apoorvmittal10,2024-11-05T00:35:25Z,what meant was that it should not be a top level rather partition level error.,0,0.9290612936019897
1828579315,17539,apoorvmittal10,2024-11-05T00:45:30Z,i understand there can't be concurrent calls to trycomplete but i didn't get this comment. though forcecomplete() cannot be called twice. but forcecomplete() on expiration can be on different thread and trycomplete() on different (that's my understanding as per delayedoperation code i have seen) can this change any behaviour here?,0,0.9854985475540161
1828580776,17539,apoorvmittal10,2024-11-05T00:47:59Z,"can be merged together. ``` sharefetchdata.future().complete(sharefetchutils.processfetchresponse(sharefetchdata, fetchpartitionsdata, sharepartitionmanager, replicamanager));",0,0.9940729737281799
1828758874,17539,adixitconfluent,2024-11-05T05:45:48Z,"my bad, i've corrected it.",-1,0.9887192845344543
1828775451,17539,adixitconfluent,2024-11-05T06:04:52Z,"my bad, you're right, i've adjusted the mock to return `optional.empty()` for the first time and `optional.of(new logoffsetmetadata(0, 1, 0))` for the second time (post `readfromlog` call)",-1,0.9687843918800354
1828820632,17539,adixitconfluent,2024-11-05T06:55:13Z,"hi , you're right, i've changed the line to `releasepartitionlocks(topicpartitiondata.keyset())`",0,0.9108558297157288
1828824435,17539,adixitconfluent,2024-11-05T06:59:40Z,"yes, there have been comments above where i left some variables as null, and it was pointed out that i need to initialize them to avoid null checks at different places, then we just need to do empty checks.. hence, i've implemented it in this manner.",0,0.9795520901679993
1828825732,17539,adixitconfluent,2024-11-05T07:01:05Z,"same reason as above, we are avoiding any null checks. we just check for empty scenarios by doing this.",0,0.9921389222145081
1828831006,17539,adixitconfluent,2024-11-05T07:06:21Z,"i have been asked to add else blocks in the above comments on this pr, hence i don' think i should change it again. [a link]",0,0.9694897532463074
1828836294,17539,adixitconfluent,2024-11-05T07:12:01Z,"now, we reset fetchoffsetmetadata everytime the `endoffset` changes (see the usages of function `updateendoffsetandresetfetchoffsetmetadata` in `sharepartition`). so, it can be frequent now that the fetchoffsetmetadata is empty. [a link]",0,0.9947758913040161
1828845131,17539,adixitconfluent,2024-11-05T07:20:53Z,"since, i am using `continue` in the loop, i prefer to do it using for instead of foreach.",0,0.9852598905563354
1828852012,17539,adixitconfluent,2024-11-05T07:27:04Z,"yes, the log statement is correct because because `isminbytessatisfied` can run only if `anytopicidpartitionhaslogreaderror` returns false. we should only check `isminbytessatisfied` if `anytopicidpartitionhaslogreaderror` returns false. if `anytopicidpartitionhaslogreaderror` return true, then we do a `forcecomplete`.",0,0.9928024411201477
1828853882,17539,adixitconfluent,2024-11-05T07:28:50Z,"my bad, you're right about both.",-1,0.9878656268119812
1828860825,17539,adixitconfluent,2024-11-05T07:35:27Z,"you're right, i've changed the line to `releasepartitionlocks(topicpartitiondata.keyset())`. if the `forcecomplete` is successful, then the partition locks are released from `oncomplete` finally block and it doesn't concern here.",0,0.9693773984909058
1828877645,17539,adixitconfluent,2024-11-05T07:50:46Z,"what i mean is that `partitionsalreadyfetched` value can't be changed once we enter this point in `oncomplete` via `forcecomplete` either by expiration or by a `trycomplete` successful call. iiuc, `forcecomplete` uses this `atomicboolean` variable `completed` which is used as locking mechanism for `forcecomplete`. this should ensure atomicity of global variables between `trycomplete` and `forcecomplete` we use in `delayedsharefetch`. i'll change the comment to explain this better.",0,0.9924582242965698
1828902626,17539,adixitconfluent,2024-11-05T08:10:20Z,"yes, i'll remove `anysharepartitionnolongerexists()` and also iterate on `sharepartitions` rather than using `sharefetchdata.partitionmaxbytes()`. will remove the null checks from our code.",0,0.9940347075462341
1829020183,17539,adixitconfluent,2024-11-05T09:31:37Z,"hey , we are doing partition level error handling in `oncomplete` using `sharepartitionmanager.handlefetchexception`. when we get an exception in this line `replicamanager.getpartitionorexception`, we directly call `forcecomplete` (mentioned in above comments), and that does a partition level handling.",0,0.9925345182418823
1829235324,17539,apoorvmittal10,2024-11-05T12:03:46Z,"if the concern is with additional null check then i would recommend general helper methods. my concern is with creating additional maps when they are always re-referenced. ``` private void addtonullablemap(map map, k key, v value) { if (map == null) { map = new linkedhashmap<>(); } map.put(key, value); } private boolean ismapempty(map map) { return map == null || map.isempty(); }",0,0.9930821061134338
1829237621,17539,apoorvmittal10,2024-11-05T12:05:33Z,i leave it on to decide then.,0,0.962911069393158
1829240438,17539,apoorvmittal10,2024-11-05T12:07:57Z,"it's missing yet, you can log a jira for me to fix as i am doing handling anyways.",0,0.9798399806022644
1829256794,17539,adixitconfluent,2024-11-05T12:19:58Z,logged a jira [a link] for the same.,0,0.9900215268135071
1830198129,17539,junrao,2024-11-05T23:15:54Z,why is this a linkedhashmap instead of just a hashmap?,0,0.9895405173301697
1830199934,17539,junrao,2024-11-05T23:18:33Z,"this is actually a super set of the partitions to complete. so, it's better to just keep the name sharefetchdata. it would be useful to add a comment that the partitions to be completed are given by sharepartitions and is a subset of sharefetchdata.",0,0.9932284951210022
1830201006,17539,junrao,2024-11-05T23:20:05Z,why is this a linkedhashmap instead of just a hashmap?,0,0.9895405173301697
1830203044,17539,junrao,2024-11-05T23:23:08Z,missingfetchoffsetmetadatatopicpartitions => partitionsmissingfetchoffsetmetadata?,0,0.9910836219787598
1830208462,17539,junrao,2024-11-05T23:31:16Z,this can be a bit simpler. [code block],0,0.9892648458480835
1830209083,17539,junrao,2024-11-05T23:32:13Z,anytopicidpartitionhaslogreaderror => anypartitionhaslogreaderror ?,0,0.9853276014328003
1830230584,17539,junrao,2024-11-06T00:06:59Z,"this part of the exception is still quite confusing to me. if we hit the exception, should we release the locks before calling forcecomplete()? otherwise, `forcecomplete` will try to acquire the same locks again, but can't. it will also help to narrow the try/catch to where the exception can be thrown.",-1,0.8207823038101196
1830231877,17539,junrao,2024-11-06T00:09:06Z,"we can skip clearing these two maps here since the operation is completed at this point. in `oncomplete()`, we don't clear these two maps. so, this will make the behavior more consistent.",0,0.99326092004776
1830238005,17539,junrao,2024-11-06T00:19:06Z,"this is an existing issue. in the line below, we are logging for each partition, but sharefetchdata contains the full request. [code block]",0,0.993831992149353
1830242539,17539,junrao,2024-11-06T00:26:42Z,testtrycompletereturnsfalsewhenminbytesnotsatisfiedonfirstfetch => testtrycompletewhenminbytesnotsatisfiedonfirstfetch?,0,0.9939415454864502
1830242838,17539,junrao,2024-11-06T00:27:17Z,testtrycompletereturnsfalsewhenminbytesnotsatisfiedonlatestfetch => testtrycompletewhenminbytesnotsatisfiedonsubsequentfetch ?,0,0.9943968057632446
1830269891,17539,junrao,2024-11-06T01:14:59Z,"hmm, apoorv had a good point in his comment ([a link] there seems to be a potential problem. it's possible that thread1 calls `trycomplete`, finds `completed` to be false, and is about to set `partitionsalreadyfetched`. the expiration thread then calls `forcecomplete` and sets `completed` to true and proceeds to here. now, thread1 continues and updates `partitionsalreadyfetched`. the expiration thread will pick up the wrong `partitionsalreadyfetched`.",0,0.9723499417304993
1830395752,17539,adixitconfluent,2024-11-06T05:07:55Z,"yes, i think changing the log line to below makes more sense. [code block]",0,0.9864306449890137
1830410313,17539,adixitconfluent,2024-11-06T05:31:34Z,"makes sense, i've changed the catch block to [code block]",0,0.9759844541549683
1830454251,17539,adixitconfluent,2024-11-06T06:27:58Z,"hi jun, reading online regarding the performance of linkedhashmap and hashmap - linkedhashmap offers better performance when iterating through elements since they maintain an ordered entry list, while a hashmap offers better performance when accessing large datasets. furthermore, when storing objects, linkedhashmap stores objects in key-value pairs, while hashmap stores them in hash table. the type of key used also affects performance. since now we are iterating over `sharepartitions` within the function `acquirablepartitions`, i thought it would be more efficient to use linkedhashmap over hashmap.",0,0.9725639224052429
1830461947,17539,adixitconfluent,2024-11-06T06:36:58Z,"hi , i've created a ticket [a link] to track this issue and if it fine to you, i would prefer to address the issue in a future pr.",0,0.8622354865074158
1830468964,17539,adixitconfluent,2024-11-06T06:44:58Z,"similar reason as [a link], i did it for performance efficiency. we are iterating over `partitionsacquired` in `releasepartitionlocks`, hence i thought it would be more efficient to use linkedhashmap over hashmap.",0,0.9873782992362976
1831062681,17539,apoorvmittal10,2024-11-06T13:56:10Z,the reason i suggested to use linkedhashmap was to maintain the fetch order of partitions. as per kip - [a link] i will add the rotation in sharepartitionmanager to ensure the behaviour.,0,0.9930199980735779
1831731314,17539,junrao,2024-11-06T21:26:53Z,"if ordering is important, should we explicitly define it as linkedhashmap in all the places?",0,0.9942767024040222
1831742440,17539,junrao,2024-11-06T21:37:58Z,should we reset partitionsacquired and partitionsalreadyfetched?,0,0.9942013621330261
1831747806,17539,junrao,2024-11-06T21:43:40Z,let's add a comment that the minbytes estimation currently assumes the common case where all fetched data are acquirable.,0,0.9931765198707581
1831878254,17539,apoorvmittal10,2024-11-07T00:08:42Z,"yeah, good point. we should.",1,0.8148512840270996
1832911918,17539,junrao,2024-11-07T15:47:22Z,"since the ordering is important, let's use linkedhashmap.",0,0.9885604977607727
1832912856,17539,junrao,2024-11-07T15:47:55Z,"since the ordering is important, let's use linkedhashmap.",0,0.9885604977607727
1832915380,17539,junrao,2024-11-07T15:49:24Z,"since the ordering is important, let's use linkedhashmap.",0,0.9885604977607727
1832921605,17539,junrao,2024-11-07T15:52:49Z,this means `trycomplete` will never get non-empty `fetchoffsetmetadata` and its calculation of minbytes will be off. we need to think through how to address this.,0,0.9663143754005432
111506681,2849,mjsax,2017-04-13T23:26:33Z,why not using validatetransactionalid here ?,0,0.9856145977973938
111517794,2849,junrao,2017-04-14T01:40:50Z,"every time the epoch advances, it seems that we need to write the transactionalid mapping message to the transactional log and we want to write that in epoch order since the transactional log is a compacted topic.",0,0.9926221370697021
111517806,2849,junrao,2017-04-14T01:41:01Z,"in the design, the epoch will wrap around.",0,0.9583561420440674
111517818,2849,junrao,2017-04-14T01:41:12Z,could we rename the method to sth like gettransactionstate?,0,0.9949454665184021
111517825,2849,junrao,2017-04-14T01:41:19Z,"hmm, we need to add the transactionalid -> pid mapping to the transactional log, right?",0,0.9881524443626404
111517832,2849,junrao,2017-04-14T01:41:26Z,a few unused imports such as kafkaexception and random.,0,0.9703974723815918
111517837,2849,junrao,2017-04-14T01:41:32Z,$error => errors: $error ditto for line in 1412.,0,0.9544336199760437
111528069,2849,junrao,2017-04-14T04:32:31Z,"hmm, how is transactionmetadata.timestamp used? if it's intended to expire a transaction, should we keep the time when the first partition is added? we probably also want to rename the field to sth like txnstarttime to make it clear.",0,0.9881407022476196
111528074,2849,junrao,2017-04-14T04:32:39Z,"hmm, is it intentional to use acks =1 instead of acks=-1? if so, could we add a comment how the potential data loss is dealt with?",0,0.9760368466377258
111528088,2849,junrao,2017-04-14T04:33:00Z,"hmm, in the design doc, the key for transactional status message is the following. is the doc outdated? is it true that we are combining the transactional status message and the transactionalid mapping message into a single one? key => version type pid version => 0 (int16) type => 1 (int16) pid => int64",0,0.9925565719604492
111528094,2849,junrao,2017-04-14T04:33:07Z,"in the design doc, the value for transactional status message is the following. is the doc outdated? value => version epoch status [topic [partition]] version => 0 (int16) epoch => int16 status => byte topic => bytes partition => int32",0,0.994272768497467
111528102,2849,junrao,2017-04-14T04:33:14Z,"the comment in line 38 doesn't include txn_timestamp_field. also, could we add a doc for each field?",0,0.9943901896476746
111528120,2849,junrao,2017-04-14T04:33:41Z,"hmm, what's the default txntimeout in the producer? the server side default is 15 minutes, definitely too long for a timeout for the callback during log append.",0,0.912752091884613
111653276,2849,junrao,2017-04-15T00:34:08Z,do we still need this object?,0,0.9899038076400757
111653293,2849,junrao,2017-04-15T00:34:35Z,"hmm, it seems that if the connection is not ready, we should just wait until it's ready or until the request timeout has been reached, instead of sending an error back immediately.",0,0.8210116624832153
111653317,2849,junrao,2017-04-15T00:35:10Z,"hmm, i am wondering if checks like this are synchronized properly. for example, the following sequence seems possible. (1) handleaddpartitionstotransaction() is called and validatetransactionalid() check passes. (2) leader of the partition changes to a different broker and changes back. (3) now txnmanager.appendtransactiontolog() may succeed but transactionstatemanager may still be loading the transaction state.",0,0.9881343245506287
111653333,2849,junrao,2017-04-15T00:35:27Z,"hmm, is it possible for txnmanager.gettransaction() to return none because leader change in the transaction topic?",0,0.9913195967674255
111653336,2849,junrao,2017-04-15T00:35:33Z,"map { case (topic, partitionids) .. } ?",0,0.991411566734314
111653338,2849,junrao,2017-04-15T00:35:37Z,"""pid mapping message"" seems no longer valid",0,0.987400472164154
111653340,2849,junrao,2017-04-15T00:35:40Z,pidmessageformatter => transactionlogformatter ?,0,0.9931123852729797
111653344,2849,junrao,2017-04-15T00:35:45Z,key => transactionalid ?,0,0.9903889298439026
111653357,2849,junrao,2017-04-15T00:35:56Z,"currently, there are a couple of cases when the following illegalstateexception is thrown. (1) a producer times out on a commit/abort request and resends the request on a different socket channel. (2) a different producer has initialized the pid on the same transactional id. it seems that in both cases, perhaps we want to send back a retriable error (e.g., coordinatorbusy) to that the client so that it can retry until successful?",0,0.979904294013977
111653362,2849,junrao,2017-04-15T00:36:02Z,this is not the replica fetcher.,0,0.9869929552078247
111653364,2849,junrao,2017-04-15T00:36:06Z,do we need this tag since we know this thread is from this broker.,0,0.9875103235244751
111653370,2849,junrao,2017-04-15T00:36:17Z,"since both the request and the response will be small, perhaps we could just use the default receive buffer.",0,0.989339292049408
111653378,2849,junrao,2017-04-15T00:36:30Z,"not sure if this is needed, but should we ensure that we send writetxnmarkersrequest with a lower coordinatorepoch before a higher one?",0,0.985943078994751
111653405,2849,junrao,2017-04-15T00:36:48Z,"(1) the reason for the disconnect could be that the current leader is down and a new leader is elected. so, we should go through the path dealing with errors.not_leader_for_partition to rediscover a potential new broker to send the request to. (2) not sure if this truly needed, but do we need to ensure that the ordering of controller epoch is preserved during re-enqueue?",0,0.9913941025733948
111653412,2849,junrao,2017-04-15T00:36:58Z,"since there are different types of epochs now, could we name this coordinatorepoch to make it clear?",0,0.9926003813743591
111653448,2849,junrao,2017-04-15T00:37:22Z,partitionlock gives people the impression that this is a lock for a transaction topic partition. perhaps rename this to sth like statelock?,0,0.9890854954719543
111653453,2849,junrao,2017-04-15T00:37:30Z,there doesn't seem be a corrupted list?,0,0.953316867351532
111653475,2849,junrao,2017-04-15T00:37:53Z,"hmm, shouldn't we load up to log end offset instead of hw? the latter can be slightly smaller than log end offset and in that case, we may miss the portion of the log between log end offset and hw.",0,0.9690877795219421
111653484,2849,junrao,2017-04-15T00:38:10Z,"hmm, ownedpartitions is updated in the scheduler, which means when this method returns, there is no guarantee that ownedpartitions has been updated. then, a client could still update the transaction log even after handletxnemigration() is called? ditto in loadtransactionsforpartition(0.",0,0.9895939826965332
111653491,2849,junrao,2017-04-15T00:38:17Z,"hmm, invalid_fetch_size seems to be for fetch requests, will log append throw this?",0,0.9617704749107361
111653493,2849,junrao,2017-04-15T00:38:25Z,"not clear what "" since the metadata does not match anymore"" is.",0,0.7620671391487122
111653508,2849,junrao,2017-04-15T00:38:56Z,"we synchronize on metadata in different classes like transactioncoordinator, transactionmarkerchannelmanager, transactionstatemanager and delayedtxnmarker. this makes a bit hard to reason about concurrency. would it be better to consolidate all concurrent accesses to transactionstatemanager or a new class and only do synchronization on methods inside that class?",0,0.8971703052520752
111653523,2849,junrao,2017-04-15T00:39:23Z,we need to add the acl check for each of the new request. this can be done in a separate pr if needed.,0,0.9925674200057983
111653527,2849,junrao,2017-04-15T00:39:32Z,we need to set transactionstopicreplicationfactor and transactionstopicminisr to 1 in config/server.properties so that local testing could work.,0,0.9943301677703857
111781296,2849,junrao,2017-04-17T17:40:42Z,"hmm, if polltimeout is maxlong, networkclient.poll() could be blocked for a long time waiting for the response to come back. this means if there are new requests for other brokers coming in, their processing will be delayed.",0,0.9108960032463074
111781327,2849,junrao,2017-04-17T17:40:51Z,"hmm, in general, it's useful not to reconnect on a failed connection, is setting reconnectbackoff to 0 intentional?",0,0.9713200926780701
111781351,2849,junrao,2017-04-17T17:40:59Z,"should we use metadatatowrite instead of metadata? also, could we just fold maybeaddpendingrequest() into addrequesttosend()?",0,0.995455265045166
111781396,2849,junrao,2017-04-17T17:41:13Z,perhaps it's better to make transactionmetadata.topicpartitions a private val and expose methods for manipulation so that it's easier to track when the state is changed?,0,0.9947453737258911
111829832,2849,junrao,2017-04-17T21:49:29Z,"hmm, shouldn't we be using the transaction timeout in the producer config instead of integer.max_value?",0,0.9886208176612854
111829857,2849,junrao,2017-04-17T21:49:40Z,"this may throw brokerendpointnotavailableexception and we probably need to handle this explicitly. otherwise, some request handler threads will fail unexpectedly.",0,0.9502880573272705
111829897,2849,junrao,2017-04-17T21:49:52Z,"we have to be a bit careful here. it's possible when a broker is restarted, it's ip and port have changed. so, we need to update the ip/port in brokerstatemap if needed.",0,0.9603285193443298
111830152,2849,junrao,2017-04-17T21:51:22Z,it seems that we need to call this during transactioncoordinator.handletxnemigration() as well?,0,0.9951275587081909
111830246,2849,junrao,2017-04-17T21:51:57Z,"here, we are draining the requests to every broker whether the broker channel is ready or not. it's probably better to only take requests from brokers whose connection is ready.",0,0.9920943379402161
111830264,2849,junrao,2017-04-17T21:52:04Z,max.transaction.timeout.ms => transaction.max.timeout.ms,0,0.9919889569282532
111932482,2849,dguy,2017-04-18T11:43:14Z,because this case is handled differently,0,0.976445734500885
111933023,2849,dguy,2017-04-18T11:46:43Z,it will be used to expire the transactions from the `transactionmetadatacache` in `transactionmanager`. it was my understanding that the timestamp should be updated to the the current timestamp (at least is supposed to be in the endtxnrequest case),0,0.9944214224815369
111933363,2849,dguy,2017-04-18T11:48:48Z,according to point 2 [a link],0,0.9864684343338013
111933574,2849,dguy,2017-04-18T11:50:12Z,yes - this was initially missing in the `initpidrequest` i've updated it so it does add it to the log,0,0.9884374737739563
111934136,2849,dguy,2017-04-18T11:53:42Z,?,0,0.9557723999023438
111966880,2849,dguy,2017-04-18T14:23:40Z,not sure i completely agree. it says in the javadoc for `requestcompletionhandler`: [code block],0,0.9871925115585327
111967313,2849,dguy,2017-04-18T14:25:15Z,"yep, i'm not sure what the thinking is/was behind that. ?",-1,0.865588903427124
111972450,2849,dguy,2017-04-18T14:43:30Z,"so, i think you are saying we need to always call `metadatacache.getaliveendpoint(...)` even if we have a node for the given brokerid already in `brokerstatemap`?",0,0.994260311126709
111978219,2849,dguy,2017-04-18T15:03:43Z,i am not sure it is a retriable error in this case. once the previous `endtxnrequest` has completed then a subsequent `endtxnrequest` for the same transactionalid should also fail - right?,0,0.7844941020011902
111997154,2849,dguy,2017-04-18T16:13:24Z,"hmmm. interesting! i don't think we want to clear everything, but just those transactionalids where the partition has emigrated? though, that is not immediately clear to me based on the current design. also there may well be in-flight-requests corresponding to the emigrated partitions. not sure which error response should be sent back for those.",1,0.8841835260391235
111997381,2849,dguy,2017-04-18T16:14:27Z,not sure - ?,-1,0.5266135931015015
112013590,2849,junrao,2017-04-18T17:23:17Z,"that sounds good. however, it seems that transactionmetadata needs 2 different timestamps. (1) the last timestamp when there is some activity from the pid. (2) the timestamp when the last open transaction is started. (1) will be used to expire pid and (2) will be used to abort a long transaction.",0,0.5961782932281494
112013865,2849,junrao,2017-04-18T17:24:25Z,"ok, could we add a comment. sth like ""it's possible for a complete message to be lost with acks=1 when the leader for the transaction coordinator changes. if so, we will re-add the complete message during handletxnimmigration()""",0,0.9935125708580017
112014229,2849,junrao,2017-04-18T17:25:53Z,"there are 2 cases when a channel is not ready: (1) the channel was ready and is disconnected now. (2) the channel is not ready and is being connected. in case (1), the callback will be called. in case (2), the current usage of networkclient is that the caller shouldn't send requests until the channel is ready. otherwise, we will be unnecessarily taking requests out of the queue, submitting it to networkclient and only to re-enqueue the failed requests.",0,0.968077540397644
112014271,2849,junrao,2017-04-18T17:26:05Z,"yes, every time that we add a new request to a broker id, it's possible for the broker's ip/port to change. we need to update the cached ip/port in brokerstatemap.",0,0.982249915599823
112014403,2849,junrao,2017-04-18T17:26:42Z,"yes, we should fail the subsequent endtxnrequest. but it seems that we want the client to backoff a bit and keep retrying until success. if we are not sending back a retriable error, the client will think the endtxnrequest actually permanently failed, which is not the case here.",0,0.9540860652923584
112014452,2849,junrao,2017-04-18T17:26:54Z,"yes, only clearing transactionalids where the partition has emigrated. for in-flight-requests, we probably want to return a nottransactioncoordinator error.",0,0.99247145652771
112138268,2849,dguy,2017-04-19T08:04:51Z,not sure - ?,-1,0.5266135931015015
112138822,2849,dguy,2017-04-19T08:08:13Z,"so, i think in the second case we probably want to check if the broker is ready before it gets to this point. as we've already drained the queue and will need to re-enqueue?",0,0.9914427399635315
112142569,2849,ijuma,2017-04-19T08:27:58Z,"as long as the `networkclient` is instantiated with an appropriate request timeout, this code is fine. the actual timeout here will be `the minimum of timeout, request timeout and metadata timeout` (as specified in the docs for`networkclient.poll`)",0,0.9919841885566711
112143022,2849,ijuma,2017-04-19T08:30:17Z,"unless we want a timeout that's lower than `requesttimeout`, of course.",0,0.9841110706329346
112282085,2849,apurvam,2017-04-19T18:38:13Z,we synced up on this with jun offline. the doc is outdated. we havea ticket here to track updates we need to make to the doc: [a link],0,0.9855622053146362
112286609,2849,apurvam,2017-04-19T18:57:54Z,"i think would have the most context on that, but i don't think we should not set it to 0. this is the connection to the leaders to write the abort marker. if the connection is disconnected, there is little reason to try to establish it again. i think the default of 50ms is reasonable here.",0,0.9782182574272156
112286690,2849,apurvam,2017-04-19T18:58:18Z,that makes sense to me.,0,0.9786012172698975
112286926,2849,apurvam,2017-04-19T18:59:24Z,"the comment is out of date. the original version of the patch had a notion of 'corrupted partitions', but the definition what is corrupted was not clear and we dropped the notion altogether.",0,0.9747765064239502
112287416,2849,apurvam,2017-04-19T19:01:30Z,the default on the producer as of now is 60 seconds. i think perhaps 120seconds on the broker is reasonable?,0,0.9811633229255676
112300739,2849,apurvam,2017-04-19T20:05:37Z,the config is being added as part of my patch. shall we introduce an overload of `initpidrequest.builder` which just takes a `transactionalid` and assigns some default timeout? my patch will use the two parameter builder and pass in the timeout from the producer config.,0,0.9955528378486633
112302162,2849,apurvam,2017-04-19T20:12:25Z,"we can avoid this by using the `networkclientutils.awaitready` method, as used in [a link] that will ensure that the destination node is ready before sending the initial request. so you could peek into the queue to get the destination, ensure that it is ready, and if so, send the request. however, if it is not ready after a particular time, you will have to rediscover the correct node to send the request to (presumably because the old broker is down and the leader has moved).",0,0.9939811825752258
112306365,2849,apurvam,2017-04-19T20:31:43Z,"yes, we have to do this across the board. i filed a jira so that we can make the change in one pr so that it is easier to make sure we are consistent. [a link]",0,0.97249436378479
112311456,2849,junrao,2017-04-19T20:55:25Z,"the broker has a request timeout, but it's probably better for the client could pass along the timeout in the rpc request?",0,0.9932230710983276
112311549,2849,junrao,2017-04-19T20:55:48Z,"ideally, we only want to take requests off a queue when the channel to the corresponding broker is ready. however, if one broker's connection is not ready, we don't want to delay the sending of requests for other brokers. one way to achieve this is to have a separate queue per broker.",0,0.9855806231498718
112311627,2849,junrao,2017-04-19T20:56:05Z,"hmm, waiting for a 30 secs request timeout is still too long if there is another request in the queue ready to be processed.",0,0.6906794309616089
112317720,2849,apurvam,2017-04-19T21:25:58Z,"jun raises a good point. right we should have two timestamps in the messages we write to the transaction log. one is the `entrytimestamp` which is the current time and which is used to expire the transactionalid. the other is the `transactionstarttime` which is the timestamp of the first `addpartitionstotransaction` request for a transaction. this is used to expire transactions on the broker. as it stands, we have only the `entrytimestamp` and so a transaction could be open for ever if it gets updates very slowly. this would hold up the progress of the lso on all the partitions involved in the transaction, which is not a desirable outcome. would you be able to add the new timestamp and add a note to update doc on this ticket? [a link]",0,0.951793372631073
112415717,2849,dguy,2017-04-20T10:05:21Z,seems to make sense to me. any reasoning behind this?,0,0.9612516760826111
112417500,2849,dguy,2017-04-20T10:14:35Z,"it seems so. it is handled like this in `groupmetadatamanager#preparestoregroup`, too",0,0.9863974452018738
112419986,2849,dguy,2017-04-20T10:28:20Z,"there already is an overload, but it also sets the timeout to `integer.max_value`",0,0.9921133518218994
112426248,2849,dguy,2017-04-20T11:05:31Z,"actually, i think this should be `producerepoch`? afaik `coordinatorepoch` is `partition.getleaderepoch`",0,0.9946744441986084
112462355,2849,dguy,2017-04-20T14:08:30Z,i'm not sure.,-1,0.8398251533508301
112472596,2849,dguy,2017-04-20T14:47:19Z,"we achieve that now as we just don't bother sending the request if the broker isn't ready. it gets re-enqueued, but it might need to be as the broker may now be down. i guess i'm missing something here, but i don't really see what.",0,0.8481894135475159
112494867,2849,junrao,2017-04-20T16:09:46Z,"hmm, i don't see invalid_fetch_size or invalidfetchsizeexception being generated in the code base. if we don't want to clean this up in this patch, could we at least file a followup jira to track this?",0,0.9387529492378235
112498072,2849,junrao,2017-04-20T16:23:54Z,"my point is on efficiency. if a channel is not ready to begin with, keep re-enqueuing the same request again and again just adds overhead. so, it's better to wait until a channel is ready and then start processing the requests intended on that channel. on the other hand, if a channel is ready, we send a request to that channel and the channel is disconnected before the response is received, we need to re-enqueue the requests for reprocessing. but that's done in the callback in the clientrequest already.",0,0.9812564253807068
112554067,2849,apurvam,2017-04-20T20:33:47Z,"the transaction timeout is passed in in the initpidrequest. it will apply to all transactions in that session. on the producer, the default for this timeout is 60s.",0,0.9933776259422302
112562609,2849,apurvam,2017-04-20T21:14:42Z,"so the transaction coordinator is colocated with the leader the topics in the transaction log which it owns. when we do a `txnmanager.appendtransactiontolog` and the coordinator has moved, the leader for the topic should also have moved. in that case, we will get a `not_leader_for_partition` error, and send back a `not_coordinator` error code, in which case the client will send another `findcoordinator` request.",0,0.9926264882087708
112572188,2849,apurvam,2017-04-20T22:13:35Z,"i agree with that this is inefficient. the producer model where we have a background sender thread and one queue per broker is more efficient, since it avoids busy waiting. however, we agreed that we can make this improvement in the future, after the initial integration is done. i filed this ticket to keep track of the work item: [a link]",0,0.8542081117630005
112572768,2849,apurvam,2017-04-20T22:17:41Z,"followed up with offline. the main case to guard against is when the partition moves to another broker, and then moves back between the call to `validatetransactionalid` an `txnmanager.appendtransactiontolog`. in this case, when the call back for `appendtransaction` executes, the coordinator may still be loading the cache, and it is unclear what we should do . we agreed that the best thing probably is that when a partitino emigrates, we should track down in flight operations (and requests sitting in the purgratory), and error them out with a `not_coordinator` code. is it feasible to do the latter in a simple fashion?",0,0.9926551580429077
112622713,2849,dguy,2017-04-21T07:09:13Z,"ok, so that is what we are already using.",0,0.9861959218978882
112623812,2849,dguy,2017-04-21T07:17:40Z,"yes it would be inefficient in the case that there is only a single broker or all brokers are not ready. in other cases it will not necessarily be so inefficient as the request will be re-enqued, but not immediately retried. other requests, to potentially, other brokers will be tried etc, before the requests for the not ready broker is retried. anyway, that said, having a queue per broker is better.",0,0.985968828201294
112623904,2849,dguy,2017-04-21T07:18:24Z,so should we just default this to something much lower? what would be a reasonable timeout?,0,0.9867918491363525
112651788,2849,dguy,2017-04-21T09:44:05Z,thanks. yeah i should be able to do that,1,0.9546812176704407
112805167,2849,dguy,2017-04-22T08:05:58Z,", correct it doesn't look it is generated anywhere. i'll remove it from here and i've filed: [a link]",0,0.9800794720649719
112806295,2849,dguy,2017-04-22T09:31:16Z,"i already changed `handletxnemigration` to remove the inflight operations that we know about, i.e., the ones in purgatory. once they complete they will error with `not_coordinator`. however this is only useful for the case where we writing the txn markers. for the other cases, if the coordinator is still loading the cache and the `transactionalid` is not yet cached we will respond with `not_coordinator`. however, if the cache is is loading it may have an old record for the `transactionalid`. should we do a check in the callback, i.e., [code block]`",0,0.9946552515029907
113041521,2849,junrao,2017-04-24T19:59:12Z,be consistent on whether to use () when calling clientid() ?,0,0.9939157366752625
113042021,2849,junrao,2017-04-24T20:01:29Z,this still needs to be addressed. the loading in groupcoordinator has the same issue.,0,0.9726567268371582
113083208,2849,junrao,2017-04-25T00:00:43Z,"i am a bit worried about all those independent checks on transactional state w/o any coordinator level locking. for example, in theory, a coordinator emigration and immigration could have happened after the check in line 104. then, the appendmetadatatolog()/initpidwithexistingmetadata() call could mess up some state. i was thinking that another way of doing this is to maintain a read/write lock for the coordinator partition. immigration/emigration will hold the write lock while setting the state. other calls like initpid will hold the read lock, do the proper coordinator state check, initiate the process like appending to the log and then release the read lock (we already have such a partition level lock in partition, not sure if it's easily reusable). this will potentially give us better protection and make things easier to reason about.",-1,0.926274299621582
113083220,2849,junrao,2017-04-25T00:00:50Z,"hmm, appendmetadatatolog() is not doing exactly the same as if the metadata has existed. it seems that we will be missing all those checks on metadata state in initpidwithexistingmetadata()?",0,0.8750280737876892
113083240,2849,junrao,2017-04-25T00:01:00Z,should we just do the eq check on reference instead?,0,0.9934440851211548
113083247,2849,junrao,2017-04-25T00:01:04Z,"i assume that entrytimestamp is used for expiring a transactional id if there is no activity. if so, this needs to be updated on any activity related to a transactional id such as addpartitions, abort/commit and initpid. also, could we rename this to sth like lastaccesstimestamp? it would also be useful to document the usage of the two timestamps in transactionmetadata.",0,0.9946836829185486
113083250,2849,junrao,2017-04-25T00:01:05Z,"hmm, transactionstarttime needs to be set when we add the first partition to the transaction.",0,0.9878541827201843
113083255,2849,junrao,2017-04-25T00:01:08Z,"hmm, in this case, the coordinator is not really in a loading state. it seems that we need a new error like concurrent_transactions?",0,0.84581059217453
113083261,2849,junrao,2017-04-25T00:01:11Z,"this can be tricky to handle completely. (1) should we also cancel any ongoing loading due to the previous immigration? (2) there could be outstanding transactional requests (e.g., initpid) waiting in producer purgatory after the log append call. ideally, we should mark the coordinator as not available, trigger a check on requests associated with the coordinator's partition in the purgatory so that they can responds with a coodinator_not_available error.",0,0.9816765785217285
113083269,2849,junrao,2017-04-25T00:01:17Z,"if we are doing this optimization, we need to make sure that the handleaddpartitionstotransaction() call first completes any pending transaction, i.e, the markers from a previous transaction must have been sent successfully and the complete transaction entry has been added to the transaction log. otherwise, the producer may start publishing the data for the next transaction before the transaction marker has been added for the previous transaction.",0,0.9948480129241943
113083272,2849,junrao,2017-04-25T00:01:18Z,it seems that we should just keep retrying until successful or the broker is no longer the transaction coordinator.,0,0.9752264022827148
113083277,2849,junrao,2017-04-25T00:01:22Z,good question. we could either keep retrying or mark the coordinator in a bad state.,1,0.661374568939209
113083280,2849,junrao,2017-04-25T00:01:26Z,the only place that brokerstatemap is needed outside of this class is in transactionmarkerchannelmanager for draining events. perhaps we can make brokerstatemap private and expose a method like drainqueuedtxnmarkers() instead? this makes it a bit easier to track the accesses to the map.,0,0.9935306906700134
113083290,2849,junrao,2017-04-25T00:01:30Z,"hmm, what about those pending requests already in the selector()? ideally we need to drain them too. not sure what's the best way to do that.",-1,0.7090223431587219
113083300,2849,junrao,2017-04-25T00:01:33Z,"hmm, not sure why we need to do flatmap instead of just map.",-1,0.5126850605010986
113083312,2849,junrao,2017-04-25T00:01:36Z,metadatapartition can be a bit confusing. how about coordinatorpartition?,-1,0.7472280859947205
113083333,2849,junrao,2017-04-25T00:01:53Z,this can be in a future patch. it would be useful to record this in some metric so that we know the state of transaction coordinator.,0,0.9926148653030396
113083342,2849,junrao,2017-04-25T00:01:55Z,should we do the eq test to only test for reference equal?,0,0.992998480796814
113083350,2849,junrao,2017-04-25T00:02:00Z,"is that enough? for transactions in the prepare state, shouldn't we try to write the txn markers to added partitions and bring those transactions to the complete state too?",0,0.9950690269470215
113083356,2849,junrao,2017-04-25T00:02:03Z,should we clear out loadingpartitions and stop any ongoing loading on that partition?,0,0.992672324180603
113083359,2849,junrao,2017-04-25T00:02:05Z,this method seems cheap. is there a reason for running this in the scheduler?,0,0.8172811269760132
113083367,2849,junrao,2017-04-25T00:02:09Z,the above issue is still not resolved.,0,0.8898343443870544
113083375,2849,junrao,2017-04-25T00:02:11Z,"hmm, do we need this check if we make sure all outstanding transactions are aborted on emigration and new transactions can only be started after the coordinator loading completes?",0,0.9866663813591003
113083384,2849,junrao,2017-04-25T00:02:16Z,inaccurate comment. internal topics are not just offset topic now.,0,0.5906708240509033
113088713,2849,junrao,2017-04-25T01:01:00Z,"if the thread is blocked in networkclient.poll and some new requests are added to the queue, it seems that we need to wake up networkclient so that new requests can be processed immediately.",0,0.9791486263275146
113088732,2849,junrao,2017-04-25T01:01:10Z,we should just wait until the target broker is available.,0,0.9834471940994263
113088785,2849,junrao,2017-04-25T01:01:42Z,"hmm, instead of throwing illegalstateexception, it seems that we should just keep retrying until successful?",0,0.9554665088653564
113089004,2849,junrao,2017-04-25T01:04:11Z,"since the timeout in delayedtxnmarker is infinite. i am wondering if we really need a txnmarkerpurgatory. in transactionmarkerrequestcompletionhandler, we are already updating the pending partitions as the client response comes back. the response that removes the last pending partition can just trigger the calling of completioncallback.",0,0.9424709677696228
113090851,2849,junrao,2017-04-25T01:26:07Z,"if the broker's message format is < v2, currently, when appending to the log, we simply convert it to an old format. in this case, we want to error out and respond to the client with a transactionnotsupported error.",0,0.978358805179596
113091081,2849,junrao,2017-04-25T01:28:07Z,"since we are sending new type of requests across the brokers, we need to check inter broker protocol and error out if the new request is not supported.",0,0.9833639860153198
113123510,2849,dguy,2017-04-25T07:28:27Z,yep any reason why we are using hw?,0,0.9344927668571472
113124537,2849,dguy,2017-04-25T07:34:51Z,it isn't clear to me what this is supposed to be saying either. ?,-1,0.5668546557426453
113125360,2849,dguy,2017-04-25T07:40:11Z,yes. we need to do that. discussed this with offline yesterday and we thought it might be better to do in a follow up patch as this patch is already quite large. thoughts?,0,0.9410008788108826
113125813,2849,dguy,2017-04-25T07:43:13Z,i guess it is because `loadtransactions` is run in the scheduler. so they won't interleave. ?,0,0.9933313727378845
113127361,2849,dguy,2017-04-25T07:52:28Z,"ok. i can do that by adding a check in the while loop in `loadtransactionmetadata`, i.e, `while(curroffset < highwatermark && loadingpartitions.contains(partitionid) && ...)` will that be ok?",0,0.9918487071990967
113127705,2849,dguy,2017-04-25T07:54:19Z,i'm not really sure what i'm supposed to be checking here?,-1,0.8147353529930115
113128786,2849,dguy,2017-04-25T08:00:21Z,i'm not sure how i can cancel all inflight requests. say for instance `transactionstatemanager.appendtransactiontolog(..)` is called and then on another thread `handletxnemigration` is called and removes the partition. how do i abort the inflight `transactionstatemanager.appendtransactiontolog(..)` call.,-1,0.5824093818664551
113129466,2849,dguy,2017-04-25T08:04:29Z,"thanks - yeah that makes sense. i was thinking about locking, too, but wasn't sure of the correct level to do it at, but the partition level seems ok. will look into it. thanks for the suggestion",1,0.984825074672699
113130366,2849,dguy,2017-04-25T08:09:55Z,"i'm not sure what was meant by the comment, but i think you are correct in that we should do `initpidwithexistingmetadata()` in the case that they aren't the same. any thoughts?",0,0.8589546084403992
113165211,2849,dguy,2017-04-25T11:03:40Z,in which case should i default it something like -1 here?,0,0.9815348386764526
113165318,2849,dguy,2017-04-25T11:04:22Z,true. any thoughts on this?,0,0.9736952781677246
113165961,2849,dguy,2017-04-25T11:08:10Z,i think we can handle (1) by: 1. in `removetransactionsforpartition` we remove the partition from `loadingpartitions` 2. in `loadtransactionmetatdata` we only perform the loop when `loadingpartitions.contains(partition) i have to think a bit more about 2,0,0.9751023054122925
113166353,2849,dguy,2017-04-25T11:10:21Z,i think this case is already handled by `handleinitpid()`,0,0.9895375967025757
113167929,2849,dguy,2017-04-25T11:19:30Z,they will error out with `not_coordinator` on completion. will that suffice? i'm not sure how we can cancel inflight requests in the `networkclient`,0,0.9589409232139587
113168889,2849,dguy,2017-04-25T11:25:14Z,i probably should just use flatten. my scala knowledge is not the best,0,0.6130453944206238
113169486,2849,dguy,2017-04-25T11:28:53Z,in `initpidwithexistingmetadata` we also need to wait on the transaction to complete if there is an inflight transaction in the `prepareabort` or `preparecommit` phase.,0,0.9947734475135803
113172390,2849,dguy,2017-04-25T11:45:47Z,how would i do that?,0,0.980241060256958
113173083,2849,dguy,2017-04-25T11:49:47Z,ok i guess i'll need todo that in `transactionmarkerchannel#addrequesttosend`,0,0.9915987253189087
113178448,2849,ijuma,2017-04-25T12:15:40Z,"`flatmap` is preferable to `map` and then `flatten`. i am guessing jun's question is because `txnmarkerentry` sounds like an element, but it's actually a `list`. maybe it should be renamed?",0,0.9882153272628784
113178626,2849,ijuma,2017-04-25T12:16:27Z,"also, you can write it a bit more concisely by doing `buffer.flatmap(_.txnmakerentry).asjava` (x doesn't add anything over the underscore).",0,0.9936514496803284
113195654,2849,dguy,2017-04-25T13:34:40Z,"the tc maintains multiple partitions, so we'd need to have a lock per partition. you mentioned that there is a read/write lock on partition - i believe you are referring to `leaderisrupdatelock`... i can't see any other locks in `partition`. anyway, do we want to expose this for other classes to use? i'd probably think not. if we maintain a lock per partition then perhaps it should be done by the `transactionstatemanager` and then we'd need to add/remove locks in the immigration/emigration. i think we'd also need to add another method on `transactionstatemanager`, say `partitionlock(partitionid)` that returns an `option[reentrantreadwritelock]`. the calls in `transactioncoordinator` to `iscoordinatorfor` could then be replaced with calls to `partitionlock(partitionid)` - if the lock exists they take a read lock. if it doesn't exist then respond with `errors.not_coordinator` does this seem sensible?",0,0.9867343902587891
113330271,2849,guozhangwang,2017-04-25T22:48:31Z,in that case do we really need this change in this pr? maybe we can just remove this change as it is actually doing the same still.,0,0.9880471229553223
113330372,2849,guozhangwang,2017-04-25T22:49:15Z,are these changes intentional? the original ordering seems ok to me.,0,0.9784537553787231
113331290,2849,guozhangwang,2017-04-25T22:55:50Z,"thinking about this a bit more, i wonder if the `coordinatorepoch` should also be in the internal entry as well, since different txn log partition leader's epoch hence the coordinator epoch would be different?",0,0.9844041466712952
113331531,2849,guozhangwang,2017-04-25T22:57:33Z,"edit: in the existing branch i have already made those changes a while back: [a link] the design doc however is not updated. i saw you did a groupby on the `coordinatorepoch` instead, so that each write marker request will only contain one `coordinatorepoch`, but since on the broker side, this coordinator epoch is checked inside the `log` layer anyways i felt it is better to change this field as a per-marker-entry field in the protocol.",0,0.9900828003883362
113332359,2849,guozhangwang,2017-04-25T23:03:23Z,"i did this in the original commit but: since this thread is owned by the broker only, we do not need this tag. instead we can just pass an empty tag map.",0,0.9918355941772461
113347218,2849,guozhangwang,2017-04-26T01:15:54Z,nice catch. currently we do not have a broker-side `reconnect.backoff` config yet so different modules just hand-code different values. but moving forward i felt we may want to introduce a new config for inter-broker reconnect backoff.,0,0.5503236055374146
113348424,2849,guozhangwang,2017-04-26T01:29:27Z,nit: indentation on the comment line 69.,0,0.990958571434021
113348812,2849,guozhangwang,2017-04-26T01:33:43Z,sounds good to me.,1,0.8850300908088684
113351582,2849,guozhangwang,2017-04-26T02:00:13Z,nit: new line after condition,0,0.9827877879142761
113352248,2849,guozhangwang,2017-04-26T02:07:55Z,"yeah i was ""piggy-backing"" on this error code since this is the only retriable error code that the client recognizes in my incomplete patch. and i do agree that we should introduce another retriable error code here.",0,0.8988243341445923
113352808,2849,guozhangwang,2017-04-26T02:14:28Z,"since we return immediately after the `preparexx` marker is written. in both `initpid` and `addpartition` request handling the metadata state could be in `preparexx` or `ongoing`, so we need to handle them in both these two places, better in a consistent way. in the design doc we said the request will be held on the broker side indefinitely until the current transaction is rolled-forward or rolled back complete. we did this in `initpid`, but here we are directly returning a non-retriable error code. i was planning to do these handling on both places in a separate pr but since is already adding the logic for `initpid` now maybe we can discuss about that now: after thinking about it a bit more i felt maybe its better to return a retriable exception either immediately (with the new error code we need anyways for the above case) or after some timeout (with the `timeout` error code) on both places, and let the client to back-off and retry. doing this we can avoid ever increasing the in-memory structures like like the per-broker queues and the purgatory. thoughts?",0,0.9885308146476746
113353056,2849,guozhangwang,2017-04-26T02:17:12Z,"i'm wondering if we should bound the size of this blocking queue or it will cause tc-broker oom when some of the txn involved partition leaders are temporarily / permanently available. my feeling is that we do not and here is my reasoning (cc ): 1. we have two in-memory structures whose size is unbounded, this blocking queue and the txn purgatory. 2. when there are some partitions unavailable, hence the current preparexx transaction cannot be completed, they will take one slot on each of the above structures; 3. then when new request is coming from the same pid, either `initpid` or `addpartitions`, they will not proceed. hence the above structures will have at most one parked item for each producer. see my other comment about handling the `initpid` and `addpartitions` request while the previous txn has not completed.",0,0.9319332242012024
113353166,2849,guozhangwang,2017-04-26T02:18:28Z,"as long as we clear the txn purgatory, even if there are inflight request during the time. when they come back as responses, either succeeded or failed, since the corresponding delayed operation has already gone its callback will effectively be reduced to a no-op. so i think that is fine.",0,0.9735495448112488
113353266,2849,guozhangwang,2017-04-26T02:19:50Z,chatted with offline. i did this mainly to just mimic group coordinator's loading behavior. but after discussing with him i think it is safer to read up to leo (we probably need to do the same for gc as well),0,0.9857224225997925
113353374,2849,guozhangwang,2017-04-26T02:21:23Z,yup. let's do that in follow-up prs.,0,0.8114050626754761
113353582,2849,guozhangwang,2017-04-26T02:23:52Z,"the log entry was wrong, maybe just ""since the the appended log did not successfully replicate to all replicas"". does that sound better?",0,0.9862223267555237
113353750,2849,guozhangwang,2017-04-26T02:26:03Z,"since we now have one queue per broker, and 1) we drain all the elements in the queue whenever trying to send; 2) we wake up the client whenever we are adding new elements to the queue; i think it is not as critical to set lower values?",0,0.988644003868103
113353816,2849,guozhangwang,2017-04-26T02:26:52Z,"agree, maybe we can have a read-write lock on the txn metadata cache and only release the read lock after the txn log has been appended locall?",0,0.9948904514312744
113354061,2849,guozhangwang,2017-04-26T02:29:31Z,i think 's comment is that we did some checking on the txn metadata's state in `initpidwithexistingmetadata` whereas we did not do such checking before calling `appendmetadatatolog`. have explained to him that it is because at line 129 we are assured that the metadata is just newly created and hence it's always `ongoing`. maybe the comment itself has been outdated after the addition of the `initpidwithexistingmetadata` logic.,0,0.9931469559669495
113354470,2849,guozhangwang,2017-04-26T02:33:57Z,"what's the motivation of trying to drain all the queued elements? since the max inflight request is only 1 in the network client, even if we construct multiple requests for a certain destination only the first request will succeed in sending right? in that case could just do the 1) peek-first 2) if-ready-send-and-pop pattern?",0,0.9857304096221924
113379063,2849,dguy,2017-04-26T07:07:11Z,we don't have one queue per broker yet. that was going to be in a follow up pr,0,0.9860097169876099
113379863,2849,dguy,2017-04-26T07:12:57Z,"actually, i don't think we need this debug message as the error cases are all logged previously. i'll just remove it.",0,0.9678383469581604
113386204,2849,dguy,2017-04-26T07:51:34Z,per partition? or a global lock?,0,0.9913712739944458
113388847,2849,dguy,2017-04-26T08:05:39Z,will the kip need to be updated with the new error?,0,0.9929736852645874
113392736,2849,dguy,2017-04-26T08:26:59Z,"so this should change back to what you previously had? we originally had your code, but during the merge with other changes it was probably removed. that is why i did the groupby on `coordinatorepoch`.",0,0.9925296902656555
113395115,2849,dguy,2017-04-26T08:40:00Z,"question more for my own understanding than anything else: if `initpid` is holding on to the request on the broker until the transaction is completed, then i think `addpartitions` should never be called when the transactionid is in a `preparexx` state. is that correct?",0,0.9678932428359985
113395718,2849,dguy,2017-04-26T08:43:18Z,this is largely a refactoring of your code from here: [a link] :-p,1,0.9928809404373169
113454320,2849,dguy,2017-04-26T13:43:12Z,"on second thoughts, i'll add a single read/write lock in the coordinator as it is much simpler than having to maintain multiple. if that is not ok, we can revisit.",0,0.9896934628486633
113457671,2849,dguy,2017-04-26T13:55:37Z,i'm not sure i understand (2). when you refer to there being outstanding requests in the producer purgatory is that w.r.t `replicamanager.appendrecords(...)`?,0,0.924979031085968
113499063,2849,apurvam,2017-04-26T16:22:42Z,we should probably have one or more jira's to track these.,0,0.9896886348724365
113501224,2849,guozhangwang,2017-04-26T16:32:02Z,"this is about the inter-broker protocol version. details are here: [a link] maybe just leave a todo marker and i can address it in a follow-up pr, so we would not drag too long for this one?",0,0.9933911561965942
113501426,2849,guozhangwang,2017-04-26T16:32:56Z,responded in another comment. let's do this incrementally in another pr and just leave a todo in this pr. otherwise we would be looking at a 10k diff,0,0.993181049823761
113506336,2849,dguy,2017-04-26T16:53:53Z,ok i've filed: [a link],0,0.97187739610672
113506744,2849,dguy,2017-04-26T16:55:31Z,i've filed [a link],0,0.9779046773910522
113510250,2849,junrao,2017-04-26T17:10:10Z,"yes, we can probably also just check if the partition is still in ownedpartitions.",0,0.9919061660766602
113511035,2849,junrao,2017-04-26T17:13:41Z,"if you set the coordinator state first and trigger a check in the purgatory, the checking of the iscomplete() logic should realize that the coordinator is no longer valid and error out.",0,0.9940809607505798
113512025,2849,junrao,2017-04-26T17:18:18Z,"most operations just need to hold a read lock. only emigration/immigration need to hold a write lock. so, perhaps having a single lock per broker is also fine as long as we don't hold the lock for too long (i.e., we should mostly be just setting critical states while holding the lock. any expensive stuff should be done outside the lock).",0,0.9902583360671997
113512989,2849,junrao,2017-04-26T17:22:29Z,"we can set it to -1, but it may not matter. transactionstarttime is only useful when aborting a transaction that's started. if the transaction is in empty state, transactionstarttime is probably not going to be used. it's more important to set transactionstarttime on adding the first partition.",0,0.991296648979187
113513257,2849,junrao,2017-04-26T17:23:39Z,"yes, we can remember this and update the kip with all the changes in a batch.",0,0.9795111417770386
113513973,2849,junrao,2017-04-26T17:26:53Z,"yes, i was referring to delayed events in the producer purgatory after the replicamanager.appendrecords(...) call. we can trigger a check of those delayed events and let them error out (since the check will find out that the broker is no longer the coordinator).",0,0.9900202751159668
113515117,2849,junrao,2017-04-26T17:31:52Z,"hmm, is it? handleinitpid() seems to just call appendmetadatatolog(). there is no guarantee that abort/commit marker from the previous transaction has been sent by the inter broker thread.",0,0.9885162115097046
113515688,2849,junrao,2017-04-26T17:34:14Z,"well, if the response fails because of disconnection, we shouldn't keep retrying right?",0,0.9421257972717285
113517731,2849,dguy,2017-04-26T17:42:47Z,in `handleinitpid` if metadata exists it calls `initpidwithexistingmetadata` that waits for the previous transaction to complete,0,0.9949374198913574
113537029,2849,dguy,2017-04-26T19:05:32Z,is calling `delayedproducepurgatory.checkandcomplete(topicpartitionoperationkey)` the correct thing to do in this case?,0,0.9952086806297302
113538220,2849,dguy,2017-04-26T19:11:47Z,"yep, it does get set when the first partition is added.",0,0.97735995054245
113550754,2849,guozhangwang,2017-04-26T20:12:19Z,"`initpid` is only called only for the lifetime of a producer, when the producer client completed the current txn and is about to start the next one, it will not call `initpid` but just `addpartitions` as the first request. only when producer client fails-over the new instance (i.e. in its next life) will send an `initpid` again.",0,0.9920368194580078
113594739,2849,apurvam,2017-04-27T00:45:09Z,"the code as it is seems correct to me. if you get `addpartitions`, you should be in an ongoing state. i also think the `empty` state is invalid in this case.",0,0.9680652618408203
113594825,2849,apurvam,2017-04-27T00:45:54Z,"or is `empty` just signally `no_ongoing_transaction`? if so, it is a valid state.",0,0.9929012060165405
113595652,2849,apurvam,2017-04-27T00:54:41Z,"i guess you mean [code block] (note the absence of the negation in my if). i think this is reasonable. more generally, if we don't find the transaction metadata in the `appendtotransactionlog` callback, or if the coordinatorepoch is different from what we expect, we should just return not_coordinator. the client will retry and eventually succeed.",0,0.9697859883308411
113595956,2849,apurvam,2017-04-27T00:57:49Z,"also, cc ..",0,0.9886391162872314
113596678,2849,apurvam,2017-04-27T01:06:30Z,"i guess current point was that a valid state here could also be `prepare`, if the previous transaction is still completing, in which case we should return `concurrent_transactions`, and have the client retry with backoff.",0,0.9925370812416077
113634970,2849,dguy,2017-04-27T07:54:21Z,"- cool makes sense now. so i guess we should do the same thing in `initpid` and `addpartitions`, i.e., respond with `concurrent_transaction` or block until the previous transaction has completed",1,0.8933736681938171
113831631,2849,guozhangwang,2017-04-28T00:32:12Z,this is already addressed.,0,0.9905385971069336
114487301,2964,ijuma,2017-05-03T07:46:13Z,there's no need to have the `errors` type parameter here. that check always succeeds.,0,0.9881379008293152
114488311,2964,ijuma,2017-05-03T07:53:55Z,this can be written more clearly as: [code block],0,0.9890700578689575
114488522,2964,ijuma,2017-05-03T07:55:26Z,"hmm, as discussed previously, it's preferable to use a case class instead of many unnamed parameters.",0,0.985826313495636
114505601,2964,dguy,2017-05-03T09:40:51Z,"do we need to update these tuples to be `(error, null, null)`? i.e., we are expecting a triple as the result",0,0.9921312928199768
114507297,2964,dguy,2017-05-03T09:50:44Z,looks like this is not used anymore?,0,0.9841361045837402
114509240,2964,dguy,2017-05-03T10:02:25Z,why do we need to do this?,0,0.9441654682159424
114510129,2964,dguy,2017-05-03T10:07:39Z,should we not just retry in this case? we've already written `preparexx` to the log and i thought we need to complete the transaction? how will the transaction be completed?,0,0.9929386973381042
114510837,2964,dguy,2017-05-03T10:09:49Z,the comment is incorrect. i don't think we are returning anything to the client. if the transaction has been emmigrated than it the commit should be completed by the new partition leader,0,0.7379248142242432
114511374,2964,dguy,2017-05-03T10:12:53Z,"i think we also need a check `case errors.not_coordinator` in which case we should just log an move on. also, in this case i think we need to retry?",0,0.9919384121894836
114512933,2964,dguy,2017-05-03T10:22:15Z,how are we cleaning up cases like this where it has failed? what are the implications for consumers etc?,0,0.969366192817688
114513958,2964,dguy,2017-05-03T10:28:55Z,why do we need to update the `txnstarttimestamp` here and in the `completecommit` case?,0,0.9952046871185303
114514040,2964,dguy,2017-05-03T10:29:26Z,could this be `case prepareabort | preparecommit` ? i think they are identical,0,0.9932859539985657
114514118,2964,dguy,2017-05-03T10:30:00Z,`case completeabort | complete commit` ? i think they are identical,0,0.9894087314605713
114515680,2964,dguy,2017-05-03T10:41:41Z,"we have the situation here that when this method returns nothing has actually happened yet, i.e., the removal is done on a different thread. so what happens if we get a request at the same time for another transactionalid that is in the same partition? are we just relying/hoping it will eventually fail?",0,0.8862317204475403
114515990,2964,dguy,2017-05-03T10:44:02Z,is this an exceptional condition? could we just log it and move on?,0,0.9804085493087769
114516182,2964,dguy,2017-05-03T10:45:16Z,should we change this to have `coordinatorepochandtxnmetadata` as a param rather than the 2 separate params?,0,0.9958789348602295
114675298,2964,guozhangwang,2017-05-03T23:20:50Z,ack,0,0.8596508502960205
114675858,2964,guozhangwang,2017-05-03T23:24:58Z,"edit: the reason i made it as unnamed parameters is that the `sendtxnmarkers` function is not long used as a parameter but also directly called elsewhere. and it has been reduced from 8 params to 4, so i feel this is better cost-effective?",0,0.9909399747848511
114677405,2964,guozhangwang,2017-05-03T23:37:23Z,"ack. this needs to be tweaked a bit since the inner map is a `pool`, let me know if you like the new pattern or not.",-1,0.8431999087333679
114677702,2964,guozhangwang,2017-05-03T23:40:09Z,ack.,0,0.5038502812385559
114677859,2964,guozhangwang,2017-05-03T23:41:42Z,ack,0,0.8596508502960205
114677949,2964,guozhangwang,2017-05-03T23:42:25Z,this is needed as `groupby` to generate the grouped map keyed by the node object.,0,0.9934819340705872
114678445,2964,guozhangwang,2017-05-03T23:46:55Z,"from `appendtransactiontolog` the only error codes we would pass in the callback are: [code block] and anything falling into `other` should be considered fatal as they should not happen (if they happen that should be a bug), and `unknown` comes from `message_too_large` or `record_list_too_large` which are also doomed as fatal.",0,0.9919745326042175
114678501,2964,guozhangwang,2017-05-03T23:47:30Z,ack. updating the comment.,-1,0.8792411684989929
114678943,2964,guozhangwang,2017-05-03T23:51:37Z,"from `delayedtxnmarker` when we call `completioncallback` we will only return `none` and hence any other error codes would not be expected and considered as fatal right? note that the write-marker-response could contain error codes like `unknown_topic_or_partition`, but this is handled in the `transactionmarkerrequestcompletionhandler`, in which case we will retry.",0,0.9941568374633789
114679087,2964,guozhangwang,2017-05-03T23:53:00Z,"generally this default is just for any un-expected error codes (i.e. there is a bug in the protocol, that broker returns some error codes not defined) to fail-fast.",0,0.9686121940612793
114679260,2964,guozhangwang,2017-05-03T23:54:19Z,"good point, ack.",1,0.9062934517860413
114679267,2964,guozhangwang,2017-05-03T23:54:22Z,"good point, ack.",1,0.9062934517860413
114679565,2964,guozhangwang,2017-05-03T23:57:09Z,"i have not reviewed your expiration pr so my understanding might be inconsistent, but here is how i read the existing code: `txnstarttimestamp` is only set when there is an active txn ongoing, otherwise it should always be set to -1 (i.e. the above check on the new metadata). and expiration will simply skip the metadata when this field is -1.",0,0.9871379137039185
114680315,2964,guozhangwang,2017-05-04T00:03:32Z,"this will be in completed in another pr for the locking mechanism, and here is a sketch: 1. we will add a per-broker read-write lock on tc. 2. all request-handling logic need to grab the read lock before accessing the cache for checking state until appending to the local log call returns. 3. the loading / removing thread will grab the write lock when removing / adding the sub-map for that partition into the cache. 4. implementation-wise, we will modify `statelock` for that read-write lock. the main purpose is to avoid log appending out-of-order, e.g. consider the following order: [code block]",0,0.9924038052558899
114680536,2964,guozhangwang,2017-05-04T00:05:22Z,"hmm, that is a good point. i think it can happen that `onfollower` called twice but the second call's triggered thread gets executed before the first call. so yeah we could just log it and move on.",0,0.7565586566925049
114681378,2964,guozhangwang,2017-05-04T00:13:26Z,"edit: similarly for `addloadedtransactionstocache`, but slightly different: we only have one background thread inside `scheduler` and we are checking on `loadingpartitions` so that no requests will be handled while loading so no new entries will be appended to the log. so even we have two loading tasks scheduled, it is safe for the second loaded metadata to replace the first loaded sub-map via `put`, so if `isdefined` we can just log it.",0,0.9927142262458801
114682211,2964,guozhangwang,2017-05-04T00:22:34Z,"i have been thinking about it, the main reason that i keep it separately is that it can be called in two paths: handler thread call it directly and the callback from writemarkersender call it separately. in the latter case the two values are separate so i ended up keep them as is.",0,0.9682496190071106
114723919,2964,dguy,2017-05-04T08:41:09Z,"in step 2 isn't the log append callback happening on another thread? so how do we release the read lock? i guess i'm missing something but i'm reading it like this: [code block] which would mean the read lock would be given up as soon as the `appendtolog` call returns, but that doesn't mean the write to the log has actually completed as it might go into purgatory and be completed by another thread. i guess you have some other idea?",0,0.9695252776145935
114724163,2964,dguy,2017-05-04T08:42:42Z,my understanding is that it only needs to be set when we add the first partition to a new transaction.,0,0.9893709421157837
114724204,2964,hachikuji,2017-05-04T08:43:01Z,"why is it safe to access `transactionmetadatacache` without a lock? it seems we protect mutations with the state lock, but since it is not a concurrent collection, don't we need to protect reads as well?",0,0.9930741786956787
114724432,2964,dguy,2017-05-04T08:44:33Z,"ok - that makes sense. however, if this does happen how would we recover from it? we'd have uncommitted data in the logs which would block consumers using read committed. do we have any plans to deal with this?",0,0.9827412962913513
114724503,2964,dguy,2017-05-04T08:45:02Z,yeah - duh! i missed that!,-1,0.9891618490219116
114724840,2964,hachikuji,2017-05-04T08:47:07Z,"not from this patch, but should this be `transactionstatemanager`?",0,0.9940567016601562
114725329,2964,hachikuji,2017-05-04T08:50:12Z,nit: this is not aligned.,-1,0.5878120064735413
114726156,2964,hachikuji,2017-05-04T08:54:40Z,"hmm... it doesn't seem right to synchronize on the instance of `coordinatorepochandtxnmetadata`. we construct a new one in every call to `addtransaction`, right? also, we're still synchronizing on the metadata elsewhere in this file.",0,0.8956378102302551
114726879,2964,hachikuji,2017-05-04T08:58:33Z,"nit: `error`? in spite of the name of `errors`, there is only one error. a few more of these in this class if you're keen.",0,0.9832610487937927
114728807,2964,hachikuji,2017-05-04T09:09:58Z,"this is a comment throughout, but it seems we rarely check the result of `preparetransitionto`. perhaps that function should just raise an invalid state exception if the state transition is invalid? otherwise we should get in the habit of adding the checks.",0,0.9813281297683716
114729513,2964,hachikuji,2017-05-04T09:13:50Z,"nit: not from this patch, but should this be `responsecallback`? it's nice to keep naming consistent and we use this name in `handleinitpid` and `initpidwithexistingmetadata`. it's also helpful that the name expresses that this callback returns to the user.",0,0.8598042726516724
114730909,2964,hachikuji,2017-05-04T09:21:29Z,shouldn't we be using `newmetadata` somehow?,0,0.9935054779052734
114732285,2964,hachikuji,2017-05-04T09:28:44Z,"nit: not from this patch, but couldn't we add a couple constructors to `initpidresult` and remove these functions? or maybe just add default values for pid and epoch.",0,0.9907150268554688
114737164,2964,hachikuji,2017-05-04T09:57:30Z,the reuse of `transactionmetadata` here is super confusing. it seems we just need a struct to propagate the new state to the completion callback. maybe we could do this with an immutable case class instead? maybe `transactionstatetransition` or something.,-1,0.9492886066436768
114739243,2964,hachikuji,2017-05-04T10:09:36Z,"typo: ""competed""",0,0.9442126750946045
114740699,2964,hachikuji,2017-05-04T10:18:53Z,"this is pretty confusing stuff. my understanding is that once this append completes, we'll invoke `transationmetadata.completetransitionto`. in this case, it will be the same `transactionmetadata` object passed to itself. might not be incorrect, but it's definitely weird. by the way, you can replace `epochandmetadata.transactionmetadata` with `metadata`.",-1,0.9896764159202576
114749671,2964,ijuma,2017-05-04T11:19:41Z,"similar to a comment that i left in a different pr, adding type annotations here triggers a pattern match and it's brittle if there are cases where the match can fail, but the compiler can't prove it (any time there is a subclass involved). it's one of the cases where relying on type inference is safer (it will always infer a safe type).",0,0.935346782207489
114750267,2964,ijuma,2017-05-04T11:24:05Z,"btw, a better way to represent this would be using `either[errors, (int, transactionmetadata)]`. even better would be to have a type for the tuple on the right, but even without it, it would make the flow way clearer imo.",0,0.9937451481819153
114807366,2964,guozhangwang,2017-05-04T15:12:07Z,"when a transaction is completed, should we reset the starttimestamp to -1 again to avoid being expired?",0,0.9940240979194641
114807926,2964,guozhangwang,2017-05-04T15:14:05Z,ack.,0,0.5038502812385559
114877797,2964,guozhangwang,2017-05-04T20:20:46Z,when this happens usually ops people need to be involved to manually truncate the log before starting. but i think this code can also be improved a bit for a more graceful shutdown. do you have any ideas?,0,0.9683012962341309
114878149,2964,guozhangwang,2017-05-04T20:22:13Z,"as i said we only need to make sure the the log entry is appended to the local data segment (even not required to flushed on disk), not necessarily replicated complete.",0,0.9895033836364746
114879314,2964,guozhangwang,2017-05-04T20:27:35Z,"1. please see my previous comment: we will modify the `statelock` into a read-write lock and the only operations that could mutate the top-level map `transactionmetadatacache` will be covered (the checking / append-to-log will be covered in read lock). 2. for the lower-level map `pool[string, transactionmetadata]`, its operations are thread safe and any modifications to the inner `transactionmetadata` will be covered by the object `synchronized` itself and all modifications will be in-place than object override.",0,0.9886227250099182
114879417,2964,guozhangwang,2017-05-04T20:28:03Z,ack.,0,0.5038502812385559
114879969,2964,guozhangwang,2017-05-04T20:30:42Z,"i have also thought about that, e.g. having sth. like [code block] and call it without overriding defaults upon checking failure cases, but i found it is less readable. if you feel strong about it i can change.",0,0.9556542634963989
114880965,2964,guozhangwang,2017-05-04T20:35:07Z,"yeah that is a good question, ideally we should sycnrhonize on `txnmetadata` only, since coordinator epoch will only likely be changed during loading / removal of the metadata. will refactor on this part.",0,0.9464493989944458
114902795,2964,guozhangwang,2017-05-04T22:33:08Z,ack.,0,0.5038502812385559
114903066,2964,guozhangwang,2017-05-04T22:35:06Z,"we check it in `transactionmetadata`, that the new state is equal to the pending state.",0,0.9934983253479004
114903584,2964,guozhangwang,2017-05-04T22:38:28Z,"i just refactored the code a bit around `initpid`, since it is a special case compared with others: 1. in other cases, we first create a new metadata as a place holder of all the pending updates to the original object and then only update it in the callback after append / send marker completes; 2. in `initpid` case, we would try first inserting a dummy into the cache but set its pending state, as `empty -> empty`; if there is an existing entry already we would either a) abort its existing txn first b) return retriable error code or c) update epoch / txn timeout and do the same as case 1) above. the new code path looks better to me know. let me know what do you think.",0,0.9919399619102478
114903764,2964,guozhangwang,2017-05-04T22:39:39Z,ack.,0,0.5038502812385559
114903788,2964,guozhangwang,2017-05-04T22:39:51Z,done.,0,0.9640594124794006
114903866,2964,guozhangwang,2017-05-04T22:40:32Z,"not sure i understand this comment, could you elaborate a bit?",0,0.9220552444458008
114904861,2964,guozhangwang,2017-05-04T22:47:50Z,ack.,0,0.5038502812385559
114905004,2964,guozhangwang,2017-05-04T22:48:54Z,ack.,0,0.5038502812385559
114906261,2964,hachikuji,2017-05-04T22:58:09Z,"but if we know the transition is invalid here, then we could skip appending to the log, right? i feel we should just make `preparetransitionto` raise an exception if the attempted transition is invalid.",0,0.983749508857727
114916468,2964,guozhangwang,2017-05-05T00:32:04Z,discussed offline.,0,0.9136196374893188
114916529,2964,guozhangwang,2017-05-05T00:32:46Z,"edit: discussed offline, realized it is a different issue than i thought about. refactored this part a bit as well.",0,0.9653375744819641
114917535,2964,guozhangwang,2017-05-05T00:45:44Z,"edit: i realized that in many cases i would return a `null`, and it will cause the annotated type to be `any` at compilation time. so i think it is actually better to enforce type annotations in this case.",0,0.9859116077423096
114917644,2964,ijuma,2017-05-05T00:47:01Z,"yeah, you should never use `null` in scala generally. using an `either` here avoids all the issues.",0,0.9790201783180237
114920333,2964,junrao,2017-05-05T01:27:36Z,not sure checking coordinatorepoch here is enough since coordinatorepoch could change when we append the log.,0,0.980782151222229
114921338,2964,guozhangwang,2017-05-05T01:42:57Z,"got it, thanks!",1,0.9856687784194946
114973551,2964,dguy,2017-05-05T11:06:35Z,ok - i missed the local bit. thanks,1,0.9430082440376282
115104932,2964,junrao,2017-05-05T23:36:30Z,"in scala, == tests object equality. i think we want to test reference equality here. if so, we should use eq for testing.",0,0.9894088506698608
115106324,2964,junrao,2017-05-05T23:57:42Z,"hmm, this means that in preparetransitionto(), we need to transition from one state to itself. not sure if all states are allowed to transition from itself.",0,0.7696205973625183
115106407,2964,junrao,2017-05-05T23:59:24Z,"since now there are different types of epoch, would it be better to name this prepareincrementproducerepoch?",0,0.9945977926254272
115106983,2964,junrao,2017-05-06T00:10:02Z,should we include pendingstate in hashcode() and equals()?,0,0.9946375489234924
115107794,2964,junrao,2017-05-06T00:26:22Z,"hmm, when transitioning from empty to ongoing, it seems it's ok for newmetadata.txnstarttimestamp to be larger than current txnstarttimestamp. it's only when transitioning from ongoing to ongoing that we don't want txnstarttimestamp to change.",0,0.9899047017097473
115107921,2964,junrao,2017-05-06T00:29:38Z,"yes, it seems damian's understanding makes sense.",0,0.9328789710998535
115108280,2964,junrao,2017-05-06T00:39:21Z,it seems the comment should be the same as in line 185: let client backoff and rety instead of retry immediately.,0,0.9908506274223328
115147118,2964,junrao,2017-05-07T16:09:38Z,highwatermark below should be renamed to logendoffset?,0,0.9947808384895325
115147657,2964,junrao,2017-05-07T16:32:52Z,"since removetransactions() is cheap, not sure if this needs to be run in a scheduler. also, perhaps it's useful to wait for the scheduler to have no pending task here before return? any pending loadtransaction task should be completed very quickly after removetransactions() is called.",0,0.9905113577842712
115163421,2964,junrao,2017-05-08T02:03:38Z,does brokerrequestqueue.destination need to be volatile?,0,0.9929916858673096
115163433,2964,junrao,2017-05-08T02:03:50Z,"hmm, the while loop may tie up a request handler thread, which is not ideal.",-1,0.6201362609863281
115163443,2964,junrao,2017-05-08T02:04:02Z,"since the timeout for delayedtxnmarker is infinite, do we need a purgatory or just a map?",0,0.9881280064582825
115163467,2964,junrao,2017-05-08T02:04:23Z,"hmm, in the disconnected case, shouldn't we check txnstatemanager.gettransactionstate as well in case an emmigration has happened?",0,0.9925122261047363
115163478,2964,junrao,2017-05-08T02:04:41Z,"since multiple immigration/emigration could have happened when the response comes back, a more reliable way is to check if the current coordinator epoch is still the same as what's in the request.",0,0.9901825785636902
115163488,2964,junrao,2017-05-08T02:04:51Z,should we also remove the entries keyed by transactionalid in purgatory?,0,0.9950653910636902
115163567,2964,junrao,2017-05-08T02:06:01Z,"structure wise, maybe it's better to do this as part of transactionmetadata.completetransitionto() so that we can limit the place where internals of transactionmetadata are modified?",0,0.9949328303337097
115163598,2964,junrao,2017-05-08T02:06:23Z,"hmm, is this right? we watch on transactionalid, not producerid. also, since txnmarkerpurgatory is passed around to different classes, it's bit hard to track who is calling checkandcomplete on this purgatory. an alternative way is to expose an access method to txnmarkerpurgatory in transactionchannelmanager and let all classes call that method.",0,0.9059935808181763
115294821,2964,hachikuji,2017-05-08T16:43:35Z,no strong preference if you already rejected the option.,0,0.9191398620605469
115317861,2964,hachikuji,2017-05-08T18:23:05Z,nit: the `toshort` is not needed.,0,0.9897728562355042
115317895,2964,hachikuji,2017-05-08T18:23:14Z,maybe we could use the `ongoing` state explicitly?,0,0.9942777752876282
115320070,2964,hachikuji,2017-05-08T18:32:24Z,nit: the whole body of `handleinitpid` is misaligned.,0,0.9039762020111084
115321540,2964,hachikuji,2017-05-08T18:38:41Z,"hmm.. if the user is trying to add partitions before the previous transaction has completed, shouldn't that be invalid_txn_state?",0,0.9416418671607971
115322180,2964,hachikuji,2017-05-08T18:41:26Z,nit: i think this is more than an optimization: it is necessary for correctness because there is no guarantee that the client will receive the result of the endtxnrequest.,0,0.9812124371528625
115322387,2964,hachikuji,2017-05-08T18:42:17Z,"nit: comment misaligned. also, pity we can't merge this branch with `completecommit` somehow.",-1,0.9809330701828003
115323214,2964,hachikuji,2017-05-08T18:45:52Z,"hmm... isn't it possible that a client resends an endtxnrequest while we are still in `preparecommit` or `prepareabort`. as long as the outcome matches, it seems we should accept those requests and perhaps return concurrent_transactions? also, can we list the states we're catching here explicitly?",0,0.9840376377105713
115323957,2964,hachikuji,2017-05-08T18:49:13Z,maybe we should log something in the else case?,0,0.993145227432251
115324352,2964,hachikuji,2017-05-08T18:51:00Z,"could we check for the case explicitly with `txnmanager.iscoordinatorfor(transactionalid)`? if the transactionalid did not migrate, then maybe it should be an illegal state.",0,0.9941582679748535
115325045,2964,hachikuji,2017-05-08T18:53:47Z,nit: add newline,0,0.9615535736083984
115337072,2964,hachikuji,2017-05-08T19:51:23Z,this should be `epochandmetadata.transactionmetadata`?,0,0.9949929118156433
115337702,2964,hachikuji,2017-05-08T19:54:22Z,same here: `epochandmetadata.transactionmetadata`.,0,0.9930557608604431
115338461,2964,hachikuji,2017-05-08T19:57:45Z,seems this class doesn't depend on the containing instance of `transactionmarkerchannel`. can we move it outside or to the companion object?,0,0.9926055669784546
115339106,2964,hachikuji,2017-05-08T20:01:02Z,nit: `private[transaction]`?,0,0.9937200546264648
115339988,2964,hachikuji,2017-05-08T20:05:42Z,"might be worth noting that `size` is o(n). also, maybe `queued` is redundant given the name of the class. maybe it could just be `totalrequests`?",0,0.9939354062080383
115340279,2964,hachikuji,2017-05-08T20:06:54Z,could this be `private[transaction]`? also i found the name a bit misleading: would `transactionmarkerqueue` or `transactionmarkeraccumulator` be closer?,0,0.982925295829773
115340733,2964,hachikuji,2017-05-08T20:09:05Z,maybe `brokerrequestqueues`?,0,0.9945812821388245
115350244,2964,hachikuji,2017-05-08T20:51:55Z,"it would be nice to decouple `transactionstatemanager` from `transactionmarkerchannel`. one way to do this is to move the building of the `requestandcompletionhandler` objects into `requestgenerator`. you can let `drainqueuedtransactionmarkers` return something like `map[int, list[txnidandmarkerentry]]`. then `transactionmarkerchannel` would not need a reference to `transactionstatemanager`. also, the generator pattern is a little odd. could we just make `interbrokersendthread` an abstract class with an abstract method `generaterequests`? in that case, you could let `transactionmarkerchannelmanager` extend directly from `interbrokersendthread` and implement the request generation.",0,0.9847474098205566
115351637,2964,hachikuji,2017-05-08T20:58:10Z,kind of unfortunate that we have a dependence on `networkclient` only in order to invoke this `wakeup()`. i'm wondering if the callers could do it instead and we can remove the dependence? that will help to decouple the objects which will make testing easier.,-1,0.9501086473464966
115352392,2964,hachikuji,2017-05-08T21:01:56Z,why do we do this? maybe worth a comment.,0,0.959611713886261
115353412,2964,hachikuji,2017-05-08T21:07:07Z,also it seems like a good idea to verify that the state of the transaction is still what we expect.,0,0.9335663318634033
115353802,2964,hachikuji,2017-05-08T21:09:02Z,i think `request_timeout` might be another possibility.,0,0.9856788516044617
115354587,2964,hachikuji,2017-05-08T21:13:06Z,i wonder if you can add a comment explaining when this case can happen.,0,0.971201479434967
115356024,2964,hachikuji,2017-05-08T21:20:23Z,sounds good. will that be part of this patch?,1,0.9329937100410461
115356574,2964,hachikuji,2017-05-08T21:23:11Z,the cast to `filerecords` is not totally safe. i fixed the same problem in `groupmetadatamanager` recently.,0,0.9647586345672607
115356894,2964,hachikuji,2017-05-08T21:24:41Z,nit: pattern match?,0,0.9880815744400024
115359708,2964,hachikuji,2017-05-08T21:37:56Z,"a cache change due to emigration/immigration would be handled by the epoch check, right? are there any cases where `completetransitionto` itself could fail?",0,0.9949114918708801
115377273,2964,guozhangwang,2017-05-08T23:25:55Z,ack.,0,0.5038502812385559
115377857,2964,guozhangwang,2017-05-08T23:30:27Z,"we could be loading for partition x while removing for partition y in this case, so waiting for the removing to complete may still take long time right? another benefit to let all three operations (loading, removing-partition, expiring-txns) to be execute by the same back ground thread is that locking mechanism would be a bit easier to reason (this is not part of this pr): only background thread would grab the write lock, and the handler thread will only try to grab read lock, and handler thread would not add / remove any entries from the maps but just modify the objects in-place.",0,0.9831998348236084
115378256,2964,guozhangwang,2017-05-08T23:33:08Z,"not sure i understand your question? `coordinatorepoch` is the value passed from the caller, which is the epoch of the cached metadata object before append is called, and here we are checking if it is still the same epoch by reading from the cache again. plus inside `completetransitionto` we also check that other fields inside metadata are expected.",0,0.9925210475921631
115378411,2964,guozhangwang,2017-05-08T23:34:33Z,ack.,0,0.5038502812385559
115378474,2964,guozhangwang,2017-05-08T23:35:07Z,ack.,0,0.5038502812385559
115378959,2964,guozhangwang,2017-05-08T23:38:52Z,"we only allow `empty` -> `empty` transition, and it is a special case for adding a txnid for the first time, the inserted entry will be empty and its pending state also empty. only when the pending state is cleared after the txn log write returns it is considered ""created succesfully"". as for this function itself, it is only used when `initpid` is received while the current pid has an ongoing txn, i.e. it is `ongoing`, and later we check if it is `ongoing` we will abort the txn first and return `concurrent_txn` to let user retry.",0,0.9887819886207581
115378997,2964,guozhangwang,2017-05-08T23:39:07Z,ack.,0,0.5038502812385559
115379242,2964,guozhangwang,2017-05-08T23:41:29Z,"that is true: when the pid is first created, there is no txn yet, the starttime is set to ""-1"", when we received the first addpartitions we will update the starttime to `now`, and it will not be updated until it has completed, and then a new addpartition is received indicating the start of a new txn for this pid.",0,0.9920704960823059
115379741,2964,guozhangwang,2017-05-08T23:45:48Z,ack.,0,0.5038502812385559
115379921,2964,guozhangwang,2017-05-08T23:47:17Z,good point! ack.,1,0.9937132000923157
115380508,2964,guozhangwang,2017-05-08T23:51:53Z,"yeah i have thought about that too.. the approach is that if we cannot locate the broker to offer to its queue then in order for this thread to return we likely need to put it in an ""unknown broker"" queue first, and periodically we can check the queue and migrate to the found brokers. does that make sense?",0,0.9795413613319397
115381202,2964,guozhangwang,2017-05-08T23:57:25Z,"i have not made up my mind about infinite timeout, and would like to have another discussion with you (as i left some comments in damian's previous patch: [a link] for now i'll add a todo marker and do that in a follow-up once we have a conclusion.",0,0.9110884070396423
115381919,2964,guozhangwang,2017-05-09T00:02:41Z,"we check that in the `appendtologcallback` callback in `txnmarkerchannelmanager`. generally speaking here is the reasoning: 1. for the handler logic, the only error code that we should not retry is ""coordinatorepochnotvalid"", in which we should complete the delayed operation immediately with a meaningful error code (currently it is always `none` ). 2. then in `appendtologcallback`, we check the error code, and if it is due to received `coordinatorepochnotvalid` we can simply ignore the rest of the operations.",0,0.9951934218406677
115382316,2964,guozhangwang,2017-05-09T00:05:42Z,"ack. i have re-factored the handling logic here to cover all the error codes, please take a look at the modified file.",0,0.767771303653717
115382553,2964,guozhangwang,2017-05-09T00:07:44Z,"not sure i understand the comment, we are indeed canceling for the transactionalid right?",0,0.9570341110229492
115382668,2964,guozhangwang,2017-05-09T00:08:47Z,ack.,0,0.5038502812385559
115388039,2964,guozhangwang,2017-05-09T00:57:01Z,ack.,0,0.5038502812385559
115388145,2964,guozhangwang,2017-05-09T00:57:55Z,ack.,0,0.5038502812385559
115388336,2964,guozhangwang,2017-05-09T00:59:38Z,"well, since we return to the user right after we have appended the log, in which case the state has updated to `preparexx`, the client code is possible to send another `addpartitions` while the sending markers are still on the flight. in this case we should not return a fatal error but let client retry.",0,0.9902593493461609
115388370,2964,guozhangwang,2017-05-09T01:00:07Z,"okay, will update the comments.",0,0.98270183801651
115388416,2964,guozhangwang,2017-05-09T01:00:37Z,ack.,0,0.5038502812385559
115388582,2964,guozhangwang,2017-05-09T01:02:29Z,good point! ack.,1,0.9937132000923157
115388842,2964,guozhangwang,2017-05-09T01:05:18Z,"edit: actually i think for most cases this case should be covered in `txnmetadata.pendingtransitioninprogress`, the only edge case that we have migrated to `preparexx` but have not prepareto `completexx` (note they should happen fairly consecutively). anyways, will add them to cover it as well.",0,0.9924057126045227
115389069,2964,guozhangwang,2017-05-09T01:08:13Z,ack.,0,0.5038502812385559
115389114,2964,guozhangwang,2017-05-09T01:08:46Z,"good point, ack.",1,0.9062934517860413
115536083,2964,hachikuji,2017-05-09T16:28:18Z,"ack, makes sense.",0,0.8411178588867188
115614545,2964,guozhangwang,2017-05-09T22:09:10Z,ack.,0,0.5038502812385559
115614791,2964,guozhangwang,2017-05-09T22:10:33Z,ack.,0,0.5038502812385559
115614938,2964,guozhangwang,2017-05-09T22:11:25Z,ack. this will be part of the minor refactoring that exhausts all the possible error codes in the writetxnmarker responses.,0,0.9655947089195251
115616278,2964,guozhangwang,2017-05-09T22:20:04Z,"actually i just realized we do not need to check the coordinator epoch anymore, since it is already checked in `appendtransactiontolog#updatecachecallback`, which is executed before calling this callback, so the error code returned is already reflecting the fact if [code block] so we can directly go head with the error code here.",0,0.9870142936706543
115624264,2964,guozhangwang,2017-05-09T23:17:10Z,"ack. after thinking about this, i'm going to merge the `markerchannel` into `markerchannelmanager` since it is always a one-to-one mapping.",-1,0.7441794276237488
115624364,2964,guozhangwang,2017-05-09T23:17:56Z,ack.,0,0.5038502812385559
115624544,2964,guozhangwang,2017-05-09T23:19:24Z,ack.,0,0.5038502812385559
115624880,2964,guozhangwang,2017-05-09T23:21:56Z,ack.,0,0.5038502812385559
115624941,2964,guozhangwang,2017-05-09T23:22:30Z,ack. let me know wdyt about the after-refactoring.,-1,0.9767657518386841
115625053,2964,guozhangwang,2017-05-09T23:23:25Z,ack.,0,0.5038502812385559
115625404,2964,guozhangwang,2017-05-09T23:26:02Z,"i'm not sure either, it is from the old code. my understanding is that `networkclient` is only pollable from the `sendthread`, and hence `wakeup` is not required. but maybe i'm missing something here, cc",0,0.9097425937652588
115628649,2964,guozhangwang,2017-05-09T23:52:22Z,rebased this already.,0,0.9873364567756653
115628821,2964,guozhangwang,2017-05-09T23:53:43Z,could you elaborate a bit? we only have logic for the `if` condition?,0,0.9935013651847839
115629030,2964,guozhangwang,2017-05-09T23:55:31Z,"good point, we could consider throw exception directly instead of returning false. there are a few of those suggestions that we can do in a follow-up pr. i have marked those places with `todo`s.",0,0.8398849368095398
115636450,2964,guozhangwang,2017-05-10T01:06:03Z,"i checked the source code, `timeoutexception` can only be thrown from producer / consumer internals, but they will never be returned from the broker side. so this should not be a possibility?",0,0.9907411336898804
115643581,2964,hachikuji,2017-05-10T02:26:46Z,did you also look for uses of `errors.request_timeout`?,0,0.9944843649864197
115647476,2964,guozhangwang,2017-05-10T03:21:13Z,you mean `request_timed_out`? there is no `request_timeout` in errors. for the latter case i searched the code and found no return errors from broker-side.,0,0.9926201701164246
116116648,2964,hachikuji,2017-05-11T22:25:56Z,"after we remove `transactionmarkerchannel`, maybe we can claim its name for this class?",0,0.9953535795211792
116124062,2964,hachikuji,2017-05-11T23:17:38Z,"can we mention the partition number? also, ""may likely has emigrated"" -> ""has likely emigrated""?",0,0.9945336580276489
116124812,2964,hachikuji,2017-05-11T23:23:57Z,"if the epoch has changed, is it still necessary or safe to continue with the logic below? in particular, we could still remove the partitions from `transactionmetadata`. maybe we should just return?",0,0.9947033524513245
116125417,2964,hachikuji,2017-05-11T23:28:33Z,we discussed offline changing this to assert a valid transition instead of returning a boolean. we could do this in a follow-up if you prefer.,0,0.9893810749053955
116125544,2964,hachikuji,2017-05-11T23:29:31Z,"should we return here? otherwise, the call to `completesendmarkersfortxnid` will be invoked below. not sure it's a problem, but seems odd. also, i'm not sure i fully understand the chain of operations that this should trigger. it seems that `removemarkersfortxnid` cancels the `delayedtxnmarker`, which means its callback won't get invoked. but what happens to the state of the `transactionmetadata`? it seems like it will just remain indefinitely in one of the prepare states. for coordinatorfenced, that seems ok; we rely on the partition to ultimately be evicted. how about producerfenced? i'm actually having a tough time imagining a scenario where we would hit that error. the only one that comes to mind is if the coordinator has become a zombie, in which case we should get blocked by the coordinator epoch. are there any others? in any case, i think it would be helpful to add some comments here clarifying the scenario and the handling expectation.",0,0.7542022466659546
116155904,2964,guozhangwang,2017-05-12T05:39:45Z,"it is done already, but was not pushed somehow, could you check again now?",0,0.9937191009521484
116156002,2964,guozhangwang,2017-05-12T05:40:42Z,this call is just for removing the delayed operation in the txn marker purgatory. i think it is still safe.,0,0.9834152460098267
116156202,2964,guozhangwang,2017-05-12T05:44:07Z,"`transactionmetadata` should be removed by the emmigration handler thread, and in the future the pid expiration scheduler's thread. other handling logic should never remove the entry, but just to update the entry in-place. and about returning here: good catch! yeah we should not call `completesendmarkersfortxnid` in this case. will fix now.",1,0.9836993217468262
116312856,2964,junrao,2017-05-12T20:00:37Z,reaperenabled doesn't seem be be used.,0,0.9411846995353699
116323993,2964,junrao,2017-05-12T21:03:33Z,is appending w/o synchronization on coordinator epoch safe? we don't want to write to the log if the coordinator epoch has changed. the most reliable way is probably to hold a read lock on transactionstatemanager.statelock() while doing the log append.,0,0.9915243983268738
116338170,2964,junrao,2017-05-12T22:54:25Z,"hmm, not sure if this is completely safe. in removetransactionsfortxntopicpartition(), we modify loadingpartitions in the scheduler and here, we modify loadingpartitions in the method directly. this means that if an emmigration is followed immediately by an immigration, the updating of loadingpartitions by emmigration could happen after the updating of loadingpartitions by immigration, which will leave the state incorrect.",0,0.9193963408470154
116339508,2964,junrao,2017-05-12T23:08:39Z,"the issue of changing the transaction states in the scheduler is that when this call returns, the new transaction states are not necessarily reflected. so, another request after this call may still see the old states?",0,0.9882269501686096
116340857,2964,junrao,2017-05-12T23:24:13Z,"txnmarkerpurgatory registers each item under transactionalid and txntopicpartition. we are only removing the item registered under transactionalid. so, which process will be removing the item registered under txntopicpartition, especially the reaper thread is not running in txnmarkerpurgatory?",0,0.99101722240448
116342175,2964,junrao,2017-05-12T23:42:41Z,"since we always send none as error in delayedtxnmarker, it seems that we can just get rid of error?",0,0.9939974546432495
116343892,2964,junrao,2017-05-13T00:10:43Z,"yes, it's just that in the case that a transaction coordinator's epoch has changed, there is no need to keep resending the writemarker request to the brokers.",0,0.9914387464523315
116638694,2964,guozhangwang,2017-05-16T01:44:41Z,ack.,0,0.5038502812385559
116638797,2964,guozhangwang,2017-05-16T01:46:02Z,"yup, it is going to be done in the locking pr that i'm also working on now. just trying to keep each pr small to make it easier for reviews.",0,0.927707314491272
116638956,2964,guozhangwang,2017-05-16T01:47:58Z,good catch! ack.,1,0.9950573444366455
116639242,2964,guozhangwang,2017-05-16T01:51:08Z,it is in the `transactionmarkerchannelmanager#removemarkersfortxntopicpartition`.,0,0.9951450228691101
116639395,2964,guozhangwang,2017-05-16T01:52:49Z,"hmm that is right, but i feel we will probably need to add other possible error codes as we as fixing various error cases under integration tests, so i'd rather keep it as is for now. if after exactly-once has been quite stable and we still do not have any other error code we can remove it. but let mw add a todo for now in case we forgot..",0,0.900467038154602
116650638,2964,guozhangwang,2017-05-16T03:53:57Z,makes sense. i will add the check.,0,0.9219503998756409
116653014,2964,guozhangwang,2017-05-16T04:29:03Z,"got it. however, if we just do the removal in the handler thread, then the immigrate-then-emigrate issue may occur. on the other hand, we cannot depend on scheduler do not have pending request since we are periodically schedule txn-expiration and pid-expiration with that scheduler as well. so here is what i will do: add a removal partitions which will be modified in the handler thread, then get txn metadata will check if the txn partition is in the removal partitions set. then in the locking pr, i will add the read-write-lock so that checking will be monitored by the read lock. wdyt?",0,0.986729621887207
79560389,1884,dguy,2016-09-20T08:35:42Z,private?,0,0.9812482595443726
79560800,1884,dguy,2016-09-20T08:38:32Z,"delegate to the other constructor: `this(config, 0, window_change_log_additional_retention_default)`",0,0.9936227202415466
79562570,1884,dguy,2016-09-20T08:49:18Z,if the topic exists we need to make sure the number of partitions is the same. if it isn't the same then we should throw an exception.,0,0.9850897789001465
79563507,1884,dguy,2016-09-20T08:54:49Z,doesn't look like this method is used anywhere?,0,0.9423396587371826
79566464,1884,dguy,2016-09-20T09:12:18Z,is this needed? it is not used anywhere,0,0.97505784034729
79566488,1884,dguy,2016-09-20T09:12:26Z,as above,0,0.9391705989837646
79566646,1884,dguy,2016-09-20T09:13:21Z,this doesn't need to be a field. could be a local in the constructor,0,0.9889577627182007
79566686,1884,dguy,2016-09-20T09:13:42Z,as above,0,0.9391705989837646
79566702,1884,dguy,2016-09-20T09:13:50Z,as above,0,0.9391705989837646
79567055,1884,dguy,2016-09-20T09:15:58Z,"nit: using an instance variable to reference a static. should be: `this.metadata = new metadata(streamsconfig.getlong(streamsconfig.retry_backoff_ms_config), streamsconfig.getlong(streamsconfig.metadata_max_age_config));`",0,0.9945031404495239
79568023,1884,dguy,2016-09-20T09:21:29Z,should this just use `streamsconfig.metric_reporter_classes_config`? and then i don't see why we need line 100,0,0.9927933216094971
79568120,1884,dguy,2016-09-20T09:22:09Z,`streamsconfig.connections_max_idle_ms_config`,0,0.9937293529510498
79568305,1884,dguy,2016-09-20T09:23:19Z,"as above. next 4 lines should use the class to reference static fields, i.e., `streamsconfig.reconnect_backoff_ms_config`",0,0.9951188564300537
79568817,1884,dguy,2016-09-20T09:25:55Z,`private static final max_iterations` ?,0,0.9919672608375549
79569302,1884,dguy,2016-09-20T09:28:55Z,nit: my preference is that all immutable parameters and fields are `final`. so: `streamskafkaclient(final streamsconfig streamsconfig)` and below: `final time time = ...` etc,0,0.9919003248214722
79569654,1884,dguy,2016-09-20T09:31:03Z,"should we make this into a final static field? i.e., `max_inflight_requests` or similar? i.e., what is 100?",0,0.9953665733337402
79569944,1884,dguy,2016-09-20T09:32:32Z,"what is the 0 for? can we make it into a static final field, so it has a name?",0,0.9945646524429321
79570181,1884,dguy,2016-09-20T09:33:38Z,do we need this? don't think it is used anywhere,0,0.9225971102714539
79570479,1884,dguy,2016-09-20T09:35:10Z,"i don't currently see this being used anywhere. is it going to cause shutdown problems if this isn't closed properly? i.e., will there be non-daemon threads hanging around that cause the jvm to not shutdown?",0,0.9006626605987549
79570684,1884,dguy,2016-09-20T09:36:23Z,`if (...) { .. }`,0,0.991266667842865
79570848,1884,dguy,2016-09-20T09:37:04Z,this should probably throw `streamsexception` as that is the top-level exception for streams,0,0.9944749474525452
79571533,1884,dguy,2016-09-20T09:40:52Z,we should change `internaltopicconfig.toproperties(...)` to return a `map ` then we won't need to copy the properties into the `topicconfig` map below,0,0.994198203086853
79571804,1884,dguy,2016-09-20T09:42:36Z,"nit: as mentioned above. my preference is for params and locals to be final if possible. i know it i adds few extra characters, but it shows intent and can prevent unnecessary bugs",0,0.9009870290756226
79571936,1884,dguy,2016-09-20T09:43:23Z,move this down to line 149 and do the init and assignment on a single line,0,0.9934369921684265
79572482,1884,dguy,2016-09-20T09:46:38Z,i don't think you need this callback. you can just pass `null` if the callback isn't necessary,0,0.9690918326377869
79573826,1884,dguy,2016-09-20T09:53:54Z,it would be good if we could say why it failed. is there a mapping from the error code to a string we could use?,0,0.9824836850166321
79573949,1884,dguy,2016-09-20T09:54:37Z,do we need this method?,0,0.9872057437896729
79575520,1884,dguy,2016-09-20T10:02:57Z,i don't think this should be a field. it probably needs to be done before each request as 1. the least loaded node will change. 2. this node might not be up when the request is made.,0,0.978847324848175
79576598,1884,dguy,2016-09-20T10:08:42Z,perhaps maxiterations should be a timeout instead? also i think it reads cleaner like so: [code block],0,0.990580141544342
79576919,1884,dguy,2016-09-20T10:10:44Z,as above we should probably change `maxiterations` for a timeout,0,0.994231641292572
79577022,1884,dguy,2016-09-20T10:11:19Z,why not just re-use the `systemtime` from above?,0,0.9913095235824585
79577074,1884,dguy,2016-09-20T10:11:44Z,do we need this? it isn't used anywhere.,0,0.9663745164871216
79577318,1884,dguy,2016-09-20T10:13:16Z,move this down to line 279,0,0.9920098781585693
79577973,1884,dguy,2016-09-20T10:17:14Z,nit: looks like the formatting has been unnecessarily changed.,-1,0.8680022358894348
79578001,1884,dguy,2016-09-20T10:17:27Z,nit: formatting?,0,0.8617483973503113
79578105,1884,dguy,2016-09-20T10:18:09Z,do we need this? i don't think we ever delete topics? also the test is commented out,0,0.9834955334663391
79578334,1884,dguy,2016-09-20T10:19:20Z,test commented out. also we may not need this if we merge `streamskafkaclient` and `internaltopicmanager` into a single class.,0,0.9944475889205933
79650885,1884,hjafarpour,2016-09-20T16:16:12Z,"yes, made it private :)",1,0.9719870686531067
79650926,1884,hjafarpour,2016-09-20T16:16:26Z,removed this constructor.,0,0.9774121046066284
79652102,1884,hjafarpour,2016-09-20T16:22:05Z,added the check for the number of partitions.,0,0.9916033148765564
79652577,1884,hjafarpour,2016-09-20T16:24:21Z,made them local in the constructor.,0,0.9907185435295105
79652760,1884,hjafarpour,2016-09-20T16:25:17Z,"they were there from the previous iteration. not being used anymore, removed them.",0,0.981712281703949
79655027,1884,hjafarpour,2016-09-20T16:35:23Z,i used the similar way of creating networkclient in kafkaconsumer. for the streamkafkaclient i can make it a constant as you mentioned. it would be good to update the kafkaconsumer too.,0,0.9598811864852905
79655809,1884,hjafarpour,2016-09-20T16:38:26Z,"yes, corrected them.",0,0.986104428768158
79656213,1884,hjafarpour,2016-09-20T16:40:12Z,"good point, moved it to the request method as a local variable.",0,0.576843798160553
79657266,1884,hjafarpour,2016-09-20T16:44:47Z,we were thinking about having streamskafkaclient available for other uses too. i'm removing this for now and we can add it later if we need it.,0,0.9786559343338013
79657548,1884,hjafarpour,2016-09-20T16:46:06Z,this was here from the previous version and i kept it. i'm going to remove it now since it is not being used.,0,0.9847046136856079
79658172,1884,hjafarpour,2016-09-20T16:49:07Z,that's a good practice. made all of the params that won't change final.,1,0.9005270004272461
79659263,1884,hjafarpour,2016-09-20T16:54:20Z,made it null.,0,0.9707766175270081
79659681,1884,hjafarpour,2016-09-20T16:56:25Z,i could get the error name or message. i am adding error name to the message.,0,0.9782121181488037
79659793,1884,hjafarpour,2016-09-20T16:56:59Z,it's not being used but we can have it in the streamskafkaclient for future use.,0,0.994023859500885
79666863,1884,hjafarpour,2016-09-20T17:28:40Z,changed them to timeouts.,0,0.9817296862602234
79667197,1884,hjafarpour,2016-09-20T17:30:15Z,needed for checking the partition number.,0,0.9890753030776978
79667509,1884,hjafarpour,2016-09-20T17:31:26Z,i'm removing these tests then.,0,0.9413141012191772
79777362,1884,dguy,2016-09-21T07:54:43Z,i'd probably use the same importance level as was used in the consumer or producer config,0,0.9911474585533142
79777945,1884,dguy,2016-09-21T07:58:22Z,"i know i said make this private... looking again it isn't actually used anywhere apart from the constructor, so it can be removed.",0,0.9616352915763855
79778569,1884,dguy,2016-09-21T08:02:37Z,"i have a pr to remove this method, [a link] as it is unused. if you want to remove it i'll close the pr? also, if you do remove it then you can also remove line 37. edit: sorry the pr was merged before i'd seen your update.",-1,0.9836295247077942
79779302,1884,dguy,2016-09-21T08:07:32Z,"a better way to do this would be to pass in the streamskafkaclient, i.e., `public internaltopicmanager(final streamskafkaclient streamskafkaclient, final int replicationfactor, final long windowchangelogadditionalretention)` why? well the `streamsconfig` is only used to construct the `streamskafkaclient` and it would mean in unit tests we can pass in a stub or mock for `streamskafkaclient`. we can then remove the no-arg constructor on line 60 (it is only used in `mockinternaltopicmanager`)",0,0.9944416880607605
79782495,1884,dguy,2016-09-21T08:27:12Z,"strictly not part of this pr, but might as-well make these params `final` :-)",1,0.9698940515518188
79783003,1884,dguy,2016-09-21T08:29:39Z,`final`,0,0.9858572483062744
79785267,1884,dguy,2016-09-21T08:42:57Z,"i'm thinking in `streamskafkaclient.gettopicmetadata(..)` we could just return the `metadataresponse.topicmetadata` regardless of the `error().code()`. so then i think we will never get `null` here as i believe we will always get a response. we can then throw an exception with a more meaningful message, i.e., based on the `error().code()` - rather than just ""topic metadata is corrupted""",0,0.9899842739105225
79785576,1884,dguy,2016-09-21T08:44:40Z,looks like this can be a local now?,0,0.9901638627052307
79785702,1884,dguy,2016-09-21T08:45:29Z,"again, i'd make all the immutable locals `final` - it is a good habit to get into. so, `metricstags`, `metadata`, `metricconfig`, `reporters`, `channelbuilder`, `selector`",0,0.9557783007621765
79786661,1884,dguy,2016-09-21T08:50:25Z,"again, `final` for all locals. also, as per my previous comment on this. i think we should change `internaltopicconfig.toproperties(...)` to return `map ` and then we don't need to copy the props into another `map`",0,0.9777151346206665
79787573,1884,dguy,2016-09-21T08:55:18Z,i still think if this is not being used anywhere we should remove it. if we really want to keep it then we need a test for it.,0,0.9659994840621948
79787831,1884,dguy,2016-09-21T08:56:41Z,"""deleting topic {} from brokers ..."" ?",0,0.9921918511390686
79787999,1884,dguy,2016-09-21T08:57:38Z,we can make all of these locals `final`,0,0.9858766794204712
79788308,1884,dguy,2016-09-21T08:59:11Z,"maybe we should make this a better name, like `readytimeout` ?",0,0.9937307834625244
79788383,1884,dguy,2016-09-21T08:59:40Z,"same here, maybe sth like: `requesttimeout`",0,0.9924909472465515
79788859,1884,dguy,2016-09-21T09:02:16Z,"probably need a more descriptive message, i.e., ""timed out waiting for node="" + brokernode + "" to become available""",0,0.9896025061607361
79789101,1884,dguy,2016-09-21T09:03:54Z,"i think this is more like: ""failed to get response from node="" + brokernode + "" within timeout""",0,0.9716988205909729
79789452,1884,dguy,2016-09-21T09:06:15Z,we can remove this as the callback isn't required. we can also remove the `callback` param from `sendrequest(..)` as we don't need it.,0,0.9941624999046326
79789680,1884,dguy,2016-09-21T09:07:42Z,"private? is only used in this class, so there is no need to make it public. also, as per comment below, we can probably remove the `callback` arg as we don't really need it, i.e., we can just pass `null` for the callback.",0,0.9938714504241943
79790026,1884,dguy,2016-09-21T09:10:00Z,see my comment above in `internaltopicmanager`; we can probably just return the matching `metadataresponse.topicmetadata` instance here. as far as i know it will never be null. if we don't find one then we should probably throw an exception,0,0.9931545257568359
79790100,1884,dguy,2016-09-21T09:10:25Z,`final` locals...,0,0.9910591244697571
79790238,1884,dguy,2016-09-21T09:11:16Z,`final` param and locals,0,0.9898923635482788
79790517,1884,dguy,2016-09-21T09:13:01Z,"`props.put(consumerconfig.key_deserializer_class_config, serdes.string().deserializer().getclass())` same on next line",0,0.9950426816940308
79790921,1884,dguy,2016-09-21T09:15:01Z,nit: `new kafkaconsumer<>(props);`,0,0.9919992089271545
79791157,1884,dguy,2016-09-21T09:16:14Z,"nit: formatting i.e., `for (string topicnameinlist : topics.keyset())`",0,0.9935014843940735
80079829,1884,hjafarpour,2016-09-22T16:21:32Z,changed it to medium.,0,0.9887863397598267
80080356,1884,hjafarpour,2016-09-22T16:24:26Z,removed it.,0,0.9713639616966248
80080581,1884,hjafarpour,2016-09-22T16:25:36Z,"removed it, please close the pr.",0,0.9910791516304016
80081058,1884,hjafarpour,2016-09-22T16:28:15Z,"good point, made the change accordingly!",1,0.9816460013389587
80081221,1884,hjafarpour,2016-09-22T16:29:01Z,they are final now :),1,0.9740291833877563
80082570,1884,hjafarpour,2016-09-22T16:36:00Z,"made the change, include error code in the message.",0,0.9887056946754456
80082828,1884,hjafarpour,2016-09-22T16:37:24Z,"yes, after the previous changes it only is used in one method. changed it to local.",0,0.989841639995575
80083158,1884,hjafarpour,2016-09-22T16:39:06Z,all are final now :),1,0.9833639860153198
80083950,1884,hjafarpour,2016-09-22T16:43:10Z,the method is being used in quite a few tests too. if i change it i should change those tests too. do you want me to go ahead and make the change?,0,0.9727383852005005
80084032,1884,hjafarpour,2016-09-22T16:43:33Z,removed it.,0,0.9713639616966248
80084885,1884,hjafarpour,2016-09-22T16:48:09Z,made the change!,0,0.9504608511924744
80200474,1884,dguy,2016-09-23T08:21:18Z,can remove this as it is no longer used,0,0.987653911113739
80200580,1884,dguy,2016-09-23T08:22:06Z,`final` params?,0,0.990549623966217
80204324,1884,dguy,2016-09-23T08:47:49Z,"i think we can remove this constructor now. it is only used in the constructor of `mockinternaltopicmanager`. so, we could change the `mockinternaltopicmanager` constructor to also take a `streamsconfig` as a param. the `streamsconfig` could be minimal, i.e, just `application_id_config` and `bootstrap_servers_config` would need to be set. then in `mockinternaltopicmanager` constructor we just do: `super(new streamskafkaclient(streamsconfig), 0, 0)` and then we can remove this constructor as it is not needed. also means we can mark `streamskafkaclient` on line 39 as `final`",0,0.9940484762191772
80204544,1884,dguy,2016-09-23T08:48:56Z,is there a mapping from the `short` code to a string somewhere?,0,0.9947999715805054
80204699,1884,dguy,2016-09-23T08:49:56Z,can remove this todo as we need these 2 config properties. all the others have been removed.,0,0.990880012512207
80205835,1884,dguy,2016-09-23T08:57:19Z,can remove this as it is not used.,0,0.9840599298477173
80206000,1884,dguy,2016-09-23T08:58:35Z,`final`,0,0.9858572483062744
80206022,1884,dguy,2016-09-23T08:58:43Z,`final`,0,0.9858572483062744
80207103,1884,dguy,2016-09-23T09:06:04Z,`final`,0,0.9858572483062744
80207117,1884,dguy,2016-09-23T09:06:12Z,`final`,0,0.9858572483062744
80207158,1884,dguy,2016-09-23T09:06:30Z,`final`,0,0.9858572483062744
80207228,1884,dguy,2016-09-23T09:07:00Z,`final`,0,0.9858572483062744
80207325,1884,dguy,2016-09-23T09:07:37Z,`collections.singletonlist(topic)`,0,0.9913233518600464
80213799,1884,dguy,2016-09-23T09:48:38Z,"it would be great if you do, but we can probably do it as another pr if you'd prefer. up to you",0,0.8636651039123535
80285978,1884,hjafarpour,2016-09-23T17:10:59Z,removed it.,0,0.9713639616966248
80286072,1884,hjafarpour,2016-09-23T17:11:32Z,removed it.,0,0.9713639616966248
80288512,1884,hjafarpour,2016-09-23T17:25:49Z,"couldn't find it in the docs. in the code we have ""org.apache.kafka.common.protocol.errors"". i can also print message() or exceptionname() instead of the code. adding the message().",0,0.9931707382202148
80288656,1884,hjafarpour,2016-09-23T17:26:32Z,removed it.,0,0.9713639616966248
80295804,1884,dguy,2016-09-23T18:03:55Z,do we need to add the `jmxreporter` here? the `todo` suggest we should be doing something differernt,0,0.993416428565979
80505313,1884,hjafarpour,2016-09-26T15:42:06Z,"in kafkastreams.java jmx_prefix is defined private: private static final string jmx_prefix = ""kafka.streams""; i could either make it public and use it here or define a new field here. which one would you suggest?",0,0.9946627616882324
80983996,1884,guozhangwang,2016-09-28T18:19:59Z,do we still need this since we already have `testcompile project(':core')` in line 704 which should bring in zkclient jars transitively?,0,0.9952943921089172
80986713,1884,guozhangwang,2016-09-28T18:32:04Z,"nit: instead of declaring a new doc variable, could we just refer to `commonclientconfigs.xxx_doc` in the `.define`?",0,0.9956658482551575
80987096,1884,guozhangwang,2016-09-28T18:33:35Z,we could use a smaller default value as this is only used for admin requests that are mostly small.,0,0.9891523122787476
80987442,1884,guozhangwang,2016-09-28T18:35:14Z,`final`,0,0.9858572483062744
80987926,1884,guozhangwang,2016-09-28T18:37:27Z,are these two props `cleanup_policy_prop` and `retention_ms` used anywhere any more?,0,0.9950011372566223
80990290,1884,guozhangwang,2016-09-28T18:48:09Z,also should we remove `zookeeper_connect_config` above as well?,0,0.994918167591095
80990884,1884,guozhangwang,2016-09-28T18:50:49Z,"in there future we will have an `adminclient` as part of completing kip-4 which is used for all such admin requests, and that can be used in kstream, kconnect, replicator, mm, etc. and whoever is about to implementing it would be suggested to borrow from this class. so i think it is ok to keep it as is for internals, and replacing it with the `adminclient` in the future.",0,0.984560489654541
80992348,1884,guozhangwang,2016-09-28T18:57:47Z,"currently the embedded client: producer, consumer, and admin, have their own metrics and reporters, and we are only correlating them with the `clientid` in the tags. it is better to be improved with hierarchical metrics moving forward. for now i think we can just follow this way but change the prefix in `jmxreporter` from `kafka.streams` to `kafka.admin`?",0,0.9929498434066772
80992958,1884,guozhangwang,2016-09-28T19:00:21Z,the comment is a bit misleading: `polls the request for a given number of iterations to receive the response.` isn't it `keep polling until the corresponding response is received`?,0,0.9146758913993835
80996029,1884,guozhangwang,2016-09-28T19:16:18Z,"if the broker node is not ready, should we consider picking a different broker instead of tie-ing up one thread doing the while loop here?",0,0.9806157946586609
80996757,1884,guozhangwang,2016-09-28T19:20:27Z,"is it a good behavior that we are simply dropping all other responses on the floor while waiting for the corresponding response? i think today we will not encounter such issues since we always send one request, and block on its response and then send another one. but this is less efficient since with n topics to create we have to go n round trips now, suppose moving forward we will do that in a more batched manner where multiple in-flight requests exist, then i this will be an issue. so instead of checking if the response, could we use the `requestcompletionhandler` interface with sth. similar to consumer where we poll until the handler set the `future` indicating it is received and processed?",0,0.9668957591056824
80996887,1884,guozhangwang,2016-09-28T19:21:07Z,"using another temporary consumer is very inefficient, could we just use `listoffsetrequest` with the admin client here?",0,0.8433133363723755
81010527,1884,guozhangwang,2016-09-28T20:33:33Z,"related to the comment below: since only one request is sent at a time, the `leastloadednode` function is not taking any load into consideration actually; so i think we could just iterate over the nodes and find one that is ready, and if all destination nodes are not ready, backoff based on the configured value and retry again.",0,0.9906885623931885
81013284,1884,dguy,2016-09-28T20:46:42Z,will sending `listoffsetrequest` result in creating the topic when `auto.topic.create` is true?,0,0.9946305751800537
81014530,1884,guozhangwang,2016-09-28T20:52:50Z,"sorry i meant `metadatarequest`, not `listoffsetrequest`. if you specify the topics to be the empty list (i.e. `all_topics_request`), then the broker will not create any topics even with `auto.topic.create` is true.",-1,0.9634038805961609
81044949,1884,mjsax,2016-09-29T00:22:36Z,"this class is still there. i did not follow the whole discussion, but i agree with that we might want to remove this class... what is the reason for keeping it?",0,0.8924915194511414
81047430,1884,guozhangwang,2016-09-29T00:47:43Z,"in `streampartitionassignor`, there is a while loop checking that the metadata has been refreshed with the right number of partitions: [code block] which is error-prone. could we remove that logic and check that the topic metadata has propagated to to the broker with the same `streamskafkaclient.topicexists(topic.name()`, i.e.: [code block]",0,0.9941489696502686
81047544,1884,guozhangwang,2016-09-29T00:48:38Z,just fyi and i found the original while-loop may be the culprit of the recent unit test hanging issue.,0,0.9678727388381958
81155529,1884,enothereska,2016-09-29T14:52:59Z,so we still need to connect to zookeeper directly to do this verification? we can't get rid of the zk dependency in tests?,0,0.9932094216346741
81163558,1884,dguy,2016-09-29T15:25:40Z,it is a combination of that and auto topic creation,0,0.9931524991989136
84377963,1884,guozhangwang,2016-10-20T21:18:21Z,"can we merge these two functions `filterexistingtopics` and `gettopicstobedeleted` into a single one, or just in-line this logic in the `makeready` function as this seems specific in the internaltopicmanager, not in the kafkaclient.",0,0.9958991408348083
84378019,1884,guozhangwang,2016-10-20T21:18:43Z,this function seems not used any more.,0,0.9564441442489624
84378082,1884,guozhangwang,2016-10-20T21:19:06Z,ditto below.,0,0.9766393303871155
84378389,1884,guozhangwang,2016-10-20T21:21:11Z,this can be private.,0,0.9784858226776123
84378437,1884,guozhangwang,2016-10-20T21:21:27Z,not used any more.,0,0.9752004742622375
84378526,1884,guozhangwang,2016-10-20T21:22:03Z,not used any more.,0,0.9752004742622375
84378580,1884,guozhangwang,2016-10-20T21:22:22Z,the function name needs to be updated to `createtopics`.,0,0.9936740398406982
84379587,1884,guozhangwang,2016-10-20T21:28:19Z,"do we want to use the same value for `networkclient.poll()` timeout, and as well as the timeout value of `create/deletetopic` requests? in addition the `max_wait_time_ms` is 30 seconds which is even lower than the default value of timeout, so it is likely that the `client.poll()` will not return even when `max_wait_time_ms` has elapsed.",0,0.9938862919807434
84737925,1884,hjafarpour,2016-10-24T17:24:12Z,pushed a new version with the updates you mentioned.,0,0.9901933073997498
94757625,1884,ijuma,2017-01-05T12:12:49Z,we should not add this file back. we removed it intentionally.,0,0.9703654050827026
94757650,1884,ijuma,2017-01-05T12:13:06Z,we should not add this file back. we removed it intentionally.,0,0.9703654050827026
94757707,1884,ijuma,2017-01-05T12:13:39Z,is this dependency still needed? the comment seemed to imply that it wasn't.,0,0.9918538331985474
94758189,1884,ijuma,2017-01-05T12:17:50Z,"instead of instantiating `systemtime`, `time.system` should be used. same applies for other instances where we are creating `systemtime` instances.",0,0.9946069121360779
95036491,1884,guozhangwang,2017-01-06T23:04:12Z,i think `jackson` is not needed either since it was only for json parsing.,0,0.9869838953018188
95036696,1884,guozhangwang,2017-01-06T23:06:15Z,you mean we should just inline this class inside `streampartitionassignor`? personally i feel that class is already quite large and the functionalities in this class is self-contained.,0,0.9827126264572144
95036764,1884,guozhangwang,2017-01-06T23:06:53Z,can be private.,0,0.9774976372718811
95036888,1884,guozhangwang,2017-01-06T23:08:00Z,better add a log entry here since otherwise the error message in `streamsexception` will never be shown anywhere.,0,0.993385374546051
95037077,1884,guozhangwang,2017-01-06T23:09:48Z,can we just inline this function in the other `makeready` since its only caller is the other function?,0,0.9948074221611023
95037147,1884,guozhangwang,2017-01-06T23:10:18Z,can be private.,0,0.9774976372718811
95037232,1884,guozhangwang,2017-01-06T23:11:02Z,"why not catch exceptions thrown here as well? also we should move it as well as the metadata fetching requests (line 60 - 63) inside the retry block as well since each time we retry, the metadata may have changed, right?",0,0.9903449416160583
95037434,1884,guozhangwang,2017-01-06T23:13:04Z,nit: this line not needed.,0,0.9360716342926025
95038339,1884,guozhangwang,2017-01-06T23:22:14Z,"i think this is not a good pattern, since afaik unlike the other clients the only `throwable` is actually `ioexception` (your error message also indicates that doesn't it :p `kafkastreamclient`), and it is only thrown from the metricsreporter.close(), capturing all throwable may hide some issues. instead, we can just let `internaltopicmanager.close()` to capture and log if there is any `ioexception` and not throw it all the way here.",0,0.9768925905227661
95038406,1884,guozhangwang,2017-01-06T23:22:46Z,could you reply to this comment as well?,0,0.9892987012863159
95038495,1884,guozhangwang,2017-01-06T23:23:42Z,btw i think this class will eventually be merged into o.a.k.common admin package when kip-4 is completed. cc,0,0.9867305755615234
95039652,1884,hjafarpour,2017-01-06T23:35:28Z,deleted the file!,0,0.8084786534309387
95039666,1884,hjafarpour,2017-01-06T23:35:37Z,deleted the file.,0,0.9855408072471619
95039719,1884,hjafarpour,2017-01-06T23:35:59Z,"removed the line ""compile libs.jacksondatabind"".",0,0.9949506521224976
95039868,1884,hjafarpour,2017-01-06T23:37:29Z,replaced it with time.system.,0,0.993715226650238
95040218,1884,hjafarpour,2017-01-06T23:41:29Z,done!,0,0.6890168786048889
95040389,1884,hjafarpour,2017-01-06T23:43:19Z,good point! moved all in the try/catch block.,1,0.9828899502754211
95040644,1884,ijuma,2017-01-06T23:46:09Z,", yeah, we will have to refactor it to make it more generic, but good to have non-test code using the protocol. :)",1,0.9943782687187195
95040864,1884,hjafarpour,2017-01-06T23:48:44Z,added a log message.,0,0.9842846393585205
95041682,1884,hjafarpour,2017-01-06T23:57:25Z,handling the io exception in internaltopicmanager.close() now.,0,0.9922450184822083
95678659,1884,xvrl,2017-01-11T21:42:16Z,"this breaks backwards compatibility. until now streams did not delete existing topics. until streams offers a way to configure partition count and min.isr for internal topics, it should never attempt to delete topics. even then it might be dangerous to delete existing topics without warning.",0,0.8694450855255127
95980233,1884,enothereska,2017-01-13T11:34:33Z,i noticed this path is gone from the new code.,0,0.9739246964454651
96026577,1884,guozhangwang,2017-01-13T16:38:25Z,"i thought wrote it down on the kip wiki but seems he's not, we discussed about this issue while proposing kip-90. the problem is that even in the case that existing number of partitions is less than expected, we can not safely add partitions and reuse the existing ones for repartition topics or changelog topics, due to hashing.",0,0.9635103344917297
96035255,1884,mjsax,2017-01-13T17:27:38Z,this is an issue that we did miss. :(,-1,0.9919657707214355
203197427,5379,stanislavkozlovski,2018-07-17T22:08:12Z,"`scrammessages`'s value regex is `""[\\x01-\\x7f&&[^,]]+""`. i tried using it but could not get my tests to pass. to be frank, i don't understand it at all. specifically the `&&[^,]` part. [a link] says but i doubt that that is the case, otherwise i think scram would not work as well. is this some feature in the java regex engine i'm not familiar with?",-1,0.6235830783843994
203203016,5379,stanislavkozlovski,2018-07-17T22:34:53Z,"i kind of want to have this in a more general space where every saslclient will have this code. an idea could be extend the saslclient interface and provide this default method, or move it to some utils resource. i'm not sure if it is worth the effort.",0,0.8444409370422363
204061226,5379,rondagostino,2018-07-20T14:23:35Z,"is the returned map supposed to be modifiable or unmodifiable? the default value (set via collections.emptymap) is unmodifiable. but if someone sets the map it isn't copied, so whether it will be modifiable or unmodifiable is non-deterministic. i think it would be best to state in the javadoc that the returned map is always unmodifiable, and when setting the map the input map should be copied and wrapped so as to be unmodifiable.",0,0.9916478395462036
204063618,5379,rondagostino,2018-07-20T14:30:45Z,"i would be careful to state that ""you can also add custom unsecured sasl extensions when using the default, builtin{ authenticatecallbackhandler} implementation using..."" because it is really the authenticatecallbackhandler instance that determines what kinds of callbacks are supported rather than this class itself.",0,0.9912125468254089
204066800,5379,rondagostino,2018-07-20T14:40:10Z,"the token and the extensions must not be added until commit() is called as per the jaas specification. i would add a field ""extensionsrequiringcommit"" to mirror how the token is handled between the login() and commit() methods. also, note that this loginmodule supports calling commit() when the subject is shared with another instance of this class associated with a separate logincontext and that other instance has not yet had its logout() method called (see the last paragraph of the javadoc for details). you will need to support this for the extensions as well as for the token. you can mirror the existing code for the token and treat the extensions the same way. failure to do this will result in the extensions being deleted from the subject when the original logincontext has its logout() method called.",0,0.9928019046783447
204068531,5379,rondagostino,2018-07-20T14:45:35Z,"also, i am wondering if maybe we shouldn't simply attach a map to the public credentials but should instead attach something more precise and fit-for-purpose. the reason is because once we attach a map we can't ever use a map on the public credentials again; if we wanted to attach something else in the future it could not implement map. map is very broad and limits flexibility in the future. i am wondering if we should make the saslextensions class part of the public api and make it immutable. then we can attach an instance of that class specifically rather than just a map and we don't constrain ourselves going forward. what do you think? saslextensionscallback would return a saslextensions instance instead of a map if we decide to do this, and it also removes the confusion about the modifiability/immutabililty of what saslextensionscallback actually returns -- it will always be immutable.",0,0.9620555639266968
204070121,5379,rondagostino,2018-07-20T14:50:10Z,copy the map and store it immutably?,0,0.9905091524124146
204071530,5379,rondagostino,2018-07-20T14:54:20Z,don't need both properties and saslextension -- probably just saslextensions.,0,0.9868878722190857
204073705,5379,rondagostino,2018-07-20T15:00:49Z,please update javadoc for the class to also state that the instance of { authenticatecallbackhandler} can optionally handle an instance of { saslextensionstokencallback} to return any extensions generated by the { login()} event on the { logincontext}.,0,0.9942459464073181
204074321,5379,rondagostino,2018-07-20T15:02:43Z,typically catch exception rather than throwable since error generally should not be caught as it denots an event that the code can't really do anything about.,0,0.9764686822891235
204074903,5379,rondagostino,2018-07-20T15:04:34Z,is there a reason to return the callback? i would think the calling code is interested in the extensions themselves rather than the callback.,0,0.9880149960517883
204075829,5379,rondagostino,2018-07-20T15:07:37Z,please update javadoc to state that this class also recognizes { saslextensionscallback} and retrieves any sasl extensions that were created when the { oauthbearerloginmodule} logged in by looking for an instance of { map} in the { subject}'s public credentials. (or an instance of saslextensions rather than a map if we decide to make saslextensions part of the public api),0,0.9940896034240723
204076627,5379,rondagostino,2018-07-20T15:10:19Z,"can you name this in the same way as handlecallback(oauthbearertokencallback) -- i.e. handlecallback(saslextensionscallback)? unless there is a reason to do it differently? maybe you are foreshadowing a move of the method onto the oauthbearerloginmodule class at some point? if so, then maybe make the method static, name it handlecallback(), and make the handlecallback(oauthbearertokencallback) symmetric by also accepting a subject parameter? i think there is value in making the two methods look very much the same except for the type of callback they accept, so whichever you decide let's make them look the same as much as possible.",0,0.9919643402099609
204080059,5379,rondagostino,2018-07-20T15:21:26Z,"it is possible that the extensions could be set and then the process() method either returns an error response to the client or throws an exception. it probably isn't too much of an issue if this happens, but best to set the extensions at the same point where tokenfornegotiatedproperty is set, so probably should add the extensions as a new parameter on the process() call.",0,0.991561233997345
204082009,5379,rondagostino,2018-07-20T15:27:35Z,"probably good to state above ""a { callbackhandler} that recognizes { oauthbearertokencallback} to return an unsecured oauth 2 bearer token and { saslextensionscallback} to return sasl extensions.""",0,0.942529022693634
204088230,5379,stanislavkozlovski,2018-07-20T15:47:49Z,should be unmodifiable come to think of it. updated docs and code,0,0.9877040386199951
204088701,5379,stanislavkozlovski,2018-07-20T15:49:24Z,agreed,0,0.9622275233268738
204091548,5379,stanislavkozlovski,2018-07-20T15:59:31Z,that would be the best approach i think. i also found this way non-ideal but decided to stick with the implementation as with `scramextensions`,0,0.978148341178894
204093826,5379,stanislavkozlovski,2018-07-20T16:07:19Z,i see. thanks for the clarification,1,0.864323616027832
204099967,5379,stanislavkozlovski,2018-07-20T16:29:38Z,"you're right, even the method name implies you get the extensions",0,0.9611469507217407
204100861,5379,stanislavkozlovski,2018-07-20T16:33:10Z,i wanted to document the code via more explicit names,0,0.9776188135147095
204101263,5379,stanislavkozlovski,2018-07-20T16:34:38Z,good catch,1,0.981269359588623
204110927,5379,rajinisivaram,2018-07-20T17:11:42Z,"yes, it makes sense. we currently use `map` for delegation tokens extension for scram. since we are only adding custom extensions to oauth in this kip, perhaps we should add `saslextensionscallback` and `saslextensionscallbackhandler` in `org.apache.kafka.common.security.auth` and use it only for `oauth` for now. for scram, we should probably stick to the `map` for now, but we could have the interfaces extend the public interface. what do you think?",0,0.9898062348365784
204136508,5379,rondagostino,2018-07-20T18:43:20Z,"agreed, we can focus on oauthbearer for now, take the right steps (adding 2 classes to the public api instead of just the callback class), and start to leverage the added public api classes in other mechanisms (i.e. scram-related) if/when the time seems right. i am less familiar with the scram-related code, so i defer to whatever/whenever you feel is best.",0,0.9570393562316895
204138659,5379,stanislavkozlovski,2018-07-20T18:51:36Z,why should we not change scram? was the delegation token publicly accessible and that would break? i feel like we should change it outright if we can,0,0.9543440937995911
204139145,5379,rondagostino,2018-07-20T18:53:16Z,"this is the only place where the separator field is used, and i'm not clear on the semantics of this method. i think maybe the separator field can be dropped and eliminate that parameter from the constructor that takes a map?",0,0.9465570449829102
204140072,5379,rondagostino,2018-07-20T18:56:56Z,make unmodifiable via collections.emptymap(),0,0.9904000163078308
204140395,5379,rondagostino,2018-07-20T18:58:19Z,javadoc on public api classes and their methods is very helpful,1,0.9777467846870422
204140849,5379,rondagostino,2018-07-20T19:00:23Z,should this constructor accept the same parameters as utils.parsemap()?,0,0.9943587183952332
204141019,5379,rondagostino,2018-07-20T19:01:03Z,probably remove separator parameter (and the field) as mentioned below,0,0.9926651120185852
204141410,5379,rondagostino,2018-07-20T19:02:49Z,might want to add an extensionentries() method that returns a map.entry,0,0.9892035126686096
204142058,5379,rondagostino,2018-07-20T19:05:23Z,"probably no need to make a copy since the map is unmodifiable; javadoc can say it returns an unmodifiable map view of the extensions. this raises the question of whether all of the map-related methods isempty(), extensionnames(), extensionentries(), and extensionvalue() are actually needed. if returning the map is cheap -- which it would be -- then all of those methods feel like clutter rather than good api additions. what do you think?",0,0.9745237827301025
204142539,5379,rondagostino,2018-07-20T19:07:43Z,i'm not sure this method needs to exist. if someone want to parse a string and get a map they can either call utils.parsemap() directly or they can construct an instance of this class and call extensionsmap() on it.,0,0.7718745470046997
204142913,5379,rondagostino,2018-07-20T19:09:31Z,i think this class should accept and return instances of saslextensions rather than a map now that saslextensions is part of the public api.,0,0.9833799004554749
204143400,5379,rondagostino,2018-07-20T19:11:45Z,is there a reason why we shouldn't always use saslextensions rather than map?,0,0.9899464249610901
204143672,5379,rajinisivaram,2018-07-20T19:13:00Z,"for this kip, i think we should do one of these: 1. implement custom extensions for oauthbearer alone, but add common callback classes to enable reuse for other mechanisms in future. this means leaving scram alone. 2. support custom extensions for both scram and oauthbearer, changing the delegation token mechanism to use the custom extensions code path treating `token` as a property in the map. i don't think we should do a half-change for scram, changing a public contract without actually providing a good reason to do so (i.e. change the way extensions are propagated without supporting custom extensions). does that make sense?",0,0.9869515895843506
204144544,5379,rondagostino,2018-07-20T19:16:39Z,i think this will end up being `extensions == mycommitedextensions` ?,0,0.9905285239219666
204144759,5379,rondagostino,2018-07-20T19:17:38Z,same -- use saslextensions instead of map?,0,0.9934003353118896
204157244,5379,stanislavkozlovski,2018-07-20T20:11:28Z,nope - [a link],0,0.9827331304550171
204157659,5379,stanislavkozlovski,2018-07-20T20:13:12Z,actually - no. my bad,-1,0.9903410077095032
204158880,5379,stanislavkozlovski,2018-07-20T20:18:23Z,fair enough - i figured to have it there for the sake of completeness,1,0.5143378376960754
204159227,5379,stanislavkozlovski,2018-07-20T20:19:54Z,"is it bad to have it, even if unused in code (only tested)?",-1,0.8999612331390381
204159567,5379,rondagostino,2018-07-20T20:21:20Z,"yeah, the use of == instead of .equals() is certainly unusual, but it is necessary in this case because we need to make sure we remove our instance as opposed to an instance put there via another logincontext. i did not comment it when i did it for the token but should have given that it is unusual.",0,0.9600765109062195
204160970,5379,stanislavkozlovski,2018-07-20T20:27:27Z,i find they're still useful to keep. it's always good to abstract away the implementation behind an interface in my opinion,0,0.5164461731910706
204164892,5379,rondagostino,2018-07-20T20:45:33Z,"good question. the biggest mistake i made in doing this oauthbearer implementation was trying to do too much. the community reigned me in over time :-) my guess would be to keep things as simple and minimalistic as possible; there is less that can go wrong, less to debate over/review/test/fix, and ultimately a shorter time to when the code actually gets merged. at least that's the lesson i took from the experience.",1,0.9950297474861145
204165198,5379,stanislavkozlovski,2018-07-20T20:47:07Z,agreed and done,0,0.959143340587616
204165223,5379,stanislavkozlovski,2018-07-20T20:47:15Z,done,0,0.8974218964576721
204165380,5379,stanislavkozlovski,2018-07-20T20:48:02Z,that's true in general. i honestly believe this is a useful constructor to have though,0,0.7590378522872925
204165803,5379,stanislavkozlovski,2018-07-20T20:50:01Z,is there a need to explicitly make it unmodifiable since `extensionsmap()` returns an unmodifiable version? come to think of it - maybe the other constructors shouldn't make it unmodifiable as well,0,0.9880443215370178
204498442,5379,rondagostino,2018-07-23T17:55:21Z,"should be ""check whether your callback **handler** is explicitly...""",0,0.9896244406700134
204499789,5379,rondagostino,2018-07-23T17:59:35Z,"need to also state: ""the { oauthbearerloginmodule} instance also asks its configured { authenticatecallbackhandler} implementation to handle an instance of { saslextensionscallback} and return an instance of { saslextensions}. the configured callback handler does not need to handle this callback, though -- any { unsupportedcallbackexception} that is thrown is ignored, and no sasl extensions will be associated with the login.""",0,0.9950657486915588
204500558,5379,rondagostino,2018-07-23T18:02:11Z,"this method doesn't actually attach the token -- it identifies the token that should be attached if/when commit() is called. the method needs a better name. maybe ""identifytoken()""?",0,0.9937942028045654
204500716,5379,rondagostino,2018-07-23T18:02:31Z,same here -- need a better method name (and also update javadoc) to reflect the fact that it is identifying the extensions that should be attached if/when commit() is called.,0,0.9942080974578857
204501651,5379,rondagostino,2018-07-23T18:05:39Z,should be == so we know it is literally the instance we committed,0,0.9580267667770386
204502047,5379,rondagostino,2018-07-23T18:07:11Z,this check is unnecessary; extensionsrequiringcommit cannot be null if tokenrequiringcommit is non-null.,0,0.991434633731842
204505373,5379,rondagostino,2018-07-23T18:17:50Z,"this isn't actually parsing the custom extensions; it is retrieving the ones that have already been parsed and stored somewhere. it needs a better name. maybe ""retrieveextensions()""?",0,0.9891425967216492
204506803,5379,rondagostino,2018-07-23T18:22:20Z,"we need to make sure the ""auth"" key isn't defined here since that is generated from the token's compact serialization. should also add to the javadoc above that all token keys that meet the regex criteria are valid except ""auth"".",0,0.9948763251304626
204507438,5379,rondagostino,2018-07-23T18:24:12Z,attaches the first saslextensions (not map anymore),0,0.9871718287467957
204507634,5379,rondagostino,2018-07-23T18:24:52Z,can add static modifier since it doesn't refer to anything in the instance,0,0.9929125905036926
204509972,5379,rondagostino,2018-07-23T18:32:13Z,stylistically it is better to write it as `this.saslextensions = validateextensions(extensions)` (and of course make that method return the extensions passed in if an exception is not raised).,0,0.9943318367004395
204510197,5379,rondagostino,2018-07-23T18:32:52Z,"make it return the extensions as per above, and also throw an exception if the ""auth"" extension is specified.",0,0.9943115711212158
204512923,5379,rondagostino,2018-07-23T18:41:53Z,`this.saslextensions = validateextensions(new saslextensions(properties))`,0,0.9921813011169434
204513594,5379,rondagostino,2018-07-23T18:44:17Z,i actually think this method is no longer needed.,0,0.9132061004638672
204513736,5379,rondagostino,2018-07-23T18:44:43Z,can/should delete this method as per above.,0,0.9932998418807983
204514223,5379,rondagostino,2018-07-23T18:46:18Z,"is this constructor ever used? if not, probably best to eliminate it; if it is used, then it should invoke `extensionsmap = collections.emptymap()`",0,0.9927012920379639
204515380,5379,rondagostino,2018-07-23T18:49:54Z,this method is not needed since map() is an inexpensive call; anybody wanting an extension value can simply call `thesaslextensions.map().get(thename)`.,0,0.9924871921539307
204515582,5379,rondagostino,2018-07-23T18:50:28Z,same here -- unnecessary method due to the ability to invoke `thesaslextensions.map().keyset()`,0,0.9946657419204712
204515709,5379,rondagostino,2018-07-23T18:50:57Z,same here -- unnecessary method due to the ability to invoke `thesaslextensions.map().isempty()`,0,0.9946038126945496
204517898,5379,rondagostino,2018-07-23T18:58:09Z,"since the isgssapi variable is only used to determine if we should return, why not just this? `if (saslconfigs.gssapi_mechanism.equals(mechanism)) return; // extensions are not supported for gssapi`",0,0.993424654006958
204518784,5379,rondagostino,2018-07-23T19:01:10Z,"""auth"" is not allowed.",0,0.9703210592269897
204532330,5379,stanislavkozlovski,2018-07-23T19:50:05Z,could you elaborate on why this should be the case? i tend to agree but cannot explicitly define why that's better - maybe it's just more obvious?,0,0.9831900596618652
204534985,5379,stanislavkozlovski,2018-07-23T20:00:08Z,should i? what do we win by that - it's private.,0,0.9190757870674133
204535795,5379,stanislavkozlovski,2018-07-23T20:03:04Z,sure,0,0.9137381911277771
204537047,5379,stanislavkozlovski,2018-07-23T20:07:42Z,"no, it's not. i kept it since i did not call `super(map)` in `scramextensions` which should not have been the case",0,0.9897252321243286
204542803,5379,stanislavkozlovski,2018-07-23T20:27:04Z,"i agree with the others but for this most common use case i propose we keep the method name. it is shorter and more concise to write. also reads better than `map().get(thename)`. glancing at `extensionvalue` you immediately understand what we're taking - in the other way, it's still obvious but not as much",0,0.9473363161087036
204545192,5379,stanislavkozlovski,2018-07-23T20:35:00Z,done,0,0.8974218964576721
204557034,5379,rajinisivaram,2018-07-23T21:18:22Z,`should be attached` => `may be added`,0,0.991643488407135
204557800,5379,rajinisivaram,2018-07-23T21:21:10Z,why was this change made? i think the single `if` statement is better than returning here.,0,0.982869565486908
204558311,5379,rajinisivaram,2018-07-23T21:23:16Z,"same as before - check the mechanism in the `if` statement below. also, i think we could check for scram mechanism in the check above and check for oauthbearer here.",0,0.9943460822105408
204562743,5379,rajinisivaram,2018-07-23T21:40:24Z,make this `private final`?,0,0.9936261177062988
204563236,5379,rajinisivaram,2018-07-23T21:42:27Z,personally i think we s should create a copy of the map.,0,0.9782544374465942
204563539,5379,rajinisivaram,2018-07-23T21:43:45Z,"personally, i would get rid of this and use `extensionvalue` and `extensionnames`. otherwise, as said below, we should remove `extensionvalue`.",0,0.9933479428291321
204564358,5379,rajinisivaram,2018-07-23T21:46:58Z,"i thought we weren't supporting `saslextensionscallback` for scram. we should either update `scramsaslclient` to process `saslextensions` and add tests for that or not deprecate this now. in any case, i am not sure why the javadoc was removed.",0,0.9333131909370422
204565761,5379,rajinisivaram,2018-07-23T21:52:51Z,make `final`?,0,0.9920191168785095
204567218,5379,stanislavkozlovski,2018-07-23T21:59:13Z,doesn't `new hashmap<>(extensionsmap)` do exactly that?,0,0.9943932294845581
204567896,5379,stanislavkozlovski,2018-07-23T22:02:02Z,"it would then require its initialized on the spot or in the constructor. the appropriate callback handler initializes it using `#extensions(...)`, so making it `final` wouldn't work",0,0.9952760934829712
204569668,5379,stanislavkozlovski,2018-07-23T22:10:29Z,"`oauthbearerclientinitialresponse` uses this to iterate over all values and build the extensions string using `utils.mkstring`. if we removed `map()`, we would need to iterate through `extensionnames`, fetch and validate each value one by one. we would also need to rebuild the map in `#extensionsmessage()` so that we could call `utils.mkstring`. this is all more complex to write and slower to execute, thus i believe we should keep `map()`. i do not understand what is inherently wrong with having an `extensionvalue` method. it keeps it consistent with `scramextensions`' usage, does not bloat the api (it's a single method) and offers a more concise and readable way to fetch a value from the extensions. can you elaborate why you believe we should remove `extensionvalue()` ?",0,0.9870790243148804
204570041,5379,stanislavkozlovski,2018-07-23T22:12:32Z,it's `protected` so `scramextensions` can have access to it. i made it `final` now,0,0.9930825233459473
204570220,5379,stanislavkozlovski,2018-07-23T22:13:25Z,"come to think of it, i'll outright remove `extensionnames` and use `map().keyset()`. did not realize `scramextensions` is not a public class",0,0.9700255990028381
204571187,5379,stanislavkozlovski,2018-07-23T22:18:34Z,removing the javadoc was a mistake. i will look into making `scramsaslclient` work with `saslextensions`. last time i tried some tests kept failing for a reason i could not debug even after significant effort. if it happens to be the case again i'll simply remove the deprecated tag,0,0.9729778170585632
204575201,5379,stanislavkozlovski,2018-07-23T22:39:32Z,personal preference. i find this more readable than a bigger if check. changed back to one `if` and now checking for the correct mechanism in each callback,0,0.9618794322013855
204575952,5379,stanislavkozlovski,2018-07-23T22:43:28Z,is this the correct way to check for the mechanism? i'm wondering why the previous code only checked for `!saslconfigs.gssapi_mechanism.equals(mechanism)` and not other mechanisms as well,0,0.986263632774353
204583187,5379,rondagostino,2018-07-23T23:24:58Z,i agree with ; since we have map() there is no need to provide any shorthand methods for functionality that the return value of map() provides.,0,0.9014830589294434
204583275,5379,rondagostino,2018-07-23T23:25:33Z,probably a good idea to add tostring() as well.,0,0.9718592762947083
204584539,5379,rondagostino,2018-07-23T23:33:27Z,"the saslclient callback handler for the oauthbearer mechanism needs to handle oauthbearertokencallback as well as saslextensionscallback (with the last one optional, but the first one is definitely mandatory). if we are going to put this code here for oauthbearer then the only way the code is going to ever be invoked in a successful runtime scenario is if 1) we also add code to handle oauthbearertokencallback; and 2) somehow this class is set as the saslclient callback handler. (2) will happen if the config explicitly specifies this class, or, alternatively, we can delete the oauthbearersaslclientcallbackhandler class and make this class the default saslclient callback handler for the oauthbearer mechanism (that decision is made at line 330 of org.apache.kafka.common.network.saslchannelbuilder; that line would have to change). i'm okay with either migrating to a fully-functional (for oauthbearer) saslclientcallbackhandler class or deleting these lines; keeping them without also handling oauthbearertokencallback doesn't make sense, though.",0,0.9938282370567322
204585957,5379,rondagostino,2018-07-23T23:41:47Z,"sure. we want to remove the instance that we put there, so we use == instead of .equals(). the .equals() method may identify another instance rather than the one we added. frankly i don't think it would be a problem due to the existence of the `break` statement below, but if that `break` statement were to be removed for some reason then we would iterate through the entire collection and remove everything that satisfied .equals() -- and that could be multiple instances. so using `==` makes the semantics very clear and acts as an insurance policy at the same time.",0,0.982984721660614
204586766,5379,rondagostino,2018-07-23T23:46:27Z,this needs to be `getpubliccredentials()` rather than `getpubliccredentials(saslextensions.class)` because the former returns the actual public credentials (see [a link] whereas the latter returns a new set that doesn't propagate changes through (see [a link].,0,0.9944117665290833
204588760,5379,rondagostino,2018-07-23T23:59:28Z,need to invoke `extensions = null` here as well.,0,0.9928024411201477
204589027,5379,rondagostino,2018-07-24T00:01:18Z,"need to state that the extension name must match th required regex but cannot be the reserved value ""auth"".",0,0.9942628741264343
204589338,5379,rondagostino,2018-07-24T00:03:42Z,probably a good idea to wrap in a try {} catch (kafkaexception e) {} block as is done above for the oauthbearertokencallback.,0,0.9896730184555054
204589592,5379,rondagostino,2018-07-24T00:05:17Z,"should be `extensions.put(extensionname, extensionvalue)`",0,0.9939265847206116
204595693,5379,stanislavkozlovski,2018-07-24T00:51:10Z,"i do not know what it should return, though",-1,0.8281310200691223
204595909,5379,stanislavkozlovski,2018-07-24T00:52:52Z,"oops, yes. this should not be here at all",-1,0.932277500629425
204596760,5379,stanislavkozlovski,2018-07-24T01:00:26Z,that is a big gotcha! thanks!,1,0.9955394864082336
204597201,5379,stanislavkozlovski,2018-07-24T01:04:00Z,and just swallow the exception? i guess it boils down to: do we want to stop authentication on invalid extension value or just not use extensions?,0,0.951296329498291
204599621,5379,rondagostino,2018-07-24T01:23:20Z,no need to check instanceof and cast it since `==` will return false if it isn't an instanceof. see line 331-338 above for what this should look like.,0,0.9928191304206848
204599894,5379,rondagostino,2018-07-24T01:25:53Z,is there a reason why this is protected and not private?,0,0.9809387922286987
204599996,5379,rondagostino,2018-07-24T01:26:29Z,`extensionsmap.tostring()` seems appropriate,0,0.9940557479858398
204600596,5379,rondagostino,2018-07-24T01:31:44Z,lines 344-347 are unnecessary; the statement `if (mycommittedextensions == credential)` will be correct regardless. see lines 332-333 above.,0,0.9953912496566772
204601020,5379,rondagostino,2018-07-24T01:35:15Z,probably should use `{ oauthbearerclientinitialresponse.auth_key}` instead of `{ oauthbearerclientinitialresponse.auth_key}`,0,0.9949281215667725
204601155,5379,rondagostino,2018-07-24T01:36:22Z,"no, don't swallow, propagate it wrapped in an ioexception as is done a few lines up.",0,0.9532725811004639
204601217,5379,rondagostino,2018-07-24T01:36:48Z,`{` instead of `{`,0,0.9917320013046265
204601696,5379,rondagostino,2018-07-24T01:40:46Z,duplicate line,0,0.9220499992370605
204602098,5379,rondagostino,2018-07-24T01:44:07Z,why delete these comments?,0,0.9385812878608704
204602841,5379,rondagostino,2018-07-24T01:50:04Z,"i think what you want to do here is accept an array of saslextensions objects; if an array element is null then the handler would throw unsupportedcallbackexception on that iteration, otherwise it returns the element. this test is making sure the simultaneous login/logout functionality doesn't get confused. basically follow what is going on with the tokens and do the same thing with the saslextensions. you might need separate indexes for tokens and saslextensions (i.e. `tokenindex` instead of `index`, and then add `extensionsindex`)",0,0.9884605407714844
204603396,5379,rondagostino,2018-07-24T01:54:34Z,"same thing here; create an array of saslextensions mocks, one element of which should be null, etc.",0,0.9937498569488525
204603442,5379,rondagostino,2018-07-24T01:54:57Z,"same thing here; create an array of saslextensions mocks, one element of which should be null, etc.",0,0.9937498569488525
204603529,5379,rondagostino,2018-07-24T01:55:36Z,"same thing here; create an array of saslextensions mocks, one element of which should be null, etc.",0,0.9937498569488525
204603724,5379,rondagostino,2018-07-24T01:57:11Z,this test becomes unnecessary after weaving saslextensions into the above tests.,0,0.9876448512077332
204604012,5379,rondagostino,2018-07-24T01:59:30Z,"create an array of saslextensions mocks, one element of which should be null, etc.",0,0.9923804998397827
204604217,5379,rondagostino,2018-07-24T02:01:00Z,this test becomes unnecessary after weaving saslextensions into the above tests as long as you include at least one null element in the array for each one.,0,0.9940326809883118
204604435,5379,rondagostino,2018-07-24T02:02:51Z,why delete these 2 lines? can you just call `response.extensions().map().get()` instead of `response.propertyvalue()`?,0,0.9933544397354126
204604726,5379,rondagostino,2018-07-24T02:05:33Z,why delete this test? can you just call `response.extensions().map().get()` instead of `response.propertyvalue()`?,0,0.9936915636062622
204605136,5379,rondagostino,2018-07-24T02:09:00Z,"indicate that ""auth"" is reserved and cannot be used.",0,0.9874398708343506
204672879,5379,rajinisivaram,2018-07-24T08:49:05Z,"sorry, my mistake.",-1,0.9917699098587036
204673218,5379,rajinisivaram,2018-07-24T08:50:14Z,"sorry, i was looking at the `unmodifiablemap` and didn't see the copy.",-1,0.9868805408477783
204673925,5379,rajinisivaram,2018-07-24T08:52:31Z,we should make this `private`.,0,0.9924864768981934
204674806,5379,rajinisivaram,2018-07-24T08:55:08Z,`scrammechanism.isscram(mechanism)`,0,0.9933794736862183
204676556,5379,rajinisivaram,2018-07-24T09:00:47Z,"in this line and the similar one for retrieving tokens, could we says `an internal error occurred while doing xxx`? also, perhaps `log.error(""error occurred while doing xxx"", e)`.",0,0.991934061050415
204680030,5379,rajinisivaram,2018-07-24T09:11:57Z,looks like duplicate code. couldn't we just use one static `oauthbearerclientinitialresponse.validateextensions(map )` method for validation?,0,0.9875972867012024
204789092,5379,stanislavkozlovski,2018-07-24T14:54:13Z,i wrote a similar test (copied this one) to this that didn't make the pr. i must have deleted the comments from the wrong test in the end,0,0.9870336055755615
204795761,5379,stanislavkozlovski,2018-07-24T15:10:39Z,"no, we'd need this. the null element won't test out this backwards-compatible behavior",0,0.955502986907959
204818374,5379,stanislavkozlovski,2018-07-24T16:09:58Z,i'll add the functionality and have one of the commit/login tests use it. i vote we keep the two tests i wrote - i don't see anything wrong with unit testing functionality in a more fine-grained way,0,0.8862420320510864
204819005,5379,stanislavkozlovski,2018-07-24T16:11:55Z,"yes. my bad, sorry",-1,0.9936343431472778
204821362,5379,stanislavkozlovski,2018-07-24T16:18:23Z,yes we can. this will result in a bit more complicated code in `oauthbearerunsecuredlogincallbackhandler#handleextensionscallback()` since it needs to unprefix the extensions first,0,0.99333655834198
204907936,5379,rondagostino,2018-07-24T20:54:55Z,can mirror the way it is done for tokens just call `getpubliccredentials()` instead of `getpubliccredentials(saslextensions.class)`. this also eliminates the need to keep calling the method to calculate a new set -- the original set will always be accurate.,0,0.9942303895950317
205113394,5379,rondagostino,2018-07-25T13:44:17Z,can remove this line after making the change mentioned in line 127 above,0,0.9900819659233093
205114012,5379,rondagostino,2018-07-25T13:45:52Z,can remove this line after making the change mentioned in line 127 above,0,0.9900819659233093
205114191,5379,rondagostino,2018-07-25T13:46:17Z,can remove this line after making the change mentioned in line 127 above,0,0.9900819659233093
205114596,5379,rondagostino,2018-07-25T13:47:15Z,can remove this line after making the change mentioned in line 127 above,0,0.9900819659233093
205114906,5379,rondagostino,2018-07-25T13:48:03Z,can remove this line after making the change mentioned in line 127 above,0,0.9900819659233093
205115117,5379,rondagostino,2018-07-25T13:48:34Z,can remove this line after making the change mentioned in line 127 above,0,0.9900819659233093
205115297,5379,rondagostino,2018-07-25T13:49:00Z,can remove this line after making the change mentioned in line 127 above,0,0.9900819659233093
205115775,5379,rondagostino,2018-07-25T13:50:16Z,same as above -- can mirror the way it is done for tokens just call getpubliccredentials() instead of getpubliccredentials(saslextensions.class). this also eliminates the need to keep calling the method to calculate a new set -- the original set will always be accurate.,0,0.9940084218978882
205116317,5379,rondagostino,2018-07-25T13:51:35Z,"saslextensions array length should be the same as token array length -- 2, not 3.",0,0.9891321063041687
205116655,5379,rondagostino,2018-07-25T13:52:19Z,can remove this line after making the change mentioned in line 230 above,0,0.9907756447792053
205116789,5379,rondagostino,2018-07-25T13:52:38Z,can remove this line after making the change mentioned in line 230 above,0,0.9907756447792053
205116910,5379,rondagostino,2018-07-25T13:52:57Z,can remove this line after making the change mentioned in line 230 above,0,0.9907756447792053
205117003,5379,rondagostino,2018-07-25T13:53:12Z,can remove this line after making the change mentioned in line 230 above,0,0.9907756447792053
205117091,5379,rondagostino,2018-07-25T13:53:28Z,can remove this line after making the change mentioned in line 230 above,0,0.9907756447792053
205117236,5379,rondagostino,2018-07-25T13:53:49Z,can remove this line after making the change mentioned in line 230 above,0,0.9907756447792053
205117560,5379,rondagostino,2018-07-25T13:54:33Z,same as above -- can mirror the way it is done for tokens just call getpubliccredentials() instead of getpubliccredentials(saslextensions.class). this also eliminates the need to keep calling the method to calculate a new set -- the original set will always be accurate.,0,0.9940084218978882
205118094,5379,rondagostino,2018-07-25T13:56:01Z,can remove this line after making the change mentioned in line 296 above,0,0.9908198714256287
205118194,5379,rondagostino,2018-07-25T13:56:16Z,can remove this line after making the change mentioned in line 296 above,0,0.9908198714256287
205118319,5379,rondagostino,2018-07-25T13:56:38Z,can remove this line after making the change mentioned in line 296 above,0,0.9908198714256287
205118397,5379,rondagostino,2018-07-25T13:56:50Z,can remove this line after making the change mentioned in line 296 above,0,0.9908198714256287
205118520,5379,rondagostino,2018-07-25T13:57:08Z,can remove this line after making the change mentioned in line 296 above,0,0.9908198714256287
205118748,5379,rondagostino,2018-07-25T13:57:43Z,same as above -- can mirror the way it is done for tokens just call getpubliccredentials() instead of getpubliccredentials(saslextensions.class). this also eliminates the need to keep calling the method to calculate a new set -- the original set will always be accurate.,0,0.9940084218978882
205119069,5379,rondagostino,2018-07-25T13:58:29Z,can remove this line after making the change mentioned in line 353 above,0,0.9912033081054688
205119183,5379,rondagostino,2018-07-25T13:58:45Z,can remove this line after making the change mentioned in line 353 above,0,0.9912033081054688
205119367,5379,rondagostino,2018-07-25T13:59:11Z,can remove this line after making the change mentioned in line 353 above,0,0.9912033081054688
205119483,5379,rondagostino,2018-07-25T13:59:29Z,can remove this line after making the change mentioned in line 353 above,0,0.9912033081054688
205119824,5379,rondagostino,2018-07-25T14:00:16Z,can remove this line after making the change mentioned in line 353 above,0,0.9912033081054688
205119994,5379,rondagostino,2018-07-25T14:00:41Z,can remove this line after making the change mentioned in line 353 above,0,0.9912033081054688
205120125,5379,rondagostino,2018-07-25T14:00:59Z,can remove this line after making the change mentioned in line 353 above,0,0.9912033081054688
205120889,5379,rondagostino,2018-07-25T14:02:54Z,i believe this test adds no value and should be eliminated because the case is covered above.,0,0.9763016104698181
205122848,5379,rondagostino,2018-07-25T14:08:10Z,this test is checking the same thing that was checked via passing in raise_unsupported_cb_exception_flag (null) at line 133 and checking for empty_extensions at lines 191 and 200. this test should be deleted.,0,0.9949912428855896
205125175,5379,rondagostino,2018-07-25T14:14:12Z,`collections.emptymap()` instead of `new hashmap<>()`,0,0.992515504360199
205125573,5379,rondagostino,2018-07-25T14:15:07Z,"oops, delete this unintended change",-1,0.9528675079345703
205178909,5379,stanislavkozlovski,2018-07-25T16:33:59Z,"hm, that is strange. i initially went with this approach (obviously sprinkling `getpubliccredentials()` before every assert is bad) but hit some problem. i assumed that the public credentials had another value in them and changed the test with what you just reviewed. the test passed afterwards so i didn't go into investigating what the problem was. now that i removed the calls, test still pass. i'm not sure what i initially missed there",-1,0.9170337915420532
205185439,5379,stanislavkozlovski,2018-07-25T16:55:30Z,"sorry about my initial comment of ""no, we'd need this. the null element won't test out this backwards-compatible behavior"". i unfortunately commented prematurely before completely understanding your suggestion. i acknowledge that this is verified in the above tests. it's just that from what i've read from tdd books, the overall approach experts recommend is to rely on single, small tests that test concrete functionality. this way, when a problem occurs you immediately know what the cause is - `commitpopulatesextensions` - oh, my extensions weren't populated. where as if you get an error in test `login1commit1login2abort2login3commit3logout3` you need to investigate the test well and figure out where the problem is. while such big tests are always useful, i believe a test suite comprised of more smaller tests is better. tests comprised of more methods serve as better documentation. you can then just read the method names and get a general feeling of what the tested subject should do. please share your thoughts on this",-1,0.9904108047485352
205185773,5379,stanislavkozlovski,2018-07-25T16:56:38Z,"take a look at my comment below for test `commitdoesnotthrowonunsupportedextensionscallback`. i do not feel as strongly about this test as i feel on the one below, but i also tentatively think it doesn't hurt to have one more test",0,0.8398846387863159
205197478,5379,rondagostino,2018-07-25T17:32:48Z,"still need this adjusted: saslextensions array length should be the same as token array length -- 2, not 3.",0,0.9919902682304382
205198355,5379,rondagostino,2018-07-25T17:35:34Z,"i agree with your point below about lots of simple tests being better than one big one. let's eliminate the null value here, replace it with a mock, and rely on your test below to verify that unhandledcallbackexception is ignored.",0,0.9760518074035645
205198824,5379,rondagostino,2018-07-25T17:37:01Z,"yes, let's eliminate this one and keep the one below.",0,0.9871962070465088
205199240,5379,rondagostino,2018-07-25T17:38:17Z,good point -- i agree. let's keep this test and eliminate the null value in `login1commit1login2abort2login3commit3logout3`.,1,0.8518223166465759
207815285,5379,rajinisivaram,2018-08-06T08:47:03Z,can you move the link to the next line and include the full name including package since that class has not been imported in this class: `{ org.apache.kafka.common.security.oauthbearer.internals.oauthbearerclientinitialresponse#auth_key}`,0,0.9937505125999451
207818595,5379,rajinisivaram,2018-08-06T08:58:44Z,"was like this earlier, but will be good to update anyway. `string.format` not required. could use: `log.info(""login failed {} : {} (uri={}"",....`",0,0.9674612879753113
207819149,5379,rajinisivaram,2018-08-06T09:00:41Z,"`log.info(""callbackhandler {} does not support..."", callbackhandler.getclass().getname())`?",0,0.9892347455024719
207819502,5379,rajinisivaram,2018-08-06T09:02:03Z,we could have a constant like `empty_extensions` for this case?,0,0.9948830604553223
207820729,5379,rajinisivaram,2018-08-06T09:06:27Z,"now that we can use java8, we could use `removeif` here and in the block above for tokens? [code block]",0,0.9930863976478577
207822201,5379,rajinisivaram,2018-08-06T09:12:06Z,`{ oauthbearerclientinitialresponse.auth_key}` => `{ oauthbearerclientinitialresponse#auth_key}`,0,0.9938018918037415
207822476,5379,rajinisivaram,2018-08-06T09:13:06Z,`get` => `containskey`?,0,0.9918831586837769
207824202,5379,rajinisivaram,2018-08-06T09:19:09Z,`oauthbearerclientinitialresponse.auth_key` => oauthbearerclientinitialresponse#auth_key,0,0.9929472208023071
207824332,5379,rajinisivaram,2018-08-06T09:19:34Z,`oauthbearerclientinitialresponse.auth_key` => `oauthbearerclientinitialresponse#auth_key`,0,0.9930349588394165
207827945,5379,rajinisivaram,2018-08-06T09:31:55Z,could just use `collections.emptymap()` here since type can be inferred?,0,0.9941746592521667
207830135,5379,rajinisivaram,2018-08-06T09:39:45Z,`static final`?,0,0.9919300079345703
207841511,5379,rajinisivaram,2018-08-06T10:20:11Z,`values` => `value`?,0,0.991367518901825
207842331,5379,rajinisivaram,2018-08-06T10:23:43Z,not used?,0,0.9285135269165039
207842366,5379,rajinisivaram,2018-08-06T10:23:51Z,not used?,0,0.9285135269165039
207859716,5379,stanislavkozlovski,2018-08-06T11:32:50Z,that is very cool,1,0.9946563243865967
38921717,191,ijuma,2015-09-08T12:59:25Z,"we should probably use 2.7.1, right?",0,0.9915885329246521
38921790,191,ijuma,2015-09-08T13:00:12Z,indenting doesn't look right in the new `allow` lines.,0,0.9612351655960083
38923719,191,ijuma,2015-09-08T13:20:24Z,is the current plan not to support `auth-int` and `auth-conf` qops?,0,0.9950231313705444
38924187,191,ijuma,2015-09-08T13:25:00Z,what is this change for? `maxfdlimit` seems to be a deprecated flag ([a link],0,0.9862978458404541
38924482,191,ijuma,2015-09-08T13:27:45Z,"instead of having one method per security protocol, why not just take the security protocol as a parameter? then 3 methods would become one. the implementation seems exactly the same apart from the security protocol passed to `boundport`.",0,0.9929826259613037
38924900,191,ijuma,2015-09-08T13:31:31Z,i agree that this is useful. i think there are a number of places where we use `milliseconds()` where we should really be using a method like this one (i noticed that recently). it may be worth thinking about the naming so that the differences are clear. maybe `milliseconds()` should be removed in favour of `currentwalltime()` introduced below?,0,0.9692584276199341
38925126,191,ijuma,2015-09-08T13:33:25Z,not sure whether we should be returning `java.util.date` as it's a somewhat deprecated class as of java 8. maybe we can return a long and the caller can decide to create a `java.util.date` or anything else?,0,0.9858946800231934
39592806,191,junrao,2015-09-16T04:25:38Z,"could we document the handshake protocol in the comment? it seems that for each token, we first send a 4-byte size, followed by the bytes in the token itself?",0,0.9932793974876404
39592812,191,junrao,2015-09-16T04:25:48Z,it seems that we can just use one level of if/else.,0,0.9868142604827881
39592816,191,junrao,2015-09-16T04:25:56Z,could we just use a bytebuffer instead of a networksend?,0,0.993930459022522
39592823,191,junrao,2015-09-16T04:26:07Z,could we get that through the config property instead of a jvm system property?,0,0.994931161403656
40359478,191,Parth-Brahmbhatt,2015-09-24T19:08:40Z,i think this could just be if(!securityprotocol.values().contains(securityprotocol)),0,0.9841101169586182
40359495,191,Parth-Brahmbhatt,2015-09-24T19:08:47Z,shouldn't this come from a config?,0,0.9926726222038269
40359539,191,Parth-Brahmbhatt,2015-09-24T19:09:12Z,is this needed?,0,0.9838624596595764
40359628,191,Parth-Brahmbhatt,2015-09-24T19:09:57Z,anyways to avoid this vendor spicific thing? can we just make this a config that defaults to sun.security.krb5.config?,0,0.9844613671302795
40362188,191,Parth-Brahmbhatt,2015-09-24T19:33:44Z,"let's also add ""socketchannel.socket().getinetaddress().gethostname() must match the hostname in principal/hostname""",0,0.9952390193939209
40375211,191,Parth-Brahmbhatt,2015-09-24T21:24:39Z,probably better to just create a method that returns the principal name and host. might be easier to extract all of it using a simple pattern matcher instead of going through bunch of indexofs and substrings.,0,0.9916565418243408
40375463,191,Parth-Brahmbhatt,2015-09-24T21:27:06Z,i am guessing this is all part of gss api magic but a link to doc or some explanation on what we are doing here might help with future maintenance.,0,0.964953601360321
40575583,191,ijuma,2015-09-28T16:52:14Z,that would not be right because of `securityprotocol.trace` (the fact that trace exists is the reason why we do the check in the first place).,0,0.9934461712837219
40575758,191,ijuma,2015-09-28T16:53:55Z,`sun.security.krb5.config` is also vendor-specific and it won't work in java 9 (see [a link] is there no way to avoid this?,0,0.9918996095657349
40669700,191,ijuma,2015-09-29T13:22:29Z,i think it would be more readable if `listeners` were a `seq` and we can build the `string` at the end with `mkstring`,0,0.9887451529502869
41590473,191,harshach,2015-10-09T01:48:04Z,enabling qop on sasl proven to cause lot of perf issues . it was discussed before hence the reason i went with proposal ssl+sasl.,0,0.9768881797790527
41590525,191,harshach,2015-10-09T01:49:06Z,the reason to use networksend is to have length encoded token . i can use bytebuffer have it encoded with length. let me know if you prefer that.,0,0.9902329444885254
41627145,191,ijuma,2015-10-09T13:03:41Z,i removed it in my pr.,0,0.9886004328727722
41627200,191,ijuma,2015-10-09T13:04:24Z,"ok, thanks. should the name of this be `sasl_plaintext` and `sslsasl` should be `sasl_ssl`? i guess this is a bit subjective, but seems a bit clearer to me.",1,0.8618541955947876
41628653,191,ijuma,2015-10-09T13:22:05Z,i removed this in my pr as it's not used anywhere.,0,0.9919262528419495
41628772,191,ijuma,2015-10-09T13:23:38Z,"i filed kafka-2607 to modify the `time` interface. in the meantime, maybe we can `nanoseconds` and `milliseconds` instead of introducing these methods? i can make the change if you agree.",0,0.9900520443916321
41628927,191,ijuma,2015-10-09T13:25:12Z,do we have anything in kafka that does something similar to this?,0,0.9918637275695801
41629059,191,ijuma,2015-10-09T13:26:18Z,i changed this in my pr.,0,0.985886812210083
41629081,191,ijuma,2015-10-09T13:26:33Z,i removed this change in my pr.,0,0.9866798520088196
41719366,191,junrao,2015-10-12T02:00:42Z,2 components -> 3 components ?,0,0.9886232018470764
41719367,191,junrao,2015-10-12T02:00:43Z,with out => without,0,0.9659348130226135
41719374,191,junrao,2015-10-12T02:00:50Z,would it be better to name this to sth like ticket_renew_window_factor?,0,0.9943240880966187
41719381,191,junrao,2015-10-12T02:01:01Z,should that be made configurable?,0,0.9937610030174255
41719400,191,junrao,2015-10-12T02:01:11Z,could we use utils.newthread() so that we can give it a proper name and register the uncaught exception handler?,0,0.9949576258659363
41719401,191,junrao,2015-10-12T02:01:15Z,should we test equals and after?,0,0.991657018661499
41719402,191,junrao,2015-10-12T02:01:20Z,not be => not be able to,0,0.6465734839439392
41719404,191,junrao,2015-10-12T02:01:24Z,newuntil => newuntil,0,0.966952383518219
41719407,191,junrao,2015-10-12T02:01:32Z,"since we just want to exit, should we change break to return?",0,0.9789998531341553
41719410,191,junrao,2015-10-12T02:01:39Z,would it be better to get kafka.init from kafka_jaas.conf file instead of another system property?,0,0.9958914518356323
41719414,191,junrao,2015-10-12T02:01:47Z,"since we are waiting for this thread to finish during shutdown, it seem that it shouldn't be a daemon thread?",0,0.9889744520187378
41719415,191,junrao,2015-10-12T02:02:07Z,it seems that t is never null. so perhaps it's simpler to just start the thread after t is created.,0,0.9883361458778381
41719416,191,junrao,2015-10-12T02:02:19Z,is this test needed? it seems that logincontextname can never be null.,0,0.9906388521194458
41719421,191,junrao,2015-10-12T02:02:26Z,"could we make ""java.security.auth.login.config"" a constant and reuse?",0,0.9950516819953918
41719433,191,junrao,2015-10-12T02:03:00Z,"i am wondering how well this works when the broker is enabled to also authenticate to zk through sasl. will the global configuration be set twice (once here and another time potentially in zookeeper client)? will that affect the login logic? , do you know?",0,0.9747572541236877
41719435,191,junrao,2015-10-12T02:03:07Z,it seems that we need to set the login time during the initial login as well.,0,0.9913749098777771
41719438,191,junrao,2015-10-12T02:03:13Z,it seems that we should setlastlogin() in setlogin() instead of here.,0,0.9928328990936279
41719441,191,junrao,2015-10-12T02:03:20Z,it seems that both logincontext and mode can just be a local variable.,0,0.9890217781066895
41719446,191,junrao,2015-10-12T02:03:39Z,do we need to make servicename configurable? could that just be hardcoded as kafka?,0,0.9953044652938843
41719449,191,junrao,2015-10-12T02:03:44Z,it doesn't seem that the client needs principalbuilder.,0,0.9748858213424683
41719453,191,junrao,2015-10-12T02:03:51Z,it seems that we need to pass in the config properties that may be specified in the jaas config file?,0,0.9955323934555054
41719460,191,junrao,2015-10-12T02:04:04Z,"we need to turn off op_write when sasl state is complete, right?",0,0.9895757436752319
41719461,191,junrao,2015-10-12T02:04:09Z,would it be enough to just check saslstate?,0,0.9943791031837463
41719464,191,junrao,2015-10-12T02:04:27Z,could you add some comments on when and what types of callbacks could be called?,0,0.9895206689834595
41719465,191,junrao,2015-10-12T02:04:31Z,this is a no op.,0,0.9778875708580017
41722182,191,junrao,2015-10-12T04:31:32Z,could you add a comment on why we need to exclude this?,0,0.9912501573562622
41722186,191,junrao,2015-10-12T04:31:45Z,should we specify those through kafka config file or just the jaas config file? it seems that the latter is more natural since it consolidates all sasl related stuff in one file?,0,0.9932923316955566
41722188,191,junrao,2015-10-12T04:31:56Z,need to add the new param configs.,0,0.9881585240364075
41722190,191,junrao,2015-10-12T04:32:03Z,is the test transportlayer.ready() necessary?,0,0.9943720102310181
41722191,191,junrao,2015-10-12T04:32:08Z,why does this need to be public?,0,0.978056788444519
41722196,191,junrao,2015-10-12T04:32:19Z,do we need to pass in the config properties that may be specified in the jaas config file?,0,0.9954029321670532
41722202,191,junrao,2015-10-12T04:32:25Z,do we need to set op_read? it seems it's always on.,0,0.992472767829895
41722205,191,junrao,2015-10-12T04:32:30Z,we need to turn off op_write when saslserver is complete.,0,0.9917681217193604
41731553,191,ijuma,2015-10-12T07:54:25Z,"i agree that it's not needed in its current state, but it makes sense with the code as it was before, that is: [code block] which version do we prefer?",0,0.9843946099281311
41735085,191,ijuma,2015-10-12T08:45:58Z,"it doesn't, i'll change this back.",0,0.9867202639579773
41752308,191,ijuma,2015-10-12T12:47:41Z,fixed locally.,0,0.9883288145065308
41752351,191,ijuma,2015-10-12T12:48:16Z,"that's right, changed it locally.",0,0.9871693849563599
41752705,191,ijuma,2015-10-12T12:53:31Z,done this locally.,0,0.9863461852073669
41752835,191,ijuma,2015-10-12T12:55:01Z,"i don't understand why we are doing this. we call this method if `authid.equals(authzid)` and set it to the value of `ac.getauthorizationid`, so it looks like a no-op?",0,0.8716118931770325
41752875,191,ijuma,2015-10-12T12:55:31Z,removed locally.,0,0.978821873664856
41753910,191,ijuma,2015-10-12T13:08:19Z,"agreed. and we should handle parsing errors properly (at the moment we are ignoring the case where `indexof` returns -1). i haven't done this yet, but i added it to my list.",0,0.9785052537918091
41754232,191,ijuma,2015-10-12T13:12:02Z,fixed locally.,0,0.9883288145065308
41754241,191,ijuma,2015-10-12T13:12:09Z,fixed locally.,0,0.9883288145065308
41754749,191,ijuma,2015-10-12T13:17:33Z,maybe we can use `kerberosname` for this?,0,0.9948379397392273
41755037,191,ijuma,2015-10-12T13:21:11Z,done locally.,0,0.9873954057693481
41755928,191,ijuma,2015-10-12T13:31:32Z,changed it locally (and in one other similar place).,0,0.9903581738471985
41756215,191,ijuma,2015-10-12T13:34:58Z,"there is the following in the constructor, so the thread can be null. [code block]",0,0.994408369064331
41756262,191,ijuma,2015-10-12T13:35:32Z,changed it locally.,0,0.9853970408439636
41756269,191,ijuma,2015-10-12T13:35:39Z,changed it locally.,0,0.9853970408439636
41756390,191,ijuma,2015-10-12T13:37:05Z,"i think so, changed it locally.",0,0.981875479221344
41756657,191,ijuma,2015-10-12T13:39:56Z,changed it locally.,0,0.9853970408439636
41756681,191,ijuma,2015-10-12T13:40:09Z,changed it locally.,0,0.9853970408439636
41759052,191,ijuma,2015-10-12T14:05:12Z,done locally.,0,0.9873954057693481
41815169,191,harshach,2015-10-13T00:13:09Z,i've a config property in sasl will replace that with this.,0,0.9892584681510925
41815315,191,harshach,2015-10-13T00:15:47Z,yes. will change that.,0,0.9876182079315186
41815592,191,harshach,2015-10-13T00:20:18Z,"no its not needed. user needs to add another section kafka_jaas.conf with ""client"" section. here is the vagrant setup that i've for kafka kerberos. example here [a link]",0,0.9912632703781128
41817433,191,harshach,2015-10-13T00:57:11Z,this is not hardcoded. users need to come up with servicename and its equivalent to the principal name of the kafkaserver.,0,0.9891933798789978
41817530,191,harshach,2015-10-13T00:58:37Z,"didn't understand , are you saying we should pass jaas config file as part of client config properties?",0,0.9702532887458801
41817534,191,harshach,2015-10-13T00:58:46Z,yes. will fix it.,0,0.982218325138092
41817553,191,harshach,2015-10-13T00:59:04Z,yes that should be enough.,0,0.9814172387123108
41817601,191,harshach,2015-10-13T01:00:11Z,jaas config special file in that it needs a different syntax like sections that we define. so it should only need to have login details like keytab files not kafka specific configs.,0,0.98817378282547
41817692,191,harshach,2015-10-13T01:02:26Z,don't understand. what you mean by config properties in jaas config file. jaas should only contain sections and it has specific syntax to them we shouldn't be treating it as generic config file.,0,0.7582105398178101
41817707,191,harshach,2015-10-13T01:02:40Z,will take it out.,0,0.9840647578239441
41820027,191,junrao,2015-10-13T01:54:20Z,do we need the stringbuilder?,0,0.9914593696594238
41820042,191,junrao,2015-10-13T01:54:40Z,"could you add some examples of the rules and keberos names? in particular, how match, frompattern, topattern, etc are used to convert keberos names to user names?",0,0.9939954876899719
41820061,191,junrao,2015-10-13T01:54:51Z,it's a bit weird that # of params doesn't match numofcomponents. could you add a comment?,-1,0.9854241013526917
41820068,191,junrao,2015-10-13T01:55:03Z,should we get this from a system property or from the jaas conf file?,0,0.9951550960540771
41820075,191,junrao,2015-10-13T01:55:14Z,would it be better to pass in timeout through the constructor?,0,0.9945225715637207
41820084,191,junrao,2015-10-13T01:55:22Z,"what does it mean to have a negative interval? also, do we need to support interval? it seems that we have no use case to run a command periodically.",0,0.9608402252197266
41822597,191,harshach,2015-10-13T02:55:10Z,we initializing lasttime to negative of interval and in run method we are checking lasttime + interval > time.currentelapsedtime()) so it guarantees at least one execution of runcommand.,0,0.9929353594779968
41823048,191,harshach,2015-10-13T03:07:50Z,we've shellcommandexecutor in the same file that takes in timeout from constructor. let me know if you want to change this for shell as well.,0,0.9929381012916565
41833260,191,ijuma,2015-10-13T07:13:33Z,i fixed this in my pr that harsha merged some minutes before you made this comment.,0,0.9719316363334656
41875295,191,ijuma,2015-10-13T14:46:55Z,i agree that it's clearer to receive the parameter via the constructor instead of assigning it directly in the subclass (it also avoids initialisation ordering issues). i've changed this locally with a few other `shell` changes.,0,0.9772011041641235
41879955,191,ijuma,2015-10-13T15:16:57Z,"as far as i can see, we don't need to support interval. i have removed it locally as it simplifies the class.",0,0.9874342083930969
41881028,191,ijuma,2015-10-13T15:23:37Z,"harsha changed this to be: `transportlayer.removeinterestops(selectionkey.op_write);` i think this also addresses the ""turn off op_write"" comment.",0,0.9945454597473145
41881164,191,ijuma,2015-10-13T15:24:25Z,"harsha address this, i believe.",0,0.9901297688484192
41881443,191,ijuma,2015-10-13T15:26:12Z,changed it locally.,0,0.9853970408439636
41883325,191,ijuma,2015-10-13T15:37:52Z,"that's right, changed it locally. with the current code, this doesn't make much of a difference in practice, but it could lead to bugs in the future.",0,0.9906553626060486
41884709,191,ijuma,2015-10-13T15:47:19Z,"there was this code in the constructor before the `login` call: `this.lastlogin = time.currentelapsedtime() - this.mintimebeforerelogin;` i've changed it to: `this.lastlogin = time.currentelapsedtime()` `mintimebeforerelogin` is only relevant for the relogin case. however, we are still setting the `lastlogin` time before we actually execute `logincontext.login` (in both the first and subsequent logins). do you think we should be updating that value after the `logincontext.login` call?",0,0.9944652915000916
41884856,191,ijuma,2015-10-13T15:48:21Z,harsha has done this.,0,0.9892275333404541
41884906,191,ijuma,2015-10-13T15:48:42Z,it looks like we don't.,0,0.9654467105865479
41885077,191,ijuma,2015-10-13T15:49:55Z,we now create the appropriate one (plaintext or ssl) based on whether it's sslsasl or plaintextsasl.,0,0.9940301179885864
41886074,191,ijuma,2015-10-13T15:56:39Z,i removed this as it wasn't being used.,0,0.9848098158836365
41886456,191,ijuma,2015-10-13T15:59:25Z,"i don't understand what you mean, could you elaborate please?",-1,0.69322270154953
41886529,191,ijuma,2015-10-13T15:59:57Z,this was fixed by harsha.,0,0.9911026954650879
41886544,191,ijuma,2015-10-13T16:00:05Z,i fixed this.,0,0.9140657186508179
41886627,191,ijuma,2015-10-13T16:00:34Z,i removed this.,0,0.9735523462295532
41886671,191,ijuma,2015-10-13T16:00:51Z,harsha did this.,0,0.9913763403892517
41887608,191,ijuma,2015-10-13T16:07:42Z,checked with jun and this is fine.,0,0.9679295420646667
41889019,191,ijuma,2015-10-13T16:18:02Z,"these new methods are only used in the `login` class, so i will move them there and make them private for now.",0,0.9936843514442444
41889636,191,ijuma,2015-10-13T16:22:52Z,will propose sasl_plain and sasl_ssl in a pr (checked with jun).,0,0.9931360483169556
41890445,191,ijuma,2015-10-13T16:30:14Z,harsha did this.,0,0.9913763403892517
41890652,191,ijuma,2015-10-13T16:31:39Z,harsha removed the check.,0,0.9922519326210022
41890663,191,ijuma,2015-10-13T16:31:50Z,harsha did this.,0,0.9913763403892517
41898819,191,ijuma,2015-10-13T17:38:35Z,i moved `transportlayer.removeinterestops(selectionkey.op_write);` from `case complete` to here in my latest pr.,0,0.9934366345405579
41907669,191,ijuma,2015-10-13T18:46:29Z,"i will add a comment explaining the `oid` line, which is particularly bizarre.",-1,0.9845148324966431
41922109,191,fpj,2015-10-13T20:43:32Z,"this class is surprisingly similar to org.apache.zookeeper.login, have we copied from the same source? ;-)",1,0.9883550405502319
41928675,191,rajinisivaram,2015-10-13T21:32:51Z,"sasl/plain is typically used to refer to sasl with mechanism plain. and sasl/plain is usually used with ssl as transport layer. since the protocols here are referring to the transport layer and the plain transport layer is called plaintext, it would be less confusing to have sasl_plaintext and sasl_ssl.",0,0.993522584438324
41929181,191,rajinisivaram,2015-10-13T21:37:21Z,"can the mechanism be made a configuration option? i haven't looked through the code yet to see if the implementation relies on this mechanism, but it will be good if it was configurable.",0,0.957287609577179
41929415,191,rajinisivaram,2015-10-13T21:39:25Z,same question as for client - can the sasl mechanism be made configurable?,0,0.994486391544342
41929710,191,rajinisivaram,2015-10-13T21:42:15Z,"is there a reason why this isn't simply using `configuration.getconfiguration()` to get the default configuration since it is using the standard java property to get the jaas config file anyway? i think `javaloginconfig` is provided by the sun provider, dont think it is available with all vendors.",0,0.9907116293907166
41930386,191,ijuma,2015-10-13T21:47:53Z,"ok, i can change my pr to use that instead. to check: is the proposed name better than what we have at the moment (sslsasl and plaintextsasl).",0,0.9914805889129639
41930669,191,ijuma,2015-10-13T21:49:59Z,i think it would be good if we could do that in a separate pr. which other mechanisms are important for you?,0,0.9804621934890747
41931374,191,rajinisivaram,2015-10-13T21:55:36Z,i do prefer sasl_plaintext and sasl_ssl since it is clearer (more readable) than sslsasl and plaintextsasl.,0,0.9913957715034485
41931566,191,ijuma,2015-10-13T21:57:05Z,"ok, great.",1,0.9248012900352478
41937626,191,rajinisivaram,2015-10-13T23:00:31Z,"the one we are keen on is plain. we will be using sasl with ssl, so plain gives us the simplest secure authentication without having to distribute certificates for mutual client auth. yes, a separate pr makes sense so that this one can be committed soon. i will raise another jira.",0,0.9793597459793091
41948372,191,junrao,2015-10-14T02:03:31Z,"since this tests both the producer and consumer, probably this can be called saslintegrationtest. also, could we parameterize the test to test sasl_ssl port too?",0,0.9944773316383362
41948393,191,junrao,2015-10-14T02:03:58Z,perhaps it's clearer to also specify the param name for the third value (false).,0,0.9926659464836121
41948396,191,junrao,2015-10-14T02:04:04Z,"since we only use 1 consumer, do we need to create multiple consumers during setup?",0,0.9939007759094238
41948402,191,junrao,2015-10-14T02:04:10Z,probably better to use foreach instead map.,0,0.9908580183982849
41948404,191,junrao,2015-10-14T02:04:14Z,could we rename this to consumeandverifyrecords?,0,0.9946980476379395
41948407,191,junrao,2015-10-14T02:04:21Z,should we verify the content of the consumed messages too?,0,0.9944319128990173
41948415,191,junrao,2015-10-14T02:04:29Z,"it seems that saslconsumertest.scala covers what's being tested in this file. so, perhaps we don't need this test.",0,0.9907129406929016
41948446,191,junrao,2015-10-14T02:05:07Z,"could we make sun.security.jgss.native a property in the broker/client config file? in general, it seems that other than the jaas config file, it's better to specify other properties from config file instead of system properties.",0,0.9952986836433411
41948452,191,junrao,2015-10-14T02:05:21Z,"it seems that we need to turn off op_write after completing the send of each token. otherwise, the server will be busy looping over the selector while waiting for the next token to be received.",0,0.9597015380859375
41979803,191,ijuma,2015-10-14T10:59:00Z,"i don't think so. i am adding the following comment to the codebase that should explain it: // as described in [a link] // ""to enable java gss to delegate to the native gss library and its list of native mechanisms, // set the system property ""sun.security.jgss.native"" to true"" // ""in addition, when performing operations as a particular subject, for example, subject.doas(...) // or subject.doasprivileged(...), the to-be-used gsscredential should be added to subject's // private credential set. otherwise, the gss operations will fail since no credential is found.""",0,0.992752194404602
41995662,191,junrao,2015-10-14T13:56:11Z,"it is probably not enough to just turn off op_write at sasl completion time. after completely sending a challenge token, the client needs to turn off op_write. otherwise, while waiting to receive the next token from the server, the client will be busy checking in the selector.",0,0.9854141473770142
42009871,191,ijuma,2015-10-14T15:35:04Z,"looking at the documentation, this only needs to be called if the value passed to `setauthorizedid` is different than the value of `getauthorizationid` which is not the case here. having said that, hadoop does the same thing so i'll leave it in case it's needed due to non-compliant implementations (unless others disagree).",0,0.9935135245323181
42062496,191,harshach,2015-10-14T22:30:08Z,yes. i'll fix it.,0,0.9685037136077881
42062570,191,harshach,2015-10-14T22:30:57Z,it will be helpful in case of doas which we are not supporting int this case. but will be added in future. leaving as it is would be better.,0,0.9849035739898682
42062645,191,harshach,2015-10-14T22:31:37Z,yes. did take it from zookeeper.,0,0.9887679219245911
42063676,191,harshach,2015-10-14T22:43:28Z,yes will make it configurable we can implement additional callbacks and digest implementation as part of another pr.,0,0.9903700947761536
42117788,191,ijuma,2015-10-15T12:33:14Z,is it right that we always set it to authorized here (instead of checking if authenticationid and authorizationid are the same like in the client)?,0,0.994236946105957
42119040,191,ijuma,2015-10-15T12:47:05Z,i changed it to do as you say and it seems to work fine. will include it in my next pr so that harsha can integrate it if he agrees.,0,0.8412062525749207
42119247,191,ijuma,2015-10-15T12:49:12Z,"what is the reason that we log here, but don't throw an exception?",0,0.9422928094863892
42126516,191,ijuma,2015-10-15T13:55:38Z,"ok, looking deeper into this, there is a difference: if someone else had called `setconfiguration`, `getconfiguration` would return that while here we override the value of configuration with the jaas file. neither option is ideal, but that's because of the global nature of this setting. i think just using `getconfiguration` is probably better, but i thought i'd mention it here for completeness.",0,0.9719362854957581
42127823,191,ijuma,2015-10-15T14:05:24Z,", do you know a way of doing this without using proprietary classes?",0,0.9906506538391113
42134970,191,rajinisivaram,2015-10-15T14:59:25Z,"sorry, i don't know of a standard way of doing this,",-1,0.9938881993293762
42186791,191,ijuma,2015-10-15T22:03:44Z,", what is the reason that we refresh tgt ourselves instead of using `renewtgt=true` in the jaas file?",0,0.9952221512794495
42187629,191,rajinisivaram,2015-10-15T22:12:12Z,why is servicename a property inside jaas config? could this be made one of the kafka sasl configuration properties instead? presumably it is used only by kafka code and hence doesn't belong in jaas.conf? ibm jdk kerberos module throws an exception because it doesn't recognize this property.,0,0.9878038167953491
42198931,191,harshach,2015-10-16T00:42:28Z,renewtgt=true doesn't mean it does the renewal on its own. if its a keytab you don't set it to renewtgt but if its kinit and the tgt in cache than we need to do the renewal.,0,0.9906389713287354
42199039,191,harshach,2015-10-16T00:44:03Z,"servicename always been used in jaas config and it has to match the keytab prinicpal name . since keytab is configured in the jaas config and it makes sense to keep it there. and all other projects from zookeeper, hdfs to everywhere else uses servicename in jaas config. i don't want to make that as an exception.",0,0.9804312586784363
42200491,191,ijuma,2015-10-16T01:13:49Z,"ok, i read from the following that it did: particularly this part ""with this feature, if krb5loginmodule obtains an expired ticket from the ticket cache, then the tgt will be automatically renewed and be added to subject of the caller who requested the ticket"" [a link] you are saying that this doesn't actually happen and we have to provide the implementation that does the actual renewal?",0,0.9832799434661865
42230500,191,ijuma,2015-10-16T10:55:40Z,"if all those projects use this property and the ibm jdk fails when it sees it, are they doing something to make it work with the ibm jdk? i looked at the zookeeper codebase and i couldn't find any code that retrieves a `servicename` from a jaas configuration file: [a link]",0,0.993403971195221
42259558,191,rajinisivaram,2015-10-16T16:08:24Z,shouldn't this be a daemon thread? otherwise it would prevent client applications from terminating.,0,0.9692960381507874
42261859,191,junrao,2015-10-16T16:31:51Z,"it seems that we need the logic to turn off op_write here too. suppose that the client tries to send a token, but couldn't completely flush the writes. we get in here and completely flush the output buffer. now, if the op_write is not turned off, the selector will be woken up all the time before the client receives the next token from the broker.",0,0.9897152781486511
42261864,191,junrao,2015-10-16T16:31:56Z,"this seems to have the same issue as in saslclient in that we need the logic to turn off op_write here too. suppose that the server tries to send a token, but couldn't completely flush the writes. we get in here and completely flush the output buffer. now, if the op_write is not turned off, the selector will be woken up all the time before the server receives the next token from the client.",0,0.9895579218864441
42262890,191,ijuma,2015-10-16T16:42:30Z,"to make sure i understand, if we completely flush here, we continue executing the method. there are a few code paths where we call `sendsasltoken` which will turn off `op_write`. however, if we are in the intermediate state and we read to the `netinbuffer` but it's not complete, we could end up returning with the op_write on even though it should be off. is that the case you are outlining?",0,0.9926375150680542
42263662,191,junrao,2015-10-16T16:50:07Z,"that's right. if we are still waiting for a new token to be completely received, we will need to turn off op_write.",0,0.9907234311103821
42343337,191,ijuma,2015-10-19T07:52:15Z,i believe this is fixed in my next pr.,0,0.9696810245513916
42343338,191,ijuma,2015-10-19T07:52:19Z,i believe this is fixed in my next pr.,0,0.9696810245513916
42343484,191,ijuma,2015-10-19T07:54:15Z,"suggested that it shouldn't be because we wait for it to terminate on `shutdown`. and if consumers are closed, then it won't prevent client applications from terminating. but it may cause this problem when consumers are not closed, so i am tempted to change it back to a daemon thread. what are your thoughts jun?",-1,0.9118600487709045
42366614,191,ijuma,2015-10-19T12:53:41Z,i added a comment explaining this in my latest pr.,0,0.9630093574523926
42366668,191,ijuma,2015-10-19T12:54:17Z,"i added a todo about this, we probably need to solve it in a subsequent release.",0,0.9796999096870422
42366763,191,ijuma,2015-10-19T12:55:21Z,", this is not actually used at the moment. can you please point me to where it should be used and i can quickly address it?",0,0.981158971786499
573093783,10070,rondagostino,2021-02-09T17:42:50Z,"should the second check appear within the first `if` as it does below in `touch()`? and assuming yes, maybe refactor that common logic out into a `private void removefromactiveandunfenced(brokerheartbeatstate broker)` method?",0,0.995558500289917
573094685,10070,rondagostino,2021-02-09T17:44:04Z,`public void remove(...)`?,0,0.9929865002632141
573095059,10070,rondagostino,2021-02-09T17:44:38Z,`boolean hasvalidsession(...)`?,0,0.9933694005012512
573095621,10070,rondagostino,2021-02-09T17:45:26Z,`public void touch(...)`?,0,0.9928808212280273
573098075,10070,rondagostino,2021-02-09T17:48:45Z,"this seems to imply that it is impossible for a broker to be doing a controlled shutdown and be fenced. i guess that means any controlled shutdown gets cancelled? a comment explaining the implications would be helpful. actually, from further down in `shouldshutdown()` it appears it can shutdown immediately if it is fenced -- so i think it's about leaders moving away? again, a comment would help.",0,0.9774419069290161
573113436,10070,rondagostino,2021-02-09T18:03:42Z,"at first i was confused as to why these two operations were necessary, then i realized it is because the instance is mutable and its places in the ordered list and `treeset` are going to change. a comment here would be helpful to make this apparent (i know there is a comment in the list and set declarations, but a reminder here would be helpful nonetheless).",0,0.983558714389801
573115965,10070,rondagostino,2021-02-09T18:07:27Z,"`public void beginbrokershutdown(...)`? javadoc would be helpful, especially to explain what `deferred` is about. or, if `private` rather than `public`, at least a comment.",0,0.9941263198852539
573116733,10070,rondagostino,2021-02-09T18:08:34Z,what is supposed to happen if it is already shutting down and this is invoked? will it matter if `deferred` is different in the second call?,0,0.9883689880371094
573117364,10070,rondagostino,2021-02-09T18:09:30Z,`public` or `private`? same with methods below.,0,0.9942448735237122
573122112,10070,rondagostino,2021-02-09T18:16:01Z,"is this the case because fenced implies leadership is already moving away? if so, a comment to that effect (or some additional wording in the log line) would be helpful.",0,0.9939663410186768
573123473,10070,rondagostino,2021-02-09T18:17:45Z,you seem to sometime use `shutdown` and other times use `shutdown` -- not sure if that is on purpose or there is a lack of consistency?,0,0.9464120864868164
573125162,10070,rondagostino,2021-02-09T18:20:10Z,`currlowestactiveoffset` a better name?,0,0.9914618730545044
573146291,10070,rondagostino,2021-02-09T18:50:32Z,what's the difference between `beginbrokershutdown()` and `updateshutdownoffset()`? why would the offset at which it can shutdown change? a comment would be helpful.,0,0.9942869544029236
573234880,10070,cmccabe,2021-02-09T20:57:26Z,"hmm, are you suggesting that it should be public? i'd rather not make this public because it's only accessed from within the controller package",0,0.9350767135620117
573235167,10070,cmccabe,2021-02-09T20:57:55Z,"hmm, i'm not sure i understand the question....",-1,0.832943320274353
573235373,10070,cmccabe,2021-02-09T20:58:15Z,"hmm, are you suggesting that it should be public? i'd rather not make this public because it's only accessed from within the controller package",0,0.9350767135620117
573236986,10070,cmccabe,2021-02-09T21:01:06Z,"thanks... that is a good catch. yes, it's a bit more efficient if the statements are nested. i will refactor this out into a separate function.",1,0.9874605536460876
573238990,10070,cmccabe,2021-02-09T21:04:59Z,"good question. a fenced broker will not have leaders, so there should be no leaders to move away. more specifically, if any fenced broker tries to enter controlled shutdown, it will be shut down immediately. i'll add a comment.",1,0.9472439885139465
573239810,10070,rondagostino,2021-02-09T21:06:23Z,"ok, i was just checking. these are all fine then.",0,0.9098491668701172
573240204,10070,rondagostino,2021-02-09T21:07:00Z,"sorry, was asking if it should be public -- but i assume not. was just checking. it's fine now.",-1,0.9909288287162781
573254808,10070,cmccabe,2021-02-09T21:29:21Z,if it's already shutting down nothing happens,0,0.9669088125228882
573254866,10070,cmccabe,2021-02-09T21:29:28Z,package-private is ok,0,0.9844063520431519
573256321,10070,cmccabe,2021-02-09T21:32:00Z,"in general it doesn't make sense to wait for controlled shutdown if the broker is already fenced, because in that case its leaders have already been moved away. i will add a comment.",0,0.9807886481285095
573256612,10070,cmccabe,2021-02-09T21:32:32Z,i wanted to standardize on shutdown. i will fix the inconsistency.,0,0.9499086141586304
573256853,10070,cmccabe,2021-02-09T21:33:00Z,i'll switch to `lowestactiveoffset`,0,0.9903908967971802
573342973,10070,junrao,2021-02-10T00:08:53Z,typo hwne,0,0.9155219197273254
573345382,10070,junrao,2021-02-10T00:15:25Z,the returned map is not keyed on partition.,0,0.9860289692878723
573345428,10070,junrao,2021-02-10T00:15:31Z,the returned map is not keyed on partition.,0,0.9860289692878723
573931818,10070,junrao,2021-02-10T17:32:46Z,do we also need to update the metric for processing time?,0,0.9913656711578369
573934771,10070,junrao,2021-02-10T17:36:55Z,could we move those private methods after all the internal classes?,0,0.9939014911651611
573952836,10070,junrao,2021-02-10T18:01:33Z,the return type is not a tuple.,0,0.9653511643409729
574130720,10070,junrao,2021-02-10T22:42:20Z,could we log lastkey too?,0,0.9932293891906738
574142240,10070,junrao,2021-02-10T23:00:23Z,is this used only for test?,0,0.9888444542884827
574147362,10070,junrao,2021-02-10T23:09:32Z,could we add a bit comment explaining logmanagers and batches?,0,0.9925640225410461
574158801,10070,junrao,2021-02-10T23:34:34Z,could we add a comment for maxreadoffset? is it the committed offset?,0,0.9951068162918091
574162564,10070,junrao,2021-02-10T23:37:53Z,"we already replay the message when it's first appended to the log and here we replay the same message again after commit. this could temporarily revert the state. for example, the latest (uncommitted) config could be overwritten by a previously committed config.",0,0.9913367033004761
574202545,10070,junrao,2021-02-11T01:33:46Z,this can throw stalebrokerepochexception. it would be useful for kafkaeventqueue.run() to log the event associated with the exception.,0,0.9877449870109558
574204032,10070,junrao,2021-02-11T01:39:11Z,"in the zk case, we use the zk version to do conditional updates. in raft, could we associated each partitionstate with the offset in the raft log and use that as partitionepoch for conditional updates? this way, we don't need to explicitly maintain a separate partitionepoch field and the epoch is automatically bumped up for any change to the partition record, not just for leader and isr.",0,0.9943114519119263
574204838,10070,junrao,2021-02-11T01:42:24Z,i thought the raft leader epoch is an int since we store only int as leader epoch in the log?,0,0.9942506551742554
574208116,10070,junrao,2021-02-11T01:51:20Z,"currently, the follower never removes the leader out of isr. so, perhaps we should just throw an exception if this is not the case.",0,0.9834932088851929
574209960,10070,junrao,2021-02-11T01:56:44Z,"this is in response to a heartbeat request. so, it should generate a response in controllerresult?",0,0.9948529601097107
574213985,10070,junrao,2021-02-11T02:13:48Z,some of the replay (e.g. unregister_broker_record) could throw exceptions. we probably need to turn the exception into an error response. are we handling that already?,0,0.9912876486778259
574216140,10070,junrao,2021-02-11T02:23:07Z,we probably should name this sth like removefromisrandmaybechooseleader.,0,0.9908513426780701
574216583,10070,junrao,2021-02-11T02:25:19Z,we need to choose at least a live replica.,0,0.987648606300354
574765157,10070,junrao,2021-02-11T19:22:01Z,is that temporary?,0,0.9821052551269531
574773300,10070,junrao,2021-02-11T19:35:06Z,"in the zk based code, we also take live brokers into consideration when selecting a new leader.",0,0.9943333864212036
574843007,10070,junrao,2021-02-11T21:35:53Z,"hmm, not all partitions with isr containing the shutting down need to change the leader.",0,0.8403781652450562
574845213,10070,junrao,2021-02-11T21:39:46Z,we already did this check and the one below in the caller through `clustercontrol.checkbrokerepoch`.,0,0.9927210211753845
574846943,10070,junrao,2021-02-11T21:43:04Z,this seems unnecessary.,0,0.609399676322937
574869742,10070,junrao,2021-02-11T22:26:32Z,"if we want to log the shutting down the broker, it seems it's more consistent if we always log it. now, it seems we log it only when leaders need to be moved.",0,0.9912927746772766
574872303,10070,junrao,2021-02-11T22:31:36Z,"it seems that we if the request wants to shut down, we should always remove the shutting down broker from isr, just like moving the leader off the shutting down broker?",0,0.9900667667388916
575409674,10070,junrao,2021-02-12T18:00:36Z,"when a broker is unfenced, some of the partitions without leader could have a new leader now. so, it seems that we need to trigger a leader election here.",0,0.9779314398765564
575433620,10070,junrao,2021-02-12T18:26:12Z,"this call generates a leader change record before the following fencedbroker record. ordering wise, it seems that we should record the fencedbroker first. also, i am wondering what's the best place to trigger leader election and removing from isr due to fenced broker. there are multiple cases when a broker can be fenced (e.g. broker controlled shutdown, broker fenced due to no heartbeat). instead of of doing leader election and isr removal in all those cases, another option is to tigger them in a single place when a fencedbroker record is replayed.",0,0.9873051047325134
575435491,10070,junrao,2021-02-12T18:28:10Z,"since we use isrchangerecord for changing the leader too, could we name it to sth more general?",0,0.9948990941047668
575451381,10070,junrao,2021-02-12T18:47:30Z,"should we also trigger leader elections here? also, should we allow broker decommission when it still has replicas?",0,0.9950042366981506
575459759,10070,junrao,2021-02-12T19:03:12Z,"this should tigger leader election too, right?",0,0.9764596819877625
575475691,10070,junrao,2021-02-12T19:35:05Z,"is the intention of `shouldshutdown` to wait until the metadata of the shutting down broker is received by other brokers? if so, not sure why `beginbrokershutdown` sets `broker.shutdownoffset` to either max_long or 0. also, if `shouldshutdown` returns false, when do we get another opportunity to mark the shutting down broker as fenced?",0,0.9943146109580994
575478386,10070,junrao,2021-02-12T19:40:05Z,"in the zk based logic, on receiving a controlled shutdown request, the controller tries to move the leaders off the broker. if this is successful, the controller sends a successful return for the broker to proceed with shutdown. here, it seems that the controller will initially return shouldshutdown as false to the broker if there are leaders moved off the broker and require the broker to heartbeat again to be able to shut down.",0,0.9936528205871582
575480618,10070,junrao,2021-02-12T19:44:40Z,i thought we want to allow topics to be created even when there is not enough live brokers now?,0,0.9898249506950378
575514366,10070,junrao,2021-02-12T20:55:11Z,do we need to use `this`? ditto below.,0,0.9920406937599182
575516660,10070,junrao,2021-02-12T20:59:54Z,"hmm, should we return the future from `appendwriteevent` ?",0,0.9935764670372009
575525508,10070,junrao,2021-02-12T21:20:15Z,"sometimes, we update the in-memory state after the record is appended to the log. here, it seems that we do the reverse. should we make that consistent?",0,0.9819289445877075
575527291,10070,junrao,2021-02-12T21:24:36Z,it seems the broker can shut down immediately if this is false?,0,0.9848846197128296
575535738,10070,junrao,2021-02-12T21:45:14Z,could we just update `partitions` in place?,0,0.9944678544998169
575541127,10070,junrao,2021-02-12T21:58:46Z,what triggers this on a hard controller failure?,0,0.9548317193984985
575542308,10070,junrao,2021-02-12T22:01:47Z,should we trigger the logic for leader election/isr removal since there could be unhandled fencedbroker records when the new controller takes over?,0,0.9936903715133667
575546009,10070,junrao,2021-02-12T22:11:02Z,should this be changed to unregisterbroker to match the kip?,0,0.9946448802947998
575547292,10070,junrao,2021-02-12T22:14:39Z,should we call this sth like waitforshutdowncomplete to match `beginshutdown`?,0,0.9951437711715698
575548758,10070,junrao,2021-02-12T22:18:13Z,is this still needed with raft metadata?,0,0.994473397731781
575548839,10070,junrao,2021-02-12T22:18:24Z,this class seems unused.,0,0.5864279866218567
575549084,10070,junrao,2021-02-12T22:19:01Z,this class seems unused.,0,0.5864279866218567
575549246,10070,junrao,2021-02-12T22:19:28Z,inaccurate comment.,-1,0.8521203994750977
575549741,10070,junrao,2021-02-12T22:20:43Z,could we add some comment for this class?,0,0.9925791621208191
575552471,10070,junrao,2021-02-12T22:25:10Z,it might be useful to log both the old and the new value.,0,0.9879246950149536
575554284,10070,junrao,2021-02-12T22:28:11Z,are we deprecating the state-change log and the controller log that we had before?,0,0.9913856983184814
577117523,10070,cmccabe,2021-02-16T20:31:01Z,"yes, it is. i will move it to the test directory.",0,0.9823819994926453
577125115,10070,cmccabe,2021-02-16T20:45:16Z,this code is only executed by the followers. it is true that the leader already applied these log messages but these nodes are not the leader.,0,0.9930372834205627
577127231,10070,cmccabe,2021-02-16T20:48:46Z,`handleeventexception` handles logging exceptions thrown by events.,0,0.9886685013771057
577135430,10070,cmccabe,2021-02-16T21:02:02Z,"yes, i think that could work for partition epoch. let's do that once we have the initial code in, though...",0,0.9770283102989197
577136289,10070,cmccabe,2021-02-16T21:03:31Z,"it is an int and will be in 2.8, but i think that's a mistake (as discussed in the mailing list) and we should plan to make this 64 bit in the near future to avoid overflow issues. so the controller code treats it as a long... cc",0,0.9697007536888123
577143791,10070,cmccabe,2021-02-16T21:17:09Z,ok. we can make this an invalid request then.,0,0.9857820272445679
577146421,10070,cmccabe,2021-02-16T21:21:53Z,"hmm, this comment shows up for me as being left in the `decommissionbroker` function, which is called in response to the decomission broker rpc, not the heartbeat rpc. maybe this is a github ui issue? did you mean to leave this comment for a different function?",0,0.9123486876487732
577147155,10070,rondagostino,2021-02-16T21:23:19Z,i believe after this we need to invoke something to cover the case where a topic has this broker as its only isr member: [code block] the implementation might look like this: [code block],0,0.9853401780128479
577148107,10070,cmccabe,2021-02-16T21:25:13Z,if an exception is thrown here we will end up in `handleeventexception`. since the exception won't be a subclass of `apiexception` we will resign as controller and return an `unknownserverexception`.,0,0.990500807762146
577148212,10070,rondagostino,2021-02-16T21:25:26Z,i believe we should surround this section of code with the following to be sure we never drop the last isr member: [code block],0,0.9885421991348267
577163457,10070,cmccabe,2021-02-16T21:52:59Z,i changed it to `removefromisrandleaderships`,0,0.9942004680633545
577167409,10070,cmccabe,2021-02-16T21:58:24Z,"good point, will fix",1,0.9652446508407593
577167941,10070,cmccabe,2021-02-16T21:59:17Z,this has to be handled by the individual brokers. it's not persisted anywhere currently (currently it is not stored in zk i believe),0,0.9894523620605469
577176042,10070,cmccabe,2021-02-16T22:14:05Z,"in this function we are iterating only over the partitions that the given broker is a leader for. ( we obtained the iterator from `brokerstoisrs#iterator(brokerid=brokerid, leadersonly=true)` )",0,0.9932371973991394
577178197,10070,cmccabe,2021-02-16T22:18:19Z,ok,0,0.8787186145782471
577187004,10070,cmccabe,2021-02-16T22:34:34Z,"i will improve the logging a bit here. i agree that we should log when a broker is told it can shut down or be (un) fenced, since those are major events.",0,0.8769354224205017
577188202,10070,cmccabe,2021-02-16T22:36:59Z,"it seemed safer to leave it in the isr until it's ready to shut down for good. also, if we take it out, it might just get re-added if it catches up... ?",0,0.9523475766181946
577214559,10070,cmccabe,2021-02-16T23:36:58Z,"good point. the appropriate place to handle this will be in the broker heartbeat handling code, since that is where the active controller unfences brokers.",0,0.5688959956169128
577217605,10070,cmccabe,2021-02-16T23:44:42Z,"hmm... it should be ok to remove the leaderships first. kip-500 controlled shutdown works this way, for example... the shutting-down broker is not actually fenced at all until all the other brokers have removed it as a leader. also, wouldn't it be a bit weird to be in a state where a broker is still marked as the leader for some partition, but doesn't show up in the list of brokers given in the metadataresponse? that would happen if we put the fencing record first. i don't think clients or brokers would handle this well. replaying a record cannot trigger the creation of any additional records. this would not work since the standby controllers can't create records, after all... only the active controller. i have created a `handlebrokerfenced` function in `replicationcontrolmanager` which does most of what needs to be done for fencing, though... aside from creating the actual fencing record.",-1,0.6813815236091614
577259797,10070,junrao,2021-02-17T01:23:48Z,sounds good. could we add a comment to make that clear?,1,0.6954603791236877
577262652,10070,junrao,2021-02-17T01:31:42Z,it seems that we are logging at the debug level. i am wondering if we should log at warn as before in zk based appoach. [code block],0,0.9749681949615479
577263866,10070,junrao,2021-02-17T01:35:14Z,"i thought the issue was that if changing leaderepoch to long requires a log format change for user data, it has significant performance impact such as down conversion.",0,0.967361330986023
577268593,10070,junrao,2021-02-17T01:48:41Z,"sorry, i meant `decommissionbroker`. it seems that decommissionbroker request should we a response too, right?",-1,0.9806714653968811
577278241,10070,junrao,2021-02-17T02:16:16Z,"well, in zk based approach, in response to a controlled shutdown, the controller changes isr and the leader. here, it seems that `result.response().isfenced()` is not always true if the broker heartbeat indicates the intention to shut down?",0,0.9934852719306946
577865782,10070,cmccabe,2021-02-17T18:57:08Z,"i normally do group private methods after internal classes, but in this case, it seemed better to keep them together. otherwise you'd have to jump around a lot when reading the code. what do you think?",0,0.9576349258422852
577866850,10070,cmccabe,2021-02-17T18:58:41Z,added,0,0.9267084002494812
577868843,10070,cmccabe,2021-02-17T19:01:51Z,"we can get here just because the user made an invalid rpc, so i don't know if warn is appropriate. i'll change it to info for now.",0,0.907702624797821
577879960,10070,junrao,2021-02-17T19:19:29Z,sounds good too.,1,0.9053424596786499
577894071,10070,cmccabe,2021-02-17T19:42:26Z,"note: this has been changed to unregisterbroker as per the mailing list discussion. it's ok to have a future that returns void. that just means you either get success, or an error (there is no other result). which is consistent with unregisterbrokerresponse.json, etc.",0,0.9912801384925842
577895640,10070,cmccabe,2021-02-17T19:45:07Z,hmm... we only fence the broker once controlled shutdown has completed. if we fenced it immediately that would be disruptive to clients since they wouldn't be able to continue fetching from it until the leaderships have moved. basically immediate fencing is the non-controlled shutdown path....,0,0.8406006693840027
577914392,10070,cmccabe,2021-02-17T20:16:22Z,i have renamed it to `partitionchangerecord`,0,0.9907239079475403
577915565,10070,cmccabe,2021-02-17T20:18:09Z,"good catch. yes, this should be moving leaders. i fixed this in the latest version of the pr. yes, this is allowed.",1,0.9532743096351624
577916179,10070,cmccabe,2021-02-17T20:19:10Z,"i restructured this code a bit. but yes, it does move leaders if needed (it's clearer in the new version i think)",0,0.9863727688789368
577916633,10070,cmccabe,2021-02-17T20:19:56Z,"this got refactored, hopefully the new version is clearer. the new version avoids the max_long / 0 hack and other ugliness that was in the initial version.",0,0.9789400696754456
577916988,10070,cmccabe,2021-02-17T20:20:33Z,that is correct. the broker must send another heartbeat before it is allowed to shut down.,0,0.9890266060829163
577918400,10070,cmccabe,2021-02-17T20:23:00Z,"good point. since we don't have much time for 2.8, i will add a todo for now.",1,0.889945924282074
577919102,10070,cmccabe,2021-02-17T20:24:17Z,good catch.,1,0.9815194606781006
577919831,10070,cmccabe,2021-02-17T20:25:33Z,"the heartbeat manager is special because it stores soft state which is not in the metadata log (when each broker last heartbeated, for example).",0,0.9906116127967834
577920156,10070,cmccabe,2021-02-17T20:26:04Z,"this got refactored. hopefully it is clearer now. yes, a broker can shut down immediately in some cases",0,0.9076614379882812
577920610,10070,cmccabe,2021-02-17T20:26:52Z,since this is stored in a `timelinehashmap` it must be treated as immutable. we can't modify the past.,0,0.993902325630188
577921275,10070,cmccabe,2021-02-17T20:27:54Z,this comes out of the raft layer and is invoked when the raft election has succeeded and produced a new leader node.,0,0.990094006061554
577922334,10070,cmccabe,2021-02-17T20:29:46Z,"the standby controller must replay all the committed records before becoming active. so, there is no unfinished work to be done at this point.",0,0.9921212196350098
577922831,10070,cmccabe,2021-02-17T20:30:39Z,"the name close comes from `autocloseable`, which makes some of the tests nicer to write (because we can use the java try-with-resources syntax).",0,0.9856921434402466
577929118,10070,cmccabe,2021-02-17T20:41:57Z,"i don't think the state change log can scale to the number of partitions we need. it gets too verbose. also, this information is available in the metadata log itself.",0,0.7058025002479553
577929403,10070,cmccabe,2021-02-17T20:42:29Z,"thanks, . in the latest version, i do not remove brokers from singleton isrs.",1,0.9674329161643982
577961646,10070,rondagostino,2021-02-17T21:36:39Z,`mockcontrollermetrics` is a test class?,0,0.9935910701751709
577971959,10070,rondagostino,2021-02-17T21:54:59Z,"maybe it would be better to check for null and exit out if it is unset -- otherwise we see this, which is not ideal: [code block]",0,0.9820238947868347
577993008,10070,junrao,2021-02-17T22:34:45Z,"in the old controller, eventqueuetimems is used to measure the amount of time an event is sitting in the queue before being processed. there is a separate timer metric per controller state that measures the processing time per event type.",0,0.9912795424461365
578003900,10070,junrao,2021-02-17T22:58:11Z,it seems that using long for leaderepoch in the log requires a bigger discussion. could we use int for now?,0,0.9893975257873535
578014387,10070,junrao,2021-02-17T23:22:16Z,"if a broker wants to shut down and is only included in isr, we still want to remove the broker from isr before allowing it to shutdown. otherwise, a new published record needs to wait for the session timeout before it can be committed.",0,0.988705575466156
578015133,10070,junrao,2021-02-17T23:24:13Z,what about the case when request.wantfence() is true?,0,0.9916663765907288
578019439,10070,junrao,2021-02-17T23:35:12Z,"(1) in zk-based approach, we do leader election a bit differently for controlled shutdown. if we can't select a leader from the remaining isr, we just leave the current leader as it is. this gives the shutting down broker a chance to retry controlled shutdown until the timeout. (2) in zk-based approach, we also remove the broker from isr for other partitions whose leader is not on the shutting down broker. that's true and is an existing problem. one way to address this is to include partitionepoch in the follower fetch request. the leader could then reject a follower request if the partitionepoch doesn't match. this can be done in a followup pr.",0,0.989120364189148
578026068,10070,junrao,2021-02-17T23:52:30Z,could we add a todo for handling the preferred leader election?,0,0.9940499067306519
578028795,10070,junrao,2021-02-17T23:59:48Z,should this be named unregisterbroker?,0,0.994236409664154
578047059,10070,junrao,2021-02-18T00:51:31Z,is this check already implied since we are iterating `brokerstoisrs`?,0,0.9948920011520386
578054305,10070,junrao,2021-02-18T01:08:09Z,is there any benefit/enough to only allow the broker to shutdown when all brokers have caught up to controlledshutdownoffset? the zk-based criteria is that a broker is allowed to shut down as long as all leaders have been moved off the shutting down broker.,0,0.9936639070510864
578062730,10070,junrao,2021-02-18T01:31:49Z,we are generating an unregisterbrokerrecord.,0,0.9926264882087708
578065045,10070,junrao,2021-02-18T01:36:55Z,are all records generated in a single controllerwriteevent appended to the metadata log atomically?,0,0.9947782754898071
578067236,10070,junrao,2021-02-18T01:43:22Z,"hmm, the comment seems to be the same as shouldshutdown.",0,0.9472958445549011
578071150,10070,junrao,2021-02-18T01:55:21Z,testfindstalebrokers ?,0,0.9912159442901611
578076422,10070,junrao,2021-02-18T02:09:31Z,could we make it private?,0,0.9922512173652649
578079100,10070,junrao,2021-02-18T02:17:13Z,testunregister?,0,0.9904782772064209
578080050,10070,junrao,2021-02-18T02:19:53Z,testplacereplicas ?,0,0.9943245053291321
578603931,10070,cmccabe,2021-02-18T17:19:36Z,"good point. i will fix it so that eventqueuetimems has its original meaning. for now, i have added a metric called eventqueueprocessingtimems which deals with processing time. i do want to do the per-state tracking but i don't think we have time right now",1,0.6854129433631897
578606545,10070,junrao,2021-02-18T17:23:17Z,an empty topic name currently results in an invalid_request error.,0,0.9787160754203796
578613805,10070,junrao,2021-02-18T17:32:32Z,an empty broker currently results in an invalid_request error.,0,0.9788792133331299
578619727,10070,cmccabe,2021-02-18T17:40:46Z,"ok, that makes sense. i will remove it from all non-singleton isrs as well as removing it from all leaderships.",0,0.9680547714233398
578621621,10070,cmccabe,2021-02-18T17:43:39Z,"good question. the broker doesn't currently request fencing once it is unfenced. but for completeness, it is simple to support this and it makes the code more intuitive, so i'll add it.",1,0.9471663236618042
578625531,10070,cmccabe,2021-02-18T17:49:18Z,"as i mentioned above, i changed it so that it now removes the broker from all non-singleton isrs, as well as removing it from leaderships. it seems like the remaining behavioral difference is that the new code will, if no other leader can be chosen, set the leader to -1 (offline). if we don't do this, controlled shutdown easily gets stuck if there are any partitions with replication factor = 1. maybe we can tune this a bit later? i like the idea of including the partition epoch in the follower fetch request.",0,0.8909679055213928
578627766,10070,cmccabe,2021-02-18T17:52:32Z,"hmm, i thought this already handles preferred leader election (there are only two options, preferred and unclean, so far...)",0,0.9464510083198547
578628736,10070,cmccabe,2021-02-18T17:53:57Z,good catch. this has been superseded by `replicationcontrolmanager#unregsiterbroker`.,1,0.9170119762420654
578629900,10070,cmccabe,2021-02-18T17:55:39Z,"we're iterating over the partitions with no leader, which may or may not have the newly activated broker in their isr.",0,0.9910649061203003
578630655,10070,cmccabe,2021-02-18T17:56:43Z,"basically it lets us know that the other brokers have successfully taken over as leader (where needed) which avoids having a period of unavailability, ideally",0,0.9927554726600647
578648887,10070,cmccabe,2021-02-18T18:23:21Z,fixed,0,0.9281549453735352
578664492,10070,junrao,2021-02-18T18:47:22Z,do we allow a heartbeat request to set both the fence and wantshutdown flag?,0,0.9946669340133667
578667056,10070,junrao,2021-02-18T18:51:14Z,"it's fine to revisit that later. the tradeoff is that if we wait, it slightly increases the probability of availability since another replica could join isr.",0,0.9916229844093323
578669898,10070,junrao,2021-02-18T18:55:42Z,"i think we need to handle preferred leader election in a special way. for example, if the assigned replicas are 1,2,3, isr is 2,3 and the current leader is 3, when doing preferred leader election, we want to keep the leader as 3 instead of changing it to 2.",0,0.9849804639816284
578693886,10070,junrao,2021-02-18T19:35:29Z,"this can be revisited later. when finalizing a feature, should be consider other controller's supported features too?",0,0.9941772222518921
578696957,10070,junrao,2021-02-18T19:40:18Z,this class seems never used?,0,0.8915638327598572
578699530,10070,junrao,2021-02-18T19:44:45Z,could we add some comments for this class?,0,0.9918127059936523
578700824,10070,junrao,2021-02-18T19:46:48Z,"to make this more intuitive, perhaps we could add a method isactive in quorumcontroller?",0,0.993998646736145
578722110,10070,junrao,2021-02-18T20:23:39Z,"hmm, why is a replication factor of 1 invalid?",0,0.7792132496833801
578817527,10070,cmccabe,2021-02-18T23:24:41Z,a resource with type broker and an empty name represents a cluster configuration that applies to all brokers. i'll add a comment,0,0.9917381405830383
578817611,10070,cmccabe,2021-02-18T23:24:57Z,"yes, it can set both",0,0.9884534478187561
578850598,10070,cmccabe,2021-02-19T00:54:40Z,"hmm... right now, we don't have a good way of finding out what features the other controllers support. maybe we will have to think more about this when we support rolling upgrade in kip-500.",-1,0.6329348087310791
578850804,10070,cmccabe,2021-02-19T00:55:21Z,it's used in unit tests,0,0.9913323521614075
578851481,10070,junrao,2021-02-19T00:57:07Z,"yes, that's the problem. from a consistency perspective, it seems that we should use the supported features from either all controller nodes or none.",0,0.97807377576828
578857828,10070,cmccabe,2021-02-19T01:15:22Z,"there are no unfenced brokers (as you mentioned earlier, we should change this so that it places on the fenced broker). i will add a todo",0,0.9913424253463745
578876029,10070,junrao,2021-02-19T02:10:09Z,could we add some comments to this class?,0,0.9913654327392578
578877349,10070,junrao,2021-02-19T02:14:23Z,"well, currently the contract is just that if every broker picks the preferred replica (i.e. 1st replica), the leaders will be balanced among brokers. if not, all other replicas are equivalent. moving leaders among non-preferred replicas just creates churns without benefiting the balance.",0,0.9914988875389099
578878282,10070,junrao,2021-02-19T02:17:34Z,"as jason pointed out, in zk based approach, the controller bumps up the leader epoch for removing replica from isr too. also, since the broker is no longer receiving the leaderandisr requests, we need some logic for the broker to ignore the new partition record (for follower fetching) once it starts the controlled shutdown process.",0,0.993649423122406
579374802,10070,cmccabe,2021-02-19T18:04:52Z,"this is resolved in the latest version of the code, where we disable metadata updates on the shutting down broker before starting controlled shutdown, and bump the leader epoch of all partitions.",0,0.9943655729293823
579378306,10070,cmccabe,2021-02-19T18:10:42Z,"i changed this so that the leader epoch is bumped if and only if there is a leader present in the partitionchange record. (it is possible to bump the epoch without changing the leader by including the same leader again in the record.) we now use this during controlled shutdown to unconditionally bump the leader epochs. otherwise, we only bump the leader epochs if the leader changed.",0,0.9940779209136963
579403297,10070,junrao,2021-02-19T18:50:24Z,"hmm, does integer.min_value have any special meaning? if so, could we use a more intuitive constant?",0,0.9747421741485596
579406849,10070,junrao,2021-02-19T18:56:29Z,"hmm, if the leader is already -1 and we can't change isr, there is no need to generate a new partitionchangerecord just to bump up the leader epoch. it won't help controlled shutdown since there is already no leader.",0,0.9682114124298096
579410463,10070,junrao,2021-02-19T19:01:26Z,"currently, for controller initiated isr change (controlled shutdown or hard failure), we always bump up the leader epoch. also, the name alwaysbumpleaderepoch is a bit weird since the code in handlenodedeactivated() doesn't directly bump up leader epoch.",-1,0.8128355145454407
579411851,10070,junrao,2021-02-19T19:03:59Z,"currently, for leader initiated alterisr request, the controller doesn't bump up the leader epoch. if we change that, it will slightly increase unavailability since all clients have to refresh the metadata in this case.",0,0.9793248772621155
579414289,10070,junrao,2021-02-19T19:08:23Z,"if we do this, does `brokermetadatalistener.close() `still need to call `beginshutdown()`.",0,0.9921305775642395
579421318,10070,junrao,2021-02-19T19:21:16Z,"hmm, it seems that we should only do `newleader != partitioninfo.preferredreplica()` if this is a preferred leader election.",0,0.9848154783248901
579438984,10070,junrao,2021-02-19T19:54:01Z,"hmm, merge bumps up the leaderepoch. it seems that this needs to be persisted in the metadata log?",0,0.9468803405761719
579458466,10070,cmccabe,2021-02-19T20:31:19Z,no special meaning. it's just a constant that can't be a valid leader. we could use -2 if that seems nicer.,0,0.9599979519844055
579462462,10070,cmccabe,2021-02-19T20:38:40Z,hmm... i don't completely understand why we would want to bump the leader epoch when the controller removes a non-leader broker b but not when an alterisrrequest removes a non-leader broker b from the isr. it seems like we should either bump in both scenarios or neither. is the fact that we bump in the first scenario just an artifact of the fact that otherwise we could not send out a leader and isr request that had a new epoch and thereby caused a change?,0,0.6896573305130005
579463797,10070,cmccabe,2021-02-19T20:41:39Z,"hmm... replicationcontrolmanager should not allow this to happen during an alter isr request. there is some code that checks if the alter isr request is attempting to remove the current leader from the isr, and returns an error if so. so the leader should not be changed by an alter isr request and therefore the leader epoch will not be. [code block]",0,0.9719074368476868
579464755,10070,cmccabe,2021-02-19T20:43:43Z,it does need to be because there are some paths through the code that don't go through here. in general calling `beginshutdown` or `close` multiple times is harmless-- only the first time has an effect.,0,0.97411048412323
579496903,10070,junrao,2021-02-19T21:52:36Z,"yes, the alterisr doesn't change leader, but generates a partitionchangerecord. on replaying this record, the code following code bumps on leaderepoch? ` partitioncontrolinfo newpartitioninfo = prevpartitioninfo.merge(record);`",0,0.9929839372634888
579497748,10070,junrao,2021-02-19T21:54:30Z,"ok, maybe the check can be `record.leader()< -1`?",0,0.9950172305107117
579522201,10070,cmccabe,2021-02-19T22:47:15Z,"even in an unclean leader election, we don't want to change the leader unless we need to.",0,0.9185413122177124
579522827,10070,cmccabe,2021-02-19T22:48:43Z,"the leader epoch is managed implicitly -- every time a partitionchangerecord appears, the epoch is bumped if the leader is not no_leader_change.",0,0.9925710558891296
579536414,10070,junrao,2021-02-19T23:28:15Z,"hmm, we should set the leader to no_leader_change, right?",0,0.9862090945243835
579538752,10070,junrao,2021-02-19T23:37:14Z,could you file a separate jira to follow up on partitionepoch post 2.8?,0,0.994325578212738
579547098,10070,cmccabe,2021-02-20T00:07:59Z,that is the default so we don't need to set it unless we're changing it,0,0.9860926270484924
579547404,10070,cmccabe,2021-02-20T00:09:24Z,filed kafka-12349,0,0.9905135631561279
579547731,10070,cmccabe,2021-02-20T00:10:42Z,merge only bumps the epoch if the leader was set. [code block],0,0.9945555925369263
579547825,10070,cmccabe,2021-02-20T00:11:10Z,"as per our discussion outside github, let's just use the old behavior for now.",0,0.9835469722747803
579547910,10070,cmccabe,2021-02-20T00:11:40Z,i added a constant. i think it looks a little nicer...,0,0.764545202255249
579553251,10070,junrao,2021-02-20T00:35:14Z,"we have no_leader_change as the default for the serialized data. however, the active controller replays the partitionchangerecord created in memory, which defaults leader to no_leader_change, right?",0,0.9931415915489197
579564268,10070,cmccabe,2021-02-20T01:15:01Z,let's revisit this after 2.8,0,0.9891941547393799
579564579,10070,cmccabe,2021-02-20T01:16:31Z,right now the answer is yes. eventually we plan on supporting multiple batches.,0,0.9897229671478271
579564654,10070,cmccabe,2021-02-20T01:17:04Z,"i do think we should harmonize this, but i think it would be better to do that when we get rid of metalogshim. we've had a plan to get rid of the shim layer for a while but we just didn't have time to do it this week. so let's plan to do it then, if that makes sense",0,0.9749334454536438
579565540,10070,cmccabe,2021-02-20T01:21:30Z,ack. i fixed this,-1,0.9805857539176941
580411938,10070,junrao,2021-02-22T16:54:21Z,do we have a jira to track this?,0,0.9919043183326721
136670512,3765,junrao,2017-09-01T21:42:22Z,could you carry over the comments in replicastatemachine about the possible state changes and the corresponding actions? ditto for the new partitionstatemachine.,0,0.9937859773635864
136672966,3765,junrao,2017-09-01T22:00:28Z,"i am actually not sure if we need to read the partition state from zk in this case. the transition to newreplica is only used in 2 places: (1) starting a new replica in partition reassignment, (2) when a new topic is created. in (1), if there is a leader, it will already be cached by the controller. in (2), currently, it seems it's guaranteed there is not a leader at this point. a subsequent transition to onlinepartition in onnewpartitioncreation() will do the leader election part. so, it seems that we can (a) just read the cached leader info, (b) call brokerrequestbatch.addleaderandisrrequestforbrokers if leader is available and doesn't equal to current replica, (c) move the replica to newreplica state unless the leader equals to the current replica, (d) we probably also want to log an error if the new replica happens to be the leader.",0,0.9893466830253601
136675513,3765,junrao,2017-09-01T22:24:23Z,it will be useful to document the response since it is a bit complicated.,0,0.9778730869293213
136678656,3765,junrao,2017-09-01T22:59:27Z,"it seems that it may be possible for the response to have a sequence of connectionloss, followed by a sequence of ok when the session was disconnected and then reconnected again. so, we may want to just do filter instead of takewhile.",0,0.9877316355705261
136679343,3765,junrao,2017-09-01T23:07:29Z,it will be useful to explicitly define the return type in each of the public methods to make it clear.,0,0.9912459254264832
136679765,3765,junrao,2017-09-01T23:13:11Z,"hmm, will kafkacontrollerzkutils.gettopicpartitionstates ever throw an exception?",0,0.9831076860427856
136872413,3765,junrao,2017-09-04T21:52:57Z,"it seems that we only need to check the topic config if the isr is empty after replicaid is removed from isr, not before.",0,0.9928493499755859
136872700,3765,junrao,2017-09-04T22:00:02Z,"for those partitions whose isr can't be shrunk due to making isr empty, we simply keep the current isr. so, it seems in this case, we can just do an optimization by not sending the leaderandisrrequest for those partition since neither the leader nor the isr will change.",0,0.9928073883056641
136873950,3765,junrao,2017-09-04T22:29:21Z,"hmm, do we need the logic here? it seems that we are refreshing the topic partition state when retrying doremovereplicasfromisr. so, reading the topic partition state here seems redundant.",0,0.9718106389045715
136874953,3765,junrao,2017-09-04T22:57:06Z,we will need to handle nonode error here by creating the missing parent path if needed.,0,0.985692024230957
136875070,3765,junrao,2017-09-04T23:00:51Z,check the error code?,0,0.9844226241111755
136875311,3765,junrao,2017-09-04T23:06:24Z,it seems that we should do this in a while loop since we do conditional update to the leaderandisr path in zk and need to retry on badversion.,0,0.9807249307632446
136875649,3765,junrao,2017-09-04T23:15:27Z,"partitionswithuncleanleaderelectionstate includes partitions that don't need unclean leader election. so, the name seems a bit miss-leading.",0,0.7534028887748718
136876376,3765,junrao,2017-09-04T23:35:34Z,"ideally, we want to select the preferred replica if it's alive, in-sync and not shutting down as controlledshutdownleaderselector does.",0,0.9916437268257141
136876429,3765,junrao,2017-09-04T23:36:33Z,unused import,0,0.9524969458580017
136876599,3765,junrao,2017-09-04T23:40:15Z,"if a create operation retries due to code.connectionloss, it's possible for the retry to receive a nodeexist error since the previous create may have succeeded. perhaps on nodeexist error during retry, we can read the value back and only return nodeexist error if the value is different from that to be created.",0,0.9905630350112915
136876729,3765,junrao,2017-09-04T23:44:05Z,do we need to add some general handling for errors like noauth?,0,0.9901657700538635
136903037,3765,onurkaraman,2017-09-05T06:23:29Z,yeah i noticed this as well. i mainly just wanted to keep the existing behavior the same and worry about tweaking the existing behavior in later patches. the only reason i can come up with for this zk lookup is to notice if another controller takes over while this current controller is in the process of doing this transition.,0,0.9816426634788513
136904968,3765,onurkaraman,2017-09-05T06:39:48Z,"it seems that in this scenario today, the leadership changes to leaderandisr.noleader (-1), the leader epoch increments, and the zkversion increments too. we send leaderandisrrequests to the full replica set (not just isr) and also send updatemetadatarequests to the whole cluster with this updated leaderandisr with leader = -1, isr = old isr with the single replica, the incremented leader epoch, and the incremented zkversion. in fact, whenever we send a leaderandisrrequest, we also broadcast updatemetdatarequests to the whole cluster. are you suggesting we do neither of these things? skipping these steps means that: 1. non-isr replicas will not be aware of the incremented leader epoch and zkversions. 2. the cluster will not receive the updated metadata.",0,0.9905099272727966
136905187,3765,onurkaraman,2017-09-05T06:41:27Z,"it's possible since it internally calls zookeeperclient.waituntilconnected, which can throw exceptions (zookeeperclientauthfailedexception and zookeeperclientexpiredexception).",0,0.9908135533332825
136906744,3765,onurkaraman,2017-09-05T06:53:16Z,it attempts to mimic the existing behavior in replicationutils.checkleaderandisrzkdata (which is called from replicationutils.updateleaderandisr). strictly speaking i don't think this logic is required. i think it just attempts to make progress on a version conflict (for instance if the partition leader concurrently updated isr) instead of starting over.,0,0.9879144430160522
137011097,3765,junrao,2017-09-05T14:53:43Z,"hmm, since we are fixing the issue with zk session expiration, there shouldn't be more than 1 controller accessing zk at the same time. in general, i agree that we don't want to make major changes to partition/replicastatemachine while refactoring zk accesses. however, if this simplifies how we use zk, it may be worth doing.",0,0.9754309058189392
137011133,3765,junrao,2017-09-05T14:53:51Z,"ah, ok. so, we did change the leader in this case.",0,0.9568120837211609
137011245,3765,junrao,2017-09-05T14:54:07Z,"hmm, for both zookeeperclientauthfailedexception and zookeeperclientexpiredexception, we probably don't want to retry forever in removereplicasfromisr(). it seems that we should just log an error and move on.",0,0.9748983979225159
137011321,3765,junrao,2017-09-05T14:54:22Z,"ok, that logic is just to handle the possibility that a previous write has succeeded on a connectionlossexception. it would be useful to document that.",0,0.9924465417861938
137052511,3765,onurkaraman,2017-09-05T16:58:18Z,it's not terribly clear but that's actually the behavior in the pr.,0,0.8626602292060852
137159386,3765,onurkaraman,2017-09-06T02:34:25Z,this falls in the category of suggestions that differ in current behavior. again i'm not sure if we want to overload this pr with more than just porting existing behavior.,0,0.5602327585220337
137159912,3765,onurkaraman,2017-09-06T02:40:39Z,"in the case of `kafkacontrollerzkutils.createtopicpartitionstates`, we're creating the state znode for the first time, in which case the following parent znodes almost definitely will not exist: * /brokers/topics/\ /partitions * /brokers/topics/\ /partitions/\ * /brokers/topics/\ /partitions/\ /state so perhaps in this case, we should push the creation of these parent znodes into `kafkacontrollerzkutils.createtopicpartitionstates`.",0,0.9949851036071777
137160199,3765,onurkaraman,2017-09-06T02:43:52Z,"yeah as stated in one of my earlier pr comments, no effort has been put into partitionstatemachinev2 yet to do error handling and retries. the idea was to first validate that the overall strategy would work in replicastatemachinev2 and then apply error handling and retries to partitionstatemachinev2.",0,0.9931371212005615
137167391,3765,onurkaraman,2017-09-06T04:07:12Z,there was one typo in gettopicpartitionstatesfromzk: `val candidateisr = leaderisrandcontrollerepoch.leaderandisr.isr.filternot(_ != replicaid)` should be: `val candidateisr = leaderisrandcontrollerepoch.leaderandisr.isr.filter(_ != replicaid)` but otherwise we actually do the topic config checks only on the partitions whose isr is empty after removal. note that the `candidateleaderandisrs` returned is used to find `partitionswithemptyisr` which is what we pass into `leaderandisrbasedonlogconfigs`.,0,0.9948968291282654
137349319,3765,junrao,2017-09-06T18:18:11Z,"yes, that sounds good.",1,0.6914747953414917
138211018,3765,junrao,2017-09-11T22:39:08Z,"it seems that we will need to set acl based on whether zk security is enabled or not, like what zkutils.defaultacls() does.",0,0.9913216233253479
138212390,3765,junrao,2017-09-11T22:47:47Z,this method can be private.,0,0.9874782562255859
138451688,3765,junrao,2017-09-12T20:06:03Z,perhaps we should also log an error for any other error code?,0,0.9884713888168335
138454615,3765,junrao,2017-09-12T20:19:12Z,"hmm, there is a bit of inconsistency here in how we deal with exceptions from zk calls. in general, it seems that exceptions (e.g. authorization error, session closed, etc) are not retriable. so, we probably should return them in a failed partition map as what we do in getlogconfigs().",0,0.8793037533760071
138478606,3765,junrao,2017-09-12T22:03:50Z,"i think we can simplify this logic a bit. badversion can happen because of updates from another client (e.g., leader) or retries from a connection loss. technically, for the latter, we can do a read and avoid updating the path again if the new value is already in place. however, it seems that it's simpler to just return any partition with badversion as updatestoretry and the let the caller retry. the caller already has the logic to read the latest value from zk on retry. since connection loss is rare, doing an extra write when it happens is probably ok.",0,0.9859970808029175
138480660,3765,junrao,2017-09-12T22:14:37Z,"hmm, it seems any other error is not really retriable and should be returned in a failed partition map.",0,0.6963768005371094
138489383,3765,junrao,2017-09-12T23:09:11Z,"""controller %d epoch %d initiated state change for partition %s from %s to %s failed"" => ""controller %d epoch %d failed to change state for partition %s from %s to %s"" ?",0,0.9921414852142334
138490985,3765,junrao,2017-09-12T23:20:44Z,"hmm, it seems the convention should be that any exception is a non-retriable error and we will just log an error on those partitions, and then move on w/o retry.",0,0.9598007798194885
138495827,3765,junrao,2017-09-12T23:55:43Z,"we want to pick the preferred replica if possible. isr in general is not ordered. so, we want to go through assigned_replicas in order as controlledshutdownleaderselector does.",0,0.9862169027328491
138496088,3765,junrao,2017-09-12T23:57:37Z,would the code be easier to read if we just return failed partitions to electleaderforpartitions() and log the error there?,0,0.9935539960861206
138499176,3765,junrao,2017-09-13T00:23:11Z,same comment here. would the code be easier to read if we just return failed partitions to removereplicasfromisr() and log the error there?,0,0.9938668608665466
138501599,3765,junrao,2017-09-13T00:46:26Z,it's a bit inconsistent to return currentleaderandisrs since it includes candidateleaderandisrs. it seems it's easier to understand if we return 4 disjoint sets. the first two parts could then be named partitionswithoutreplicainisr and partitionswithreplicainisr,0,0.9068431258201599
138502217,3765,junrao,2017-09-13T00:52:27Z,it seems that we should extract the topic set before passing into kafkacontrollerzkutils.getlogconfigs()?,0,0.9956753849983215
138502301,3765,junrao,2017-09-13T00:53:17Z,could topics be a set?,0,0.9920456409454346
138505415,3765,junrao,2017-09-13T01:22:10Z,"the method name is a bit confusing. it sounds like that we are just reading the partition state from zk, but we actually also remove the isr here. so, we probably want to use a more accurate method name. also, would it be better to change the isr in leaderandisrbasedonlogconfigs() instead of here?",0,0.5274125337600708
138505545,3765,junrao,2017-09-13T01:23:35Z,"hmm, do we need those wrappers? could be just change controllerevent directly?",0,0.9584177732467651
138675875,3765,onurkaraman,2017-09-13T16:46:26Z,"anything with a v2 suffix is just temporary. it's there to make the diff easier to read. once we agree on the changes, i'll remove the suffix and make the new code replace the old.",0,0.9894507527351379
138677309,3765,onurkaraman,2017-09-13T16:52:16Z,this had also crossed my mind but decided to just try to replicate existing behavior in the first pass. however i agree that doing so simplifies the logic here quite a bit and agree that the change should be made in this pr.,0,0.9659314751625061
138684045,3765,onurkaraman,2017-09-13T17:20:35Z,"the behavior in the pr just tries to imitate `zkutils.conditionalupdatepersistentpath` which marks the update success as false when it receives any exception other than badversion. `zkutils.conditionalupdatepersistentpath` is called by `replicationutils.updateleaderandisr` which is called by `kafkacontroller.removereplicafromisr`. that update success value is what determines if we should retry in the while loop of `kafkacontroller.removereplicafromisr`. that being said, the existing behavior isn't necessarily right.",0,0.9941868782043457
138807407,3765,onurkaraman,2017-09-14T06:35:39Z,suppose we collect all failed partitions and return it to `electleaderforpartitions`. how will `electleaderforpartitions` log relevant information? i think you'd basically have to return error messages or exceptions back to `electleaderforpartitions`. so the end result would just consolidate all the calls to `logfailedstatechange` into one place. is this what you had in mind?,0,0.9909909963607788
139002874,3765,junrao,2017-09-14T20:28:40Z,"yes, i was thinking of returning partition -> error_code map to the caller.",0,0.980465292930603
139269156,3765,junrao,2017-09-15T23:39:22Z,should we do that in every test?,0,0.9912015199661255
139270862,3765,junrao,2017-09-16T00:01:44Z,"it will be useful to add a test for the controlled shutdown case, which involves setting controllercontext.shuttingdownbrokerids and making the state transition to online.",0,0.9921191930770874
139271124,3765,junrao,2017-09-16T00:05:51Z,could we consolidate all the logfailedstatechange() calls here?,0,0.9943464398384094
139271360,3765,junrao,2017-09-16T00:08:47Z,could this be private?,0,0.9903441071510315
139271478,3765,junrao,2017-09-16T00:10:43Z,could we add a comment on the return value?,0,0.9903683662414551
139271708,3765,junrao,2017-09-16T00:14:25Z,it seems that we should return failedupdates to the caller so that we can log the error.,0,0.987649142742157
139272320,3765,junrao,2017-09-16T00:25:57Z,could we consolidate all the logfailedstatechange() calls here?,0,0.9943464398384094
139272482,3765,junrao,2017-09-16T00:29:45Z,"hmm, not sure that i really understand this comment. also, could we document the return value?",0,0.5321264863014221
139273133,3765,junrao,2017-09-16T00:43:56Z,"i think this part of the logic could be simplified a bit from the original implementation. if isr only contains replicaid, it seems that we can just always leave the last replica in isr independent of the uncleanleaderelection config. this is because the leader will be set to noleader. so, no new data could be written to this partition and replicaid will remain in sync.",0,0.9923215508460999
139273316,3765,junrao,2017-09-16T00:48:15Z,leaderandisrs.keys.map(_.topic).toseq => leaderandisrs.keys.map(_.topic).toset ?,0,0.991564154624939
139298824,3765,onurkaraman,2017-09-17T00:54:22Z,"it doesn't seem like we should relax the easymock strictness in general. i only had to do it because i had issues specifying expectations on some scala methods with defaults (specifically, the isnew param for `mockcontrollerbrokerrequestbatch.addleaderandisrrequestforbrokers`).",0,0.9818940758705139
139298830,3765,onurkaraman,2017-09-17T00:55:08Z,your above earlier comment suggests we can get rid of this method entirely. so problem solved!,1,0.8400076627731323
139298835,3765,onurkaraman,2017-09-17T00:55:31Z,done.,0,0.9640594124794006
139298837,3765,onurkaraman,2017-09-17T00:55:38Z,agreed.,0,0.9005043506622314
139298838,3765,onurkaraman,2017-09-17T00:55:46Z,done.,0,0.9640594124794006
139298862,3765,onurkaraman,2017-09-17T00:56:46Z,done.,0,0.9640594124794006
139298884,3765,onurkaraman,2017-09-17T00:58:58Z,"this ends up getting surprisingly ugly due to the option[int] return values of `partitionleaderelectionalgorithms` as well as the leader election helper methods, specifically `leaderforoffline` which also does its own logging.",-1,0.6499109268188477
139298901,3765,onurkaraman,2017-09-17T01:00:52Z,i agree that it should be logged. it's just a bit tricky to cleanly consolidate all of the logging in partitionstatemachinev2. i'll give it another try in a follow-up update to this pr.,0,0.9230088591575623
139299269,3765,onurkaraman,2017-09-17T01:37:07Z,done.,0,0.9640594124794006
139316087,3765,junrao,2017-09-17T17:20:41Z,"structure-wise, it's probably better to do line 234 to 238 in electleaderforpartitions()?",0,0.9951345324516296
139316113,3765,junrao,2017-09-17T17:22:09Z,could we add a comment on what will fail if this is not added?,0,0.9910231828689575
139317183,3765,onurkaraman,2017-09-17T18:07:56Z,"we could, but in doing so, we'd have to return more state to `electleaderforpartitions`. currently, `doelectleaderforpartitions` returns `(seq[topicandpartition], seq[topicandpartition], map[topicandpartition, exception])` where the successes are just that first `seq[topicandpartition]`. if we delegate the work to `electleaderforpartitions`, we'd have to pass back not only the successful partitions, but their leaderandisr as well as the intended recipients of that partition's share of leaderandisrrequest. the code could end up messier as a result.",0,0.9930839538574219
139318096,3765,onurkaraman,2017-09-17T18:48:30Z,"sure. alternatively, one option is to just get rid of scala default arguments in controllerbrokerrequestbatch. if we actually want to keep something resembling default arguments, we can just do it the java way. split the methods with default arguments into two: 1. one with all of the arguments 2. one without the default argument that fills in the default value for the user. i'm fine with either commenting why or converting to java-style default arguments.",0,0.9697484374046326
139323536,3765,junrao,2017-09-17T22:57:40Z,"ok, we can leave it as it is then.",0,0.9876459240913391
139323553,3765,junrao,2017-09-17T22:58:00Z,perhaps we can just do 2?,0,0.9920333027839661
140394457,3765,junrao,2017-09-22T01:14:39Z,"could we change p to case (tp, _) to get rid of ._1 for better readability? ditto in a few other places.",0,0.9934272766113281
140394568,3765,junrao,2017-09-22T01:15:53Z,this comment is probably not longer valid?,0,0.9013988375663757
140394943,3765,junrao,2017-09-22T01:19:44Z,could we explicitly define the return type for all methods in the class?,0,0.9934248924255371
143092927,3765,junrao,2017-10-06T01:14:59Z,"it's possible that the controllereventthread has just taken an event out of the queue before eventmanager.clearandput(expire) is called. so, it seems that we need to wait for controllereventthread to return back to idle state before creating a new zk session. otherwise, controllereventthread may use the newly create zk session to process an event that happens before the session expiration.",0,0.9888113737106323
143096688,3765,junrao,2017-10-06T01:57:13Z,perhaps it's better to close kafkacontrollerzkutils before shutting down the controller to avoid it blocked on any zk operation.,0,0.9918711185455322
143225895,3765,junrao,2017-10-06T15:47:52Z,"hmm, not sure that we really need to read the controllerid from zk again. it seems that we could just always set activecontrollerid to -1, call oncontrollerresignation(), and then call elect.",0,0.8184321522712708
143226529,3765,junrao,2017-10-06T15:50:36Z,i am wondering if we could just remove line 1242 to 1251 and alway try to create the controller path in zk.,0,0.983643114566803
143230568,3765,junrao,2017-10-06T16:07:42Z,unused import org.i0itec.zkclient.izkstatelistener and org.apache.zookeeper.watcher.event.keeperstate,0,0.9948262572288513
143231117,3765,junrao,2017-10-06T16:10:22Z,"over time, other components will be using this class, should we name this sth more general that's not tied to controller?",0,0.9877069592475891
143232047,3765,junrao,2017-10-06T16:14:59Z,this line seems unnecessary since it's done in the previous line.,0,0.9784412980079651
143232631,3765,junrao,2017-10-06T16:17:57Z,could replicastatemachine.handlestatechanges() take a set of replicas instead of a sequence?,0,0.9945928454399109
143234078,3765,junrao,2017-10-06T16:24:49Z,we probably don't intent to check code.ok again?,0,0.9673040509223938
143237031,3765,junrao,2017-10-06T16:38:57Z,"it's possible that the controller is still working on an event when expire() is called. in this case, it seems that we want to wait until the controller returns to idle state before we create a new zk session. otherwise, the controller may process an old event using the new session.",0,0.9806073904037476
143255144,3765,onurkaraman,2017-10-06T17:47:49Z,good catch. this must've been some leftover code while refactoring.,1,0.9574999213218689
143255167,3765,onurkaraman,2017-10-06T17:47:57Z,good catch.,1,0.9815194606781006
143262946,3765,junrao,2017-10-06T18:22:32Z,controllerstate.topicchange is incorrect.,0,0.5635056495666504
143263715,3765,junrao,2017-10-06T18:26:03Z,is v2 needed?,0,0.9932981133460999
143292558,3765,junrao,2017-10-06T20:56:33Z,is v2 needed?,0,0.9932981133460999
143316120,3765,onurkaraman,2017-10-07T00:20:06Z,"from an offline discussion, i think we agreed to leave this logic as is and change it in a later patch.",0,0.9832136631011963
143316125,3765,onurkaraman,2017-10-07T00:20:11Z,"from an offline discussion, i think we agreed to leave this logic as is and change it in a later patch.",0,0.9832136631011963
143318695,3765,onurkaraman,2017-10-07T01:17:23Z,good catch.,1,0.9815194606781006
143318696,3765,onurkaraman,2017-10-07T01:17:26Z,good catch.,1,0.9815194606781006
143318830,3765,onurkaraman,2017-10-07T01:21:51Z,"that's the current behavior and i think it's right. partitionmodifications is the event used for adding partitions to a topic. if you look at the other controllerstate states, it's the most accurate option.",0,0.9625318050384521
143319274,3765,onurkaraman,2017-10-07T01:38:52Z,"i was hoping to do a later ""cleanup"" pr that would contain: 1. renaming kafkacontrollerzkutils 2. removing state change logger entirely 3. doing your above suggestion of removing the ith tuple element notation ex: x._1",0,0.9880465269088745
143598970,3765,junrao,2017-10-09T23:14:27Z,"instead of exposing countdownlatch directly, perhaps it's better to add a waituntilprocessed() method in expireevent and call countdownlatch.await() there?",0,0.9950957298278809
143601978,3765,junrao,2017-10-09T23:38:37Z,i am not sure why replicas needs to be a seq instead of a set. it seems that all callers are converting a set to a seq.,0,0.6203734278678894
143604811,3765,junrao,2017-10-10T00:03:03Z,could we use case inside map to avoid unnamed reference _._2? ditto in the line below.,0,0.9940662384033203
143605920,3765,junrao,2017-10-10T00:12:17Z,"this matches the existing code. however, in this case, it seems that we probably want to throw an exception instead of proceeding w/o a new controller epoch.",0,0.9861499071121216
143607644,3765,junrao,2017-10-10T00:28:05Z,should we just pass the locally created brokerrequestbatch to both the replicastatemachine and partitionstatemachine?,0,0.9956631064414978
143611081,3765,junrao,2017-10-10T01:01:22Z,"this will be called when a topic is deleted. so, we probably want to make this a no-op instead of throwing an exception.",0,0.9913010001182556
143611266,3765,junrao,2017-10-10T01:03:36Z,"this will be called when the partition reassignment completes. so, we probably want to make this a no-op instead of throwing an exception.",0,0.991569459438324
143611398,3765,junrao,2017-10-10T01:04:56Z,"this will be called when the preferred leader election completes. so, we probably want to make this a no-op instead of throwing an exception.",0,0.9912070631980896
143612243,3765,junrao,2017-10-10T01:14:49Z,could we use case inside filter to avoid unnamed reference p._2?,0,0.9955411553382874
143612493,3765,junrao,2017-10-10T01:17:19Z,could we use case inside partition to avoid unnamed reference _._2? there are a few other places like that.,0,0.9928748607635498
143612617,3765,junrao,2017-10-10T01:18:49Z,it seems that failedupdates.tomap can just be failedupdates.,0,0.9503362774848938
143612849,3765,junrao,2017-10-10T01:21:12Z,could we use case to avoid unnamed reference _._2? there are a few other places like that in this file.,0,0.994478702545166
143613461,3765,junrao,2017-10-10T01:28:23Z,"could we explicitly define the return type in this and the following private method? otherwise, it's a bit hard to follow the logic.",0,0.6766536831855774
143613534,3765,junrao,2017-10-10T01:29:06Z,"the class is a bit harder to read now with the new zk wrapper. to make that a bit easier, could we add a comment to describe the return type and this method does? it may be worth doing that on a few other methods in this class as well.",0,0.985237181186676
143614244,3765,junrao,2017-10-10T01:37:17Z,add a new line above. could we explicitly define the return type of this method?,0,0.9888900518417358
143614282,3765,junrao,2017-10-10T01:37:44Z,could we explicitly define the return type explicitly of this method and describe a bit the return type and the method? ditto for the method below.,0,0.9893233180046082
143614860,3765,junrao,2017-10-10T01:44:35Z,could we add a comment to describe the return value?,0,0.989915132522583
143614998,3765,junrao,2017-10-10T01:46:20Z,could we add a comment to describe the return value?,0,0.989915132522583
143615041,3765,junrao,2017-10-10T01:46:52Z,could we explicitly specify the return type of this method?,0,0.9921154379844666
143615065,3765,junrao,2017-10-10T01:47:09Z,could we explicitly specify the return type of this method?,0,0.9921154379844666
143615317,3765,junrao,2017-10-10T01:50:48Z,"we probably want to wait for zookeeperclient to be connected within the connection timeout. otherwise, fail the restart of the broker.",0,0.9873588681221008
143621204,3765,onurkaraman,2017-10-10T03:04:22Z,sounds good. i'll make the change.,1,0.8403770327568054
143864242,3765,onurkaraman,2017-10-10T21:59:18Z,this is definitely something i've had in mind for a while now and i've mentioned it in the redesign doc. we agreed offline to do this change in a follow-up patch to minimize regressions.,0,0.9822131395339966
143867505,3765,onurkaraman,2017-10-10T22:16:03Z,"that's not quite right. topicdeletionmanager's `completedeletetopic` first unregisters the partitionmodificationshandler before deleting the topic znode. in addition to looking at the code, i did a topic deletion and didn't find any errors in any of the logs. i think there are 3 options here: 1. change unimplemented methods to be no-ops on a case-by-case basis. 2. change all of the controller's unimplemented handle methods to be no-ops. 3. change the traits themselves to make these methods no-ops by default. you'd only override if you need to. i am leaning towards option 3 since it'll make the code more concise but am okay with any option.",0,0.9858420491218567
143869274,3765,onurkaraman,2017-10-10T22:25:19Z,that's a good point. see my above comment describing several ways we can address this.,1,0.8164002299308777
143870540,3765,onurkaraman,2017-10-10T22:32:38Z,that's a good point. see my above comment describing several ways we can address this.,1,0.8164002299308777
143871821,3765,junrao,2017-10-10T22:39:53Z,"option 3 sounds reasonable. the thing with unregistering a watcher is that it only gets reflected during the next read. so, it may not happen immediately.",0,0.9825319051742554
143880980,3765,onurkaraman,2017-10-10T23:42:31Z,"watches are tricky with zookeeper. the key point is that zookeeperclient handler unregistration is not the same thing as watcher removal. prior to zookeeper 3.5, there actually [a link]. watchers can only get removed after they get triggered. however, from the zookeeperclient's perspective, handler unregistration is local and immediate. it's possible for the zookeeper ensemble to send you a notification for a watcher after you've unregistered that watcher's corresponding handler, but it won't have any effect. zookeeperclient maintains local mappings from paths to registered handlers and updates these mappings immediately upon handler registration and unregistration. when zookeeperclient receives a watcher notification, its zookeeperclientwatcher first looks up a handler in its local mappings and only if one exists does it actually trigger the corresponding handle method.",0,0.9798187017440796
143885696,3765,junrao,2017-10-11T00:17:20Z,"ok, then, it's probably covered in this case.",0,0.9838782548904419
143898041,3765,onurkaraman,2017-10-11T02:18:37Z,"this is already exactly what happens. the zookeeperclient constructor calls `waituntilconnected(connectiontimeoutms, timeunit.milliseconds)`.",0,0.9938305020332336
143908207,3765,onurkaraman,2017-10-11T04:07:48Z,made the change in the latest update.,0,0.9837439656257629
144068415,3765,junrao,2017-10-11T16:43:53Z,it seems this should really be called onreconnectiontimeout?,0,0.9853315353393555
144133096,3765,junrao,2017-10-11T20:54:11Z,i am not sure if we need to explicitly have this callback. it seems that this can just be fold into the logic of waiting for the connection to be ready during initial connect and reconnect?,0,0.9378372430801392
144136815,3765,junrao,2017-10-11T21:08:57Z,we probably want to mention that the new leaders will be written to zk.,0,0.9888548254966736
144136971,3765,junrao,2017-10-11T21:09:28Z,identation,0,0.8915899395942688
144150290,3765,junrao,2017-10-11T22:13:41Z,this is redundant given what's in line 115.,0,0.9457749724388123
144151962,3765,junrao,2017-10-11T22:23:45Z,we probably want to document that new isr will be written to zk.,0,0.991287887096405
144160128,3765,onurkaraman,2017-10-11T23:12:25Z,that indentation's actually what intellij suggested to me.,0,0.974230945110321
144165799,3765,junrao,2017-10-11T23:54:29Z,this seems unnecessary since we log in the first statement in replicastatemachine.startup() already.,0,0.9915426969528198
144165817,3765,junrao,2017-10-11T23:54:44Z,this seems unnecessary since we log in the first statement in partitionstatemachine.startup() already.,0,0.9914320707321167
144177295,3765,onurkaraman,2017-10-12T01:41:48Z,done.,0,0.9640594124794006
144177305,3765,onurkaraman,2017-10-12T01:41:53Z,done.,0,0.9640594124794006
144482045,3765,onurkaraman,2017-10-13T07:27:27Z,"`statechangehandler.onauthfailure` only gets used in our zookeeperclient's custom zookeeperclientwatcher: [code block] `statechangehandler.onauthfailure` would only get called when the raw zookeeper client transitioned from the connecting state to the auth_failed state as shown in the state transition diagram below: [a link] there are three scenarios that could have caused you to be in the connecting state in the first place: 1. initial zookeeperclient instantiation 2. transient disconnect from the zookeeper ensemble 3. zookeeperclientwatcher initializing a new session after session expiration if you get rid of `statechangehandler.onauthfailure`, then only 1 and 3 will react to the auth failure on their own: * for scenario 1, assuming you want to keep the thrown zookeeperclientauthfailedexception, then 1 will throw that exception in waituntilconnected. * for scenario 3, eventually the connection timeout will be hit and the `statechangehandler.onconnectiontimeout` will get called. * however for scenario 2, without `statechangehandler.onauthfailure`, a reaction to the auth failure for 2 can only occur if the user calls waituntilconnected or if they observe the return code from any requests that were in-flight or sent after the auth failure. so you now risk a scenario where the application is just sitting around indefinitely with a client in the auth_failed state.",0,0.9951186180114746
144585764,3765,ijuma,2017-10-13T15:29:17Z,"out of curiosity, what is the reasoning for the `listener` -> `handler` rename?",0,0.9881072044372559
144588126,3765,ijuma,2017-10-13T15:38:31Z,"btw, there are some really long lines in this pr. our convention is that lines should not be longer than the github review window.",0,0.8686147928237915
144624196,3765,junrao,2017-10-13T18:18:07Z,"hmm, in case 2, wouldn't the zk session expire eventually?",0,0.9854389429092407
144668085,3765,junrao,2017-10-13T22:18:38Z,"we probably want to delete the log dir event first and then register the handler. otherwise, we may be processing those events triggered by deletion unnecessarily. ditto for deleteisrchange.",0,0.9052109718322754
144669429,3765,junrao,2017-10-13T22:29:17Z,it seems that it's better to batch the call to handlestatechanges across all replicas like before?,0,0.9943061470985413
144669526,3765,junrao,2017-10-13T22:30:08Z,"we only need to do this on newtopics, right?",0,0.9859166741371155
144676732,3765,onurkaraman,2017-10-13T23:42:37Z,good catch.,1,0.9815194606781006
144677353,3765,onurkaraman,2017-10-13T23:50:05Z,done.,0,0.9640594124794006
144680808,3765,onurkaraman,2017-10-14T00:45:15Z,"the diagram seems to indicate that you can either hit auth failure or session expiration, but not both.",0,0.9881097078323364
144681072,3765,junrao,2017-10-14T00:51:03Z,"hmm, that could be true. perhaps we could keep it and just log an error for now.",0,0.9620293378829956
144681238,3765,onurkaraman,2017-10-14T00:54:51Z,"1. it's more concise. 2. it's also easier to read and verbalize, for me at least. 3. it let me keep both version of the classes side-by-side as a reference. 4. they pretty much mean the same thing in programming.",0,0.9433578848838806
145007795,3765,junrao,2017-10-17T01:13:16Z,instead of duplicating the comment. we could just refer it to the one in handle(requests: seq[asyncrequest])?,0,0.9948270916938782
145007985,3765,junrao,2017-10-17T01:15:05Z,"registerznodechildchangehandler(znodechildchangehandler: znodechildchangehandler) calls this method. so, it's better to put the detailed comments here and let the former refer it here.",0,0.992594301700592
145008953,3765,junrao,2017-10-17T01:26:05Z,"it seems that in all state transitions, it's useful to know the assigned replica list, the leader and the isr. perhaps, we can just do a generic logging at the end of the method?",0,0.9907419085502625
145010777,3765,junrao,2017-10-17T01:44:39Z,i had a comment on this before. should onconnectiontimeout() be onreconnectiontimeout?,0,0.9805251955986023
145206369,3765,junrao,2017-10-17T17:57:40Z,could we explicitly define the return type of this method?,0,0.9920564293861389
145206447,3765,junrao,2017-10-17T17:57:56Z,could we explicitly define the return type of this method?,0,0.9920564293861389
145212540,3765,onurkaraman,2017-10-17T18:19:03Z,"now that we've decoupled handler registration from watcher registration, there's really no benefit to having `registerznodechangehandlers` and `registerznodechildchangehandlers` since these are now purely local operations and equivalent to registering one-at-a-time. i'm going to remove these methods.",0,0.9793244004249573
145215526,3765,onurkaraman,2017-10-17T18:29:16Z,"hmm not sure if this would actually work. some of these concepts don't even exist in certain states. - newpartition has no leader or isr. - nonexistentpartition has no replicas, leader, or isr.",0,0.6349490284919739
145215623,3765,onurkaraman,2017-10-17T18:29:38Z,sure.,0,0.9664214849472046
145215655,3765,onurkaraman,2017-10-17T18:29:47Z,makes sense.,0,0.9811486601829529
145227489,3765,junrao,2017-10-17T19:12:45Z,"ok. maybe in the case where we transition to onlinepartition, we can just log the whole leaderandisr instead of just the leader.",0,0.9921776652336121
145250912,3765,onurkaraman,2017-10-17T20:45:25Z,done,0,0.8974218964576721
145250947,3765,onurkaraman,2017-10-17T20:45:34Z,done.,0,0.9640594124794006
145250967,3765,onurkaraman,2017-10-17T20:45:40Z,done.,0,0.9640594124794006
145483014,3765,tedyu,2017-10-18T17:20:24Z,dowork() doesn't use putlock. is it possible that an event retrieved by dowork() is supposed to be cleared by this call ?,0,0.9885057210922241
145488953,3765,tedyu,2017-10-18T17:42:14Z,updatestoretry is not used.,0,0.9758715033531189
145489072,3765,tedyu,2017-10-18T17:42:39Z,partitionsleadbybroker -> partitionsledbybroker,0,0.9932394027709961
145664130,3765,ijuma,2017-10-19T10:46:03Z,"i think it's a good point that we should document the expected behaviour even if there's no bug. , can we please do that in a follow-up?",0,0.8203306198120117
145664835,3765,ijuma,2017-10-19T10:49:39Z,fixed in [a link],0,0.9866787791252136
145664852,3765,ijuma,2017-10-19T10:49:45Z,fixed in [a link],0,0.9866787791252136
145820562,3765,junrao,2017-10-19T20:52:58Z,"the purpose of putlock is to make sure no other callers can put anything to the queue in the middle of a clearandput() call. it's ok for a reader to have taken an event out of the queue just before the queue is cleared since in kafkacontroller.expire(), we wait until the last event in the queue is processed before creating a new zk session. we can probably document this to make it clear.",0,0.9938278794288635
1104737066,13240,Hangleton,2023-02-13T16:38:01Z,"the sequence of validation chosen here reflects what is used on the fetch request path: - if topic ids are used and the given topic id cannot be resolved (and no fallback name is provided), send back `unknown_topic_id`; - if the topic name is valid but that name is not authorized, send `topic_authorization_failed`; - if the topic name is authorized but not present in the metadata cache (in which case, that topic will not have been resolved via its id because in this case, we expect it to be in the cache), send `unknown_topic_or_partition`.",0,0.9953262805938721
1104738082,13240,Hangleton,2023-02-13T16:38:36Z,note: topic id must not be null for a request/response version >= 9 to be serialized. `zero_uuid` means no topic id specified.,0,0.9943300485610962
1104738961,13240,Hangleton,2023-02-13T16:39:12Z,note: topic id must not be null for a request/response version >= 9 to be serialized. `zero_uuid` means no topic id specified.,0,0.9943300485610962
1104740902,13240,Hangleton,2023-02-13T16:40:29Z,"note 1: if the `topicname` is not null, we should also check if it resolves to the same uuid as we have cached locally.",0,0.9939960241317749
1104760648,13240,Hangleton,2023-02-13T16:53:38Z,note 2: we could fail partially - just for the given topic entry - rather than the entire response.,0,0.9798989295959473
1105846605,13240,dajac,2023-02-14T13:48:17Z,"there is very likely a bug here. in this case, `topic.name` is `null` and the response builder uses a hashmap keyed by topic name. therefore, all the topics with an unknown topic id will end up together.",0,0.9588602185249329
1105854122,13240,dajac,2023-02-14T13:54:34Z,"we are calling `resolvetopicname` three times. i think that it would be better to iterate once over the topics to resolve the topic ids and build the list of topic names (if one was found) while doing this. then, we can check the authorization and do the rest.",0,0.9908762574195862
1105855843,13240,dajac,2023-02-14T13:55:54Z,i suppose that this check is not necessary if we are using topic ids. we already know that the name resolved based on the topic id is valid.,0,0.9891710877418518
1105985661,13240,Hangleton,2023-02-14T15:31:23Z,"apologies, you are right. this hints that perhaps we should reconstruct the list of `offsetcommitrequesttopic` and use it internally to avoid any such mistake?",0,0.9884594082832336
1105987099,13240,Hangleton,2023-02-14T15:32:31Z,"you are right, yes. let's make this explicit in the code.",0,0.8357903361320496
1106229439,13240,Hangleton,2023-02-14T18:36:47Z,"i replaced this approach with a single iteration over the list of topic data, resolving and populating the topic name in place (line 455). i am concerned though because this involved mutating the request's body. but i am also concerned about the cost of creating a new arraybuffer, sequence or another data structure to pre-filter. without falling into premature optimization, what do you think about in-place mutation? i think the problem here is that we have the instantiation of the `offsetcommitrequest` decoupled from the resolution of topic ids. it makes sense since the former corresponds to the request deserialization while the latter corresponds to added semantics unconveyed by the request itself. in responsibility chains on server request handlers, one pattern sometimes adopted is to decorate a request with extraneous information which fall beyond the scope of ser/de. i wonder if topic id resolution could happen before passing it to the business request handler.",0,0.9824827909469604
1113132735,13240,dajac,2023-02-21T14:21:42Z,nit: we probably don't need to duplicate `data` here. i understand why you are doing it but in practice we assume that `data` is owned by the builder once it is given to it.,0,0.9785726070404053
1113142734,13240,dajac,2023-02-21T14:29:30Z,nit: invalidrequestexception would be more appropriate.,0,0.8485154509544373
1113146018,13240,dajac,2023-02-21T14:32:07Z,i just realized that this is only used in tests. i wonder if we should just get rid of it and use the auto-generated classes in tests as well.,0,0.9696924686431885
1113149061,13240,dajac,2023-02-21T14:34:29Z,nit: you could replace this by the following: [code block],0,0.9890433549880981
1113151869,13240,dajac,2023-02-21T14:36:46Z,nit: ditto.,-1,0.9302301406860352
1113153482,13240,dajac,2023-02-21T14:37:59Z,nit: we could remove this empty line.,0,0.9825745224952698
1113156030,13240,dajac,2023-02-21T14:39:58Z,"i think that there is a bug here for the case where multiple topic ids are unknown in a single request. for those, the topic name will be null so they will be aggregated in the same offsetcommitresponsetopic and that one will have the topic id of the first unknown topic id seen.",0,0.9806864857673645
1113156632,13240,dajac,2023-02-21T14:40:25Z,nit: i think that we could remove this comment. it does not bring much.,0,0.9217546582221985
1113157135,13240,dajac,2023-02-21T14:40:49Z,the kip also specifies new errors for this version. could we mention them here?,0,0.991058886051178
1113160687,13240,dajac,2023-02-21T14:43:33Z,"at l1361 in this file, we construct `topicpartition` based on the response data but we don't resolve the topic id. i think that we should add the resolution there as well, no? we probably need to extend tests to better cover this as well. regarding `unknown_topic_id`, would it make sense to place it after `unknown_topic_or_partition` as they are quite similar?",0,0.9934501051902771
1113164928,13240,dajac,2023-02-21T14:46:18Z,"i would prefer to inline `resolvetopicname` and avoid allocating an `option` which does not bring much here. in the mean time, i would directly construct the list of topic names for the authorizer at l461. this way, we could save re-iterating over the topics and the `filter`. what do you think? moreover, the kip states that an `invalid_request` should be return if both a topic id and a topic name are provided. we could also handle this here.",0,0.9926264882087708
1113175049,13240,dajac,2023-02-21T14:52:56Z,"this issue is still present. yeah, we definitely need to update the response builder to support this. one way would be to change the semantic of `addpartitions` to directly add to the response when it is called and to only put the topic in the hashmap when `addpartition` is used.",0,0.9836152195930481
1113176828,13240,dajac,2023-02-21T14:54:08Z,it would be great if we could extend the tests here. i think that we need to use multiple unresolvable topic ids in the same request and also check the different versions. i am not sure if we could extend this one or if we should add other ones.,0,0.9663870930671692
1113178848,13240,dajac,2023-02-21T14:55:25Z,"what's the reason for this change? if we refactor this, it may be better to directly go with the auto-generated data structures.",0,0.9889670014381409
1113183283,13240,dajac,2023-02-21T14:58:39Z,we also need tests to check if the response is handled correctly.,0,0.991557240486145
1113220631,13240,dajac,2023-02-21T15:26:05Z,nit: could we add `.` at the end?,0,0.9939374923706055
1113220793,13240,dajac,2023-02-21T15:26:12Z,nit: could we add `.` at the end?,0,0.9939374923706055
1116196039,13240,Hangleton,2023-02-23T20:10:09Z,"sure, i used the auto-generated class in the unit test for the `offsetcommitrequest`. i moved this method to the unit test class as it is used from other unit tests in for the consumer coordinator, from where using the full-fledged request object would be less convenient.",0,0.9938576817512512
1116198012,13240,Hangleton,2023-02-23T20:12:23Z,"you are right, thanks for finding this bug (again!). i followed the approach you suggest here in the builder of the `offsetcommitresponse`, please let me know if the semantics make sense.",1,0.763139009475708
1116200049,13240,Hangleton,2023-02-23T20:14:13Z,"that is right, thanks for pointing out. the resolution of topic name has been added to the response handler. if the topic is not defined, or the response topic is invalid because it contains neither an id or name, or contains both, that topic is ignored. the offset commit invocation is however not failed.",1,0.6746116876602173
1116202452,13240,Hangleton,2023-02-23T20:16:23Z,"thanks, i built the list of resolved topics and pass it to the authorizer, inlining name resolution. if a topic has both a name and id defined, the broker fails fast the request and returns an `invalid_request`. is this what you had in mind? should we send more information to the client in that case?",0,0.9622000455856323
1116203414,13240,Hangleton,2023-02-23T20:17:14Z,"sure, i added another unresolvable topic to the request/response. i will add more cases covering more of the possible code paths.",0,0.98929762840271
1116204122,13240,Hangleton,2023-02-23T20:17:54Z,"sure, i reverted this refactoring and use the response class instead.",0,0.9887545108795166
1116205901,13240,Hangleton,2023-02-23T20:19:26Z,"that is right, i added tests which invoke the sync and async offset commit method.",0,0.9832730293273926
1119248386,13240,dajac,2023-02-27T19:58:06Z,"i discussed offline with a few committers and the consensus is that having both the topic name and the topic id in the same version is not the right way. they share the same concerns that we discussed last week. could you update the pr to only have topicid from version 9? we can also remove the nullableversions for the name and set the versions to 0-8. i suppose that both fields could be ignorable. regarding the admin client, which does not support topic ids, it cannot use version 9 at the moment. we need to handle this in the builder (we can set the maximum allowed version). sorry for this late change.",0,0.983530580997467
1119798298,13240,Hangleton,2023-02-28T09:40:06Z,"hi david, thanks for the follow-up and clarifying. this is all good, i am working on adapting the pr. thanks!",1,0.9959515333175659
1121486904,13240,dajac,2023-03-01T10:29:55Z,"now that we can rely on the version, we should use it here and simplify all this logic.",0,0.9825252294540405
1121487731,13240,dajac,2023-03-01T10:30:29Z,it would be better to rely on the version of the request instead of the topic name here.,0,0.9908326268196106
1121488495,13240,dajac,2023-03-01T10:31:00Z,i would move this up and do it in the first iteration.,0,0.9840217232704163
1121489116,13240,dajac,2023-03-01T10:31:23Z,you could use `resolvedtopics` instead of `offsetcommitrequest.data.topics` here.,0,0.9951096177101135
1121494379,13240,dajac,2023-03-01T10:35:07Z,i think that we could remove those checks now.,0,0.9637105464935303
1121496085,13240,dajac,2023-03-01T10:36:34Z,i think that we could just set both the name and the id all the time as the fields are ignorable. the serialization framework will do the right thing based on the version. we could also remove `version` from the arguments.,0,0.9923332929611206
1121499577,13240,dajac,2023-03-01T10:39:12Z,we could get this in the base class and always set both of them. the serialization framework knows what to do.,0,0.9910873770713806
1121501980,13240,dajac,2023-03-01T10:41:03Z,"is this change related to the pr? if not, i would rather do it in a separate pr.",0,0.991296648979187
1121502171,13240,dajac,2023-03-01T10:41:14Z,same question here.,0,0.9866698384284973
1121506569,13240,dajac,2023-03-01T10:44:43Z,"i am not a fan of all those attributes in test. one or two are fine if they are really re-used on all the tests. otherwise, it may be better to check define what you need in tests. i would also use `topicidpartition` when relevant so you can basically group the name, id, and partition together.",0,0.5638296008110046
1121510354,13240,dajac,2023-03-01T10:47:36Z,is this really needed?,0,0.975869357585907
1121710275,13240,Hangleton,2023-03-01T13:14:50Z,note: is this ok to break message round trip between < 9 and >= 9?,0,0.9774306416511536
1121724366,13240,Hangleton,2023-03-01T13:24:49Z,"adding the version to the response seems to be an anti-pattern as i haven't seen any other similar use in other responses. semantically it should be ok because the response instance is supposed to be built against a given version. if another approach is advisable, i will remove it.",0,0.9858091473579407
1121724819,13240,Hangleton,2023-03-01T13:25:09Z,will add javadoc.,0,0.9882354736328125
1122096890,13240,Hangleton,2023-03-01T17:33:31Z,there is still a problem here if `topicname` and `topicid` are both undefined in which case we should do what was done before and add to the response without caching.,0,0.9895304441452026
1122097709,13240,Hangleton,2023-03-01T17:34:20Z,move the `topicresolver` in the `metadatacache` or create it without copying the map of topic ids as this is costly.,0,0.9936912059783936
1122175488,13240,Hangleton,2023-03-01T18:52:25Z,"this case shouldn't be reachable because once we have proceeded with constructing the response via `addpartition` all topic ids are supposed to have been resolved successfully. here, we choose to add the topic to the response with the error code `unknown_topic_id` if no error is already set. any existing error is not overwritten.",0,0.99488765001297
1122188628,13240,Hangleton,2023-03-01T19:06:41Z,"at this point, topic ids should be always resolvable. however if some aren't, we should fallback to adding the topic ""as is"" to the response to avoid caching `zero_uuid` with risk of overwrites.",0,0.9949029684066772
1122265994,13240,Hangleton,2023-03-01T20:27:38Z,adding more tests to this class.,0,0.9846900701522827
1122271424,13240,Hangleton,2023-03-01T20:34:15Z,note - this duplicated invocation of the `builder` constructor is to allow the resolution of the parameter type as either `uuid` or `string`. not graceful but...,0,0.9658598899841309
1122830477,13240,Hangleton,2023-03-02T09:41:36Z,"thinking about it, it seems unnecessary to adopt a different classification for v >= 9 since topic names should always be resolved when calling `addpartition`. will remove all this logic and simplify.",0,0.987832248210907
1124559198,13240,Hangleton,2023-03-03T14:48:12Z,not strictly needed. we can remove the condition and the logger as well.,0,0.9876877665519714
1125501983,13240,dajac,2023-03-04T16:59:02Z,should we add tests to cover this new logic?,0,0.993069589138031
1125687390,13240,Hangleton,2023-03-05T15:35:04Z,sure! added the tests. thanks.,1,0.9819558262825012
1126511918,13240,Hangleton,2023-03-06T14:38:48Z,"hmm, we probably don't want to include a topic without id in the response version 9 here.",0,0.8926856517791748
1128110858,13240,dajac,2023-03-07T16:01:47Z,nit: we usually don't leave such comment in our code base.,0,0.9852260947227478
1128111731,13240,dajac,2023-03-07T16:02:18Z,nit: should we use a boolean?,0,0.9891065955162048
1128113386,13240,dajac,2023-03-07T16:03:22Z,nit: i usually prefer to use `zero_uuid.equals(...` as it is safe for null values.,0,0.9900544881820679
1128117144,13240,dajac,2023-03-07T16:05:47Z,nit: we usually don't break long lines like this. i personally prefer the following: [code block] you can find other ways in the code base.,0,0.933869481086731
1128122177,13240,dajac,2023-03-07T16:08:47Z,"is this really true? as we keep the `topicresolver` used to construct the request, all topics should be there. this case could happen if the server returns an unexpected topic id that was not in the request and that is not in the `topicresolver`. do i get this right?",0,0.9943088889122009
1128123974,13240,dajac,2023-03-07T16:09:50Z,"for my understanding, are we going to propagate this error back to the end user?",0,0.9808037877082825
1128126364,13240,dajac,2023-03-07T16:11:15Z,we don't really use those in our code base at the moment. we usually just mention those characteristics in the java doc.,0,0.9915288686752319
1128126821,13240,dajac,2023-03-07T16:11:31Z,should this be an invalidstateexception?,0,0.985365629196167
1128128673,13240,dajac,2023-03-07T16:12:33Z,i am not really happy with this name but i could not find a better one yet. my concern is that this class is really about resolving topic ids/names and not really topics per say. have you considered any alternatives?,-1,0.9394054412841797
1128130754,13240,dajac,2023-03-07T16:13:43Z,is this constructor still used?,0,0.9906550049781799
1128132186,13240,dajac,2023-03-07T16:14:32Z,"nit: when we break the line like this, we usually align the arguments on the first one. otherwise, you can use the style that i mentioned earlier.",0,0.9903832077980042
1128133377,13240,dajac,2023-03-07T16:15:16Z,nit: should we also add the other ones?,0,0.9886314272880554
1128136075,13240,dajac,2023-03-07T16:16:52Z,did you check how we did this for the fetchrequest?,0,0.9940318465232849
1128141284,13240,dajac,2023-03-07T16:19:55Z,i am not sure about passing the `topicresolver` here. my understanding is that we are doing this because topic ids are lost when we call the group coordinator. wouldn't it better to update the group coordinator to preserve those topic ids? we may be able to handle this in the groupcoordinatoradaptor or we could switch to using topicidpartitions. we could also consider doing this in a separate pr as this one is already quite large.,0,0.9757542610168457
1128148229,13240,dajac,2023-03-07T16:24:11Z,this does not look good. it would be better to place those helpers in `offsetcommitrequesttest` for instance or to keep them where they are used.,0,0.7727078795433044
1128149528,13240,dajac,2023-03-07T16:24:56Z,nit: you can omit the `()` after `topics` as we usually don't put them for getters in scala. there are a few other cases in the pr.,0,0.9930296540260315
1128151493,13240,dajac,2023-03-07T16:26:10Z,i think that there is a race condition here. you have no guarantee that both maps are consistent with each others.,0,0.8932492136955261
1128154143,13240,dajac,2023-03-07T16:27:47Z,should we just throw an illegale state exception if we end up having a topic without id? ignoring it seems to be risky.,0,0.8994867205619812
1128157560,13240,dajac,2023-03-07T16:29:43Z,i wonder if using optional is necessary here given that we always use `ornull` and `ordefault`. what do you think?,0,0.9871897101402283
1129066723,13240,dajac,2023-03-08T07:41:32Z,i had a deeper look into this and it seems that we could get the version with `this.response.requestheader().apiversion()`. could you check if this would work?,0,0.9890578389167786
1129167871,13240,Hangleton,2023-03-08T09:26:49Z,"i agree with you and am not satisfied either with `topicresolver` but could not find a better name. `topicidresolver` would be misleading because this class treats topic ids and names symmetrically. one of the closest entity with similar purposes as this is in [a link] where `topicidinfo` is used to refer to the bidirectional mapping. the suffix `info` could be used here as well although it is not strictly aligned with other uses of that suffix such as in [a link]. interestingly another entity for which may have had to be assigned a generic name is [a link]. using another name to refer to the dual name/id reference such as `topicrefresolver` introduces yet another noun (_reference_) not used elsewhere in the codebase and which can be confusing. so, i am not sure about what could be a better name but maybe `topicinforesolver` or `topicidinforesolver` or `topicidinfo` or `topicidresolver` may sound better albeit still ambiguous and partially incorrect?",0,0.9829195737838745
1129194029,13240,dajac,2023-03-08T09:51:18Z,another way would be to implement a minimal and generic bimap that we could use here. would it be an option?,0,0.9938876032829285
1129266598,13240,Hangleton,2023-03-08T11:03:53Z,"with the synchronous api in the consumer, the error is not surfaced (only `true`/`false`). however, i added the missing tests to exercise the asynchronous api for this use case, and it did expose the `unknowntopicidexception` to the user. since it violates the api contract which exclusively relies on topic names, i raised the error `unknown_topic_or_partition` when an `unknown_topic_id` is returned in the offset commit response. do you think this is sensible? i added the corresponding unit tests for the consumer coordinator.",0,0.9939507246017456
1129267206,13240,Hangleton,2023-03-08T11:04:35Z,"yes, that is right. apologies, this is a fundamental misunderstanding/overlook.",-1,0.9853775501251221
1129272424,13240,Hangleton,2023-03-08T11:10:09Z,"i would tend to have a preference for a business type which conveys semantics versus a generic data structure, but that is not very important here especially since the entity exposing the bidirectional mapping is relatively short-lived when used in the code. one advantage of a generic ds is that it can be reused for other purposes. another thing is that there is no functionality provided outside that of a bimap and since no extension is foreseen, there is no need to expose a specialized type. very happy to expose it as a bimap. i could not find an existing implementation in the codebase or its dependencies, although there is a bidirectional multimap defined within restricted scope [a link].",1,0.9651063680648804
1129283573,13240,Hangleton,2023-03-08T11:22:44Z,"it was only used in tests, so best to have it removed.",0,0.9922894835472107
1129311477,13240,Hangleton,2023-03-08T11:51:54Z,"yes, this works. thanks for the call-out.",1,0.9225396513938904
1129371713,13240,Hangleton,2023-03-08T12:41:39Z,oops...,-1,0.9654041528701782
1129407685,13240,Hangleton,2023-03-08T13:11:41Z,"yes, there is a code smell here.",-1,0.7807987928390503
1129452978,13240,Hangleton,2023-03-08T13:46:03Z,"i see what you mean. i moved this logic in the callback of the future which merges the results from the coordinator with those created by the request handling method. i thought about extending the support id in internal layers (group coordinator) in a pr of its own. so, eventually, the coordinator will return results populated with topic ids when applicable. added [a link] to track this work, if that is ok?",0,0.9772281050682068
1129482786,13240,Hangleton,2023-03-08T14:05:41Z,"modified the pr so that the server now sends an `unknown_server_error` when this happens, in the code moved to the future handler in `kafkaapis`. would this behaviour be acceptable?",0,0.9955227375030518
1129710408,13240,Hangleton,2023-03-08T16:22:25Z,maybe `topicidandnamebimap`?,0,0.9947131276130676
1130670740,13240,dajac,2023-03-09T08:54:40Z,"i actually wonder if we should do it the other way around. we could do kafka-14793 first, merge it, and update this one accordingly. without kafka-14793, the contract of the not really respected and it feels a bit weird to work around it here instead of fixing the real issue. is kafka-14793 complicated? what do you think?",-1,0.9584717750549316
1130671265,13240,dajac,2023-03-09T08:55:06Z,both names are fine for me. i leave it up to you.,0,0.9080665707588196
1130866578,13240,Hangleton,2023-03-09T11:36:23Z,"hi david, thanks for the insight. i think you are right that implementing support of topic ids in the functional layer before exposing it in the api makes sense as it provides the guarantee that offsets and metadata belong to the partitions of the right topic in case of homonyms. now, one question is how deep we go in the integration of ids in this layer. would you consider changing the data model authored by the group coordinator down to the `offsetcommitvalue ` as prescribed by kip 848?",1,0.9499096274375916
1130942769,13240,dajac,2023-03-09T12:18:21Z,the offsetcommitvalue part is not possible at the moment because we dont have a way to downgrade. my colleague works on a proposal for this. we could start by either migrating from using topicpartition to using topicidpartition or handling this in the groupcoordinatoradaptor layer. the former is likely simpler.,0,0.9898865222930908
1131047710,13240,Hangleton,2023-03-09T13:41:44Z,"thanks for the answer. if i understand correctly, we would then have a resolution of topic ids from topic-name-based persisted data, so this may not prevent offsets from a topic to be provided as those of another topic with the same name (defined at different point in time in the server)? the resolution can be done in the group coordinator layer, assuming it has access to the topic id resolved upstream by the request handler. because we want to preserve the same mapping used when request processing started, we need to ensure the right ids are used within the adaptor's `groupcoordinator#commitoffsets` method(). since the mapping returned from the metadata cache depends on the snapshot used at the time the mapping is requested, if the adaptor retrieves it from the metadata cache internally, at a different time from the request handler, there is no guarantee the metadata is the same hence that the topic ids registered with the broker are the same. this means that the topic ids need to be propagated from the request handler (`kafkaapis`) to the coordinator adaptor somehow. without a change in the method and contract implemented by the coordinator, these ids could be transferred via the `offsetcommitrequestdata` dto directly, which means a change in the api schema would be required prior to the change. alternatively, we may want to change the interface of the coordinator and change the signature of the offset commit method to allow for the propagation of topic ids. i may be missing the entire thing though?",1,0.5635728240013123
1131114261,13240,dajac,2023-03-09T14:33:59Z,"how about doing the following? we change the signature of `groupcoordinator.handlecommitoffsets` to the following: [code block] note the change from `topicpartition` to `topicidpartition` for `offsetmetadata` and `responsecallback`. then, we have to adapt the implementation of `handlecommitoffsets` to get the `topicpartition` from the `topicidpartition` where required. we can keep `pendingoffsetcommits` and `offsets` keyed by `topicpartition` for now in `groupmetadatamanager`. this allows the preservation of the topic ids provided to the groupcoordinator but it does not provide any stronger guarantee for the offsets yet (as you pointed out). with this approach, we don't depend on the resolver at all.",0,0.9949955940246582
1131139080,13240,Hangleton,2023-03-09T14:49:42Z,"sounds good. thanks for your guidance. as you mentioned, this pr is already quite large, so if you agree, i will go ahead and implement this change first, in a pr of its own. thanks!",1,0.9950147271156311
1131241761,13240,dajac,2023-03-09T15:56:05Z,sounds good to me. thanks!,1,0.99457186460495
1168410473,13240,dajac,2023-04-17T09:17:52Z,"it looks like `topicidandnames` is only used if version >= 9. should we move it that else branch? moreover, it seems that we don't need the bimap anymore here. should we just get the mapping that we need and revert the bimap think in the `metadatacache`?",0,0.9936435222625732
1168412474,13240,dajac,2023-04-17T09:19:41Z,"just to be sure. the addition of `true` is the only real change here, right?",0,0.9812938570976257
1168414850,13240,dajac,2023-04-17T09:21:50Z,i think that `topicid` is optional so we could just set it here.,0,0.9864655137062073
1168415581,13240,dajac,2023-04-17T09:22:24Z,"is using `true` all the time correct here? i suppose that it should be `false` if `version` < 9, no?",0,0.9913001656532288
1168416665,13240,dajac,2023-04-17T09:23:22Z,nit: i think that we could set it all the time here as well.,0,0.9763344526290894
1168423960,13240,dajac,2023-04-17T09:29:54Z,"should this test be parameterized as well? with this change, it seems that we don't have any tests exercising the validation with topic names now.",0,0.992900013923645
1168430856,13240,dajac,2023-04-17T09:35:45Z,nit: `true` should be derived from the `version`.,0,0.9944016337394714
1168433830,13240,dajac,2023-04-17T09:38:23Z,"changing the code structure like this is really annoying during reviews. it explodes the diff for no reasons and distracts the reviewing from the more important changes. it would be better to keep those for separate prs. in this case, we could just add the `true` and the `topicid` to the previous code.",-1,0.8784704208374023
1168454144,13240,dajac,2023-04-17T09:56:31Z,would you mind if we keep to keep those code refactoring in the tests for separate pr(s)? this pr is already extremely large and i would like to focus on getting the new code right. all those non-related changes are additional (unnecessary) distractions for now.,0,0.9277024269104004
1168456953,13240,dajac,2023-04-17T09:59:08Z,i think that you could pass config overrides to `createconsumer` directly.,0,0.9870021343231201
1168464261,13240,dajac,2023-04-17T10:05:22Z,i think that consumers created with `createconsumer` are closed automatically by the super class.,0,0.9904334545135498
1168468628,13240,dajac,2023-04-17T10:09:03Z,nit: this could be private.,0,0.931050717830658
1168468929,13240,dajac,2023-04-17T10:09:20Z,nit: `topicnames.map(topic => {` -> `topicnames.map { topic => `,0,0.9839582443237305
1168469544,13240,dajac,2023-04-17T10:09:58Z,do we really need to use `nameandid` here? this does not seem necessary.,0,0.990588903427124
1168470063,13240,dajac,2023-04-17T10:10:28Z,"nit: you could get `topicids` with `gettopicids(""topic1"", ""topic2"", ""topic3"")`.",0,0.9922947883605957
1168472971,13240,dajac,2023-04-17T10:13:06Z,i would rather prefer to use the request/response data objects here.,0,0.9840787649154663
1168473224,13240,dajac,2023-04-17T10:13:22Z,could we parameterize the test instead of doing this?,0,0.9915785789489746
1168473647,13240,dajac,2023-04-17T10:13:46Z,i wonder if we already have integration tests for the consumer covering this. do we?,0,0.9767401814460754
1168474784,13240,dajac,2023-04-17T10:14:55Z,this test does not seem to be at the right place. it seems to me that `offsetcommitrequesttest` is more focused on testing the offsetcommitrequest api.,0,0.9792444109916687
1168475048,13240,dajac,2023-04-17T10:15:09Z,nit: let's make all the private methods private.,0,0.9639783501625061
1168475457,13240,dajac,2023-04-17T10:15:32Z,nit: could we revert this change and just add the boolean?,0,0.9906725287437439
1168671042,13240,dajac,2023-04-17T13:11:41Z,nit: indentation seems to be off here.,0,0.5314800143241882
1168675481,13240,dajac,2023-04-17T13:14:40Z,nit: `topicidorzero`?,0,0.991751492023468
1168676628,13240,dajac,2023-04-17T13:15:01Z,nit: `topicnameornull` and get rid of the `optional`?,0,0.9916182160377502
1168677142,13240,dajac,2023-04-17T13:15:24Z,nit: should we remove ` `?,0,0.9914242625236511
1168678603,13240,dajac,2023-04-17T13:16:32Z,nit: should we replace `ofnullable` by a simple `if/else` statement? allocating an optional does not seem necessary here.,0,0.9921057224273682
1168679689,13240,dajac,2023-04-17T13:17:09Z,nit: this one is already in the list (l47).,0,0.990070641040802
1168688432,13240,dajac,2023-04-17T13:23:02Z,"nit: could we try to combine those? `private static topicidpartition t1p = new new topicidpartition(uuid.randomuuid(), 0, topic1)`?",0,0.994411289691925
1168689266,13240,dajac,2023-04-17T13:23:38Z,nit: `topicidandnamebimapping`?,0,0.9940828680992126
1168693500,13240,dajac,2023-04-17T13:26:00Z,nit: this empty line could be removed.,0,0.985887348651886
1168694559,13240,dajac,2023-04-17T13:26:28Z,nit: this empty line could be removed.,0,0.985887348651886
1168696909,13240,dajac,2023-04-17T13:28:15Z,"if the outcome of the test is different in this case, isn't it a bit weird to combine them in the same unit test?",-1,0.9048857688903809
1168703280,13240,dajac,2023-04-17T13:33:05Z,this goes a bit too far in my opinion. we usually prefer to have simpler parameterized tests. could we simplify this somehow and bring stuck back in the main unit test?,0,0.5520168542861938
1168735466,13240,dajac,2023-04-17T13:52:19Z,"this one made me think that we are probably not doing the right thing in the implementation. in this particular case, if we have only one committed offset and we don't have a response for it because the topic id is wrong, i think that `commitoffsetssync` should not succeed because we actually don't know if the offset was committed or not. what do you think? one way around this would be to verify that we have received a response for each topic-partitions.",0,0.9680184721946716
1168742716,13240,dajac,2023-04-17T13:57:02Z,i am not sure to follow why we need this `consumer` here. couldn't we just have a matcher which verifies what we want/need?,0,0.7889537811279297
1168815694,13240,dajac,2023-04-17T14:36:03Z,"this seems to be a quite complicated way to group `offsetcommitrequestpartition` or `offsetcommitresponsepartition` by `topicidpartition`, no? i would just write two methods to do just this.",0,0.9357621669769287
1185002319,13240,clolov,2023-05-04T13:17:25Z,i believe t1p is abstracted because it is being used in 175 other places in this test class for test setup and assertions.,0,0.9915585517883301
1185137613,13240,clolov,2023-05-04T14:51:40Z,"sorry, could you elaborate, because i am not certain i follow? `gettopicids(...)` will return a map but only if the topics requested have been created first. are you suggesting that since all tests create these three topics we move the creation to the setup method and then we use `gettopicids` everywhere else?",-1,0.9782585501670837
1185779424,13240,Hangleton,2023-05-05T07:29:21Z,"that is right. christo, maybe you can create two separate tests for these cases and factor in common code in a method?",0,0.7217350602149963
1185861417,13240,clolov,2023-05-05T09:04:20Z,"yup, i will get to this today",0,0.8980804681777954
1197974839,13240,clolov,2023-05-18T15:36:59Z,"to be honest i would prefer if we leave it like this. if we parameterise it, this means we have to change `sendoffsetcommitrequest`. if we change `sendoffsetcommitrequest` then we need to come up with a different source for `testoffsetcommitwithunknowntopicid`. alternatively i can parameterise this test, but i would end up wrapping a single version in a seq. is the reason you want it parameterised here so that it breaks it down when running the tests in intellij?",0,0.9882651567459106
1197988726,13240,clolov,2023-05-18T15:49:27Z,from my reading of the code this consumer is a captor. we validate some of the things in this method and we validate the overall captured value elsewhere in individual tests. i am not too certain how this can be simplified to just a matcher to be honest.,0,0.6152743697166443
1203965540,13240,Hangleton,2023-05-24T11:46:23Z,"i think david probably hints at consolidating both in one defining object to ease future updates of topic-partition to topic ids. i updated the test class as per david's comment, i am happy to revert if this brings too many loc changes.",1,0.929214358329773
1203992806,13240,Hangleton,2023-05-24T12:03:45Z,"i think i see what you mean, it is rather heavy-weight and lacks single scope which is preferable for unit tests. updating accordingly.",0,0.8974664211273193
1204079800,13240,Hangleton,2023-05-24T12:54:16Z,did the change to provide higher cohesion to the tests. i split the initial test method in two separated test methods.,0,0.9898117184638977
1204087015,13240,Hangleton,2023-05-24T12:58:43Z,that is true.,0,0.9785748720169067
1204151150,13240,Hangleton,2023-05-24T13:34:57Z,"sure, i removed the method `createtopics` and use `gettopicids` instead.",0,0.993540346622467
1204162396,13240,Hangleton,2023-05-24T13:40:14Z,"yes, i think the idea of parameterizing the test by version of request is it is faster to identify version-specific failures.",0,0.9774141311645508
1204312762,13240,Hangleton,2023-05-24T14:52:34Z,added a commit to build the dtos directly. this removes the contingency on correctness of the test code which built these dtos.,0,0.9946129322052002
1204356253,13240,Hangleton,2023-05-24T15:12:20Z,"you are right, this is exercised in `offsetfetchrequesttest`, `plaintextconsumertest`, `groupcoordinatorintegrationtest` and `authorizerintegrationtest`. so, i removed this test to avoid duplication.",0,0.9903385043144226
1204361177,13240,Hangleton,2023-05-24T15:14:16Z,added parameterization as david suggested.,0,0.992646336555481
1204376110,13240,Hangleton,2023-05-24T15:20:43Z,"agreed, i thought to put it there because the underlying rpc is used, but you are right, it is a different client-level api.",0,0.980927586555481
1204403475,13240,Hangleton,2023-05-24T15:33:49Z,i removed the test since this method is already exercised in `org.apache.kafka.clients.admin.kafkaadminclienttest#testoffsetcommitnumretries`.,0,0.9947581887245178
1205089112,13240,Hangleton,2023-05-25T07:11:05Z,"just to clarify, do you mean the commit offsets method should return false when at least 1 over n > 1 could not be committed due to topic id mismatch, or when n == 1 could not be committed for the same reason?",0,0.9895854592323303
1205119564,13240,Hangleton,2023-05-25T07:40:48Z,"sure, that makes sense to get rid of the consumer, since it is mixing test design pattern and overlaps the responsibilities of the matcher as you pointed out.",0,0.989484965801239
1226607855,13240,dajac,2023-06-12T12:41:20Z,"as a second thought, i wonder if we should complete the future with an exception here. being defensive would help us to catch bugs early one. what do you think?",0,0.87880539894104
1226610273,13240,dajac,2023-06-12T12:43:20Z,should we remove this one for now as it is not implemented yet?,0,0.9913943409919739
1226612028,13240,dajac,2023-06-12T12:44:42Z,should we remove stale_member_epoch and unknown_member_id for now?,0,0.9938368201255798
1226632779,13240,dajac,2023-06-12T13:00:26Z,"my understanding is that we don't retry when `commitoffsetsasync` is used. is it correct? if it is, it may be better to split the test in two. it is really misleading otherwise.",0,0.8308637142181396
1226634411,13240,dajac,2023-06-12T13:01:50Z,nit: it may be better to name this one `prepare....`.,0,0.9900367259979248
1226634534,13240,dajac,2023-06-12T13:01:56Z,nit: it may be better to name this one `prepare....`.,0,0.9900367259979248
1226636149,13240,dajac,2023-06-12T13:03:07Z,nit: i would inline this in the respective tests because it seems not related to what this method does.,0,0.9662440419197083
1226638371,13240,dajac,2023-06-12T13:04:55Z,is this used anywhere?,0,0.989799976348877
1226638660,13240,dajac,2023-06-12T13:05:09Z,is this used anywhere?,0,0.989799976348877
1226647441,13240,dajac,2023-06-12T13:12:15Z,"i think that the method should return false if any mismatched topic id. if i commit foo-topic-id and bar-topic-id, the method should not succeed if we don't get a response for any of them, right?",0,0.9623989462852478
1226648857,13240,dajac,2023-06-12T13:13:25Z,this case is not correct as well in my opinion. the caller should get an exception in this case.,-1,0.5214218497276306
1226673880,13240,dajac,2023-06-12T13:32:08Z,nit: topicnameandid?,0,0.9913832545280457
1226675517,13240,dajac,2023-06-12T13:33:23Z,it is a bit weird to have this class defined here but i cannot think of a better place for now. thoughts?,-1,0.9885879755020142
1226676007,13240,dajac,2023-06-12T13:33:43Z,nit: this seems to be misaligned.,-1,0.8740751147270203
88262234,2140,ijuma,2016-11-16T15:45:33Z,is it intentional that this is `logbuffer` instead of `log_buffer`? same for the `tostring` implementation.,0,0.9928568601608276
88262970,2140,ijuma,2016-11-16T15:48:36Z,should this method be renamed as well?,0,0.9939760565757751
88285663,2140,hachikuji,2016-11-16T17:25:22Z,ack. there are probably a few of these. i'll do another pass and try to find others.,-1,0.9356474280357361
89426622,2140,junrao,2016-11-24T02:13:36Z,should we assert record.magic() > 0?,0,0.9931179285049438
89426686,2140,junrao,2016-11-24T02:14:27Z,"to be consistent, perhaps this.size and this.channel should just be size and channel?",0,0.9934631586074829
89426710,2140,junrao,2016-11-24T02:14:45Z,"it seems that some of the changes are lost during rebase? for example, there was code in memoryrecords for setting the buffer limit according to length, and cast position to int instead of creating a long object.",0,0.9846116900444031
89426721,2140,junrao,2016-11-24T02:14:55Z,"this seems to be an existing issue. for uncompressed messages, do we double count messagesread since we already increased the count in line 98?",0,0.9816853404045105
89426736,2140,junrao,2016-11-24T02:15:05Z,this and line 144 don't seem to be correct. it seems that we should add the number of entries in retainedentries?,0,0.9736213684082031
89426742,2140,junrao,2016-11-24T02:15:10Z,should we add slice.limit or slice.position?,0,0.9944333434104919
89426755,2140,junrao,2016-11-24T02:15:19Z,it seems that this is only used in test now?,0,0.9919633865356445
89680530,2140,junrao,2016-11-27T00:17:36Z,"in line 337, we get the deep iterator by constructing a logbufferiterator with shallow set to false. to be consistent, it seems that if we want to get a shallow iterator, we should construct a logbufferiterator with shallow set to true instead of call a separate static method?",0,0.99444180727005
89680531,2140,junrao,2016-11-27T00:17:43Z,is this comment at the right place? the following code doesn't directly allocate any buffer.,0,0.9865649938583374
89680539,2140,junrao,2016-11-27T00:17:57Z,"since logentries is a deque, perhaps it's clearer if we explicitly use addlast() ?",0,0.9952044486999512
89680541,2140,junrao,2016-11-27T00:18:03Z,recordsiterator.deeprecordsiterator is no longer valid.,0,0.9766436219215393
89698576,2140,junrao,2016-11-27T20:26:51Z,"instead of having shallowentries() and deepentries(), would it be better to combine them into a logentries(boolean isshallow)? this will make it consistent with how we get an iterator for records through abstractlogbuffer.records(boolean isshallow).",0,0.9946452379226685
89698580,2140,junrao,2016-11-27T20:26:55Z,this can be private.,0,0.9784858226776123
89698584,2140,junrao,2016-11-27T20:27:07Z,"hmm, this seems like an existing issue. it seems that we should subtract the wrapper header and the record overhead from position() to get the compressed data size?",0,0.9713404774665833
89698589,2140,junrao,2016-11-27T20:27:17Z,could this be private since it seems to be only used within the class?,0,0.9946683049201965
89698592,2140,junrao,2016-11-27T20:27:35Z,"it seems that logentry.writeheader() is only used inside this class. perhaps we could just move the code from logentry to here as a private method. once we do that, it seems that we could also make putlong() and putint() private in this class.",0,0.9943369030952454
89698597,2140,junrao,2016-11-27T20:27:41Z,it seems that we could just eliminate this line?,0,0.9891873002052307
89931628,2140,junrao,2016-11-29T02:43:47Z,"with this change, it seems that we can make bufferpool.deallocate(bytebuffer buffer, int size) private?",0,0.9917987585067749
89931638,2140,junrao,2016-11-29T02:43:52Z,should we just remove the commented out code?,0,0.9929928779602051
89931661,2140,junrao,2016-11-29T02:44:09Z,perhaps we can make the comment clearer by saying that this can happen when there is no full log entry in the log buffer.,0,0.9919708967208862
89931696,2140,junrao,2016-11-29T02:44:35Z,would it be necessary to cache the record instance and reuse? it seems that a few methods like size() and setcreatetime() are calling record().,0,0.9946674108505249
89931716,2140,junrao,2016-11-29T02:44:46Z,this maybe a bit confusing since our default compression type to the user is none. could we let the callers use gzip directly?,0,0.5807623267173767
89931730,2140,junrao,2016-11-29T02:44:52Z,$targettimestamp can only be used in scala.,0,0.9916998744010925
89931765,2140,junrao,2016-11-29T02:45:09Z,could we just always load records lazily and get rid of eagerloadrecords? not sure if we lose any performance by doing that.,0,0.9752748608589172
89931793,2140,junrao,2016-11-29T02:45:18Z,"to be consistent, should we change record to message?",0,0.9944853186607361
89931855,2140,junrao,2016-11-29T02:45:53Z,could we rename shallowentries/deepentries to shallowlogentryiterator/deeplogentryiterator so that it's clear that we are not buffering all entries in the call?,0,0.9930927753448486
89931924,2140,junrao,2016-11-29T02:46:37Z,"the contract for loginputstream seems to be that a null value from calling nextentry() indicates normal completion of the iterator and any ioexception indicates an error. so perhaps we should capture eofexception in dataloginputstream since it's only expected there, and convert it to a null return value in nextentry(). then, here, we can just check null for ending the iterator like other places.",0,0.9941271543502808
89931932,2140,junrao,2016-11-29T02:46:43Z,do we want to add a separator between records?,0,0.9931259155273438
89931956,2140,junrao,2016-11-29T02:46:53Z,perhaps we could add a comment here that this class deals with the write path to memorylogbuffer while memorylogbuffer only deals with the read path?,0,0.9945915341377258
89931968,2140,junrao,2016-11-29T02:47:03Z,could this method just call appendunchecked() to avoid code duplication?,0,0.9926908612251282
89931980,2140,junrao,2016-11-29T02:47:09Z,it seems that estimatedbyteswritten() and numrecordswritten() can be private?,0,0.9949938654899597
89931983,2140,junrao,2016-11-29T02:47:11Z,bufferstream.buffer() can just be buffer().,0,0.9922422170639038
89932016,2140,junrao,2016-11-29T02:47:36Z,"this also seems to be an existing issue. until memorylogbufferbuilder is closed, buffer().position() is not necessarily accurate since the compressor may not have flushed compressed data to the output stream. currently, recordaccumulator.drain() calls this method before closing memorylogbufferbuilder. so, if builtlogbuffer != null, perhaps it's better to use estimatedbyteswritten()?",0,0.9918960928916931
89932051,2140,junrao,2016-11-29T02:47:59Z,"this also seems to be an existing problem. it seems that when generating those internal messages (tombstone, groups, etc), we assume the message timestamp type is always create_time. however, the offset topic could be configured with log_append_time.",0,0.9910893440246582
89932067,2140,junrao,2016-11-29T02:48:08Z,it seems that we could get rid of ensurematchingmagic since no caller is setting it?,0,0.992294192314148
90155476,2140,junrao,2016-11-30T01:52:30Z,"for compressed messageset, perhaps it's more consistent if we always return the lastoffset as offsetofmaxtimestamp regardless of the timestamp type? we only need that for timestamp indexing. indexing at the shallow offset level is good enough and will make the indexing logic consistent between the leader replica and the follower replica (which doesn't do decompression during log append).",0,0.9940828680992126
90155523,2140,junrao,2016-11-30T01:52:58Z,"to be future proof, should we pass in the timestamp in this record instead of no_timestamp?",0,0.9952604174613953
90155541,2140,junrao,2016-11-30T01:53:10Z,"since this is only used in memorylogbufferbuilder, perhaps it can be a private method there?",0,0.9952489733695984
90155548,2140,junrao,2016-11-30T01:53:14Z,it seems that this method can be private?,0,0.9930277466773987
90155558,2140,junrao,2016-11-30T01:53:18Z,it seems that this method can be private?,0,0.9930277466773987
90155589,2140,junrao,2016-11-30T01:53:35Z,"info.offsetofmaxtimestamp returns the deep offset of the message with max timestamp. to be consistent with the other code path, if compression is enabled, it seems that we want to return the shallow offset? it maybe clearer to also rename validationandoffsetassignresult.offsetofmaxtimestamp to sth like shallowoffsetofmaxtimestamp.",0,0.9938966631889343
90155602,2140,junrao,2016-11-30T01:53:42Z,it seems that toformatversion() is only used in test now?,0,0.9940751791000366
90155611,2140,junrao,2016-11-30T01:53:46Z,it seems that converttobuffer() is no longer used?,0,0.9900550842285156
90155619,2140,junrao,2016-11-30T01:53:50Z,unused import kafka.api.fetchresponsepartitiondata,0,0.9927672147750854
90155632,2140,junrao,2016-11-30T01:53:58Z,"""message set size"" is bit ambiguous. perhaps we should say ""number of messages""?",0,0.8778343796730042
90155643,2140,junrao,2016-11-30T01:54:08Z,"not sure what's ""byte offset"".",0,0.7562292218208313
90155656,2140,junrao,2016-11-30T01:54:15Z,"hmm, why do we have to change the expected size?",0,0.8127507567405701
90155674,2140,junrao,2016-11-30T01:54:24Z,is there a reason that we only test non-compressed message conversion now?,0,0.9919854402542114
90361346,2140,hachikuji,2016-12-01T00:35:21Z,"hmm.. there was actually a reason for this. the static `shallowiterator` returns the more specific logentry type, which would not be possible if `shallow` is passed as an argument. having the more specific type in shallow iteration lets you do some operations to the shallow entries that are not possible with the deep entries (such as setting offsets or timestamps in-place).",0,0.9722936153411865
90363088,2140,hachikuji,2016-12-01T00:50:56Z,ack. i'll fix this and the one below and update the test cases.,-1,0.9439612627029419
90377352,2140,hachikuji,2016-12-01T03:27:16Z,"to be honest, i'm not really sure why this comment is needed. it seems obvious that the key and value sizes in the inner messages are based on the uncompressed data (how could they be otherwise if we compress the inner message set as a whole?).",0,0.8749452829360962
90377503,2140,hachikuji,2016-12-01T03:29:28Z,"thanks, i like this idea.",1,0.9866650104522705
90378055,2140,hachikuji,2016-12-01T03:36:43Z,how about `shallowiterator` and `deepiterator`?,0,0.9936004877090454
90378753,2140,hachikuji,2016-12-01T03:45:52Z,"related to my comment above. the reason to separate them is so that we can return a more specific type in the shallow iterator. for `memorylogbuffer`, `shallowentries` returns `bytebufferlogentry`, which gives you hooks for writing over the offset and the timestamp. these methods do not make sense for the inner entries, so it is not desirable to add them to the general `logentry` interface. similarly, with `filelogbuffer`, we get shallow instances of type `filechannellogbuffer`, which provides its own custom hooks. the other thing i like about having the explicit names is that it makes the iteration type clear in the calling code (i don't have to remember whether `true` or `false` means shallow). for consistency, we could change `records(boolean isshallow)` to support two variants. i added this method mainly for testing, but still it would be nice to have a consistent approach.",0,0.968970000743866
90378909,2140,hachikuji,2016-12-01T03:48:01Z,"as a matter of fact, the `shallow` option is unused for `records()`, so maybe i will change this to have it only return the deep records.",0,0.9910050630569458
90381994,2140,hachikuji,2016-12-01T04:34:16Z,"thanks for the suggestion. i modified `logentry.writeheader` to work with the `dataoutputstream`. after doing so, i found that i no longer needed `putlong` and `putint`.",1,0.8378154635429382
90382244,2140,hachikuji,2016-12-01T04:38:04Z,apologies... i often comment this out in testing and forget about it.,0,0.6874495148658752
90382891,2140,hachikuji,2016-12-01T04:47:58Z,i think we can. the only cost is that we have to allow for the possibility of an exception thrown from `logentry.record()` instead of `loginputstream.nextentry()` (which already deals with io errors).,0,0.9891756176948547
90383775,2140,hachikuji,2016-12-01T05:02:32Z,"hmm.. i think the test was broken or at least incomplete since `message.toformatversion` only did shallow conversion. when i implemented this in the client code, i forbid shallow-only conversion because it results in bugs like we found in `logcleaner`. we'll probably end up dropping this code after we remove `message.toformatversion` as suggested above.",0,0.9579976797103882
90383989,2140,hachikuji,2016-12-01T05:06:19Z,"it puzzled me for a while when writing this code why the size was coming out different only for snappy, but it turns out that we've overridden the block size in the client code, instead of using the default as was done for the server code.",-1,0.6262378692626953
90486643,2140,ijuma,2016-12-01T16:43:09Z,"also, in java, having named methods is clearer than using booleans since one cannot use named arguments. however, it can be a bit confusing to have both options.",0,0.8605222702026367
90487017,2140,ijuma,2016-12-01T16:44:50Z,`shallowiterator` and `deepiterator` sounds good to me.,0,0.5131282806396484
90487806,2140,ijuma,2016-12-01T16:48:26Z,good catch. we probably don't want the change the buffer size in the server to be the same as the client. we may consider changing the client to be the same as the server. see kafka-3704 for details.,0,0.5450184345245361
90805334,2140,guozhangwang,2016-12-05T05:23:18Z,did we get rid of the re-allocation logic as a whole? otherwise we cannot remove this additional check i think.,0,0.9897245168685913
90805786,2140,guozhangwang,2016-12-05T05:31:37Z,"is this private function better than previously in-lined, since it is private anyways?",0,0.9922431111335754
90806087,2140,guozhangwang,2016-12-05T05:36:06Z,"if we only deallocate the initial buffer, if re-allocation happens does that mean we will effectively have ""memory leaks""?",0,0.9795483350753784
90810199,2140,guozhangwang,2016-12-05T06:42:19Z,data -> memory?,0,0.9886054396629333
90810687,2140,guozhangwang,2016-12-05T06:49:42Z,is there any rationale for this magic number?,0,0.9898367524147034
90813219,2140,guozhangwang,2016-12-05T07:22:36Z,"i'm following myself about renaming here: we could consider rename to recordentryinputstream, with t extends recordentry.",0,0.9846803545951843
90814254,2140,guozhangwang,2016-12-05T07:36:51Z,this is not introduced in this patch: since we get the exact number of bytes returned from `log.append` could we use that in the trace logging?,0,0.995627760887146
90815062,2140,guozhangwang,2016-12-05T07:46:44Z,where is this function used?,0,0.9919946193695068
90978864,2140,hachikuji,2016-12-05T23:18:12Z,"this ended up a little ugly whichever way i cut it. i think i prefer the current location because it keeps the message format encapsulated in `record` a bit better, but it comes at the cost of leaking the write optimization which is only used in `memoryrecordsbuilder`. i could go either way here, so let me know if you feel strongly about moving it into `memoryrecordsbuilder`. for now, i'll add a javadoc which explains the usage better.",0,0.8247172236442566
90979896,2140,guozhangwang,2016-12-05T23:24:38Z,i have a comment on this function and it seems squashed. my question was since it is a private function do we really need this rather than having it in-lined?,-1,0.6895613670349121
90979998,2140,guozhangwang,2016-12-05T23:25:18Z,nit: data -> space?,0,0.9781107902526855
90980061,2140,guozhangwang,2016-12-05T23:25:42Z,what is the rationale for this magic number for compressed set?,0,0.991706132888794
90981109,2140,guozhangwang,2016-12-05T23:32:53Z,we use `maxrecordsize` here and `maxmessagesize` in the other extended class.,0,0.9936781525611877
90981197,2140,guozhangwang,2016-12-05T23:33:27Z,+1.,0,0.9498199820518494
90986644,2140,guozhangwang,2016-12-06T00:12:47Z,"we are using `logentry` here for the message set wrapper, and in other places `logentry` is used for the internal message. we may need to update the javadoc on `logentry` accordingly in different extensions of `loginputstream` and `records` clarify if its `nextentry` and `iterator` returns shallow or deep iterations.",0,0.9939526915550232
90986838,2140,guozhangwang,2016-12-06T00:14:24Z,"this actually returns the message set as a `record`, right?",0,0.9916381239891052
90986917,2140,guozhangwang,2016-12-06T00:15:09Z,nit: also add the `filerecords` reference here?,0,0.99367356300354
90987096,2140,guozhangwang,2016-12-06T00:16:37Z,nit: indicate that this needs shallow iterations on the entries.,0,0.9792962670326233
90987112,2140,guozhangwang,2016-12-06T00:16:45Z,nit: indicate that this needs deep iterations on the entries.,0,0.9720731377601624
90987175,2140,guozhangwang,2016-12-06T00:17:18Z,"this statement is a bit misleading, how about ""to the format indicated by the given magic value"".",-1,0.5667818784713745
90987669,2140,guozhangwang,2016-12-06T00:21:56Z,nit: unnecessary new lines.,-1,0.9308233261108398
90988043,2140,guozhangwang,2016-12-06T00:24:42Z,we can reuse record_overhead_v0 and record_overhead_v1 here.,0,0.9912009239196777
90988718,2140,guozhangwang,2016-12-06T00:30:03Z,"update the comment as well for `public`. also i'm wondering if we could rename `wrapperxx` just to `xx` and add comments indicating that they are only used for old formatted messages with magic number > 0, and also add a check in constructor that the `magic()` field is consistent with its values: if it is larger than 0 these two fields should never be null; if it is 0 then these two fields should always be null etc.",0,0.9934554696083069
90989533,2140,guozhangwang,2016-12-06T00:36:26Z,is this function only used for unit tests?,0,0.9923496842384338
90989804,2140,guozhangwang,2016-12-06T00:38:51Z,is this function only used in tests?,0,0.9930738210678101
90989898,2140,guozhangwang,2016-12-06T00:39:40Z,why we keep its reverse function as private static in `record` while making it in utils?,0,0.9950743317604065
90990467,2140,guozhangwang,2016-12-06T00:44:19Z,read from -> write to?,0,0.9904701709747314
90991673,2140,guozhangwang,2016-12-06T00:54:36Z,why we can use `integer.max_value` for deep iteration?,0,0.9935157299041748
90991785,2140,guozhangwang,2016-12-06T00:55:33Z,do we still need to override this function from `abstractrecords` since we already override its calling `shallowiterator`?,0,0.9951648712158203
90992078,2140,guozhangwang,2016-12-06T00:58:01Z,ditto above. we use `maxmessagesize` and `maxrecordsize` interleavingly.,0,0.982575535774231
90992562,2140,guozhangwang,2016-12-06T01:02:27Z,hmm... not sure i understand this: if compression is not use we will simply ignore the `shallow` flag and always go shallow??,-1,0.7802687287330627
90994228,2140,guozhangwang,2016-12-06T01:17:26Z,could you elaborate a bit why shallow iterator allows extensible `logentry` while deep iterator does not?,0,0.9939126372337341
90994615,2140,guozhangwang,2016-12-06T01:21:28Z,why we need to re-construct the `logentry` if its magic number is larger than 0? could we just set its corresponding record's timestamp directly?,0,0.9919901490211487
90995329,2140,guozhangwang,2016-12-06T01:28:44Z,good idea :),1,0.9955371618270874
90995731,2140,guozhangwang,2016-12-06T01:32:38Z,those java docs need to be updated with the new class names. ditto everywhere else.,0,0.9774388670921326
90996571,2140,guozhangwang,2016-12-06T01:41:11Z,nit: group kafka imports?,0,0.9861209988594055
90997090,2140,guozhangwang,2016-12-06T01:45:58Z,"i think we do not need to make `builderwithentries` public since this is the only caller here, and it is followed by a `build()` call immediately, so we can still use `withlogentries`.",0,0.9837017059326172
90997888,2140,guozhangwang,2016-12-06T01:53:42Z,"it is not introduced in this patch: i think its more clear to use two vals here, one named `trimedrecords` and one named `validrecords`.",0,0.9902147054672241
90998010,2140,guozhangwang,2016-12-06T01:55:10Z,where is this object used?,0,0.992591381072998
90998487,2140,guozhangwang,2016-12-06T02:00:39Z,"a meta clarification question: for all these classes, are we planning to get rid of them all at the same time when the old consumer is removed?",0,0.9866862297058105
90999554,2140,guozhangwang,2016-12-06T02:12:13Z,looks good :),1,0.9955553412437439
90999912,2140,guozhangwang,2016-12-06T02:16:23Z,private?,0,0.9812482595443726
91007176,2140,hachikuji,2016-12-06T03:45:33Z,hmm... i may have misunderstood how this worked. i'll add it back.,-1,0.5465817451477051
91008613,2140,hachikuji,2016-12-06T04:05:02Z,"""data"" is correct, but i'll clarify the comment since it does read a little awkwardly. we're trying to say that the client should raise an error if the size of the message exceeds the bytes returned in the response.",0,0.7379422783851624
91008790,2140,hachikuji,2016-12-06T04:07:51Z,it was copied from the server code: [a link] i think perhaps the 1024 comes from the minimum block size for snappy encoding. i can add a comment about that part at least.,0,0.9910513162612915
91009212,2140,hachikuji,2016-12-06T04:13:44Z,it's used in this file. it may not show in the diff because i moved it from `filemessageset` (which was deleted).,0,0.9929700493812561
91009296,2140,hachikuji,2016-12-06T04:15:00Z,inside `logmanager.asyncdelete`.,0,0.9909965991973877
91009688,2140,hachikuji,2016-12-06T04:20:18Z,it's the maximum size of a record entry to read. i think the only place we use it is in `dumplogsegments`.,0,0.9921388030052185
91010122,2140,hachikuji,2016-12-06T04:27:05Z,"the main reason for extension of `logentry` is to enable optimization tricks like overwriting the offsets in place (see `bytebufferlogentry`) or reading the magic byte without loading the record data (see `filechannellogentry`). these tricks are generally only possible for the shallow records. you can't modify the deep records in place since they have been decompressed, nor can you optimize which parts of the record to read (you have to read the whole thing). for the deep records, there's not much you can do aside from read the data, so extension seemed unnecessary.",0,0.9925710558891296
91010212,2140,hachikuji,2016-12-06T04:28:14Z,"haha, depends on whether it's compressed or not, right?",1,0.8432119488716125
91010306,2140,hachikuji,2016-12-06T04:29:41Z,i have a comment in `loginputstream` which attempts to make the distinction clear. let me know if more explanation is needed.,0,0.980767548084259
91011143,2140,hachikuji,2016-12-06T04:41:47Z,"the wrapper values can be null if either the magic is 0 or if the record is uncompressed. i'll add an assertion for this, but i'd prefer to keep the current names since it's otherwise harder to explain.",0,0.9841963052749634
91011764,2140,hachikuji,2016-12-06T04:51:21Z,"it was necessary before because of the optimization in `filechannellogentry.magic()`, but since i've factored that into `logentry`, i was able to remove it.",0,0.9937305450439453
91011883,2140,hachikuji,2016-12-06T04:52:59Z,"if compression is not used, there are no deep entries.",0,0.9870604276657104
91012046,2140,hachikuji,2016-12-06T04:55:40Z,"i followed what the current code did. previously deep iteration was done here in `bytebuffermessageset.deepiterator`, which has no check for max message size.",0,0.9921169877052307
91012622,2140,hachikuji,2016-12-06T05:02:47Z,"hmm... seems worth exploring. we could add a `setwrappertimestamp(timestamptype, long)` or something like that, but i'm not sure it's a good idea to make those fields mutable.",0,0.8643469214439392
91012841,2140,hachikuji,2016-12-06T05:06:55Z,the public version of `builderwithentries` is used in `logvalidator` and `bytebuffermessageset`.,0,0.9946449995040894
91013183,2140,hachikuji,2016-12-06T05:12:28Z,"on second thought, doing so would change the behavior of this function.",0,0.969394326210022
91013213,2140,hachikuji,2016-12-06T05:12:48Z,"yes, that is the hope. i've removed almost all other uses.",1,0.6705019474029541
91017536,2140,hachikuji,2016-12-06T06:12:35Z,"actually i had to remove these assertions. first, if the magic is 1, then we can't distinguish between a shallow uncompressed entry, and a deep entry, which would also not have its compression flag enabled. we could at least raise an error if magic is 0 and there is a provided wrapper timestamp., but we currently have test cases which allow us to create a record with only a valid crc (which means we can't check magic). we could probably be a little stricter: if there aren't enough bytes in the bytebuffer to read the record overhead, then obviously the record can't be valid, so maybe those test cases are kind of silly and should be removed.",0,0.982333242893219
91149520,2140,guozhangwang,2016-12-06T19:11:31Z,"aha, i was thinking about the new format :) nvm.",1,0.9959980249404907
91149711,2140,guozhangwang,2016-12-06T19:12:25Z,"i was thinking if we can save one object creation, but it seems less worth optimizing since we are not re-creating the underlying buffer anyways. so it's your call.",0,0.9707679748535156
91826419,2140,junrao,2016-12-10T02:22:04Z,deepentries => deepiterator ?,0,0.990658164024353
91826423,2140,junrao,2016-12-10T02:22:10Z,"is ""file-backed log buffer."" still needed?",0,0.9945831894874573
91826431,2140,junrao,2016-12-10T02:22:21Z,"hmm, why do start and end need to be long?",0,0.7136098146438599
91826435,2140,junrao,2016-12-10T02:22:28Z,"""log buffer"" probably need to be changed?",0,0.9912219047546387
91826438,2140,junrao,2016-12-10T02:22:35Z,it seems that position should be int?,0,0.9927714467048645
91826441,2140,junrao,2016-12-10T02:22:40Z,could we just cast channel.size() to int?,0,0.9935815334320068
91826447,2140,junrao,2016-12-10T02:22:45Z,shallowentries in this and the next two methods should be shallowiterator?,0,0.9932829141616821
91826461,2140,junrao,2016-12-10T02:23:01Z,"is the reference to ""log buffer"" still valid?",0,0.9934015870094299
91826468,2140,junrao,2016-12-10T02:23:08Z,"it seems that the follower could call this more than once. so, perhaps it's worth caching.",0,0.9870215058326721
91826477,2140,junrao,2016-12-10T02:23:21Z,it doesn't seem that last offset is being maintained here.,0,0.9719217419624329
91826488,2140,junrao,2016-12-10T02:23:46Z,"hmm, we are getting the last offset, which is not necessarily the offset for message with the max timestamp.",0,0.9610402584075928
91826489,2140,junrao,2016-12-10T02:23:52Z,this and the next method probably should be deepiterator() too?,0,0.9922623634338379
91826492,2140,junrao,2016-12-10T02:23:59Z,"i had the following comment earlier. is that valid? this also seems to be an existing issue. until memorylogbufferbuilder is closed, buffer().position() is not necessarily accurate since the compressor may not have flushed compressed data to the output stream. currently, recordaccumulator.drain() calls this method before closing memorylogbufferbuilder. so, if builtlogbuffer != null, perhaps it's better to use estimatedbyteswritten()?",0,0.9927486777305603
91826501,2140,junrao,2016-12-10T02:24:05Z,are the references to log buffer still valid?,0,0.9935717582702637
91826508,2140,junrao,2016-12-10T02:24:13Z,"to be consistent, should we change entries to records?",0,0.9944650530815125
91826512,2140,junrao,2016-12-10T02:24:18Z,should logentries be records?,0,0.9932221174240112
91830966,2140,ijuma,2016-12-10T07:53:07Z,"btw, it's a bit of a shame to lose the enhanced foreach syntax. is there a reason not to expose a `deepiterable()` method instead?",-1,0.9553170204162598
91880865,2140,becketqin,2016-12-12T04:10:01Z,kafka-4497 reported an issue regarding this. there was a few other issues in `bytebuffermessageset.filterinto()` logic. i provided a patch in #2242 . we should probably fix the logic here as well.,0,0.9943549633026123
92014373,2140,hachikuji,2016-12-12T18:57:41Z,"yes, that makes sense. apologies for missing the comment before.",1,0.5039892196655273
92020118,2140,hachikuji,2016-12-12T19:24:26Z,"ack. this goes back to logcleaner actually, but i'll go ahead and fix here.",-1,0.8944605588912964
92072625,2140,junrao,2016-12-13T00:21:41Z,"a 4 byte size, an 8 byte offset => an 8 byte offset, a 4 byte size of the record",0,0.9862646460533142
92072954,2140,junrao,2016-12-13T00:24:22Z,"is the reference to ""log buffer"" still valid?",0,0.9934015870094299
92072967,2140,junrao,2016-12-13T00:24:27Z,"is the reference to ""log buffer "" still valid?",0,0.9934159517288208
92195306,2140,ijuma,2016-12-13T15:42:32Z,"it's a bit annoying that we create so much indirection (dataloginputstream -> bytebufferinputstream -> underlyinginputstream -> bytebuffer -> byte[]). in an ideal world, we would not bother with `inputstream` at all and would just operate at the `bytebuffer` level. however, the gzip case is hard to do that way.",-1,0.9747506976127625
92216997,2140,junrao,2016-12-13T17:09:21Z,do we need to change the position of buffer? perhaps we could instead just change the position in the slice passed to record().,0,0.992752194404602
92217186,2140,junrao,2016-12-13T17:10:13Z,"""a 4 byte size,"" needs to be removed.",0,0.9807175993919373
92225885,2140,hachikuji,2016-12-13T17:50:35Z,"haha, yeah. one of the layers is sort of fake (`datainputstream` should be a mixin), but the point is still valid.",1,0.9383083581924438
92227525,2140,hachikuji,2016-12-13T17:58:31Z,"currently `record` expects the position of the `bytebuffer` to be at 0. i was tempted to change this assumption, but decided to leave it for now (it's a bit annoying to change all the accessors to assume relative positioning). we could accomplish the same result using `mark()` and `reset()` if that seems any better.",-1,0.721836507320404
563471404,2140,dengziming,2021-01-25T05:30:44Z,"should this be `math.min(length, size.get() - offset)`?",0,0.9937159419059753
563909128,2140,junrao,2021-01-25T17:32:58Z,: thanks for the comment. this does seem like a bug. would you be interested in submitting a separate pr to have this fixed?,1,0.7347074747085571
179653282,4830,tedyu,2018-04-06T03:32:29Z,should this be kafka_1_1_iv0 ?,0,0.9945396780967712
179653551,4830,tedyu,2018-04-06T03:35:26Z,i think channelunmutingcallback would be better name,0,0.9884794354438782
179898815,4830,jonlee2,2018-04-06T23:49:03Z,"this was based on the comments in lines 31-36, which states ""when we change the protocol a second time while developing 0.10.0, we will add a new config value ""0.10.0-iv1"" and a corresponding case object kafka_0_10_0-iv1. we will change the config value ""0.10.0"" to map to the latest internal version object kafka_0_10_0-iv1."" following the example, i set 1.1 to the latest internal version, kafka_1_1_iv1.",0,0.9944033622741699
179919414,4830,lindong28,2018-04-07T15:22:58Z,`throttledelayms`?,0,0.9921841025352478
179919602,4830,lindong28,2018-04-07T15:30:06Z,"if connection state is connecting (i.e. connectiondelay = long.max_value) and throttledelay is 10 ms, should we poll this connection right after 10 ms, or should we wait until the state is connected?",0,0.9928073883056641
179919811,4830,lindong28,2018-04-07T15:38:07Z,would it be more intuitive and consistent to let `clusterconnectionstates.isready()` return false if the connection is throttled?,0,0.9944366216659546
179919877,4830,lindong28,2018-04-07T15:40:51Z,maybe `throttledelayms`?,0,0.9931527376174927
179919904,4830,lindong28,2018-04-07T15:41:38Z,"maybe `polldelayms`? also, can you update the param in the java doc?",0,0.9944615960121155
179919911,4830,lindong28,2018-04-07T15:41:53Z,maybe `polldelayms`?,0,0.9932479858398438
179920062,4830,lindong28,2018-04-07T15:47:04Z,"according to the java doc of log.trace(), it says `this form avoids superfluous string concatenation when the logger is disabled for the trace level`. thus we probably don't need to explicitly check `log.istraceenabled`.",0,0.9941307902336121
179920083,4830,lindong28,2018-04-07T15:48:11Z,nits: it may be simpler to just do `if (nodeswithclientsidethrottlingenabled.contains(nodeid) && throttletimems > 0)`,0,0.9949306845664978
179920227,4830,lindong28,2018-04-07T15:53:25Z,we probably don't need to explicitly check log.isdebugenabled(...) because `log.debug` will automatically check this before doing string operation.,0,0.9906226992607117
179920433,4830,lindong28,2018-04-07T16:00:33Z,"it seem a bit unintuitive -- if a node's apiversionresponse's version is smaller than 2, why would the node be in `nodeswithclientsidethrottlingenabled` in the first place? it maybe more intuitive to remove this `else` branch and instead remove the node from `nodeswithclientsidethrottlingenabled` in `handleconnections()`. what do you think?",0,0.8805529475212097
179920578,4830,lindong28,2018-04-07T16:04:56Z,"in order to be consistent with other comments, it may be better to say `introduced apiversionsrequest v2 via kip-219`. also, can you move `""1.1"" -> kafka_1_1_iv1` to the last entry?",0,0.9954124093055725
179920783,4830,lindong28,2018-04-07T16:13:09Z,can `throttledchannel` be `val` instead of `var`?,0,0.9941040873527527
179920867,4830,lindong28,2018-04-07T16:17:45Z,it seems that the return value of `tryunmuate` is only needed for trace level logging. can we move the trace level logging into this method and make this method void to simplify the implementation?,0,0.9938666224479675
179920958,4830,lindong28,2018-04-07T16:22:49Z,can `throttledchannel` be `val`?,0,0.9940081834793091
179920962,4830,lindong28,2018-04-07T16:22:56Z,can `throttledchannel` be `val`?,0,0.9940081834793091
179921259,4830,lindong28,2018-04-07T16:35:48Z,it is probably not necessary to check `throttletimems > 0` since `maybethrottle()` will check it anyway.,0,0.9923620223999023
179921295,4830,lindong28,2018-04-07T16:37:03Z,"it maybe more readable to keep the code style consistent by moving `quotas.request.maybethrottle(request, requestthrottletimems)` to a new line with `{` and `}`.",0,0.9941599369049072
179921553,4830,lindong28,2018-04-07T16:44:54Z,i think the word `maybe` in the original method name `mayberecordandthrottle` is mostly for `throttle`. it is probably more intuitive to name this method `getthrottletimems`.,0,0.9923056960105896
179921638,4830,lindong28,2018-04-07T16:48:10Z,it seems a bit redundant to check `quotasenabled` in both `mayberecord` and `maybethrottle`. it is probably more intuitive to check `quotasenabled` only in `mayberecord` such that `throttletimems` will be 0 if `quotasenabled` is false. then `maybethrottle` can act solely based on `throttletimems`.,0,0.9927177429199219
179921729,4830,lindong28,2018-04-07T16:51:06Z,"nits: it may be more readable to use math.max(bandwidththrottletimems, requestthrottletimems) to be consistent with other code and also to show that these two variables are treated equally.",0,0.9937509894371033
180278955,4830,jonlee2,2018-04-10T02:01:50Z,done,0,0.8974218964576721
180286163,4830,jonlee2,2018-04-10T03:09:53Z,done,0,0.8974218964576721
180286169,4830,jonlee2,2018-04-10T03:09:57Z,done,0,0.8974218964576721
180286176,4830,jonlee2,2018-04-10T03:10:00Z,good point. i think throttledelay should make sense only when connected (either checking_api_versions or ready). updated the code to explicitly check the connection state to determine which delay to return.,1,0.7264910936355591
180286183,4830,jonlee2,2018-04-10T03:10:06Z,done. i also updated clusterconnectionstates.hasreadynodes() to take the throttling state into account. please review that change as well.,0,0.9889479875564575
180286188,4830,jonlee2,2018-04-10T03:10:08Z,done,0,0.8974218964576721
180286192,4830,jonlee2,2018-04-10T03:10:10Z,done,0,0.8974218964576721
180286207,4830,jonlee2,2018-04-10T03:10:20Z,done,0,0.8974218964576721
180286219,4830,jonlee2,2018-04-10T03:10:26Z,"based on your next comment, i think it still makes sense to call this mayberecord() (or mayberecordandgetthrottletimems?) because recording only happens when quotasenabled == true. and also rename maybethrottle() to throttle(). i made those changes. what do you think?",0,0.9854603409767151
180286234,4830,jonlee2,2018-04-10T03:10:32Z,"makes sense assuming that maybethrottle() always uses throttle time returned by mayberecord(), which is the case.",0,0.9945632815361023
180286244,4830,jonlee2,2018-04-10T03:10:34Z,done,0,0.8974218964576721
180286350,4830,jonlee2,2018-04-10T03:11:33Z,done,0,0.8974218964576721
180286480,4830,jonlee2,2018-04-10T03:12:56Z,this variant takes 3+ arguments after the format string and the comment says that it incurs a small overhead. looks like the same check is used for other places where 3+ arguments are taken. will keep unless you have other concerns.,0,0.9697180390357971
180286492,4830,jonlee2,2018-04-10T03:13:04Z,done,0,0.8974218964576721
180286561,4830,jonlee2,2018-04-10T03:13:38Z,"for this, i removed the check because it take 1 or 2 args.",0,0.9922922849655151
180286995,4830,jonlee2,2018-04-10T03:15:53Z,"it was to cover corner cases where a broker restarted with a lower version (like rollback). i am not entirely sure how this can be in handleconnections(), though. it looks like just initiating api version fetch. can you elaborate?",0,0.9582971930503845
180287026,4830,jonlee2,2018-04-10T03:15:59Z,done,0,0.8974218964576721
180287053,4830,jonlee2,2018-04-10T03:16:05Z,done,0,0.8974218964576721
180287077,4830,jonlee2,2018-04-10T03:16:10Z,done,0,0.8974218964576721
180287095,4830,jonlee2,2018-04-10T03:16:14Z,done,0,0.8974218964576721
180287122,4830,jonlee2,2018-04-10T03:16:20Z,done,0,0.8974218964576721
180671354,4830,lindong28,2018-04-11T08:22:18Z,is this method used only in test? it maybe unnecessary to add a method to a interface solely for test purpose.,0,0.9881501197814941
180673624,4830,lindong28,2018-04-11T08:30:23Z,`isthrottled()` is only called once in non-test code (i.e. `clusterconnectionstates.isready(...)`). it maybe simpler to just call `throttledelayms(...) > 0` in `isready()`. (similar to the code in `hasreadynodes()`),0,0.9952976107597351
180675326,4830,lindong28,2018-04-11T08:36:50Z,how about just call `isready()` here? i understand that existing code does not re-use the isready(). it maybe better to improve it.,0,0.9915016889572144
180678877,4830,lindong28,2018-04-11T08:49:44Z,it seems that we can remove `isconnected(..)` and replace it with `isready(...)` in `polldelayms(...)`. `isconnected()` will be different from `isready()` only when state is `checking_api_versions`. but we are sending apiversionrequest to broker in `handleinitiateapiversionrequests()` anyway without checking whether the connection is throttled. alternatively we can update `handleinitiateapiversionrequests()` so that it does not send `apiversionrequest` if the connection is throttled. personally i would not do this because i don't think the first version apiversionrequest would overload the broker and thus the extra code/logic in client-side implementation is probably not worthwhile.,0,0.9946448802947998
180679073,4830,lindong28,2018-04-11T08:50:31Z,"`throttledeadlinems` maybe be a bit ambiguous in how it is used -- does it mean the connection should be throttled or un-throttled after this deadline? how about `throttleuntiltimems`, `muteuntiltimems` or `earliestsendtimems`?",0,0.9911264777183533
180679291,4830,lindong28,2018-04-11T08:51:20Z,we probably don't need this method if we don't need `clusterconnectionstates.isconnected()`.,0,0.9900741577148438
180682137,4830,lindong28,2018-04-11T09:00:59Z,we can probably just use `now` without calling `time.milliseconds()` here.,0,0.9922480583190918
180682340,4830,lindong28,2018-04-11T09:01:36Z,we can probably call `time.milliseconds` only once and share it with the existing `now = time.milliseconds()`.,0,0.9936374425888062
180683981,4830,lindong28,2018-04-11T09:07:30Z,yeah `mayberecordandgetthrottletimems()` sounds better.,0,0.9916353225708008
180813450,4830,lindong28,2018-04-11T16:14:40Z,"previously the way we throttle a request is pretty extensible: we first throttle based on byte rate, and if that passes, then we throttle based on produce rate. if in the future we have another throttle mechanism, e.g. based on cpu, we can easily stack this on top of byte-rate-based and request-rate-based throttling mechanism. the way this patch implements throttling is kind of hard to extend (or appears to be difficult to read) due to the following reasons: - the number of throttling mechanisms is hard-coded to be 2 in throttlechannel.tryunmute() - instead of being able to distribute throttling mechanism in multiple places, now we have to determine the throttle time of all mechanism in one place (e.g. here) and use the one that has the largest throttle time. this will work for now. but it will be hard to extend and seems not-so-readable. - we pass around option[throttledchannel] and treats `none` separately from `some()`. it will be cleaner to just pass one non-option object. i am wondering if the following high-level solution would be better: in class `kafkachannel` we use an integer to keep track of the number of existing mechanisms that are throttling this channel. for example, if this request exceeds the byte-based quota, we increment this integer by one and enqueue an object into a delayed queue. after the corresponding throttle time is passed, we dequeue this object and decrement the value of this integer in the `kafkachannel`. if the value is 0 after it is decremented, we unmute the channel. this solution may be cleaner in the following sense: - we no longer needs to pass option[throttledchannel]. - we can implement byte-based and request-based throttling mechanism in the same manner as the existing kafka implementation without having to put them together. - the solution is more extensible since it does not assume there are exactly two throttling mechanisms. what do you think?",0,0.9633634686470032
182270273,4830,jonlee2,2018-04-17T23:21:30Z,done,0,0.8974218964576721
182270329,4830,jonlee2,2018-04-17T23:21:47Z,done,0,0.8974218964576721
182270349,4830,jonlee2,2018-04-17T23:21:58Z,done,0,0.8974218964576721
182270366,4830,jonlee2,2018-04-17T23:22:04Z,done,0,0.8974218964576721
182270438,4830,jonlee2,2018-04-17T23:22:32Z,renamed to throttleuntiltimems.,0,0.9900112748146057
182271668,4830,jonlee2,2018-04-17T23:31:08Z,"now that isready() checks for throttling status, i don't think it can be used directly for polldelayms(). polldelayms() needs to check if the state is ready and *throttled*. i can directly check if the state is ready, instead of isconnected(). will that work?",0,0.9924227595329285
182271745,4830,jonlee2,2018-04-17T23:31:44Z,see the comment above. i'll remove once we agree on what to do for polldelayms().,0,0.9893313646316528
182271764,4830,jonlee2,2018-04-17T23:31:52Z,done,0,0.8974218964576721
182271781,4830,jonlee2,2018-04-17T23:31:59Z,done,0,0.8974218964576721
182271956,4830,jonlee2,2018-04-17T23:33:16Z,"we discussed this offline and agreed to keep the current logic for using the max. as for option[throttledchannel], i used kafkachannel to keep the ref count as suggested and got rid of the use of option[throttledchannel].",0,0.9945071339607239
183115763,4830,lindong28,2018-04-20T17:15:27Z,"the java doc seems to be inconsistent with the implementation. if the connection has been established and the throttle delay is 0, we actually return `long.max_value` instead of 0. also, can this java doc follow the style of the existing java doc for `connectiondelay`. for example, `returns the number of milliseconds to wait, based on the connection state and the throttle time, before attempting to send data.`",0,0.9935095906257629
183115843,4830,lindong28,2018-04-20T17:15:45Z,the java doc seems to be inconsistent with the implementation.,0,0.8294981122016907
183145676,4830,lindong28,2018-04-20T19:16:12Z,"it seems that `decrementunmuterefcountandget` and `unmute` are always used together. would it be simpler to just modify the existing method `unmute` to be `maybeunmute`, which internally will decrement the reference count and umute the channel if the reference count is 0?",0,0.9952700734138489
183146203,4830,lindong28,2018-04-20T19:18:35Z,"would it be simpler to just modify the existing method `mute` to be `maybemute`, which internally will increment the reference count and mute the channel if the reference count is 1 after it is incremented?",0,0.9943220615386963
183147589,4830,lindong28,2018-04-20T19:24:59Z,should this be debug level logging?,0,0.9925387501716614
183150790,4830,lindong28,2018-04-20T19:40:01Z,"it maybe subjective. i am more inclined not to use super.*. can we keep the existing java method style, where we check `quotasenabled` in `mayberecordandgetthrottletimems`, and call `recordandgetthrottletimems` if `quotasenabled` is true. `mayberecordandgetthrottletimems` can be defined in both `clientrequestquotamanager` and `clientquotamanager`. `recordandgetthrottletimems` will be defined only in `clientquotamanager`.",-1,0.8816714286804199
183152661,4830,lindong28,2018-04-20T19:49:15Z,"this method is in `clientrequestquotamanager` but not in `clientquotamanager`. and it kind of overlaps with `throttle` and `mayberecordandgetthrottletimems`. so the simplification of removing callback in kafkaapis.java comes at the cost of added methods and inconsistency in `clientrequestquotamanager` and `clientquotamanager`. i am usually conservative and prefer to keep the existing code style unless the code style is clearly superior. in this case there is pros and cons in the new code style. and since difference people may have different opinion, it may cause back-and-forth change in open source development. later the second reviewer can comment on this.",0,0.9053953886032104
183153259,4830,lindong28,2018-04-20T19:52:02Z,"previously the throttletimems in fetchresponse is `bandwidththrottletimems + requestthrottletimems`. now it is changed to `max(bandwidththrottletimems, requestthrottletimems)`.",0,0.9944064617156982
183153543,4830,lindong28,2018-04-20T19:53:30Z,"previously the throttletimems in produceresponse is `bandwidththrottletimems + requestthrottletimems`. now it is changed to `max(bandwidththrottletimems, requestthrottletimems)`.",0,0.9943650960922241
183155316,4830,lindong28,2018-04-20T20:00:37Z,i am wondering if there is specific reason for the previous method signature.,0,0.6725019812583923
183588951,4830,jonlee2,2018-04-24T02:20:45Z,we need to return max since we are not stacking throttling anymore.,0,0.9870681762695312
183588956,4830,jonlee2,2018-04-24T02:20:49Z,we need to return max since we are not stacking throttling anymore.,0,0.9870681762695312
183588969,4830,jonlee2,2018-04-24T02:20:54Z,this is because we don't need to pass this as a callback anymore.,0,0.9878381490707397
183603418,4830,jonlee2,2018-04-24T04:43:04Z,done,0,0.8974218964576721
183603427,4830,jonlee2,2018-04-24T04:43:11Z,done,0,0.8974218964576721
183603515,4830,jonlee2,2018-04-24T04:43:59Z,i actually removed mayberecordthrottle() from clientrequestquotamanager. it is now consistent with clientquotamanager.,0,0.991234540939331
183603548,4830,jonlee2,2018-04-24T04:44:21Z,done. thanks for catching this.,1,0.8837432861328125
183603566,4830,jonlee2,2018-04-24T04:44:33Z,updated,0,0.968669593334198
183604255,4830,jonlee2,2018-04-24T04:50:13Z,"i thought about it and i actually prefer to keep it this way. the reason why is that the ref count is used by socketserver only and thus i want socketserver to be the only one that updates the count. in other words, whatever layer that uses this ref count should update it within that layer. if we expose this to selector, i am concerned that there may be some misuse. what do you think?",0,0.6401050686836243
183604277,4830,jonlee2,2018-04-24T04:50:29Z,please see the comment above.,0,0.9780430793762207
183916192,4830,lindong28,2018-04-25T00:19:45Z,nits: can we use math.max(...)?,0,0.9907498955726624
183917654,4830,lindong28,2018-04-25T00:33:09Z,it may be slightly better to share the code with the existing `setexpectedapiversionsresponse()`.,0,0.9944450259208679
183918381,4830,lindong28,2018-04-25T00:39:55Z,do we need this change?,0,0.9887621998786926
183919344,4830,lindong28,2018-04-25T00:48:28Z,"typo requoest. also, should the throttle time for request rate quota to be larger than 0, since the request rate quota is 0.01?",0,0.9923770427703857
183919358,4830,lindong28,2018-04-25T00:48:39Z,typo requoest,0,0.9731860756874084
183940157,4830,jonlee2,2018-04-25T04:27:12Z,done,0,0.8974218964576721
183940161,4830,jonlee2,2018-04-25T04:27:15Z,refactored the code to maximize code reuse.,0,0.9846145510673523
183940170,4830,jonlee2,2018-04-25T04:27:24Z,forgot to remove. updated.,0,0.9697922468185425
183940176,4830,jonlee2,2018-04-25T04:27:28Z,"fixed. the test is instrumented so that both quotas are violated, but throttle time is recorded for the max of the two only. that's why throttle time metrics for request quota is supposed to be 0.",0,0.9877648949623108
183940180,4830,jonlee2,2018-04-25T04:27:31Z,fixed,0,0.9281549453735352
184196347,4830,rajinisivaram,2018-04-25T20:30:58Z,"there are a lot of comments like this that refer to kip-219. typically, we don't include kip numbers and jiras in comments for code changes. it is preferable to have comments that are self contained so that developers don't have to find the kip to follow the code.",0,0.9854653477668762
184196826,4830,rajinisivaram,2018-04-25T20:32:58Z,"had a comment on the kip discuss thread about the approach to update only apiversions version. can you respond on the thread, please?",0,0.9888910055160522
184197543,4830,rajinisivaram,2018-04-25T20:35:47Z,"i haven't gone through the pr in detail, but i think this callback is invoked on a different thread when throttle time expires. `selector` is not thread-safe and we expect methods on the selector to be invoked from a single thread.",0,0.9862832427024841
184199595,4830,rajinisivaram,2018-04-25T20:43:28Z,"i am not sure about this. since quotas are calculated differently, not sure `max` gives the same result as the throttle times calculated separately as it was done earlier.",0,0.6147512793540955
184753260,4830,jonlee2,2018-04-27T17:25:02Z,"i removed kip-219 references, except for apiversion.scala.",0,0.9932677745819092
184753299,4830,jonlee2,2018-04-27T17:25:10Z,"yes, i replied to the vote thread for seeking comments. could you also respond to that thread since you were one of the original voters?",0,0.9906033873558044
184753337,4830,jonlee2,2018-04-27T17:25:17Z,"thank you for catching this. this is an important point. i made the following changes to address this. - removed the callback from socketserver to the api layer - when throttling starts and ends, the api layer will put responses using new responseactions to the request channel queue to notify socket server of start/end throttling - when socketserver receives responses with these new actions, it will update reference count and try to unmute the channel with these changes, reference count handling and mute/unmute channel will be handled in the same thread.",1,0.9756994247436523
184754840,4830,jonlee2,2018-04-27T17:30:50Z,"with this kip, a response needs to be sent out with a throttle time value before actually starting throttling, and thus we need to determine how long we should mute the channel first before sending out the response. in other words, if multiple quotas are violated, we can't really wait till throttling for one quota is over before computing throttle time for next quota. under this scenario, i thought using the max is reasonable. it will be same as before if only one quota is violated. if multiple quotas are violated, using max may not give the same throttle time in some cases but i am not sure what will be a better alternative. i am not entirely sure about how throttle times can be ""calculated separately"" with this kip. are you suggesting that on multiple quota violations, say, produce and request, we throttle for produce violation only and deal with any remaining request quota violation the next time the client sends another produce request after the initial throttling? but this is also different from the way it was and can be inefficient (in case we keep picking smaller throttle time).",0,0.9283554553985596
184950779,4830,rajinisivaram,2018-04-30T10:10:15Z,"no, i am not suggesting that we do only one at a time. i think we need to see if we can do a better calculation than `max` to combine the two (or potentially many in future).",0,0.9667537212371826
185120383,4830,jonlee2,2018-04-30T21:49:07Z,"i still think using max is reasonable. in my understanding, that is the minimum amount of time we need to throttle anyway for the traffic at the time of quota violation. there may be other connections using the same client id/user while the throttling is going on, but that will only add more load and thus will not improve the throttle time. i also discussed with and he agreed. would you let me know if you have any specific suggestions?",0,0.8324722647666931
186307847,4830,lindong28,2018-05-07T00:06:29Z,nits: can we replace `throttledeadlinems` with `throttleuntiltimems` for consistency?,0,0.9941750168800354
186308119,4830,lindong28,2018-05-07T00:14:46Z,nits: can we align the second line of parameters with the first line in the same manner as `sendinternalmetadatarequest()`?,0,0.994821310043335
186308382,4830,lindong28,2018-05-07T00:21:40Z,"according to the java doc of org.slf4j.logger.trace, `this form avoids superfluous string concatenation when the logger is disabled for the trace level. however, this variant incurs the hidden (and relatively small) cost of creating an object[] before invoking the method`. so it is probably ok to skip checking `log.istraceenabled`. it will also be more consistent with the existing invocation of `log.trace()` in kafka.",0,0.9945182204246521
186308601,4830,lindong28,2018-05-07T00:28:08Z,"since this integer is decremented when `tryunmutechannel()` is called, would it be a bit more intuitive to name it `muterefcount()`? if so, we may want to also rename methods such as `incrementunmuterefcount()`, `decrementunmuterefcountandget()`, `getunmuterefcount()` and `incrementchannelunmuterefcount()`.",0,0.9948581457138062
186309712,4830,lindong28,2018-05-07T00:55:33Z,"for the same reason that this patch adds the throttletimems field to the leaderandisrresponse, should we also add this field to stopreplicaresponse?",0,0.9950634837150574
186313712,4830,lindong28,2018-05-07T02:03:46Z,"broker's handling of fetchrequest becomes stateful after kip-227 added support for incremental fetch response. it means that the state in broker will be inconsistent with the state in client if we replace a non-empty fetchresponse with an empty response. more specifically, in `cachedpartitions.updateresponsedata()`, state (e.g. highwatermark) will be updated if a partition is assumed to be included in the fetchresponse. in order to solve this problem, we probably need to change the implementation related to kip-227. currently `cachedpartitions.updateresponsedata()` will 1) determine the partitions to be included and 2) update the state for those partitions that are included. we probably need to split this into two separate functions. the the state for those partitions should be updated only if the fetchresponse is not throttled. another problem is that `clientsensors.quotasensor.record` has already been called in `recordandgetthrottletimems()` at this point. it means that we have already assumed that the resource is used to send the fetchresponse at this point. it will cause under-utilization if we only sends an empty fetchresponse after updating the quotasensor. the main motivation of this kip is to address problem caused by producerequest. fetchrequest is small and probably not a concern. if we don't have a simpler way to handle the above two problems, i would recommend not to touch the handlefetchrequest() logic in this patch, i.e. broker still sends the non-empty fetchresponse after the throttle time has passed.",0,0.9939257502555847
187203528,4830,jonlee2,2018-05-09T23:23:32Z,"per discussion with , i reverted the changes i made to cluster action responses.",0,0.9859648942947388
187203579,4830,jonlee2,2018-05-09T23:23:56Z,done,0,0.8974218964576721
187203589,4830,jonlee2,2018-05-09T23:24:01Z,done,0,0.8974218964576721
187203602,4830,jonlee2,2018-05-09T23:24:09Z,done,0,0.8974218964576721
187203618,4830,jonlee2,2018-05-09T23:24:15Z,done,0,0.8974218964576721
187204068,4830,jonlee2,2018-05-09T23:27:20Z,"thanks for catching this. i made the following changes to address these points: 1. added getresponsesize() to fetchcontext to get the response size (for calculating throttle time) without updating the internal states 2. in case of fetch throttling, unrecord the recorded usage value by recording a negative value of the same quantity. i added comments stating more details about these changes.",1,0.8491901159286499
187911027,4830,rajinisivaram,2018-05-14T10:59:10Z,"`atomicinteger` suggests that this field is updated from multiple threads. since we rely on this to be updated and accessed only from a single thread, it would be better to make it an `int` (like the other fields in this class). also, it is confusing to have a field `muted` and another `muterefcount` and separate methods to go with each. can we combine these two? possibly even just have `mute/unmute` methods in `kakachannel` and make the reference count internal rather than managed by `socketserver`?",0,0.9780022501945496
187913359,4830,rajinisivaram,2018-05-14T11:09:53Z,this response as well as others without a throttle time don't need version bump.,0,0.9863725304603577
187913661,4830,rajinisivaram,2018-05-14T11:11:03Z,i think it would be better to add a `throttletimems()` method to `abstractresponse` that returns throttle time for responses which contain the time and zero for others.,0,0.9922471046447754
187914030,4830,rajinisivaram,2018-05-14T11:12:40Z,should just return zero for this response as well as other responses which don't contain throttle time.,0,0.9877290725708008
187924822,4830,rajinisivaram,2018-05-14T11:54:47Z,we don't usually use `get` prefix for getters.,0,0.9844244122505188
187925371,4830,rajinisivaram,2018-05-14T11:56:57Z,hmm.. this is not ideal. metrics are externally visible entities that are used for monitoring. recording and unrecording can be confusing. but agree that it is hard to fix. we should at least record using the same time (will also avoid an extra `system.currenttimemillis()` per fetch request).,-1,0.7377378344535828
187925735,4830,rajinisivaram,2018-05-14T11:58:28Z,"this is the request quota manager, so it is always request processing time.",0,0.9886462688446045
188146295,4830,jonlee2,2018-05-15T01:53:39Z,done,0,0.8974218964576721
188146303,4830,jonlee2,2018-05-15T01:53:44Z,done,0,0.8974218964576721
188146314,4830,jonlee2,2018-05-15T01:53:49Z,done,0,0.8974218964576721
188146336,4830,jonlee2,2018-05-15T01:53:56Z,done,0,0.8974218964576721
188146689,4830,jonlee2,2018-05-15T01:56:58Z,"i agree that it is not ideal, but the current implementation couples the reporting and quota checking a little too tightly. i used the same time for both record/unrecord as suggested.",0,0.958182156085968
188149319,4830,jonlee2,2018-05-15T02:21:38Z,"i changed atomicinteger to int. as for your other comments, the ref count is used by socketserver and thus i think it should be updated by socketserver only. i am concerned that the ref count combined with the existing kafkachannel mute/unmute may cause some issues when misused by other kafkachannel users. for example, what if someone calls mute() twice? the second mute() is supposed to be a no-op, but if we decide to increase the ref count as part of mute(), it is not actually a no-op. also, socketserver still needs to call some method to increase the count when startthrottlingaction is received, so it won't be completely transparent. another point is that unmute() will be effectively tryunmute() because it only unmutes when the ref count is 0. with these reasons, i initially decided to separate the ref count from the existing mute/unmut logic. but i do agree that it is confusing to have both in kafkachannel. having said that, would it make more sense if i maintain the ref count in socketserver (by using a per-processor map from channel id to ref count) instead of kafkachannel? what do you think?",0,0.9394382834434509
188299694,4830,rajinisivaram,2018-05-15T14:04:47Z,"the problem with mute is that we already have too many different ways of controlling and tracking it, making the code really confusing. there is `kafkachannel.muted`, `kafkachannel.muterefcount`, `kafkachannel.isinmutablestate()`, `selector.explicitlymutedchannels` and the actual interest ops of the selection key in the transport layer. i don't think we want a per-processor map containing channel ids in `socketserver` since managing two lists of channels is just more work and could result in inconsistencies. the particular problem with `kafkachannel.muterefcount` is that if you are looking at `kafkachannel`, then that field and the methods that go with it make no sense since you can have `muted=true, refcount=0`. would it be possible to convert `kafkachannel.muted` to `kafkachannel.mutestate` with enum states like `not_muted`, `muted`, `response_pending`, `throttled`, `throttled_response_pending` or something along those lines with clear state transitions?",0,0.707188069820404
188508062,4830,jonlee2,2018-05-16T05:42:19Z,thank you for the suggestion. makes a good sense. i replaced kafkachannel.muted with kafkachannel.mutestate and remove the ref count. transition of the mutestate of each channel will be controlled by mute-related events reported by socketserver (details mentioned in the comments).,1,0.9754667282104492
188706191,4830,tedyu,2018-05-16T17:21:10Z,what if mute state becomes channelmutestate.muted after the above call ? should unmute still be carried out ?,0,0.9904947280883789
188729990,4830,jonlee2,2018-05-16T18:35:52Z,"yes. this is a noop response case, so if the mute state transitions to muted after the above call (meaning that there's no throttling in progress), we should unmute the channel.",0,0.9908037185668945
189442592,4830,lindong28,2018-05-19T19:17:08Z,nits: return the number ...,0,0.9379493594169617
189442599,4830,lindong28,2018-05-19T19:17:19Z,nits: return the number ...,0,0.9379493594169617
189442674,4830,lindong28,2018-05-19T19:21:24Z,can you make it private?,0,0.9924909472465515
189442716,4830,lindong28,2018-05-19T19:23:11Z,nits: personally i feel the string can be in the same line.,0,0.9249556660652161
189448493,4830,lindong28,2018-05-20T01:10:34Z,"it seems that we will mute a channel after receiving request from client, and maybe unmute a channel after sending the response to client. so should the first two entries be renamed to `request_received` and `response_sent` (with updated docs) respectively?",0,0.9949232935905457
189448703,4830,lindong28,2018-05-20T01:27:00Z,is this change in the leaderandisrresponse needed?,0,0.9938848614692688
189448829,4830,lindong28,2018-05-20T01:36:54Z,is this change needed?,0,0.9904143810272217
189448832,4830,lindong28,2018-05-20T01:37:28Z,is this change needed?,0,0.9904143810272217
189448835,4830,lindong28,2018-05-20T01:37:43Z,is this change needed?,0,0.9904143810272217
189448844,4830,lindong28,2018-05-20T01:38:49Z,is this change needed?,0,0.9904143810272217
189448845,4830,lindong28,2018-05-20T01:39:00Z,is this change needed?,0,0.9904143810272217
189448878,4830,lindong28,2018-05-20T01:41:22Z,nits: it maybe slightly simpler to skip the `if ` statement,0,0.9864039421081543
189448885,4830,lindong28,2018-05-20T01:41:27Z,nits: it maybe slightly simpler to skip the `if ` statement,0,0.9864039421081543
189448890,4830,lindong28,2018-05-20T01:41:48Z,nits: it maybe slightly simpler to skip the `if ` statement,0,0.9864039421081543
189448893,4830,lindong28,2018-05-20T01:41:52Z,nits: it maybe slightly simpler to skip the `if ` statement,0,0.9864039421081543
189449055,4830,lindong28,2018-05-20T01:57:35Z,nits: `${quotatype}` can be replaced with `$quotatype`,0,0.9945255517959595
189449166,4830,lindong28,2018-05-20T02:09:07Z,"since we only unrecord quota sensor if the request is throttled, it may be better to skip checking `quotasenabled` (or throw exception if quotasenabled = false) and rename this method to `unrecordquotasensor`.",0,0.9945001602172852
189449289,4830,lindong28,2018-05-20T02:20:40Z,it could be `val`.,0,0.9912242889404297
189449309,4830,lindong28,2018-05-20T02:22:42Z,nits: it seems that we typically put the the body of the if statement in a new line?,0,0.9915728569030762
189449419,4830,lindong28,2018-05-20T02:34:35Z,`shouldbeincludedinresponse ` name may be a bit confusing because it does not tell whether this method can change state or not. can we name it `maybeupdateresponsedata`?,0,0.9219138026237488
189449460,4830,lindong28,2018-05-20T02:39:48Z,"can we make this class private? and would it be better to add `type resp_map_iter = iterator[util.map.entry[topicpartition, fetchresponse.partitiondata]]` in fetchsession object, and replace the first parameter with `val iter: resp_map_iter`. this seems to be more consistent with the existing code patter and make it more obvious that the new class is a wrapper around the original iterator.",0,0.9937971830368042
189450020,4830,lindong28,2018-05-20T03:11:43Z,would it make the code a bit more readable by initializing unconvertedfetchresponse to an empty map here. by doing this we initialize unconvertedfetchresponse in roughly the same place and createresponse() does not need to do `if (throttletimems > 0)`.,0,0.9942014813423157
189450100,4830,lindong28,2018-05-20T03:18:04Z,nits: can we move `2.0-iv0` to be after `2.0`?,0,0.9948360919952393
189474811,4830,jonlee2,2018-05-20T23:55:52Z,done,0,0.8974218964576721
189474816,4830,jonlee2,2018-05-20T23:55:58Z,done,0,0.8974218964576721
189474821,4830,jonlee2,2018-05-20T23:56:02Z,done,0,0.8974218964576721
189474823,4830,jonlee2,2018-05-20T23:56:06Z,done,0,0.8974218964576721
189474841,4830,jonlee2,2018-05-20T23:56:53Z,"hmm.. i thought i already removed it here and other cluster action responses, but obviously not. done.",0,0.9310824871063232
189474845,4830,jonlee2,2018-05-20T23:56:59Z,done,0,0.8974218964576721
189474848,4830,jonlee2,2018-05-20T23:57:05Z,done,0,0.8974218964576721
189474850,4830,jonlee2,2018-05-20T23:57:11Z,done,0,0.8974218964576721
189474855,4830,jonlee2,2018-05-20T23:57:17Z,done,0,0.8974218964576721
189474857,4830,jonlee2,2018-05-20T23:57:22Z,done,0,0.8974218964576721
189474864,4830,jonlee2,2018-05-20T23:57:29Z,done,0,0.8974218964576721
189474865,4830,jonlee2,2018-05-20T23:57:35Z,done,0,0.8974218964576721
189474868,4830,jonlee2,2018-05-20T23:57:41Z,done,0,0.8974218964576721
189474869,4830,jonlee2,2018-05-20T23:57:48Z,done,0,0.8974218964576721
189474873,4830,jonlee2,2018-05-20T23:57:57Z,done,0,0.8974218964576721
189474877,4830,jonlee2,2018-05-20T23:58:03Z,done,0,0.8974218964576721
189474880,4830,jonlee2,2018-05-20T23:58:10Z,done,0,0.8974218964576721
189474885,4830,jonlee2,2018-05-20T23:58:15Z,done,0,0.8974218964576721
189474890,4830,jonlee2,2018-05-20T23:58:22Z,done,0,0.8974218964576721
189474891,4830,jonlee2,2018-05-20T23:58:27Z,done,0,0.8974218964576721
189475769,4830,jonlee2,2018-05-21T00:23:40Z,done,0,0.8974218964576721
189476185,4830,jonlee2,2018-05-21T00:34:28Z,"request/response in this enum and the previous one refer to request/response between socketserver and the api layer, not between the client and socketserver. one reason why i chose this way was because we don't send out a response to the client when acks = 0. but you are right that we try unmuting after sending out to the response to the client, so i updated as suggested. i still use response_sent for acks=0 case, but i think it should not be confusing (mentioned that in the comments).",0,0.9730387330055237
462738230,9103,abbccdda,2020-07-30T05:07:29Z,you commented on the previous pr about the style here. the reasoning is that this is a more common style than having period at the end in our codebase.,0,0.9912024736404419
463919020,9103,abbccdda,2020-08-01T04:11:47Z,moved to `alterconfigsutil`,0,0.9942240118980408
464029227,9103,abbccdda,2020-08-02T04:18:20Z,moved to `alterconfigsutil`,0,0.9942240118980408
464029411,9103,abbccdda,2020-08-02T04:21:07Z,"this is the new test, the rest of changes in this file are just side cleanups.",0,0.9850267767906189
464241946,9103,dajac,2020-08-03T07:34:55Z,could we use optional for these two as they are not always provided?,0,0.9938054084777832
464242434,9103,dajac,2020-08-03T07:36:02Z,nit: i would actually keep the callback as the last argument as it is a bit more natural to have the callback last.,0,0.9827636480331421
464244756,9103,dajac,2020-08-03T07:41:05Z,nit: empty line could be removed.,0,0.9870886206626892
464245796,9103,dajac,2020-08-03T07:43:25Z,"i personally prefer the previous indentation which is, i believe, more common in our code base. or do we plan to adopt a new formatting?",0,0.9847833514213562
464246880,9103,dajac,2020-08-03T07:45:52Z,nit: could we move it after `clientinformation` to keep the order inline with the order in the constructor?,0,0.9950165152549744
464247255,9103,dajac,2020-08-03T07:46:42Z,shall we use optional here as well?,0,0.9940817952156067
464247740,9103,dajac,2020-08-03T07:47:47Z,"actually, we will also use it for quota. i think that we could say that both `initialprincipalname` and `initialclientid` will be used for logging and quota purposes.",0,0.9853401780128479
464248637,9103,dajac,2020-08-03T07:49:43Z,"as 2.7 has not be release yet, we don't need to introduce a new version. we can reuse `kafka_2_7_iv0`.",0,0.992693305015564
464248862,9103,dajac,2020-08-03T07:50:12Z,shall we use option here?,0,0.9936740398406982
464249275,9103,dajac,2020-08-03T07:51:05Z,nit: that was already present before your change but could we remove the extra space before the colon?,0,0.9917805790901184
464255551,9103,dajac,2020-08-03T08:04:21Z,the usage of the square brackets and the colon looks weird here. the audit log does not look like a sentence anymore. i wonder if we could go with something like this instead: `principal = a on behalf of principal = b is allowed...`. we could also put the initial principal name only if it is set.,-1,0.9286453723907471
464260158,9103,dajac,2020-08-03T08:14:21Z,nit: remove extra space before `authorizedresources`.,0,0.9904914498329163
464271174,9103,dajac,2020-08-03T08:36:17Z,* i presume that this does not work if we use the same listener for bother the control plane and the data plane. * i also wonder if it is a good thing to have this extension here as it applies to all the authorization in the api layer. i think that we should be cautious and only do this for forwarded requests.,0,0.9288142323493958
464271735,9103,dajac,2020-08-03T08:37:25Z,i presume that this does not work if the broker uses the same listener for the control plane and the data plane.,0,0.9620009660720825
464274377,9103,dajac,2020-08-03T08:42:43Z,"nit: `as admin client doesn't know how to find the controller` is not relevant anymore. what about the following: `when ibp is smaller than xyz, forwarding is not supported therefore requests are handled directly`?",0,0.938412070274353
464276809,9103,dajac,2020-08-03T08:47:21Z,"it looks like that we will propagate the `not_controller` error back to the client. is it intentional? as clients don't send this request to the controller (and new ones won't get the controller id anymore), it sounds weird to return them this error. we could perhaps return another generic error.",-1,0.8490750789642334
464277479,9103,dajac,2020-08-03T08:48:34Z,have we considered using scala functions as callbacks? it would be more aligned with the other callbacks that we have in scala and also would avoid having to define classes for each handler that support forwarding. what do you think?,0,0.9911127686500549
464292019,9103,dajac,2020-08-03T09:15:10Z,"for my understanding, i suppose that we don't verify that redirection is enabled here to ensure that the controller can accept forwarded requests as soon as one broker in the cluster is configured with ibp 2.7. am i getting this right?",0,0.9829820990562439
464567004,9103,abbccdda,2020-08-03T17:44:56Z,it is not necessary as we don't check nulls for these fields.,0,0.9793112874031067
464569040,9103,abbccdda,2020-08-03T17:48:54Z,"not necessary, as explained.",0,0.986312210559845
464570322,9103,abbccdda,2020-08-03T17:51:19Z,"i don't think we need initial client id for audit logging, is there some other logging you have in mind?",0,0.9650883674621582
464582897,9103,abbccdda,2020-08-03T18:16:19Z,will requests only flow to data plane if they use the same listener?,0,0.9938177466392517
464583310,9103,abbccdda,2020-08-03T18:17:08Z,not this is propagating to the sender broker.,0,0.9822340607643127
464584005,9103,abbccdda,2020-08-03T18:18:30Z,"yes, the purpose is to always handle a forwarding request even if ibp is not 2.7 yet. this is because some brokers may already upgrade their ibp and they start sending forwarding requests, which is totally legitimate.",0,0.990541398525238
464585176,9103,abbccdda,2020-08-03T18:20:47Z,sg!,1,0.5679675340652466
465272340,9103,dajac,2020-08-04T19:16:28Z,"yeah, i was actually thinking about the request log. i thought that it may be useful to print them out there as well: [a link]",0,0.9481797814369202
465273597,9103,dajac,2020-08-04T19:18:54Z,"sorry, i was not clear. if the control plane listener is not configured, control requests will go to the data plane listener. based on your last commits, it seems that you have figured that out.",-1,0.9903159737586975
465273903,9103,dajac,2020-08-04T19:19:35Z,ack. i have missed the handling of `not_controller` in the `brokertocontrollerchannelmanager`.,0,0.8435893654823303
465274018,9103,dajac,2020-08-04T19:19:49Z,ack. this is what i thought.,-1,0.8203675150871277
465275440,9103,dajac,2020-08-04T19:22:33Z,"actually, we check nulls for these two in `isforwardingrequest` method. i don't feel strongly about this but i usually better to use optional when such values are not always present.",0,0.9616847634315491
465908873,9103,dajac,2020-08-05T18:05:16Z,"i wonder if this is correct. usually, we use `cluster_action` action with the `cluster` resource. for instance, this is how we authorize control requests: [code block] i thought that we would do the same in this case. don't we?",0,0.9866963028907776
466582281,9103,abbccdda,2020-08-06T17:45:49Z,"i'm not sure either, cc",-1,0.8030509352684021
466714423,9103,abbccdda,2020-08-06T22:14:07Z,"actually i think you are right, will change here.",0,0.8586521148681641
467214507,9103,cmccabe,2020-08-07T18:54:46Z,"can we get rid of whitespace-only changes like this, or at least move them to another pr?",0,0.9934189915657043
467215647,9103,abbccdda,2020-08-07T18:56:53Z,let me check around.,0,0.9605053663253784
473158779,9103,abbccdda,2020-08-19T16:26:12Z,add equality check for the sake of easymock verification,0,0.9863615036010742
475710400,9103,cmccabe,2020-08-24T15:43:18Z,need to include: [code block],0,0.9931656718254089
475712573,9103,cmccabe,2020-08-24T15:46:38Z,"how about: ""a broker failed to authorize itself to another component of the system. this indicates an internal error on the broker cluster security setup"". this isn't specific to forwarding... there might be other reasons why a broker would need to authorize itself and fail",0,0.9076755046844482
475714230,9103,cmccabe,2020-08-24T15:49:13Z,in general we don't define equals or hashcode on these builders. why are we defining it here?,0,0.9841582775115967
475725389,9103,cmccabe,2020-08-24T16:06:10Z,just as a note the alter isr pr may also have an object like this. so maybe we want a name which is more specific to redirection.,0,0.9921233057975769
476860796,9103,abbccdda,2020-08-25T23:33:02Z,the purpose is for the mock tests to compare the expected builder in `kafkaapistest`,0,0.9950632452964783
476864248,9103,abbccdda,2020-08-25T23:36:10Z,"interesting, why does the `authorizationexception` have no `serialversionuid`? is it because we never use that error code explicitly?",0,0.9699033498764038
489875283,9103,abbccdda,2020-09-17T01:59:50Z,i'm still trying to decide how to make sure we could turn off the redirection in 2.7. having a separate ibp for 3.0 may not work.,0,0.9121571779251099
493160927,9103,hachikuji,2020-09-23T02:31:05Z,"nit: might be useful to document the expectation that `resources` is a subset of the key set of `configs`. the signature surprised me a little bit. as an aside, this kind of convenience conversion seems more appropriate for `incrementalalterconfigsrequest.builder` rather than a static class.",0,0.9837201833724976
493165520,9103,hachikuji,2020-09-23T02:48:53Z,typically responses are immutable after construction. it seems kind of a brittle pattern to rely on being able to mutate the response we receive from the other broker. for example we inherit the throttle time which is a bit weird. are we saving that much by not creating a new response?,-1,0.9426457285881042
493168061,9103,hachikuji,2020-09-23T02:58:59Z,"in general, the forwarded request may have a different version than the client request. i'm wondering if we should keep the version the same in case there are semantic differences. as an example, a newer version of the api may introduce unexpected error codes. unless we have logic to convert those error codes, then we might break compatibility unexpectedly.",0,0.8696213960647583
493168697,9103,hachikuji,2020-09-23T03:01:28Z,get rid of this todo. we do not need to remove ibp internal versions.,0,0.9828231930732727
493169192,9103,hachikuji,2020-09-23T03:03:34Z,"nit: why don't we add a case class and make this optional. for example: [code block] in addition to reducing parameters, that makes the expectation that both are provided explicit.",0,0.9942448735237122
493169273,9103,hachikuji,2020-09-23T03:03:54Z,nit: space after `if`,0,0.9915086030960083
493169694,9103,hachikuji,2020-09-23T03:05:42Z,can you explain why this change is needed?,0,0.9858853816986084
493170132,9103,hachikuji,2020-09-23T03:07:28Z,the comment doesn't seem to make sense here. seems like the logic doesn't have anything to do with the controller?,0,0.8223268389701843
493170494,9103,hachikuji,2020-09-23T03:09:02Z,this function has 3 callbacks... it would be nice if we could figure out how to pass through the `forwardrequesthandler` directly.,0,0.9121081829071045
493170831,9103,hachikuji,2020-09-23T03:10:24Z,nit: this is misaligned,-1,0.8925305604934692
493171357,9103,hachikuji,2020-09-23T03:12:42Z,"we can't guarantee that this broker will still be the controller when we call `process` or that the broker we're forwarding to will still be the controller when it receives the request. in these cases, we need to return some retriable error to the client. can you help me understand how this is implemented?",0,0.9624198079109192
493171799,9103,hachikuji,2020-09-23T03:14:28Z,"nit: this is subjective, but this style is a bit ugly. i would prefer the following: [code block] that makes it easier visually to separate the return type and the function logic (again, in my opinion).",-1,0.9586330652236938
493172457,9103,hachikuji,2020-09-23T03:17:08Z,nit: seems `handle` doesn't really need to be part of `forwardrequesthandler`. instead we could pull it out: [code block] the advantage of this is that it allows us to pull the type out of `kafkaapis` without inheriting all of the dependencies that are needed by `handle`.,0,0.9938503503799438
493173723,9103,hachikuji,2020-09-23T03:22:14Z,it would be helpful to have a comment explaining this. it does not seem obvious.,0,0.9708446264266968
493174084,9103,hachikuji,2020-09-23T03:23:45Z,"good to see the unit tests in here. i think we also need at least a couple integration tests. for example, could we add something to `createtopicsrequesttest` to ensure that forwarding works as expected?",1,0.5639521479606628
493206068,9103,abbccdda,2020-09-23T05:28:51Z,the primary reason is that we would trigger the disallowed import if we do it in the request builder: [code block] let me check if we could make exceptions here,0,0.992897629737854
493209974,9103,abbccdda,2020-09-23T05:41:23Z,"but in case we release ak 2.7, wouldn't this flag give user the confidence to upgrade to, which we don't want to happen?",0,0.9918796420097351
493518004,9103,rajinisivaram,2020-09-23T12:15:37Z,nit: `ssl` => `ssl`,0,0.9912883043289185
493518728,9103,rajinisivaram,2020-09-23T12:16:25Z,does this get reset somewhere or will we keep adding `/`?,0,0.9896173477172852
493519587,9103,rajinisivaram,2020-09-23T12:17:26Z,`ssl` => `ssl`,0,0.9884517192840576
493520160,9103,rajinisivaram,2020-09-23T12:18:05Z,"this means update was requested, but not necessarily that file has changed?",0,0.9926238059997559
493520165,9103,rajinisivaram,2020-09-23T12:18:05Z,"this means update was requested, but not necessarily that file has changed?",0,0.9926238059997559
493522186,9103,rajinisivaram,2020-09-23T12:20:21Z,can't we put this logic in `dynamicbrokerconfig`?,0,0.9947016835212708
493742677,9103,hachikuji,2020-09-23T16:50:32Z,i'm not sure i follow. do you not want redirection to be part of 2.7?,-1,0.5978842377662659
493751026,9103,abbccdda,2020-09-23T17:03:58Z,"the rational is to trigger a reload of ssl store file by the zk notification. came out this idea to augment the path to [code block] when a reload is requested on the receiver broker, and by propagating such a path other brokers would see a difference and thus reload their corresponding store files as well. in the meantime, we need to trim the path back to single slash after handling the notification: [code block]",0,0.9929437041282654
493752855,9103,abbccdda,2020-09-23T17:07:06Z,"the logic is needed when there is an alterconfigrequest targeting at a specific broker. since the non-controller node will no longer handle alterconfigs, it is possible to see a redirected changing request with a broker.id different than the controller broker.id.",0,0.9909981489181519
493771144,9103,abbccdda,2020-09-23T17:37:09Z,"yes, we would trim it in `trimsslstorepaths`",0,0.9928883910179138
493771267,9103,abbccdda,2020-09-23T17:37:24Z,yea,0,0.9144599437713623
493773324,9103,abbccdda,2020-09-23T17:41:05Z,"i feel it's more explicit to do it in here, as zk notification is the only target case.",0,0.9663072824478149
493782410,9103,abbccdda,2020-09-23T17:56:03Z,i guess we could get rid of it and do the merge in caller level.,0,0.9830332398414612
493795436,9103,abbccdda,2020-09-23T18:17:46Z,"it's a bit hard since we are passing requestbuilder all the way to networkclient, so if we want a designated version to build the request, that may involve some non-trivial changes.",0,0.8860508799552917
493823776,9103,hachikuji,2020-09-23T18:56:42Z,"as discussed offline, we can pass the expected version down to the builder. the abstract builder already supports an explicit range of versions. in any case, it doesn't seem like we have a choice. by the way, one potential edge case here is that the broker receiving the request has upgraded to a later version than the controller. this would be possible in the middle of a rolling upgrade. i don't think there's an easy way to handle this. we could return unsupported_version to the client, but that would be surprising since the client chose a supported api based on apiversions and is not aware of the controller redirection. one idea to address this problem is to gate version upgrades to redirectable apis by the ibp. basically all of these apis have become inter-broker apis through redirection so they need the safeguard of the ibp. feels like we might have to do this.",0,0.9568406939506531
504286524,9103,hachikuji,2020-10-13T22:08:10Z,nit: why don't we call it `requestdata` to be consistent with the name used in the api spec?,0,0.9932548999786377
504287723,9103,hachikuji,2020-10-13T22:10:46Z,nit: i think it might be better to pull this out of the request class. the direction we're moving is toward dumber request/response classes. eventually `enveloperequest` will go away and we'll just use `enveloperequestdata`.,0,0.988908588886261
504288659,9103,hachikuji,2020-10-13T22:12:59Z,not sure why we need this change. i think the convention is to include `none` in error counts.,0,0.8505924940109253
504293144,9103,hachikuji,2020-10-13T22:24:33Z,i'm wondering if we really need the ibp to leak into the common library. it should really only be a broker concern. seems like the only point is so that we can continue to use the factory methods defined below from the broker code. is that right? could we instead move the factories to the broker?,0,0.9765666723251343
504295024,9103,hachikuji,2020-10-13T22:29:23Z,"in a similar vein, i think it's better to not include serialization logic in the response object. it tends to hide some of the details like byte buffer allocation that we might want to control at another level.",0,0.9809162020683289
504295874,9103,hachikuji,2020-10-13T22:31:40Z,same here. we can return `bytebuffer` and leave parsing to higher layers.,0,0.9935200810432434
504298663,9103,hachikuji,2020-10-13T22:39:21Z,"it is strange to couple the serialization of the principal with the version of the envelope request. this might help us in the case of default principal builder, but users with their own custom builder are on their own, right? i think it is better to be consistent and always leave versioning to the principal builder.",0,0.687843382358551
504298879,9103,hachikuji,2020-10-13T22:39:55Z,nit: maybe print `forwardingprincipal` only if it is defined,0,0.9936667084693909
504300234,9103,hachikuji,2020-10-13T22:43:56Z,do we have a use case for this yet? i don't see that it gets used anywhere.,0,0.9687733054161072
504327985,9103,abbccdda,2020-10-14T00:12:51Z,i guess there are some inconsistency between different rpcs as i spotted cases excluding none. i would initiate a separate jira for the cleaning and revert the change here.,0,0.9405698776245117
504345664,9103,abbccdda,2020-10-14T01:19:44Z,"not yet, could be removed.",0,0.9870136380195618
504408633,9103,abbccdda,2020-10-14T05:23:43Z,"the tricky thing here is that if we handle the api version constraints on the broker side, it means we need to either make changes directly to the returned apiversionsresponse or spawn a new instance with applied constraints. that means leaking of the internal architecture of apiversionsresponse to the broker level and redundant conversions imho. the current approach makes sure the broker level logic is clean with only the necessity of passing the ibp number.",0,0.9859850406646729
505765664,9103,hachikuji,2020-10-15T18:47:39Z,what is the benefit of using a different error code instead of `cluster_authorization_failure`?,0,0.9925064444541931
505768901,9103,hachikuji,2020-10-15T18:53:21Z,"i believe we need to set `requiresdelayedallocation` for this api. typically we will release the underlying buffer allocated for a request when `requestchannel.request` is constructed. however, since we are using ""zerocopy,"" we need to hold onto the `bytebuffer` reference until the api has been handled.",0,0.9946703314781189
505798234,9103,hachikuji,2020-10-15T19:47:58Z,"it seems like we're trying to reuse this handler from the previous patch, but i'm not sure it still makes as much sense. a simpler structure might be something like the following: [code block]",0,0.9411932826042175
505842904,9103,abbccdda,2020-10-15T20:56:55Z,"`cluster_authorization_failure` normally indicates a client side security configuration error. we intentionally define a separate error code to let admin know that there is some security config trouble with the brokers, not the clients.",0,0.9919664859771729
505852939,9103,abbccdda,2020-10-15T21:08:41Z,i think we do have that logic enforced by setting `zerocopy` to true for request data field in the rpc json.,0,0.9873009920120239
509528009,9103,hachikuji,2020-10-21T18:01:43Z,not sure i follow. all current inter-broker apis are gated by `clusteraction` and will return `cluster_authorization_failure` if the principal does not have access. there is no distinction between clients and brokers. it's not clear to me why we need something different here.,0,0.7255039811134338
509533968,9103,hachikuji,2020-10-21T18:06:33Z,"rather than assuming highest supported version, we should include the version in the serialized data. the simple thing would be to write the version first, then write the payload.",0,0.9942302703857422
509537587,9103,hachikuji,2020-10-21T18:09:44Z,nit: can we move this back to where the request parsing logic is. otherwise it becomes a bit hidden.,0,0.9522945880889893
509538545,9103,hachikuji,2020-10-21T18:10:43Z,"nit: add braces to all of these methods. even though they are not required, braces make it easier to see the scope",0,0.987139880657196
509540617,9103,hachikuji,2020-10-21T18:12:56Z,nit: use `match`,0,0.9927911758422852
509541377,9103,hachikuji,2020-10-21T18:13:43Z,nit: use `match`,0,0.9927911758422852
509545893,9103,hachikuji,2020-10-21T18:19:31Z,nit: this is misaligned. it might be better to pull the body here into a separate method (e.g. `parseenveloperequest`),0,0.7613056898117065
509550124,9103,hachikuji,2020-10-21T18:24:02Z,"we should have a check at the beginning of `handle` to restrict the ""forwardable"" apis.",0,0.9947934746742249
509550802,9103,hachikuji,2020-10-21T18:24:48Z,"we use 'forward' and 'redirect' interchangeably throughout the pr, but the names do suggest different behavior. in my mind 'redirection' suggests that we are telling the client to go somewhere else, while 'forward' suggests that the broker is passing the request through to its destination. so maybe we can stick with 'forward' consistently (e.g. `isforwardingenabled`)?",0,0.9940809607505798
509553533,9103,hachikuji,2020-10-21T18:28:14Z,"as mentioned above, you can see the rest of the cases in this class where we check cluster_action and they all return `cluster_authorization_failure`.",0,0.9932963252067566
509555177,9103,hachikuji,2020-10-21T18:29:41Z,nit: you can just use `channel.principalserde.asscala`,0,0.991696834564209
509562013,9103,hachikuji,2020-10-21T18:35:40Z,"we want to avoid this serialization since it introduces the possibility for the request to be altered by the forwarding broker. the `requestchannel.request` object retains the reference to the original buffer, which we can use here, but we need to tell the channel to delay releasing the buffer using `apikeys.requiresdelayedallocation` for all of the ""forwardable"" apis.",0,0.9927132725715637
509565018,9103,hachikuji,2020-10-21T18:38:58Z,use `defineinternal`,0,0.9898143410682678
509565555,9103,hachikuji,2020-10-21T18:39:36Z,how about `enable.metadata.quorum`?,0,0.9938982725143433
509645115,9103,abbccdda,2020-10-21T20:09:07Z,had a try but it seems java optional doesn't have an `asscala` option,0,0.9807509183883667
509670268,9103,abbccdda,2020-10-21T20:31:29Z,sounds good.,1,0.9417163729667664
510533897,9103,hachikuji,2020-10-23T00:37:04Z,you probably need the following: [code block],0,0.9899925589561462
510536894,9103,hachikuji,2020-10-23T00:49:41Z,"i was thinking a little bit about this and trying to decide if the envelope request should have a more literal representation of the client ip address. the way it is working right now, it looks like the following: 1) use `socket.getinetaddress` to populate `requestcontext.clientaddress`. 2) use `inetaddress.gethostname` to populate the `clienthostname` field in the envelope request. this will do a reverse dns lookup based on the ip address from 1). 3) now we send `clienthostname` over the wire. it gets unpacked here by doing a dns lookup to get to the `inetaddress` object. so it seems we should be skipping the dns translation and just using the ip address from 1). the `inetaddress` class gives us `getaddress` and `gethostaddress`. the first provides the raw byte representation of the ip address, while the latter provides a textual representation. i am thinking we should use `getaddress` and let this field be represented as bytes. what do you think?",0,0.9874529242515564
510540720,9103,hachikuji,2020-10-23T01:06:42Z,"can we move some of the checks from `maybeforward` here? this is the flow i'm thinking about: 1. first check authorization => cluster_authorization_failure 2. verify forwarding is enabled => invalid_request 3. verify the api is forwardable => invalid_request if all of these pass, then the request continues down the normal handling path.",0,0.992295503616333
510552124,9103,hachikuji,2020-10-23T01:56:06Z,"quotas are one aspect of this work that need more consideration. what we don't want is for the inter-broker channel to get affected by the individual client throttle, which is what will happen with the current patch. what i'd suggest for now is that we allow the broker to track client quotas and pass back the throttle value in the underlying response, but we set the envelope throttle time to 0 and ensure that the inter-broker channel does not get throttled. for this, i think we we will need to change the logic in `kafkaapis.sendresponsemaybethrottle`. if it is a forwarded request, we still need to check `mayberecordandgetthrottletimems`, but we can skip the call to `clientquotamanager.throttle`. when the response is received on the forwarding broker, we will need to apply the throttle, which i think the patch already handles. one challenging aspect is how this will affect quota metrics. currently quota/throttling metrics are relatively simple because they are recorded separately by each broker. however, here the controller is the one that is tracking the throttling for the client across multiple inbound connections from multiple brokers. this means that the broker that is applying a throttle for a forwarded request may not have actually observed a quota violation. other than causing some reporting confusion, i am not sure whether there are any other consequences to this. cc",0,0.9894458651542664
510554587,9103,hachikuji,2020-10-23T02:06:38Z,"one challenge we have here is that there are two levels of errors. the current patch seems to conflate the two, which makes it confusing. i think we need a structure which allows us to separate the errors possible at the envelope level and those possible at the request level. what i'm thinking is this: 1. for cluster auth and principal serde errors, we should return the envelope error and null response body. 2. for everything else, we return envelope error none and just pass through whatever error is in the response. does that make sense?",0,0.8556658029556274
510568706,9103,abbccdda,2020-10-23T03:06:57Z,"the question would be how the forwarding broker should do the error handling for auth & principal serde exceptions. to me we should get a vanilla error response with `unknown_server_error` and get back to the original client? besides that, i think we could add a differentiation here to avoid passing the serde-type errors to the client.",0,0.9897153973579407
511007228,9103,abbccdda,2020-10-23T16:39:28Z,"for pt2, if the forwarding is not enabled on the active controller, but it has the capability, should we just serve the request?",0,0.9928350448608398
511012913,9103,abbccdda,2020-10-23T16:49:50Z,so the proposal is simply for saving the unnecessary dns translation? not sure if representing as bytes would also serve the security purpose as well.,0,0.9876647591590881
511872018,9103,rajinisivaram,2020-10-26T10:52:19Z,"i guess the only quota that is affected for the rpcs we currently forward is request quotas. totally agree that we shouldn't throttle inter-broker connections. there are a few other things to consider here: 1) every forwarded request uses network thread and request handler time on two brokers. are we saying that we can ignore the time spent on the forwarding broker because that is negligible? in a deployment with ssl on the external listener and plaintext on the inter-broker listener, there may be more network thread time used on the forwarding broker rather than the controller. do we record these, but use the controller throttle time for throttling? 2) are we changing the semantics of quotas? for example, if a client sends a request1 to leastloadednode a which mutes the connection and then sends request2 to leastloadednode b that happens to be the controller, we would mute that connection too. another client with the same principal would get muted on b, but not a because a's quota hasn't been violated. i think this should be ok, though a bit confusing. 3) are these measures good enough to protect the controller? this is the one that needs some more thought. request quotas are configured to allocate a percentage of thread usage to each principal. our quotas aren't very good at protecting against dos attacks, but they help to limit usage for normal clients using the apis. so if we can make sure the implementation for forwarded requests can handle this case, it would be good enough. in the old world, a client doing a lot of config updates would have just distributed the load across brokers as each node was throttled. now, we distribute the iniital request across brokers as controller decides to throttle. total rate for these requests across the cluster is dramatically reduced because all load is now on the controller. but from the controller broker's point of view, we are now allowing more requests through for the same quota from every client because a client can forward through `n` brokers. may have more context on whether these request types actually hit request quotas in real deployments.",0,0.9840170741081238
513608319,9103,hachikuji,2020-10-28T16:56:18Z,"hmm.. it looks like we do not serialize the response header, but i think we probably should. today it only includes the correlationid, but who knows how it will evolve in the future? since we do serialize the request header, it seems better to be consistent.",0,0.9670002460479736
513612935,9103,hachikuji,2020-10-28T17:02:38Z,"since this is a public api, it's worth documenting that these apis should raise a consistent error, such as `serializationexception`, in case of an error.",0,0.9913973808288574
513613435,9103,hachikuji,2020-10-28T17:03:23Z,nit: for the the purpose of inter-broker forwarding,0,0.9897178411483765
513614262,9103,hachikuji,2020-10-28T17:04:30Z,we may as well add a check here for the version so that we get a useful error in case we receive a version that we do not support.,0,0.9873769283294678
513615916,9103,hachikuji,2020-10-28T17:06:37Z,nit: use upper-case `tokenauthenticated` for consistency with other fields,0,0.9946402907371521
513616503,9103,hachikuji,2020-10-28T17:07:26Z,might be worth mentioning `org.apache.kafka.common.security.authenticator.defaultkafkaprincipalbuilder` explicitly.,0,0.9950088262557983
513617300,9103,hachikuji,2020-10-28T17:08:33Z,perhaps add a little more detail?,0,0.9875898361206055
513619656,9103,hachikuji,2020-10-28T17:11:52Z,"since principals should be small, it is tempting to just use simple byte arrays for this interface. this is typically simpler for users and gives us a stronger boundary between plugin and broker code.",0,0.9779077172279358
513635843,9103,hachikuji,2020-10-28T17:34:28Z,"it looks like these changes made it to 2.7. we need to revert them before the release or it will not be safe to remove them. the danger is that we might use these tag ids for another purpose in the future, which will break the request parsing.",0,0.9591321349143982
513645474,9103,hachikuji,2020-10-28T17:48:22Z,i guess this shows an inconsistency between the envelope and the other inter-broker apis. the throttle time field is only useful if we actually expect the forwarding broker to respect it and backoff. i wonder if we should just be consistent for now and leave this out.,0,0.8366196751594543
513646769,9103,hachikuji,2020-10-28T17:50:11Z,"would it make sense to add a default rule? if the api is forwardable, then we can assert it requires delayed deallocation.",0,0.9940018057823181
513647237,9103,hachikuji,2020-10-28T17:50:49Z,"in fact, the schema doc says that the response header should be included.",0,0.9896043539047241
513648122,9103,hachikuji,2020-10-28T17:52:10Z,it's not clear to me why we need to do this now since we are not enabling forwarding yet.,0,0.9481044411659241
513659883,9103,hachikuji,2020-10-28T18:09:37Z,"hmm.. the request logging will not be too useful if we cannot see what is in the embedded request and response. i think we should print the envelope structures separately. longer term, we should figure out how to incorporate the envelope into [a link]",0,0.7873302102088928
513662914,9103,hachikuji,2020-10-28T18:14:32Z,not sure why this was resolved. i don't see the check. basically the first thing we should do in `handle` is check whether we have an envelope request and if it is authorized.,-1,0.5713838338851929
513667101,9103,hachikuji,2020-10-28T18:21:14Z,"unless the internal config is present, i think we should treat the envelope as non-existing. once we are ready to enable it in the ibp, then we will accept the envelope request even if the local ibp is not high enough.",0,0.9905785918235779
513743473,9103,abbccdda,2020-10-28T20:35:38Z,i think it's ok to remove this flag for now.,0,0.9544901251792908
513750141,9103,abbccdda,2020-10-28T20:48:19Z,"i was under the impression that byte buffer provides more information such as a read position and capacity/limits, which makes the deserialization easier. if given a byte[], i'm afraid they need to convert to byte buffer internally eventually.",0,0.6775021553039551
513757978,9103,abbccdda,2020-10-28T21:02:19Z,"sounds good, will remove the throttle time field from the envelope",1,0.7198486328125
513759802,9103,abbccdda,2020-10-28T21:05:21Z,"sg, but i guess we need to keep it as is for now to try using the correct api version.",0,0.9149045348167419
513826471,9103,abbccdda,2020-10-28T23:44:21Z,"sg, will initiate a pr for that.",0,0.9884034991264343
515212449,9103,hachikuji,2020-10-30T16:11:00Z,"probably the first thing we should check is `isforwardingenabled`. if it is not, i suggest we close the connection, which is basically the broker's way of saying ""i don't know how to handle this.""",0,0.9596652984619141
515215364,9103,hachikuji,2020-10-30T16:16:02Z,can we add a description explaining what this is for?,0,0.9914408922195435
515219198,9103,hachikuji,2020-10-30T16:22:25Z,we should duplicate the buffer instead of modifying it directly.,0,0.9821528792381287
515219726,9103,hachikuji,2020-10-30T16:23:22Z,"we can leave this for a follow-up, but it would be nice if we could avoid this deserialization (and the subsequent re-serialization).",0,0.9658445119857788
515220480,9103,hachikuji,2020-10-30T16:24:37Z,probably useful to explain why we do this. a debug log message with the original error would be helpful as well.,0,0.9487050175666809
515229180,9103,hachikuji,2020-10-30T16:39:03Z,"i think this was one of my initial questions, but do we have a timeout for the request? looking at the current logic in `handleresponse`, it seems like we will just retry indefinitely. that is probably what we want for requests generated by the broker (e.g. `alterisr`), but it is not so useful for client requests since the client itself will eventually give up and send a new request.",0,0.9843592047691345
515230020,9103,hachikuji,2020-10-30T16:40:21Z,nit: can we create a helper for `request.envelopecontext.isempty`? perhaps we can write this as `!request.isforwarded`?,0,0.9953092932701111
515231023,9103,hachikuji,2020-10-30T16:42:03Z,"hmm.. i had assumed we would be using the same channel manager. can you explain why we need two? in the end, i think all of the requests get serialized on the controller, so i'm not sure we're buying much.",0,0.6710041165351868
515245665,9103,hachikuji,2020-10-30T17:04:46Z,"as far as i can tell, the `callback` here is unused. tracing this back to `kafkaapis`, the callback passed to `sendresponsemaybethrottle` also appears to be unused. i think we can remove it from both apis and simplify this a bit.",0,0.992023229598999
515276738,9103,abbccdda,2020-10-30T17:48:18Z,"i agree we don't have a prioritization system on the controller yet, but in long term having two separate managers mean we don't block alterisr unnecessarily, which seems to be definitely a higher priority message. cc",0,0.9740278124809265
515377453,9103,abbccdda,2020-10-30T20:51:51Z,sg,0,0.6295669078826904
515388258,9103,abbccdda,2020-10-30T21:20:47Z,"yea, i think this could be done as a follow-up. filed: [a link]",0,0.9329198002815247
515389068,9103,abbccdda,2020-10-30T21:23:12Z,filed: [a link],0,0.9908856749534607
515395403,9103,abbccdda,2020-10-30T21:41:50Z,got a follow-up ticket as well: [a link],0,0.9285426139831543
515413173,9103,hachikuji,2020-10-30T22:44:52Z,can we use `closeconnection`. we do not want to even acknowledge that the api exists unless forwarding is enabled.,0,0.9701724648475647
515414500,9103,hachikuji,2020-10-30T22:50:24Z,nit: drop parenthesis for simple getter,0,0.9749947190284729
515417787,9103,hachikuji,2020-10-30T23:05:00Z,"this begs the question whether the api should even be advertised from non-privileged listeners if users cannot access it. i am thinking we can make this case similar to the behavior if forwarding is not enabled. here we can use this logic: [code block] similarly, we can change the check in `apiversion.apiversionsresponse` so that it skips the envelope api if the request is not from a privileged listener.",0,0.9924381375312805
515418503,9103,hachikuji,2020-10-30T23:08:15Z,not sure i follow the point about the correct api version.,0,0.8907586932182312
515421189,9103,hachikuji,2020-10-30T23:21:24Z,"i think this logic still conflates the envelope error and the inner response error. we might catch an exception raised from `validateforwardrequest` or from the request handler in `kafkaapis.handle`. both paths flow through `kafkaapis.handleerror`, so we do not have a way to distinguish the two cases. this means that an uncaught error from the underlying request will get sent back to the forwarded broker as an error in the envelope, which will cause us to translate it to unknown_server_error. i think we should handle envelope errors explicitly through a separate method. we can define a method here such as `buildfailedenvelope` which can be used inside `validateforwardrequest`. then inside `buildresponse` here, we can always return `errors.none` as the envelope error.",0,0.9774328470230103
515421553,9103,abbccdda,2020-10-30T23:23:16Z,"it's a bit tricky to do it here since we rely on exception catching to skip all the rest of handling logic, not sure it is worth to add this special case and do `if-else` to incur a large code change.",-1,0.7552390098571777
515427912,9103,hachikuji,2020-10-30T23:57:37Z,"perhaps it is obvious, but this logic does not give us any tight guarantees that the request will actually be handled by the broker that is currently the controller. for example, a new controller might get elected between the check in `validateforwardrequest` and the handler here. that is probably fine at the moment, because the zk logic in `adminmanager` can execute on any broker. if we imagine instead how this will work with the kip-500 controller, i think the incoming request will get put on the controller's queue. by the time the request gets dequeued, we will be able to know for sure whether this node is the controller or not, so we will be able to have a much better guarantee. the only reason i bring this up is that we are currently assuming that the not_controller gets propagated in the envelope error field. we'll have to keep this in mind when we adapt this logic for the new controller.",0,0.9886122345924377
515428385,9103,hachikuji,2020-10-31T00:00:26Z,perhaps we could return a boolean to indicate whether the handling logic should execute. i think it is important to avoid exposing this api until we're ready for it.,0,0.9871019124984741
516344965,9103,hachikuji,2020-11-02T23:57:03Z,nit: seems this change was not needed,0,0.968083381652832
516349664,9103,hachikuji,2020-11-03T00:06:25Z,"nit: i feel `failureexception` is redundant. can we just call it `principaldeserializationexception`? also, i am not sure about this extending `authorizationexception`. i would consider it more of an invalid request than an authorization failure, though the effect is the same. i think it's probably better to avoid categorizing it and just let it extend `apiexception`.",0,0.9483478665351868
516356565,9103,hachikuji,2020-11-03T00:21:28Z,nit: every other property name uses a capital first letter,0,0.9584985971450806
516363883,9103,hachikuji,2020-11-03T00:37:20Z,"it is quite expensive to parameterize these test cases. i am not sure it is worthwhile. if forwarding works for one of these cases, why would the others be different? since we are not planning to enable this feature yet, i think unit tests in `kafkaapistest` and maybe one integration test are good enough.",0,0.8853654861450195
516364497,9103,hachikuji,2020-11-03T00:38:40Z,i think it would be simpler to short-cut return. [code block],0,0.9801919460296631
516365803,9103,hachikuji,2020-11-03T00:41:17Z,nit: `validatedforwardedrequest`,0,0.9813259840011597
516366191,9103,hachikuji,2020-11-03T00:42:10Z,"nit: we are doing more than building the response here, we are sending it. how about `sendfailedenveloperesponse`?",0,0.9400168657302856
516372020,9103,hachikuji,2020-11-03T00:54:27Z,"nit: instead of `original`, could we use `forwarded` in these names?",0,0.9949877262115479
516373262,9103,hachikuji,2020-11-03T00:56:55Z,nit: define return type,0,0.9850097298622131
516375303,9103,hachikuji,2020-11-03T01:00:58Z,can you add a javadoc for these methods and mention ` serializationexception`?,0,0.9938644766807556
516378459,9103,hachikuji,2020-11-03T01:09:12Z,"hmm, not sure i get your point. nothing is simpler than a byte array. the main question is whether we want to expose the actual request buffer to the plugin, especially since we still plan on using it afterwards. the plugin is treated as a trusted component in any case, so it might not make a big difference. probably we should optimize here for simplicity. that may or may not be true. if it is, users can just use `bytebuffer.wrap`.",0,0.9321306347846985
516381090,9103,hachikuji,2020-11-03T01:19:18Z,nit: `network` prefix is not needed since we are already in this package,0,0.9896429777145386
516933194,9103,hachikuji,2020-11-03T20:20:55Z,"this inherits all tests from `dynamicbrokerreconfigurationtest`, which doesn't look to be intended. can we just remove it? we can add it back once we get to testing the ssl path changes. for now i think the simple integration test for createtopics is good enough. (by the way, it's curious that `testtruststorealter` still passes even after we have removed the path update logic.)",0,0.9831027388572693
516933962,9103,hachikuji,2020-11-03T20:22:34Z,do we need this change anymore?,0,0.9897213578224182
516934696,9103,hachikuji,2020-11-03T20:24:08Z,i don't think we want to make this the default until we are ready to enable it. i would suggest we create a new `forwardrequesttest` which extends `baserequesttest`. then we can move the test case from `createtopicsrequesttest`.,0,0.9894876480102539
516938814,9103,hachikuji,2020-11-03T20:32:19Z,nit: is this change needed?,0,0.9868229627609253
516942223,9103,hachikuji,2020-11-03T20:39:33Z,is this change needed? i am not sure i follow the comment about the privileged listener. that shouldn't affect acls i think.,0,0.9153667092323303
516950684,9103,abbccdda,2020-11-03T20:56:53Z,seems ok to remove,0,0.9778627157211304
516951766,9103,abbccdda,2020-11-03T20:59:06Z,"yea, that's weird, let's move to the next pr for a discussion.",-1,0.9832330346107483
37318079,132,hachikuji,2015-08-18T16:09:35Z,"4,2,0?",0,0.9895575642585754
37320190,132,hachikuji,2015-08-18T16:28:11Z,it might make this code a little easier to follow if you split the rack-aware and default assignments into separate functions. what do you think?,0,0.9881497621536255
37323035,132,hachikuji,2015-08-18T16:52:26Z,maybe getinversemap instead?,0,0.9937639832496643
37441970,132,allenxwang,2015-08-19T17:24:41Z,"it will be difficult to separate them out as they actually share quite a lot of common logic, specifically around choosing the leader of the partition. the code change may seem a lot but actually very little for the default assignment algorithm other than changing the name of `brokerlist` to `arrangedbrokerlist`. i can try separate out the logic of choosing followers into different functions for default vs. rack aware assignment and see how it looks like.",0,0.9676850438117981
37442156,132,allenxwang,2015-08-19T17:26:15Z,that's correct. will fix.,0,0.958560585975647
37442594,132,allenxwang,2015-08-19T17:30:10Z,sure.,0,0.9664214849472046
37448769,132,hachikuji,2015-08-19T18:19:45Z,"yep, there would probably be some redundancy, but at least the default path would be uncluttered with all the rack-aware logic. i don't think it's too bad as it is, but clearer separation would be nice if possible.",0,0.9215008020401001
49287039,132,joestein,2016-01-11T02:48:05Z,"can you add some negative testing please, folks do weird and odd things in their properties by accident and we want to guard against that too, etc",-1,0.9559323787689209
49287098,132,joestein,2016-01-11T02:50:07Z,"something about the scala of this makes me want to say it should be an implicit, that is a much bigger topic and change so i would say maybe not introduce that now but here is one of a lot of places we could without losing readability or performance reduce code. maybe even try it with this change as your converting type only in raclocator",0,0.9518106579780579
49287153,132,joestein,2016-01-11T02:52:34Z,rack-locator might be a bit confusing to the user when just coming and looking at the new command / api changes in a release. why not rack-aware or rack-placement-class (keep the simplaracklocator class as is) and then rack-placement-properties? or something of the sort?,0,0.8927904367446899
49287181,132,joestein,2016-01-11T02:53:34Z,what/why are we ignoring here? not looking at entire class just seeing the diff hard to say if this makes sense or not to ignore,0,0.8071898221969604
54477992,132,hachikuji,2016-02-29T21:08:46Z,nitpick: maybe should be rack_key_name for consistency?,0,0.9908207058906555
54478309,132,hachikuji,2016-02-29T21:10:57Z,"also, the comment doesn't add much. maybe you can just relocate under ""endpoint key name""?",0,0.9913942217826843
54489948,132,allenxwang,2016-02-29T22:26:45Z,"i don't think rack belongs to endpoint. it is the same level as ""endpoint"" as indicated in the json format of broker in zookeeper and updatemetadatarequest protocol. a broker can have multiple endpoints but only one rack.",0,0.9896565675735474
54490437,132,hachikuji,2016-02-29T22:30:12Z,"yep, you are right. guess it would make sense for it to go under broker key names then?",0,0.8764609098434448
54498311,132,allenxwang,2016-02-29T23:28:28Z,sounds good.,1,0.9417163729667664
54592298,132,granthenke,2016-03-01T16:26:46Z,do we need to support null? would empty string work well enough and avoid null checks throughout the code?,0,0.9932194352149963
54592311,132,granthenke,2016-03-01T16:26:50Z,related to my protocol question above. would defaulting to empty string work?,0,0.9914500117301941
54592316,132,granthenke,2016-03-01T16:26:51Z,could use the constructor that doesn't take a rack.,0,0.9873048663139343
54592322,132,granthenke,2016-03-01T16:26:53Z,could use the constructor that doesn't take a rack.,0,0.9873048663139343
54592337,132,granthenke,2016-03-01T16:26:58Z,is brokerlist used here?,0,0.9933131337165833
54592349,132,granthenke,2016-03-01T16:27:03Z,seams i may need to use this in kip-4. which means it would need to live in the clients library under the common package. could this be a java enum there?,0,0.9942039847373962
54592380,132,granthenke,2016-03-01T16:27:09Z,is this includerack boolean used anywhere?,0,0.9928725957870483
54592390,132,granthenke,2016-03-01T16:27:10Z,is this includerack boolean used anywhere?,0,0.9928725957870483
54592404,132,granthenke,2016-03-01T16:27:15Z,are there unsafe characters that could be in the rack string that would break the json read/write?,0,0.9854692816734314
54624794,132,hachikuji,2016-03-01T19:52:38Z,is this only public for testing? would protected or default also work?,0,0.9938307404518127
54627527,132,hachikuji,2016-03-01T20:10:36Z,"would ""safe"" be a better default? looks like the default is only used in test cases, so maybe it would be better to always require the argument?",0,0.9921951293945312
54645170,132,allenxwang,2016-03-01T22:13:58Z,"broker.sizeinbytes() and broker.writeto() was used for serialization and deserialization of updatemetdatarequest when i started the pr. that's why i have to add includerack parameter for version compatibility. it was recently changed to use the java code in kafka.common for this. but broker.readfrom and broker.writeto remain in the code. so i am not sure if they are still needed. if not, we can delete this part of code all together.",0,0.9907442927360535
54645719,132,allenxwang,2016-03-01T22:17:44Z,"i am not sure. this is only used when replica assignment is needed. if the only change in client library is to be able to access rack in topicmetadatarequest/response, then this can stay in scala in kafka.admin.",0,0.9193108677864075
54645900,132,allenxwang,2016-03-01T22:18:59Z,i would think any character is fine.,0,0.9624637365341187
54646069,132,granthenke,2016-03-01T22:20:14Z,topiccommand is taking this as a parameter when creating a topic. assuming the options is important. when createtopic calls go through the broker i will need to pass this option in the request.,0,0.9930267333984375
54646230,132,allenxwang,2016-03-01T22:21:21Z,"no, it is used in controllerchannelmanager and has to be public.",0,0.9878479242324829
54648019,132,allenxwang,2016-03-01T22:33:44Z,"""safe"" is only used in auto topic creation. in command line tools, we would like to be strict about using rack (to catch mis-configured rack) unless the user wants to disable it. this was discussed in kip process. the reason to make this argument optional is that in most cases, user would supply rack for all brokers or no rack for any broker which can be handled automatically in ""enforced"" mode. then createtopic can remain the same signature so that caller of this method does not need to be concerned about rack aware.",0,0.9943675398826599
54648159,132,allenxwang,2016-03-01T22:34:44Z,sure.,0,0.9664214849472046
54649101,132,allenxwang,2016-03-01T22:43:27Z,i discussed this in kip discussion. nullable_string was recommended in the discussion. i think it makes sense as rack itself is designed to be nullable (option[string]). it is legal to define rack as an empty string. there isn't really any null checks in the code as far as i can tell. null just means no rack is defined.,0,0.9807021021842957
54649841,132,hachikuji,2016-03-01T22:49:22Z,"is that because we're depending on this constructor for version 1? i know we depend on choosing the right constructor in other request objects to get the right version, but i wonder if it would be better to have explicit static factory methods (e.g. `updatemetadatarequest.createv0()`)?",0,0.9913948178291321
54649887,132,allenxwang,2016-03-01T22:49:41Z,it's not. i will remove it.,0,0.9795899391174316
54650027,132,granthenke,2016-03-01T22:50:37Z,"i checked the java doc for `json.encode`. it says `this method does not properly handle non-ascii characters.` i am not sure how ""bad"" it fails. some basic limitations/validation on available rack characters and length might help prevent unforeseen issues. something similar to the limitations for a topic name maybe.",0,0.8120514750480652
54663838,132,allenxwang,2016-03-02T00:57:52Z,"if topic creation is available from clients, then we need to pass rackawaremode in the request. in that case i agree this class should be in common package as enum. do you want me to make this change? does the protocol support enum?",0,0.9922749400138855
54664542,132,allenxwang,2016-03-02T01:06:12Z,"we depend on this constructor to create version 1 and 2 updatemetadatarequest, and possibly for future versions as well.",0,0.9905967712402344
54667264,132,hachikuji,2016-03-02T01:39:53Z,fair enough. i was only wondering if there was a way to keep the version better encapsulated (like all of the other requests). perhaps at least there should be a check on the version to make sure it is greater than 1? i might even enforce only version 1 and 2 since we'll almost certainly have to touch this code anyway if there is another version bump.,0,0.8719251751899719
54668363,132,hachikuji,2016-03-02T01:53:29Z,"makes sense, thanks.",1,0.7218227386474609
54807092,132,allenxwang,2016-03-02T22:53:29Z,"i will add the check for version. i believe 0 is still supported so 0, 1 and 2 should be allowed.",0,0.9855473041534424
54811738,132,hachikuji,2016-03-02T23:30:47Z,"actually it's probably fine as it is since we would raise an error in `protoutils.requestschema()`. i didn't notice that this also supports version 0, so would it make sense change controllerchannelmanager to use this constructor for all cases. (and apologies for all this nitpicking)",0,0.660426914691925
54812799,132,ijuma,2016-03-02T23:39:22Z,"by the way, for a bit of history, i initially proposed having a single constructor with a version when i introduced this class. however, preferred having separate constructors with all, but the most recent version deprecated.",0,0.9831704497337341
54813357,132,hachikuji,2016-03-02T23:44:08Z,i think my preference would probably be to have static factory methods with the versions included in the name. using constructors is kind of annoying because you have to check the comment to make sure you get the right one.,-1,0.9649166464805603
54813814,132,ijuma,2016-03-02T23:48:37Z,"yeah, we should use more static factories and less overloaded constructors in kafka.",0,0.9891993403434753
54815295,132,allenxwang,2016-03-03T00:02:35Z,"i don't really know what would be the valid characters or length limit for rack. looking at the implementation of json.encode() there is nothing suspicious how characters are handled. note that in some cases, rack can be a logical name and used for grouping brokers for fault tolerance. so any character is possible. apache cassandra does not seem to do any validation on rack name for their property file based configuration. if there is no specification or usual convention for the rack name, i suggest we leave it unchecked.",0,0.8294125199317932
54817202,132,allenxwang,2016-03-03T00:22:24Z,would you mind if i leave this code refactoring of constructors to you guys?,0,0.9705542325973511
54817893,132,ijuma,2016-03-03T00:28:21Z,fine by me.,0,0.7648894190788269
54817929,132,hachikuji,2016-03-03T00:28:39Z,ditto,0,0.9222367405891418
54838116,132,junrao,2016-03-03T05:41:11Z,could we fix the alignment?,0,0.9908056855201721
54838129,132,junrao,2016-03-03T05:41:23Z,alignment,0,0.9156739115715027
54838137,132,junrao,2016-03-03T05:41:37Z,we should probably mark this as deprecated.,0,0.9730610847473145
54838143,132,junrao,2016-03-03T05:41:40Z,an -> a,0,0.9433128833770752
54838189,132,junrao,2016-03-03T05:42:43Z,"by leader, do you mean preferred leader? the first replica is not always the leader. perhaps it's clearer to just refer to them as 1st replica, the rest of replicas, etc.",0,0.9862062335014343
54838197,132,junrao,2016-03-03T05:42:53Z,would it be better to combine brokerlist and rackinfo and pass in a seq of brokermetadata that includes id and rack?,0,0.995236337184906
54838204,132,junrao,2016-03-03T05:43:00Z,can reversemap(rack).toiterator just be list.toiterator?,0,0.990984320640564
54838213,132,junrao,2016-03-03T05:43:13Z,could we use case instead of tuple to make it clearer? ditto below.,0,0.9917029738426208
54838217,132,junrao,2016-03-03T05:43:17Z,should we sort the broker list per rack?,0,0.9933717250823975
54922060,132,allenxwang,2016-03-03T18:16:50Z,"rackinfo here can be different from the actual broker-rack mapping. in case some brokers have rack and some brokers do not have rack, adminutils.getbrokersandrackinfo() will modify the mapping depending on how strict we want to be rack aware. it will also return empty map if user does not want rack aware. i think it is better to have higher level api (like createtopic()) to be influenced by the rack aware mode depending on the situation and user input and leave this assignment api free of that influence.",0,0.9872999787330627
54928901,132,junrao,2016-03-03T18:59:57Z,"we will still need a separate constructor for v1 of updatemetadatarequest since in controllerchannelmanager, we may need to send a v1 request depending on inter.broker.protocol.",0,0.993915855884552
54928926,132,junrao,2016-03-03T19:00:07Z,"now that we are returning the assignment, it's a bit weird to print the assignment to stdout. perhaps we should let the caller do that.",-1,0.979113757610321
54928999,132,junrao,2016-03-03T19:00:36Z,"it seems that readfrom and broker.writeto are only used in tests now since the serialization of updatemetadatarequest is based on the one in o.a.k. instead of maintaining the logic here, could we just remove readfrom and broker.writeto and the corresponding test code?",0,0.995664656162262
54929005,132,junrao,2016-03-03T19:00:38Z,unused import,0,0.9524969458580017
54929073,132,junrao,2016-03-03T19:01:01Z,we will need to construct v1 and v2 request using different constructors. see comment in updatemetadatarequest.,0,0.9931356906890869
54929083,132,junrao,2016-03-03T19:01:05Z,unused import,0,0.9524969458580017
54929093,132,junrao,2016-03-03T19:01:10Z,unused import,0,0.9524969458580017
54929109,132,junrao,2016-03-03T19:01:19Z,could we add the new params in the comment above?,0,0.9899259805679321
54929134,132,junrao,2016-03-03T19:01:27Z,this seems to be an expensive way to test auto topic creation since it needs to start a cluster. could we just test adminutils.assignreplicastobrokers() directly?,0,0.9752203822135925
54929143,132,junrao,2016-03-03T19:01:32Z,do we need to start zk for this test?,0,0.9936947226524353
54929192,132,junrao,2016-03-03T19:01:42Z,is this useful since none of the 3 verifications are enabled by default. ditto below.,0,0.9701325297355652
54929198,132,junrao,2016-03-03T19:01:45Z,unused import,0,0.9524969458580017
54929228,132,junrao,2016-03-03T19:01:50Z,"should those comments starting with ""ensure"" be here?",0,0.9941393136978149
54929246,132,junrao,2016-03-03T19:01:56Z,do we need to start zk in this test? it seems that we can just test adminutils.assignreplicastobrokers() directly?,0,0.9951334595680237
54929251,132,junrao,2016-03-03T19:02:00Z,similar to the above. do we need to start zk in this test? it seems that we can just test adminutils.assignreplicastobrokers() directly?,0,0.9951633214950562
54937233,132,allenxwang,2016-03-03T19:51:18Z,do you suggest using a case class to represent the tuple?,0,0.9930374026298523
54937680,132,granthenke,2016-03-03T19:54:04Z,i think just like you did in the map above is good: [code block],1,0.7070042490959167
54954835,132,ijuma,2016-03-03T21:54:00Z,"the kip says: `case class broker(id: int, endpoints: map[securityprotocol, endpoint], rack: option[string] = none)` i prefer how you have it here, but we should update the kip.",0,0.9928668737411499
54955136,132,ijuma,2016-03-03T21:55:52Z,yes and the kip should be updated to remove the point about updating `broker.writeto`.,0,0.9923452734947205
54971611,132,allenxwang,2016-03-04T00:15:15Z,"i think we can use the same constructor for both v1 and v2 except for the version number. when the request is serialized, the rack in v1 request is ignored according to protocol. in other words, regardless v1 or v2, we can have rack in updatemetadatarequest.broker and have it handled differently only at serialization. see the updated test requestresponsetest where i added the test for v1 request to make sure it still works.",0,0.9910321831703186
54971962,132,allenxwang,2016-03-04T00:19:06Z,this may not be necessary. see my comment in controllerchannelmanager.,0,0.9924688935279846
54972661,132,junrao,2016-03-04T00:26:36Z,"yes, you are right.",0,0.7251467108726501
54974078,132,allenxwang,2016-03-04T00:41:59Z,the only caller is main(). i feel it is little bit over stretched to print from main or create another function just to print the result.,0,0.9078906178474426
54974433,132,allenxwang,2016-03-04T00:45:54Z,will update the kip,0,0.9845832586288452
54974451,132,allenxwang,2016-03-04T00:46:04Z,will update the kip,0,0.9845832586288452
54977110,132,allenxwang,2016-03-04T01:10:56Z,"we have unit tests for adminutils.assignreplicastobrokers() that does not require starting a server. however, since the logic that governs the rack aware mode is separate from adminutils.assignreplicastobrokers(), we need to have tests to make sure the right api is called from kafkaapi. the behavior we need to test is - if all brokers have rack, rack aware assignment will be generated - if some brokers have rack and some do not, it will be treated as none of the brokers have rack",0,0.9928826093673706
54978198,132,allenxwang,2016-03-04T01:24:05Z,there is a test case (testgetbrokersandracks) testing the behavior of what broker-rack mapping should be used under different rack aware mode.,0,0.9938617944717407
54980762,132,allenxwang,2016-03-04T01:54:08Z,it is a bug that by default the three verifications are disabled. i will fix it.,0,0.6898031234741211
54981583,132,allenxwang,2016-03-04T02:06:34Z,"it ensures that user can disable rack aware in the command line in topiccommand and the reassignpartitioncommand can generate the assignment which is rack aware, if user does not disable rack aware when running reassignpartitioncommand.",0,0.9957171082496643
54981885,132,allenxwang,2016-03-04T02:11:04Z,"this covers the situation where replica assignment is rack aware for alter operation. again, i added this test since user input in the command line can change how rack aware is enforced.",0,0.992048442363739
54983632,132,allenxwang,2016-03-04T02:38:55Z,"given the comment from that the old constructor should be deprecated, i think it is better to use the new constructor.",0,0.9842756986618042
54996851,132,granthenke,2016-03-04T07:08:34Z,works for me,0,0.9660178422927856
54997151,132,granthenke,2016-03-04T07:13:12Z,the way protocols support enum is via some id field. examples can be seen in existing enums and my kip-4 prs: [permissiontype.java ]([a link],0,0.9927411079406738
55029807,132,ijuma,2016-03-04T13:35:25Z,note that this constructor is only used in tests. does it even make sense to keep it?,0,0.9881860017776489
55030014,132,ijuma,2016-03-04T13:37:23Z,"this constructor is only used in tests, does it make sense to keep it? i guess the question is whether the request classes are api. as i understand, they are not, but i would like to get 's take.",0,0.9595020413398743
55031610,132,ijuma,2016-03-04T13:52:14Z,"can you please elaborate why you think it's not good to move the println to `main`? in fact, that is exactly what was done in the following pr that adds some tests to the reassign partitions command: [a link]",0,0.9907799363136292
55032389,132,ijuma,2016-03-04T14:00:22Z,"i think it would be good if we could elaborate a little more on the purpose of this property (with some brief examples, maybe).",0,0.9474454522132874
55033837,132,ijuma,2016-03-04T14:14:35Z,"we say that we register the v3 format including rack, but the code only adds the rack if `apiversion >= 3`. if we follow the same approach as what we did with v2, we should always add the rack as it will simply be ignored if `version < 3`, right?",0,0.9939275979995728
55033946,132,ijuma,2016-03-04T14:15:36Z,"also, the documentation here isn't accurate as we may register `v2` depending on the value of `apiversion`.",0,0.9873853921890259
55075041,132,allenxwang,2016-03-04T19:16:21Z,"do you really need to serialize rackawaremode from the client side? if you want to send a request to broker to create topic, the only thing related to rack aware is whether you want to disable it. and you can send a string for this purpose like the ''--disable-rackaware"" command line option, right?",0,0.9939806461334229
55075472,132,granthenke,2016-03-04T19:19:51Z,"why send a string and translate it in 2 places, with 2 pieces of logic, if instead i can have 1 common enum that lets me send a small byte and ensure translation is the same on both sides. my understanding is this is not a boolean choice but there are 3 values to pick from. i have not spent enough time digging into rackawaremode and if its really required, but if i need to use it to communicate to a broker it should be in the clients code.",0,0.9584601521492004
55076734,132,allenxwang,2016-03-04T19:29:16Z,it is more of a style issue. i noticed that most of the command class' `main` does not have println. the above pr refactored the `generatedassignement` function into two and there is no println in main. i am fine with this approach.,0,0.9728534817695618
55082237,132,ijuma,2016-03-04T20:09:58Z,"that's fine too. the main aim is to keep the method that returns a value without `println` so that it can be tested without polluting the logs, for example.",0,0.9876740574836731
55082518,132,ijuma,2016-03-04T20:12:28Z,"are you suggesting that `safe` mode would not make sense in this context? if so, then i agree that this enum would not make sense in `common`.",0,0.9918100237846375
55083450,132,allenxwang,2016-03-04T20:20:07Z,i will update the document. i think it is safer not to register the rack when version < 3 and having rack in v2 violates the specification anyway which might be confusing to users.,0,0.9521530270576477
55084318,132,ijuma,2016-03-04T20:27:37Z,"ok, i think this has been discussed before and i apologise for asking again. why do we need to write v2 at all? with the exception of 0.9.0.0, the parsing code reads any version and ignore fields that it doesn't know about, right? is it to make it possible to upgrade from 0.9.0.0 (even if that will break old clients anyway)?",-1,0.8064936995506287
55088095,132,junrao,2016-03-04T21:00:54Z,"i think the reason that we have to design the broker registration json in a backward compatible way is that the old consumer and admin tools still read the json directly. once we deprecate the old consumer and move the admin tools to the admin api, only the brokers need to read the json. then, potentially we can make non compatible json changes as long as the broker writes the json according to inter.broker.protocol. for example, we make want to clean up the redundant host field in the future. so, it is true that at this moment, we can always write the latest version of the json that the broker understands since the change is backward compatible. however, following the inter.protocol convention is probably what we want to do in the future. so, we may want to just start doing this now.",0,0.9910953044891357
55088361,132,allenxwang,2016-03-04T21:03:37Z,safe mode is currently only used for auto topic creation. it is not used for command line tools. i think it is better for you guys to do the necessary changes when implementing the client side code since i cannot verify the changes i make here will work for clients in the future. and it will be more efficient to do this later since there might be unforeseen problems or design changes arise when client code is implemented.,0,0.9813081622123718
55088556,132,granthenke,2016-03-04T21:05:20Z,i am okay with that.,0,0.8253441452980042
55095191,132,ijuma,2016-03-04T22:00:10Z,"thanks for explaining. if we want to do it this way, i think we need to add a comment explaining it because it's not obvious and it's inconsistent with how we did the v1 to v2 change. having said that, i am not sure if it's worth doing this now for the following reasons: - it will probably be a long time before we can actually drop support for the old consumer and admin tools in the broker (i think 3 non-bug fix releases is the absolute minimum, but it will probably be longer) - it's inconsistent with how the parser code works (for compatibility as you mentioned). without changing the parser code, older brokers will break if we suddenly remove fields. - it doesn't seem to buy us anything in terms of what gets stored (people will bump inter.broker.protocol as part of the upgrade and then v3 will be stored anyway) for the time when we want to delete fields. it seems to me that when we have a concrete plan to clean this up, we can add the necessary code for both writing and parsing. it will probably take a few releases before we can actually delete the fields, but that's probably ok.",0,0.8543758988380432
55098730,132,junrao,2016-03-04T22:27:05Z,": yes, we can probably just write the v3 json for now and clean things up later.",0,0.9880748391151428
55102385,132,allenxwang,2016-03-04T23:02:57Z,one thing i want to add is that we have to write v2 when protocol is 0.9.0.x because of kafka-3100. having rack in v2 version is probably fine but i don't see any benefit of doing that.,0,0.9848634600639343
55103536,132,ijuma,2016-03-04T23:16:52Z,"right, so that was my original question, this helps with people who want to upgrade brokers from 0.9.0.0 to 0.10.0.0, right? that's a fair argument and worth mentioning in the code. with this approach, only old clients have to go to 0.9.0.1 before the 0.10.0.0 upgrade. brokers can go straight from 0.9.0.0 to 0.10.0.0 (provided that they do the inter.broker.protocol dance).",0,0.923868715763092
55106909,132,allenxwang,2016-03-05T00:00:19Z,ok. i like that approach too and it will simply my junit tests. i will borrow that in this pr. you still need to resolve the conflict through in the future.,1,0.9697017073631287
55107138,132,ijuma,2016-03-05T00:03:20Z,sounds good.,1,0.9417163729667664
55187222,132,ijuma,2016-03-07T10:47:20Z,", if we use something like the following, we can still handle the scenarios you describe, right? [code block] i am happy to try this out on a branch to see how it looks. thoughts?",1,0.868016242980957
55188628,132,ijuma,2016-03-07T11:00:54Z,i think we should also update the text around: `there are 2 goals of replica assignment` either we need to add a third goal or we should make it clear that that description is for rack unaware and then explain what the goals are for the rack-aware case.,0,0.9918941855430603
55402888,132,allenxwang,2016-03-08T18:24:57Z,updated the doc. please take a look.,0,0.9652737379074097
55404378,132,ijuma,2016-03-08T18:33:53Z,"looks good, thanks.",1,0.9901825785636902
55487522,132,ijuma,2016-03-09T08:52:56Z,"""notes to clients"" maybe?",0,0.9908032417297363
55488300,132,ijuma,2016-03-09T09:00:44Z,"maybe: ""clients with a zookeeper dependency (old scala high-level consumer and mirrormaker if used with the old consumer) will not work with 0.10.0.x brokers. therefore, 0.9.0.0 clients should be upgraded to 0.9.0.1 before brokers are upgraded to 0.10.0.0.""?",0,0.9953867793083191
55532555,132,granthenke,2016-03-09T15:15:02Z,this is a big deal right? it breaks kafka's backwards compatibility guarantee. it should probably be moved from the performance impact section to the breaking section. is there anything else we can do to fix this? are we sure it does not break 0.8 clients? cc,-1,0.7670474648475647
55534413,132,granthenke,2016-03-09T15:26:22Z,"i went back and looked. i see why its only an issue for 0.9.0.0. its because a change went in that throws an exception for any version > 2 ([a link], where in 0.8.x version isn't even used ([a link]. can we leverage the fact that we are only adding a field, therefore this is a ""compatible"" update that does not require a version bump? that way we stay at version 2, 0.9.0.0 ignores the rack field, and everything works? this should work because all of our json parsing just uses a map[a link] anyway.",0,0.9646381139755249
55536850,132,ijuma,2016-03-09T15:41:09Z,", yes, it is a big deal. your suggestion was discussed in the kip thread, but said that we need to increase the version when we change the format. as i understand it, the idea is to move away from being limited to just adding fields once we stop supporting old clients (but that is a while away in my opinion). thinking more about this, we could also add a new version field and deprecate the old one (which can stay at `2` until we no longer support `0.9.0.0` many years from now) if we really care about having an incrementing version each time we change the format. thoughts?",0,0.8134440183639526
55538191,132,granthenke,2016-03-09T15:49:05Z,"i agree, we don't want to be limited to just adding fields, but when we are just adding fields a version bump may not be required. this patch assumes anything over version 1 will be compatible in the else statement, so even though our goal is being able to remove fields, this patch does not do that. i don't think adding another version makes sense, thats just adding another field to (old) version 2. we can just add the rack field and achieve the same goal.",0,0.9695836305618286
55539640,132,ijuma,2016-03-09T15:57:16Z,"i don't agree that we achieve the same goal. from a storage format documentation perspective, it's easier to track format changes if there is a version associated with them (even when doing compatible changes like adding fields). it is still useful to know when a particular set of fields was added ((in this case it's just a single field, but in others there will be more). yet another way to handle that is to tie the format with `apiversion`. this can be done implicitly or explicitly.",0,0.9845289587974548
55541167,132,granthenke,2016-03-09T16:05:41Z,"i completely agree. versioning the the format is important. it acts as valuable documentation and (when used correctly) can help improve compatibility. let me be clear about my intentions. i am making no comment on the future of zookeeper json compatibility, just this change and its impact to the upcoming release. given that we still, even in this patch, don't support removing fields in future versions. changing the version for that reason is a moot point. therefore the only value the version has is documentation. if we weigh documentation and compatibility for 0.10 and choose documentation, then we can bump the version. if we think compatibility is the most important thing to maintain. that can be solved by keeping the version at 2.",1,0.7107645273208618
55604952,132,junrao,2016-03-09T22:50:20Z,": yes, we could keep version 2 in json. but the the drawback is the following. if we want to support upgrading form 0.9.0.0 to any future releases post 0.10.0, we can't bump the version in json forever. given that (1) versioning the json in zk is useful and (2) the issue in 0.9.0.0 is a bug and relatively few people are using 0.9.0.0 yet, i think it's probably better to change the zk version now, but require people to upgrade from 0.9.0.1.",0,0.989277720451355
55631206,132,granthenke,2016-03-10T03:57:23Z,"in future releases we expect to remove the old scala clients. this means only the brokers will talk directly to zookeeper and this should not longer be an issue. my understanding is the goal of 0.10.0 is to be a ""compatible"" release. future releases may remove other deprecated things and choose to be breaking. i think that's the best time to break here as well. i don't want to push the issue too much. in the end, i am okay with either choice. i just want to be sure we are consciously choosing to break and for good reason.",0,0.580598771572113
55909377,132,junrao,2016-03-12T00:37:13Z,"this doesn't seem to be 100% safe in that we can potentially assign 2 replicas to the same broker. consider the following example. rack : a b a a broker: 0 1 2 3 at some point, we assign the 1st replica to broker 1. suppose that nextreplicashift is 0. we then assign 2nd replica to broker 2. when assigning the 3rd replica, we will be skipping 3 and 0 and assign broker 2 to the 3rd replica again. before we don't have this issue since when assigning replicas other than the 1st, we cycle through the brokers sequentially without skipping. the new logic allows skipping. so, it's possible for us to hit the same broker.",0,0.9713999629020691
55909620,132,junrao,2016-03-12T00:41:32Z,"i still think that this test and adminrackawaretest (except for testgetbrokermetadatas) can still be simplified. for example, if we restructure the code a bit by wrapping assignreplicastobrokers in another helper method that takes the following signature, then we should be able to test all kinds of rack/rackawaremode combinations w/o needing to start broker/zk, right? (brokermetadatas: seq[broker], rackawaremode: rackawaremode, npartitions: int, replicationfactor: int, fixedstartindex: int = -1, startpartitionid: int = -1)",0,0.9890156388282776
55909641,132,junrao,2016-03-12T00:41:38Z,"hmm, what does notenoughpartitions mean?",0,0.5800263285636902
55909658,132,junrao,2016-03-12T00:41:48Z,is filling the same value expensive? would it be more efficient to just iterate each size and do a check?,0,0.9825804829597473
55909701,132,junrao,2016-03-12T00:42:30Z,should we also verify that no two replicas from the same partition are assigned to the same broker?,0,0.9929176568984985
55909718,132,junrao,2016-03-12T00:42:41Z,is there anything special with 12 partitions?,0,0.9869391918182373
55910465,132,ijuma,2016-03-12T00:56:40Z,this is really cheap compared to other things we do in our tests and it gives better error messages.,0,0.6469953656196594
55911136,132,allenxwang,2016-03-12T01:07:54Z,"i don't think that will help from test's perspective. even if we add rackawaremode here, we still need to make sure that for auto topic creation and command line tools (where you can disable rack aware) the right rackawaremode is used. the tests that have dependency on broker/zk make sure no matter how underlying api is structured, the end result is correct. so i think there are values in the tests.",0,0.9875311255455017
55911374,132,allenxwang,2016-03-12T01:12:35Z,i will fix the confusing name. the test makes sure the algorithm works when the number of partition is not multiple of brokers.,0,0.5803526639938354
55911537,132,allenxwang,2016-03-12T01:15:43Z,"probably not. :) in general, these tests run very fast since all they do is operate on collections in memory. so i have not thought about reducing the number of tests.",1,0.995061457157135
55915045,132,allenxwang,2016-03-12T03:23:17Z,that's a very good point. i will address this in my next update.,1,0.9770026206970215
55917767,132,allenxwang,2016-03-12T07:16:04Z,"thinking a little bit more on this, i think this situation is actually covered by the algorithm. in this case, there are three replicas and only two racks. once replicas are assigned to 1 and 2, we know that all racks have replicas for the partition and skipping behavior will stop.",0,0.9741748571395874
55922985,132,junrao,2016-03-12T15:49:24Z,"right, this example actually works. but the following won't. consider the following broker to rack mapping. rack : a b c a a broker: 0 1 2 3 4 let's say you want to have 4 replicas and the first replica is assigned to broker 2. then you assign 2nd replica to 3. then you skip broker 4 and 0 since both are on rack a and not all racks are filled yet. then you assign 3rd replica to 1. finally, you will assign 4th replica to broker 3 again.",0,0.9624075889587402
55929323,132,allenxwang,2016-03-12T23:09:16Z,"yes, i will add that check.",0,0.9791268110275269
55929568,132,allenxwang,2016-03-12T23:31:03Z,excellent example. added the logic to prevent assigning replica twice to the same broker for the same partition.,1,0.99455726146698
55933791,132,ijuma,2016-03-13T08:37:22Z,"nitpick: we don't really need this `assertequals` or the `brokerlist` val since that is checking that `tobrokermetadata` works correctly, which is not the purpose of this test.",0,0.9885514974594116
55933813,132,ijuma,2016-03-13T08:39:50Z,this was probably an accidental reformatting by intellij.,0,0.9684622883796692
55933814,132,ijuma,2016-03-13T08:39:55Z,this was probably an accidental reformatting by intellij.,0,0.9684622883796692
56015924,132,junrao,2016-03-14T15:12:39Z,"only this test needs zk. could we pull this test to a different class and remove the zk dependency from this class? otherwise, each test will unnecessarily start a zk server, which will slow down the test.",0,0.9678510427474976
56016010,132,junrao,2016-03-14T15:13:09Z,could we add an error message in assertequals? ditto in the assertequals below.,0,0.9938496947288513
56053157,132,allenxwang,2016-03-14T18:40:06Z,will do.,0,0.9864637851715088
56054757,132,allenxwang,2016-03-14T18:50:00Z,"i think there is value in checking this to make sure test set up is correct. otherwise if `tobrokermetadata` is changed, there are two possibilities: - test fails and it is difficult to debug why it fails - test passes but is actually weakened",0,0.9841262102127075
56095654,132,ijuma,2016-03-14T23:45:37Z,", we use `tobrokermetadata` in many other tests and we don't check its behaviour in the other cases, so it looks a bit inconsistent. in my opinion, if we want to be sure about its behaviour, we should write a test for it instead of checking its behaviour inside other tests. in any case, this is a very minor point and i'm fine if we leave as is.",0,0.8633028864860535
220379749,5693,vvcephei,2018-09-25T22:47:11Z,"this change (and similar changes below) are to make sure the serdes we need for suppression are available. i sort of thought that we already merged a pr to do this, but perhaps it was only partial.",0,0.9905508756637573
220380552,5693,vvcephei,2018-09-25T22:51:38Z,"i realized belatedly that i missed this (internal) interface when i renamed ""maxkeys"" to ""maxrecords"" in part 1.",0,0.9797155857086182
220380693,5693,vvcephei,2018-09-25T22:52:29Z,this wraps the value so that the buffer can store the whole record context for later forwarding.,0,0.9886718988418579
220381174,5693,vvcephei,2018-09-25T22:55:02Z,"since we don't actually store the value serialized in the in-memory impl, we annotate the value with its size so we can maintain the current footprint of the buffer. alternatively, we could serialize it again on removal to idempotently re-compute its size, but this seemed cheaper.",0,0.9934341907501221
220383032,5693,vvcephei,2018-09-25T23:04:56Z,"this could be configurable in the future, but for now, we enforce the time limit in the following fashion: * start a timer when a key first enters the buffer * that key and its most recent value will be emitted when the time limit expires, regardless of how recently it has been updated the primary advantage of this implementation is that we guarantee that if you set a 5-minute limit, we delay emitting the key for no more than five minutes. if we instead re-set the timer on each update, you might never see a record that gets consistently updated more frequently than the time limit. my judgement was that this is the most intuitive default and starting point for the feature. if people want to configure it, we can easily add that option later.",0,0.9838981032371521
220383454,5693,vvcephei,2018-09-25T23:07:36Z,"as demonstrated by part 1, we don't always need the buffer, so i thought it best to avoid allocating it and scheduling the associated punctuator until we first discover we need to buffer something.",0,0.9830009937286377
220384765,5693,mjsax,2018-09-25T23:15:03Z,why do we need this in `process` -- seem like moving it to `init()` should be sufficient?,0,0.9938791990280151
220385505,5693,vvcephei,2018-09-25T23:19:53Z,"this was the punctuation concern brought up. i haven't optimized this yet because i wanted to discuss the available options first. i'm thinking: 1. store the min timestamp in the buffer to make this function cheap when there's nothing to do 2. schedule just one punctuator for all the buffers. this would require more coordination in the topology builder, and i'm not sure if it would actually yield any benefit. is iterating over buffers any better than iterating over an equal number of punctuators? 3. schedule the punctuator less frequently. this would improve performance for high-frequency topics, but not for medium to low frequency topics. on the downside, it would sacrifice resolution and make the tests a little tricky to reason about. 3a. we could probably make a reasonable approximation of the appropriate resolution based on the suppression time limit, like `min( max(1, suppressduration / 10), 30 seconds)`, or even tie it to the commit interval. 3b. to mitigate the testing problem, we could add a private mechanism to directly set the resolution. (not sure this is needed; would like to see how awkward it is in practice once we decide on some optimizations)",0,0.957645058631897
220385584,5693,mjsax,2018-09-25T23:20:27Z,`suppress.gettimedefinition()` should return the same thing each time? should we put it into a member variable?,0,0.9950874447822571
220385995,5693,vvcephei,2018-09-25T23:22:55Z,"come to think of it, this is probably insufficient to catch the wrong serde (due to erasure). i probably need to relocate this error message to the actual call to de/serialize",0,0.7951343059539795
220386097,5693,vvcephei,2018-09-25T23:23:35Z,oops. i'll take these out.,-1,0.9591315984725952
220386172,5693,mjsax,2018-09-25T23:23:58Z,"i am wondering about this: as we compute the byte-size later, and already pay the cost to serialize the record, should we not store `byte[]/byte[]` in the buffer? of course, still will imply that we need to deserialize later, however, the keeping the actual deserialized objects around would haver more storage overhead and would not obey the buffer size imho. thoughts?",0,0.846261203289032
220386402,5693,mjsax,2018-09-25T23:25:24Z,we should resolve this before merging imho.,0,0.9903912544250488
220386480,5693,vvcephei,2018-09-25T23:25:55Z,"oh yeah, i was meaning to figure out the right exception to throw to achieve a nice shutdown (i think any runtime exception will do it, but is there a semantically best one?)",0,0.8684412240982056
220386796,5693,mjsax,2018-09-25T23:28:01Z,do we need this check?,0,0.984759509563446
220387020,5693,vvcephei,2018-09-25T23:29:25Z,this is specifically for storing the keys sorted by timestamp in the buffer. i wasn't sure whether a more general or more specific name like `bufferkey` is better...,0,0.801096498966217
220387145,5693,mjsax,2018-09-25T23:30:17Z,nit: remove `this`,0,0.9891441464424133
220387246,5693,vvcephei,2018-09-25T23:31:02Z,"aka, ordering of keys that share a timestamp is arbitrarily. if anyone cares, we can do ""better"" by requiring k to be comparable (but i don't think anyone should care, so i kept it simple)",0,0.9710100293159485
220387263,5693,mjsax,2018-09-25T23:31:07Z,should we check for `last == null` and set `last = null` ?,0,0.994553804397583
220387414,5693,mjsax,2018-09-25T23:31:56Z,guess this should be removed?,0,0.9908344745635986
220387906,5693,mjsax,2018-09-25T23:35:08Z,not sure about this. see my other comment. would be good to get input from and about this.,0,0.7498526573181152
220387946,5693,vvcephei,2018-09-25T23:35:24Z,aha. i was thinking of [a link] which just isn't merged (yet).,0,0.9207016229629517
220390443,5693,mjsax,2018-09-25T23:50:35Z,"imho, scheduling a `1ms` punctuation would cause quite some overhead. alsw, we only need this for ""time based"" eviction, not for buffer size (num records, num bytes), right? we should also know, *when* we need to evict earliest -- thus, it should be sufficient to schedule accordingly? i think, we can also exploit cancellation to scheduled punctuation to be more flexible. also note, that during runtime, we don't check for punctuation execution after each record, but do this only after n records are processed (with n being adjusted dynamically during runtime). we also need to consider, that we fire a lot of punctuations if we ""jump ahead"" in time what seems to be inefficient.",0,0.9808659553527832
220390754,5693,mjsax,2018-09-25T23:52:28Z,i agree with the described semantics.,0,0.9613409042358398
220390935,5693,mjsax,2018-09-25T23:53:39Z,"forgot to add this to my review: this seems to have large runtime overhead and imho, we should try to find a better way to handle this.",-1,0.6746269464492798
220391498,5693,mjsax,2018-09-25T23:57:09Z,do we need to use punctuations to enforce record/byte limit? might be better to check for record/byte limit on put and use punctuations only to evict time based?,0,0.994575023651123
220402141,5693,vvcephei,2018-09-26T01:19:05Z,"ah, ok. i was hoping this is not how punctuations work (i'm ashamed to say i haven't looked at it yet). what i was hoping is that if i start at stream-time 0ms and then get a record at time 100ms, then my 1ms punctuator would be invoked just once, at time 100ms. i.e., i was thinking it would ""jump ahead"" (i thought i observed this, but maybe it was using the `topologytestdriver`). one alternative is to ""brew my own"" schedule exactly as i described, checking during `process` if there are any old-enough records. this could be done in the same loop that evicts if we're over capacity. this implementation would be very cheap. the tradeoff is that the punctuator will be fired on any advancement in stream time, whether or not that record actually reaches the buffer. but the hack i described would only ""tick"" when `process` is invoked. i *think* this would probably be satisfactory semantics.",-1,0.8229729533195496
220403434,5693,vvcephei,2018-09-26T01:29:19Z,"regarding: this is true, but it's slightly tricky (or at least it took me a while to realize it's not sufficient to trigger every `suppressduration` ms). i guess that each time we have a new min buffered timestamp `m`, we'd schedule a punctuation, we could cancel the previous punctuation and schedule a punctuation for `m + suppressduration` time from now. the punctuation schedule doesn't let you schedule in the form of ""`x` ms from now"", (i'm guessing it's epoch aligned like the windows), so we'd do a little math to compute a punctuation interval that would next fire at the correct time. i said ""each time we have a new min timestamp"". this can happen when we buffer new records or when we evict records. is this what you had in mind?",0,0.886179506778717
220405269,5693,vvcephei,2018-09-26T01:44:03Z,"it's not so easy to tell when we really need to buffer records until we actually get some records. this is a consequence (maybe a downside) of my choice to use `timedefinition` to use the window-end time as ""now"" and the grace period as the `suppressduration`. because of this, within the buffering context, even with a `suppressduration` of 0, we might still need to buffer, as the effective timestamp is in the future. thinking through this, we could try instead using the window start as ""now"" and using the window size + grace period as the suppress duration, but offhand it seems this wouldn't work too well with sessionwindows (or other variable-sized windows). so instead what i chose to do is just do a lightweight check when i need the buffer and initialize it if it hasn't already been. i could even move the `if buffer == null` to right here, and jit branch prediction would ensure this lazy check is almost zero after buffer gets initialized. some alternatives: 1. discard the optimization and just always initialize it, in case i need it. 2. junk the (maybe unnecessarily) flexible `timedefinition` function and instead just use a ""time strategy"" enum that tells the processor whether it should use record time or window-end time: in the former case, if the duration is zero, we know we'll never need a buffer. if it's > zero, we'll probably need one. in the latter case, we'll probably need a buffer, regardless of the suppression duration. wdyt?",0,0.97443026304245
220413716,5693,vvcephei,2018-09-26T02:54:39Z,"yeah, i think this is a reasonable thing to do. i've been going back and forth on it. the downside of storing it serialized is then we need to deserialize it to emit it. this is a moot point for the (planned) on-disk implementation, but for in-memory it saves some cpu and possibly some gc pressure not to round-trip it through a byte array. as is, we serialize it just once instead of serialize + deserialize. plus we currently discard the produced array immediately, so it's easy on the gc, whereas if we keep it, then we have 3 medium-to-long term objects: the incoming record, the serialized array, and the (deserialized) outgoing record. is this premature optimization? possibly. some other factors to consider: when we send to the changelog, we'll need to serialize it anyway. but i'm planning to send only on `flush` and to keep the changelog buffer compact with a linkedhashmap, so records that get updated or retracted several times within a commit interval would only get serialized once. plus, for this purpose, we still only need the `serialize` side; we could hang onto the produced array after computing the size long enough to send it to the changelogger. for changelogging purposes, we'd only need to deserialize when we recover on startup, not in steady-state operations, so i think it's still more economical to store the records as objects instead of serialized. it is true that there's really no tight correlation between the heap used by an object and the heap used by its serialized form. so at the moment, we're only roughly obeying the size limit. for primitive data, it's probably pretty close, though. i'm open to either way of doing it, but that was my thinking. what say you?",0,0.9123352766036987
220413812,5693,vvcephei,2018-09-26T02:55:41Z,"definitely. should it just be a `kafkaexception`, or something more specific?",0,0.9782206416130066
220415961,5693,vvcephei,2018-09-26T03:16:24Z,"good idea, setting it to null after i use it will make it available for gc. i can guard against null also, but fwiw, i'm not sure how that situation could arise. it's an `illegalstateexception` to invoke `delegate.remove` without an intervening call `delegate.next`. or to call it before `next`. `delegate.next` could return null, but in that case, we'd get an exception in line 69... which i should check for there.",0,0.8576185703277588
220416468,5693,vvcephei,2018-09-26T03:21:03Z,"probably not. i don't think this can happen unless this buffer is used across threads (which shouldn't happen), or unless we screw up the implementation in the future (which we could do in any number of ways, it doesn't mean we need guards everywhere). wdyt?",0,0.9426896572113037
220416859,5693,vvcephei,2018-09-26T03:24:51Z,i think you're spot on. i'll check it out.,0,0.9476706385612488
220424615,5693,vvcephei,2018-09-26T04:38:31Z,i think i like this better than my ideas 2 and 3 above. i'm on the fence about this vs just doing it as a part of `process`. i think we'll probably want to do idea 1 regardless.,0,0.7804617881774902
220435089,5693,mjsax,2018-09-26T06:06:25Z,"compare [a link] and the corresponding pr for more details about punctuation semantics. `topologytestdriver` should not work differently (if it does, it's a bug in the test driver -- behavior must be the same to allow for unit testing -- would be bad if it would behave differently). about the second point: yes, something like this. i did not think this through. maybe it's also ""good enough"" to have something more coarse grained for first release. going with ""manual punctuation"" with ""process"" might also be a good first approach -- might still be better than `1ms` punctuation from an overhead point of view (of course, depends on the throughput... 1ms == 1000 records/second/task...)",0,0.9270453453063965
220435537,5693,mjsax,2018-09-26T06:09:25Z,hard to say -- jit branch prediction might make my concern invalid -- it's just because it's on the hot code path. would be good to get input from and,0,0.9121262431144714
220435742,5693,mjsax,2018-09-26T06:10:44Z,"also, we should avoid pre-mature optimization...",0,0.9907700419425964
220436580,5693,mjsax,2018-09-26T06:16:03Z,"agree with all trade-offs you mention. for ktable caches, we also went to storing `byte[]` to obey the size config. also note, we don't need to deserialize all byte[] arrays, but only on eviction -- if we have a lot of suppression. many byte[] arrays would never the deserialized but overwritten. depending on throughput and number if unique keys, this might happen quickly enough to still be young gen. hard to say. again, more input from and would be helpful. and as above, pre-mature optimization should be avoided. could we do some prototyping and benchmarking of both approaches? not sure if there is enough time. also, it's an internal implementation and if performance becomes an issue, we ca also improve on it in 2.2.",0,0.958943784236908
220436698,5693,mjsax,2018-09-26T06:16:42Z,i guess `streamexception` or maybe a new sub-class would be a good idea.,0,0.9916626214981079
220437021,5693,mjsax,2018-09-26T06:18:42Z,"i tend to think, that we don't need this guard because a bug that gives multi-threaded access seems to be very unlikely. but it's a personal opinion... my concern again is because this is the hot code path. but i am also ok to keep the check if somebody insists.",0,0.8273776173591614
220437726,5693,mjsax,2018-09-26T06:22:08Z,"ack. see your point that `delegate` does the check for us. i was aware that it would imply incorrect api usage (ie, wrong call order or similar). just wanted to make sure we catch a bug like this -- but seems it would crash anyway even if we don't add a check for `null`.",-1,0.8509209752082825
220585715,5693,vvcephei,2018-09-26T14:26:29Z,"ok, i think the in-`process` approach sounds simple and low-overhead, so i'll do that for starters, and we'll see what we think.",0,0.9451460838317871
220586765,5693,vvcephei,2018-09-26T14:28:52Z,"this is very true: i won't do anything with it right now, but wait for more input (and take care of the other things we discussed)",0,0.8644555807113647
220587434,5693,vvcephei,2018-09-26T14:30:28Z,i also think it's unlikely to be useful. i'll remove it.,0,0.9341894388198853
220675913,5693,bbejeck,2018-09-26T18:32:37Z,i also agree with the semantics for enforcing the time limit.,0,0.9866359829902649
220687788,5693,vvcephei,2018-09-26T19:08:12Z,"ok, i just confirmed that `treemap#entryset().iterator().next()` can never return `null`, but we could theoretically store a null value in the map, which could still throw an npe on this line. i'll guarded against it.",0,0.9905557036399841
220689349,5693,bbejeck,2018-09-26T19:13:22Z,"while i also agree with the trade-offs mentioned by , we can't say exactly what the better approach will be without testing. to me, the bigger savings potential would be in cpu but again we can't say without testing. but we do need to serialize for sending to the changelog, and even if we only send on `flush` and couple that with the fact that a `byte[]` coming in does not always get deserialized due to updates by key. so i'm starting to think to go with either approach will be a wash. so, for now, i'm leaning towards storing `byte[]` 1. that's what we currently use for `ktable`, while that by itself is not enough of a reason, imho we need to be careful about having different approaches for similar issues without a clear, demonstratable reason for doing so. 2. benchmarking will really give us the answers we are looking for, but time is something we don't have right now for getting this into 2.1 3. i could be wrong about this but i think the biggest users of suppression are going to have several updates per key, so as mentions, many of the `byte[] arrays` are going get overwritten.",0,0.8975845575332642
220695412,5693,bbejeck,2018-09-26T19:33:58Z,left over debugging?,0,0.9623068571090698
220695672,5693,bbejeck,2018-09-26T19:34:51Z,+1 for a sub-class of `streamexception`,0,0.949237585067749
220701301,5693,bbejeck,2018-09-26T19:54:12Z,i think doing it in `process` is a good start as well.,0,0.7361190319061279
220703951,5693,vvcephei,2018-09-26T20:02:12Z,"yeah, i noticed it late. it's gone now.",0,0.949312150478363
220707349,5693,vvcephei,2018-09-26T20:13:40Z,"ok, it sounds like no one has a super strong performance intuition. i think 's point about uniformity is a good one. if anyone wants to insist on this, i'll change it right now. otherwise, if we're all comfortable making a performance-based decision, i think i'll propose to implement change-logging first and then do a comparative benchmark to make the final call.",0,0.5129333734512329
220777672,5693,vvcephei,2018-09-27T02:29:33Z,"i've been mulling this over... it seems like byte arrays is the more normal choice in the code base, so it should be the default until proven otherwise by a performance test. the fact that i made the opposite choice in development is irrelevant. so i'll go ahead and swap it out for byte arrays tomorrow.",0,0.8398019075393677
220953221,5693,bbejeck,2018-09-27T14:44:59Z,can we add two cases to `ktablesuppressprocessortest` to hit this branch? one for the `emit` case and another for the `shut_down`,0,0.99481600522995
220954471,5693,bbejeck,2018-09-27T14:48:13Z,"we could use a test to hit this branch as well, but imho it's a lower priority than the others mentioned above.",0,0.978249728679657
220989558,5693,vvcephei,2018-09-27T16:21:32Z,"this line is actually gone now. but if it were still there, i'd agree with you.",0,0.9305498003959656
221031086,5693,bbejeck,2018-09-27T18:31:04Z,"nit: this can be simplified to: `testutils.waitforcondition(() -> driver.state() == kafkastreams.state.error, timeout_ms, ""streams didn't shutdown in error state"");`",0,0.9944297671318054
221046943,5693,vvcephei,2018-09-27T19:21:55Z,"ah, right. i looked for something like that, but i was looking in `integrationtestutils`. thanks.",1,0.9417479038238525
221048082,5693,vvcephei,2018-09-27T19:26:00Z,"ok, i've updated it.",0,0.9438710808753967
221336195,5693,guozhangwang,2018-09-28T18:04:25Z,"could we merge #5521 (i think it is in pretty good shape) and rebase this pr on that? i felt a couple of the changes blew are a bit redundant, e.g. passing in the materializedinternal object as well as its serde fields.",0,0.954913318157196
221346202,5693,guozhangwang,2018-09-28T18:41:04Z,"could we move this function to a single class, e.g. `windowedserdes` to avoid duplicates (we have the same function in `sessionwindowedkstreamimpl.java`). btw in #5521 i just inlined each call, but i think extracting it is also fine.",0,0.9896875023841858
221346600,5693,guozhangwang,2018-09-28T18:42:16Z,"why only passing the windows object (for its length) here, but not in other callers below?",0,0.9921546578407288
221347082,5693,guozhangwang,2018-09-28T18:44:00Z,this reminds me of the `lrucacheentry` class used for caching.. could we consolidate these two?,0,0.9927319884300232
221348235,5693,guozhangwang,2018-09-28T18:48:15Z,"can we just use `org.apache.kafka.streams.processor.internals.stamped`? they seem very similar (feel free to rename the class if you like other names better: since it is internal classes, we can change it whenever we want.)",0,0.9569548964500427
221350777,5693,guozhangwang,2018-09-28T18:57:17Z,do we assume we will only remove the head of the iterator? if not i'm not clear why we can simply set the mintimestamp as the next key's timestamp.,0,0.9604290127754211
221351979,5693,guozhangwang,2018-09-28T19:01:31Z,edit: it seems the above assumption is true from the other classes. in this case could we guard against the unexpected case if there are un-deleted entries before the current position?,0,0.9935357570648193
221352155,5693,guozhangwang,2018-09-28T19:02:14Z,nit: i'd suggest putting the size calculation of `contextualrecord` inside the `contextualrecord` class instead of in this class.,0,0.9928678274154663
221376160,5693,guozhangwang,2018-09-28T20:42:21Z,do we ever expect the passed in not-null valueserde is a `fullchangeserde` already? if not we should wrap it with `fullchangeserde` still.,0,0.9941336512565613
221377817,5693,guozhangwang,2018-09-28T20:49:51Z,"we've encountered some issues related to the ordering of this before: [a link] could you read that ticket and double check if flush-first-remove-later would not cause any issues for re-entrant puts on the same buffer (say, if we have a loop in the topology)?",0,0.9857962727546692
221378172,5693,guozhangwang,2018-09-28T20:51:25Z,"should we clear the buffer upon closing? maybe it does not make a difference on correctness, but would it worthy for performance?",0,0.9837437272071838
221380146,5693,vvcephei,2018-09-28T21:00:17Z,"the one in sessionwindowedkstreamimpl is actually different (wraps it with a sessionwindowedserde). fwiw, i think inlining it is actually preferable to extracting it to a ""common"" location if it's actually just going to have one use.",0,0.9833877086639404
221380482,5693,vvcephei,2018-09-28T21:01:45Z,this was an oversight. thanks for the catch!,1,0.9285082817077637
221381920,5693,vvcephei,2018-09-28T21:08:17Z,"it is similar, but the lrucacheentry tracks `isdirty` that would be confusing in this context, so i wouldn't use lrucacheentry here, but we could go the other way and make lrucacheentry wrap contextualrecord instead of storing the value + context itself. let me know if this sounds good to you... i'll go ahead and optimistically code it up.",0,0.8433103561401367
221382215,5693,vvcephei,2018-09-28T21:10:01Z,"yeah, this sounds good.",1,0.7535192370414734
221384089,5693,vvcephei,2018-09-28T21:19:35Z,"hmm. actually, stamped has unusual implementations of equals, hashcode, and compareto. they all disregard the stamped value and are only determined by the timestamp... so, stamped won't provide the semantics we need from timekey, and i'm afraid to change the equals/hashcode/compareto of stamped and messing up _its_ semantics... wdyt?",-1,0.9822935461997986
221384963,5693,vvcephei,2018-09-28T21:24:08Z,"aaah, yes. this min-timestamp update does depend on always removing the head of the iterator. i'll fix it. thanks.",1,0.9075385928153992
221386195,5693,vvcephei,2018-09-28T21:31:16Z,"this computation makes use of the fact that this reference is a `contextualrecord `, the value type is generic in contextualrecord. of course, this is the only usage of that class, so, i could just build the `byte[]` value type into contextualrecord. but i'm slightly in favor of keeping it as-is so we can use contextualrecord in other contexts where we need both the value (not serialized) and the context in the future. wdyt?",0,0.9712381362915039
221387849,5693,vvcephei,2018-09-28T21:39:38Z,"this would mean that they have configured the `default.value.serde` as a fullchangeserde, which is in the `internals` package. nevertheless, it doesn't hurt to guard it. will do.",0,0.9820448160171509
221389162,5693,guozhangwang,2018-09-28T21:46:57Z,"i meant to have `contextualrecord` contains its only computesize() function which caluclates the size of bytes ""except"" the value size, which can then be called by this function, and here we only need to calculate the key size and value size plus whatever returned from `contextualrecord#computesize`. anyways, it is a nit comment and i do not feel strong about it.",0,0.8052164316177368
221389407,5693,guozhangwang,2018-09-28T21:48:17Z,"yeah i point is that is seems ""impossible"" that the passed in serde will be a `fullchangeserde` but just the inner serde used for `fullchangeserde`, so we should always wrap (either the default one from config, or the inherited one) with the `fullchangeserde`, right?",0,0.973675549030304
221390374,5693,guozhangwang,2018-09-28T21:54:10Z,"do we need to require value ordering for `timekey` here? i thought it is not required as they are not following offset ordering to break ties anyways, right?",0,0.9869793653488159
221390459,5693,guozhangwang,2018-09-28T21:54:38Z,`make lrucacheentry wrap contextualrecord` yeah that sounds good.,1,0.8041108250617981
221390529,5693,guozhangwang,2018-09-28T21:55:07Z,ack.,0,0.5038502812385559
221391967,5693,vvcephei,2018-09-28T22:03:46Z,"interesting! that issue seems to be cache-specific: that two subsequent processors can be backed by the same cache (as in the join case). i don't think loops are generally allowed in the subtopology, are they? if so, this code would indeed result in an infinite loop or possibly a concurrent modification exception. i was concerned that the remove might be sent to the buffer's changelog record collector and maybe sent to the broker, and then some exception might happen before the forward, resulting in the record being forgotten upon restart. i looked at some other processors, and they tend to do (logged) store operations first and then forward last. but then again, normal operations are forwarding a value that's a direct consequence of processing the _current_ record, which wouldn't have been committed and would therefore get re-processed upon restart. but the buffer is forwarding some older record, which has already been committed. reprocessing the new record (which caused the eviction the first time) won't cause us to remember the old record, which we were supposed to emit. under eos, if we crash after the changelog update but before the forward, we'll be fine because the changelog update won't be visible (it'll be in an aborted transaction) on restart, so the buffer will go back to it's correct starting point for reprocessing the new record. if we can't be sure that streams subtopologies are acyclic, then i reckon we'd better swap these two lines and tell people they'd better use eos if they want to be protected from all crash corruption (which i think is true anyway). otherwise, if subtopologies are acyclic, then i think it's better to leave it as is. wdyt?",0,0.7352232933044434
221392110,5693,vvcephei,2018-09-28T22:04:40Z,"yeah, i wasn't sure. i'll go ahead and do it.",0,0.6485522389411926
221392505,5693,vvcephei,2018-09-28T22:07:08Z,"actually, let's defer this to part 4, where the buffer becomes a proper store, and has its own `close()` method.",0,0.9936220049858093
221393704,5693,vvcephei,2018-09-28T22:15:25Z,"i don't _think_ that will work... `comparable` requires a total ordering and also specifies that `a.compareto(b) == 0` iff `a.equals(b)`, which in turn requires that `a.hashcode() == b.hashcode()`. but this would prevent us from inserting two different keys with the same time into our buffer map. it doesn't seem like `stamped` is suitable for map keys or set entries for this reason.",0,0.937508761882782
221405676,5693,vvcephei,2018-09-28T23:59:18Z,"ok, this is done now.",0,0.9723977446556091
221408442,5693,vvcephei,2018-09-29T00:41:29Z,"ok, i put in a guard. i also refactored the interface to purely evict the head of the buffer while a condition holds, which cleans up the usage quite a bit. let me know what you think.",0,0.9540612101554871
221408530,5693,vvcephei,2018-09-29T00:43:01Z,"since the part of the contextualrecord that isn't the value is just the processorcontext, i just added a `sizebytes()` method there. wdyt?",0,0.9919208288192749
221408651,5693,vvcephei,2018-09-29T00:45:27Z,"oh, i gotcha. the type of valueserde is already a fullchangeserde. in the case of an inherited serde, it gets wrapped in the constructor. the types ensure that the constructor arg is not already a fullchangeserde.",0,0.882148265838623
221412551,5693,vvcephei,2018-09-29T02:23:50Z,"yes, i think that's a good plan. i agree on the reduncancy, but i wanted to keep the serde-related perturbations to a minimum so we wouldn't distract from the pr.",1,0.5170345902442932
221478048,5693,mjsax,2018-09-30T23:44:40Z,just reviewed #5521 again -- left some more comments.,0,0.9857980608940125
221478098,5693,mjsax,2018-09-30T23:47:24Z,"i actually think that forward before delete is correct. compare: [a link] and the corresponding pr, that we never finished.",0,0.9713231325149536
221492758,5693,mjsax,2018-10-01T04:15:54Z,nit: `castorwrap`,0,0.9927111864089966
221492805,5693,mjsax,2018-10-01T04:16:41Z,why this change? (just for my own education.),0,0.9731860756874084
221493048,5693,mjsax,2018-10-01T04:19:29Z,could we extend `wraporcast` to add a `null` check and return `null` for this case and use it here to make code more readable?,0,0.9941697120666504
221493375,5693,mjsax,2018-10-01T04:24:31Z,"i think we need to call `put` only if `previouskey == null`? ie, we could merge l103 ad l105 into an if-then block? might be more readable?",0,0.9945388436317444
221493496,5693,mjsax,2018-10-01T04:26:03Z,"this check for `previouskey == null` could be merged with the check from above? (it's hot code path, so might be worth to unify.)",0,0.9930745363235474
221493640,5693,mjsax,2018-10-01T04:28:03Z,different thought: why do we need to call `remove` above explicitly? `put` would return the old/replace value anyway if there is any -- would avoid one tree-traversal?,0,0.9931169748306274
221493984,5693,mjsax,2018-10-01T04:32:40Z,"i don't see the advantage of using generics in `contextualrecord` is it's only used once with `byte[]` types. as generic types are lost after compilation, i would prefer to remove the generic if not needed (afaik, generics have some runtime overhead as the compiler needs to insert casts that are evaluate during runtime.)",0,0.9834738373756409
221494361,5693,mjsax,2018-10-01T04:38:14Z,"this value should only be `0` or `1` -- maybe use a boolean instead? also wondering, if we need this at all? have the gut feeling, that `last != null` and `nextcount != 0` is the same thing?",-1,0.7790597081184387
221494851,5693,mjsax,2018-10-01T04:45:43Z,"if `next()` is called twice in a row without `remove()` in between, `nextcount` could be larger than 1 and thus we should throw -- seems that the current code enforces a `next-remove-next-remove...` pattern? if yes, why?",0,0.9826854467391968
221494894,5693,mjsax,2018-10-01T04:46:12Z,should this be set to `1` instead of incrementing?,0,0.9937254786491394
221495017,5693,mjsax,2018-10-01T04:48:07Z,"see my other comments -- it's still unclear from the code that we want to enforce `next-remove-...` pattern -- might also be worth to add a javadoc to the iterator about correct usage, even if it's an internal class only.",0,0.9910444021224976
221496039,5693,mjsax,2018-10-01T05:02:37Z,"i am wondering, if `suppressdurationmillis` is a valid config? i had problem to understand this part in the original pr already. can you explain once more? (maybe it's an indicator that we should add a comment explaining the cases we are handling here?)",0,0.9816595911979675
221496235,5693,mjsax,2018-10-01T05:05:34Z,`and` -> `or` or `and/or` ?,0,0.9905407428741455
221496719,5693,mjsax,2018-10-01T05:11:06Z,"should we inline this method? also, i am wondering if we could/should call this unconditionally? if `overcapacity()` is true, we might or might not expire records here (same if called unconditionally). if `overcapacity()` is false, but `buffer.mintimestamp() <= expirytime` is true, we would expire record (same if called unconditionally). if both are false, `drainexpriredrecords()` would not expire anything if called either, because it passed in the corresponding boolean predicate anyway? ie, i _think_ we can just remove the `if` condition and execute the `then` part always",0,0.9924181699752808
221496860,5693,mjsax,2018-10-01T05:13:00Z,nit: `next` -> `evictedrecord` or just `record` ?,0,0.9936800003051758
221497240,5693,mjsax,2018-10-01T05:17:31Z,nit: `deserializedkey` -> `key` and `key` -> `rawkey` ?,0,0.9943630695343018
221497342,5693,mjsax,2018-10-01T05:18:50Z,should we cast here and keep `bufferconfig bufferconfig` as member type?,0,0.995151162147522
221497656,5693,mjsax,2018-10-01T05:22:47Z,"while i think, it's semantically fine, it might be nice to get the same eviction behavior for a reprocessing use-case... i am also realizing, that `timekey` is actually always used with `bytes` -- thus, i would recommend to remove the generic type, and exploit that `bytes` implements `comparable` already.",0,0.9336510300636292
221498033,5693,mjsax,2018-10-01T05:27:24Z,"`key` is always `bytes()`, thus, this output is not very useful. can we can hold on the deserialized for human readable output here?",0,0.9786351323127747
221498255,5693,mjsax,2018-10-01T05:30:19Z,"each java object has a natural overhead -- might be worth to add this here? would need to search the internet how many bytes, however, we would have it for `processorrecordcontext` itself, as well as `topic`, `headers` (including it's nested `header` objects).",0,0.9906730055809021
221498409,5693,mjsax,2018-10-01T05:32:06Z,"a `string` also store the length (it's a `char[]` internally) -- should we add 4 more bytes here? also, has a `char[]` similar overhead than a regular object?",0,0.9949213862419128
221498827,5693,mjsax,2018-10-01T05:36:55Z,`value` is always `byte[]` -- can we get a handle on the deserializer to get human readable output here? (one more reason to avoid generic if not necessary -- those issues slip easily with missing type information).,0,0.993195652961731
221498993,5693,mjsax,2018-10-01T05:39:01Z,"should we add 4 byte to store array size? also, do we have object overhead for an array type?",0,0.9942604303359985
221499058,5693,mjsax,2018-10-01T05:39:49Z,should we add object overhead for `context` itself? (might be included in `sizebytes()` if we update is accordingly thought),0,0.9953699707984924
221640642,5693,vvcephei,2018-10-01T14:55:34Z,"it's just evidence of my mental slowness... in the prior pr, guozhang pointed out that my calling `buffer.array()` was incorrect, since the backing array isn't guaranteed to be exactly within the bounds we allocated. i fixed it at the time by delegating to the `bytebufferserializer`, which handles this. later on i realized that there is a more efficient solution available. by pre-creating the backing array and wrapping it, we know that `buffer.array()` returns what we needed. no need for the more general handling logic in `bytebufferserializer`.",0,0.9682512283325195
221640973,5693,vvcephei,2018-10-01T14:56:22Z,i can and will.,0,0.9650355577468872
221642753,5693,vvcephei,2018-10-01T15:00:59Z,"i've added that check because `context.valueserde()` (called elsewhere) could return null. if it's ok with you, though, i prefer the current code right here. this code ensures that `valserde` is of the correct type (notice that no casting is necessary). in general, i think we should avoid casting unless we actually need it, as it makes regressions harder to catch.",0,0.9862824082374573
221646019,5693,vvcephei,2018-10-01T15:09:46Z,"this is true about `put`, but we still need to choose a key to insert into `sortedmap`. if i don't declare the `nextkey` variable, i need to have a bunch of redundant code in the if and else blocks: [code block] imho, this is less readable than the linear version where we just reuse or construct the key in line 103.",0,0.9894271492958069
221646437,5693,vvcephei,2018-10-01T15:10:56Z,"but if, after looking at it, you prefer the branching version, i'll change it.",0,0.9788818359375
221648943,5693,vvcephei,2018-10-01T15:17:41Z,"please see my comment above. i agree it's more efficient to have just one branch, but i do think this version is easier to follow. regardless, you have a fresher perspective. if you prefer the branching version above, i'm happy to change it.",1,0.989437460899353
221650193,5693,vvcephei,2018-10-01T15:21:04Z,"ok, apparently the way to convince me is to point out three reasons... i'll switch it out for the branching version.",0,0.9755827784538269
221655192,5693,vvcephei,2018-10-01T15:34:50Z,i didn't consider this runtime overhead. i'll go ahead and inline the generic type.,0,0.9549437761306763
221655988,5693,vvcephei,2018-10-01T15:37:06Z,"it is ok to call next multiple times, but if you do, you can't subsequently call remove. i don't think that we can learn whether next has been called twice by looking at any of the other fields we're maintaining.",0,0.9762193560600281
221661624,5693,vvcephei,2018-10-01T15:52:56Z,"yes. this is an optimization to support maximal efficiency in: * removing some unknown number records, each of which is currently the minimum in the buffer when it gets removed * maintaining a correct value of `mintimestamp`. as far as we know right now, we will only ever need to remove the min records from the buffer. i.e., i don't think we need to iterate for a while and *then* remove. but we may need to remove more than one record, and we won't know if we need to remove the *next* record until after we remove *this* record. previously, i didn't have this guard, but in that case, we can't just set `mintimestamp` to the buffer time of the next record upon removing. because we don't know whether the record we just removed is the leftmost record in the tree without traversing it again. because of that, i had to avoid updating `mintimestamp` until you close the iterator (and therefore it had to be a `closeableiterator`). this means that the ktablesuppressprocessor couldn't just keep popping records while the mintimestamp was less than the desired boundary, it had to get the ""buffer time"" from the timekey and make its decision from that. all in all, it's way cleaner this way, with the expense of that one extra guard. i could go one step further and make it like a ""predicated, consuming iterator"", which just pops records out as long as the predicate condition is true. do you think this would be more straightforward?",0,0.9740989804267883
221661740,5693,vvcephei,2018-10-01T15:53:15Z,no; see the reply above.,0,0.9768385887145996
221662088,5693,vvcephei,2018-10-01T15:54:14Z,"from your later comments, it seems like you would say it would be more straightforward. i'll go ahead and simplify it.",0,0.9579448103904724
221667743,5693,vvcephei,2018-10-01T16:11:01Z,i think the complexity is due to my over-flexible time definition. i'll drop it and then we'll see if it's still non-obvious what's going on here.,0,0.9135724902153015
221690047,5693,mjsax,2018-10-01T17:22:54Z,i guess it's personal taste -- don't insist on a change.,-1,0.5703864097595215
221690536,5693,mjsax,2018-10-01T17:24:31Z,"think, even without the branching, this `remove` and the `put` below should be merged.",0,0.9926599860191345
221690691,5693,vvcephei,2018-10-01T17:25:03Z,"ok, i've decided that this optimization is premature and complex, so i've gone ahead and simplified it. (i'll let you know when i push the update). i've also updated the timedefinition class to be less flexible (although it doesn't really simplify this particular method). fwiw, though i think that ""suppress for 0ms"" is a perfectly valid way to disable a suppression operation. note that this is also what we wind up with when you use final-results on a windowed stream with graceperiod set to 0ms, which also seems perfectly fine.",0,0.8599081635475159
221691013,5693,vvcephei,2018-10-01T17:26:10Z,i added the missing punctuation instead.,0,0.9850139021873474
221691019,5693,mjsax,2018-10-01T17:26:11Z,this breaks the iterator contract and should be well documented,0,0.9871339201927185
221692098,5693,vvcephei,2018-10-01T17:29:27Z,"i wanted to save on setting up the iterator, but your comment made me realize we can and should do that with an initial `if (predicate.get())` inside `evictwhile`. i did this and removed the condition as you recommended.",0,0.9655764102935791
221692337,5693,vvcephei,2018-10-01T17:30:09Z,good point. i called it `toemit`.,1,0.9065421223640442
221693619,5693,vvcephei,2018-10-01T17:34:29Z,"this made me realize that i named them `impl` when i meant to name them `internal`. in other words, both `suppressedinternal` and `bufferconfiginternal` to indicate that these are the internal interfaces.",0,0.9935624599456787
221694264,5693,vvcephei,2018-10-01T17:36:43Z,i didn't notice that. that is handy.,0,0.4822574555873871
221696756,5693,vvcephei,2018-10-01T17:44:39Z,"i agree that this is an under-estimate, but i don't think there's much point in being exact. the overhead is dependent on the jvm implementation, so we'd have to detect the jvm and maintain a mapping for each different implementation. even then, we don't know how much extra memory we're using in the various garbage collectors, of which there are now three different implementations in the oracle jdk alone... i'd rather just make the best effort we reasonably can to live more-or-less within the desired boundary. for example, storing the `byte[]` value is much closer than storing the object. but beyond that, we get into diminishing returns for quickly increasing complexity.",0,0.9103444218635559
221697255,5693,vvcephei,2018-10-01T17:46:16Z,"i believe arrays also store their types. but again, we are getting into jvm implementation details. there are too many jvm implementations for us to be expected to worry about this, imho.",-1,0.8346077799797058
221698960,5693,vvcephei,2018-10-01T17:51:38Z,"i didn't consider this overhead, and agree it would be good to get rid of it.",0,0.7895529866218567
221699155,5693,vvcephei,2018-10-01T17:52:12Z,"i don't think the record needs to know how to deserialize itself. since `tostring` is only for debugging, i'm fine printing out the `arrays.tostring` summary of the value. if we wanted to print out the value in a log message, we would format it more specifically (including a deserialization if desired). that said, i will go ahead and get rid of the generic type.",0,0.9825996160507202
221701912,5693,vvcephei,2018-10-01T18:00:46Z,as above.,0,0.9878018498420715
221702092,5693,vvcephei,2018-10-01T18:01:16Z,"it would be the responsibility of the context to account for its own overhead, but see my comments above.",0,0.9853488802909851
221756263,5693,vvcephei,2018-10-01T21:04:23Z,"roger that. it's moot now, since i've removed this iterator entirely.",0,0.9106280207633972
221757521,5693,vvcephei,2018-10-01T21:09:03Z,"i think in sum, your points elevate it beyond personal taste. i've gone ahead and done the branching. after a little cleanup, it's not too shabby anyway.",0,0.5226801037788391
221792731,5693,vvcephei,2018-10-02T00:01:39Z,"i had to add these so that suppress doesn't ""forget"" the window end time when it round-trips the record.",0,0.9596392512321472
221793798,5693,mjsax,2018-10-02T00:08:26Z,ack. that's fair. the existing caches also use rough estimates only. (might be interesting how much we are off though... but this could be a follow up improvement.),1,0.6968286633491516
221794070,5693,mjsax,2018-10-02T00:10:24Z,"my point is, that even for debugging it's not useful to print `byte[]` -- my argument is, to either ""fix this"" or don't overwrite `tostring()` at all.",0,0.9813910722732544
221794878,5693,mjsax,2018-10-02T00:16:14Z,is this mentioned in the kip? it's a public api change.,0,0.9938721656799316
221795634,5693,mjsax,2018-10-02T00:21:39Z,not sure if this is the best way to tack it? requires public api change.,0,0.9714744687080383
221796847,5693,mjsax,2018-10-02T00:29:57Z,i guess we can remove this generics?,0,0.9856005311012268
221797359,5693,mjsax,2018-10-02T00:33:39Z,`nextkey.time()` -> `time`,0,0.9931538105010986
221797795,5693,mjsax,2018-10-02T00:37:11Z,"should we compute `buffertime` within `buffer()` -- no need to pass it in, as both `internalprocessorcontext` and `key` are available there, too?",0,0.9956283569335938
221797893,5693,mjsax,2018-10-02T00:38:08Z,so we need this here? no need to pass it into `enforceconstraints()` imho.,0,0.9931603670120239
221798063,5693,mjsax,2018-10-02T00:39:28Z,should this be `<` instead of `<=` ?,0,0.9941889047622681
221798280,5693,mjsax,2018-10-02T00:41:14Z,guess we can remove variable `key` (only used once).,0,0.9910399317741394
221798347,5693,mjsax,2018-10-02T00:41:45Z,`key1` -> `key` and `key.get()` -> `toemit.key.get()`,0,0.9929458498954773
221798908,5693,mjsax,2018-10-02T00:46:05Z,"similar argument as for `byte[]` value: of course, here we still get the `time` information, but the `bytes` `key` is useless.",0,0.9886589646339417
221800768,5693,mjsax,2018-10-02T01:00:20Z,why remove this comment? seems to be valid?,0,0.9671074748039246
221800971,5693,mjsax,2018-10-02T01:01:37Z,"the change makes sense -- test was bubby before, but we did not notice at it threw anyway?",0,0.9870874881744385
221801525,5693,mjsax,2018-10-02T01:06:01Z,what was the original intend of this part? and why don't we need it?,0,0.9694172739982605
221802094,5693,mjsax,2018-10-02T01:10:39Z,why `timestamp - 1l` ?,0,0.9921888113021851
221805529,5693,vvcephei,2018-10-02T01:38:54Z,"ah, no. when i did this before, i did it differently to keep it private. i thought this was a better way, but overlooked the public-ness of it. i'll go back to private mode.",0,0.8484660387039185
221805956,5693,vvcephei,2018-10-02T01:43:11Z,"ah, yeah, it was previously used also here, but it's not needed anymore. good catch.",1,0.923332929611206
221805975,5693,vvcephei,2018-10-02T01:43:21Z,same here. thanks!,1,0.9924012422561646
221806806,5693,vvcephei,2018-10-02T01:49:57Z,"it wouldn't be wrong, but i think `<=` is also right, and it's a tighter bound. let's say we have buffered an event with time 10 at stream time 10 and the suppressduration is 1. the expiry time is `10-1 = 9`. mintimestamp is 10, and `10 <= 9` is false, so we don't evict. then, we get an event with time 11 at stream time 11. now, the expiry time is `11-1=10`. mintimestamp is still 10, but now the check is `10 <= 10`, so we evict that first event. i think this matches up to the intention of saying ""suppress for 1 ms"".",0,0.9881008863449097
221807188,5693,vvcephei,2018-10-02T01:52:48Z,"it's not anymore. now, we buffer the new event before we enforce the buffer constraints, so we return the more intuitive most recent state of `""v1"", 1l, 2l` right away, instead of later on.",0,0.9925875067710876
221808272,5693,vvcephei,2018-10-02T02:01:52Z,"we didn't throw it away before, just emitted it later on. this is what the comment i removed was explaining.",0,0.9803824424743652
221808394,5693,vvcephei,2018-10-02T02:02:54Z,"when we enforced constraints before buffering, we needed one extra tick to flush everything out. now that we buffer first, everything happens more promptly, so we don't need this last cycle to witness all the results we're looking for.",0,0.9884926676750183
221808532,5693,vvcephei,2018-10-02T02:04:09Z,"it doesn't matter for anything, it just seemed weird to have window start == window end. the window end is the time that matters for this test, which is why i made it the baseline.",-1,0.882080078125
221811667,5693,mjsax,2018-10-02T02:34:28Z,ack,0,0.8596508502960205
221812576,5693,mjsax,2018-10-02T02:44:07Z,"we set record timestamp to `timestamp` -- thus, the record will be put in window `[timestamp, timestamp+1)`, right? seems weird to use the wrong window imho. or do i miss something?",-1,0.8281517028808594
221813111,5693,vvcephei,2018-10-02T02:49:17Z,"ok, i wasn't thinking about it like this. it makes sense.",0,0.6903135180473328
221813409,5693,mjsax,2018-10-02T02:52:09Z,i see. the comment focus on the second `v1` -- i applied it to the third `v1`. seems the comment was ambiguous :),1,0.969147264957428
221813838,5693,vvcephei,2018-10-02T02:56:43Z,good thing it's gone!,1,0.9951608777046204
221821211,5693,guozhangwang,2018-10-02T04:13:10Z,makes sense.,0,0.9811486601829529
231290134,5821,lindong28,2018-11-06T20:58:29Z,exception and its corresponding error code is part of public interface. can you update design doc as appropriate and reply to the email thread with this change?,0,0.9907830357551575
231292242,5821,lindong28,2018-11-06T21:05:09Z,"currently all epoch fields (e.g. controller epoch, leader epoch) uses int32. would it be more consistent and space efficient to use int32 for broker epoch as well? max int32 value is more than 2 billion which seems large enough for broker epoch. if we change the type of broker epoch from int64 to int32, can you also update the design doc and reply to the email thread?",0,0.9934254884719849
231294160,5821,lindong28,2018-11-06T21:11:32Z,"since we are modifying the schema here, it may be a good time to use the new way of specification as shown in fetchrequest for consistency. then we can use `struct.getorelse(...)` here. it is specifically preferred to make this refactor together with the change in this pr if the existing code footprint is small (e.g. `stopreplicarequest.java`).",0,0.9919663667678833
231294372,5821,lindong28,2018-11-06T21:12:14Z,nits: can you add an empty line between these two methods?,0,0.9884173274040222
231300243,5821,lindong28,2018-11-06T21:30:41Z,nits: it seems a bit more consistent with the existing style (e.g. `produce_response_v4 = produce_response_v3` in produceresponse.java) to do `leader_and_isr_response_v2 = leader_and_isr_response_v1`. it is probably more readable as well since we typically want to see how the new schema compares with the previous version.,0,0.9739922881126404
231304928,5821,lindong28,2018-11-06T21:45:58Z,"nits: for consistency with the exiting style, can we use `update_metadata_response_v5 = update_metadata_response_v4`?",0,0.9951372742652893
231306661,5821,lindong28,2018-11-06T21:51:11Z,"it seems that even if we do this filter, the broker may still go offline after this step and before controller sends the request to the broker. so we still need to have this filter logic later. could you explain the benefit of having this logic here?",0,0.9818899631500244
231319305,5821,lindong28,2018-11-06T22:33:29Z,would this be more consistent and readable to move this logic to the class `controlledshutdown`? this can also ensure that the `brokerepochscache` is accessed only by the controller event thread after controller is initialized.,0,0.9952912330627441
231323345,5821,lindong28,2018-11-06T22:48:40Z,nits: there is one extra space after `=`,0,0.9884095191955566
231329438,5821,lindong28,2018-11-06T23:13:47Z,"currently `brokerepoch` is a `var` and its internal state is also immutable. it is generally preferred to allow mutation in only one way. since `brokerepoch` has its initial value from `kafkaserver.startup()` and it can be updated multiple times in `registerbrokerandreelect`, would it make sense to define ` var brokerepoch: int` in `kafkacontroller` similar to the existing `brokerinfo` field. `kafkaserver.startup()` can get the initial value of the broker epoch as integer and passes it to the `kafkacontroller` constructor as `initialbrokerepoch`. this approach seems much simpler and we would not need the helper class `brokerepoch`.",0,0.9948408007621765
231332131,5821,lindong28,2018-11-06T23:26:01Z,"i am wondering if it will be more intuitive and cleaner to move the logic of checking broker epoch from replicamanager to kafkaapis. currently there is already logic such as `controller.isactive` in kafkaapis which is similar to the logic of checking broker epoch. and if we do that, we can keep replicamanager unchanged. kafkaapis can first compare the epoch from the stoprepliarequest with the epoch in `controller.brokerepoch` before invoking e.g. `replicamanager.stopreplicas(...)`. controller can have api such as `controller.isactivebrokerepoch(epoch)` to make the logic more explicit.",0,0.9918420314788818
231339976,5821,lindong28,2018-11-07T00:02:54Z,"nits: `zookeepr` has typo. would the message `s""$request does not need controller epoch check""` be more appropriate here?",0,0.9870123267173767
231343743,5821,lindong28,2018-11-07T00:23:49Z,"now we have three methods named `retryrequestsuntilconnected(...)`. i am wondering if it would be more readable to keep the number still as two, one for single request and the other for sequence of requests. one thing that may be confusing to the reader is that, `retryrequestsuntilconnected[req <: asyncrequest](requests: seq[req])` does not take `expectedcontrollerzkversion` as parameter and thus it is not clear what is the expected behavior with controller epoch check in this method.",0,0.9522408843040466
231344408,5821,lindong28,2018-11-07T00:27:31Z,"can we also throw `illegalstateexception` if `zkopresults` does not match the pattern `seq(zkopresult(checkop: checkop, checkopresult), zkopresult)`?",0,0.9950177073478699
231348543,5821,lindong28,2018-11-07T00:50:29Z,"now the patch is not longer using zookeeper transaction, will there be issue if e.g. controller znode is created but the controller epoch is not incremented?",0,0.9931516647338867
231352782,5821,hzxa21,2018-11-07T01:14:05Z,the reason why we use int64 for broker epoch is that the `czxid` we get back from zookeeper is of int64 type. i think it is not a good idea to convert it into int32 because we may lose the globally unique and monotonically increasing guarantee.,0,0.9700552225112915
231365666,5821,hzxa21,2018-11-07T02:45:38Z,"after introducing broker epoch, we need to fill in the broker epoch we want to use for the control request we send out. only brokers in `controllercontext.liveorshuttingdownbrokerids` will have a entry in the `controllercontext.brokerepochscache`. the benefit of this change is to ensure that we can always get back the broker epoch from the cache in controller context when constructing the control requests. we can instead add extra logic in `controllerchannelmanager.sendrequeststobrokers` to check the existence of the broker epoch when constructing the request but i think it is cleaner and easier to reason about the code with this change because we will not send out requests to brokers that are not in `controllercontext.liveorshuttingdownbrokerids` anyway. it is true that the broker can become offline and this will cause requestsendthread to fail to send out the request if controller doesn't process the broker change event before requestsendthread sending out the request to the offline broker. this change will not affect this behavior and does not aim to solve this race condition. this change only acts as a pre-filter to ensure we can always construct the control request with broker epoch. whether we can actually send out the request is a separate issue.",0,0.9900836944580078
231397289,5821,lindong28,2018-11-07T06:58:52Z,"sounds good. i am not sure when brokerid in the `brokerids` will be negative. since we don't expect any brokerid in `liveorshuttingdownbrokerids` to be negative, can we just do `brokerids.filter(controllercontext.liveorshuttingdownbrokerids.contains)` to simplify the code here? same for `addstopreplicarequestforbrokers()` and `addupdatemetadatarequestforbrokers()`.",0,0.8642557263374329
231397355,5821,lindong28,2018-11-07T06:59:11Z,yeah i forgot this reason. sounds good.,1,0.6809840202331543
231609250,5821,hzxa21,2018-11-07T17:47:41Z,that is a good point. i think we can simplify it.,1,0.9401563405990601
231624498,5821,hzxa21,2018-11-07T18:28:48Z,thanks for the suggestion. it makes sense and i will move it.,1,0.9417772889137268
231629225,5821,hzxa21,2018-11-07T18:42:53Z,"currently `brokerepoch` can be updated in `kafkaserver.startup()` as well as `registerbrokerandreelect` in the controller, and it can be read by `replicamanager` in order to reject outdated control requests. if we store `brokerepoch` in `kafkacontroller`, it requires passing the `kafkacontroller` object to `replicamanager` just for reading `brokerepoch`. i think use a helper class is simpler in this case. what do you think?",0,0.9935559630393982
231629808,5821,hzxa21,2018-11-07T18:44:39Z,"miss your next comment. if we do the check in `kafkaapis`, then you are right. please ignore the comment i just wrote down.",0,0.9888655543327332
231629969,5821,hzxa21,2018-11-07T18:45:06Z,makes sense. that is a good point.,1,0.8452299237251282
231713300,5821,hzxa21,2018-11-07T23:09:38Z,"i am a little bit confused about your concern. there is no controller epoch check in `retryrequestsuntilconnected[req <: asyncrequest](requests: seq[req])` because this is the raw method that only does send requests as well as receive responses, and the epoch check happens outside of this method when calling `wraprequestwithcontrollerepochcheck` and `unwrapresponsewithcontrollerepochcheck`. maybe i understand you wrong, i think there is little confusion here. do you suggest only have `retryrequestsuntilconnected[req <: asyncrequest](requests: seq[req], expectedcontrollerepochzkversion: int)` and `retryrequestsuntilconnected[req <: asyncrequest](request: req, expectedcontrollerepochzkversion: int)`?",-1,0.6306477785110474
231724344,5821,hzxa21,2018-11-08T00:02:31Z,it is fine because we are using the zookeeper multi op directly right now. it is essentially the same as using zk transaction so we still provide the same guarantee.,0,0.983768880367279
232446499,5821,hzxa21,2018-11-10T08:53:01Z,done.,0,0.9640594124794006
232446521,5821,hzxa21,2018-11-10T08:54:07Z,sure. i have adopted the new pattern in all control requests.,0,0.9889321327209473
232446524,5821,hzxa21,2018-11-10T08:54:13Z,fixed.,0,0.979083240032196
232446526,5821,hzxa21,2018-11-10T08:54:17Z,fixed.,0,0.979083240032196
232446530,5821,hzxa21,2018-11-10T08:54:22Z,fixed.,0,0.979083240032196
232446539,5821,hzxa21,2018-11-10T08:54:30Z,done.,0,0.9640594124794006
232446540,5821,hzxa21,2018-11-10T08:54:34Z,done.,0,0.9640594124794006
232446542,5821,hzxa21,2018-11-10T08:54:38Z,fixed.,0,0.979083240032196
232446547,5821,hzxa21,2018-11-10T08:54:45Z,fixed.,0,0.979083240032196
232446550,5821,hzxa21,2018-11-10T08:54:49Z,done.,0,0.9640594124794006
232446551,5821,hzxa21,2018-11-10T08:54:54Z,fixed.,0,0.979083240032196
232446554,5821,hzxa21,2018-11-10T08:55:02Z,sure. done.,0,0.9251468181610107
232477712,5821,lindong28,2018-11-11T08:02:17Z,"the exception name is inconsistent with name specified in kip-380. i feel that it is better to use the `stale_controller_epoch` which suggests that the broker epoch in the request is smaller than the expected value. since we do not expect the epoch in the request to be larger than the expected value, it would be illegalstateexception if the epoch in the request is larger than the expected value.",0,0.9820472002029419
232477749,5821,lindong28,2018-11-11T08:04:01Z,nits: can we follow the existing code style and move `brokerepochmismatchexception::new` to a new line?,0,0.9934980869293213
232477941,5821,lindong28,2018-11-11T08:11:11Z,"unlike updatemetadatarequest, this field is named `live_leaders` rather than `live_brokers`.",0,0.9940071105957031
232478024,5821,lindong28,2018-11-11T08:13:45Z,nits: there is an unnecessary space.,0,0.7148604393005371
232479092,5821,lindong28,2018-11-11T08:50:14Z,nits: there is an unnecessary space.,0,0.7148604393005371
232479565,5821,lindong28,2018-11-11T09:07:05Z,"can we do `struct.setifexists(offline_replicas, offlinereplicas.toarray())` here? also, it seems that `setifexists(field.array def, object[] value)` and `setifexists(field.complexarray def, object[] value)` in `struct.java` should only set value if the field exists. can you help fix that?",0,0.993195652961731
232479847,5821,lindong28,2018-11-11T09:15:25Z,nits: would it be simpler to just do `brokerids.filter(controllercontext.liveorshuttingdownbrokerids.contains)`? the extra variable name does not seem useful here.,0,0.9913177490234375
232480199,5821,lindong28,2018-11-11T09:25:44Z,"we currently uses `controllercontext.brokerepochscache` in `sendrequeststobrokers()` under the assumption that the `leaderandisrrequestmap`, `updatemetadatarequestpartitioninfomap` and `stopreplicarequestmap` only includes brokerid that is defined in `brokerepochscache`. however, the logic to guarantee this is in other methods such as `addupdatemetadatarequestforbrokers`. would it make the code more readable to put these logics closer together in `sendrequeststobrokers()`? we can make the logic even more explicit by filtering the brokerid using `brokerepochscache` rather than `controllercontext.liveorshuttingdownbrokerids` in `sendrequeststobrokers()`.",0,0.9956377148628235
232480419,5821,lindong28,2018-11-11T09:32:08Z,would it be more readable to have method `isbrokerepochstale`? `iscurrentorunknownbrokerepoch` is a bit verbose and it feels a bit weird to look for unknown broker epoch. `isbrokerepochstale` would better match the name of `stalebrokeepochexception`.,-1,0.7408329844474792
232480534,5821,lindong28,2018-11-11T09:34:41Z,would it be simpler to just name the method `brokerepoch`? the variable can be named `_brokerepoch` similar to `_lastcaughtuptimems` in `replica.scala`.,0,0.9943010807037354
232480834,5821,lindong28,2018-11-11T09:42:29Z,currently most variables (e.g. `livebrokersunderlying`) in `controllercontext` provide cached information. it will be a bit inconsistent and confusing if we just put the word `cache` for brokerepoch. can we just name it `brokerepochs`?,0,0.901919424533844
232480935,5821,lindong28,2018-11-11T09:44:54Z,nits: can we rename `bid` to `brokerid`? `bid` is an english word and currently the existing code does not use `bid` as shortcut for broker id.,0,0.9946969747543335
232481318,5821,lindong28,2018-11-11T09:55:51Z,"the log message itself raises concerns for user/developer without explaining why it is at warning rather than error level. can we add comment that says why this is ok? and since we expect this to happen normally when broker is restarted quickly, i am not sure we need to log it at warning level. we can ask other reviewer to comment on this later.",0,0.9860052466392517
232481594,5821,lindong28,2018-11-11T10:04:18Z,the code can probably be more readable with less nested if/else by doing this: [code block] same for other methods.,0,0.990742027759552
232481972,5821,lindong28,2018-11-11T10:17:56Z,"the code here is comparing the zkversion with epoch, which seems misleading. also, `expectedcontrollerzkversion < 0`, will `expectedcontrollerzkversion` be anything other than `matchanyversion`? if not, it seems better to explicitly check `expectedcontrollerzkversion == zkversion.matchanyversion`. and if they are not equal, we can throw illegalstateexception if `expectedcontrollerzkversion` is negative.",0,0.9861994981765747
232482145,5821,lindong28,2018-11-11T10:24:33Z,nits: it seems that intellij complains here. can you change it to `getsortedbrokerlist()`.,0,0.826686680316925
232482175,5821,lindong28,2018-11-11T10:25:54Z,"do we expect `brokeridznode.decode(...).broker` to return null? if not, it may be simpler to just do `some(brokeridznode.decode(brokerid, getdataresponse.data).broker, getdataresponse.stat.getczxid)`.",0,0.9948784112930298
232482475,5821,lindong28,2018-11-11T10:36:38Z,nits: can you add space between `case class` to be consistent with the existing code style?,0,0.993320107460022
232482769,5821,lindong28,2018-11-11T10:46:07Z,"right, that is what i would suggest to reduce the overloaded methods number from 3 to 2. now looking at it again, the current way also looks good.",0,0.8171480298042297
232516981,5821,hzxa21,2018-11-12T01:37:08Z,that is a good point. i have changed it back to `stale_broker_epoch`. i also move the broker epoch check helper function from `kafkacontroller` to `kafkaapis` and throw `illegalstateexception` when the broker sees the broker epoch in the request larger than the current epoch.,0,0.7076244950294495
232516997,5821,hzxa21,2018-11-12T01:37:19Z,sure. done.,0,0.9251468181610107
232517017,5821,hzxa21,2018-11-12T01:37:31Z,good catch. fixed.,1,0.9882318377494812
232517029,5821,hzxa21,2018-11-12T01:37:37Z,fixed.,0,0.979083240032196
232517036,5821,hzxa21,2018-11-12T01:37:42Z,fixed.,0,0.979083240032196
232517050,5821,hzxa21,2018-11-12T01:38:00Z,sure. fixed.,0,0.9648053050041199
232517068,5821,hzxa21,2018-11-12T01:38:20Z,yes. fixed.,0,0.9153916835784912
232517104,5821,hzxa21,2018-11-12T01:38:45Z,good suggestion. done.,1,0.9897598624229431
232517335,5821,hzxa21,2018-11-12T01:41:16Z,i have renamed it and moved this helper function to `kafkaapis` because it will only be called in `kafkaapis` and we will need to throw `illegalstateexception` when the epoch is larger than the expected one. i think it is more readable this way.,0,0.9869480133056641
232517345,5821,hzxa21,2018-11-12T01:41:21Z,fixed.,0,0.979083240032196
232517357,5821,hzxa21,2018-11-12T01:41:28Z,sure. done.,0,0.9251468181610107
232517373,5821,hzxa21,2018-11-12T01:41:38Z,sure. done.,0,0.9251468181610107
232517606,5821,hzxa21,2018-11-12T01:44:49Z,"comments added. when the broker sees stale controller epoch in the request, we also log the message at warning level. so i think it is better to do the same thing for stale broke epoch to keep it more consistent.",0,0.9881635308265686
232517635,5821,hzxa21,2018-11-12T01:45:15Z,that is a good point. thanks for the suggestion. done.,1,0.9939888715744019
232517651,5821,hzxa21,2018-11-12T01:45:23Z,"fixed. btw, i think it is better to throw `illegalargumentexception` if `expectedcontrollerzkversion` is negative.",0,0.9901548624038696
232517736,5821,hzxa21,2018-11-12T01:46:39Z,fixed.,0,0.979083240032196
232517759,5821,hzxa21,2018-11-12T01:46:51Z,good catch. fixed.,1,0.9882318377494812
232517773,5821,hzxa21,2018-11-12T01:46:57Z,done.,0,0.9640594124794006
232555865,5821,lindong28,2018-11-12T07:37:31Z,"it will be practically very rare to have `broker` that is not found in `controllercontext.brokerepochs`. so this trace level logging is probably not useful. my understanding is that we only use trace level logging for something that is almost always triggered. if we do not have good use-case for this trace level logging, can we simplify the code change here by just adding one line (relative to the original code) to filter the key for `leaderandisrrequestmap`. more specifically, we can change the code from [code block] to [code block] same for `updatemetadatarequestpartitioninfomap` and `stopreplicarequestmap`.",0,0.9893268346786499
232557832,5821,lindong28,2018-11-12T07:47:19Z,nits: `not equal to current broker epoch` => `smaller than the current broker epoch`. same for other logs.,0,0.9929210543632507
232562259,5821,lindong28,2018-11-12T08:08:05Z,"according to the zookeeper client javadoc, the name in `createresponse` is expected to be `the name of the znode that was created`. also, it is mentioned that `on success, name and path are usually, equal, unless a sequential node has been created`. on the other hand, the javadoc for `createresult` says that, `a result from a create operation. this kind of result allows the path to be retrieved since the create might have been a sequential create`. we need to make sure that the `createresult.path` has the same value as the original value of the `name` in `createresponse` when a sequential node is created. the javadoc `createresult` suggests this is the case but the name of its variable, i.e. `path`, suggests they are different. can you double check this by creating a sequential znode?",0,0.9920265078544617
232566446,5821,lindong28,2018-11-12T08:27:51Z,"should we also update `controllercontext.brokerepochs` properly in `brokermodifications.process()`? to reduce the chance of missing such update in the future, it is probably good to make `brokerepochs` a private variable. and expose a single method in `controllercontext` to update `brokerepochs`, `livebrokersunderlying` and `livebrokeridsunderlying` together. this method can replace the existing method `livebrokers_=(brokers: set[broker])` in `controllercontext`.",0,0.9941149353981018
232567122,5821,lindong28,2018-11-12T08:30:51Z,"thinking about this more, it may be better to do the following to explicit show that we want to keep only broker ids that are in `liveorshuttingdownbrokerids`. [code block]",0,0.9937117099761963
232764958,5821,hzxa21,2018-11-12T18:25:36Z,"both zookeeper `createrequest` and `createresponse` use the field `path` to represent the resulting path (can handle the sequential create case). i think what you think it is confusing is that when we are using zookeeper async create, the `processresult` methond in `stringcallback` has a `path` field to represent the path included in the request and has a `name` field to represent the resulting path. i double check zookeeper source code and zookeeper client (to be more specific, in `clientcnxn.java`). the logic to invoke the callback is: [code block] the 2nd argument in `processresult` is `path` and the 4th argument is `name`. this confirms that we use `rsp.getpath()` for the `name` in `processresult`.",0,0.992191731929779
232767009,5821,hzxa21,2018-11-12T18:32:10Z,"i actually think of what you have suggested at the very beginning and the reason i didn't do that is that the only place we can update the broker epoch is in brokerchange event. broker epoch will only change when the broker ephemeral znode gets deleted and re-created so that is why we use czxid (create transaction id). czxid will only change when we create the broker znode, not when we modify it, so in `brokermodification` event the czxid will not change. the only place we will capture the czxid change is in `brokerchange` evnet because we are listening on the children nodes change.",0,0.98831707239151
232772273,5821,hzxa21,2018-11-12T18:49:51Z,agree. done.,0,0.8812008500099182
232772296,5821,hzxa21,2018-11-12T18:49:56Z,fixed.,0,0.979083240032196
232782780,5821,lindong28,2018-11-12T19:25:52Z,sounds good. thanks for the explanation.,1,0.9526329040527344
232782818,5821,lindong28,2018-11-12T19:25:59Z,sounds good. thanks for the explanation.,1,0.9526329040527344
233259207,5821,junrao,2018-11-13T23:11:36Z,could we fix the javadoc above?,0,0.9934825301170349
233260194,5821,junrao,2018-11-13T23:15:47Z,"it would be useful to avoid _1/_2 for better readability. we could do foreach { case (broker, epoch) => ...}",0,0.9906128644943237
233278007,5821,junrao,2018-11-14T00:43:32Z,it would be useful to avoid _1/_2 for better readability.,0,0.9878756403923035
233278057,5821,junrao,2018-11-14T00:43:47Z,it would be useful to avoid _1 for better readability.,0,0.9814452528953552
233279558,5821,junrao,2018-11-14T00:52:38Z,"instead of bouncedbrokerids(broker.id), it might be clearer to do bouncedbrokerids.contains(broker.id).",0,0.9940756559371948
233281539,5821,junrao,2018-11-14T01:03:18Z,"hmm, could we just change livebrokersunderlying to a map[broker, long] instead of introducing a separate val?",0,0.9842879772186279
234024398,5821,junrao,2018-11-15T21:59:47Z,could this be debug?,0,0.9894627928733826
234025608,5821,junrao,2018-11-15T22:04:07Z,this probably should be info since we handle it as expected.,0,0.9836609959602356
234028770,5821,junrao,2018-11-15T22:15:45Z,"normally, when we call onbrokerfailure(), the passed in deadbrokers won't be in controllercontext.livebrokers, which is used by onbrokerfailure() through partitionstatemachine/replicastatemachine. with this change, this may not be true. will that have any impact?",0,0.9890249371528625
234029553,5821,junrao,2018-11-15T22:18:43Z,should we log the broker epoch in addition to the broker id?,0,0.9945975542068481
234033660,5821,junrao,2018-11-15T22:34:33Z,could we use case for e to avoid _1/_2?,0,0.994782030582428
234055778,5821,junrao,2018-11-16T00:24:48Z,"this may be an existing problem. if a zk multi fails because of one of the operations, does that error get reflected in the rc in the top level response or in individual zkopresult?",0,0.9883268475532532
234057258,5821,junrao,2018-11-16T00:34:27Z,"do we need to add ()? in general, we only need () for methods with side effects.",0,0.9885863661766052
234059863,5821,junrao,2018-11-16T00:50:39Z,this logic needs to be done after the response.resultcode match block as before the patch since getafternodeexists() can return code.ok too.,0,0.9936637878417969
234061971,5821,junrao,2018-11-16T01:04:43Z,is it still useful to log in the above line since codeafterrecreate hasn't changed?,0,0.9933185577392578
234062220,5821,junrao,2018-11-16T01:06:25Z,typo abstarct,0,0.9655051231384277
234064469,5821,junrao,2018-11-16T01:21:21Z,perhaps those warn should be info since there is nothing for the user to act on this.,0,0.9541498422622681
234065021,5821,junrao,2018-11-16T01:25:20Z,epoch => brokerepochinrequest ?,0,0.9633449912071228
234065222,5821,junrao,2018-11-16T01:26:51Z,there is logging in zkclient.registerbroker(). we could just log the broker epoch there.,0,0.9950954914093018
234067161,5821,junrao,2018-11-16T01:40:40Z,are leader_and_isr_request_topic_state_v0 and leader_and_isr_request_partition_state_v1 still valid? perhaps it's simpler to just say we normalized partitions under each topic.,0,0.9942674040794373
234069244,5821,junrao,2018-11-16T01:54:52Z,this is unnecessary since shutdown() is blocking.,0,0.9804352521896362
234069643,5821,junrao,2018-11-16T01:56:25Z,"since the propagation of the zk event is async, we may need to put the checking logic in a waituntiltrue() block. ditto below.",0,0.991824209690094
234069804,5821,junrao,2018-11-16T01:57:13Z,the comment seems out of place.,0,0.8443710207939148
234070541,5821,junrao,2018-11-16T02:02:40Z,outdated comment?,0,0.9534004330635071
234070606,5821,junrao,2018-11-16T02:03:07Z,we are not sending stale epoch anymore?,0,0.9750679731369019
234070761,5821,junrao,2018-11-16T02:04:24Z,does this need to be volatile?,0,0.9890959858894348
234071333,5821,junrao,2018-11-16T02:08:28Z,the code in this method is quite similar to that in testcontrolrequestwithcorrectbrokerepoch(). should we merged them somehow?,0,0.9909946322441101
234071751,5821,junrao,2018-11-16T02:11:44Z,should this be volatile?,0,0.9902241826057434
234073100,5821,junrao,2018-11-16T02:21:50Z,this is unnecessary. great test!,1,0.9945111274719238
234073572,5821,junrao,2018-11-16T02:25:08Z,indentation,0,0.822169840335846
234073709,5821,junrao,2018-11-16T02:26:06Z,indentation,0,0.822169840335846
234144660,5821,hzxa21,2018-11-16T09:48:12Z,"this is a very good point. i think it is fine because the bounced broker will reject the control requests anyway because the cached broker epoch has not been updated yet. however, this brings up another question: do we actually need to call `onbrokerfailure()` for bounced brokers? after a second thought, i think the answer is no because the end goal of controller handling bounced brokers in brokerchange event is to make sure the quickly bounced brokers will be initialized correctly and the end partition/replica states will be the same with and without calling `onbrokerfailure` for the bounced brokers (if there are no new brokers and dead brokers). in this case, only calling `onbrokerstartup` is sufficient. invoking `onbrokerfailure` first is a correct and safe option but it comes with some overhead because we need to perform leader election and send out the stopreplica/leaderandisr/updatemetadata, which are not necessary. previously i thought that missing `onbrokerfailure` will cause correctness issue because we might miss some state clean up but looks like it is not the case. also note that if we use controlled shutdown to shutdown and restart the broker, the leadership election actually happens before processing the brokerchangeevent. tl;dr: to be more specific for your original question (why updating the live brokers first then invoke `onbrokerfailure` is fine), there are three places where we use the live brokers informartion in `onbrokerfailure`: 1. determine whether we need to transition partition states to offlinepartition: since at the time of the brokerchange event processing, the bounced brokers are alive so there will not be offline partitions. 2. determine which brokers we want to consider when performing leader election in `partitionstatemachine.triggeronlinepartitionstatechange()`: since the bounced brokers are online at that time so we should consider them. 3. determine which brokers we need to send out control requests and which brokers we need to include in the live brokers field in updatemetadatarequest: since the bounced brokers will not accept control requests anyway so the first point doesn't matter. for the second point, the bounced brokers are live so we don't want to exclude them in the updatemetadatarequest.",1,0.5359353423118591
234152612,5821,hzxa21,2018-11-16T10:13:25Z,"code from zookeeper (clientcnxn.java): [code block] this suggests that if we can get back the opresult from zookeeper (no connection_loss), rc represents the first error in the operations. so using the rc in the top level response after unwrapping the multi response is fine becuase the first error will also be the actual error for create/setdata/delete if we pass the controller epoch check. this also suggests that list[opresult] can be null in the callback and i don't handle this in our zookeeperclient so i will fix it.",0,0.9919736385345459
234307011,5821,lindong28,2018-11-16T18:36:20Z,"regarding info vs. warn, i usually follow the summary in [a link] which says that info level is for `generally useful information to log (service start/stop, configuration assumptions, etc)`, and warn level is for `anything that can potentially cause application oddities, but for which i am automatically recovering`. in this case the `brokerepoch < cachedbrokerepoch` can happen only under rare scenario when controlledshutdownrequest is re-sent due to disconnection between broker and controller. this is similar to the scenarios captured in `networkclient.processdisconnection(...)` which are currently logged in warn level. and it is unlike all other info level logging in kafka for normal broker start/stop. so it seems that warn level is appropriate here?",0,0.9939334988594055
236885202,5821,junrao,2018-11-27T23:14:43Z,"yes, the question is whether rare == odd. to me, odd should be unexpected. brokerepoch < cachedbrokerepoch is rare, but is not unexpected.",0,0.9690147042274475
236902108,5821,junrao,2018-11-28T00:36:16Z,": overall, i agree with your assessment that the onbrokerfailure() call seems redundant. the only thing is that it can force a leader epoch change. suppose that broker 1 is a bounced broker and is the current leader. if we skip onbrokerfailure(), the controller just keeps broker 1 as the leader w/o bumping the leader epoch. this means that the follower won't go through leader epoch based log truncation, which maybe needed since broker 1 may not have all the data in its local log after the bounce. so, perhaps we can't skip onbrokerfailure(). the next question is should the live broker list exclude the bounced brokers when we call onbrokerfailure(). it seems that we should since live broker list influences which broker is the new leader. if the bounced brokers are still in the live broker list and are the current leaders, those leaders' epoch won't change. so, in summary, it seems that we should still call onbrokerfailure() but excluding bounced brokers from live broker list first. we then add the bounced brokers to live broker list and call onbrokerstartup().",0,0.9909977912902832
236906085,5821,hzxa21,2018-11-28T00:57:13Z,"i agree. also after an offline discussion with dong, we agree that the benefit of optimizing for quickly bounced brokers is minor and since in normal scenario we will go through onbrokerfailure and then onbrokerstartup for the bounce brokers, it is better to do the same thing here ( invoke onbrokerfailure() and then update live brokers). thanks for the comment. i will update the pr accordingly.",1,0.9680647253990173
236907622,5821,junrao,2018-11-28T01:05:33Z,"thanks. since the code still uses the rc in the individual ops, it seems that we need to change it to check the top level rc?",1,0.7176803946495056
237354671,5821,hzxa21,2018-11-29T05:09:40Z,fixed.,0,0.979083240032196
237354685,5821,hzxa21,2018-11-29T05:09:45Z,fixed.,0,0.979083240032196
237354693,5821,hzxa21,2018-11-29T05:09:49Z,fixed.,0,0.979083240032196
237354698,5821,hzxa21,2018-11-29T05:09:52Z,fixed.,0,0.979083240032196
237354713,5821,hzxa21,2018-11-29T05:10:02Z,done.,0,0.9640594124794006
237354811,5821,hzxa21,2018-11-29T05:10:53Z,"good suggestion. i have changed livebrokeridsunderlying to a map[int, long] to avoid introducing the val.",1,0.9676052331924438
237355006,5821,hzxa21,2018-11-29T05:12:19Z,i think it is better to keep it info because the broker epoch information is as informative as the broker ids. we als log the broker ids in info log so we should keep it consistent.,0,0.987069845199585
237355104,5821,hzxa21,2018-11-29T05:13:13Z,i think info is fine. i have changed it to info. thanks you guys for sharing the guideline.,1,0.9888229370117188
237355138,5821,hzxa21,2018-11-29T05:13:31Z,done.,0,0.9640594124794006
237355290,5821,hzxa21,2018-11-29T05:14:32Z,the broker epoch is already logged at the end of the broker change event: [a link],0,0.9907346963882446
237355315,5821,hzxa21,2018-11-29T05:14:43Z,sure. done.,0,0.9251468181610107
237357526,5821,hzxa21,2018-11-29T05:27:45Z,"we need to use the rc in the individual ops (check and create/delete/set) because we need to differentiate whether the error happened in the controller epoch znode zkversion check or in create/delete/set. the opresut for the check op will reflect whether it has succeeded or not. if it succeeds, the top level rc will reflect the error happened in create/delete/set and we do use top level rc when constrcuting the response for create/delete/set. if the check op fails, we will throw exception accordingly.",0,0.9943199157714844
237357668,5821,hzxa21,2018-11-29T05:28:58Z,i don't think we need to add () here. the problem is we have () in the function definition which exists before this patch. i remove the () in the updated pr.,0,0.9834851622581482
237357712,5821,hzxa21,2018-11-29T05:29:19Z,good catch. thanks for pointing it out. fixed.,1,0.9952340722084045
237357743,5821,hzxa21,2018-11-29T05:29:33Z,no. my bad. i have removed the log.,-1,0.9906607270240784
237357752,5821,hzxa21,2018-11-29T05:29:38Z,fixed.,0,0.979083240032196
237357777,5821,hzxa21,2018-11-29T05:29:48Z,sure. done.,0,0.9251468181610107
237357789,5821,hzxa21,2018-11-29T05:29:52Z,done.,0,0.9640594124794006
237357805,5821,hzxa21,2018-11-29T05:30:03Z,yes. done.,0,0.819446325302124
237357830,5821,hzxa21,2018-11-29T05:30:15Z,thanks for the suggestion. done.,1,0.7864897847175598
237357840,5821,hzxa21,2018-11-29T05:30:23Z,removed.,0,0.9782117605209351
237357856,5821,hzxa21,2018-11-29T05:30:30Z,good point. fixed.,1,0.9682416915893555
237357868,5821,hzxa21,2018-11-29T05:30:35Z,removed.,0,0.9782117605209351
237357874,5821,hzxa21,2018-11-29T05:30:39Z,removed.,0,0.9782117605209351
237357953,5821,hzxa21,2018-11-29T05:31:19Z,fixed.,0,0.979083240032196
237358000,5821,hzxa21,2018-11-29T05:31:37Z,yes. fixed.,0,0.9153916835784912
237358049,5821,hzxa21,2018-11-29T05:32:02Z,sure. i have merged them into a single function.,0,0.988676905632019
237358057,5821,hzxa21,2018-11-29T05:32:07Z,yes. fixed.,0,0.9153916835784912
237358075,5821,hzxa21,2018-11-29T05:32:14Z,remove. thanks!,1,0.9925965070724487
237358087,5821,hzxa21,2018-11-29T05:32:17Z,fixed.,0,0.979083240032196
237358092,5821,hzxa21,2018-11-29T05:32:21Z,fixed.,0,0.979083240032196
237710891,5821,junrao,2018-11-30T00:33:25Z,could initialbrokerepoch be right after initialbrokerinfo?,0,0.9940372705459595
237716547,5821,junrao,2018-11-30T01:07:40Z,indentation,0,0.822169840335846
237718706,5821,junrao,2018-11-30T01:21:33Z,control request => controlled shutdown request,0,0.9804023504257202
237719353,5821,junrao,2018-11-30T01:26:07Z,the controller part is not right. non-controllers are registered through this api too.,0,0.92138671875
237719687,5821,junrao,2018-11-30T01:28:31Z,it seems that this logging is redundant since registerbroker() logs the same info already?,0,0.9896107912063599
237721321,5821,junrao,2018-11-30T01:40:07Z,perhaps it's better to return a map instead of a sequence of pairs?,0,0.9932981133460999
237723919,5821,junrao,2018-11-30T01:58:10Z,normalize => normalizes,0,0.9807645678520203
237724317,5821,junrao,2018-11-30T02:01:06Z,perhaps add a comment on how v1 differs from v0?,0,0.9913026094436646
237724569,5821,junrao,2018-11-30T02:02:47Z,normalize => normalizes,0,0.9807645678520203
237725390,5821,junrao,2018-11-30T02:08:58Z,unused import,0,0.9524969458580017
237725957,5821,junrao,2018-11-30T02:13:03Z,typo reuest,0,0.9668195843696594
237799160,5821,hzxa21,2018-11-30T09:42:03Z,sure. done.,0,0.9251468181610107
237799446,5821,hzxa21,2018-11-30T09:43:00Z,fixed.,0,0.979083240032196
237799723,5821,hzxa21,2018-11-30T09:43:54Z,"i mean leaderandisr/updatemetadata/stopreplica requests here, not controlled shutdown request. i have updated the comment to avoid confusion.",0,0.9898927807807922
237799747,5821,hzxa21,2018-11-30T09:44:00Z,fixed.,0,0.979083240032196
237799890,5821,hzxa21,2018-11-30T09:44:27Z,thanks for pointing out. i have removed the log here.,1,0.9088107943534851
237799946,5821,hzxa21,2018-11-30T09:44:39Z,agree. fixed.,0,0.9794597029685974
237799968,5821,hzxa21,2018-11-30T09:44:42Z,fixed.,0,0.979083240032196
237799996,5821,hzxa21,2018-11-30T09:44:48Z,sure. added.,0,0.9809174537658691
237800040,5821,hzxa21,2018-11-30T09:44:53Z,fixed.,0,0.979083240032196
237800071,5821,hzxa21,2018-11-30T09:44:58Z,removed.,0,0.9782117605209351
237800090,5821,hzxa21,2018-11-30T09:45:02Z,fixed.,0,0.979083240032196
238013840,5821,junrao,2018-11-30T21:53:05Z,could we put return after param ?,0,0.9936410784721375
238013931,5821,junrao,2018-11-30T21:53:30Z,could we change the comment accordingly?,0,0.9925690293312073
238020317,5821,hzxa21,2018-11-30T22:20:31Z,sure. done.,0,0.9251468181610107
238020331,5821,hzxa21,2018-11-30T22:20:36Z,done.,0,0.9640594124794006
238021750,5821,junrao,2018-11-30T22:26:43Z,it seems that you fixed a different line?,0,0.9823499917984009
238069509,5821,hzxa21,2018-12-01T16:57:44Z,ah. my bad. i mislooked this one. fixed.,-1,0.9920433163642883
205630399,5428,guozhangwang,2018-07-26T23:23:28Z,this is a bug found in mockproducer: we should never throw producerfenced in send() call as it should only be returned in the future callback.,0,0.9616326093673706
205630643,5428,guozhangwang,2018-07-26T23:24:49Z,"this is the optimization on commit: we only execute commit when some processing has been done since last commit, either some records processed, or punctuation triggered. for standby task commit will be triggered only when some update has been applied to the state store.",0,0.9940977096557617
205630742,5428,guozhangwang,2018-07-26T23:25:28Z,this is the optimization we have done for partition stream time update.,0,0.9902691841125488
205912746,5428,guozhangwang,2018-07-27T22:19:59Z,this is not intended and will be removed when rebasing on part ii merged.,0,0.9846343398094177
207436880,5428,guozhangwang,2018-08-03T04:17:16Z,this test is invalid (see the above comment).,0,0.9682216048240662
207436995,5428,guozhangwang,2018-08-03T04:18:12Z,"if a producer is fenced, its producerfencedexception is wrapped in the kafkaexception.",0,0.9934729933738708
207437074,5428,guozhangwang,2018-08-03T04:18:47Z,this function should only be called once within each iteration after records enqueued.,0,0.9926718473434448
207437109,5428,guozhangwang,2018-08-03T04:19:08Z,inline this function since it only have one caller.,0,0.9882490634918213
207437286,5428,guozhangwang,2018-08-03T04:21:09Z,"this flaky test is found while working on the pr, so i'm piggy back the fix here. but itself is really independent of the pr, so if people wants to put it into a separate one i can also do that.",-1,0.6889224648475647
208295539,5428,bbejeck,2018-08-07T16:16:47Z,i think we could simplify this block like so [code block] wdyt?,0,0.9881911873817444
208346664,5428,bbejeck,2018-08-07T18:54:08Z,"in trunk, the ordering of calls for the `producer` during a commit was broken up, but now they are all grouped together. it seems ok to do this and is cleaner to follow, i just wanted to double check the change of ordering doesn't matter. maybe we should run system tests to confirm?",0,0.9836519956588745
208347652,5428,bbejeck,2018-08-07T18:56:53Z,nit: we could return `commitneeded` and get rid of `else` and return `false` directly if no punctuation occurred.,0,0.9944124817848206
208347752,5428,bbejeck,2018-08-07T18:57:10Z,same as above,0,0.965356171131134
208354835,5428,bbejeck,2018-08-07T19:20:47Z,nice addition!,1,0.9957290291786194
208727056,5428,guozhangwang,2018-08-08T20:37:54Z,"good point, i will run the system test accordingly.",1,0.5616188645362854
208728232,5428,guozhangwang,2018-08-08T20:41:28Z,yup! :),1,0.9959648847579956
208741696,5428,mjsax,2018-08-08T21:27:14Z,should we check the root cause?,0,0.9912760257720947
208745329,5428,mjsax,2018-08-08T21:41:04Z,"isn't this a behavior change? iirc, we had a discussion to do this change, or to maybe make it configurable if we want to interleave processing with recovery.",0,0.9911558628082275
208745919,5428,mjsax,2018-08-08T21:43:28Z,should this be `timesincelastpoll >= maxpolltimems / 2` ?,0,0.9941278696060181
208747346,5428,mjsax,2018-08-08T21:49:19Z,"we set poll interval to integer.max_value by default. thus, if user does not change the default (most won't i assume), the condition will never be met. should we rather consider to set a different default value (note, there is already a jira for this)?",0,0.9925617575645447
208749613,5428,mjsax,2018-08-08T21:58:16Z,isn't `timesincelastpoll < maxpolltimems` covered via `if (timesincelastpoll / 2 >= maxpolltimems) { break; }` and redundant?,0,0.9926633834838867
208761166,5428,mjsax,2018-08-08T22:55:11Z,could we actually remove this guard? we don't call `time. milliseconds()` as below.,0,0.9932481050491333
208761888,5428,mjsax,2018-08-08T22:59:09Z,"why do we need this? wouldn't it be easier to remove `else` block and just call `return committed > 0;` after the `if`? if i understand correctly, we want to return `true` if committing happen, and currently, even if we commit we could return `false`",0,0.992228090763092
208771114,5428,guozhangwang,2018-08-08T23:55:56Z,good point!,1,0.9942666888237
208771638,5428,guozhangwang,2018-08-08T23:59:02Z,"ah good point! i was actually not intentionally changing the behavior, i will revert it back to the old manner.",1,0.9926361441612244
208772074,5428,guozhangwang,2018-08-09T00:01:52Z,"yes, that was my plan. i'm aware that this line is basically a no-op because max.poll is integer.max_value, and want to do it in another pr. if people feel that we should reverse the ordering, i.e. change the default value first, then do this pr, i'm fine too.",0,0.8633229732513428
208772154,5428,guozhangwang,2018-08-09T00:02:28Z,"gosh, my bad.",-1,0.9930311441421509
208772446,5428,guozhangwang,2018-08-09T00:04:17Z,"yes. in an old commit the code structure was a bit different and hence we may run over the check (assuming the maxpolltimems is not integer.max_value), but in this format we will always check for `timesincelastpoll >= maxpolltimems / 2` anyways in each loop, and hence we can remove this.",0,0.9896648526191711
208772726,5428,guozhangwang,2018-08-09T00:06:00Z,"the intention is to save calling `taskmanager.activetaskids(), taskmanager.standbytaskids()` etc and pass them as parameters. it may not really introduce significant differences, but no harm to still keep them?",0,0.985375165939331
208772966,5428,guozhangwang,2018-08-09T00:07:45Z,"you're right, and actually i should changed the above line to `committed += taskmanager.commitall();`.",0,0.9734272956848145
208773153,5428,mjsax,2018-08-09T00:08:52Z,"i would personally prefer, to keep the condition in the `while` conditions instead of using `if() break` construct.",0,0.9893532991409302
208773238,5428,mjsax,2018-08-09T00:09:30Z,"i see. fine with my both ways -- as long as it's intentional and we know about it, it's ok.",1,0.6227365136146545
208997552,5428,guozhangwang,2018-08-09T16:33:28Z,this is also a flaky test that i discovered here.,0,0.7054515480995178
209042674,5428,mjsax,2018-08-09T18:56:36Z,fine with me to keep the guard. was just double checking.,0,0.8472738265991211
209293245,5428,vvcephei,2018-08-10T15:13:11Z,i didn't follow why we need this now. can you explain?,0,0.720778226852417
209300543,5428,vvcephei,2018-08-10T15:36:16Z,"just checking my understanding: we are planning to replace this counter with a wall-clock timer in kip-353. i think that once we do that, we can actually move this logic into `isprocessable()` because the condition would no longer be dependent on the number of calls.",0,0.9801472425460815
209300893,5428,vvcephei,2018-08-10T15:37:31Z,"it seems like it might be worth actually putting your remark ""this function should only be called once within each iteration after records enqueued."" in a comment so we can remember during refactoring later.",0,0.9906874299049377
209310471,5428,vvcephei,2018-08-10T16:09:53Z,is this just because punctuations might result in context.forwards?,0,0.9876825213432312
209313656,5428,vvcephei,2018-08-10T16:20:51Z,"i believe that java (or the alu) will do exactly the same thing whether you say `maxpolltimems >> 1` or `maxpolltimems / 2`, but your human colleagues might appreciate the latter ;)",1,0.9772747755050659
209336733,5428,vvcephei,2018-08-10T17:47:21Z,"nice! now that the condition is no longer dependent on the number of invocations, i think you can move it into `isprocessable()` and not need to call this method outside of this class.",1,0.9518952369689941
209338385,5428,vvcephei,2018-08-10T17:53:27Z,"actually, we should re-set the timer whenever we process, right? imagine we have the following sequence: [code block]",0,0.9905263185501099
209339003,5428,vvcephei,2018-08-10T17:55:50Z,"i think there's a risk of forcing processing on the very first iteration if too much time passes between construction and processing (like if the startup protocol takes a while). maybe we can initialize it to `long.max_value` instead, which should cause us never to force processing the first time.",0,0.9796104431152344
209344830,5428,vvcephei,2018-08-10T18:16:44Z,"i take it this was the source of the flakiness. can you explain why, for my education?",-1,0.5437462329864502
209405125,5428,guozhangwang,2018-08-10T23:23:23Z,"this is following the same pr that had: [a link] the point is that when a xxxconfig is created, by default it will print `logall` and hence swamped the logs (we can see the same lists to be printed multiple times whenever it is created). this function is to disable `log` for such cases.",0,0.993083119392395
209405232,5428,guozhangwang,2018-08-10T23:24:16Z,actually it is because users can call `context.commit()` in either ` punctuate()` or `process()` calls.,0,0.9954425096511841
209405249,5428,guozhangwang,2018-08-10T23:24:32Z,ack :),1,0.9894511103630066
209405308,5428,guozhangwang,2018-08-10T23:25:07Z,"yup, good point.",1,0.9837555885314941
209405511,5428,guozhangwang,2018-08-10T23:27:15Z,"that's a good catch, but if we move `isprocessable()` inside the iteration, it will mean that we will only enforce-process one record for every `max.idle.ms` right? my original thought is that once we've decided to enforce process, we'll enforce for that whole thread iteration.",0,0.8434239029884338
209405561,5428,guozhangwang,2018-08-10T23:27:49Z,"hmm, good point, i'll see what can be done here.",1,0.5359721183776855
209405825,5428,guozhangwang,2018-08-10T23:30:47Z,"the flakiness is actually that for this dedup integration test, we should check that ""for each key, the last record is the expected value"", while previously we just check that ""we retrieve n records, and check that these n records are exactly the expected values"". however even with dedup based on caching, it may not be the case that we only produce n final records. this pr increases the likelihood that we do not only produce n final records, and hence i updated the check logic accordingly.",0,0.9895323514938354
209406887,5428,guozhangwang,2018-08-10T23:42:22Z,i will set the enforced process in the `inittopology` which will be triggered when the task transits to running state.,0,0.992177426815033
209757140,5428,vvcephei,2018-08-13T21:00:25Z,ah! i misread this as turning `logall` *on* instead of *off*. now i get it :),1,0.9880967140197754
210646404,5428,bbejeck,2018-08-16T15:43:04Z,nit: can be package private,0,0.9883657693862915
210646473,5428,bbejeck,2018-08-16T15:43:19Z,nit: can be package private,0,0.9883657693862915
210689155,5428,bbejeck,2018-08-16T18:02:59Z,why did this go from 2 to 1? other than not passing an arg to `runonce` the test logic to this point hasn't changed,0,0.980369508266449
211453536,5428,guozhangwang,2018-08-21T01:16:54Z,"the logic does have changed: in the old code we will commit twice on producer, one during the rebalance and one from the elapsed time. in the new code, the optimization i added will realize that nothing has been generated since the last commit, and hence we will skip committing in this case. thinking about it, this does have a side-effect though since for eos if commit was not called in a long time then txn will be aborted, and if producer does not talk to txn coordinator even longer it could be removed as well. but personally i think it is okay for such scenario to happen, since really no data was generated, and hence committing an empty txn does not really make sense, and we should rather increase the txn expiration time in this case. wdyt?",0,0.9569788575172424
211764912,5428,vvcephei,2018-08-21T21:23:35Z,"i guess that we always have a transaction open, not just when we have something to commit. it seems like one solution is to open a transaction only when we have data to process. although this might complicate things. alternatively, is there a way to periodically send a ""keep alive"" message to let the broker know we do still intend to use that transaction? it seems like either this or just abort/close the empty txn and re-open is better than a super-long expiration time. otherwise, why is there even an expiration time? is there any tradeoff between having one transaction open for a super long time, vs periodically closing empty transactions and starting new ones?",0,0.9432520866394043
211773323,5428,guozhangwang,2018-08-21T21:57:21Z,"completing a txn and starting a new one come with some cost, and hence is what we want to avoid generally. on the other hand, we do not yet have a mechanism for ""keep alive"": with that, i think keeping a long lived empty txn is okay, note that if the txn is not empty, then not committing it in time will increase the latency. hence i'm only trying to optimize the case when the txn is empty.",0,0.9732059240341187
211775968,5428,mjsax,2018-08-21T22:09:46Z,"i just talked to about this. not committing is actually fine. note, that begintx() is a client local state transition -- nothing is written to the log (there are no ""begin tx markers"") and the tc state is also not modified. this implies, that the transaction timeout is not started on begintx() -- the timeout only starts after the first record was written to the log. thus, we don't need ""keep alive heartbeats"" and don't need to tell users to increase the tx timeout for low traffic topics that might have longer periods with no data.",0,0.9817644953727722
212116777,5428,mjsax,2018-08-22T21:30:07Z,nit: `out-of-ordering` -> `out-of-order`,0,0.9932726621627808
212120236,5428,mjsax,2018-08-22T21:44:01Z,nit: can be limited to be package private,0,0.988983690738678
212120925,5428,mjsax,2018-08-22T21:46:59Z,nit: `failed to commit streamtask {} due` -- to distinguish active and standbys as before.,0,0.9822695851325989
212121159,5428,mjsax,2018-08-22T21:47:55Z,why do we remove `tasktypename` for the log statement?,0,0.9932628273963928
212121272,5428,mjsax,2018-08-22T21:48:21Z,why do we remove `tasktypename` for the log statement?,0,0.9932628273963928
212121781,5428,mjsax,2018-08-22T21:50:33Z,"i think we should increase `committed` after `task.commit()` returns -- otherwise, we over count if committing fails?",0,0.9914408922195435
212121812,5428,mjsax,2018-08-22T21:50:42Z,"i think we should increase `committed` after `task.commit()` returns -- otherwise, we over count if committing fails?",0,0.9914408922195435
212122618,5428,mjsax,2018-08-22T21:54:04Z,nit: `lastenforcedprocess[ingtime[stamp]]` ?,0,0.9926365613937378
212122704,5428,mjsax,2018-08-22T21:54:20Z,nit: `enforedprocess[ing]`,0,0.9912508726119995
212123252,5428,mjsax,2018-08-22T21:56:36Z,should we change the order of the order? not sure atm if this has a semantic impact due to potential partial evaluation? just want to double check.,0,0.9304112195968628
212123631,5428,mjsax,2018-08-22T21:58:06Z,"also, it seems that we might want to rename `enforcedprocess` to `enforceprocessing` (without `d`) ?",0,0.995089590549469
212123911,5428,mjsax,2018-08-22T21:59:11Z,this comments seems not to be addressed?,0,0.9528179168701172
212125423,5428,mjsax,2018-08-22T22:05:14Z,"both good points. basically, we should reset the timer when there is data for all input partitions. thus, we should check after poll() if we can reset the timer (ie, in `streamtask#addrecords()` each time all partitions have data)?",0,0.9349157214164734
212125967,5428,mjsax,2018-08-22T22:07:43Z,nit: formatting -> more `}` to next line,0,0.9894982576370239
212126272,5428,mjsax,2018-08-22T22:09:07Z,why do we not check `if(commitneeded)` any longer?,0,0.9925008416175842
212127138,5428,mjsax,2018-08-22T22:13:22Z,"it was broken apart because we checked if there is anything to commit in the first place (ie, do the check on one place)-- if we did not process any data, we don't need to commit. this check now happens outside of `streamtask` as pointed out by guozhang [a link] thus, regrouping makes sense. code is cleaner this way.",0,0.9775621294975281
212128396,5428,mjsax,2018-08-22T22:19:04Z,"meta comment: not sure if this is a good argument for inlining in general---code might be more readable if it's broken apart is smaller pieces and calling methods (with good names) actually self-documents the code. also, shorter methods are easier to understand. for this particular case, inlining is ok imho, as with `if (commitneeded)` check, we don't loose anything.",0,0.9642729759216309
212129095,5428,mjsax,2018-08-22T22:21:57Z,"hmmm... if there is nothing to commit, it might also be fine to ignore the user commit request? it's a tricky question what to do for this case. just follow what the user demands, or be smart? from a correctness point of view, it should not make a difference, would it? also, we set flag `commitrequested` for this case -- thus, it might be better to put this logic somewhere else? eg: `abstracttask` or overwrite in `streamtask`: [code block] (an alternative, that i like less would be to add a check if `commitrequested==true`)?",0,0.9466100335121155
212131579,5428,mjsax,2018-08-22T22:33:34Z,nit: remove `this`,0,0.9891441464424133
212133194,5428,mjsax,2018-08-22T22:41:50Z,nit: `maybeenforceprocess[ing]` ?,0,0.9940009713172913
212133245,5428,mjsax,2018-08-22T22:42:10Z,nit: `maybeenforceprocess[ing]`?,0,0.9943546056747437
212133339,5428,mjsax,2018-08-22T22:42:41Z,nit: `maybeenforceprocess[ing]`?,0,0.9943546056747437
212134225,5428,mjsax,2018-08-22T22:46:58Z,"why this? the condition checks for `activerunningtasks` -- why would we need to punctuate if there are not active tasks? also, should we `maybeupdatestandbytasks()` before we do `maybecommit()` to include the data that is processed by standbys in the commit?",0,0.9948387742042542
212135789,5428,mjsax,2018-08-22T22:55:13Z,this seems to contradict that we set `commitneeded` after punctuations (cf. my comments below).,0,0.987250804901123
212136165,5428,mjsax,2018-08-22T22:57:17Z,"should we move this into the and `else` branch of `if (committimems >= 0 && lastcommitms + committimems < now)` -- if the condition is true, we call `taskmanager.commitall()` and thus `taskmanager.maybecommitactivetasks()` seems to be redundant here?",0,0.995623767375946
212386802,5428,guozhangwang,2018-08-23T17:09:26Z,good point!,1,0.9942666888237
212387543,5428,guozhangwang,2018-08-23T17:12:06Z,"no specific reasons, i should add it back.",0,0.976545512676239
212387559,5428,guozhangwang,2018-08-23T17:12:11Z,ditto.,0,0.6705162525177002
212387745,5428,guozhangwang,2018-08-23T17:12:44Z,yes!,1,0.7005663514137268
212388642,5428,guozhangwang,2018-08-23T17:15:44Z,"the ordering thing: my old-school instinct is to put ""cheapest"" condition first for an `or` operator, but in modern compiler / cpu it really not matter at all :) renaming: ack.",1,0.9945566654205322
212389112,5428,guozhangwang,2018-08-23T17:17:20Z,my bad...,-1,0.9906704425811768
212395430,5428,guozhangwang,2018-08-23T17:37:20Z,"we check this in the assignedtasks now: if no commit is needed, we skip the whole committing function, including commit offsets, flushing stores, etc.",0,0.994667649269104
212398936,5428,guozhangwang,2018-08-23T17:47:42Z,"not sure i follow your comment here.. let me elaborate a bit on my logic: we have two commits in places: commitall (periodic) and maybecommit (for user requested): the latter checks [code block] while the former only checks: [code block] i.e. the logic for the latter is that ""only if user have requested, and it is indeed needed to commit"": for example, if we have actually committed from the commit interval, and then user requested it as well, the second will be omitted. i intentionally separated ""commitrequest"" (this is only set by user) and ""commitneeded"" (this is determined by the library) because this way looks cleaner to me.",0,0.9408332705497742
212399201,5428,guozhangwang,2018-08-23T17:48:27Z,i've removed this function as whole and only reset upon `addrecords` as you suggested.,0,0.9885464906692505
212399262,5428,guozhangwang,2018-08-23T17:48:38Z,ditto below.,0,0.9766393303871155
212400548,5428,guozhangwang,2018-08-23T17:52:24Z,"good catch. the deliberation was that even though ""there is no data processed"", not ""there is no active tasks"" as the original check is `state == running` :) note that although `taskmanager.hasactiverunningtasks()` returns true, we may still not process any data (i.e. `totalprocessed` == 0 and we break the loop immediately). but with the new condition, we will always execute `if (maybepunctuate() || maybecommit())` anyways, so we only need to do `maybeupdate` followed by a `maybecommit` again.",1,0.9767558574676514
212401916,5428,guozhangwang,2018-08-23T17:56:27Z,"actually thinking about this, i feel it is better to separate the standby tasks from active tasks in maybecommit as otherwise we are doomed to waste some cpus doing either one of them. will refactor the code a bit more.",0,0.8244820833206177
212402352,5428,guozhangwang,2018-08-23T17:57:37Z,still not sure if i follow.. we do `maybepunctuate` before `maybecommit` so this should be fine?,0,0.9443952441215515
212402578,5428,guozhangwang,2018-08-23T17:58:25Z,"yes we can, as i mentioned i felt it is better to separate committing for standby tasks and for active tasks.",0,0.9702430367469788
212404222,5428,mjsax,2018-08-23T18:03:45Z,"so setting `commitneeded` is a conservative approach, because we don't know what the user did within punctuation call? might be better to set `commitneeded` if user calls `context.forward` or `state.put()` -- not sure how hard this would be -- would also be out-of-scope for this pr. if we think it might be worth it, we should create a jira for this optimization.",0,0.9897409677505493
212405498,5428,mjsax,2018-08-23T18:07:36Z,i think i miss understood the logic before. please ignore this comment.,-1,0.58446204662323
212779553,5428,mjsax,2018-08-25T00:05:14Z,"nit: the naming always confuses me -- maybe we could rename this to `checkforusercommitrequest` or similar? the name should reflect that this method should be called to ""commit on user request only"" -- not for commit-interval purpose.",0,0.9577292799949646
212779739,5428,mjsax,2018-08-25T00:07:31Z,seems you missed this one :),1,0.9689115881919861
212779906,5428,mjsax,2018-08-25T00:09:27Z,wondering if this is redundant to [code block],0,0.9877628684043884
212780227,5428,mjsax,2018-08-25T00:14:15Z,thought on my last comment?,0,0.9646986126899719
212780732,5428,mjsax,2018-08-25T00:22:19Z,"it seem we rely on `computelatency()` above to advance `now` -- it seems ""dangerous"" to rely on a ""side effect"" for this. should we advance time explicitly here? or at least put a check if `now < lastpollms || now > timesincelastpoll` ?",0,0.9721204042434692
212780848,5428,mjsax,2018-08-25T00:24:17Z,nit: should we rename to `taskmanger.maybepunctuate()` as well as `assignedstreamtasks#maybepunctuate()` to align naming?,0,0.9954819679260254
212780939,5428,mjsax,2018-08-25T00:26:00Z,nit: add comment `// visible for testing`,0,0.9845753908157349
212781336,5428,mjsax,2018-08-25T00:33:14Z,"`taskmanager#commitall()` still commits both, active and standby tasks. what kind of separation do you mean? and even if we separate both, it seems to be orthogonal to my comment. if we commit all tasks because commit time elapses, we don't need to check for user requested commits any longer. atm, we might iterator over all tasks twice. first iteration is checking for user requested commits, and if commit interval is passed, we iterate over all tasks again. however, if we commit time passed, we commit all tasks anyway and thus can avoid checking for user requested commits (ie, we can put `int committed = taskmanager.maybecommitactivetasks();` into the `else` of `if (committimems >= 0 && lastcommitms + committimems < now)` ? or maybe i miss understood your comment?",0,0.978050947189331
212781601,5428,mjsax,2018-08-25T00:38:36Z,"note, that we call `waituntilfinalkeyvaluerecordsreceived` now instead of `waituntilminkeyvaluerecordsreceived`. not sure why we need to update the commit interval? isn't `auto.commit=false` anyway? if not, should we set `auto.commit=false` instead of setting commit interval to ""infinite""?",0,0.9925554394721985
212781654,5428,mjsax,2018-08-25T00:39:41Z,nit: move `consumerproperties` to next line,0,0.9926069974899292
212781954,5428,mjsax,2018-08-25T00:45:26Z,"simplify both lines to `finalaccumdata.putifabsent(kv.key, new arraylist<>()).add(kv);`",0,0.9944332242012024
212781963,5428,mjsax,2018-08-25T00:45:35Z,as above,0,0.9391705989837646
212782085,5428,mjsax,2018-08-25T00:47:20Z,seem so to duplicate line above?,0,0.9913022518157959
212782144,5428,mjsax,2018-08-25T00:48:36Z,"what do you mean by ""respect"" -- don't understand the test name",0,0.8754749298095703
212782288,5428,mjsax,2018-08-25T00:51:28Z,"shouldn't commitrequest not be false by default? also, did you intent to call `task.requestcommit()` above?",0,0.9938428401947021
212782318,5428,mjsax,2018-08-25T00:52:23Z,i think we need to initialize this with `false`? (compare my comment in the tests above),0,0.992716908454895
212782384,5428,mjsax,2018-08-25T00:54:07Z,"if commit interval is 100ms, we might want to test the edge case 100 and 101 -- the test does not cover that we would force processing at 70l already.",0,0.9938588738441467
212782504,5428,mjsax,2018-08-25T00:56:48Z,"why 202l? i cannot inver from the test, to what time the timer get's reset?",0,0.5585897564888
212782744,5428,mjsax,2018-08-25T01:02:32Z,why do we remove this test?,0,0.9751499891281128
213046088,5428,vvcephei,2018-08-27T17:10:02Z,"yeah, i can confirm that i just now got confused about the names. can we maybe call this (and up the chain) `commitifrequestedandneeded` or similar? specifically, the thing that confused me was differentiating the periodic commits on any dirty task vs. the on-demand commit driven by `processorcontext#commit`.",0,0.9635932445526123
213052103,5428,vvcephei,2018-08-27T17:30:25Z,"overall, the enforced-processing algorithm is unclear to me. * following on 's comment, it seems strange to set this right before we return true anyway. note that this is currently the only place we set `enforceprocessing` to true. * also, it still seems to me that `maxtaskidlems` should count from the last time we process at all, not the last time we forced processing (same basic scenario i pointed out last time). is this right?",0,0.9514616131782532
213140235,5428,guozhangwang,2018-08-27T22:55:46Z,"oops, my bad.",-1,0.9922622442245483
213140554,5428,guozhangwang,2018-08-27T22:57:20Z,ack.,0,0.5038502812385559
213141057,5428,guozhangwang,2018-08-27T22:59:59Z,"we still need to commit even if no records are processed: consider a topology which only contains a single source node, then no data processed at all, but we still want to commit so that we would not re-process them right?",0,0.9750924110412598
213152609,5428,guozhangwang,2018-08-28T00:15:02Z,"it is not: once `enforceprocessing` is set, we want to continue in that state until the next batch of records are enqueued and we not have all partitions buffered. note that once we set the flag we update `lastenforcedprocessingtime = now;` as well, but we do not want to disable enforce processing in the next run immediately.",0,0.9933740496635437
213152646,5428,guozhangwang,2018-08-28T00:15:30Z,"it is not: once `enforceprocessing` is set, we want to continue in that state until the next batch of records are enqueued and we not have all partitions buffered. note that once we set the flag we update `lastenforcedprocessingtime = now;` as well, but we do not want to disable enforce processing in the next run immediately.",0,0.9933740496635437
213153611,5428,guozhangwang,2018-08-28T00:24:58Z,"the motivation of advancing `now` in `computelatency` is to save on `milliseconds()` call. i admit it is not ideal, if we want to change it to a different way, say: passing `now` along the calls than using a variable at all, then i'd suggest we do it in a separate pr as this pr has been dragging too long. regarding the check: that is a good idea, but i guess you mean `now - lastpollms > timesincelastpoll` right? i will add that check.",0,0.8780300617218018
213154023,5428,guozhangwang,2018-08-28T00:28:20Z,"i think `commit()` and `punctuate()` in taskmanager is okay, as they return the number of actual number of punctuation / commits triggered, while the `maybexx` returns true or false.",0,0.9921221137046814
213154784,5428,guozhangwang,2018-08-28T00:34:22Z,"i left a general comment before, copying here: [code block] regarding your question: yes i think switching the checking for time-based commits and then user-requested commits for now makes sense, i will update the code accordingly.",0,0.9736418724060059
213155160,5428,guozhangwang,2018-08-28T00:37:36Z,"i think this is not needed, will remove this.",0,0.9469522833824158
213156091,5428,guozhangwang,2018-08-28T00:44:52Z,"note sure what do you mean? `task.needcommit()` sets the flag, `commitrequested()` checks the flag. do you suggest renaming `needcommit` to `requestcommit`?",0,0.9936316609382629
213156299,5428,guozhangwang,2018-08-28T00:46:21Z,"the default init value should be `false` anyways, but yeah i can make it explicit.",0,0.9825621843338013
213156684,5428,guozhangwang,2018-08-28T00:49:15Z,"note we are testing for max idle time as `now - lastenforcedprocessingtime > maxtaskidlems` so 101 is necessary, ditto for below `202`.",0,0.994455873966217
213157946,5428,guozhangwang,2018-08-28T00:59:03Z,"here is the rationale of this logic: 1. once we decide to `enforceprocessing`, we will continue enforcing until we got new data enqueued and all the buffer become full, in this case we will in `normalprocessing` state. 2. but we will update the `lastenforcedprocessingtime` the last time we decide to start enforce processing. 3. we know that once we decide to enforce processing, we will always process immediately as there are indeed some data buffered already. so the logic above sets `lastenforcedprocessingtime` at the time we decide to ""turn it on"", and only ""turn it off"" during records enqueuing and all buffers contain some data. and hence we will first check `enforceprocessing`: if it is true we just continue enforce processing. lgty?",0,0.9895164370536804
213162972,5428,guozhangwang,2018-08-28T01:39:44Z,note that `putifabsent()` will return null if it does not contain the key previously. i can try to use `computeifabsent` though.,0,0.9942923784255981
213173389,5428,mjsax,2018-08-28T03:11:36Z,fair enough. thanks for pointing it out.,1,0.9806886911392212
213173805,5428,mjsax,2018-08-28T03:15:49Z,"good point. now i am wondering, if we should set `lastenforcedprocessingtime = long.max_value`, too, when we set `enforceprocessing == false` when adding records to the buffers?",1,0.7056479454040527
213174290,5428,mjsax,2018-08-28T03:19:57Z,"renaming helps -- `needscommit` implies ""there is something to commit"" while `requestcommit` implies ""user request committing"" -- it's too different things and we need to keep naming separated to avoid confusion.",0,0.977253794670105
213800151,5428,vvcephei,2018-08-29T19:09:54Z,"i see. thanks for explaining. it still seems like the `enforceprocessing` variable isn't strictly necessary, it just saves calls to `partitiongroup.allpartitionsbuffered()`, `partitiongroup.numbuffered()`, and the comparison `now - lastenforcedprocessingtime > maxtaskidlems`. these are all just cached field lookups, though, so i don't know if the performance boost is worth the algorithmic complexity. regarding `lastenforcedprocessingtime`, consider this scenario. [code block] two things to note here: 1. the expression should probably be `now - lastenforcedprocessingtime >= maxtaskidlems` (with `>=` instead of `>`), otherwise you'll wait at least one extra ms _beyond_ the purported ""max task idle time"". 2. in the scenario above, we said we want to wait *2 ms* before forcing processing, but we actually force processing *immediately*. to fix this, we should be comparing against `lastprocessingtime`, which we should set every time we process.",0,0.5651648640632629
213814276,5428,guozhangwang,2018-08-29T19:59:30Z,"good point, i will try to address this along with 's other comment:",1,0.9188375473022461
213815807,5428,vvcephei,2018-08-29T20:04:51Z,"thanks. one final thought about whether the `enforceprocessing` optimization is worth it. it might be a good idea to benchmark it without the optimization, since branch prediction *should* eliminate any overhead from the checks on rarely used branches.",1,0.9281359910964966
214207271,5428,guozhangwang,2018-08-30T23:10:55Z,"this turns out to be harder than i thought. the tricky thing is that we originally want to 1) record the sensor only for the first time when we transit to ""enforced processing"" state, and 2) start the idleness timer only for the first time when we do not have all buffered but some buffered. i tried to even implement a streamtask state just like kafkastreams and streamthread, but that turns out to not be so elegant as well. so what i ended up now is this: we will record the sensor whenever we enforce processing, either for the first time or not, and hence we will only update idlestarttime once, and reset it whenever we have all buffered. lmk wdyt.",0,0.8959576487541199
215719543,5428,mjsax,2018-09-06T17:52:03Z,not sure if i understand this. why is a commit only required if we did not restore all records that were passed in? don't we need to commit if we did a restore and updated `lastoffset` ?,0,0.9650556445121765
215734428,5428,mjsax,2018-09-06T18:38:24Z,nit: should it be `>` instead of `>=` ?,0,0.9937708973884583
215734587,5428,mjsax,2018-09-06T18:38:58Z,nit: `not_known` -> `unknown` ?,0,0.9917893409729004
215735099,5428,mjsax,2018-09-06T18:40:40Z,"nit: `fatal` is not a good name (was named like this before, no not introduced in this pr) -- this exception is not fatal but we can recover from it.",0,0.6968110799789429
215737734,5428,mjsax,2018-09-06T18:49:08Z,"why not just: `timesincelastpoll = now - lastpollms` ? if we assume that `now` never goes backwards, i don't see the need for calling `math.max`? and if we need the `math.max` guard, why do we need both? or do i miss something?",0,0.9794877171516418
215738983,5428,mjsax,2018-09-06T18:53:09Z,"should we check for `timesincelastpoll < maxpolltimems / 2`, too? according to the comment above, if we break the while-loop, we want to half `numiterations`, too. ie, instead of checking in the `while` condition, add a check here and call `break` after reducing `numiterations`?",0,0.9948134422302246
215741170,5428,mjsax,2018-09-06T18:59:52Z,"nit: `lastcommitms + committimems < now` -> `now - lastcommitms > committimems` imho, easier to read this way.",0,0.9864121675491333
215741742,5428,mjsax,2018-09-06T19:01:48Z,why another `if`? i thought this would be an `else` to the condition above?,0,0.9899186491966248
215803459,5428,mjsax,2018-09-06T23:02:09Z,sounds good to me.,1,0.8850300908088684
216033050,5428,guozhangwang,2018-09-07T17:32:21Z,there was an early comment on the test code that suggests `>=`. personally i think it does not make a big difference at all.,0,0.9768277406692505
216033754,5428,guozhangwang,2018-09-07T17:35:11Z,"again, this comes from a previous comment that it is safer to make sure `timesincelastpoll` does not go backwards, in case `now` is reduced.",0,0.9930958151817322
216037853,5428,guozhangwang,2018-09-07T17:49:27Z,good point!,1,0.9942666888237
216039375,5428,guozhangwang,2018-09-07T17:54:27Z,"`!restorerecords.isempty()` means we have non-empty records that are applied inside `statemgr.updatestandbystates` call, note it does not remove records that are applied after the call.",0,0.993782103061676
216067026,5428,vvcephei,2018-09-07T19:38:19Z,"i am to blame for this suggestion. i agree it doesn't make a big difference. the reasoning was that if it's the ""maximum idle time"", then you shouldn't idle longer than it, otherwise, it's not really a maximum.",-1,0.9577346444129944
216141583,5428,mjsax,2018-09-08T21:50:01Z,"i agree that it does not matter too much :) (that why it's a nit) however, i think that the maximum is inclusive, and only if we exceed it, we should force processing. from my understanding, ""maximum idle time"" is actually a lower bound (-> don't force processing until this time passed) because we cannot guarantee anyway to not exceed this threshold. i see your point why the name might be counter intuitive (even if i think the name is correct). if you interpret the name strictly, we would be allowed (or actually we would be required) to force processing before the time passed. this interpretation would make the parameter useless (ie, user tells us to idle max 5 minutes and we obey by forcing processing after 1 minute). to me, the right interpretation is, ""wait until this time passed and force processing asap if the time is exceeded"". chaning the name to `min.idle.time.ms` would be more precise, but i think it would be more confusing to users.",1,0.9892523884773254
216141611,5428,mjsax,2018-09-08T21:51:27Z,how could this happen? seems to be impossible to me.,-1,0.7801938056945801
216141645,5428,mjsax,2018-09-08T21:53:28Z,ack. i confused it with `remainingrecords`. all good :),1,0.9896748661994934
216399814,5428,guozhangwang,2018-09-10T17:05:51Z,"quoting your comment: [code block] the above change is for addressing this comment. again i'd admit it is not ideal to rely on the side effect of `computelatency()` to advance `now` but at the same time i want to avoid calling system time necessarily. if you feel strong about it, i can just go ahead and explicitly advance `now`, does it sound better to you?",0,0.8882571458816528
216400887,5428,guozhangwang,2018-09-10T17:09:01Z,"okay guys, i'm going to make a final call here to end the discussion: i'm staying with `max.idle..` since i feel it is easier to understand for users, and be aware that this is not strictly respected in practice unless it is set to `0`. also i'm staying with `>=` since again, it is easier to understand though not strictly sound mathematically.",0,0.7657633423805237
216403879,5428,mjsax,2018-09-10T17:17:35Z,:) fair enough.,0,0.4960038661956787
216404303,5428,mjsax,2018-09-10T17:18:48Z,i see. i did not make the connection to the other discussion. i think we can leave as-is.,0,0.946560263633728
216520595,5428,guozhangwang,2018-09-11T01:14:46Z,"to make it clear, i 1) renamed the function, and 2) explicitly called it outside the `sensor.record` call.",0,0.993561863899231
216550162,5428,mjsax,2018-09-11T05:37:09Z,"should we compute this, before we call `taskmanager.updatenewandrestoringtasks()` ? also, do we need to update `now` after `updatenewandrestoringtasks()` to compute `processlatency` correctly, below?",0,0.9952516555786133
216551625,5428,mjsax,2018-09-11T05:48:59Z,nit `stays at 2` seems to be correct -- it's `equalto(2)` below.,0,0.985824704170227
216829644,5428,guozhangwang,2018-09-11T21:30:35Z,ack.,0,0.5038502812385559
216853354,5428,guozhangwang,2018-09-11T23:15:27Z,ack,0,0.8596508502960205
108246948,2743,hachikuji,2017-03-27T18:38:12Z,sorry for the drive-by comment. maybe this could be `partitionleaderepoch` so there's no potential confusion with the producer epoch?,-1,0.9849114418029785
108319243,2743,junrao,2017-03-28T01:50:05Z,"to follow the existing convention, partition_id and error_id should be partition and error_code?",0,0.9952704310417175
108319252,2743,junrao,2017-03-28T01:50:11Z,epochs => leader epochs ?,0,0.991483747959137
108319291,2743,junrao,2017-03-28T01:50:33Z,"to follow the convention in other requests like fetchrequest, perhaps we can store map , where int is for leaderepoch?",0,0.9949336647987366
108319308,2743,junrao,2017-03-28T01:50:44Z,could we consolidate the log here and in line 173 into a single one? perhaps it's also useful to log the leo at this point.,0,0.9928102493286133
108319315,2743,junrao,2017-03-28T01:50:50Z,"it seems that during log recovery, we should recover the leader epoch cache as well?",0,0.9946796298027039
108319326,2743,junrao,2017-03-28T01:50:55Z,entry => batch,0,0.9873535633087158
108319349,2743,junrao,2017-03-28T01:51:11Z,"map { case (tp, state) => ...} ?",0,0.9896803498268127
108319571,2743,junrao,2017-03-28T01:53:41Z,"currently, in abstractfetcherthread, we try not to hold the partitionmaplock while making an rpc call. otherwise, if an rpc call takes long for some reason, the becomingleader/follower call will be delayed while waiting for the partitionmaplock. perhaps, we can structure the code like the following. [code block] in processleaderepochrequest(), we can do sth similar to processfetchrequest: send the leaderepochrequest w/o holding partitionmaplock; then hold onto partitionmaplock and do log truncation.",0,0.9916885495185852
108319584,2743,junrao,2017-03-28T01:53:48Z,merge 218-220 into the state line in 217?,0,0.9941546320915222
108319612,2743,junrao,2017-03-28T01:54:02Z,"the reason for calling partitionmapcond.signalall() is to wake up the abstractreplicathread. if the method is only called within abstractreplicathread, we know the thread is awake when making the call. so, there is no need to call signalall().",0,0.9928717017173767
108319622,2743,junrao,2017-03-28T01:54:09Z,handlehandleoffsetforleaderepochrequest => handleoffsetforleaderepochrequest,0,0.9923079013824463
108319626,2743,junrao,2017-03-28T01:54:15Z,it seems that offsetsforleaderepoch.getresponsefor() should be a method in replicamanager?,0,0.9950075149536133
108319633,2743,junrao,2017-03-28T01:54:19Z,missing license header,0,0.9875472784042358
108319657,2743,junrao,2017-03-28T01:54:30Z,"we probably only want to resort to hw if the error is noleaderepoch. otherwise, we should probably just backoff a bit and then retry.",0,0.9775830507278442
108319674,2743,junrao,2017-03-28T01:54:40Z,"if epochoffset.endoffset() is unsupported_epoch_offset, which can happen during the transition phase, we should fall back to hw?",0,0.9918274879455566
108319712,2743,junrao,2017-03-28T01:55:10Z,"if epochoffset.endoffset() >= replica.logendoffset.messageoffset, perhaps we could avoid log truncation.",0,0.9909229874610901
108319722,2743,junrao,2017-03-28T01:55:17Z,perhaps we should change the file name to offsetcheckpointfile?,0,0.9944494962692261
108319742,2743,junrao,2017-03-28T01:55:31Z,"if epoch is < latestepoch(), it might be useful to log a warning. we probably also want to assert that offset is > the offset of the last epoch.",0,0.9916073083877563
108319753,2743,junrao,2017-03-28T01:55:36Z,is epochs.last() of o(1) cost? it will be called on every request.,0,0.9926419854164124
108319812,2743,junrao,2017-03-28T01:56:21Z,"we want to be a bit careful here, especially during the transition phase when some existing messages may not have a leader epoch. so, if requestedepoch is < the first epoch in epochs, we probably want to return unsupported_epoch_offset so that the follower can fall back to hw.",0,0.9869377613067627
108319839,2743,junrao,2017-03-28T01:56:39Z,"do we need retainmatchingoffset? it seems that in both log.truncateto() and log.truncatefullyandstartat(), we want the offset to be inclusive, i.e., an epoch with offset will be removed.",0,0.9945417046546936
108319862,2743,junrao,2017-03-28T01:56:53Z,"could we log the topic/partition too? also, does this need to be info? seems more like debug level. ditto below in clearoldest().",0,0.9911414384841919
108319865,2743,junrao,2017-03-28T01:56:55Z,is the comment accurate?,0,0.9855098724365234
108319919,2743,junrao,2017-03-28T01:57:20Z,not sure if we need retainmatchingoffset here either. it seems the caller always wants this to be inclusive.,0,0.9670323133468628
108379720,2743,benstopford,2017-03-28T09:52:12Z,"yes, i'm using a listbuffer: [a link]",0,0.9810848236083984
108408756,2743,benstopford,2017-03-28T12:41:13Z,have changed to: `offset >= the offset of the last epoch.` as epoch can increment on the leader when the offset does not change.,0,0.9946759939193726
108652909,2743,benstopford,2017-03-29T11:31:33Z,"i've pulled the logic up into abstractfetcherthread. what i've done is somewhat similar to your snippet, but it includes a lock around the truncation step. [code block]",0,0.9860925078392029
109215784,2743,junrao,2017-03-31T17:54:40Z,"it seems that $leaderepoch is the same as ${partitionstateinfo.leaderepoch}? perhaps we can change the logging to ""$topicpartition starts leader epoch $leaderepoch from offset ${getreplica().get.logendoffset.messageoffset}""?",0,0.9951871633529663
109216215,2743,junrao,2017-03-31T17:56:39Z,"given the logging in partition.makeleader(), it seems that we don't need the logging here.",0,0.9898688793182373
109217691,2743,junrao,2017-03-31T18:03:39Z,indentation,0,0.822169840335846
109219494,2743,junrao,2017-03-31T18:12:35Z,"this needs to be logged before line 80? otherwise, the new epoch is already the last epoch.",0,0.9907389879226685
109225083,2743,junrao,2017-03-31T18:38:38Z,"we only want to return the offset for the epoch if the replica is still the leader. we probably want to call replicamanager.getleaderreplicaiflocal(), catch exceptions like not_leader_for_partition and unknowntopicorpartitionexception and convert it to an error code like what's in replicamanager.readfromlocallog().",0,0.9923673272132874
109225474,2743,junrao,2017-03-31T18:40:24Z,"hmm, if requestedepoch == undefined_epoch, it seems that we should return undefined_epoch_offset so that the follower can fall back to hw.",0,0.9845218062400818
109225572,2743,junrao,2017-03-31T18:40:50Z,inaccurate comment.,-1,0.8521203994750977
109225580,2743,junrao,2017-03-31T18:40:52Z,inaccurate comment.,-1,0.8521203994750977
109226958,2743,junrao,2017-03-31T18:48:03Z,it seems that we should call leaderepochcache.clear() in this case since all data is gone.,0,0.9946598410606384
109227964,2743,junrao,2017-03-31T18:53:24Z,"in this case, we are removing all data starting at startoffset. so, we want to call leaderepochcache.clearlatest instead. even if there is no log recovery, it will be useful to make sure that leaderepochcache is consistent with what's in the log. so, instead of doing it here, we could just call leaderepochcache.clearlatest(nextoffset) immediately after loadsegments().",0,0.9936467409133911
109229094,2743,junrao,2017-03-31T18:59:10Z,"legacy messages will have epoch < 0 and we don't want to flood the logging. so, we can probably only log a warning if epoch is >= 0?",0,0.9754637479782104
109230643,2743,junrao,2017-03-31T19:07:19Z,"not sure if it matters, but we probably want to define leaderepochcache before loadsegments() is called since log recovery needs access to leaderepochcache.",0,0.9873867630958557
109231519,2743,junrao,2017-03-31T19:12:46Z,"i think this also needs to be called during log recovery in logsegment.recover(). also, during this process, it's possible for an older epoch to be assigned again. to avoid the unnecessary logging in maybewarn, on way is for the caller can only call assign() from latestoffset().",0,0.989124059677124
109256482,2743,junrao,2017-03-31T21:47:17Z,the comment seems inaccurate. deletesegment only clearoldest.,-1,0.6062366366386414
109256659,2743,junrao,2017-03-31T21:48:39Z,could we add epochcache to the comment above?,0,0.9945875406265259
109256943,2743,junrao,2017-03-31T21:50:55Z,clearearliest to match clearlatest?,0,0.9908623695373535
109261174,2743,junrao,2017-03-31T22:26:58Z,no need for this logging?,0,0.963982880115509
109261760,2743,junrao,2017-03-31T22:33:01Z,indentation,0,0.822169840335846
109262199,2743,junrao,2017-03-31T22:37:36Z,allpartitions no longer used.,0,0.977255642414093
109263288,2743,junrao,2017-03-31T22:48:18Z,this can be private.,0,0.9784858226776123
109264654,2743,junrao,2017-03-31T23:02:45Z,consumerid not used.,0,0.9785858392715454
109265484,2743,junrao,2017-03-31T23:12:15Z,"we should probably add a new tag kafka_0_11_0_iv2 which corresponds to the introduction of leaderepoch request, and use it here.",0,0.9935000538825989
109265507,2743,junrao,2017-03-31T23:12:29Z,"""fetch from the leader"" can be a bit confusing. ""issue leaderepochrequest to the leader""?",0,0.630723237991333
109265520,2743,junrao,2017-03-31T23:12:34Z,remove ?,0,0.9887279272079468
109268030,2743,junrao,2017-03-31T23:45:31Z,perhaps we can also change the line 945 from if(targetoffset > logendoffset) { to if(targetoffset >= logendoffset) {,0,0.9901747703552246
109269015,2743,junrao,2017-03-31T23:58:16Z,this is the case the leader returned an offset >= leo. it would be useful to log the topic/partition as well.,0,0.9913942217826843
109269023,2743,junrao,2017-03-31T23:58:20Z,it would be useful to log the topic as well.,0,0.9894633293151855
109269093,2743,junrao,2017-03-31T23:59:19Z,could we add override?,0,0.9913414120674133
109269313,2743,junrao,2017-04-01T00:02:35Z,this can be private.,0,0.9784858226776123
109269322,2743,junrao,2017-04-01T00:02:44Z,this can be private.,0,0.9784858226776123
109269876,2743,junrao,2017-04-01T00:11:25Z,it doesn't seem this method and the trait are used.,0,0.9798702001571655
109311609,2743,junrao,2017-04-02T15:27:22Z,"could we remove todo? if we just want to test corrupted messages, there is no need to set includepartitioninitialisation to true.",0,0.9924818873405457
109312409,2743,junrao,2017-04-02T15:58:38Z,this is because we bounce the leader epoch when the controller changes the isr too so that the latest isr can be updated in the broker's cache.,0,0.9924310445785522
109312786,2743,junrao,2017-04-02T16:17:18Z,"hmm, there is a subtle question here, which is should the new epoch be added to epoch cache when the leader epoch advances or when there is actually a message added in the new epoch. the latter means that epoch will be more consistent after log recovery and be more consistent between the leader and the follower. so, perhaps it's better to do the latter. then the flow will be (1) we remember the latest epoch in partition.leaderepoch when receiving leaderandisrrequests, but not updating the leader epoch cache yet; (2) we pass partition.leaderepoch to log.append() and only update the leader epoch cache when there is a new message produced. this will also make the test a bit easier to understand since the epoch will always be consistent btw the leader and the follower.",0,0.9654486775398254
109313719,2743,junrao,2017-04-02T16:54:09Z,this can be done using testutils.waituntiltrue(() ?,0,0.9909740090370178
109313817,2743,junrao,2017-04-02T16:58:00Z,"since we have a large linger and batch size in the producer, does it matter whether we send those 100 messages in batches? it seems that all of them will be in the same batch after the flush() call.",0,0.991823136806488
109314127,2743,junrao,2017-04-02T17:10:49Z,unused method.,0,0.9563766121864319
109314585,2743,junrao,2017-04-02T17:31:46Z,put two statements in different lines and remove ;,0,0.9805133938789368
109314603,2743,junrao,2017-04-02T17:32:27Z,remove ;,0,0.9667384624481201
109314622,2743,junrao,2017-04-02T17:33:15Z,remove ; in the above 2 statements. ditto in a few other places.,0,0.9874166250228882
109315673,2743,junrao,2017-04-02T18:11:09Z,"deletecorrespondingleaderepochs should only be set to true when we are deleting a prefix of the log segments. the only caller for that is def deletesegments(deletable: iterable[logsegment]). also, segment.nextoffset() needs scanning the log and can be a bit expensive. so, perhaps, we can call leaderepochcache.clearoldest() in deletesegments(deletable: iterable[logsegment]) with the recomputed logstartoffset, which is much cheaper.",0,0.9933788776397705
109316101,2743,benstopford,2017-04-02T18:27:47Z,"this was a pretty big change, but the final one of your first round of comments. committed now.",0,0.9201529026031494
109316191,2743,junrao,2017-04-02T18:32:06Z,"the error message seem inaccurate. here, we are just verifying the log for broker 0, not for broker 1.",0,0.5051024556159973
109316509,2743,junrao,2017-04-02T18:47:39Z,do we need testsender or could we just reuse replicafetcherblockingsend?,0,0.9940642714500427
109320017,2743,junrao,2017-04-02T21:05:12Z,"when clearearliest() is called, it means that the first offset of the log starts at offset. so we want to (1) preserve an entry whose startoffset == offset; (2) if the last entry whose startoffset is < offset and the next entry's offset is > offset or is not present, we want to preserve that last entry and just set its startoffset to offset. we want to change the comment accordingly.",0,0.9928886294364929
109320018,2743,junrao,2017-04-02T21:05:14Z,oldest => earliest?,0,0.9804608225822449
109320084,2743,junrao,2017-04-02T21:07:48Z,is this needed?,0,0.9838624596595764
109320101,2743,junrao,2017-04-02T21:08:16Z,should we use just use createproducer()?,0,0.9932244420051575
109320117,2743,junrao,2017-04-02T21:08:55Z,a few methods like that can be made private.,0,0.9901898503303528
109320127,2743,junrao,2017-04-02T21:09:21Z,"hmm, why do we need to create a new producer here? if so, should we close the old one first?",0,0.9826295375823975
109320169,2743,junrao,2017-04-02T21:11:39Z,this is because we have to first change leader to -1 and then change it again to the live replica.,0,0.9898353219032288
109320452,2743,junrao,2017-04-02T21:24:48Z,a few methods like that in this file can be private.,0,0.9903974533081055
109320567,2743,junrao,2017-04-02T21:29:44Z,is this needed? it seems that we create the dir when initializing log in loadsegments().,0,0.994375467300415
109320709,2743,junrao,2017-04-02T21:34:25Z,the second param should be offset + 3 too?,0,0.9939184188842773
109321139,2743,junrao,2017-04-02T21:50:17Z,this can be private.,0,0.9784858226776123
109321508,2743,junrao,2017-04-02T22:04:12Z,"hmm, if we are only deleting one segment, shouldn't the first offset be 5 and we should preserve epochentry(1,5)?",0,0.9825097322463989
109321591,2743,junrao,2017-04-02T22:06:53Z,this is actually not truncating the first segment. ditto in line 1478.,0,0.9653657078742981
109321653,2743,junrao,2017-04-02T22:09:46Z,"hmm, we are already testing multiple lines in the previous test. is this testing multiple partitions in the same topic?",0,0.9739037752151489
109321773,2743,junrao,2017-04-02T22:14:26Z,should this be removed now that leader epoch is at the set level?,0,0.9950473308563232
109321789,2743,junrao,2017-04-02T22:15:07Z,unused import,0,0.9524969458580017
109321997,2743,junrao,2017-04-02T22:24:47Z,the code is for 3 times.,0,0.9848740100860596
109322753,2743,junrao,2017-04-02T22:54:58Z,the part of calling assign() during log recovery still needs to be addressed.,0,0.9881468415260315
109322961,2743,junrao,2017-04-02T23:02:18Z,"this probably can be done in a followup patch. if there is an error, we probably want to add a bit of delay to the partition before retrying the offsetsforleaderepoch request (like what we do when the fetch request has an error).",0,0.9920437932014465
109333196,2743,junrao,2017-04-03T02:45:44Z,should we uncomment this?,0,0.9909861087799072
109447563,2743,benstopford,2017-04-03T15:29:09Z,"(2) is a good point. thank you. have altered and added appropriate tests. in a bit of a rush, coding this in the airplane lounge.",1,0.9942697286605835
109447763,2743,benstopford,2017-04-03T15:29:50Z,i need this to get tests to pass locally. feel free to remove as i have a pr to change these running separately.,0,0.9566482305526733
109448157,2743,benstopford,2017-04-03T15:31:17Z,hmm. this is covering a chicken/egg situation around the initialisation of log (i.e. where we initialise leaderepochcache). needs changing.,-1,0.7295509576797485
109547558,2743,junrao,2017-04-03T23:24:20Z,epochsbytopic => epochsbytopicpartition?,0,0.99244624376297
109547577,2743,junrao,2017-04-03T23:24:27Z,this doesn't seem to be used.,0,0.9257559776306152
109547593,2743,junrao,2017-04-03T23:24:34Z,this doesn't seem to be used.,0,0.9257559776306152
109547736,2743,junrao,2017-04-03T23:25:33Z,-1l = > epochendoffset.undefined_offset ?,0,0.9919974207878113
109547743,2743,junrao,2017-04-03T23:25:39Z,the method is not used.,0,0.9555602073669434
109547807,2743,junrao,2017-04-03T23:26:02Z,"at this point, the log dir may not have been created. so, we probably need to make sure the log dir exists first.",0,0.9882310032844543
109547834,2743,junrao,2017-04-03T23:26:16Z,we can set the deleteepoch flag to false here since we call clearlatest() after loading the log.,0,0.9947314262390137
109547857,2743,junrao,2017-04-03T23:26:26Z,could we move line 943 to after line 949?,0,0.9940776824951172
109547889,2743,junrao,2017-04-03T23:26:37Z,"could we remove the todo? also, could we move this line to before line 960?",0,0.9941575527191162
109548130,2743,junrao,2017-04-03T23:28:14Z,"hmm, if the broker is on a version before kafka_0_11_0_iv2 and we don't let the partition go through the initialization phase, then the followers won't be doing any truncation based on hw. we can probably always set the partition to need initialization. if the broker is on a version before kafka_0_11_0_iv2, in fetchepochsfromleader(), we don't do the actual leader epoch request, but simply set the response to unknown_offset. then the maybetruncate() logic will just fall back to hw.",0,0.9904450178146362
109548156,2743,junrao,2017-04-03T23:28:20Z,it would be useful to log the topic/partition as well.,0,0.9904137253761292
109548176,2743,junrao,2017-04-03T23:28:27Z,do maybewarn() in else?,0,0.9863247275352478
109548190,2743,junrao,2017-04-03T23:28:33Z,"it will be useful to log the topic/partition as well. also, could this just be debug level logging?",0,0.9901909828186035
109548206,2743,junrao,2017-04-03T23:28:42Z,"if earliestoffset() == offset, it seems that we don't need to do anything.",0,0.9861602187156677
109548223,2743,junrao,2017-04-03T23:28:49Z,"similar here, we want to find entries with entry.startoffset < offset.",0,0.9922045469284058
109548234,2743,junrao,2017-04-03T23:28:54Z,not sure if we need the if test here.,0,0.95717453956604
109548266,2743,junrao,2017-04-03T23:29:09Z,"this should say ""epoch < latestepoch"". an partitionleaderepoch => a partitionleaderepoch",0,0.9923491477966309
109548287,2743,junrao,2017-04-03T23:29:19Z,it seems that we only append messages of format v2 and newer. so epoch is never expected to be <0 ?,0,0.9762409329414368
109548308,2743,junrao,2017-04-03T23:29:29Z,"hmm, it seems that only the first segment will be removed according to the retention policy?",0,0.9852967858314514
109548322,2743,junrao,2017-04-03T23:29:35Z,it's no longer doing this in batches.,0,0.977616012096405
109548330,2743,junrao,2017-04-03T23:29:39Z,this can be private.,0,0.9784858226776123
109548343,2743,junrao,2017-04-03T23:29:47Z,put two statements in different lines and remove ; there are quite a few other places using ;.,0,0.98055499792099
109651046,2743,benstopford,2017-04-04T12:42:53Z,"oh, it's used by one of the tests. authorizerintegrationtest. all the request/response classes have it.",0,0.991057276725769
109651092,2743,benstopford,2017-04-04T12:43:09Z,as above,0,0.9391705989837646
109651463,2743,benstopford,2017-04-04T12:45:10Z,see authorizerintegrationtest,0,0.9921969175338745
109781747,2743,benstopford,2017-04-04T21:26:54Z,"i think this is ok, but can remove if you feel strongly.",0,0.882408618927002
109795882,2743,benstopford,2017-04-04T22:43:51Z,hmm. i think this actually correct. i would like a better way to express it but i can't see one. i'd encourage you to look at the tests in leaderepochfilecachetest to see if you disagree with any of them.,0,0.8306958675384521
109967050,2743,junrao,2017-04-05T16:41:06Z,"yes, i agree that it's needed.",0,0.9790717959403992
124910746,2743,lindong28,2017-06-29T20:55:49Z,it seems that the method's java doc is inconsistent with its behavior if requestedepoch is < the first epoch in epochs. i am wondering if we should update the java doc or comment in this code to explain this. i only realized it is intentional after reading this 's comment in this pull request.,0,0.887382447719574
124923278,2743,junrao,2017-06-29T22:01:02Z,: we can clarify that in the comment. could you file a jira?,0,0.9915663599967957
124927503,2743,lindong28,2017-06-29T22:27:39Z,sure. i filed [a link] and assigned it to .,0,0.9902550578117371
1890534015,18240,jsancio,2024-12-18T16:37:36Z,can we try moving this to the internal module? anything public in this package can be used outside the `raft` module.,0,0.9951350092887878
1890534655,18240,jsancio,2024-12-18T16:38:08Z,can we explicitly mark private any method that is not used outside of this class?,0,0.9935945868492126
1890535623,18240,jsancio,2024-12-18T16:38:49Z,please write java doc for all public methods.,0,0.9828678369522095
1890542820,18240,jsancio,2024-12-18T16:43:51Z,`illegalargumentexception` seems like a better exception type.,0,0.9855232238769531
1890544866,18240,jsancio,2024-12-18T16:45:11Z,let's write java doc for all public methods.,0,0.983491837978363
1890552560,18240,jsancio,2024-12-18T16:50:45Z,"this is not a warning. this is a valid state or condition. we should be able to log this message at info level. it should be rare because there are backoff/timeout logic in candidate, follower and unattached which limit how quickly a replica transitions to prospective. what do you think?",0,0.9810628294944763
1890554341,18240,jsancio,2024-12-18T16:52:04Z,let's use the same word you used in the `nomineestate`: `isnomineestate()` and `nomineestateorthrow()`.,0,0.993933379650116
1890660800,18240,ahuang98,2024-12-18T18:22:03Z,"|i see your point here, there's nothing 'incorrect' about this happening. but i'm wondering about the case where a controller quorum is left partially upgraded on accident. would having a warning log make this situation more discoverable?",0,0.6897282600402832
1890678659,18240,jsancio,2024-12-18T18:37:30Z,"yeah. this would be interesting to monitor but cluster are not really monitored by looking at the log. clusters are monitored by collecting and comparing metrics. this is an issue beyond kraft and should be solved holistically. kafka could have a metrics that fires if the api versions and supported features don't match across all of the replicas. this metric would require a kip to implement. having said that, we should keep this message but it should not be logged at warn. it should be logged at info.",0,0.9530590772628784
1894260795,18240,ahuang98,2024-12-20T18:28:20Z,"it might not be expected that a state has both leader and voted key state, but i think it's better not to lose the state if it does happen to exist. not an issue for backwards compatibility, older version would lose votedkey state but would have leader state and will reject standard votes correctly because of that.",0,0.971764326095581
1895898210,18240,ahuang98,2024-12-23T15:52:47Z,"open to what you think, this definitely isn't necessary but i thought this could help reduce the complexity of handlevoteresponse (this is called in a 3rd level of conditional statements)",0,0.972131609916687
1895926505,18240,ahuang98,2024-12-23T16:24:52Z,"found existing test which checks that observers with ids can vote - [a link] which was added in kafka-16526, so i've removed `voted` for now (vs translating to `unattachedvoted`)",0,0.9948128461837769
1896920647,18240,jsancio,2024-12-24T18:52:19Z,the type should be `candidatestate`. let's add the field `retries` back to the message. how about replacing `voterstates` with `epochstate` and implementing a `tostring` method for `epochstate`?,0,0.9940703511238098
1896921039,18240,jsancio,2024-12-24T18:53:27Z,let's move this method so that it doesn't show in the diff.,0,0.9880245327949524
1896921206,18240,jsancio,2024-12-24T18:53:57Z,let's move this method so that it doesn't show in the diff.,0,0.9880245327949524
1896921449,18240,jsancio,2024-12-24T18:54:31Z,let's move this method so that it doesn't show in the diff.,0,0.9880245327949524
1896921655,18240,jsancio,2024-12-24T18:54:53Z,let's move this method so that it doesn't show in the diff.,0,0.9880245327949524
1896923862,18240,jsancio,2024-12-24T19:01:12Z,let's revert this change. we should make it clear that this pr is not changing the persisted `quorum-state`.,0,0.9936745166778564
1896926243,18240,jsancio,2024-12-24T19:07:42Z,nice code removal! thanks.,1,0.9961022138595581
1896926826,18240,jsancio,2024-12-24T19:09:03Z,"i got the impression that you don't use this in `src/main`. if so, let's remove it.",0,0.9717375636100769
1896930978,18240,jsancio,2024-12-24T19:21:53Z,"let's just remove this method and have the tests use `transitiontounattached(int, optionalint)`. also update the java doc to match the new signature and parameters.",0,0.9937698245048523
1896932468,18240,jsancio,2024-12-24T19:26:02Z,"let's remove this and update the callers to use `transtitiontounattached(int, optionalint)`.",0,0.9950622916221619
1896934629,18240,jsancio,2024-12-24T19:32:12Z,how about: [code block],0,0.9921973347663879
1896935574,18240,jsancio,2024-12-24T19:35:15Z,let's fix the indentation. in the raft module we using this formatting style: [code block],0,0.9933130145072937
1896936282,18240,jsancio,2024-12-24T19:37:26Z,let's fix this formatting. see my under examples on how we try to format code in the raft module.,0,0.9796764850616455
1896936776,18240,jsancio,2024-12-24T19:39:06Z,this code only have one caller. how about just manually inline it at the call site.,0,0.9502047300338745
1896939688,18240,jsancio,2024-12-24T19:47:01Z,same here. let's fix the indentation since you are already changing this part of the code.,0,0.9805128574371338
1896941400,18240,jsancio,2024-12-24T19:52:07Z,i think this is too relax. the previous code assumed that if `leaderid.ispresent()` then `!leaderendpoints.isempty()`. that should not change in this pr.,0,0.9593770503997803
1896944012,18240,jsancio,2024-12-24T20:00:05Z,when would raft hit this case?,0,0.9813936948776245
1896944517,18240,jsancio,2024-12-24T20:01:45Z,"minor but you can just inline the expression: `quorum.isprospective()`. also, the call site that calls this knows the `nomineestate` so it can use that information to determine if the request is a prevote request. no need to query `quorumstate` for this information. for example, you can add `isprevote` to the `nomineestate` interface and update the signature of this method to `buildvoterequest(replicakey, boolean)`.",0,0.9935651421546936
1896952514,18240,jsancio,2024-12-24T20:29:38Z,this handle when the majority of the voters rejected the candidate. this needs to also handle when the majority of the voters reject the prospective candidate.,0,0.9866857528686523
1896953461,18240,jsancio,2024-12-24T20:33:17Z,this code shouldn't check `isvoterejected` if it is handled in `handlevoterespose`. i left a comment about this in that method. this is an event driven programming model. the event that cause the majority of the voters to reject the prospective state is received in the vote response. and not when polling the prospective state.,0,0.9919004440307617
1896955782,18240,jsancio,2024-12-24T20:40:24Z,i see. retries is only preserved when the prospective transition from prospective to candidate. the retries are lost if it transitions to unattached. i think we should file a jira to remove this exponential backoff. i am convinced that it is starting to lose its value with this implementation and if we make the election timeout improvements you highlight in the kip,0,0.9507899880409241
1896957160,18240,jsancio,2024-12-24T20:44:47Z,let's also include the epoch election and add a `tostring` method to the `epochelection` type.,0,0.993780791759491
1896957660,18240,jsancio,2024-12-24T20:46:39Z,let's write a comment explaining why this expression is needed.,0,0.9855835437774658
1896958513,18240,jsancio,2024-12-24T20:49:40Z,should this check that the epoch is not decreasing?,0,0.9832406640052795
1896958745,18240,jsancio,2024-12-24T20:50:28Z,let's fix this formatting. [code block],0,0.9875883460044861
1896958960,18240,jsancio,2024-12-24T20:51:19Z,this should check that the epoch is not decreasing.,0,0.9774486422538757
1896959037,18240,jsancio,2024-12-24T20:51:36Z,fix formatting.,0,0.9685641527175903
1896960167,18240,jsancio,2024-12-24T20:55:06Z,how about this formatting: [code block],0,0.9908894896507263
1896961481,18240,jsancio,2024-12-24T21:00:19Z,let's add a java doc comment to this method.,0,0.9831792116165161
1896962158,18240,jsancio,2024-12-24T21:02:46Z,let's undo this change. it is good to keep the existing invariant to avoid persisting both `leaderid` and `votedkey`.,0,0.9584119319915771
1896962727,18240,jsancio,2024-12-24T21:04:56Z,let's add a `tostring` method to this type so that its value is included in log messages.,0,0.9904243350028992
1896962935,18240,jsancio,2024-12-24T21:05:52Z,this is a publicly visible change. let's update the kip if it doesn't include this change.,0,0.9908968806266785
1897006321,18240,ahuang98,2024-12-25T00:07:15Z,"this method is solely for the case of adding voted state to unattached in the same epoch (if higher epoch, we take the path of transitiontounattached) the transitiontounattached method has the following comment, i will duplicate it for this method too [code block]",0,0.9937792420387268
1897013977,18240,ahuang98,2024-12-25T00:36:05Z,"i think i had convinced myself this was arguably not an invariant since it is not enforced (and perhaps just an unintentional quality of kraft today). i know we chatted earlier about how kraftversion=2 should enforce that both votedkey and leaderid are persisted if they exist, which i agree with. i guess what we're not on the same page about is if we can start to persist all the information we have, now. i would argue it is fine to do now because it is backwards compatible, the additional info isn't necessary for correctness, and losing that additional information also doesn't affect correctness (e.g. currently, if unattached with leaderid grants a standard vote, it transition to unattachedvoted w/o leaderid. unattachedvoted w/o leaderid and unattachedvoted w/ leaderid behave the same way in rejecting votes. if unattached has both leaderid and votedkey in electionstate and then downgrades, it would only retain the votedkey and transition to unattachedvoted w/o leader, which is the same transition that would have been taken in the past for an unattached w/ leaderid that grants a vote)",0,0.9211896657943726
1897014715,18240,ahuang98,2024-12-25T00:39:01Z,"retaining both leaderid and votedkey also can help other replicas find the leader faster (though not needed for correctness) - unattachedvoted w/ leader will reject vote requests w/ a leaderid unattachedvoted w/o leader will reject vote request w/o a leaderid if we only persist one, then on startup a replica just doesn't have all the information it _could_ have",0,0.9847446084022522
1899044657,18240,ahuang98,2024-12-29T01:12:26Z,fixed. i added this because i thought it was an oversight not to check for empty endpoints given that we can initialize in unattachedstate when the leaderendpoints are not known. but i see now that `maybetransition` is only called in places where the leaderendpoints are expected to be populated,0,0.9897262454032898
1899071006,18240,ahuang98,2024-12-29T06:28:07Z,fixed,0,0.9281549453735352
1899072269,18240,ahuang98,2024-12-29T06:41:32Z,we can use this jira to track - [a link],0,0.9820132851600647
1899074255,18240,ahuang98,2024-12-29T06:59:55Z,i could also remove `epoch` as one of the params (method can use state.currentepoch instead of parameter value). but i would prefer to keep `epoch` as a param so we can validate the method is being used correctly (without any unintentional epoch change).,0,0.9941337704658508
1899074463,18240,ahuang98,2024-12-29T07:01:25Z,"same as above, this is meant to be called only to transition from prospectivenotvoted in epoch x to prospectivevoted in epoch x",0,0.9933326840400696
1899076157,18240,ahuang98,2024-12-29T07:16:33Z,"this is called within the third level of a conditional statement, adding this back violates checkstyle's cyclomatic complexity check",0,0.9883711934089661
1899077542,18240,ahuang98,2024-12-29T07:27:49Z,"for now, i've kept the helper but increased its scope to handle the case when prospective loses the election. i've renamed it as `maybehandleelectionloss`",0,0.9909167885780334
1899341945,18240,ahuang98,2024-12-30T07:39:52Z,"the existing raft event simulation tests picked up on a new bug in pollresigned - if we simply replace the transitiontocandidate(currenttimems) with transitiontoprospective(currenttimems), a cordoned leader in epoch 5 could resign in epoch 5, transition to prospective in epoch 5 (with leaderid=localid), fail election and then attempt to become follower of itself in epoch 5. so far, these are the alternatives which seem reasonable to me: - resigned voter in epoch x should transition to prospective in epoch x+1 - cons: need to create a special code path just for this case to allow becoming prospective in epoch+1 (would also add trivial complexity for determining if votedkey or leaderid should be kept from prior transition). transitioning to prospective in epoch + 1 is almost as disruptive as transitioning directly to candidate since it involves an epoch bump - pro: probably the option which follows intentions of past logic most closely - resigned voter in epoch x should simply transition to unattached in epoch x+1 (current version) - con: resigned replica has to wait two election timeouts after resignation to become prospective - pro: simplified logic. unless this is the only replica eligible for leadership in the quorum (e.g. due to network partitioning), the impact of waiting two election timeouts after resignation is small - all other replicas should be starting their own elections within a single fetch timeout/election timeout - resigned voter in epoch x instead waits a smaller backofftimems before transitioning to unattached in epoch x+1 - con: scope creep - what should this backoff be? additional changes to resignedstate - pro: resigned voter waits less time before becoming eligible to start a new election.",0,0.9924777150154114
1899579689,18240,jsancio,2024-12-30T14:26:34Z,yes. this is correct. observers can vote for candidate (kip-853) and prospective (kip-996). this was changed as part of kip-853 as documented [a link].,0,0.9839497804641724
1899610803,18240,jsancio,2024-12-30T15:11:33Z,"got it. thanks. i see now that kraft doesn't check if both the leader and voted field are set during iniialization. during initialization, it does check the voted field first before checking the leader field. i think we should switch that order. if the leader and the leader endpoints are known, the replica should transition to follower immediately instead of needing to rediscover the leader. let's change this comment too as it is slightly inaccurate. there are many reason why the replica may not send the leader endpoints. using an old version for the rpc is not the only reason why the replica may send the leader id but not the leader endpoint: [code block]",1,0.9311564564704895
1899633981,18240,jsancio,2024-12-30T15:47:39Z,what is the exact error? let's add an unittest to one of the `kafkaraftclient*test` suite that shows the bug. let's add a check to `transtitiontofollower` that checks that `leaderid` is not equal to `localid`. it makes sense to me that after the resign state the replica should always increase its epoch. the replica resigned from leadership at epoch x so eventually the epoch will be at least x + 1. did you consider transitioning to candidate and relaxing the transition functions to allow both resigned and prospective to transition to candidate?,0,0.9943670630455017
1899726228,18240,ahuang98,2024-12-30T18:37:26Z,"discussed offline, transitiontounattached has existing logic for assigning election timeouts which we can borrow - we can just add an additional if clause that if we came from resignedstate, assign electiontimeout to resignedstate.electiontimeout which is effectively 0",0,0.9929665327072144
1899726857,18240,ahuang98,2024-12-30T18:38:54Z,discussed offline that this method is only used for adding voted state to unattached (in same epoch),0,0.9708836078643799
1899727021,18240,ahuang98,2024-12-30T18:39:15Z,discussed offline,0,0.9513140320777893
1899773951,18240,jsancio,2024-12-30T20:22:57Z,sounds good to keep the epoch parameter and validating it against the current epoch.,1,0.5037177801132202
1899778973,18240,jsancio,2024-12-30T20:34:54Z,let's add an else case and throw an illegal state exception.,0,0.9686804413795471
1899780274,18240,jsancio,2024-12-30T20:38:21Z,"how about passing the `nomineestate` object, checking the subtype of that object and casting to the appropriate subtype.",0,0.9899644255638123
1899782793,18240,jsancio,2024-12-30T20:44:33Z,how about just printing the entire `epochelection`? it may be useful to know the state of the entire voter set not just the rejecting voters.,0,0.9901306629180908
1899783114,18240,jsancio,2024-12-30T20:45:25Z,how about just printing the entire `epochelection`? it may be useful to know the state of the entire voter set not just the rejecting voters.,0,0.9901306629180908
1899783839,18240,jsancio,2024-12-30T20:47:12Z,"i think you can join these lines. if not, there should be a newline before `);`",0,0.9898738861083984
1899783973,18240,jsancio,2024-12-30T20:47:36Z,add a newline before `);`.,0,0.983437180519104
1899785061,18240,jsancio,2024-12-30T20:50:11Z,remove this line. let's not have commented code.,0,0.9138752222061157
1899785505,18240,jsancio,2024-12-30T20:51:24Z,let add a comment that summarizes our discussion and conclusion. it is good to document and explain this decision.,0,0.5849773287773132
1899790092,18240,jsancio,2024-12-30T21:03:06Z,"as we discussed offline, the resigned state also transitions to unattached with a greater epoch. let's document that. having said that, let's also update the comment at the top of this file that documents the transitions from resigned: let's also update the kip.",0,0.9908075928688049
1899791694,18240,jsancio,2024-12-30T21:07:39Z,missing new line between these two lines.,0,0.9570184350013733
1900259204,18240,jsancio,2024-12-31T20:30:38Z,let's keep the previous pattern of using static methods to construct `electionstate`. you can add `optional ` parameter to `withelectedleader`.,0,0.9940044283866882
1900264788,18240,jsancio,2024-12-31T20:55:16Z,"why do you need to call `maybefireleaaderchange`? based on the inputs and since prospective doesn't increase the epoch, i would assume that the leader and epoch doesn't change when transitioning to prospective.",0,0.9920916557312012
1900278415,18240,jsancio,2024-12-31T22:01:43Z,"`quorumstate` already logs all transitions. it logs the ""from"" and ""to"" state. not sure this add any information.",0,0.9822184443473816
1900278536,18240,jsancio,2024-12-31T22:02:33Z,same here. quorumstate already logs all state transitions.,0,0.991402804851532
1900279911,18240,jsancio,2024-12-31T22:09:59Z,"transitioning to prospective is not really a durable transition since no persisted data should have changed, right? you can see this is the case since the function `transitiontoprospective` doesn't take any inputs and it doesn't increase the epoch. in other words, the information that is persisted is information that quorum state already knows and has already been persisted.",0,0.9928829669952393
1900448685,18240,jsancio,2025-01-01T19:17:21Z,"you don't need this method, right? this method is declared by `epochstate`.",0,0.9896305203437805
1900449219,18240,jsancio,2025-01-01T19:22:56Z,can you remove this if it is not needed anymore?,0,0.9931615591049194
1900449269,18240,jsancio,2025-01-01T19:23:30Z,can you remove this if it is not needed?,0,0.9901639819145203
1900451851,18240,jsancio,2025-01-01T19:45:23Z,offline you mentioned that you added this because you didn't want to lose information when transitioning states. i agree with this goal but the voted key is lost when the replica transitions to the `leaderstate`. do you agree? if so can you file a jira to fix this after this pr.,0,0.9725170135498047
1900452510,18240,jsancio,2025-01-01T19:50:09Z,minor but let's just remove the `=` sign. [code block],0,0.9903102517127991
1900453595,18240,jsancio,2025-01-01T19:59:59Z,state transition changes are already logged at `info` level.,0,0.9902982115745544
1900455665,18240,jsancio,2025-01-01T20:18:33Z,"isn't this the same [code block] if so, you can remove the variable `retainvotedkey`. similar to the unattached implementation, let's document why this is done.",0,0.9936038851737976
1900458506,18240,jsancio,2025-01-01T20:42:39Z,"you should be able to remove the check for if it is the only voter by making that case transition to prospective instead. when the replica transitions to prospective, it already short-circuits that transition. when the replica transitions to prospective it checks if it can immediately transition to candidate.",0,0.9927954077720642
1900460957,18240,jsancio,2025-01-01T21:04:44Z,looks like this doesn't need to be public. looks like this method can be removed since it is not used.,0,0.983607828617096
1900461371,18240,jsancio,2025-01-01T21:08:36Z,why not just print the map? [code block],0,0.9929352402687073
1900540449,18240,ahuang98,2025-01-02T04:59:01Z,"it felt redundant to print the keys given that the replica ids are also contained in the values. since this is would only be used for debugging though, i'll take your suggestion and just print the entire map",0,0.9750149250030518
1900541138,18240,ahuang98,2025-01-02T05:01:16Z,"replicakey's tostring method contains the class name so i didn't want to be redundant - `string.format(""replicakey(id=%d, directoryid=%s)"", id, directoryid);`",0,0.9875138401985168
1900546362,18240,ahuang98,2025-01-02T05:17:15Z,like the following? [code block] is the intention of the additional parameter to make it clear this method should be called on nomineestate? this seems a bit redundant with the existing quorumstate helpers (e.g. iscandidate() and candidatestateorthrow()).,0,0.9942532181739807
1900571487,18240,ahuang98,2025-01-02T06:24:14Z,i'll also change prospective and unattached's election() to use the static methods.,0,0.9898046255111694
1900580715,18240,ahuang98,2025-01-02T06:46:34Z,replacing with code comments instead,0,0.9916669726371765
1900583997,18240,ahuang98,2025-01-02T06:54:06Z,:exploding_head:,0,0.9828261733055115
1900614259,18240,ahuang98,2025-01-02T07:53:35Z,thanks! i'll add the logic for short-circuiting transitions for only-voters. this also allows our invariant - only prospective can transition to candidate - to remain simple w/o edge cases.,1,0.9572808146476746
1900648700,18240,ahuang98,2025-01-02T08:43:45Z,are you perhaps confusing `epochelection` with `electionstate` (the latter is what epochstate has declared),0,0.9899402260780334
1900951176,18240,jsancio,2025-01-02T14:48:09Z,"if the quorum has a size of one and since the replica votes for itself when transitioning to prospective, `isvotegranted()` should always return true. if so, the replica doesn't need to check if it is the only voter. let's confirm we have a test for this in kafkaraftclienttest. if not, let's add a test. let's also confirm that we have a test for this in prospectivestatetest and candidatestatetest. if not, let's add tests for these cases.",0,0.9920886754989624
1900954282,18240,jsancio,2025-01-02T14:51:23Z,why do you check that is not leader? in kraft a replica should never start as a leader. kraft throws and illegal state exception if it starts as leader. see line 545 above. [code block],0,0.9876041412353516
1901113187,18240,jsancio,2025-01-02T17:43:07Z,yes. we discussed this offline.,0,0.9865456819534302
1901117479,18240,ahuang98,2025-01-02T17:48:39Z,discussed,0,0.9423765540122986
1901142655,18240,ahuang98,2025-01-02T18:17:36Z,"discussed offline, technically the replica can transition to leader due to the above conditional. we can improve this conditional by directly checking if the replica is unattached or follower, and merge this conditional into the above conditional",0,0.9875696301460266
1901235462,18240,ahuang98,2025-01-02T20:27:29Z,"added four tests for this, starting at `testinitializeasonlyvoterwithemptyelectionstate` confirmed!",0,0.953166663646698
1902113084,18240,ahuang98,2025-01-03T19:49:45Z,"i've organized quorumstatetest in the following way - misc tests were pulled to the front. all other tests are organized under banners (e.g. initialization tests, tests of transitions from state x)",0,0.9889096617698669
1902114352,18240,ahuang98,2025-01-03T19:51:26Z,the diff is misleading here. this test was just removed because i found it was a duplicate of `testinitializeasresignedleaderfromstatestore`,0,0.58358234167099
1902116235,18240,ahuang98,2025-01-03T19:54:13Z,the hw drops to -1l after candidate transitions to leader - if you agree this is a bug i'll file a jira for this,0,0.9647965431213379
1915345255,18240,jsancio,2025-01-14T17:48:56Z,this feels like it needs a comment explaining what and why.,0,0.8547348380088806
1915429555,18240,ahuang98,2025-01-14T18:45:41Z,clobbered `unattachedstatewithvotetest.java` into `unattachedstatetest.java`. i didn't think it was necessary to have a separate file (both having votedkey state and leaderid state are tested in this one file). i wanted to prevent introducing a separate withvotetest for prospectivestate as well,0,0.9924496412277222
1916914867,18240,jsancio,2025-01-15T15:55:11Z,okay. i went through all of the possible combination of quorum state and this change seem to be backward compatible and correct.,0,0.9383434057235718
1917004191,18240,jsancio,2025-01-15T16:43:54Z,"please make sure that all of the constructors delegate to this constructor. there is at least one constructor (`this(optionalint, uuid)`) that doesn't delegate construction to this constructor. that may mean that the tests should not specify the voters through the constructor but instead use the `with...` methods. in general the `builder` constructor should be as small as possible and the user can override the configuration using the builder's methods before calling `build()`. i think that means that ideally we should delete this method or it should have this signature: `builder(replicakey)`.",0,0.994500994682312
1917022963,18240,jsancio,2025-01-15T16:55:41Z,can we avoid this? can we let the caller makes this decision? it is technically possible for the replicas to support new rpc (protocols) but their voter configuration to be static.,0,0.9926735758781433
1917031492,18240,jsancio,2025-01-15T17:00:48Z,let's create a followup jira to remove this method.,0,0.9914546012878418
1917037427,18240,jsancio,2025-01-15T17:05:00Z,"we are very close to being able to remove this method, `initializedasleader`. do you want to do the honor and fix the last remaining test?",0,0.970574676990509
1917046168,18240,jsancio,2025-01-15T17:11:28Z,please use `electionstae.withelecterdleader`.,0,0.9931562542915344
1917046679,18240,jsancio,2025-01-15T17:11:51Z,did you mean `votedkey`?,0,0.9934646487236023
1917055500,18240,jsancio,2025-01-15T17:16:05Z,this looks like a `static` method. it doesn't use any object fields or methods.,0,0.9865509271621704
1917062525,18240,jsancio,2025-01-15T17:19:48Z,can we use `isreconfigsupported()`? this will break when we add a new kraft.version.,0,0.9951169490814209
1917064565,18240,jsancio,2025-01-15T17:21:20Z,should this version check that the `prevote` field is `false`?,0,0.9940338730812073
1917068135,18240,jsancio,2025-01-15T17:24:10Z,hmm. how about having `raftprotocol` implement `voterpcversion()`?,0,0.9903731346130371
1917072892,18240,jsancio,2025-01-15T17:27:47Z,this is too relax. it should return 0 only for kip_595_protocol and throw an illegal argument/state exception for the `else` case.,0,0.8024064302444458
1917074839,18240,jsancio,2025-01-15T17:29:18Z,do you want to update the exception messages to reference `withraftprotocol` instead?,0,0.9950299263000488
1917096432,18240,jsancio,2025-01-15T17:44:56Z,do you need this since you are using begin_quorum_epoch to propagate the leader and epoch.,0,0.9942229390144348
1917097458,18240,jsancio,2025-01-15T17:45:46Z,the prospective candidate is the same as the leader. was this done on purpose?,0,0.9924435019493103
1917114855,18240,jsancio,2025-01-15T17:57:18Z,is there a reason why you used 2 instead of 1 (like the other cases) for the leo?,0,0.9920145273208618
1917116456,18240,jsancio,2025-01-15T17:58:37Z,same here. why was the leo changed to 2 in this case?,0,0.9885774850845337
1917117528,18240,jsancio,2025-01-15T17:59:30Z,same here. why was the leo changed to 2 in this case?,0,0.9885774850845337
1917136327,18240,jsancio,2025-01-15T18:12:05Z,"i see. this actually depends on the kraft.version. for kraft.version 1 the local log will have an leo of 3 (leader change message, kraft version record and voter set record). for kraft.version 0 the local log will have an leo of 1, no?",0,0.9906167387962341
1917149169,18240,jsancio,2025-01-15T18:20:32Z,is it intentional that this response has a leader for the epoch but the other one does not?,0,0.9869340658187866
1917155747,18240,jsancio,2025-01-15T18:24:30Z,interesting that unattached waits for election timeout to transition to prospective while follower waits for fetch timeout to transition to prospective. it is okay for now but maybe they should both wait for fetch timeout since unattached now sends fetch requests.,0,0.9749190211296082
1917168666,18240,jsancio,2025-01-15T18:35:32Z,"you can just call `polluntilrequest` since it calls poll at least once, no?",0,0.9937775135040283
1917177912,18240,jsancio,2025-01-15T18:43:51Z,the most informative comparison in case of a failures is: [code block],0,0.9858274459838867
1917185173,18240,jsancio,2025-01-15T18:49:48Z,does it need to sleep for 1 ms? why? is calling `poll` enough?,0,0.9713980555534363
1917187753,18240,jsancio,2025-01-15T18:52:02Z,in other tests you sleep for `electiontimeoutms * 2` why the difference?,0,0.9726611375808716
1917190771,18240,jsancio,2025-01-15T18:54:11Z,same here. is calling poll enough since the remaining time is 0?,0,0.9787017107009888
1917203942,18240,jsancio,2025-01-15T19:04:24Z,"technically possible but it is odd that the replica is using a static voter set, with kip_595_protocol and an elected leader or voted candidate that is not in the voter set. maybe it is less confusing if you limit these tests to kip_853_protocol. minor but technically the protocol configuration is not needed since the replica doesn't need to send or handle rpcs to become leader.",0,0.8869620561599731
1917213839,18240,jsancio,2025-01-15T19:13:37Z,is this used? i couldn't find a caller for this method.,0,0.8145596981048584
1917216983,18240,jsancio,2025-01-15T19:16:37Z,checking the leader is not enough. it should also check that the epoch match.,0,0.9877177476882935
1917220113,18240,jsancio,2025-01-15T19:19:21Z,"let remove the ""todo"". how about: [code block]",0,0.9920329451560974
1917231251,18240,jsancio,2025-01-15T19:29:13Z,how about this formatting: [code block],0,0.9908894896507263
1917235613,18240,jsancio,2025-01-15T19:33:19Z,okay. i think it is fair to file a bug but assign it to yourself or me.,0,0.8982378244400024
1917246184,18240,jsancio,2025-01-15T19:43:16Z,not sure if idempotent is the correct description. i would just call this test: `testconsecutivegrant`.,0,0.9826011061668396
1917246675,18240,jsancio,2025-01-15T19:43:47Z,not sure if idempotent is the correct description. i would just call this test: testconsecutivereject.,0,0.91471928358078
1917255498,18240,jsancio,2025-01-15T19:52:23Z,what about the non-empty case?,0,0.9887507557868958
1917258238,18240,jsancio,2025-01-15T19:54:56Z,we should have done this in a different pr. it is difficult for me to see what has change and what has move so i have to review almost the entire file.,0,0.7124875783920288
1917365519,18240,ahuang98,2025-01-15T21:36:42Z,i'll change the other variations of this method to do the same,0,0.9824693202972412
1917376912,18240,ahuang98,2025-01-15T21:46:22Z,"sorry, i wish github was a bit smarter with diffs :( it was difficult for me to figure out what coverage we were missing without the tests being more ordered (and i thought it would be difficult for you to tell what we might be missing as well) so i ended up deciding the re-order was worth it. we discussed this briefly before, but ideally each state will have its own file in the end - i decided not to make that change in this pr since it would make it even harder to tell what had changed.",-1,0.9919472336769104
1917380871,18240,ahuang98,2025-01-15T21:50:33Z,same with all the other `xyzrpcversion()` methods?,0,0.9945763349533081
1917398669,18240,jsancio,2025-01-15T22:08:40Z,you could but i didn't suggest it for the sake of keeping the diff smaller. you can file a jira to fix this if you want.,0,0.9785078763961792
1917398687,18240,ahuang98,2025-01-15T22:08:41Z,"yes, i had considered allocating a different node for local to make its voted candidate, but rationalized that the behavior won't change and that this is also a valid/common state for a follower to be in (votedcandidatekey=leaderid)",0,0.9911812543869019
1917401126,18240,jsancio,2025-01-15T22:11:13Z,i take it back. this implementation is fine if you want to keep it. maybe just make it `else if (raftprotocol.isreconfigsupported()) {`.,0,0.9832457304000854
1917404175,18240,jsancio,2025-01-15T22:14:51Z,"i think i miss spoke. how about moving this out of the constructors and adding a configuration method like `withstartingvoter(voterset, kraftversion)`. the implementation delegates to `withstaticvoters` or `withbootstrapsnapshot`.",0,0.9649116396903992
1917419710,18240,ahuang98,2025-01-15T22:29:46Z,"hm, can't think of a reason. i'll standardize",-1,0.7903597950935364
1917424027,18240,ahuang98,2025-01-15T22:35:05Z,"yep, i decided to just use an leo of 3 for both cases as to not overcomplicate since it's valid for othernodekey to have a larger leo than local anyways. the difference in leo after gaining leadership between kraftversion 0 and 1 is also highlighted and tested in other kafkaraftclienttests which focus more on fetch/offset validation. i'll just add the conditional since it's easy enough",0,0.9787535667419434
1917434854,18240,ahuang98,2025-01-15T22:48:44Z,"yes, it was just for variation (since both could be valid responses)",0,0.9920191168785095
1917454524,18240,ahuang98,2025-01-15T23:10:33Z,i think i wanted to be more explicit with what happens when - i'll replace `polluntilrequest()` with the necessary `poll()` calls,0,0.9622672200202942
1917456559,18240,ahuang98,2025-01-15T23:13:38Z,yes!,1,0.7005663514137268
1917459804,18240,ahuang98,2025-01-15T23:17:02Z,"no strong reason, i'll standardize",0,0.9580089449882507
1917512126,18240,ahuang98,2025-01-16T00:38:50Z,"ah, this actually clears the mock send queue (otherwise the following check `raftrequest.outbound fetchrequest = context.assertsentfetchrequest();` fails due to unexpected number of requests in send queue) it works to remove the poll and clear the expected fetch later in the test, so i'll do that instead.",0,0.9930993318557739
1917518120,18240,jsancio,2025-01-16T00:48:53Z,"well, it is good to have self documented test (or code). you can make this connection clear by using the local log end offset if you expect the logs to match. e.g. `context.log.endoffset()`.",0,0.7970866560935974
1917525983,18240,jsancio,2025-01-16T01:01:45Z,missing newline between parenthesis: [code block],0,0.9913956522941589
1917526225,18240,jsancio,2025-01-16T01:02:10Z,missing newline between parenthesis: [code block],0,0.9913956522941589
1917526506,18240,ahuang98,2025-01-16T01:02:35Z,"i introduced this constructor to remove some of the redundancy and conditionals i was seeing with test parameterization. factoring in your next comment as well, maybe it makes more sense to remove this constructor and have a helper method do something similar instead in kafkaraftclientprevotetest.",0,0.9920482039451599
1917539718,18240,ahuang98,2025-01-16T01:25:06Z,i missed your last response with your suggestion about `withstartingvoter`. i'll leave this as is for now and we can discuss tomorrow,0,0.9889925122261047
1918724919,18240,jsancio,2025-01-16T15:06:33Z,can we make this an annotation that suppresses that check?,0,0.9912065863609314
1918748224,18240,jsancio,2025-01-16T15:20:38Z,given this implementation it is also correct to just store it as `endpoints leaderendpoints` and changing the constructor to accept an `endpoints` instead of an `optional `. it looks like in the raft module we never use `optional ` since `endpoints.empty()` is a valid value.,0,0.9945780038833618
1918750392,18240,jsancio,2025-01-16T15:22:06Z,this type doesn't write any log messages. we don't need to pass the log context to the object.,0,0.985929548740387
1918761915,18240,jsancio,2025-01-16T15:29:05Z,i think we use this formatting in this case: [code block],0,0.981991708278656
1918763846,18240,jsancio,2025-01-16T15:30:18Z,okay but i would like us to standardize on using `string.format`. i think his should be formatted as: [code block],0,0.9884632229804993
1918795087,18240,jsancio,2025-01-16T15:50:02Z,some code duplication can be removed with: [code block] or [code block],0,0.9936855435371399
1918812401,18240,jsancio,2025-01-16T16:01:09Z,"why would the replica send another request since it already sent a request [a link]? or is the issue that the replica change state from unattached (with voted) to follower [a link] and reset its connection and request manager? which means that it will send another fetch request when it becomes a follower? if this is the case, maybe the test structure you had earlier is better where you assert a fetch request is sent while in the unattached stated.",0,0.993425726890564
1918822107,18240,jsancio,2025-01-16T16:07:41Z,let's use this formatting: [code block],0,0.9863731861114502
1918823415,18240,jsancio,2025-01-16T16:08:31Z,missing newline character. [code block],0,0.9922669529914856
1918831481,18240,jsancio,2025-01-16T16:13:56Z,let's use this formatting: [code block],0,0.9863731861114502
1918838919,18240,jsancio,2025-01-16T16:19:08Z,if just one of the voter doesn't support pre-vote this replica needs to transition to candidate. that because that voter that doesn't support pre-vote may be need to establish quorum with the majority. i would change this working to: [code block],0,0.9914576411247253
1918852989,18240,jsancio,2025-01-16T16:28:12Z,"fyi, this shows the issue you highlighted in the metrics test. the known hwm is lost when transitioning to leader. this is odd from the client's (users of raftclient) point of view. this semantic turns out to be correct because the new hwm established by the leader is guarantee to be greater than the previous hwm. this is true because the leader first commits the current epoch before establishing the new hwm.",0,0.9443931579589844
1918931718,18240,ahuang98,2025-01-16T17:24:19Z,it's needed for `unattachedorprospectivecangrantvote`,0,0.9949636459350586
1918935598,18240,ahuang98,2025-01-16T17:27:18Z,i'll convert,0,0.9692055583000183
1918980033,18240,ahuang98,2025-01-16T18:02:58Z,"english is hard :face_with_tongue: i meant ""not the entire quorum"" vs ""entire quorum does not""",-1,0.4869353175163269
1918980139,18240,ahuang98,2025-01-16T18:03:04Z,i'll add more details to the jira - we can decide if it's worth changing this behavior,0,0.98428875207901
1919002962,18240,ahuang98,2025-01-16T18:22:42Z,"locally, checkstyle seems to take issue w/ this particular check. i'll give it a shot and see if it builds w/ ci",0,0.9838236570358276
1919024139,18240,ahuang98,2025-01-16T18:40:17Z,"ci doesn't like the change either :( [code block] i recall spending some time trying to debug the issue, and the potential fix (suppressioncommentfilter) seemed a bit more work than it was worth javancss is mentioned in the existing jira for addressing these raft suppressions though - [a link]",-1,0.9927750825881958
1919031445,18240,jsancio,2025-01-16T18:45:36Z,got it. thanks.,1,0.9407241940498352
92508146,2244,mjsax,2016-12-14T22:49:16Z,nit: either `kafka streams` or `{ kafkastreams}` (more ofter farther down),0,0.9937200546264648
92508580,2244,mjsax,2016-12-14T22:51:46Z,nit: `{ org.apache.kafka.streams.state.readonlykeyvaluestore readonlykeyvaluestore}` applies to all links with package prefix,0,0.9946624636650085
92508710,2244,mjsax,2016-12-14T22:52:35Z,` ktable`,0,0.9899618625640869
92509183,2244,mjsax,2016-12-14T22:55:15Z,"just a view, i.e., it is not materialized in a state store, on top",0,0.9934123158454895
92509708,2244,mjsax,2016-12-14T22:57:47Z,javadoc missing `replicatedtable` -> `globalktable`,0,0.9934399724006653
92509786,2244,mjsax,2016-12-14T22:58:12Z,`table` -> `globalktable`,0,0.9928681254386902
92510046,2244,mjsax,2016-12-14T22:59:34Z,"an exception? seems to align with `ktable` so not part of this pr -- but should we change this and just skip/drop those records? if we apply an aggregation to compute a ktable, we do the same, ie, just dropping those records. so there is an gap between aggregation and join -- even if for aggregation the input is a kstream... nevertheless, we should think about this (\cc )",0,0.9766188263893127
92514204,2244,mjsax,2016-12-14T23:27:03Z,nit. indention.,-1,0.7487024068832397
92514591,2244,mjsax,2016-12-14T23:30:05Z,nit `kstreamglobalktablejoin`,0,0.9923959970474243
92514897,2244,mjsax,2016-12-14T23:32:20Z,"can we unify this with inner class of `kstreamktablejoin` (ie, extract both inner classes and make top level class)? if not, maybe rename to `kstreamglobalktablejoinprocessor`.",0,0.9951512813568115
92515229,2244,mjsax,2016-12-14T23:34:50Z,nit: rename `thejoinprocessor ` ->`ktableglobalktablejoinprocessor`,0,0.9941437840461731
92515479,2244,mjsax,2016-12-14T23:36:32Z,nit: rename `thevaluegettersupplier` -> `ktableglobalktablejoinvaluegettersupplier`,0,0.9942219853401184
92516392,2244,mjsax,2016-12-14T23:44:07Z,i just compared with `ktablektablejoinprocessor` and the logic there is less nested thus easier to read. maybe we can break this down into smaller pieces similar to `ktablektablejoinprocessor`,0,0.9895992279052734
92517207,2244,mjsax,2016-12-14T23:50:10Z,"if we can reuse `ktablektableleftjoinprocessor` why not the inner join processor, too?",0,0.9949482679367065
92517353,2244,mjsax,2016-12-14T23:51:16Z,why renaming?,0,0.9611669778823853
92518822,2244,mjsax,2016-12-15T00:02:57Z,comment does not apply anymore -- nodegroup will never be null now (maybe empty though),0,0.9921556115150452
92573799,2244,dguy,2016-12-15T09:41:02Z,"yeah, i think that is a discussion worth having.",0,0.8838222622871399
92574547,2244,dguy,2016-12-15T09:45:15Z,"thanks, i'll remember that going forward. you are my javadoc hero ;-)",1,0.9956628680229187
92577752,2244,dguy,2016-12-15T10:03:30Z,looks like a mistake.,-1,0.6108811497688293
92578027,2244,dguy,2016-12-15T10:05:14Z,should be `topicgroupid` is null,0,0.9928814172744751
92583292,2244,dguy,2016-12-15T10:36:26Z,yep - thought i did that already.,0,0.9689480662345886
92712542,2244,mjsax,2016-12-15T22:18:49Z,nit: root -> statestore,0,0.9769656658172607
92712675,2244,mjsax,2016-12-15T22:19:21Z,nit: name -> viewname,0,0.9877589344978333
92713058,2244,mjsax,2016-12-15T22:21:49Z,should we check for `key == null` -- or is this checked before the call already? we should start using assertions... would avoid those questions. (\cc ),0,0.529420018196106
92714906,2244,mjsax,2016-12-15T22:32:40Z,"state stores are added via an supplier -- a suppliers is not required here, but it might be confusing for users if there are different method signature -- i think we should align both. wdyt?",0,0.9616535902023315
92716639,2244,mjsax,2016-12-15T22:42:58Z,"i am just wondering what abstraction we want to provide at papi level -- we never discussed this in detail -- and it's not part of the kip either. we only talked about globalktable. for globalktable we have the requirement that it is always populated from a source topic. thus, this method mimics this -- but it this a papi concept? should we have a method like this? and if it is a papi concept, should global stores always be used like this? if yes, we might want to drop `addglobalstore(final statestore store)`. not sure about the answers. we should discuss this.",0,0.9745995402336121
92719445,2244,mjsax,2016-12-15T23:00:21Z,"i am still not sure about this design. actually, the global part shout use a singleton pattern. it is kinda weird that we have two `processortopology` ""types"" -- the global one and the regular one. as the kip is still under discussion, we might want to think about this once more. also from an papi vs dsl point of view -- i think, we need a better separation between both and not ""pollute"" papi with dsl concepts.",-1,0.9750216007232666
92719996,2244,mjsax,2016-12-15T23:03:55Z,should we implement singleton pattern here?,0,0.9933493733406067
92720200,2244,mjsax,2016-12-15T23:05:21Z,should we release the lock here?,0,0.992834210395813
92720829,2244,mjsax,2016-12-15T23:09:57Z,why not `.endoffsets()`? could replace the whole method.,0,0.9880133867263794
92723075,2244,mjsax,2016-12-15T23:26:58Z,not strictly required -- only suppresses the log message. is this intended?,0,0.9329544901847839
92723476,2244,mjsax,2016-12-15T23:30:19Z,are checkpoint files delete somewhere else? or should be do this here?,0,0.9928556680679321
92726236,2244,mjsax,2016-12-15T23:52:21Z,"as the restore consumer is shared, can we make sure no parallel restore operation messes with global state thread here? applies to the whole class... also -- if we change partitions assignment -- would we need to restore a previous assignment or maybe better just extend the current assignment (instead or replacing it)? or does every ""user"" of the consumer restores its own assignment each time it uses the consumer (this might also imply that doing the assignment in `initialize` is wrong)? btw: how does state recovery work today? single threaded?",0,0.9896998405456543
92773817,2244,dguy,2016-12-16T08:59:13Z,hmm - i'm don't think viewname really describes it any better. the class is already named `keyvaluestorejoinview` - name seems appropriate,0,0.943719208240509
92773828,2244,dguy,2016-12-16T08:59:20Z,as above,0,0.9391705989837646
92773952,2244,dguy,2016-12-16T09:00:20Z,this is what it is on the interface and is consistent with every other `statestore`,0,0.9880747199058533
92774161,2244,dguy,2016-12-16T09:02:15Z,it is worth adding a null check here. though i will probably just return null rather than throwing exceptions etc. i'm not convinced that calling `get(null)` is worthy of raising an exception.,0,0.9475528001785278
92774515,2244,dguy,2016-12-16T09:05:28Z,i don't think we should use a suppler here. we want a single instance of a `statestore` and this shows that intent. a supplier indicates that there may be multiple instances.,0,0.9820241928100586
92774899,2244,dguy,2016-12-16T09:08:42Z,"this is in the kip. anyway, this method has been added so that the joins generated by `globalktables` can be queried etc. as they are just views on top of other `globalktables` they don't have their own source as such. also, from a users point of view - why shouldn't they be able to add a global store of whatever type they like? they might have a pre-populated table or something that they'd like available in all of there processors.",0,0.987873375415802
92775816,2244,dguy,2016-12-16T09:15:00Z,"i'm not 100% happy with this either, but as you know, the dsl just builds on the papi and the concepts are already mixed. i don't like this, but this is where we are at the moment. i'd much prefer that `kstreambuilder` didn't extend `topologybuilder` - imo there should be another class, lets say `papibuilder` (name sucks), `topologybuilder` becomes package private. `kstreambuilder` and `papibuilder` are standalone classes, they don't inherit from `topologybuilder` they just use it to build the topology. then we have no mixing of dsl and papi concepts at the api layer. anyway, i don't want to do that as part of this task!",-1,0.9742106199264526
92776262,2244,dguy,2016-12-16T09:18:21Z,no. not a fan of singletons at all. we just create a single instance of it.,-1,0.5713624954223633
92777615,2244,dguy,2016-12-16T09:28:09Z,didn't know it existed!,-1,0.8582729697227478
92778385,2244,dguy,2016-12-16T09:33:36Z,it probably should be deleted after it is first loaded. at least that is what we do elsewhere.,0,0.9929699301719666
92780091,2244,dguy,2016-12-16T09:44:14Z,"this consumer is not the restore consumer. it is a consumer just for this thread so it isn't shared at all. there are no parallel operations on it. when the `statestores` are restored, in `globalstatemanagerimpl`, they each `assign` their own partitions, fetch the data up to the hw, then un-assign their partitions. during this process all of the `topicpartition` for global stores are collected and that is what is assigned here. this is the set of partitions we need to consume to keep all global stores up-to-date. yes, recovery of statestores is always single threaded.",0,0.9891083240509033
92882610,2244,mjsax,2016-12-16T20:42:27Z,agreed: this should definitely not be done in this pr! i am just afraid that this pr makes reworking and separating papi and dsl even harder.,-1,0.9874297976493835
92883151,2244,mjsax,2016-12-16T20:46:28Z,hmmm... weird naming. should we rename all?,-1,0.9839634299278259
92883382,2244,mjsax,2016-12-16T20:48:16Z,sounds opinion based :) what's the problem with singletons?,1,0.9958251714706421
92888694,2244,mjsax,2016-12-16T21:24:39Z,"i understand that argument. my point is more about api design -- we break an api pattern and thus reveal something to the user, that you can consider an implementation detail. the user does not care how ofter we do instantiate a store. if i write code for a store, and hand it in, i don't care about it -- i want to same api for regular and global stores. why should i care about the number of instantiation as a user? i personally dislike the whole handing in factories instead of stores from a user perspective completely -- even if i understand why it is necessary for streams. (flink for example has a very nice api for this and it's not a concern there.) as a user, i want to implement a store -- i don't want to bother with a store factory (i don't want to change this pattern because we have good reasons to enforce is, and one more wrapper for the store is an acceptable burden for the user imho). so we educate the user to implement factories and suddenly we change our mind and say -- ""not for global store"".",-1,0.7919250726699829
92889320,2244,mjsax,2016-12-16T21:29:12Z,"understood. but than, we should maybe only keep `addglobalstore(final statestore store)` and remove the second (this) `addglobalstore` method -- it's a dsl concept again -- i understand the ""i don't care, papi legacy"" argument, but everything we introduce in hard to remove later on. we could just add a global store, and do the wiring with a topic in kstreambuilder instead of topologybuilder?",0,0.9883402585983276
92890189,2244,dguy,2016-12-16T21:35:22Z,not in this pr,0,0.9772689342498779
93021658,2244,dguy,2016-12-19T12:24:23Z,everything in software development is opinion based! singletons are ok for simple objects with no dependencies. as soon as you start adding dependencies in to the mix you end up with tightly coupled code. that is hard to test.,-1,0.485013872385025
93022514,2244,dguy,2016-12-19T12:31:19Z,"we could do that if we make some of the fields in `topologybuilder` protected, i.e., so they can be accessed from `kstreambuilder`. i'm not a big fan of doing this, but i agree with your point about making things harder to remove later",0,0.902696430683136
94648336,2244,mjsax,2017-01-04T19:28:48Z,"i had a discussion about when to set the state to running with and we agreed that it is better to change the state before we start the threads -- can't remember the details of our discussion though. however, i would keep it as is. maybe can elaborate on it.",0,0.9682120084762573
94648979,2244,mjsax,2017-01-04T19:32:16Z,"joins with other globalktable got removed, right?",0,0.9862235188484192
94649387,2244,mjsax,2017-01-04T19:34:30Z,nit: better markup would be [code block],0,0.9894822835922241
94650151,2244,mjsax,2017-01-04T19:38:23Z,"weather [or] not seem like c&p error -- would you mind fixing the other typos in all javadocs, too?",0,0.981082558631897
94650667,2244,mjsax,2017-01-04T19:41:14Z,"remove this paragraph -- we did removed it for other javadocs, too.",0,0.9916512370109558
94650786,2244,mjsax,2017-01-04T19:41:51Z,as above,0,0.9391705989837646
94651214,2244,mjsax,2017-01-04T19:44:01Z,"i would prefer to use `gk` (like global key), `gv`, and `rv` (result value) instead of `k1`, `v1`, and `r` to have somewhat more meaningful names instead of numbering. (`rv` is used in other methods, too)",0,0.9934968948364258
94651248,2244,mjsax,2017-01-04T19:44:13Z,as above.,0,0.9878018498420715
94675135,2244,mjsax,2017-01-04T22:05:41Z,"should we not do this in ``? if test fails and `` is never executed, next test run might fail.",0,0.9900370836257935
94676111,2244,mjsax,2017-01-04T22:11:28Z,"i think that join result should not depend of other values being null or not. line 102/103 might hit a race condition if global table get altered between both calls. thus we might end up with wrong results imho. not 100% sure, but i think it's worth thinking about it.",0,0.9102306962013245
94676192,2244,mjsax,2017-01-04T22:11:51Z,as above.,0,0.9878018498420715
94679715,2244,mjsax,2017-01-04T22:33:41Z,"this test is only sufficient for stream-globaltable join imho, but not for table-globalktable join for which we need to test `null` tombstone input record for ktable input. furthermore, i think we need a test that updates globalktable in the background while processing -- this might be a separate test though (it's about the race condition i mentioned that we should test for).",0,0.9926387071609497
94686399,2244,mjsax,2017-01-04T23:18:45Z,does this test anything that is not already covered by `globalktableintegrationtest` -- or the other way round?,0,0.9950188398361206
94688157,2244,mjsax,2017-01-04T23:32:34Z,"the test behavior is ok, but i think the name is wrong. -> `shouldnotforwardifoldvalueisnull` we should also have one more test, that test if `null` is emitted if `oldvalue != null`",0,0.9845507740974426
94688915,2244,mjsax,2017-01-04T23:38:53Z,i think we should expect `a.newvalue == null` because input `oldvalue != null` -- we cannot know if globaltable was updated in between and thus previous oldvalue might have joined.,0,0.992798924446106
94689054,2244,mjsax,2017-01-04T23:40:09Z,"imho, this test is redundant with my suggested version of `shouldnotforwardifdeleteandoldkeynotinotherstoreandsendoldvalues`",0,0.9100463390350342
94689208,2244,mjsax,2017-01-04T23:41:40Z,"from my understanding, if old and new value is `null` nothing should be forwarded -- independent of the content of globalktable.",0,0.988570511341095
94689292,2244,mjsax,2017-01-04T23:42:27Z,i guess similar comments as above apply -- skipping this class for now.,0,0.9548932313919067
94689865,2244,mjsax,2017-01-04T23:47:10Z,we should use `lockexception` instead of `streamsexception` imho.,0,0.9941018223762512
94690456,2244,mjsax,2017-01-04T23:52:15Z,why not just one test for `shouldinitializestatestores` and `shouldreturninitializedstorenames` ? both test the same method.,0,0.993985116481781
94690596,2244,mjsax,2017-01-04T23:53:24Z,"remove try-catch and fail and add `(expected = illegalargumentexception.class)` (same below) or could `statemanager.initialize(context);` throw `illegalargumentexception`, too?",0,0.995053768157959
94691732,2244,mjsax,2017-01-05T00:03:39Z,:),1,0.7730679512023926
94692341,2244,mjsax,2017-01-05T00:09:17Z,"nit: ""kaboom!"" ;)",1,0.9951339364051819
94692983,2244,mjsax,2017-01-05T00:15:15Z,should we apply a test timeout to check if `join()` got stuck because it did not stop running on `close()` ?,0,0.9906705617904663
94693136,2244,mjsax,2017-01-05T00:16:40Z,unify `shouldstoprunningwhenclosedbyuser` and `shouldclosestatestoresonclose` ? both do test `close()`,0,0.9946274161338806
94695940,2244,mjsax,2017-01-05T00:43:44Z,isn't this test covering `shouldupdatestatewithreceivedrecordsforpartition` ?,0,0.9945557117462158
94696136,2244,mjsax,2017-01-05T00:45:47Z,unify `shouldflushstorewhenflushintervalhaslapsed` and `shouldnotflushoffsetswhenflushintervalhasnotlapsed` ?,0,0.9949358701705933
94727438,2244,dguy,2017-01-05T08:17:54Z,sure - i'll put it back. didn't really make sense to me to set the state to running before the threads have started. but whatever,0,0.5913492441177368
94728105,2244,dguy,2017-01-05T08:24:48Z,next test wont fail as it will use a different state directory.,0,0.9635230302810669
94729425,2244,dguy,2017-01-05T08:37:42Z,"we should have both tests. they cover some of the same things, but this is much easier to write and debug issues. it runs much quicker. however, it doesn't cover the more end-to-end scenario that the integration tests cover.",0,0.9639931917190552
94730687,2244,dguy,2017-01-05T08:49:00Z,"i don't agree with the name you have suggested, but i also think the name of the test is not completely correct",0,0.7602797746658325
94734155,2244,dguy,2017-01-05T09:15:44Z,"yep. i was thinking that a direct key mapping could result in the join, but that was incorrect.",0,0.6406481862068176
94735025,2244,dguy,2017-01-05T09:22:02Z,"sure, but `lockexception` didn't exist when i wrote this!",0,0.9745197892189026
94735566,2244,dguy,2017-01-05T09:25:54Z,"yes, you could test them both in the same method. however, i prefer to have single focused tests where the test names describe what is happening. there is nothing wrong with having multiple tests for the same method and params, in-fact i'd encourage it.",0,0.9518879652023315
94735880,2244,dguy,2017-01-05T09:28:02Z,"it doesn't now, but it, or something, it uses might in the future. i prefer this approach for these sort of scenarios as it guarantees that the exception was raised from the code i am trying to test",0,0.9872690439224243
94736396,2244,dguy,2017-01-05T09:31:37Z,nope - they are testing different things that happen on close. i prefer it this way as it is easier to just read the test names to see what should be happening rather than have to read through the assertions.,0,0.9665933847427368
94736604,2244,dguy,2017-01-05T09:33:14Z,not quite - this is checking the multiple topic case. the other is just checking a single topic,0,0.9499068856239319
94736696,2244,dguy,2017-01-05T09:33:57Z,see my other comments. this is how i'd prefer to see the tests written,0,0.9172568917274475
94739678,2244,dguy,2017-01-05T09:53:44Z,"the `null` tombstone cases are already covered by `ktableglobalktablejointest` and `ktablektableleftjointest` - i don't think they need to be covered here again. i'm not sure about the background thread. yes there could be a race condition (i've updated the code as suggested below), but i'm not 100% sure how we could/should handle it.",0,0.7693748474121094
94823111,2244,mjsax,2017-01-05T18:27:56Z,"if you apply this argument, you can never use `(expected = ...)` as it would apply to all tests using this pattern. wouldn't it?",0,0.9901441335678101
94823260,2244,mjsax,2017-01-05T18:28:47Z,"yes. but if multi-topic works, single topic works, too. or not?",0,0.9886119961738586
94829084,2244,mjsax,2017-01-05T19:00:26Z,i just thought about this once more. to me it seems that the race condition is because of sending oldvalues. why do we actually need this? or could we just disable sending old values?,0,0.9736027717590332
94832919,2244,mjsax,2017-01-05T19:22:06Z,"what is the different from this test to `shouldnotsendanythingifchangeisnullnullandkeymapstonullinothertable`? furhtermore, why do you setup a new `ktableglobalktableleftjoin` ? if i did not miss anything, it is the same setup as the global member `join` variable.",0,0.9915955662727356
94919202,2244,dguy,2017-01-06T09:23:13Z,yeah they do look the same. brain fade!,-1,0.8305128216743469
94919538,2244,dguy,2017-01-06T09:26:11Z,"it is a question of how you write tests. i write tests and code starting from the simplest things and working out from that. so the test for the single topic comes first, and then the test for multiple topics. in this case the test for multiple topics might be enough, but maybe it isn't, maybe the code assume there is always >1 topic? it is good to have both",0,0.9276909232139587
94920231,2244,dguy,2017-01-06T09:32:06Z,"no, i disagree. most tests i'd use `(expected = ....)` in would either have a single method call in them, so you know that is the only method that can throw the exception. or, it would be a `new blah(..)` followed by testing the single method. of course the `new ..` could throw an exception, but hopefully most ctors are side-effect free.",0,0.7604507803916931
94930979,2244,enothereska,2017-01-06T11:01:39Z,"""weather"" typo",0,0.6863272786140442
94931159,2244,enothereska,2017-01-06T11:03:28Z,would be good to be consistent at least with the ktable.,0,0.9762242436408997
94931291,2244,enothereska,2017-01-06T11:04:46Z,currently we always materialize though.,0,0.9879029393196106
94939282,2244,dguy,2017-01-06T12:29:21Z,hmmm - maybe we don't need to get the old value from the other table at all. as in `ktablektableleftjoin` we get the current value from the other table and then if `sendoldvalues` we join `change.oldvalue` with the value from the other table. thoughts?,0,0.9783827662467957
94950774,2244,enothereska,2017-01-06T14:16:25Z,i agree with both of you.,0,0.7364805340766907
94980385,2244,mjsax,2017-01-06T17:04:46Z,"i would not send old value whatsoever -- because of async updates of globalktable we cannot guarantee any semantical meaning -- we might miss multiple update from globalktable and thus, me might send an ""old value"" that was never emitted as ""new value"" before.",0,0.9666560292243958
94981984,2244,dguy,2017-01-06T17:14:29Z,"i've been looking a bit more and i'm still not certain what the correct thing to do in this situation is. we need to send an old value for the subtractors of the aggregators/reducers, but the old value may not be the same value as previously seen. an example that doesn't work properly. [code block] if i initialize g1 with: (1, green) (2, blue) (3, yellow) (4 red) then send to t1 (1, 1) (2, 1) (3, 1) and flush state i get (green, 3) all good so far. however if i then send to g1 (1, orange) and then to t1 (1, 4) and flush state i get (green, 3) (orange, -1) (red, 1) which is obviously incorrect. the oldvalue of green never gets sent so the count for green doesn't reduce by 1, rather the oldvalue is orange, hence orange with a count of -1. hmmmm!",0,0.8056519627571106
95020150,2244,mjsax,2017-01-06T21:06:45Z,"that is exactly what i had in mind with my previous comment... i just thought we might be able to not send the old value at all -- but your example shows that we need to send it. one way to fix it, is to remember the old value on the triggering ktable side (i guess we need another store for this...). thus, instead of looking up old value in globalktable, we look it up the the new store. not sure if there is a better way to do it.",0,0.9501453638076782
95133661,2244,dguy,2017-01-09T10:49:03Z,would appreciate your thoughts on this.,1,0.8751740455627441
95287565,2244,guozhangwang,2017-01-10T01:57:06Z,not sure if this interface is usefeul with `processorstatemanager`? should it be in the extended `globalstatemanager` only?,0,0.9932854175567627
95287972,2244,guozhangwang,2017-01-10T02:01:50Z,why we want to maintain an interface of `globalstatemaintainer`? is it because of mocking in unit tests? otherwise its only impl is `globalstateupdatetask`.,0,0.9931135773658752
95288306,2244,guozhangwang,2017-01-10T02:05:03Z,"my gut feeling is that we do not need to mimic a `processortopology` and `internalprocessorcontext` interface for this task, as it is a very special task whose topology will just be a list of source topics and a list of state stores, making them as generic interfaces would just introduce one-time classes like `globalprocessorcontext` in which lots of its functions will not be required at all. instead we can just e.g. pass into it a list of source topics, a map between topics to state stores, etc and let it run its only loop for fetching + updating stores, etc.",0,0.42239540815353394
95288621,2244,guozhangwang,2017-01-10T02:09:14Z,"the usage of `sourcenodeandserializer` is a bit awkward to me here: we have wrapped the source node in order to get its corresponding deserializer in this class, and we again keep a map from topic name to this deserializer; so why don't we just use a map from topics to deserializer directly?",-1,0.900187611579895
95319354,2244,dguy,2017-01-10T08:42:06Z,it is used by `processorcontextimpl` it is needed on the interface,0,0.9951454997062683
95319810,2244,dguy,2017-01-10T08:44:51Z,"using interfaces is good oo design practice. it facilitates loose coupling, flexibility, better design of roles. yes, it also helps with testing.",1,0.7096126675605774
95324378,2244,dguy,2017-01-10T09:16:20Z,"because we need both the sourcenode and the deserializer when we receive data from the topic. i.e., we need to deserialize the data and the `sourcenode` to process it",0,0.9922435879707336
95327582,2244,dguy,2017-01-10T09:35:35Z,"i disagree. firstly it isn't mimicing a `processortoplogy` - it is one! we have various classes in place already that do the the work needed to keep the table up-to-date, i.e, `soucenode` and `ktablesourceprocessor`. they need a `processcontext`. if we don't go down this path then we will be duplicating the code in those classes as we need to do the same thing. further `globalprocessorcontext` is as one-time as `standbycontextimpl`. i don't see any difference here. i also abstracted out all of the common `processorcontext` methods to `abstractprocessorcontext` to avoid having to avoid duplication and implementing of some unnecessary methods.",-1,0.870150625705719
95420343,2244,guozhangwang,2017-01-10T17:56:25Z,"this is a meta comment about `change<>`, not sure if my thoughts are correct: currently we propagate the need to send old values in any aggregate operators back-wards all the way to source nodes: if a ktable aggregate operator is observed it will be propagated to all its ancestors; with materialized results of ktable-ktable join, this propagation can be stopped at such operations. in this case, ktablektablexxjoin do not need to expect a `change<>` at all as it will never need the old value any more. i'm not sure if we can immediately change its type from `change ` to `v`, but i think technically it should be the case.",0,0.9754611849784851
95420796,2244,guozhangwang,2017-01-10T17:58:32Z,nit: rename to `globalcontextimpl` to be consistent?,0,0.9949309229850769
95422432,2244,guozhangwang,2017-01-10T18:07:24Z,"it is a subjective thing, but i usually find such oo design most useful when the interface is public and the impl has some separate functions to be used in other internal classes (e.g. the refactoring are doing to separate topologybuilder user-facing apis from its internal functions used by `streamthread`, etc). while this class is pure internal we can always just extend / override for testing.",0,0.9478431344032288
95424323,2244,guozhangwang,2017-01-10T18:16:58Z,"okay, make sense.",0,0.8702600598335266
95425307,2244,guozhangwang,2017-01-10T18:22:24Z,"instead of adding this interface, could we let `processorcontextimpl` to contain two `statemanagers`, while `standbycontextimpl` and `globalcontextimpl` each contain one? i know it is an internal interface so maybe it's not that important at all, but just wanted to throw my ideas here.",0,0.9123470783233643
95425732,2244,guozhangwang,2017-01-10T18:24:39Z,this is not about this pr: in #1446 we are removing specific cache sensors since we are adding sensors for generic purposes already. there will be some major conflicts between these two.,0,0.9801685810089111
95428000,2244,enothereska,2017-01-10T18:36:30Z,"there will be a conflict, but hopefully not major.",0,0.9145995378494263
95428041,2244,dguy,2017-01-10T18:36:39Z,yep :-(,-1,0.9886493682861328
95428151,2244,dguy,2017-01-10T18:37:14Z,sure,0,0.9137381911277771
95429909,2244,dguy,2017-01-10T18:45:57Z,i'm not sure i follow. not immediately clear to me how `ktablektablexxjoin` can't expect a `change<>`. that is what is will be sent from the previous `ktablexxxprocessor`,0,0.5593398809432983
95455229,2244,dguy,2017-01-10T20:57:11Z,if we did that i think we'd need another `statemanager` implementation. as we wouldn't want the one used by `processorcontextimpl` to go through the initialization and restoration of global stores.,0,0.9925835132598877
95455897,2244,dguy,2017-01-10T21:01:01Z,we'll have to agree to disagree on this one!,-1,0.8955774307250977
95475213,2244,mjsax,2017-01-10T22:44:29Z,created [a link] for this.,0,0.9913290739059448
85607023,2074,vahidhashemian,2016-10-28T20:44:23Z,"this is where the bug was introduced. if `state` is `none`, there is a possibility that the old consumer based group does not have any active members; so we need to check whether new consumer is used or not, and then proceed accordingly.",0,0.9929787516593933
85607062,2074,hachikuji,2016-10-28T20:44:33Z,was there a kip for this that i missed?,0,0.9769739508628845
85607674,2074,vahidhashemian,2016-10-28T20:48:28Z,"thanks for bringing this up. i wasn't totally sure what to process is for changing the protocol, and whether i'm actually correct to assume that the protocol has to be changed for this jira. i haven't opened a kip yet, if you think that's eventually going to be needed for i'd be happy to create one. thanks in advance for clarifying this.",1,0.990580141544342
85608617,2074,hachikuji,2016-10-28T20:54:01Z,"yeah, protocol changes definitely need a kip. probably makes sense then to split the bug fix into a separate patch.",0,0.7880526781082153
85608849,2074,vahidhashemian,2016-10-28T20:55:44Z,"thanks. i'll submit the bug fix separately, and then work on creating a kip.",1,0.8686965107917786
86647580,2074,vahidhashemian,2016-11-04T23:11:13Z,"i was hoping you could take a look at an issue i'm running into if and when you get a chance. while kip-88 is open for discussion i spent some time creating some unit tests for this pr. this particular unit test simply mocks two consumers that consume from the same 1-partition topic and belong to the same consumer group. a similar unit test on old consumers exists earlier in the same file and runs fine. there are also other unit tests above using the new consumer that run fine but they mock only one consumer. the problem i'm running into is this line that mocks the second consumer and takes a long time to run (i believe for the consumer to join the group that eventually times out) and the consumer group gets corrupted somehow. when i debug and check the status of the group down in the `waituntiltrue` check, sometimes it is `empty`, or `dead`, or even `stable` with only one of the consumers and it never gets into the expected state (`stable` with two members). where it gets stuck in a loop i think is [a link] (after [a link]. i'm not sure if i'm doing something wrong with the unit test or if i'm hitting some bug. i thought you might know by just looking at it. thanks.",0,0.8585125803947449
92458550,2074,hachikuji,2016-12-14T18:34:17Z,nit: the `offsetfetchrequest` suffix seems redundant. how about this `offsetfetchrequest.forallpartitions()`?,0,0.9583063125610352
92458890,2074,hachikuji,2016-12-14T18:36:11Z,"don't we need a null check in the loop above? also, should we return a null array in the response if the requested partitions are null?",0,0.994208812713623
92459503,2074,hachikuji,2016-12-14T18:39:37Z,one thing i'm realizing is that this schema gives us no way to indicate that a group doesn't exist when you fetch all partitions. that may be ok since we usually know ahead of time whether or not a group _should_ exist (e.g. by using listgroups).,0,0.9841046929359436
92460753,2074,hachikuji,2016-12-14T18:46:06Z,seems like we could do these two lines with a `map` and `getorelse` combo.,0,0.9875118732452393
92461437,2074,hachikuji,2016-12-14T18:49:42Z,this is a little hard to follow. maybe we could create two vals and do the append at the end?,0,0.6185866594314575
92461907,2074,hachikuji,2016-12-14T18:52:02Z,can we cover the error case also for a request for all partitions?,0,0.9928382039070129
92462186,2074,hachikuji,2016-12-14T18:53:15Z,"maybe we can just say ""versions 1 and above""?",0,0.9942182302474976
92462799,2074,hachikuji,2016-12-14T18:56:21Z,is the version check necessary?,0,0.9940663576126099
92463197,2074,hachikuji,2016-12-14T18:58:13Z,maybe we could wrap the `some` at the end to remove one level of nesting?,0,0.9918060302734375
92463905,2074,hachikuji,2016-12-14T19:02:05Z,hmm... i don't think we should be accessing the group directly at this layer. it's probably better to either overload `groupcoordinator.handlefetchoffsets` or expose a new method.,0,0.9067507982254028
92468547,2074,vahidhashemian,2016-12-14T19:24:18Z,"sure, that sounds reasonable. i'll update the method name.",0,0.9853715300559998
92477069,2074,hachikuji,2016-12-14T20:01:48Z,"thinking about this a little more.. there is an edge case around coordinator failover. we may lookup the coordinator for some group, find that it is broker a, and then send the offsetfetch for all partitions. before the request arrives, it could happen that broker b becomes the coordinator (it may have already begun the transition even before we did the initial coordinator lookup), but we won't have a way to detect it. this will cause us to mistakenly report that there are no offsets for the group.",0,0.805747389793396
92478985,2074,vahidhashemian,2016-12-14T20:11:55Z,"yes, i missed that. thanks. i'll try to fix it in the next update.",1,0.7354236841201782
92495078,2074,vahidhashemian,2016-12-14T21:39:40Z,"could you please clarify your first comment above? with this change, i can still see the `error: consumer group '...' does not exist.` message if 1) the consumer group is never created. 2) the consumer group is created but its offsets are all expired. regarding the second comment, are you referring to double `findcoordinator(...)` calls in this use case (through [a link] and [a link]? if so, one improvement would be to somehow preserve the `coordinator` value found in `describeconsumergroup(...)` for use in `listgroupoffsets(...)`. please advise if i misunderstood the issue. thanks.",0,0.9953706860542297
92501254,2074,hachikuji,2016-12-14T22:10:14Z,"the basic issue is that the error codes are in the partition data of the response schema. if we have no partitions to return, then we cannot return any errors either. this is fine for most cases because we should already know if the group exists or not. however, there are (at least) two problematic edge cases: 1. the case i mentioned above. to use the offsetfetch api, we must first lookup the coordinator for the group. it could happen that when we do so, we happen to get a stale coordinator. this is possible because it takes some time for metadata changes to propagate to all the brokers. 2. when the coordinator first is started, it must read through the `__consumer_offsets` topic to populate the offset cache. usually we return a `coordinator_not_available` error in this situation which lets the consumer know it needs to retry a bit later. so if we happen to send an offset fetch for all partitions in either of these cases, then we could mistakenly believe that there are no offsets for the group.",0,0.9840905070304871
92674520,2074,vahidhashemian,2016-12-15T18:52:08Z,"thanks for explaining the issue. if i'm not mistaken, the first edge case (stale coordinator) could occur with the current code too ([a link] that leads to [a link]. so the main issue is that with the current protocol we cannot report error codes when there is no partition in the response. to me the options are 1. making further changes to the protocol to address this issue too. 2. rethinking how to solve the problem of kafka-3853 (with another option than proposed in kip-88). 3. accepting that limitation for now and continue with the current solution. is there another option? which option do you recommend we take?",1,0.785826563835144
92679066,2074,vahidhashemian,2016-12-15T19:14:10Z,sounds good. i'll refactor the whole block a little bit.,1,0.8157298564910889
92679685,2074,hachikuji,2016-12-15T19:17:13Z,"adding an `error_code` at the top level in the response object seems like the cleanest solution. this error code could be used to communicate group-related errors, which is arguably a bit nicer than writing those errors into all the individual partition data. it's a bit painful to reopen a kip that has passed, but i don't think we can ignore this problem. perhaps send a comment to the kip-88 discussion thread explaining the problem and what you think the best option to fix it is?",-1,0.764539897441864
92680619,2074,vahidhashemian,2016-12-15T19:21:36Z,sounds good. i'll do that. thanks for your feedback and advice.,1,0.975155234336853
92697405,2074,vahidhashemian,2016-12-15T20:51:52Z,one more question before i re-open the kip. the issue doesn't seem to be a side-effect of the suggested protocol change in kip-88 (we are not modifying the response in kip-88) and it would surface whenever there is no partition in the response. do you think it can be addressed in a separate kip? or i am missing something here?,0,0.9804449081420898
92702988,2074,hachikuji,2016-12-15T21:25:16Z,"i think it is a consequence of the changes to the request from this kip though, right? before we would always have at least one partition in the request, so we always had somewhere to pack an error code in the response. now that's no longer true.",0,0.9867664575576782
92706549,2074,vahidhashemian,2016-12-15T21:43:42Z,"ok. i see. thanks. so before, it was guaranteed that whatever partition is in the request will be in the response. with the new protocol we could end up getting back an empty list if the group has no offset data. what about passing an empty array in the request with current protocol? wouldn't this cause the same problem?",0,0.5211029052734375
92707749,2074,hachikuji,2016-12-15T21:50:10Z,"that is true, but the impact is different. if you request offsets for an empty list of partitions, the correct response, regardless of the state of the group or the coordinator, is to return an empty partition list.",0,0.9843946099281311
92710994,2074,vahidhashemian,2016-12-15T22:08:45Z,this makes it clear ( hopefully :) ). thanks a lot. i'll work on that email and updating the kip.,1,0.9960303902626038
92729320,2074,vahidhashemian,2016-12-16T00:21:06Z,"a quick follow-up question: is it possible for the current api to return an offset fetch response with various error codes associated with the partitions? i'm trying to think if we can remove the internal ""error_code"" from the schema. thanks.",1,0.9096337556838989
92730823,2074,hachikuji,2016-12-16T00:35:52Z,"i was wondering about this also. unfortunately, it seems we can't remove the per-partition error code since we do authorization on the topics separately.",-1,0.7016738653182983
92861504,2074,vahidhashemian,2016-12-16T18:30:06Z,"i guess not, since in previous versions it's not possible to pass in a null array. thanks.",1,0.9372225999832153
92876208,2074,vahidhashemian,2016-12-16T19:58:21Z,"sure. i think i'll expose a new method (something like `groupcoordinator.getpartitions(groupid)`), since the partitions have to go through authorization check and, after a quick look, i don't see a clean way of overloading `handlefetchoffsets` for this purpose that fits well with how `kafkaapis.handleoffsetfetchrequest` is implemented. unless we want to refactor that method more extensively.",0,0.9861547350883484
94959538,2074,ijuma,2017-01-06T15:14:34Z,this should be `kafka_0_10_2_iv0`.,0,0.9944102168083191
94994319,2074,vahidhashemian,2017-01-06T18:30:04Z,thanks for catching this. i'll fix it shortly.,1,0.779902994632721
95102027,2074,ewencp,2017-01-09T04:36:55Z,"is this still supposed to be included? it's not in the kip (i can't remember if it existed in a previous version.) if it is supposed to be included, presumably it'd be an override of an interface method from `consumer`?",0,0.9937699437141418
95103021,2074,ewencp,2017-01-09T05:08:34Z,style nit: normally we'd use braces around blocks unless they're a single line,0,0.9895784258842468
95103761,2074,ewencp,2017-01-09T05:30:01Z,"aren't you still missing setting the error code field on the struct in this case though? the pattern that seems to be used elsewhere, e.g. in `metadataresponse`, is to make the constructor that takes the version contain all the fields as arguments as well as the version. then all the decoded fields are kept as member variables and written regardless of whether that version contains them, but only written to the struct conditionally. for example, `metadataresponse` has some code that looks like this in its constructor: [code block] (after having constructed the `struct` with the correct schema). i think if the current code is working, it's just lucking out on `none`'s error code being `0` or something. i wouldn't think it would work as is since the field doesn't have a default value defined.",0,0.9940954446792603
95104096,2074,ewencp,2017-01-09T05:38:53Z,"shouldn't some of these change to remove the topic partition data since the v2 version will just include an empty list in that case? also, might be worth checking in on the patch(es) for [a link] to see how this will be impacted. i'd imagine you actually want to test both versions.",0,0.9917773008346558
95104149,2074,ewencp,2017-01-09T05:40:32Z,"since the is specific to v2+, the constructor used doesn't even really need the `responsedata` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `offsetfetchresponse`.",0,0.9941860437393188
95106780,2074,ewencp,2017-01-09T06:43:47Z,comment can be cleaned up,0,0.9865871071815491
95106900,2074,ewencp,2017-01-09T06:46:14Z,"also, i noticed when reviewing this that `offsetfetchrequest.handleerror` doesn't use the request version when constructing the `offsetfetchresponse`. this seems broken, but even more so now that the format differs between versions. (strictly speaking i think it was already broken and a strict client could have potentially caught the issue.)",0,0.974526047706604
95108544,2074,ewencp,2017-01-09T07:10:51Z,"i think you need to be careful about listing unauthorized topics. if `offsetfetchrequest.isallpartitions()` is `true`, then you shouldn't reveal the existence of unauthorized topics. see `handletopicmetadatarequest` for an example of what i mean.",0,0.9750033617019653
95235045,2074,vahidhashemian,2017-01-09T20:06:14Z,thanks for catching this. this method is not required anymore as it's part of rejected alternatives 1 and 2. i'll remove it.,1,0.8914698958396912
95239706,2074,vahidhashemian,2017-01-09T20:32:26Z,that's fair. i can modify the condition of the `if` block before this `switch` statement to skip building `responsedata` for version 2 and beyond.,0,0.5075600147247314
95273042,2074,vahidhashemian,2017-01-09T23:43:03Z,you're right. i'll try to follow a similar pattern for `offsetfetchresponse` in the next update.,0,0.9693549871444702
95294702,2074,vahidhashemian,2017-01-10T03:25:11Z,"i'll update the expected responses as you suggested. regarding supporting both versions it seems that work would conflict with what is being implemented for kip-97. not sure what's the best way to handle it, wait for that to merge first, or move forward with this as is (assuming the latest api version), and then update as part of or after kip-97.",0,0.9714563488960266
95297660,2074,ewencp,2017-01-10T04:10:35Z,"yeah, tbh i wasn't sure either since i hadn't reviewed those patches yet and wasn't sure of the state. i mentioned this to today as well. his thought was that since [a link] (which is actually only 1 of a couple of patches for kip-97) is quite large, it might make sense to get it merged first. we're pretty sure this is the only kip that will potentially be affected by it. has also taken a pass at that one, so if we merge it and you need guidance on updating the patch, he can probably give direction pretty easily. i just checked and there are some minor merge conflicts, but nothing too crazy, so my guess would be that it'd only be a bit more work to layer on the extra bit of compatibility work.",0,0.8074653148651123
95298064,2074,vahidhashemian,2017-01-10T04:17:08Z,sounds good to me. i'll work on the rest of items you found in the meantime that pr gets merged. then we can revisit this piece.,1,0.837452232837677
95298512,2074,vahidhashemian,2017-01-10T04:24:36Z,another good catch. will try to address this it in the next update.,0,0.8990975618362427
95431126,2074,vahidhashemian,2017-01-10T18:51:35Z,you're right. i'll try to fix this in the next update.,0,0.9259819984436035
95485200,2074,hachikuji,2017-01-10T23:54:00Z,kind of annoying that the response doesn't give us an instance of `errors` directly.,-1,0.9820106625556946
95485372,2074,hachikuji,2017-01-10T23:55:28Z,comment is out of date.,0,0.8860992789268494
95488199,2074,hachikuji,2017-01-11T00:17:09Z,nit: not really sure we need two separate constants even though they are separate fields in the struct.,-1,0.6738003492355347
95488264,2074,hachikuji,2017-01-11T00:17:48Z,perhaps useful to break down which of these are partition errors?,0,0.986884593963623
95489296,2074,hachikuji,2017-01-11T00:26:36Z,"this will be a little annoying to handle when we incorporate the client compatibility kip since we'll have to check for the presence of these errors at both levels. one option might be to enhance the parsing of the response to check for the presence of one of the top-level errors in the partition data. if it is there, we could insert it at the top level as well. currently i think we just put `errors.none` at the top level for old versions.",-1,0.7701437473297119
95491518,2074,hachikuji,2017-01-11T00:45:18Z,"couldn't we push this logic into the response constructor? perhaps if the version is equal to 1, we take the top level error code and insert it into the partition data?",0,0.9947915077209473
95497258,2074,vahidhashemian,2017-01-11T01:40:34Z,i'll add a method to `offsetfetchresponse` that returns the actual `errors` value.,0,0.9920067191123962
95497341,2074,vahidhashemian,2017-01-11T01:41:27Z,no problem. i'll use the same constant.,0,0.8020704984664917
95498385,2074,vahidhashemian,2017-01-11T01:52:46Z,"sure, i also used a constant below this comment to define and use that in the code.",0,0.9894872903823853
95501741,2074,vahidhashemian,2017-01-11T02:24:15Z,sure. and i think it would be safe to insert one top level error in case there are more than one.,0,0.9874666333198547
95650676,2074,vahidhashemian,2017-01-11T19:20:32Z,"i think i'm missing something here. we are already iterating over all partitions here (for version 1) and injecting the proper error code. if we want to do the injection in `offsetfetchresponse` constructor, we need to iteration over them again, which wouldn't be very efficient. could you please clarify? thanks.",1,0.49731770157814026
95652522,2074,hachikuji,2017-01-11T19:29:38Z,"mainly what i'm trying to achieve is keeping version handling logic out of `groupcoordinator` as much as possible. so what i had in mind is a constructor or a factory which accepts a top-level error code and a list of the partitions. in the case of the old version, we take the top-level error code and override the partition-level errors. in the case of the new version, we can ignore the partition data and just return the top-level error code.",0,0.9878026843070984
95659959,2074,vahidhashemian,2017-01-11T20:04:47Z,thanks for clarifying. so the signature of this `groupcoordinator` method would likely need to be modified to return a `offsetfetchresponse` instance.,0,0.5137468576431274
95660614,2074,hachikuji,2017-01-11T20:07:41Z,true. i'm not sure that's better or worse. it doesn't seem too bad given that we already return `offsetfetchresponse.partitiondata` though.,-1,0.5586084127426147
95669374,2074,vahidhashemian,2017-01-11T20:52:43Z,"yes, the only thing is after building the offset response here we'll have to later add response data for unauthorized topics.",0,0.987368643283844
95672186,2074,hachikuji,2017-01-11T21:08:28Z,"good point... one option that comes to mind is to use exceptions to propagate top-level errors. this would rely on `offsetfetchrequest.geterrorresponse` to build the response. but we don't do that for any of the other coordinator apis, so i'd rather not make this case exceptional. so how about this: in addition to returning the top-level error code directly in the tuple, we also use it to fill the partition-level error code. then we don't need to pass the version into `groupcoordinator` at all and we can let the handler in `kafkaapis` decide how to do the serialization. basically if the top-level error code is not none, then ignore the partitions.",0,0.8522933125495911
95672359,2074,hachikuji,2017-01-11T21:09:24Z,can we use `errors` instead of `short` in the return type?,0,0.9947291016578674
95673432,2074,hachikuji,2017-01-11T21:15:04Z,"or perhaps even simpler: we could always return the error code and an empty map, and we could let `kafkaapis` expand the error code into the partition data when required by the fetch version?",0,0.9951370358467102
95677478,2074,vahidhashemian,2017-01-11T21:36:08Z,thanks. i also like your last suggestion.,1,0.980342447757721
95700427,2074,hachikuji,2017-01-11T23:58:36Z,could we just use `errors` throughout? you can always get the code from `errors` if you really need it.,0,0.9925668239593506
95719434,2074,hachikuji,2017-01-12T03:17:37Z,i wonder if we ought to just assume that the error goes at the top-level. it's a little weird to receive a partition-specific error code here and then assume that it should be used for _all_ partitions.,-1,0.9776041507720947
95719458,2074,hachikuji,2017-01-12T03:18:01Z,"this is `errorcodethrown`, right?",0,0.9907523393630981
95719646,2074,hachikuji,2017-01-12T03:20:34Z,maybe we can remove this and force the use of `error()`?,0,0.9944444298744202
95721130,2074,hachikuji,2017-01-12T03:43:01Z,nit: braces for multi-line branches,0,0.9784700870513916
95721250,2074,hachikuji,2017-01-12T03:43:54Z,nit: i think this could be replaced by `offsets.get(topicpartition).map(_.offset)`,0,0.9899829626083374
95721791,2074,hachikuji,2017-01-12T03:51:41Z,nit: right-hand side could be replaced by `new topicandpartition(offset._1)`,0,0.993248462677002
95722080,2074,hachikuji,2017-01-12T03:56:23Z,"a little easier to follow this if you deconstruct the tuple (i.e. use `case (topicpartition, partitiondata)`.",0,0.9929912090301514
95722163,2074,hachikuji,2017-01-12T03:57:36Z,"where do we check errors in the response? if we push the error checking into `listgroupoffsets`, maybe this api could return `map[topicpartition, long]` as you would probably expect.",0,0.9951702952384949
95722389,2074,hachikuji,2017-01-12T04:00:57Z,same as comment above: maybe we always treat this as a top-level error?,0,0.9945709109306335
95722449,2074,hachikuji,2017-01-12T04:01:54Z,nit: the `case` is unneeded.,0,0.9386289715766907
95722624,2074,hachikuji,2017-01-12T04:04:27Z,"nit: slightly more natural if `errors` is the first entry? also, we don't need `apiversion` anymore, right?",0,0.9878413081169128
95722933,2074,hachikuji,2017-01-12T04:08:46Z,we need to synchronize on the group to access its state.,0,0.9901620149612427
95723097,2074,hachikuji,2017-01-12T04:10:06Z,not sure about the name. how about `partitionswithcachedoffsets`?,0,0.9386854767799377
95723245,2074,hachikuji,2017-01-12T04:12:45Z,"alternatively, we could allow `handlefetchoffsets` to return all offsets for the group, and we could filter out the partitions that the principal is not authorized to access. that seems a little bit better than exposing a new method in `groupcoordinator`.",0,0.9944349527359009
95723440,2074,hachikuji,2017-01-12T04:15:42Z,"if there should be a member, perhaps we should assert it?",0,0.9930956959724426
95723511,2074,hachikuji,2017-01-12T04:17:00Z,"nit: easy to miss the `&&` with this alignment. perhaps this could go on the previous line? also we can use `contains`. for example: `state.contains(""dead"")` instead of `state == some(""dead"")`.",0,0.9784992933273315
95723657,2074,hachikuji,2017-01-12T04:19:41Z,nit: replace with `contains`,0,0.9928966164588928
95723677,2074,hachikuji,2017-01-12T04:20:05Z,nit: we could use `count` here.,0,0.9922531247138977
95723736,2074,hachikuji,2017-01-12T04:21:01Z,maybe this should be in a `finally`? similar below,0,0.9915550351142883
95724623,2074,hachikuji,2017-01-12T04:36:09Z,"you can use `==` instead of `equals` for all of these. as it is, intellij is complaining that the types are unrelated.",0,0.9348025918006897
95725601,2074,hachikuji,2017-01-12T04:54:05Z,nit: pretty sure we shouldn't need this if we're throwing an exception above. more of these below.,0,0.9250133037567139
95847224,2074,vahidhashemian,2017-01-12T17:55:09Z,so you mean if there is a top-level error code it should not be partition error? i'm okay with that. in that case the second check on this line would be redundant. please advise if i misunderstood. thanks.,1,0.9676145911216736
95849478,2074,vahidhashemian,2017-01-12T18:06:20Z,and perhaps later we should remove this method from other `response` classes.,0,0.9929595589637756
95854631,2074,vahidhashemian,2017-01-12T18:32:55Z,sounds good. i had missed the error check after the latest api change. thanks.,1,0.9927853345870972
95855842,2074,hachikuji,2017-01-12T18:39:06Z,"haha, i'm not sure whether we're saying the same thing. my suggestion was to blindly treat the exception as a top-level error. in other words, take the error code from the exception and use it as the top-level error code for new versions, and as the partition-level error code for old versions.",0,0.6495034098625183
95855851,2074,vahidhashemian,2017-01-12T18:39:08Z,"right, and with the change to return type of `listgroupoffsets` this will become `offsets.get(topicpatition)`. thanks.",1,0.6799507737159729
95859684,2074,hachikuji,2017-01-12T18:57:39Z,definitely. this is one of my favorite gripes. using more specific types whenever possible allows the compiler to do more work for us.,1,0.9201013445854187
95869619,2074,vahidhashemian,2017-01-12T19:45:04Z,so even the older versions will have an error code at the top level? this would change it to [code block],0,0.9949530959129333
95875608,2074,vahidhashemian,2017-01-12T20:17:31Z,"sure, this is a better approach. thanks.",1,0.9121367335319519
95886293,2074,vahidhashemian,2017-01-12T21:16:06Z,`contains` seems to be not supported in scala 2.10. and builds are failing locally for me because of that. don't we still support 2.10? is there a way to get around it?,0,0.7923425436019897
95891116,2074,vahidhashemian,2017-01-12T21:41:53Z,"sure, i'm using eclipse and it doesn't complain about `equals`.",0,0.9495245814323425
95912504,2074,hachikuji,2017-01-12T23:54:49Z,don't worry about it if it's not supported.,0,0.5152056217193604
95913606,2074,vahidhashemian,2017-01-13T00:04:00Z,"well, this actually breaks the unit test, because we don't want to run the `try` block only once. we want to keep trying until the group stabilizes. if we move the `close` to `finally` we close the command after the first try and run into an error on the next try.",0,0.7753696441650391
95937690,2074,vahidhashemian,2017-01-13T04:51:32Z,"so if we want to just check the top level error for any error in the response for partition level errors we lose the specific partitions that are erroneous. also, if there are different partition level error types present we'll report only one. this just limits the error reporting but shouldn't affect the functionality. i hope i did not misunderstand your point.",0,0.8615491986274719
95937720,2074,vahidhashemian,2017-01-13T04:52:12Z,"also, do you happen to know why out of the 5 possible errors we just check only 3 here?",0,0.990382730960846
95938741,2074,hachikuji,2017-01-13T05:09:43Z,maybe we should enforce a minimum version number when querying all partitions? you can look at `listoffsetrequest` for an example of this.,0,0.9940371513366699
95939088,2074,hachikuji,2017-01-13T05:16:00Z,nit: add a space before the `:`.,0,0.9885234236717224
95939338,2074,hachikuji,2017-01-13T05:20:11Z,wonder if there's any harm retaining the top-level error regardless of the version. seems more consistent with how we handle the case of constructing from a `struct`.,0,0.9489936232566833
95939575,2074,hachikuji,2017-01-13T05:23:09Z,probably worth a comment explaining why we do this.,0,0.977178692817688
95939801,2074,hachikuji,2017-01-13T05:25:39Z,"related to above comment. this method only makes sense for version 2, so maybe we should remove `version` and use 2 directly.",0,0.9946702122688293
95939909,2074,hachikuji,2017-01-13T05:27:50Z,do we need to check the partition errors also?,0,0.9935542345046997
95939988,2074,hachikuji,2017-01-13T05:29:04Z,nit: space after comma.,0,0.9043383598327637
95940177,2074,hachikuji,2017-01-13T05:31:54Z,you could also use `new topicandpartition(topicpartition)`,0,0.9934448003768921
95940449,2074,hachikuji,2017-01-13T05:36:09Z,"instead of using `null` as the sentinel, we could use an `option`.",0,0.9925825595855713
95940542,2074,hachikuji,2017-01-13T05:37:41Z,another option would be to push the handling of all offsets into `getoffsets`. one small advantage is that you would only need to acquire the lock once instead of twice.,0,0.9922798871994019
95942547,2074,hachikuji,2017-01-13T06:11:25Z,you could do these assignments at once: [code block] we use this pattern just below.,0,0.9897117614746094
95942666,2074,hachikuji,2017-01-13T06:13:31Z,"seems like this and the other call to `handlefetchoffsets` below needs to go to the `else` case after the check for version 0. for version 0, we pull offsets from zookeeper. i'm wondering if your first approach, which collected all partitions from the coordinator first, may have been a little cleaner. another option to consider, perhaps you could do the post-filtering for the `isallpartitions` case separately, and continue doing pre-filtering when we are provided the partition list.",0,0.9913621544837952
95942941,2074,hachikuji,2017-01-13T06:17:07Z,"i was thinking we could handle both of these cases in the same constructor. the constructor would take a single error code and the list of requested partitions. if the version is greater than or equal to 2, the partitions are ignored; otherwise, the error code is written into the partition errors.",0,0.9903749823570251
96034941,2074,vahidhashemian,2017-01-13T17:25:50Z,i think it should be okay to do that. will update.,0,0.9140802621841431
96036429,2074,vahidhashemian,2017-01-13T17:34:41Z,will there be any partition error? in the case of all offsets unauthorized partitions are excluded and there won't be any unknown topic partition. do you think we should throw an exception if there is any?,0,0.9857843518257141
96042948,2074,hachikuji,2017-01-13T18:12:16Z,seems safer (and more future-proof) to check and throw an exception.,0,0.9852707386016846
96043181,2074,vahidhashemian,2017-01-13T18:13:33Z,great idea because `getoffsets` already gives us what we want ([a link].,1,0.9242249727249146
96057467,2074,vahidhashemian,2017-01-13T19:29:20Z,good idea. thanks.,1,0.9934762120246887
96058029,2074,vahidhashemian,2017-01-13T19:32:19Z,"would it also work if one assignment depends on the other one? `partitions` uses `groupoffsets`. also, it may not read easily since there is a big type definition for `groupoffsets`.",0,0.9937066435813904
96059742,2074,hachikuji,2017-01-13T19:40:46Z,does type inference not work? i was thinking something like this: [code block],0,0.9472489953041077
96060015,2074,hachikuji,2017-01-13T19:42:08Z,nit: unneeded parenthesis.,0,0.5482472777366638
96062247,2074,vahidhashemian,2017-01-13T19:53:46Z,"yes, it works perfectly. sorry for the premature question!",-1,0.9925887584686279
96085672,2074,vahidhashemian,2017-01-13T22:21:35Z,still not too sure about this. did you want to move this error check up in the first `if` block?,0,0.5528271198272705
96088422,2074,hachikuji,2017-01-13T22:41:45Z,i'm not sure i see the problem. would we ever see this at the top level?,-1,0.809382438659668
96089207,2074,hachikuji,2017-01-13T22:46:58Z,"actually i guess we could make this a little simpler. we know we need version 2, so maybe we can use it directly and remove `minversion`?",0,0.9902395009994507
96089229,2074,vahidhashemian,2017-01-13T22:47:07Z,"i'm referring to [a link], and i'm not sure if it implied modifying this method too.",0,0.8764669299125671
96089343,2074,vahidhashemian,2017-01-13T22:48:03Z,"sure, i thought about it too, but thought to keep it in sync with `listoffsetrequest`. i'll update.",0,0.9889532327651978
96090049,2074,hachikuji,2017-01-13T22:53:44Z,"i was mainly concerned that we'd need to check errors in both places, but i think we're good now since we ensure that top-level error codes will always appear at the top level (even for older versions).",0,0.8286395072937012
96090198,2074,hachikuji,2017-01-13T22:54:55Z,"yeah, we're still feeling out the best patterns for handling older versions.",-1,0.7426343560218811
96090442,2074,vahidhashemian,2017-01-13T22:56:45Z,"great, thanks for clarifying.",1,0.9897940158843994
96091324,2074,hachikuji,2017-01-13T23:04:02Z,could we mention that we do this so that the client can depend on the top-level error code regardless of the offset fetch version?,0,0.9940351843833923
96091481,2074,hachikuji,2017-01-13T23:05:30Z,do we need another field if the errors are already contained in `partitiondata`?,0,0.995036780834198
96092241,2074,hachikuji,2017-01-13T23:10:41Z,"talked to about this, and i don't think we need to bump the internal version number since the brokers do not use offset fetches themselves.",0,0.976409912109375
96092616,2074,vahidhashemian,2017-01-13T23:13:53Z,i added this to keep track of partition errors that is needed by `adminclient` [a link]. unless it's okay to process `partitiondata` on the fly?,0,0.9941281080245972
96092684,2074,vahidhashemian,2017-01-13T23:14:22Z,sounds good. i'll remove the internal version.,1,0.7352470755577087
96092918,2074,hachikuji,2017-01-13T23:16:39Z,"seems just as efficient to me, especially since we only throw the first error.",0,0.8464471697807312
96093935,2074,vahidhashemian,2017-01-13T23:24:50Z,"sure, then i think we perhaps need to at least have another `errors` member for that first partition error. so we don't have to process `partitiondata` multiple times for checking the existence and actually retrieving the error (in `haspartitionerrors` and `partitionerrors`).",0,0.9930908679962158
96094359,2074,hachikuji,2017-01-13T23:28:38Z,"i think this is close, but it's a bit annoying that we have to call `handlefetchoffsets` in two places, right? wouldn't it be better to delay the check for `isallpartitions` and the filtering until after the call to `handlefetchoffsets` below. that gives us a clean separation of the kafka and zookeeper offset handling. so maybe the logic can be something like this: 1. filter unauthorized partitions 2. check if this is version 0 a. fetch from zk for version 0 b. check from kafka for versions 1 and above. after receiving the fetched offsets, check if `isallpartitions` is set. if so, additionally filter out the fetched offsets for topics we are not authorized for. does that make sense?",-1,0.9073401093482971
96094652,2074,hachikuji,2017-01-13T23:31:17Z,hmm.. it just doesn't seem worth optimizing for. processing the partition data means what? looping over it and checking if error is none? does it matter if we do that twice? we could also just leave off the `haspartitionerrors` and do a single iteration and raise the error on the first exception.,-1,0.5575945377349854
96095174,2074,vahidhashemian,2017-01-13T23:36:50Z,would something like this work? [code block],0,0.9886420369148254
96095469,2074,hachikuji,2017-01-13T23:40:03Z,"sure, that would work. maybe `getfirstpartitionerror` is a clearer name? or you could bundle the exception throwing as well into a single `maybethrowfirstpartitionerror`? either way is fine with me, but i'd prefer not to additional fields without a clear case that they're needed.",0,0.9858470559120178
96096333,2074,vahidhashemian,2017-01-13T23:48:54Z,"if i understand this correctly, for version 1 and above, to receive the fetched offsets we already need to check `isallpartitions` to determine if `none` or `some(partitions)` should be passed to `handlefetchoffsets`.",0,0.9937806725502014
96096521,2074,hachikuji,2017-01-13T23:50:38Z,"yeah, that's fair. the point is that it should happen in the kafka branch of that `if` and not before.",0,0.6348565816879272
96097187,2074,vahidhashemian,2017-01-13T23:58:29Z,i think we need to call `isallpartitions` upfront anyway because we need to make sure `offsetfetchrequest.partitions` is not null before starting to filter.,0,0.9904616475105286
96097302,2074,hachikuji,2017-01-13T23:59:40Z,ack,0,0.8596508502960205
96099907,2074,vahidhashemian,2017-01-14T00:28:49Z,i hope this is now closer to what you described.,0,0.7657142877578735
138698389,3849,becketqin,2017-09-13T18:15:47Z,it seems better to say producer.send() instead of send.,0,0.9920775294303894
138699047,3849,becketqin,2017-09-13T18:18:06Z,we are passing `now` everywhere else. maybe we can just keep the argument name the same.,0,0.986336350440979
138726608,3849,tedyu,2017-09-13T20:14:46Z,should <= be used ?,0,0.9921808242797852
138726989,3849,tedyu,2017-09-13T20:16:27Z,deliverytimeoutms should be mentioned,0,0.9888628721237183
138787782,3849,becketqin,2017-09-14T03:06:17Z,should we validate the delivery.timeout.ms is greater than request.timeout.ms?,0,0.9942662119865417
138789918,3849,becketqin,2017-09-14T03:31:27Z,it is probably cleaner to have an explicit `expired` state.,0,0.9921547770500183
138791125,3849,becketqin,2017-09-14T03:46:07Z,"the logic here probably needs more comments. we may have the following three cases that the state of a batch has been updated before the produceresponse returns: 1. a transaction abortion happens. the state of the batches would have been updated to `aborted`. 2. the producer is closed forcefully. the state of the batches would have been updated to `aborted`. 3. the batch is expired when it is in-flight. the state of the batch would have been updated to `expired`. in the other cases, we should throw illegalstateexception.",0,0.9884318709373474
138791482,3849,becketqin,2017-09-14T03:50:16Z,"the batches still needs to be expired in order if `max.in.flight.requests.per.connection` is set to 1. so we probably still want to check if the partition is muted or not. that said, if we guarantee that when `recordaccumulator.expiredbatches()` returns non-empty list, all the earlier batches have already been expired, we can remove the muted check here. btw, i did not see the logic of expiring an in-flight batch in the current patch. am i missing something?",0,0.9900875687599182
138791524,3849,becketqin,2017-09-14T03:50:53Z,isfull is no longer used.,0,0.9738633632659912
138977901,3849,sutambe,2017-09-14T18:40:05Z,agreed,0,0.9622275233268738
139014083,3849,sutambe,2017-09-14T21:19:24Z,"the actual argument is `now`. however, i like the formal argument name to be `createtime` because it's an immutable value while constructing a batch. `now`, is by definition, changing.",0,0.9877568483352661
139014648,3849,sutambe,2017-09-14T21:22:07Z,i did some digging around. an expired batch's final state is `failed`. i don't feel great about adding yet another `finalstate`. we already have `aborted` and `failed`. the `producerbatch.done` will get even more complicated.,-1,0.7664315700531006
139246402,3849,sutambe,2017-09-15T20:45:56Z,please review the updated method documentation.,0,0.9836147427558899
139768240,3849,tedyu,2017-09-19T17:53:22Z,this variable can be dropped.,0,0.983862578868866
139842619,3849,tedyu,2017-09-19T23:24:22Z,in not -> is not,0,0.8711827397346497
139843016,3849,tedyu,2017-09-19T23:27:37Z,the check 'if (deliverytimeoutms <= (now - this.createdms))' inside maybeexpire() would be true. looks like another method can be created inside producerbatch which expires the batch.,0,0.9945687055587769
139851577,3849,sutambe,2017-09-20T00:34:32Z,`maybeexpire` has a side-effect of setting `errormessage` internally. hence calling it again in `if`.,0,0.9915968775749207
139852241,3849,tedyu,2017-09-20T00:40:18Z,understand. that part can be refactored - goal is to reduce unnecessary comparison.,0,0.9907045960426331
139852661,3849,sutambe,2017-09-20T00:43:47Z,those test don't even compile or run on my machine. what's up with those tests?,0,0.647663950920105
139853479,3849,apurvam,2017-09-20T00:51:42Z,they can't construct a kafka producer with the changes made in this pr.,0,0.9662906527519226
139871039,3849,becketqin,2017-09-20T04:01:43Z,is this comment accurate? the new state is not necessarily succeeded.,0,0.985625684261322
139871499,3849,becketqin,2017-09-20T04:04:58Z,"maybe it's not a big deal but just want to call out that this is a behavior change. currently the producer will throw exception when transition from failed state to another state due to some reason other than expiration. if we change this logic, we may miss those cases which are not failed by expiration but still got state update twice. it may not be that important if we do not have programming bugs. personally i think it is better to clearly define the states of the batches even if additional complexity is necessary. the comments should probably also cover the force close case for completeness.",0,0.968910813331604
139873674,3849,becketqin,2017-09-20T04:33:40Z,"some typos in this comments. ""expire the batch if no outcome is known within delivery.timeout.ms""",0,0.9710285663604736
139874459,3849,becketqin,2017-09-20T04:44:01Z,does this have to be a per partition map? intuitively we just need a `treeset ` with a comparator?,0,0.9917705059051514
139874583,3849,becketqin,2017-09-20T04:45:39Z,"assuming `nflightbatches` is a treeset suggested above, this code can be simplified to: [code block]",0,0.994404673576355
139874633,3849,becketqin,2017-09-20T04:46:09Z,`tp` is not used anymore.,0,0.9845669865608215
139874861,3849,becketqin,2017-09-20T04:49:12Z,no longer used.,0,0.9473962187767029
139874980,3849,becketqin,2017-09-20T04:50:43Z,this logic would become `inflightrequests.remove(batch)` when a `treeset` is used for this.,0,0.9950289130210876
139875140,3849,becketqin,2017-09-20T04:52:44Z,this would be just `inflightbatches.add(batch)`,0,0.9941642880439758
139875288,3849,becketqin,2017-09-20T04:54:13Z,we usually just use `earliestdeliverytimeout` in kafka.,0,0.9938947558403015
139875598,3849,becketqin,2017-09-20T04:58:47Z,it seems we don't need the `deliverytimeoutms` in the sender. it is only used as an argument passed to the accumulator. but the accumulator already has the config.,0,0.9946808218955994
139876175,3849,becketqin,2017-09-20T05:06:51Z,it seems an existing issue. when we expire the batches here. the memory of those batches will be deallocated. it seems that we will deallocate the same batch again when the produceresponse returns?,0,0.9281538128852844
140056222,3849,becketqin,2017-09-20T18:37:07Z,"apparently the my understanding of `treeset` is not accurate. it uses the comparator to decide whether the entries are the same or not. we can use a treemap > then. we may also want to bucket the timestamp a little bit, say one second to avoid huge amount of sets created for each ms in the `treemap`.",0,0.9846929311752319
140087965,3849,tedyu,2017-09-20T20:45:59Z,"i was thinking about this too. using millisecond as unit for map key is not prudent. after the switch to second as unit, we may need to check the two adjacent buckets keyed by ts-1 (sec) and ts+1 (sec).",0,0.8089562654495239
140133571,3849,becketqin,2017-09-21T01:50:36Z,this test has nothing to do with linger.ms anymore...,0,0.941789984703064
140133681,3849,becketqin,2017-09-21T01:51:43Z,similar to above we should rename this.,0,0.991216778755188
140133773,3849,becketqin,2017-09-21T01:52:35Z,typo: timeout,0,0.9553384184837341
140133809,3849,becketqin,2017-09-21T01:53:02Z,typo: timeout,0,0.9553384184837341
140136188,3849,becketqin,2017-09-21T02:19:02Z,"should we still expire the batches when they are expired instead of expiring all the bucket? having a second granularity bucket does not prevent us from doing that, right?",0,0.9829330444335938
140303384,3849,sutambe,2017-09-21T17:11:05Z,"as we discussed, `treeset` does not cut it. the naming is consistent. a `treeset` is a set. it's just that equality criterion is different.",0,0.9852005243301392
140304267,3849,sutambe,2017-09-21T17:14:47Z,it's there now,0,0.9798941016197205
140367934,3849,hachikuji,2017-09-21T21:47:38Z,"hmm.. might not be too important, but it doesn't seem necessary to include the retry backoff in this check. if the user sets retries=0, then the backoff shouldn't matter.",0,0.8598453402519226
140370206,3849,hachikuji,2017-09-21T21:58:50Z,"we are using the creation time of the batch to check for expiration. that will tend to expire some records which were added to the batch after creation earlier than the delivery timeout (by as much as linger.ms). alternatively, we could use the time that the batch was closed, which will tend to expire records later than the delivery timeout (by as much as linger.ms), but maybe expiring late is bit safer than expiring early? this is equivalent to saying that the delivery timeout excludes linger time.",0,0.9901865720748901
140371334,3849,hachikuji,2017-09-21T22:05:06Z,"checking my understanding. with this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. if so, do we still need the logic to abort appends on expiration? (it might be safer to have it anyway, just checking if it is still needed for correctness)",0,0.9921663999557495
140373989,3849,hachikuji,2017-09-21T22:21:29Z,"after we reset `earliestdeliverytimeoutms`, it seems that we do not take into account the expiration times of in-flight batches.",0,0.9934344291687012
140375038,3849,hachikuji,2017-09-21T22:29:00Z,do we have any microbenchmarks that show this (potential) optimization is justified?,0,0.9932623505592346
140377235,3849,hachikuji,2017-09-21T22:44:15Z,why do we need this check? a comment would be helpful.,0,0.9730907678604126
140392052,3849,sutambe,2017-09-22T00:47:58Z,batch close may be arbitrrily delayed in some cases. see 's explanation: [a link],0,0.987165629863739
140394635,3849,sutambe,2017-09-22T01:16:46Z,fixed. take a look.,0,0.9660331606864929
140395587,3849,sutambe,2017-09-22T01:26:49Z,`recordaccumulator.maybeupdateearliestdeliverytimeout`,0,0.9948622584342957
140560836,3849,apurvam,2017-09-22T18:10:06Z,"shouldn't we also be removing the batches from the inflight set when the batch is completed (failed or successfully)? i might be missing something, but i don't see that code here.",0,0.9791772961616516
140571976,3849,sutambe,2017-09-22T18:59:40Z,"right. cleanup of `soontoexpireinflightbatches` happens in two places (1) if a batch gets reenqueued and (2) when `sender` looks for `expiredbatches`. in the second case, we cleanup the batches whose final state is known (success or failure) and there by ""removing"" them.",0,0.9947070479393005
140590998,3849,hachikuji,2017-09-22T20:35:40Z,"as far as i can tell, it shouldn't be possible to abort a batch after it has been completed. is this correct? if so, i think it might be better to continue to raise `illegalstateexception`. it's preferable to keep the allowable state transitions as narrowly defined as possible since it ensures faster failure for unexpected paths.",0,0.986877977848053
140591599,3849,hachikuji,2017-09-22T20:38:58Z,this is still not used,0,0.9182710647583008
140591635,3849,hachikuji,2017-09-22T20:39:10Z,still not used,0,0.8395108580589294
140592411,3849,hachikuji,2017-09-22T20:43:10Z,"nit: ""for quick **access** to the oldest batch""?",0,0.9790118336677551
140594775,3849,hachikuji,2017-09-22T20:55:31Z,"if you are not implementing this, can you please remove it?",0,0.9913700819015503
140596621,3849,hachikuji,2017-09-22T21:05:43Z,the name is a little misleading given its proximity to similarly named fields. maybe something like `nextexpirationtimestampms` would be clearer?,0,0.9599810242652893
140597138,3849,hachikuji,2017-09-22T21:08:29Z,thanks. i synced with jun and it seems reasonable. it would help to document somewhere why we use create time.,1,0.9885748028755188
140603555,3849,hachikuji,2017-09-22T21:45:41Z,i think the answer to this question is that it is possible to expire while the batch is still being built because closing the batch can be arbitrarily delayed by inflight fetches.,0,0.9840332865715027
140604152,3849,hachikuji,2017-09-22T21:49:42Z,please respond to this. is it necessary to include retry_backoff in this check?,0,0.9887738227844238
140604457,3849,hachikuji,2017-09-22T21:51:32Z,do we want to mention the other case where a record is expired early because it was added to a batch which was already nearing expiration?,0,0.9913526177406311
140606225,3849,hachikuji,2017-09-22T22:04:24Z,"the logic for updating this field seems to assume that the batch at the front of the deque will always be the next to expire, but i'm not sure that is true in the case of retries.",0,0.9756007194519043
140608227,3849,hachikuji,2017-09-22T22:21:05Z,"to be honest, this lazy expiration seems like overkill. it should be a rare case where we actually have entries in `soontoexpireinflightbatches` because of the other optimization to only add to it when the delivery timeout will expire prior to the request timeout. and if the producer is in a situation where batches are being expired, then the performance of removal for a particular batch is probably not a major concern. maybe some benchmarking would show whether it is a worthwhile optimization.",0,0.975409984588623
140608868,3849,hachikuji,2017-09-22T22:26:51Z,inadvertent commit i assume.,0,0.9104030132293701
140609030,3849,hachikuji,2017-09-22T22:28:14Z,"if we're just returning `true` for `matches`, we don't need to provide a `requestmatcher` at all.",0,0.9930158853530884
140614799,3849,sutambe,2017-09-22T23:24:16Z,i think `retrybackoff` can be dropped. perhaps we can do two tests based on whether `retries` is set or not.,0,0.9928841590881348
140617891,3849,tedyu,2017-09-22T23:59:57Z,i don't see bucketing,0,0.7614823579788208
140619943,3849,becketqin,2017-09-23T00:30:02Z,"i agree in most case we probably do not need this. it is probably only useful for large producers (e.g. mirror maker which has thousands of partitions to send). there may still be value to have this: 1. since delivery.timeout.ms and request.timeout.ms are both user configurations. it would be good to guard against some configurations. (e.g. request.timeout.ms=delivery.timeout.ms, linger.ms=0). 2. it seems that in some scenarios this would help. for example, when the brokers are being rolling bounced, there will be a lot of retried batches. those batches may have `remainingdeliverytimeoutms` < `request.timeout.ms`. we may have even more than one batches per partition to insert if max.in.flight.request is greater than 1. a benchmark would be useful. but in general i think it is safer to have this optimization given it does not increase too much complexity.",0,0.9813947677612305
140625298,3849,becketqin,2017-09-23T04:01:04Z,i had a comment earlier that it seems we should still expire the batch at exact createtime + deliverytimeoutms even if we bucket them by seconds.,0,0.9906778335571289
140625337,3849,becketqin,2017-09-23T04:04:48Z,"i agree with that using retry backoff is a little weird here. `retries` means that ""at most retry that many times within delivery.timeout.ms"". so even if `retries` is greater than 0, it does not mean there must be a retry. so we should probably just check the `delivery.tiemout.ms` is at least `linger.ms` + `request.timeout.ms`.",-1,0.5424867868423462
140625355,3849,becketqin,2017-09-23T04:06:58Z,i also think we should mention the scenario that a record is added to a batch that is about to expire.,0,0.9858853816986084
140625458,3849,becketqin,2017-09-23T04:14:29Z,can we update the java doc to explain the return value?,0,0.9937475919723511
140625583,3849,becketqin,2017-09-23T04:24:43Z,personally i still think a clear expired state would be clearer. we can let batch.done() method take a finalstate argument instead of inferring the state from the exception.,0,0.9883756637573242
140625869,3849,becketqin,2017-09-23T04:46:59Z,"good point. it would work if max.in.flight.requests.per.connection=1, or when we enable idempotence. but otherwise the first batch may not be the first to expire. since we do not even have callback order guarantee in that case, maybe it is fine? but we should definitely document this.",0,0.8870349526405334
140626273,3849,becketqin,2017-09-23T05:15:12Z,this test will pass whether line 76 throws illegalstateexception or not. should we add a fail() statement after line 76?,0,0.99359130859375
140626284,3849,becketqin,2017-09-23T05:16:11Z,is this needed? in what case could e be null?,0,0.9875017404556274
140626361,3849,becketqin,2017-09-23T05:21:32Z,we should change the test name to something like testbatchexpiration. and the test below to testbatchexpirationafterreenqueue.,0,0.9949648380279541
140626370,3849,becketqin,2017-09-23T05:22:08Z,the typo is still there.,0,0.9772840142250061
140626470,3849,becketqin,2017-09-23T05:23:40Z,"testsoontoexpire... (upper case ""to"")",0,0.9862217307090759
140626641,3849,becketqin,2017-09-23T05:25:13Z,do you mean it should not be included...,0,0.9656854271888733
140626811,3849,becketqin,2017-09-23T05:38:05Z,typo in the test name.,0,0.988774299621582
140626831,3849,becketqin,2017-09-23T05:39:42Z,request1 and request 2 are not used.,0,0.9864830374717712
140626885,3849,becketqin,2017-09-23T05:43:03Z,should we check the completeness of request1?,0,0.9947388768196106
140626907,3849,becketqin,2017-09-23T05:44:46Z,we may need to call sender.run() one more time to ensure the message is not reenqueued. the reqenqueued message won't be sent out again in the same sender.run().,0,0.9869001507759094
140646338,3849,tedyu,2017-09-24T03:32:38Z,createtime -> creationtime,0,0.9864577651023865
140646367,3849,tedyu,2017-09-24T03:35:40Z,nit: 'else' can be dropped,0,0.9887048602104187
140671368,3849,sutambe,2017-09-24T23:48:00Z,restored the test as it was before.,0,0.9816243052482605
140864460,3849,sutambe,2017-09-25T18:47:43Z,just added a test to ensure that we don't do double deallocation. `sendertest.testnodoubledeallocation`,0,0.9945414662361145
140880631,3849,sutambe,2017-09-25T19:55:16Z,the batch is expired at exact time but not removed from the `soontoexpireinflightbatches`. based on some earlier comments grouping them to avoid pointer chasing?,0,0.9946231842041016
140881985,3849,becketqin,2017-09-25T20:00:59Z,"this method either throw exception or return true, which indicates there is no need to have a return value.",0,0.989349365234375
140884890,3849,apurvam,2017-09-25T20:13:30Z,"hmm. this seems a bit off. what this means that in the 'normal' case when responses are successful and there is no backlog in the accumulator, we will hang on to batches (and not garbage collect them) until the delivery timeout. indeed, if you add the following at the end of sender tests where there are no more inflight requests (ie. all requests have completed and will never be retried) ` asserttrue(accumulator.soontoexpireinflightbatches().isempty());` all the tests fail. i think this should be fixed. we should clear the `soontoexpireinflightbatches` as soon as the batch is completely resolved (ie. failed or completed) so that we don't hang on to the reference unnecessarily.",0,0.6266871094703674
140888794,3849,sutambe,2017-09-25T20:29:28Z,added the muted check back,0,0.9898532032966614
140910557,3849,becketqin,2017-09-25T22:00:14Z,the method never returns false. we can keep it as void if so.,0,0.9839532971382141
140914352,3849,becketqin,2017-09-25T22:20:07Z,should probably add an expire case?,0,0.9924546480178833
140918001,3849,becketqin,2017-09-25T22:41:20Z,the map is not used.,0,0.9664052128791809
140918233,3849,becketqin,2017-09-25T22:42:40Z,should we assert the pool is not deallocated after the expiration but before the response returns?,0,0.9931595325469971
140918761,3849,becketqin,2017-09-25T22:46:05Z,how could the order be violated if we only append the first batch after the first one is expired?,0,0.9864353537559509
140919067,3849,becketqin,2017-09-25T22:47:55Z,the map is not used.,0,0.9664052128791809
140919353,3849,becketqin,2017-09-25T22:49:39Z,nit: can we avoid reusing the argument name?,0,0.9896418452262878
140927438,3849,becketqin,2017-09-25T23:46:36Z,"actually, it seems we may release the memory before the the response returns?",0,0.9925317168235779
140928325,3849,apurvam,2017-09-25T23:53:15Z,"as i mentioned in my other comment, the memory utilization itself is not the issue as much as the fact that we are retaining the reference to `producerbatch` for at least `deliverytimeoutms`. this probably won't cause too much memory pressure, but is still an undesirable behavior.",0,0.981564462184906
140935275,3849,becketqin,2017-09-26T00:53:48Z,"got it. good catch. yes, we should remove the completed batch.",1,0.9309185147285461
142276754,3849,sutambe,2017-10-02T22:55:37Z,return type restored to `void`,0,0.9906975626945496
142484042,3849,sutambe,2017-10-03T18:29:10Z,can some please clarify what suggestion is made here? remove completed batch from where?,0,0.9917004704475403
150616359,3849,sutambe,2017-11-13T17:56:25Z,fixed the test,0,0.985722541809082
151183810,3849,sutambe,2017-11-15T16:45:17Z,the new code seems to deallocate the batch right away. i'm not changing the behavior for now.,0,0.9236709475517273
151194892,3849,sutambe,2017-11-15T17:21:41Z,added,0,0.9267084002494812
151195752,3849,sutambe,2017-11-15T17:24:58Z,right,0,0.8996442556381226
151571211,3849,becketqin,2017-11-16T23:56:46Z,`verifyandgetdeliverytimeout()`?,0,0.994407057762146
151572566,3849,becketqin,2017-11-17T00:06:55Z,this check is a little flaky. what if deliverytimeoutms is `long.max_value - 1`?,-1,0.9397762417793274
159586946,3849,becketqin,2018-01-04T06:27:34Z,still not used.,0,0.8160346150398254
159587416,3849,becketqin,2018-01-04T06:34:00Z,we don't need a priorityqueue for this because the batches in the recordaccumulator is already in order. so we just need to keep the draining order.,0,0.9914148449897766
159587789,3849,becketqin,2018-01-04T06:39:32Z,"if we always insert the batch to the inflightbatches queue and there is no bug, the batch to be removed should always be the first batch. can we assert on that?",0,0.9933837056159973
159588151,3849,becketqin,2018-01-04T06:44:30Z,"the original reason we have this optimization is because we used to have a big sorted data structure. so avoiding inserting elements to it makes sense. given that now the batch order in the recordaccumulator is already guaranteed. it seems we can just put all the drained batches to the inflightbatches queue, which is simpler.",0,0.9866092801094055
159593877,3849,becketqin,2018-01-04T07:41:33Z,the while loop may break if the request size has reached. so there is no guarantee that it will iterate over all the partitions. one alternative is to find the nextbatchexpirytimems in the expirebatches.,0,0.9768312573432922
159594768,3849,becketqin,2018-01-04T07:50:21Z,it seems intuitively this should be the earliest batch in the entire record accumulator?,0,0.9726337194442749
159600209,3849,becketqin,2018-01-04T08:36:38Z,"it seems we may release the memory for the expired batches before the response is returned. this means the underneath bytebuffer is still referred by the producerbatch instance in the inflightrequests. i am not sure if this would cause any problem, but it seems a little dangerous.",-1,0.7599490284919739
159602229,3849,becketqin,2018-01-04T08:50:18Z,is the response preparation needed in this case?,0,0.9946617484092712
67447081,1336,junrao,2016-06-17T00:34:31Z,"reporting both owner and member-id can be a bit confusing. also, for zk based consumer, we get the following output. the member-id part is repeated in the owner part. perhaps instead, we can report 3 fields: member-id, client-id, and client-ip. for kafka-based consumer, we can fill in all 3 fields. for zk-based consumer, we can just fill in member-id. we can leave the client-id and client-ip part empty since that are not stored explicitly. [code block]",0,0.9689531326293945
67447089,1336,junrao,2016-06-17T00:34:33Z,could all those scala.collection.mutable.map be just mutable.map?,0,0.9945908784866333
67447119,1336,junrao,2016-06-17T00:34:51Z,could we rename this to describemembertopicpartitions() to make it clear?,0,0.9951541423797607
67447129,1336,junrao,2016-06-17T00:35:00Z,"in this case, since the member has no associated partitions, do we need to pass in topic at all? could we just pass in none?",0,0.9946680068969727
67566895,1336,vahidhashemian,2016-06-17T19:59:57Z,sure. will do in the next update.,0,0.9911672472953796
67566945,1336,vahidhashemian,2016-06-17T20:00:20Z,"yes, none should work too. will update the pr.",0,0.9686805605888367
67567026,1336,vahidhashemian,2016-06-17T20:00:57Z,i'll make this change too in the next update.,0,0.9831258654594421
67567292,1336,vahidhashemian,2016-06-17T20:03:09Z,"that's fair. i'll update the code to return the output in the format you suggested. i'm thinking of always returning an empty string for client id and ip for zk-based consumer (as you suggested), and returning ""none"" for member id when no active consumer exists for the group.",0,0.657629668712616
67725952,1336,junrao,2016-06-20T17:00:35Z,"it doesn't seem that topic is being used. also, could we fix the indentation?",0,0.9800933003425598
67725986,1336,junrao,2016-06-20T17:00:48Z,"could we change getowner and getownerhost to getclientid and getmemberhost accordingly? also, i am not sure why we getmemberid, getowner and getownerhost need to be a function. could we just pass in an option and get rid of ""get""?",0,0.9875734448432922
67726057,1336,junrao,2016-06-20T17:01:15Z,could we change owner to client-id? could owner-host be member-host since not every member owns a partition?,0,0.9941284656524658
67726065,1336,junrao,2016-06-20T17:01:19Z,"could we change owneropt and ownerhostopt to clientidopt and memberhostopt, respectively?",0,0.9951936602592468
67726085,1336,junrao,2016-06-20T17:01:27Z,"if topicpartition doesn't exist, should we really pass in offsetopt? it seems it's more intuitive to pass in none.",0,0.9880558252334595
67726141,1336,junrao,2016-06-20T17:01:51Z,"not sure why we need to use ephemeral owner here. it seems that topicpartition->owner gives us the mapping from topic partition to group member id directly. consumergroupdir + ""/ids gives us all members. from these two, we know members that don't own any partitions.",0,0.9782111048698425
67726172,1336,junrao,2016-06-20T17:02:03Z,"this is the case for members not owning any topic partitions, right? if so, could we just set topicpartitions and partitionoffsets to empty?",0,0.9939129948616028
67750840,1336,hachikuji,2016-06-20T19:27:44Z,it seems weird to let this function accept `none` for either of these fields (why would i ever try to get the leo if i don't have a topic or a partition?). maybe the function can accept an instance of `topicandpartition` and the caller can make sure they have an instance prior to calling?,-1,0.6488379836082458
67753873,1336,hachikuji,2016-06-20T19:47:38Z,basically the same comment as above: it's weird to have a function `describepartition` where the partition is optional. could we take the logic for handling that case out of this function?,-1,0.9343017935752869
67763714,1336,hachikuji,2016-06-20T20:50:42Z,minor: would it be helpful to echo the group back to the user in quotes (so that formatting errors are apparent)?,0,0.9918707609176636
67780260,1336,vahidhashemian,2016-06-20T22:42:58Z,you're right. i'll remove the `topic` parameter and fix indentation.,0,0.8947999477386475
67780312,1336,vahidhashemian,2016-06-20T22:43:19Z,"sure, i'll update in the next patch.",0,0.990121603012085
67780332,1336,vahidhashemian,2016-06-20T22:43:27Z,sure.,0,0.9664214849472046
67780472,1336,vahidhashemian,2016-06-20T22:44:31Z,"yup, and i'm going to switch the last two parameters so member related parameters are next to each other. i hope that's fine.",1,0.9237253069877625
67780508,1336,vahidhashemian,2016-06-20T22:44:48Z,"right, will change to `none`.",0,0.9862668514251709
67781246,1336,vahidhashemian,2016-06-20T22:51:20Z,"i think i had tried that combination before to extract the info. the issue is when i try `get /consumers/group1/owners/test/0` the output looks like this: `cgroup1_kafka-1466461259713-759adaaa-0`. however, when i try `ls /consumers/group1/ids` the output is like `[cgroup1_kafka-1466462141465-ff19e1a5, cgroup1_kafka-1466461259713-759adaaa]`. it seems the first call returns a client id, and the second one a list of member ids, and that's why the outputs do not quite match (`cgroup1_kafka-1466461259713-759adaaa-0 != cgroup1_kafka-1466461259713-759adaaa`). that's why i did not use this approach as i wasn't sure if there is anything further i can assume to connect the two outputs. if there is, please let me know.",0,0.9936238527297974
67784301,1336,vahidhashemian,2016-06-20T23:18:06Z,that's correct and makes sense. will do.,0,0.7679691314697266
67787649,1336,vahidhashemian,2016-06-20T23:52:01Z,i understand the concern. will make some changes to fix the issue.,0,0.9261959791183472
67787692,1336,vahidhashemian,2016-06-20T23:52:27Z,i'll try to fix this as suggested.,0,0.9779236912727356
67788112,1336,vahidhashemian,2016-06-20T23:56:46Z,that's a good suggestion. will update this one and the one a few lines below to return the group name as part of the output message.,1,0.9387163519859314
71457060,1336,hachikuji,2016-07-20T02:28:50Z,minor: maybe we could just debug log the stack trace?,0,0.986171305179596
71457421,1336,hachikuji,2016-07-20T02:34:23Z,nit: maybe something like `partitionassignmentstate` would be more accurate?,0,0.9911673665046692
71457470,1336,hachikuji,2016-07-20T02:35:35Z,"another small nit: the ""opt"" suffix is kind of annoying. could we drop it?",-1,0.9762406945228577
71457574,1336,hachikuji,2016-07-20T02:37:37Z,maybe we could change this to something like this: [code block] that might make testing easier.,0,0.9909108281135559
71458065,1336,hachikuji,2016-07-20T02:45:11Z,or maybe we keep the current name and just change the argument type since this is `outputwriter`.,0,0.9925919771194458
71458303,1336,hachikuji,2016-07-20T02:49:45Z,i'm wondering if we can collapse these bottom 3 methods into a single `printassignment(assignment: array[consumergroupassignment])`. doesn't seem like we're saving that much with the abstract for loop.,0,0.9688483476638794
71458830,1336,hachikuji,2016-07-20T02:58:36Z,nit: the name `describegroup` no longer seems quite right. maybe `assignmentstate` would be more accurate since that's what the method returns.,0,0.9866076707839966
71459346,1336,hachikuji,2016-07-20T03:07:25Z,maybe `describegroup` could be `collectgroupassignment` and this method could be `collectmemberassignment`?,0,0.9949912428855896
71459524,1336,hachikuji,2016-07-20T03:10:07Z,suggestion: `getalltopicpartitions`?,0,0.9944077730178833
71459607,1336,hachikuji,2016-07-20T03:11:43Z,is this used anywhere?,0,0.989799976348877
71459749,1336,hachikuji,2016-07-20T03:14:11Z,"actually i see that we print some context-specific error messages, so maybe we need to allow the message to come through. but perhaps we could pass the exception in an optional argument so that we can have a common place to log the stacktrace.",0,0.9892874956130981
71580318,1336,vahidhashemian,2016-07-20T18:28:28Z,i believe this is being handled in [a link]. if it's okay i would let it come through that pr. one of the two prs would have to be rebased depending on which one goes in first.,0,0.9832924008369446
71581180,1336,vahidhashemian,2016-07-20T18:32:45Z,both sound good. will update in the next commit.,1,0.6429903507232666
71592461,1336,vahidhashemian,2016-07-20T19:38:48Z,"sure, i'll make necessary changes for this.",0,0.9814048409461975
71592754,1336,vahidhashemian,2016-07-20T19:40:44Z,"that's fair. would it make sense to use `assignments`/`assignments` to imply all assignments, and `assignment`/`assignment` to imply a single assignment row?",1,0.8958685994148254
71593221,1336,vahidhashemian,2016-07-20T19:43:45Z,sure. i was wondering if we should use a `get` prefix (e.g. `getgroupassignment`) to indicate there is some return value. but i don't see that respected as a convention everywhere in the code.,0,0.9847227334976196
71593255,1336,vahidhashemian,2016-07-20T19:43:57Z,sounds good.,1,0.9417163729667664
71593302,1336,vahidhashemian,2016-07-20T19:44:19Z,no. thanks for catching this. will be removed.,1,0.8779916763305664
71604687,1336,hachikuji,2016-07-20T20:54:15Z,not sure i understand the question. i was thinking that a single `printassignment` method could accept the complete assignment for the full group. then printing assignment rows or whatever is just an implementation detail. does that make sense or not?,0,0.8018799424171448
71606434,1336,vahidhashemian,2016-07-20T21:04:26Z,"i agree with merging those three methods. i was just curious about naming convention for the method and the variables used to implement them. maybe [a link] helps, where i use `assignments` as the full list of assignments, and then each individual member is an `assignment`. i thought i could use this convention across the board. this is very minor and not a big deal though if it's confusing.",0,0.5402029752731323
71608339,1336,hachikuji,2016-07-20T21:16:23Z,"ah i see. maybe we could use `groupassignment` and `memberassignment`? as long as it's clear in its context, either way seems ok to me.",0,0.9696546196937561
71609719,1336,vahidhashemian,2016-07-20T21:25:15Z,"yeah, that works too, and would probably be more descriptive. thanks.",1,0.9814267754554749
72295665,1336,hachikuji,2016-07-26T17:19:46Z,"minor: if we use debug(), do we need to extract the stack trace? maybe you could do something like this: [code block]",0,0.9935044050216675
72296396,1336,hachikuji,2016-07-26T17:23:50Z,"it's a little weird to have describe() return the partition state. in the test case below using the mock of `outputwriter`, could you replace the assertions on the result of describe() with `easymock.expect()` assertions?",-1,0.9725273847579956
72317288,1336,hachikuji,2016-07-26T19:14:02Z,seems like the only thing this method is contributing is the computation of lag. maybe we could replace it with a method like this: [code block] what do you think?,0,0.9884024262428284
72317749,1336,hachikuji,2016-07-26T19:16:39Z,"based on the usage below, would `printmessage` be a more accurate name?",0,0.9936161041259766
72318145,1336,hachikuji,2016-07-26T19:19:00Z,would it make sense to default `excludeinternaltopics` to true?,0,0.9947262406349182
72321388,1336,vahidhashemian,2016-07-26T19:37:48Z,"this is what i originally wanted to do, but struggled with how to verify the actual result (what would be printed as a result of `describe()` call) against how i call `easymock.expect(...)`, which is something like `easymock.expect(outputwritermock.printerror(""the consumer group 'missing.group' does not exist""))` for the first unit test (`testdescribenonexistinggroup`). how do i make sure that a call to `consumergroupcommand.describe()` would actually make the call identified in `easymock.expect`?",0,0.9529252648353577
72321525,1336,vahidhashemian,2016-07-26T19:38:35Z,"sure, i'll make this change.",0,0.9730041027069092
72324174,1336,vahidhashemian,2016-07-26T19:53:35Z,"yup, that makes sense.",0,0.8642135262489319
72324734,1336,vahidhashemian,2016-07-26T19:56:57Z,"yes, it would be more appropriate. i'll change it. thanks.",1,0.9760740995407104
72325636,1336,vahidhashemian,2016-07-26T20:02:19Z,i guess it would. there is an existing method before this one (`getconsumerspertopic`) that also takes `excludeinternaltopics` and assumes no default value for it. i wanted to make the new method consistent with that one.,0,0.9917512536048889
72375727,1336,hachikuji,2016-07-27T03:29:00Z,"that's kind of unfortunate. so here's another idea (feel free to dismiss it if it doesn't make sense). maybe having `describe()` return the assignment is actually heading in the right direction. what if we get rid of `outputwriter` and move the printing logic into the main method. then the `consumergroupservice` becomes more functional (and testable). for `list()`, you can have it return the list of groups instead of printing them. the trickier one seems to be `delete()`. maybe you can leave it as it is.",-1,0.9468594193458557
72523263,1336,vahidhashemian,2016-07-27T21:03:42Z,"sure, i'll try that. having `describe()` return the assignment would make testing much easier.",0,0.9839032888412476
72666749,1336,hachikuji,2016-07-28T17:38:28Z,this is looking promising. maybe we could rename `list` to `listgroups` and `describe` to `describeassignment`?,1,0.7878576517105103
72688365,1336,vahidhashemian,2016-07-28T19:40:09Z,sounds good. wouldn't `describegroup` (singular) be more self-explanatory than `describeassignment`?,1,0.7562719583511353
72688649,1336,hachikuji,2016-07-28T19:41:51Z,"yeah, that sounds good to me.",1,0.7535457611083984
72688751,1336,vahidhashemian,2016-07-28T19:42:32Z,and we could also rename `delete` to `deletegroups`?,0,0.9938017725944519
72691457,1336,hachikuji,2016-07-28T19:58:55Z,makes sense to me.,0,0.9787083268165588
72722638,1336,vahidhashemian,2016-07-28T23:43:33Z,i was wondering what your opinion is about the response above to your comment. this pr has gone through a few more rounds of reviews thanks to and this currently is the only outstanding item. thanks in advance for looking into this.,1,0.9470469951629639
72728458,1336,hachikuji,2016-07-29T00:53:38Z,looks like we would print this twice: once here and once in main. i'm wondering if we could remove `consumergroupoutputwriter` from this class and do all the output in main. maybe we just need to move the empty check that you have below in main?,0,0.9806296229362488
72839362,1336,vahidhashemian,2016-07-29T18:28:54Z,"thanks for catching this. i'll fix in the next update. and we can remove `consumergroupoutputwriter` from that class, as you suggested.",1,0.7331080436706543
83920039,1336,hachikuji,2016-10-18T18:28:43Z,"is this needed for a consumer group? i think protocol type will always be ""consumer.""",0,0.9927323460578918
83920161,1336,hachikuji,2016-10-18T18:29:15Z,"for consumer groups, the protocol is really the assignment strategy.",0,0.9923871755599976
83921286,1336,hachikuji,2016-10-18T18:34:09Z,"as far as i can tell, the return type of this method doesn't need to be mutable. maybe something like this would be a little nicer? [code block] (note i used `keys` instead of `keyset` since we throw away the set anyway.)",0,0.9870310425758362
83922730,1336,hachikuji,2016-10-18T18:41:08Z,would it make a big difference if this method accepted `topicpartition` instead of `topicandpartition` since it seems that's what we need anyway?,0,0.9946393370628357
83923001,1336,hachikuji,2016-10-18T18:42:34Z,is this intentional? same for the couple doc changes below.,0,0.980409562587738
83924024,1336,hachikuji,2016-10-18T18:47:48Z,"since we didn't end up needing this for testing, maybe we can just get rid of it and keep its methods one level up?",0,0.9874699711799622
83924432,1336,hachikuji,2016-10-18T18:49:47Z,"nit: since you're using `map`, we don't need this check.",0,0.9883991479873657
83924865,1336,hachikuji,2016-10-18T18:51:46Z,could we let this function handle the empty assignment case as well?,0,0.9949337840080261
83925389,1336,hachikuji,2016-10-18T18:54:23Z,"i'm not actually sure this message is still correct. in kafka-2720, we introduced an `empty` state for the group, which basically persists until all the offsets for the group have expired. in this case, the assignment will be empty, but it will not be rebalancing.",0,0.8729791045188904
83925578,1336,hachikuji,2016-10-18T18:55:21Z,should this be `private`?,0,0.9922074675559998
83926233,1336,hachikuji,2016-10-18T18:58:31Z,similar to other comment: maybe we could use `topicpartition` here.,0,0.9942882061004639
83926524,1336,hachikuji,2016-10-18T18:59:55Z,why not use `map`?,0,0.9913173913955688
83932002,1336,hachikuji,2016-10-18T19:28:41Z,seems like this is another case where we don't actually need a mutable collection if we use `flatmap`.,0,0.9909031987190247
83933934,1336,hachikuji,2016-10-18T19:39:34Z,"it seems the node of the partition owner includes the threadid. the pattern is always ""{consumerid}-{threadid}"", so checking the prefix of the partition owner would always get us the right id. maybe it's a little nicer to use that than the ephemeral owner?",0,0.99085932970047
83934306,1336,hachikuji,2016-10-18T19:41:21Z,"maybe change this to `map`, then i think `flatmap` as suggested above would work nicely.",0,0.9931673407554626
83934935,1336,hachikuji,2016-10-18T19:44:51Z,this looks odd. we create an option just so we can call `map`? could we replace this with: [code block] same for the loop below.,-1,0.9202881455421448
83935126,1336,hachikuji,2016-10-18T19:45:44Z,using `map` would be nicer?,0,0.9919736385345459
83948295,1336,vahidhashemian,2016-10-18T20:52:35Z,"yes, it'll be `consumer`, but there is a check [a link] to verify that the protocol type os valid. if we remove this, i think that check has to be removed too. should i still go ahead and remove it?",0,0.9907106757164001
83948616,1336,vahidhashemian,2016-10-18T20:54:22Z,"sure, i'll rename this field to `assignmentstrategy`.",0,0.9905147552490234
83952330,1336,vahidhashemian,2016-10-18T21:14:02Z,makes sense. thank you for the suggestion. i'll update the method.,1,0.939825177192688
83955679,1336,vahidhashemian,2016-10-18T21:33:13Z,you're right. would it be ok to change this message to `consumer group ... has no active member or is rebalancing`?,0,0.9747821688652039
83957107,1336,hachikuji,2016-10-18T21:42:04Z,"i would probably move that check into `describegroup`. now that i'm thinking about it, we should probably either rename `describegroup` to `describeconsumergroup`, or we should let `describegroup` return a generic `groupsummary` while `describeconsumergroup` returns `consumergroupsummary`.",0,0.9934872388839722
83957355,1336,hachikuji,2016-10-18T21:43:17Z,it would be more ideal if we could tell the user which is the case. maybe we need to propagate the state of the group down to this method.,0,0.9923946857452393
83960147,1336,vahidhashemian,2016-10-18T22:00:51Z,"thanks. with the first suggestion, there already is a `describeconsumergroup` method. unless you prefer this suggestion (using a different method name) i'll go ahead with your second suggestion.",1,0.9288831353187561
83963057,1336,vahidhashemian,2016-10-18T22:20:09Z,"upon further consideration, i think i'm going to adopt your first suggestion, because i need the current `describegroup` method to return the coordinator as part of its output; so i can report the coordinator's broker id. i'm going to use the method name `getconsumergroupsummary` instead.",0,0.9720825552940369
83973106,1336,vahidhashemian,2016-10-18T23:35:51Z,"yup, will try to do this in the next patch.",0,0.981931209564209
83973553,1336,vahidhashemian,2016-10-18T23:39:43Z,"this `case class` is used in other classes in the same file. since it's defined outside the scope of those classes `private` wouldn't work, but `protected` would. i hope i didn't misunderstood your point.",0,0.9326463937759399
83974748,1336,vahidhashemian,2016-10-18T23:49:50Z,"sure, sounds good.",0,0.6141389012336731
83974783,1336,vahidhashemian,2016-10-18T23:50:11Z,thanks for catching this.,0,0.5459718704223633
83975322,1336,vahidhashemian,2016-10-18T23:55:12Z,"we could, but we would need to pass more arguments now that we want to distinguish between empty group and rebalancing group. plus, in the case of an empty assignment we are using the `printerror` method, instead of actually printing assignments. do you still think we should change it?",0,0.991943359375
84141950,1336,vahidhashemian,2016-10-19T18:55:49Z,i'll try to make use of `flatmap`.,0,0.9880466461181641
84143779,1336,vahidhashemian,2016-10-19T19:05:03Z,sure i'll try to use that (by ignoring the threadid part) instead of ephemeral owner.,0,0.9888299107551575
84150277,1336,vahidhashemian,2016-10-19T19:39:35Z,this section will be removed now that we decided to use the owner info directly.,0,0.989827036857605
84157718,1336,vahidhashemian,2016-10-19T20:17:48Z,i'll give it a try in the next patch.,0,0.9771816730499268
84164530,1336,vahidhashemian,2016-10-19T20:53:37Z,"to be honest, it's been so long that i don't recall why i made these changes. but when i try the current command, i can't tell what the meaning of ""new consumer being the default"" is. it seems to me that we need to either provide `--zookeeper` or `--bootstrap-server`; it's not like if we use `--new-consumer` we don't have to provide `--bootstrap-server`. the only restriction around `--new-consumer` seems to be that it cannot be used along with `--zookeeper`. the descriptions in parenthesis are not very clear to me. but it might be just me. your thoughts?",0,0.7857728600502014
84167217,1336,hachikuji,2016-10-19T21:07:13Z,"i agree it's not super clear. maybe we should just avoid saying it's required since it saves us from needing to qualify? you can try to fix this if you want, but i'd be ok just leaving it as it is since it seems orthogonal to the rest of this.",0,0.8410235047340393
84173733,1336,vahidhashemian,2016-10-19T21:42:52Z,"sure, i'll revert these changes. i'm ok with leaving the ""required"" text in since other tools have it too, but we need to better qualify them, as you mentioned. i may work on it separately later.",0,0.981445848941803
84191293,1336,hachikuji,2016-10-19T23:53:22Z,"if we had `consumergroupsummary` include a list of `consumersummary` objects instead of `membersummary`, would we still need this function?",0,0.9951795339584351
84192091,1336,hachikuji,2016-10-20T00:00:45Z,seems like this method isn't giving us much anymore. maybe it's ok to use `println` directly?,0,0.9825907349586487
84192990,1336,hachikuji,2016-10-20T00:10:00Z,it's a little weird to locate this in `kafka.coordinator` since the coordinator is technically agnostic to group internals. the best alternative i can think of is maybe to put it in tools with `adminclient`. what do you think?,-1,0.975342869758606
84193326,1336,hachikuji,2016-10-20T00:13:17Z,"nitpick: since it's a simple statement, maybe parenthesis in `map` would be a little nicer than braces?",0,0.9750330448150635
84193423,1336,hachikuji,2016-10-20T00:14:14Z,nitpick: we usually don't put a space before the ':'.,0,0.9848922491073608
84193800,1336,hachikuji,2016-10-20T00:18:18Z,nitpick: i think parenthesis are a little nicer for simple one-liners like this.,0,0.744770884513855
84194583,1336,hachikuji,2016-10-20T00:26:11Z,there are few other places in the patch where we could also change this.,0,0.9855619072914124
84194947,1336,vahidhashemian,2016-10-20T00:30:38Z,i'm not sure if i follow. could you please elaborate a bit?,-1,0.6638505458831787
84195024,1336,hachikuji,2016-10-20T00:31:31Z,"since the zookeeper service has no notion of consumer state, should we return `option[string]` instead?",0,0.9944911003112793
84195092,1336,vahidhashemian,2016-10-20T00:32:12Z,"sure, it makes sense. i'll move it.",0,0.9809884428977966
84195261,1336,vahidhashemian,2016-10-20T00:34:17Z,i'll remove the space. there are a few other occurrences in this file that i'll fix too.,0,0.9885773658752441
84195305,1336,hachikuji,2016-10-20T00:34:51Z,"currently `consumergroupsummary` has a field for the group members, which are represented as instances of `membersummary`. i'm wondering if it would make sense to use `consumersummary` instead. then we might only need a single method returning `consumergroupsummary`.",0,0.9835498332977295
84195485,1336,hachikuji,2016-10-20T00:36:58Z,"if we use normal `map` instead of `flatmap`, does this need to be a `seq` anymore?",0,0.9954290390014648
84195843,1336,hachikuji,2016-10-20T00:41:19Z,could this one be a `flatmap` like the one just above?,0,0.9942375421524048
84195844,1336,vahidhashemian,2016-10-20T00:41:20Z,"no, it doesn't. thanks for catching it.",1,0.7509163618087769
84196169,1336,hachikuji,2016-10-20T00:44:54Z,looks like we're missing the 's' at the start of the string. another few of these below.,0,0.984357476234436
84196393,1336,hachikuji,2016-10-20T00:47:07Z,nitpick: i think the braces are unnecessary if it is a simple variable.,0,0.9469343423843384
84196615,1336,vahidhashemian,2016-10-20T00:49:59Z,"thanks, i noticed there were a few more.",1,0.8514882922172546
84196895,1336,hachikuji,2016-10-20T00:53:01Z,looks like another case where we might be able to change the `foreach` to a `map` with a `toarray` at the end.,0,0.9910184144973755
84197069,1336,hachikuji,2016-10-20T00:55:32Z,nitpick: maybe we could destructure on assignment? [code block],0,0.9931191205978394
84197288,1336,vahidhashemian,2016-10-20T00:58:28Z,"do you mean merging `getconsumergroupsummary` and `describeconsumergroup` into one method that returns a `consumergroupsummary` object? if so, i thought about it when i was making the recent changes, and noticed that `getconsumergroupsummary` is being used in a few other places. that's why i hesitated to make the unnecessary change. but i guess they could be merged and all calls to `getconsumergroupsummary` would become calls to `describeconsumergroup`. please correct me if i'm misunderstood. thanks.",-1,0.7328890562057495
84197311,1336,hachikuji,2016-10-20T00:58:45Z,"nitpick: should 'member' be plural? also, a little surprising we don't have a variable for the groupid. maybe we could add one above to make these messages a little easier to read.",0,0.5684414505958557
84197388,1336,hachikuji,2016-10-20T00:59:50Z,"yeah, that's what i meant. don't bother if it's a ton of additional work, but seems like a nice cleanup.",1,0.7920410633087158
84198268,1336,vahidhashemian,2016-10-20T01:08:24Z,good suggestion.,1,0.9752551317214966
84198564,1336,vahidhashemian,2016-10-20T01:12:50Z,"no problem, i'll give it try in the next patch.",0,0.9739919304847717
84349940,1336,hachikuji,2016-10-20T18:42:27Z,"nit: shouldn't need parenthesis for most of these getters, i think. there are a bunch of these around the patch.",0,0.8218271136283875
84350479,1336,hachikuji,2016-10-20T18:45:11Z,nit: might be nice to add a `require` to validate that the group assignment is not empty.,0,0.9924638271331787
84352489,1336,hachikuji,2016-10-20T18:55:19Z,this check needs to be updated since `state` is now an `optional`.,0,0.9930500984191895
84352847,1336,hachikuji,2016-10-20T18:57:03Z,this should probably be `foreach` since we don't need any the return type.,0,0.9918203353881836
84363117,1336,hachikuji,2016-10-20T19:55:17Z,nit: no need for `new`.,0,0.9905449151992798
84363280,1336,hachikuji,2016-10-20T19:56:14Z,nit: maybe this could be [code block],0,0.9913484454154968
84363729,1336,hachikuji,2016-10-20T19:58:46Z,nit: maybe this could be a `foreach`?,0,0.9901662468910217
84364647,1336,hachikuji,2016-10-20T20:04:04Z,nit: no need for `new`,0,0.9896016716957092
84364950,1336,hachikuji,2016-10-20T20:06:07Z,nit: unneeded `tolist`.,0,0.979023814201355
84365278,1336,hachikuji,2016-10-20T20:08:04Z,nit: unneeded import,0,0.5279206037521362
84365476,1336,hachikuji,2016-10-20T20:09:08Z,could this be `consumers`. the `summaries` suffix seems a tad verbose.,0,0.9399435520172119
84366002,1336,hachikuji,2016-10-20T20:12:08Z,"nit: since we've converted most of these to use string interpolation, maybe we could do the same here? i noticed a couple others.",0,0.9876205325126648
84369348,1336,vahidhashemian,2016-10-20T20:30:13Z,"sure, sounds fair.",0,0.7862374782562256
84369482,1336,vahidhashemian,2016-10-20T20:30:56Z,i'll try to remove them. i see that their occurrences are beyond what's in this patch.,0,0.9817197918891907
84379640,1336,vahidhashemian,2016-10-20T21:28:38Z,you're right. thanks. i'll fix this in the next patch.,1,0.974342405796051
84388805,1336,vahidhashemian,2016-10-20T22:28:24Z,not sure if i follow this one?,0,0.8470862507820129
84390074,1336,vahidhashemian,2016-10-20T22:38:02Z,never mind. i think you mean something like [code block],0,0.7439541220664978
84391557,1336,hachikuji,2016-10-20T22:49:38Z,"yeah, something like that. kind of hard to tell sometimes when you're trying to get a little too cute, but using `map` and `foreach` seems to generally be preferred over an explicit check for `isdefined` or `isempty`.",-1,0.9663896560668945
84391755,1336,hachikuji,2016-10-20T22:51:12Z,"the general rule is to omit the parenthesis if the function does not mutate any state. no need to catch all such cases, it just stood out a bit on this line.",0,0.9892260432243347
84513550,1336,hachikuji,2016-10-21T16:45:27Z,"i may have missed it, but how do we know this `get` is safe? should we match using the option instead?",0,0.9848096966743469
84520691,1336,vahidhashemian,2016-10-21T17:53:51Z,"i believe for the zookeeper-based consumers the `describegroup` returns either `none` for `assignments` or some array (and the array cannot be empty because as soon as a group starts there is an assignment row). therefore, this line would not be reached in that case. and for java based consumer groups as far as i can tell `state` always has some value, and it cannot be `none`. so this line would be safe to call. having said that i'm ok with checking `state` here instead of `state.get`. one more question. i tried creating a new topic and starting an old consumer consuming from that topic belonging to a new consumer group. when i tried `describe` with this patch i get this output for a few seconds, and then the error vanishes as the initializations are done. are we ok with this behavior? [code block]",0,0.9344552755355835
84525026,1336,vahidhashemian,2016-10-21T18:36:18Z,this is the refactored code for `state` check. please let me know if you see issues with it. thanks.,1,0.7468174695968628
84536951,1336,hachikuji,2016-10-21T20:15:14Z,nit: you can use `nonempty`.,0,0.9931387305259705
84536970,1336,hachikuji,2016-10-21T20:15:23Z,"couple naming suggestions: 1. `member-id` -> `consumer-id` 2. `member-host` -> `host` what do you think? also, it seems neither of these options are available for the old consumer. maybe it would reduce the noise if we leave them out of the output in that case? not sure if there's a clean way to do that though.",0,0.984869122505188
84539540,1336,vahidhashemian,2016-10-21T20:33:45Z,"i can make the name changes. regarding availability for old consumer, it's actually `member_host` and `client_id` (the last two) that will be blank in the output. i think i can leverage the `node` variable (that i introduced to report the coordinator broker id for new consumer option) and based on that decide whether the last two column should be printed or no. i'll submit an update shortly and you can take a look and let me know what you think. thanks.",1,0.8973561525344849
84542689,1336,vahidhashemian,2016-10-21T20:54:10Z,i don't feel very happy about this repeating check. to me it was either this or totally separate print statements for old and new consumers in the `match` block of line 114 above. what do you think?,-1,0.9526011943817139
84543875,1336,hachikuji,2016-10-21T21:00:56Z,it might be a little less annoying if you put the result in a val (e.g. `usenewconsumer`). maybe you could even pass `opts.useoldconsumer` into this function to avoid the need to check the coordinator.,0,0.7027122378349304
84544537,1336,vahidhashemian,2016-10-21T21:05:24Z,"btw, i'm thinking printing ""-"" instead of """" when data is not available or does not apply would look better and more readable (especially when there are multiple rows with blank columns). compare [code block] with [code block]",0,0.9906879663467407
84545114,1336,hachikuji,2016-10-21T21:09:20Z,good idea.,1,0.9718119502067566
84545242,1336,vahidhashemian,2016-10-21T21:10:22Z,passing `opts.useoldconsumer` sounds good; but that doesn't avoid the need for this repeating `if` block. or i misunderstood?,0,0.9709153771400452
84545937,1336,hachikuji,2016-10-21T21:15:37Z,"yeah, you still need it. seems not too bad to me. you could move it outside the loop, but then you'd need to repeat the loop in both arms of the `if`, which seems worse.",-1,0.9513078331947327
84546160,1336,vahidhashemian,2016-10-21T21:17:00Z,"right, i'll keep it as is then. thanks.",1,0.9784063100814819
84551578,1336,hachikuji,2016-10-21T21:58:36Z,"really sorry to keep adding comments... did we print this before? it seems unnecessary given that we require the group to be passed on the command line. one downside to having this line and the one below is that it's a little tougher to parse the output. on the other hand, having a way to get the coordinator seems useful for debugging. i wonder if it would make sense to add that to the `--list` option in a separate patch. what do you think?",-1,0.9904638528823853
84552130,1336,vahidhashemian,2016-10-21T22:03:39Z,that's fine with me. i added these two lines (along with [a link] and [a link] because there was a request on the corresponding jira asking for some clarification on the printed output. i'm fine with removing them and have the `--list` option report the coordinator broker id. should i also leave out the other two lines i linked to above?,0,0.8864844441413879
84553085,1336,hachikuji,2016-10-21T22:12:24Z,"looked back at the jira. maybe you could print the warning messages to stderr? i also saw jun's comment about printing the coordinator. it's a little odd to print it as a column in the table as you suggested (since it will be the same for all members), but that might be a better choice. i'd be ok with either doing that or adding it to the `--list` option separately. the latter might be a little nicer since this already has a lot of columns and i think we should have the coordinator information already when using `--list`.",0,0.8344680070877075
84553913,1336,vahidhashemian,2016-10-21T22:18:00Z,"i also think using `--list` to report the coordinator id is better for the same reasons you mentioned. i'll submit another update shortly, and open a jira for reporting the coordinator.",0,0.9786307215690613
108825282,2744,junrao,2017-03-30T01:39:13Z,"hmm, not sure if this is accurate to capture the network thread utilization. what we are recording is essentially the responsesendtime, which includes the time for waiting for the socket to be writable. that portion of the time actually doesn't tie up the network threads and shouldn't be accounted for in the request time. also, this seems to only cover the network thread time for sending responses, not for reading requests (which could be significant for produce requests). i was thinking that we may need to do the following. in selector.pollselectionkeys(), we will measure the time spent for reading/writing each kafkachannel and propagate the time back to the caller. then, we can account for both request/response time in network threads in socketserver.",0,0.9208570122718811
108825299,2744,junrao,2017-03-30T01:39:22Z,quotathreadpercentdefault => quotarequestpercentdefault ?,0,0.9944964051246643
108825310,2744,junrao,2017-03-30T01:39:26Z,it seems that toint is redundant.,0,0.816867470741272
108825313,2744,junrao,2017-03-30T01:39:29Z,it seems that tolong is redundant.,0,0.7606163024902344
108825331,2744,junrao,2017-03-30T01:39:39Z,do we need to make this protected? it doesn't seems to be customized in the subclass and it doesn't seem that we can change it to anything other than rate().,0,0.9920387268066406
108825337,2744,junrao,2017-03-30T01:39:42Z,unused import,0,0.9524969458580017
108825350,2744,junrao,2017-03-30T01:39:48Z,utilizationthrottletimems => requestthrottletimems?,0,0.9909634590148926
108825356,2744,junrao,2017-03-30T01:39:52Z,remove space after trace( ?,0,0.9858373999595642
108825402,2744,junrao,2017-03-30T01:40:17Z,"hmm, i am wondering if we really need to subtract bandwidththrottletimsms from the throttle time. while the response is delayed for bandwidththrottletimsms, some time has passed, which should bring down the value of the metric when we check the request quota. then, naturally, this request will be delayed less for request quota violation.",0,0.8860878944396973
108826148,2744,junrao,2017-03-30T01:49:43Z,we throttle leaderandisrrequest if it's unauthorized. should we do the same thing here?,0,0.9575822353363037
108916491,2744,rajinisivaram,2017-03-30T12:49:37Z,done.,0,0.9640594124794006
108916544,2744,rajinisivaram,2017-03-30T12:49:54Z,removed.,0,0.9782117605209351
108916572,2744,rajinisivaram,2017-03-30T12:50:00Z,removed.,0,0.9782117605209351
108916610,2744,rajinisivaram,2017-03-30T12:50:13Z,reverted.,0,0.9610875844955444
108916623,2744,rajinisivaram,2017-03-30T12:50:18Z,removed.,0,0.9782117605209351
108917372,2744,rajinisivaram,2017-03-30T12:53:19Z,in this case `authorizeclusteraction` method throws an exception and the response is sent from the exception handler in `handle`. all responses sent from the exception handler are throttled.,0,0.987387478351593
108917401,2744,rajinisivaram,2017-03-30T12:53:29Z,done.,0,0.9640594124794006
108917419,2744,rajinisivaram,2017-03-30T12:53:34Z,done.,0,0.9640594124794006
108917772,2744,rajinisivaram,2017-03-30T12:55:10Z,"yes, i wasn't sure which way to go. either way, i think the throttle times will correct themselves over time. i have removed the subtraction.",0,0.8607985377311707
108919055,2744,rajinisivaram,2017-03-30T13:00:59Z,"thank you, i have reworked the code for recording network thread time as you suggested. at the moment, ssl/sasl handshake time is included in the time for the first request. is that reasonable? i can clear the time after authentication if it is confusing.",1,0.8553195595741272
108923119,2744,rajinisivaram,2017-03-30T13:19:36Z,"sorry, had to revert that since `toint` was required for newer versions of scala.",-1,0.9892244935035706
109046976,2744,junrao,2017-03-30T21:53:07Z,"could we add a comment somewhere so that people know that if they want to add a non-internal request in the future, they would need to include the throttle time field?",0,0.9918861389160156
109047035,2744,junrao,2017-03-30T21:53:31Z,this takes care of the time spent on receiving requests. we will need to do the same thing to track the time on sending responses.,0,0.9857140779495239
109049180,2744,junrao,2017-03-30T22:05:52Z,"the approach in the patch works. but one issue is that the implementor of all future requests will have to deal with throttling the responses directly. another approach is to do the throttling early in handle(). if a request needs to be delayed, we first throttle it and then hand it over to the specific request handler. this way, we just need to implement the request throttling logic in one place and all future requests don't have to be aware of it. we probably need to mark whether a request is at the cluster level so that we can throttle unauthorized internal requests too. also, not sure if there is an easier way for the request handler thread to pick up the requests after throttling is done. if there is, this may be a simpler approach?",0,0.9901987314224243
109049691,2744,junrao,2017-03-30T22:08:59Z,that seems fine for now. perhaps we could add a comment in case we need to revisit in the future?,0,0.9657865762710571
109146033,2744,rajinisivaram,2017-03-31T12:09:54Z,i have added unit test in `apikeystest` that checks that all responses except those explicitly excluded contain a field named `throttle_time_ms`. there is a comment in the test as well to ensure that new requests either contain the field or are manually added to the test's exclusion list.,0,0.9925530552864075
109146742,2744,rajinisivaram,2017-03-31T12:15:02Z,"the time is accumulated in `selector` and includes the full time spent for each channel in `pollselectionkeys`. for each request, the accumulated time is used and the value is reset. this time includes the time for write of the previous response and the time for read of the current request. i have added a comment in the code.",0,0.9947113990783691
109149032,2744,rajinisivaram,2017-03-31T12:30:54Z,"thank you for the review. it will be nice to handle throttling in a single place. however, handling of all new requests need to be aware of throttling, so that they add the throttling time to the response. the bigger issue is the exclusions. we need to authorize in a central place for `clusteraction`. and worse, we need to handle `produce` differently since we don't want to throttle until after the request is processed and the memory can be released. we probably want to throttle later for `fetch` as well since we are relying on the bandwidth throttle time to reduce the request throttle time. we will need to record two more timestamps to take into account time spent before throttle in some cases and after throttle in others. and as you mentioned, we still want the request to be processed after throttling on the request handler thread. taking all that into account, i am not sure it is worthwhile to restructure the code to centralize the throttling logic. i have updated `requestquotatest` to ensure that unauthorized requests of all types are throttled. and also to check that all requests not explicitly excluded are throttled and return throttle time in response. this should catch any missing throttling in new requests. let me know if this is sufficient or whether i should try out the centralized approach.",1,0.8266215324401855
109149244,2744,rajinisivaram,2017-03-31T12:32:32Z,added comment in `socketserver`.,0,0.9907128214836121
109189436,2744,rajinisivaram,2017-03-31T15:42:41Z,"after writing the comment above, i realized that it sounds rather odd. so i have updated the code to record network thread time when request metrics are updated, so that receive+send are recorded together. this does also ensure that the last network time on each connection is recorded and it would work even if requests on a connection use different clientids. throttling is still performed only on subsequent requests.",0,0.7377030253410339
110187347,2744,ijuma,2017-04-06T15:08:36Z,why is this an `atomiclong` instead of a plain long?,0,0.988474428653717
110188076,2744,ijuma,2017-04-06T15:11:24Z,"hmm, it seems a bit unfortunate that we need to do a `system.nanotime` per selection key. have we done any measurements on the overhead?",-1,0.95615553855896
110188616,2744,ijuma,2017-04-06T15:13:33Z,i think we'd want to override `parseresponse` for `api_versions` only.,0,0.9905515909194946
110189171,2744,ijuma,2017-04-06T15:15:19Z,i wonder if there's a way to add this to `responseheader` in a compatible way. it seems a bit annoying to have to add that to every response.,-1,0.9813047647476196
110189630,2744,ijuma,2017-04-06T15:17:01Z,"since we use `ms`, should we not be using `ns` instead of `nanos`?",0,0.994820237159729
110190164,2744,ijuma,2017-04-06T15:19:12Z,"nit: the logic inside this catch has become a bit complicated. can we perhaps extract methods? also, something i was thinking about recently is that methods like `geterrorresponse` could throw an exception due to bugs. it would be nice for us not to leak connections in such cases.",0,0.9227792620658875
110190689,2744,ijuma,2017-04-06T15:20:48Z,"if we could somehow add the throttle time in the response header, it would be easier to handle it in a generic way for the typical cases.",0,0.9931110143661499
110422348,2744,rajinisivaram,2017-04-07T15:52:11Z,"there are a few requests which don't have throttle time (controlledshutdown, stopreplica etc. used for inter-broker and not by producer/consumer). so it made sense to add throttle time to individual requests. error codes seem to be handled this way. but my main concern was compatibility. even if we looked at request version to determine the response header version, there is still the issue of `apiversionsresponse` which needs to be handled. according to kip-35, `apiversionresponse.errorcode is guaranteed to be the first int16 of the response for all future versions of apiversionrequest`. i didn't want to break that assumption.",0,0.9924532771110535
110422668,2744,rajinisivaram,2017-04-07T15:53:33Z,i couldn't see any way around it. i will kick off system test runs to see the impact.,0,0.9003314971923828
110422700,2744,rajinisivaram,2017-04-07T15:53:42Z,done.,0,0.9640594124794006
110423058,2744,rajinisivaram,2017-04-07T15:55:21Z,"both `ns` and `nanos` are already used in the code. i chose `nanos` everywhere in the pr since it stands out better from `ms`, especially since i was changing some measurements from millis to nanos. but i am ok with switching to `ns` if that is preferable.",0,0.9818124175071716
110423731,2744,rajinisivaram,2017-04-07T15:58:29Z,"have moved to a method. i think errors are propagated and logged. we won't close acks=0 connections if `geterrorresponse` threw an exception, but perhaps that is ok since that would still not be a leaked connection?",0,0.9912548065185547
110425748,2744,rajinisivaram,2017-04-07T16:08:22Z,because the value is updated on the network thread and read-and-reset on the request handler thread. i have added a comment.,0,0.9901918172836304
110442824,2744,junrao,2017-04-07T17:39:04Z,our system test currently doesn't do perf validation well. it would be useful to just run producerperformance and consumerperformance and see if there is any noticeable degradation.,0,0.9842982292175293
110478783,2744,rajinisivaram,2017-04-07T20:42:21Z,i ran `producerperformance` and `consumerperformance` on my laptop and didn't see any noticeable difference. this is the throughput in mb/s (average of three runs): test (message size) | trunk | with pr -------------------------|--------------|------------ producer (100 bytes) | 158.68 | 160.18 producer (1000 bytes) | 355.43 | 350.36 consumer (100 bytes) | 376.20 | 378.52 consumer (1000 bytes) | 559.45 | 559.45,0,0.9820839166641235
112594508,2744,junrao,2017-04-21T01:43:24Z,"perhaps we should only fall back to version 0 of the request if the error is unsupported_version? for other kinds of error, just disconnect?",0,0.9859053492546082
112594514,2744,junrao,2017-04-21T01:43:29Z,"instead of returning atomiclong, could we just reset to 0 and return a long?",0,0.9914693236351013
112594523,2744,junrao,2017-04-21T01:43:37Z,"hmm, not sure why we need this. it seems that the client should always use the requested version to parse the response of api_versions?",0,0.7675691246986389
112594538,2744,junrao,2017-04-21T01:43:44Z,"this makes things a bit more complicated. i was thinking of the following. in updaterequestmetrics(), we remember networkthreadtime as previousnetworkthreadtime. in kafkaapis, we can just add previousnetworkthreadtime to the throttler. that way we don't need this callback. will that be better?",0,0.9371938109397888
112594555,2744,junrao,2017-04-21T01:43:54Z,it seems that we should update the instance level localcompletetimenanos instead of a local one?,0,0.9936220049858093
112594610,2744,junrao,2017-04-21T01:44:36Z,apikey in the comment needs to be changed accordingly.,0,0.9856811761856079
112594983,2744,junrao,2017-04-21T01:49:17Z,will subsequently used => will subsequently be used,0,0.9850045442581177
112726629,2744,rajinisivaram,2017-04-21T16:23:31Z,done.,0,0.9640594124794006
112726925,2744,rajinisivaram,2017-04-21T16:24:55Z,atomiclong is returned so that the the value can be updated from the i/o thread when a request is complete without propagating `kafkachannel` to the request handling code.,0,0.9947689771652222
112727184,2744,rajinisivaram,2017-04-21T16:26:18Z,"if client sends apiversionsrequest with a higher version that client supports, broker responds with a version 0 response that indicates unsupported version.",0,0.985529899597168
112729035,2744,rajinisivaram,2017-04-21T16:36:20Z,"hmm... network thread time needs to be accumulated against the (user, client-id) and needs to include the time for the sending the response. the callback avoids having to propagate (user, client-id).",0,0.9885953068733215
112729071,2744,rajinisivaram,2017-04-21T16:36:30Z,done.,0,0.9640594124794006
112729097,2744,rajinisivaram,2017-04-21T16:36:38Z,done.,0,0.9640594124794006
112729130,2744,rajinisivaram,2017-04-21T16:36:46Z,done.,0,0.9640594124794006
112791899,2744,junrao,2017-04-21T23:13:34Z,could we consistently add newthrottletimefield() as the first field?,0,0.9949493408203125
112791907,2744,junrao,2017-04-21T23:13:41Z,"offset_for_leader_epoch_response is an inter broker request. so, we shouldn't add a throttle field.",0,0.9927046895027161
112791941,2744,junrao,2017-04-21T23:14:08Z,"it might be useful to report all the time still as ms, but up to micro sec level accuracy now that we track with nanosec.",0,0.9897079467773438
112791964,2744,junrao,2017-04-21T23:14:21Z,"for request quota, since we are collecting request time in nanosecs already, it will be useful to create a rate with nanosec as the time unit. this will make the measurement more accurate.",0,0.9905558228492737
112791985,2744,junrao,2017-04-21T23:14:32Z,"hmm, in this case, we probably only want to throttle if the exception is related to authorization. for any other exceptions, we should send an error immediately?",0,0.970386266708374
112791992,2744,junrao,2017-04-21T23:14:40Z,"hmm, this can be a bit tricky. fetch requests from the follower are considered internal and shouldn't be throttled.",-1,0.8569271564483643
112792013,2744,junrao,2017-04-21T23:14:57Z,"hmm, when there is no data, the consumer will wait for the timeout. so, not sure if this is enough to trigger the throttling. we probably need to either set a low maxwait in consumer config and set the quota to be really low.",0,0.5294181108474731
112792018,2744,junrao,2017-04-21T23:15:02Z,"hmm, not sure where the test is.",0,0.506064236164093
112792036,2744,junrao,2017-04-21T23:15:18Z,"why is the replicaid 5000? that indicates it's from a follower. also, i am wondering if 100 maxwait is enough to trigger throttling.",0,0.8424066305160522
112792083,2744,junrao,2017-04-21T23:15:48Z,"got it. an alternative is to call networkthreadtimenanos() in socketserver.processnewresponses() and processcompletedsends(). then we can just reset and return the value, which is easier to understand?",0,0.9887046217918396
112792089,2744,junrao,2017-04-21T23:15:53Z,thanks for the explanation. could we add that as comment in the code?,0,0.5454484820365906
112792094,2744,junrao,2017-04-21T23:15:56Z,got it. this is fine then.,0,0.8243718147277832
112908803,2744,rajinisivaram,2017-04-24T10:06:26Z,"according to kip-35, the java clients don't rely on this, but just in case some other clients do, i have left `error_code` as the first field for `apiversionsresponse`.",0,0.9930860996246338
112908831,2744,rajinisivaram,2017-04-24T10:06:36Z,fixed.,0,0.979083240032196
112909448,2744,rajinisivaram,2017-04-24T10:09:51Z,the yammer metrics `histogram` class that tracks time only takes long and not double. hence the millisecond value is used.,0,0.9874799847602844
112910225,2744,rajinisivaram,2017-04-24T10:14:24Z,"for request quota, values are recorded as double, so even though they use millisecond as unit to be consistent, they have higher precision. isn't that sufficient?",0,0.9851896166801453
112910635,2744,rajinisivaram,2017-04-24T10:16:49Z,"yes, `authorizeclusteraction` takes care of throttling for unauthorized request and all other paths including error path goes through this `sendresponseexemptthrottle` which does not perform throttling.",0,0.9937127232551575
112910724,2744,rajinisivaram,2017-04-24T10:17:22Z,"oops, you are right. fixed.",1,0.8169966340065002
112911096,2744,rajinisivaram,2017-04-24T10:19:27Z,consumers in this test are configured with `fetch.max.wait.ms=0`. the quota is set very small as well to trigger throttling.,0,0.9941439032554626
112911132,2744,rajinisivaram,2017-04-24T10:19:36Z,"oops, fixed.",0,0.5780893564224243
112911223,2744,rajinisivaram,2017-04-24T10:20:09Z,copy-paste error. fixed and set maxwait to zero.,0,0.9874216318130493
112911309,2744,rajinisivaram,2017-04-24T10:20:38Z,done.,0,0.9640594124794006
112911522,2744,ijuma,2017-04-24T10:21:59Z,i think the atomiclong comment should be moved to the field.,0,0.9821370244026184
112912615,2744,ijuma,2017-04-24T10:28:34Z,is there a reason why we don't replace the 4 lines above with: [code block],0,0.9943913817405701
112917077,2744,rajinisivaram,2017-04-24T10:55:44Z,done.,0,0.9640594124794006
112917164,2744,rajinisivaram,2017-04-24T10:56:08Z,"thank you, done.",1,0.9496875405311584
112965720,2744,junrao,2017-04-24T14:46:06Z,"ok, could we add a comment that error_code has to be the first field in apiresponse?",0,0.9941866397857666
112965772,2744,junrao,2017-04-24T14:46:20Z,i was actually referring to line 169 where we log the time components in trace logging. it's useful to see more precise time there since sometimes the time may take less than 1ms.,0,0.9841827750205994
112965811,2744,junrao,2017-04-24T14:46:30Z,thanks. that should be enough then.,1,0.9512077569961548
112969979,2744,junrao,2017-04-24T15:00:57Z,"here, we throttle independent of the exception type. perhaps, it's better to only engage in throttling if the exception is clusterauthorizationexception?",0,0.9899556636810303
113048200,2744,rajinisivaram,2017-04-24T20:30:53Z,fixed to throttle only for `clusterauthorizationexception` for broker-only requests.,0,0.9934961795806885
113595344,2744,junrao,2017-04-27T00:51:18Z,this is an inter-broker request as well and clusteraction should be true.,0,0.9932346940040588
113596378,2744,junrao,2017-04-27T01:02:52Z,"this is an inter-broker request. so, no throttling needed.",0,0.9893323183059692
113597310,2744,junrao,2017-04-27T01:13:52Z,perhaps it's better to pass the networkthread time to request.updatemetrics() and call the recordnetworkthreadtimecallback there?,0,0.9944256544113159
113597451,2744,junrao,2017-04-27T01:15:46Z,"hmm, we probably don't want to call recordnetworkthreadtimenanos here since it will be called in processcompletesends() again. instead, it seems that we want to call recordnetworkthreadtimenanos() in all places where we call request.updaterequestmetrics().",0,0.9834807515144348
113598851,2744,junrao,2017-04-27T01:31:19Z,it's actually read and reset by the broker's network thread.,0,0.992381751537323
113599869,2744,junrao,2017-04-27T01:42:13Z,"for the trace logging in line 177, could we report all the time still as ms, but up to micro sec level accuracy?",0,0.9941266775131226
113600212,2744,junrao,2017-04-27T01:45:55Z,"given this, should we just remove line 65?",0,0.9936337471008301
113694991,2744,ijuma,2017-04-27T13:29:57Z,"sorry for the delay on this one. so, one way to do this would be the following: 1. add two fields to responseheader _if_ the request version is higher than the version before this pr: error_code, throttle_time_ms (in this order) 2. remove any top-level error_code in the new version of all affected responses 3. remove throttle_time_ms from fetchresponse and produceresponse in the new version 4. throttle_time_ms is always 0 for requests that are never throttled as part of this, we would also solve the issue that we currently have no way to return generic errors via the protocol. since we are bumping the protocol version for so many requests, it seems like it would be a good opportunity to fix both issues at the same time. is there a reason why this is a bad idea or would not work?",-1,0.9906842708587646
113730628,2744,ijuma,2017-04-27T15:38:43Z,"discussed this with . the main challenge with this option is having the top level error field for every response. this would probably affect a lot of code: 1. we would need to handle this top level error code everywhere. 2. a bunch of protocols that currently have a top level error code would no longer have them, so a bunch of code would have to be updated as well. so, it doesn't seem appropriate to do this as part of this kip.",-1,0.5536399483680725
113731419,2744,rajinisivaram,2017-04-27T15:42:10Z,thank you for looking into this.,1,0.7517444491386414
113735595,2744,junrao,2017-04-27T15:58:07Z,could we make this and a few other methods in the class private?,0,0.9945995807647705
113736431,2744,junrao,2017-04-27T16:01:12Z,"hmm, is the test added? i don't see the code for submittest that checks the throttling field in the response.",0,0.9622393250465393
114028254,2744,rajinisivaram,2017-04-28T22:05:14Z,fixed.,0,0.979083240032196
114028270,2744,rajinisivaram,2017-04-28T22:05:25Z,fixed.,0,0.979083240032196
114028303,2744,rajinisivaram,2017-04-28T22:05:39Z,fixed.,0,0.979083240032196
114028317,2744,rajinisivaram,2017-04-28T22:05:47Z,done.,0,0.9640594124794006
114028402,2744,rajinisivaram,2017-04-28T22:06:32Z,"yes, you are right. replaced with `long` and updated comment.",0,0.7950292229652405
114028417,2744,rajinisivaram,2017-04-28T22:06:39Z,done.,0,0.9640594124794006
114028438,2744,rajinisivaram,2017-04-28T22:06:52Z,done.,0,0.9640594124794006
114028518,2744,rajinisivaram,2017-04-28T22:07:28Z,"sorry, had forgotten the tests, fixed now.",-1,0.9932789206504822
114028539,2744,rajinisivaram,2017-04-28T22:07:37Z,done.,0,0.9640594124794006
511148601,9487,wcarlson5,2020-10-23T20:48:43Z,this will call closetoerror but i am testing if that has a problem. so far it does not,0,0.8535524010658264
511149017,9487,wcarlson5,2020-10-23T20:49:47Z,moved into stream thread because of a concurrent operation exception that appeared,0,0.9871088266372681
512320447,9487,wcarlson5,2020-10-26T23:03:45Z,method was a few lines too long,0,0.6660082340240479
514527605,9487,lct45,2020-10-29T19:57:51Z,is this spacing on purpose?,0,0.9828466773033142
514531597,9487,lct45,2020-10-29T20:03:00Z,is this section going to be re-added after the other thread handling stuff gets figured out?,0,0.9941820502281189
514535353,9487,lct45,2020-10-29T20:07:44Z,supposed to be here?,0,0.9831358790397644
514535737,9487,lct45,2020-10-29T20:08:33Z,two new lines in a row,0,0.9780896902084351
514536366,9487,lct45,2020-10-29T20:09:41Z,extra line,0,0.9711664915084839
514536509,9487,lct45,2020-10-29T20:09:56Z,extra line (:,0,0.9837366938591003
514538306,9487,lct45,2020-10-29T20:13:34Z,extra line,0,0.9711664915084839
514540200,9487,lct45,2020-10-29T20:17:02Z,line!,0,0.8659770488739014
514566700,9487,wcarlson5,2020-10-29T21:05:19Z,it will. i don't know if we should merge as comment or just add it later,0,0.8732540607452393
514567028,9487,wcarlson5,2020-10-29T21:05:43Z,same as the other use in ks,0,0.9840680956840515
516994424,9487,vvcephei,2020-11-03T22:32:35Z,"[code block] in l389, we say that we throw an exception if the handler is null, which sounds like a more reasonable api to me.",0,0.9871604442596436
516995632,9487,vvcephei,2020-11-03T22:35:32Z,what's up with the `` on this line? i don't think i've seen that before.,0,0.932961642742157
516996830,9487,vvcephei,2020-11-03T22:38:42Z,"it's normally kinda weird to merge commented-out code. i'd either delete it or instead have a todo, like `// todo kafka-xxxx: add case replace_stream_thread once kip-? is implemented`, where `kafka-xxxx` is a follow-up ticket you create to implement this feature.",-1,0.9621679186820984
516998180,9487,vvcephei,2020-11-03T22:41:56Z,"[code block] just a little extra information, so we don't always have to pull up this code block to remember what exact response action this message corresponds to.",0,0.9793729186058044
517009538,9487,vvcephei,2020-11-03T23:11:46Z,[code block] didn't follow the prior message. is this what you meant?,0,0.9854843020439148
517009778,9487,vvcephei,2020-11-03T23:12:30Z,[code block] similar confusion here...,0,0.9718409180641174
517012283,9487,vvcephei,2020-11-03T23:20:08Z,"this doesn't look like an ""error"". at best it's a ""warn"" log, but only if we think that this combination definitely looks like a misconfiguration. even then, why wouldn't we check for the misconfiguration in kafkastreams, since both the new and old handlers would be set over there?",0,0.9821068644523621
517012839,9487,vvcephei,2020-11-03T23:21:52Z,[code block] this looked a bit off...,0,0.9764652848243713
517013547,9487,vvcephei,2020-11-03T23:24:09Z,it doesn't look like this needs to be shared outside of this thread. it seems like it just needs to be shared between the streamthread and its consumer?,0,0.9834209084510803
517464968,9487,cadonna,2020-11-04T16:19:46Z,could you please also add the needed changes to system test `streams_upgrade_test.py::streamsupgradetest.test_version_probing_upgrade` to this pr.,0,0.9945512413978577
517474129,9487,cadonna,2020-11-04T16:32:17Z,"i guess this should be 2.8.0, shouldn't it?",0,0.9845135807991028
517481718,9487,wcarlson5,2020-11-04T16:43:03Z,i don't remember putting it there so it was probably a mistake,0,0.8519883155822754
517485257,9487,wcarlson5,2020-11-04T16:48:10Z,that works,0,0.9653556942939758
517486135,9487,cadonna,2020-11-04T16:49:27Z,i would also remove the commented-out code.,0,0.9871196746826172
517505173,9487,cadonna,2020-11-04T17:18:01Z,wouldn't it also be possible to start a shutdown thread here which closes the client without timeout? i think the other shutdown thread in close is rather useless (or i do simply not get its value).,0,0.8606199622154236
517507950,9487,cadonna,2020-11-04T17:22:26Z,"imo, it would be better to extract code to methods instead of removing some lines.",0,0.9912081956863403
517543638,9487,ableegoldman,2020-11-04T18:22:10Z,can you also leave a comment here reminding us to fix the version probing system test whenever this protocol number is bumped? since we apparently always forget,0,0.9920194745063782
517576758,9487,wcarlson5,2020-11-04T19:20:51Z,i think it is simpler to check in the stream thread because we don't in kafkastreams if the handlers have been set so we would have to check the stream thread a global thread so it would be much easier to just check in the thread. i do agree that it should be bumped down to warn through.,0,0.979209303855896
517621757,9487,wcarlson5,2020-11-04T20:47:05Z,you are right it seems that it is not necessary,0,0.9672901630401611
517627843,9487,wcarlson5,2020-11-04T20:59:16Z,"thanks for the reminder. i think i i under stood the test ad incrementing to the next version, as the version is now 9",1,0.9718989133834839
517909467,9487,cadonna,2020-11-05T09:32:23Z,is this comment correct? in this code path we do not check that all threads have been stopped.,0,0.9915255904197693
517910538,9487,cadonna,2020-11-05T09:34:07Z,could you also remove the commented-out code here.,0,0.9897862672805786
517916345,9487,cadonna,2020-11-05T09:43:22Z,the name is a bit ambiguous. i would go for `streamsuncaughtexceptionhandlerintegrationtest`,0,0.5407142639160156
517993498,9487,cadonna,2020-11-05T11:51:47Z,"what is the benefit of using a latch versus simply sleeping here? actually, you should use `streamstestutils.startkafkastreamsandwaitforrunningstate()` to avoid flakiness coming from the kafka streams client not being in state running before the verifications.",0,0.9921120405197144
517995934,9487,cadonna,2020-11-05T11:55:58Z,[code block] an application is actually a group of kafka streams clients (or instances).,0,0.9935240745544434
518008710,9487,cadonna,2020-11-05T12:19:08Z,you could wait for this flag to become true with `testutils.waitforcondition()` before you verify the other criteria.,0,0.9921446442604065
518010780,9487,cadonna,2020-11-05T12:23:05Z,why do clean the state twice?,0,0.963731050491333
518014119,9487,cadonna,2020-11-05T12:29:10Z,why do you need to set all these properties?,0,0.977456271648407
518021251,9487,cadonna,2020-11-05T12:41:57Z,i would remove these comments.,0,0.9455108046531677
518033723,9487,cadonna,2020-11-05T13:03:05Z,"i had a hard time to understand this. we write just one record to the topic, but we end up processing two records. this is true, because we use two stream threads and there is no commit between the processing of the record of the first stream thread and the processing of the second stream thread. why do you use two stream threads here?",-1,0.8287851214408875
518035301,9487,cadonna,2020-11-05T13:05:41Z,most of the above comments also apply to the other tests.,0,0.9882524609565735
518039024,9487,cadonna,2020-11-05T13:11:58Z,"why are those fields all package-private instead of private? we usually define string constants as `private static final string idempotent_topic = ""idempotenttopic""`.",0,0.9954261183738708
518042865,9487,cadonna,2020-11-05T13:18:06Z,i do not understand the motivation behind this topic. could you clarify?,-1,0.6779135465621948
518044472,9487,cadonna,2020-11-05T13:20:37Z,unit tests for this case are missing.,0,0.9756157994270325
518263368,9487,wcarlson5,2020-11-05T18:14:44Z,yes,0,0.9659429788589478
518263937,9487,wcarlson5,2020-11-05T18:15:40Z,it might be but i do not think that it is necessary,0,0.9391682744026184
518264927,9487,wcarlson5,2020-11-05T18:17:21Z,i don't think we actually need it either way so i will just remove it,0,0.8437159061431885
518265803,9487,wcarlson5,2020-11-05T18:18:47Z,sure,0,0.9137381911277771
518267956,9487,wcarlson5,2020-11-05T18:22:27Z,"thats a good idea, i didn't see that option",1,0.8818028569221497
518269493,9487,cadonna,2020-11-05T18:25:11Z,"why not? it would be much cleaner. we would close all stuff like admin client and the metrics, remove the client metrics and set the state to not_running which is not necessarily done with timeout zero (probably not because of the death lock). additionally, we would get an nice info debug saying `streams client stopped completely` instead of `streams client cannot stop completely within the timeout`. ;-)",1,0.8963268399238586
518271215,9487,wcarlson5,2020-11-05T18:28:06Z,good idea,1,0.9759455323219299
518271918,9487,wcarlson5,2020-11-05T18:29:17Z,we probably don't need all of them. i will trim them down,0,0.9486991763114929
518274359,9487,wcarlson5,2020-11-05T18:33:24Z,i use 2 threads there to make sure the old behavior is being followed. just one thread dies and then the next thread is tries. the second thread makes sure that the new path is not closing the client unintentionally.,0,0.9396248459815979
518283539,9487,cadonna,2020-11-05T18:49:19Z,my last comment is not true! sorry! everything alright!,-1,0.9937286376953125
518326776,9487,wcarlson5,2020-11-05T19:55:10Z,actually the latch ensures the rebalance gets processed,0,0.9889616370201111
518335631,9487,wcarlson5,2020-11-05T20:11:16Z,it can be removed,0,0.983828067779541
518371511,9487,wcarlson5,2020-11-05T21:17:19Z,added unit test,0,0.9745031595230103
518371722,9487,wcarlson5,2020-11-05T21:17:33Z,good questions,1,0.9794450402259827
518478117,9487,ableegoldman,2020-11-06T01:55:29Z,"i had a little trouble following the `handler` class. some trivial things -- eg the handler in the streamthread is named `streamsuncaughtexceptionhandler` but it's actually _not_ a `streamsuncaughtexceptionhandler`. also the usage of the return value; iiuc it's supposed to indicate whether to use the new handler or fall back on the old one. to me it sounds like if `handle` returns `true` that means we should handle it, ie we should _not_ rethrow the exception, but this looks like the opposite of what we do now. honestly either interpretation is ok with me, as long as it's documented somewhere do we really need the `handler` in the first place though? it's already pretty confusing that we have to deal with two types of handlers (old and new) so i'd prefer not to add a third unless it's really necessary. it seems like we can just inline the logic of whether to invoke the new handler or rethrow the exception, which would also clear up the confusion around the meaning of the return value. but i might be missing something here -- wdyt?",0,0.5738784074783325
518479524,9487,ableegoldman,2020-11-06T01:59:50Z,seems like we can just pass in a runnable with `kafkastreams::closetoerror` instead of adding a whole `shutdownerrorhook` functional interface,0,0.9946737289428711
518483194,9487,ableegoldman,2020-11-06T02:12:42Z,should this be logged at error?,0,0.9876426458358765
518484271,9487,ableegoldman,2020-11-06T02:16:48Z,"looks like we call `setstate(error)` three times in this method, is that intentional?",0,0.9904680848121643
518485280,9487,ableegoldman,2020-11-06T02:20:24Z,"it probably doesn't matter too much since `handlerebalancecomplete` doesn't do anything that important at the mometn, but it seems like we should call it before shutting down, not after.",0,0.9685206413269043
518485749,9487,ableegoldman,2020-11-06T02:22:02Z,this should probably stay `final` so we don't accidentally change it ever,0,0.9848304986953735
518488577,9487,ableegoldman,2020-11-06T02:32:29Z,"this cast makes me kind of uncomfortable...either the `assignmenterrorcode` that we have in the assignmentinfo is conceptually the same as the one we're adding to the subscriptioninfo (in which case it should be the same type), or it's not the same, in which case we should use a different variable to track it. personally i think it's probably simpler to keep them the same, and just add an `int` errorcode field to the subscription instead of a `byte` shutdownrequested field. but it's your choice",-1,0.9233778715133667
518489261,9487,ableegoldman,2020-11-06T02:35:01Z,"i think we should mirror the `errorcode` in the assignmentinfo here, both in terms of naming and type. if we're going to use the same assignorerror for both, then they should really be the same. and we may want to send other kinds of error codes in the subscription going forward: better to just encode a single `int` than a separate `byte` for every logical error code. i don't think we'll notice the extra three bytes since subscriptions aren't sent that frequently",0,0.9687128663063049
518837250,9487,wcarlson5,2020-11-06T15:46:47Z,we could do the logic inline how ever this does make it slightly simpler. also we only expose the `streamsuncaughtexceptionhandler` to the user and had a problem with the wrapping that again with the same type. so we introduced a wrapper class. if we renamed it from `handler` to `streamsuncaughtexceptionhandlerwrapper` would that make it more clear?,0,0.9919614195823669
518838421,9487,wcarlson5,2020-11-06T15:48:45Z,in the normal close method the corresponding log is also info. as multiple thread will be calling this at once i would rather not flood the logs with error unnecessarily.,0,0.9351935982704163
518838586,9487,wcarlson5,2020-11-06T15:49:01Z,"no, i hadn't seen that",0,0.7818903923034668
518840121,9487,wcarlson5,2020-11-06T15:51:21Z,"we can do that, it doesn't seem make difference which order it is called. however if it is not called it will get stuck continually rebalancing. we return because setting the state to partitions assigned will cause an error",0,0.8630064129829407
518840602,9487,wcarlson5,2020-11-06T15:52:00Z,i was changing it intentionally but i think i can get away with not,0,0.8807333111763
518842747,9487,wcarlson5,2020-11-06T15:55:21Z,yes we can,0,0.9449439644813538
518850419,9487,wcarlson5,2020-11-06T16:08:05Z,"i think i agree on the name, i am not sure about the type. we should be able to fit thousands of different error code into the byte so we should not run out of space. the reason the errorcode. is an integer in the first place is because there is not `atomicbyte` that i know of.",0,0.9568043351173401
518913514,9487,ableegoldman,2020-11-06T17:57:36Z,"gotcha. in that case maybe we shouldn't log anything here at all? or just reword it to clarify that this is expected (eg `""skipping shutdown since we are already in error""`) since ""can not transition..."" kind of sounds like something went wrong",0,0.9561522006988525
518938852,9487,wcarlson5,2020-11-06T18:47:09Z,"that is a good idea, ill change the log",1,0.9724164605140686
520077048,9487,ableegoldman,2020-11-09T19:47:31Z,"i'm not really worried that we'd run out of space, i just think it sends a signal that the assignment and subscription error codes are semantically distinct and don't refer to the same underlying concept. so it seems better to go with the simpler approach than over-optimize to save an occasional three bytes",0,0.803547739982605
520104884,9487,wcarlson5,2020-11-09T20:38:03Z,"[a link] i originally had it at int32, but suggested int16, now it is int8. would you be good with int16 or do you think int32 is the way?",0,0.9845922589302063
522596527,9487,ableegoldman,2020-11-13T03:51:22Z,this wording is a little difficult to parse,-1,0.8738759756088257
522597486,9487,ableegoldman,2020-11-13T03:55:34Z,"just curious, what's the motivation for doing it like this vs just immediately throwing the exception?",-1,0.6538986563682556
522598008,9487,ableegoldman,2020-11-13T03:57:50Z,nit: parameters unaligned,0,0.9556306600570679
522598142,9487,ableegoldman,2020-11-13T03:58:34Z,that's a lot of line breaks :upside-down_face:,-1,0.7982545495033264
522598707,9487,ableegoldman,2020-11-13T04:00:50Z,is everything after this line the same as the code in the regular `close()`? might be a good idea to move it to a separate method so we don't accidentally forget to update one of them if we ever need to make changes to how we close,0,0.9936368465423584
522613334,9487,ableegoldman,2020-11-13T04:26:45Z,"it seems like we shouldn't both handle the exception in the catch block and shut down the client in the finally block. if the new handler is used, then we've already shut down the client or possibly started to shut down the whole application. it's tricky, though, because if the old handler was used then we _do_ want to make sure that the global thread is all cleaned up before rethrowing the exception. seems like we need some way to detect whether we're using the old or the new handler after all. but i think you can do it without too many changes, since basically the rule is ""if they set a new handler at all or didn't set either handler, then use the new one"". so maybe you can just make the `streamsuncaughtexceptionhandler` a local field instead of the `consumer<>`, and leave it as `null` to indicate that the old handler should be used and therefore this shutdown logic should be invoked. otherwise just call the new handler directly. or something like that...you'd know this code better than me, wdyt?",0,0.949155330657959
522616515,9487,ableegoldman,2020-11-13T04:30:37Z,"hmm...this one seems like it should be a fatal error, so is it safe to just pass it along to the user and let them potentially just keep replacing the thread? (i know that option doesn't exist yet, but it will). there are some instances where we interpret errors as permanently fatal and choose to shut down the entire application, eg some errors during assignment. should we do the same here? cc or for more context on this error",0,0.84835284948349
522622229,9487,ableegoldman,2020-11-13T04:37:49Z,i think we should add the `errorcode` parameter to the existing constructor rather than add a new one. it shouldn't be possible to construct a version 9 subscription that doesn't have an `errorcode`,0,0.9918506741523743
522622882,9487,ableegoldman,2020-11-13T04:38:35Z,"nice, thanks for the comment. btw anytime we bump this protocol version we should add the corresponding unit tests, eg `subscriptioninfotest#shouldencodeanddecodeversion8()`",1,0.9710663557052612
522626697,9487,ableegoldman,2020-11-13T04:43:11Z,"does the comment relate to the `` suppression? either way this probably makes more sense as a comment on the pr than in the code. given how bad we are about updating comments, i'd try to avoid anything that describes a change and reserve code comments for describing what's currently going on (or better yet, ""why"")",0,0.8831146359443665
522627296,9487,ableegoldman,2020-11-13T04:43:39Z,"same here, what is the comment referring to? also what does it mean for a test to be deprecated :thinking_face:",0,0.9770227670669556
522635059,9487,ableegoldman,2020-11-13T04:49:40Z,ditto here,0,0.9701400399208069
522639947,9487,ableegoldman,2020-11-13T04:55:41Z,"is the latch ever being counted down anywhere? you might want to take a look at some of the test utils, there's a lot of useful stuff so you don't have to implement everything from scratch. if you just want to make sure that the client gets to `closed` within 15s then i'd recommend `testutils#waitforcondition`",0,0.9808117151260376
522641072,9487,ableegoldman,2020-11-13T04:57:10Z,is this the only property that changed? might be clearer if you just override what you need to here,0,0.9905367493629456
522650704,9487,ableegoldman,2020-11-13T05:09:14Z,"we should probably use an actual handler here to make sure it works with the globalthread. actually maybe we should add a few unit tests here to make sure that it closes down and rethrows when the old handler is used, but handles the exception internally when the new handler is used, etc",0,0.9940245747566223
522654080,9487,ableegoldman,2020-11-13T05:13:23Z,why set the exception handler in this test and no others?,0,0.976403534412384
523028163,9487,cadonna,2020-11-13T15:35:28Z,"nit: usually we indent 4 spaces, not 8.",0,0.9799461960792542
523034271,9487,cadonna,2020-11-13T15:45:11Z,"are you sure this is the correct method to call? as far as i understand the the javadocs and the decompiled code, this method does not return the handler you can set on a `thread` with `setuncaughtexceptionhandler()`.",0,0.9943485856056213
523041454,9487,cadonna,2020-11-13T15:56:14Z,"i guess, you wanted to do this [code block]",0,0.9823700189590454
523041842,9487,cadonna,2020-11-13T15:56:53Z,please use a more meaningful parameter name.,0,0.9883302450180054
523044111,9487,cadonna,2020-11-13T16:00:23Z,"i still have a question here. since the stream thread is alive when it calls `close()` there will not be a deadlock anymore. so, why do we call `close()` with duration zero?",0,0.9383357167243958
523069611,9487,wcarlson5,2020-11-13T16:40:19Z,changed to ` in order to get the thread uses use thread.currentthread()` does that work better?,0,0.99483323097229
523070844,9487,wcarlson5,2020-11-13T16:42:18Z,we have to do the casting in order to throw the exception. otherwise the compiler complains about checked vs unchecked exceptions,0,0.9486212134361267
523072781,9487,wcarlson5,2020-11-13T16:45:31Z,yes good catch,1,0.94463711977005
523073595,9487,wcarlson5,2020-11-13T16:46:49Z,that is a lot of line breaks,0,0.5683317184448242
523079456,9487,wcarlson5,2020-11-13T16:56:05Z,everything except the state we leave it in. we can move most of it to a helper,0,0.9855526089668274
523079965,9487,wcarlson5,2020-11-13T16:56:55Z,we should be able to change it to `close()`,0,0.9930369257926941
523080590,9487,cadonna,2020-11-13T16:57:57Z,"the name is a bit confusing. the best i could come up is `handlestreamsuncaughtexceptionbydefault()`, but i am sure there is a better name.",-1,0.893779456615448
523089743,9487,vvcephei,2020-11-13T17:06:49Z,"if that's the case, then we really should just set a flag on kafkastreams to indicate whether that handler has been set.",0,0.9923227429389954
523090161,9487,wcarlson5,2020-11-13T17:07:04Z,there is a logic to use the old handler if the conditions you laid out are true. the odd series of casts of exception types in `handlestreamsuncaughtexceptiondefaultwrapper` are what makes this happen. this is a bit tricky but i think we want to close the client either way. as we don't have plans to replace the global thread and shutting down the application is best effort. we talked about this a while back and we decided the global handler was mainly for information and the return type we would try to follow but we need to make sure we at least close the client.,0,0.7985187768936157
523095231,9487,wcarlson5,2020-11-13T17:10:31Z,i think this is fine for now. when we add replace thread as an option we can include overrides when handling the response that prevent the thread from being restarted in certain error cases.,0,0.9772896766662598
523103147,9487,wcarlson5,2020-11-13T17:21:13Z,when we remove the old handler we either need to remove the test or remove the suppression. that is what i am hoping the comment will do,0,0.9692660570144653
523109393,9487,wcarlson5,2020-11-13T17:28:41Z,"i'll add that to the comment, and add a test",0,0.9884310960769653
523136568,9487,wcarlson5,2020-11-13T18:14:59Z,how about `defaultstreamsuncaughtexceptionhandler`?,0,0.994674801826477
523138325,9487,wcarlson5,2020-11-13T18:17:29Z,we can just set a flag through to be safe,0,0.9846187233924866
523141998,9487,wcarlson5,2020-11-13T18:21:29Z,same as above,0,0.965356171131134
523230140,9487,wcarlson5,2020-11-13T21:01:25Z,"so the problem that i am facing is that many tests are set up to work with the old handler. i was able to adapt most to use the new handler but not all. some, like a few eos tests, require one thread to die at a time. so i either suppress the deprecation or tag the test as deprecated, thus indicating it should be removed when the old handler is. another problem is that a few tests rely on the threads dying one at a time or they test behavior in this case but they do not set an old handler. so i can either 1) set an old handler and mark for deletion or 2) adapt for the new out come. for the ones i could, i changed to the new flow but i could not do that with all of them. how would you suggest updating these tests?",0,0.7834300398826599
523277374,9487,wcarlson5,2020-11-13T23:04:52Z,because otherwise the task migrated exception sends it into a endless rebalance,0,0.7175900340080261
523280093,9487,wcarlson5,2020-11-13T23:14:47Z,that is useful thanks. i went with `waitforapplicationstate`,1,0.9829109311103821
523280707,9487,wcarlson5,2020-11-13T23:17:00Z,agree,0,0.9753760099411011
523288678,9487,wcarlson5,2020-11-13T23:49:17Z,for the same reason i had to add to the other cases as the close from the new handler will not finish otherwise,0,0.9665114283561707
523296833,9487,ableegoldman,2020-11-14T00:16:51Z,is there an extra `uses` in there or am i not looking at this sentence from the right angle?,0,0.9799845814704895
523302976,9487,ableegoldman,2020-11-14T00:47:17Z,"ah ok i thought we executed this cleanup logic in the globalstreamthread's `shutdown` method but now i see that's not true. sorry for the confusion there. i do see some minor outstanding issues here, mainly around the state diagram. let's say the user opts to `shutdown_client` in the new handler: the intended semantics are to end up in `not_running` but i think what would happen is that from the global thread we would immediately call `kafkastreams#close` , which kicks off a shutdown thread to wait for all threads to join and then sets the state to `not_running`. then when the handler returns, it would transition the global thread to `pending_shutdown` and then finally to `dead`. and during the transition to `dead`, we would actually end up transitioning the kafkastreams instance to `error`, rather than `not_running` as intended. so probably, we just need to update the `onchange` method in kafkastreams. this also reminds me of another thing, we need to update the fsm diagram and allowed transitions in kafkastreams to reflect the new semantics we decided on for error (which iirc is basically just to make it a terminal state). does that sound right to you?",-1,0.9853224754333496
523303062,9487,ableegoldman,2020-11-14T00:47:52Z,"i suspect the tests didn't catch this because we would still transition out of error to pending_shutdown and finally not_running in this case. but really, we shouldn't transition to error in the first place",0,0.9190817475318909
523311219,9487,ableegoldman,2020-11-14T01:05:18Z,"what happens if we try to read the error code of an earlier subscription version? i genuinely don't know what the generated code does, but we should make sure it doesn't throw an npe or something. could you add a unit test for this case?",0,0.7887635827064514
523319677,9487,ableegoldman,2020-11-14T01:15:05Z,"i think any test that's trying to verify some unrelated behavior and just using the ""one thread dies at a time"" paradigm as a tool to do so should not be deleted. i'm sure in most if not all cases, there's some way to modify the test to verify that specific behavior either using the new handler or multiple apps or rewriting it altogether. but, there are a lot of tests that do this and a lot of them are pretty tricky, so i wouldn't want to stall this pr on waiting for all of these tests to be updated/adapted. i think we should file tickets for all of these tests and just try to pick up one or two of them every so often. maybe that's being overly optimistic about our inclination to pick up small tasks even over a long period, but it's better than losing track of them altogether. wdyt?",-1,0.8177663683891296
523322776,9487,ableegoldman,2020-11-14T01:18:45Z,but taskmigratedexception should never be thrown all the way up to the exception handler. is that what you're seeing?,0,0.9644452929496765
523327104,9487,wcarlson5,2020-11-14T01:23:46Z,i appreciate the benefit of the doubt :) but you are right there is an extra `uses`,1,0.9959419369697571
523327338,9487,ableegoldman,2020-11-14T01:24:03Z,"well it's not exactly a default, technically this method is always used to decide which handler to invoke (which may or may not invoke a default handler). any of these would be fine by me but i'll throw one more idea out there: `invokeoldornewuncaughtexceptionhandler`",0,0.9902935028076172
523334335,9487,wcarlson5,2020-11-14T01:32:21Z,"i don't think it will actually transition to `error` because the handler will call close before the global thread is dead, which will transition to peding_shutdown, there is no transition to error from either pending_shutdown or not_running. the fsm will be part of the add thread work as it doesn't really make sense to remove the change to error until we can add threads",0,0.9881629347801208
523334732,9487,wcarlson5,2020-11-14T01:35:22Z,i agree we shouldn't remove the valid test cases. maybe the ones that are more complicated i can just set an idempotent old handler and mark as deprecated and we can file tickets to update. either we work them down or when we go to remove the old handler they will fail and we need to fix them then.,0,0.975886344909668
523337226,9487,wcarlson5,2020-11-14T01:52:07Z,not quite. if i remove the handler and just run it there is an illegal state exception which runs endlessly until the handler can exit the loop. it looks like the thread hadn't started all the way before the taskmigratedexcpetion is thrown `info state transition from starting to pending_shutdown (org.apache.kafka.streams.processor.internals.streamthread:223) [`,0,0.9513139128684998
523337785,9487,wcarlson5,2020-11-14T01:56:35Z,good idea. it does not seem to do anything. but good to have a test for it,1,0.9852762818336487
523372464,9487,ableegoldman,2020-11-14T04:08:25Z,"ah ok so there's some other illegalstateexception that would get swallowed if we just used `e -> {}` like in the other tests, so we need to explicitly rethrow it? that seems fine, although it makes me think that we should go ahead and use a ""real"" handler in _all_ of the tests, not just this one. otherwise there could be some bug which causes an unexpected exception, but the test would just swallow it and silently pass. can we just use the default handler wrapper for all of these tests so they reflect realistic scenarios?",0,0.9446529746055603
523375614,9487,ableegoldman,2020-11-14T04:45:56Z,"oh you're totally right, sorry for letting my paranoia start spreading conspiracy theories here :slightly_smiling_face: given all this i'd still claim that the fsm is in need to being cleaned up a bit (or a lot), but if you'd prefer to hold off on that until the add thread work then i'm all good here. thanks for humoring me and explaining the state of things. i just wanted/want to make sure we don't overlook anything, since there's a lot going on. for example in the current code, if the global thread dies with the old handler still in use then we'll transition to error. however the user still has to be responsible for closing the client themselves, and it will ultimately transition from error to not_running. whereas if we transition to error as the result of a shutdown_application error code, the user should not try to invoke close themselves, and the error state will be terminal. that's pretty confusing eg for users who use a state listener and wait for the transition to error to call close(). we should make sure that error has the same semantics across the board by the end of all this work. anyways i'm just thinking out loud here, to reiterate i'm perfectly happy to merge this as-is. but for reasons like the above, i think it's important to tackle the fsm in the next pr and make sure it all gets sorted out by the next ak release",-1,0.9492537975311279
524433881,9487,wcarlson5,2020-11-16T17:11:38Z,it's actually not always used. it is only used until a new handler is set in which it is over written. once that happens we don't want the old handler to be set so we do not wrap a user provided handler with this method,0,0.9714580178260803
524435241,9487,wcarlson5,2020-11-16T17:13:23Z,"the default is in kafkastreams, but i see your point. we can make all of them rethrow then we will not have to worry about swallowing",0,0.9722632765769958
524437940,9487,wcarlson5,2020-11-16T17:17:31Z,"+1 to sorting out fsm before next release, i have a ticket to track the work. i started to change it and it ballooned out to be much more expansive than i thought. this pr is already complicated enough, so we can add is later.",0,0.8026728630065918
524447256,9487,vvcephei,2020-11-16T17:30:29Z,i think i'd personally still prefer the non-blocking version. it seems better to avoid blocking indefinitely when a thread is trying to shut itself down due to some unknown exception (or error).,0,0.960176408290863
524448160,9487,vvcephei,2020-11-16T17:31:54Z,"likewise, here, it seems better to do a non-blocking close.",0,0.9868978261947632
524475389,9487,vvcephei,2020-11-16T18:14:59Z,"personally, as long as users have the information available to understand the nature of the error, it's fine to let them make their own decision about how to handle it. maybe another team is in the middle of a broker upgrade, for example, and the owner of this app would like to just keep trying until the broker team gets it together.",0,0.9885097146034241
524478717,9487,vvcephei,2020-11-16T18:20:34Z,i think i'd like to re-raise sophie's concern here. it doesn't compute for me why we are casting an int to a byte here..,0,0.8400273323059082
524487609,9487,wcarlson5,2020-11-16T18:35:22Z,"that is probably fine. we can really get into it when we add the replace option, as now all calls to the handler are fatal.",0,0.9059137105941772
524490211,9487,wcarlson5,2020-11-16T18:39:34Z,"it doesn't really matter to me, though i think that non blocking is probably preferable.",0,0.9161645770072937
524540416,9487,wcarlson5,2020-11-16T20:06:47Z,i guess i must have misunderstood your earlier comment. i thought you wanted it to stay a byte so that is why i pushed back. but if you have no objections i will just change it,0,0.5830878019332886
524814932,9487,ableegoldman,2020-11-17T00:56:33Z,"that's a fair point about broker upgrades, but don't we require the brokers to be upgraded to a version that supports eos _before_ turning on eos-beta? anyways i was wondering if there was something special about this exception such that ignoring it could violate eos or corrupt the state of the program. i'll ping the eos experts to assuage my concerns",0,0.9043019413948059
524817135,9487,ableegoldman,2020-11-17T01:03:03Z,"can you clarify? i thought we would still be in danger of deadlock if we use the blocking `close()`, since `close()` will not return until every thread has joined but the streamthread that called `close()` would be stuck in this blocking call and thus never stop/join",0,0.9483746290206909
524819063,9487,ableegoldman,2020-11-17T01:08:55Z,"just to clarify i think it's ok to leave this as-is for now, since as walker said all handler options are fatal at this point",0,0.9848142266273499
524824649,9487,ableegoldman,2020-11-17T01:25:57Z,"mm ok actually i think this should be fine. i was thinking of the handler as just ""swallowing"" the exception, but in reality the user would still let the current thread die and just spin up a new one in its place. and then the new one would hit this unsupportedversionexception and so on, until the brokers are upgraded. so there shouldn't be any way to get into a bad state",0,0.7994441986083984
525161434,9487,cadonna,2020-11-17T13:41:49Z,"ok, i think you are right. i focused too much on [code block] without considering that before the stream threads are shutdown which makes them not running. in the meantime, i understood a bit better the motivation of the shutdown thread in `close()`. the shutdown thread ensures that the timeout is still consiered in case `close()` is called by a stream thread. i think we should revisit it. but that is outside the scope of this pr. to unblock this pr, i am fine with `close(duration.zero)`, but i have the feeling we could do better.",0,0.6862637996673584
525169791,9487,cadonna,2020-11-17T13:52:01Z,there is something wrong in this sentence.,0,0.6593421101570129
525170922,9487,cadonna,2020-11-17T13:53:37Z,`oldhanlder` -> `oldhandler`,0,0.9925605058670044
525194549,9487,cadonna,2020-11-17T14:26:06Z,nit: remove line,0,0.9777287840843201
525442248,9487,wcarlson5,2020-11-17T19:41:19Z,oops,-1,0.9215677976608276
525444958,9487,wcarlson5,2020-11-17T19:43:34Z,need to remove `use`,0,0.9926530122756958
525636554,9487,ableegoldman,2020-11-18T01:32:09Z,i think it makes more sense to transition to error in this case than to not_running. but let's put this on file with the other fsm-related work planned for following prs,0,0.9885790348052979
525640088,9487,ableegoldman,2020-11-18T01:43:12Z,"why do we shut down the global thread only after all stream threads have completed their shutdown? seems like it would be more efficient to send the shutdown signal to everyone first, and then wait for all the threads to join. can you try this out in the followup pr?",0,0.9911501407623291
525650632,9487,ableegoldman,2020-11-18T02:14:15Z,"i just realized that this is going to be a problem with the way the error state is being used. if we `closetoerror` then we transition to error and shut down, however `error -> pending_shutdown` is still an allowed transition so there's nothing to prevent the shutdown from being triggered again when a user calls `close()`. and note that a lot of users most likely have a state listener at the moment which does exactly that, ie when it sees a transition to error it immediately invokes close (because that's what you should do with the current semantics) just another thing that i think we can fix with some minor rewiring of the fsm.",0,0.9772418737411499
525658639,9487,ableegoldman,2020-11-18T02:23:10Z,"hm ok this might be a problem. since this is thrown from another catch block and not from the try block, it won't be caught by the catch block below and will slip through the exception handler.",0,0.9356818795204163
525663640,9487,ableegoldman,2020-11-18T02:28:30Z,we should remember to update the wording here when we add the replace_thread functionality,0,0.99265056848526
525678234,9487,wcarlson5,2020-11-18T02:44:07Z,you are right i think. i just copied from the normal close method because i knew it worked. in a follow up we can maybe change both of these. do you think that there should be a ak ticket to track it?,0,0.9319191575050354
525680874,9487,wcarlson5,2020-11-18T02:46:55Z,i am on the fence about this. i do think its would be consistent to be not running but also it did shutdown cleanly. we made this choice when error still meant all threads had died and that is not true now. in the end i just went with what we had in the kip rather than try to change it. though i could be swayed to leave this in error.,0,0.7754117846488953
525681642,9487,wcarlson5,2020-11-18T02:47:48Z,this is currently the plan to remove that transition. it is pretty much the only change we plan to make to the fsm.,0,0.9839667677879333
525686843,9487,wcarlson5,2020-11-18T02:53:20Z,like in stream thread we can just add a call to the handler,0,0.9923179149627686
525692960,9487,ableegoldman,2020-11-18T02:59:37Z,"eh, i wouldn't bother with an ak ticket if this will be tackled in the next pr. i'll just make a list of all the minor followup work somewhere to keep track",0,0.9431127905845642
525701691,9487,ableegoldman,2020-11-18T03:06:40Z,"that's fair. i guess i was thinking less about the inherent meaning of error vs not_running, and more about not behaving differently in this special case. ie if there _are_ still streamthreads running when a user selects shutdown_application, then we ultimately transition to error. so it strikes me as a bit odd to transition to not_running just because we didn't happen to have any threads left.",0,0.4519294202327728
525734417,9487,ableegoldman,2020-11-18T03:30:18Z,"wdyt about having both not_running and error go through pending_shutdown, rather than just transitioning directly and permanently to error? at a high level i think it just makes sense for error and not_running to be symmetric. also any benefit to having an intermediate pending_shutdown for the not_running case presumably applies to the error case as well. eg, it indicates whether streams has completed its shutdown or not: users know that an app in pending_shutdown should never be killed, its only safe to do so once it reaches not_running. we should provide the same functionality and only transition to error after the shutdown is complete",0,0.9765713214874268
526211409,9487,wcarlson5,2020-11-18T16:08:54Z,"i do think that error should not have direct transition. however i don't like using `pending_shutdown` , mostly because we can already distinguish between the two states and it would be best to inform right away. also it could be a problem if we went to set error and some how it went from pending_shutdown to not_running. i am in favor of adding something like `pending_error` just to be more precise.",0,0.8791021108627319
526477258,9487,ableegoldman,2020-11-18T22:53:15Z,sounds reasonable,0,0.9049308896064758
665553313,10851,vlsi,2021-07-07T17:00:34Z,i guess it would be better to move the assignment to the field declaration to avoid duplication among constructors.,0,0.9876102209091187
665561377,10851,vlsi,2021-07-07T17:12:31Z,can you please clarify why `treemap ` is used here? would `map ` suffice?,0,0.9940947890281677
669473299,10851,cadonna,2021-07-14T10:05:18Z,i was wondering whether we can simply standby assignment if `configs.numstandbyreplicas == 0`. here or as first step in the method body of `assignstandbyreplicatasks()`. in this way we can remove `noopstandbytaskassignor`.,0,0.9945395588874817
669496452,10851,cadonna,2021-07-14T10:41:19Z,"as far as i can see, this map is only used in `clienttagawarestandbytaskassignor` and it is only used to iterate over pairs (taskid, uuid). that can also be accomplished by iterating over the client states and for each client state iterate over the assigned active tasks. i do not think that we need to modify the signature of `assignactivestatefultasks()`. or am i missing something?",0,0.9907981157302856
669500118,10851,cadonna,2021-07-14T10:47:36Z,i think it should be `sortedmap` instead of `treemap`. i also saw that we sometimes missed to use `sortedmap` instead of `treemap` in some signatures. it needs to be a sorted map because the assignments should be stable otherwise it could happen that we compute different assignments for the same input which could lead to unnecessary state migrations.,0,0.9918728470802307
669504412,10851,cadonna,2021-07-14T10:54:30Z,why do we need this internal class? wouldn't it be simpler to structure the code with methods directly under `clienttagawarestandbytaskassignor`?,0,0.994586706161499
669849371,10851,lkokhreidze,2021-07-14T18:20:28Z,"thanks for the feedback bruno. i reasoned that, since internal states like `clientspertagvalue`, `standbytaskclientsbytaskload`, etc., have to be allocated per invocation of `assignstandbytasks` method, it felt easier and more readable to create one single internal object rather than invalidating local caches in `clienttagawarestandbytaskassignor`.",1,0.975033164024353
669851397,10851,lkokhreidze,2021-07-14T18:23:36Z,"i tried to avoid unnecessary iterations. with that we would have to do separate iteration in the `clienttagawarestandbytaskassignor`, which felt redundant, since `assignactivestatefultasks` can return necessary mapping since it has to iterate over client states either way.",0,0.9918732047080994
669853519,10851,lkokhreidze,2021-07-14T18:26:40Z,i didn't give it much thought to be honest. `treemap` for the `clientstates` was already used in the `highavailabilitytaskassignor` and went with the same signature here. i think it makes sense to change the contract to be a `sortedmap`. will do that.,0,0.9595021605491638
669865915,10851,lkokhreidze,2021-07-14T18:45:48Z,sure! done. personal preference. having all the strategies of standby task assignment implementations in a single class makes unit testing a bit easier. but i do agree that removing one extra class is indeed good idea.,1,0.9747321009635925
670294370,10851,cadonna,2021-07-15T09:27:04Z,"yes, the `treemap` in the signatures has been already there before this pr. thank you for fixing this!",1,0.9771286249160767
670309425,10851,cadonna,2021-07-15T09:47:08Z,"as far as i can see, we would iterate only over the active tasks in both cases. the difference is that in case we have one loop and in the other we have two nested loops. in the nested loop case, the code in the innermost loop is executed the same number of times as in the one loop case. that is, as many times as the number of active tasks. in general, i would not change too much code for a performance improvement before we hit a performance issue. you know, as donald e. knuth stated ""premature optimization is the root of all evil"". :slightly_smiling_face:",1,0.9064991474151611
670332282,10851,cadonna,2021-07-15T10:18:49Z,"method `assignstandbytasks()` is only invoked once per assignment, as far as i can see. i do not see the need to avoid invalidating caches. or am i missing somethings?",0,0.9698126912117004
670333813,10851,cadonna,2021-07-15T10:20:54Z,"i would prefer to have an interface instead of an abstract class. in the past, it turned out to be cleaner and easier maintainable even if we need to duplicate the `configs` field in the implementations of this interface.",0,0.989834725856781
670336504,10851,cadonna,2021-07-15T10:24:46Z,i think a factory method as used [a link] should suffice instead of an entire class.,0,0.9865326881408691
671829899,10851,lkokhreidze,2021-07-18T11:47:01Z,"that is correct. currently, `standbytaskassignor` implementations are created once per `taskassignor#assign` method call, and `assignstandbytasks` is called only once. i just didn't want to assume how and how many times `assignstandbytasks` is called as i didn't want to leak the implementation details to the caller. however, if you feel strongly that it's better to have the implementation in the `clienttagawarestandbytaskassignor`, i can refactor the code. since it's internal contract of the assignment, maybe it's okay.",0,0.9873619079589844
672023300,10851,lkokhreidze,2021-07-19T06:38:07Z,"fair enough, done.",0,0.7684450745582581
672023438,10851,lkokhreidze,2021-07-19T06:38:26Z,done,0,0.8974218964576721
672023741,10851,lkokhreidze,2021-07-19T06:39:04Z,moved factory method in `standbytaskassignor` interface itself. hope it addresses your comment.,0,0.4986937940120697
685807795,10851,cadonna,2021-08-10T08:31:19Z,"i see your point, but i do also not see the need for an internal state for which we need to avoid invalidation. variables `numstandbyreplicas` and `numstandbyreplicas` are configs that can be stored as member fields of `clienttagawarestandbytaskassignor` or passed along to the methods that need them. variables `tagkeytotagvaluesmapping`, `clientspertagvalue`, `standbytaskclientsbytaskload`, and `clientstates` can also be passed to the methods that need them. avoiding state makes reasoning about code simpler and here it seems possible to avoid state. see `highavailabilitytaskassignor`, it does not have any state.",0,0.9870451092720032
685816278,10851,cadonna,2021-08-10T08:42:05Z,"i would prefer to make this interface independent of its implementations. if you put the factory method here, the interface is not independent anymore. i would prefer a factory method named `createstandbytaskassignor()` in `highavailabilitytaskassignor` similar to the existing factory method `createtaskassignor()` in `streamspartitionassignor`.",0,0.9924301505088806
685822324,10851,cadonna,2021-08-10T08:49:41Z,"minor: you could extend interface `taskassignor` and remove `assignstandbytasks()` from this interface since `assign()` in `taskassignor` has almost the same signature. the difference is parameters `configs` and `alltaskids`. you will need `configs` if you will not keep the config as a member variable as mentioned in my other comment. you will not need `alltaskids`, but that would be ok, i guess.",0,0.9856471419334412
685824044,10851,cadonna,2021-08-10T08:51:51Z,"i guess the initialization in the constructor on line 79 is only temporary. this will change in one of the next prs. nevertheless, i agree that it would also be fine to move the initialization to the field declaration for now. i would even propose to pass the client tags to the constructor, since those are kind of constants coming from the config.",0,0.9864903688430786
685865965,10851,cadonna,2021-08-10T09:48:09Z,i would prefer to just add two parameters -- `source` and `destination` -- to the `isvalidmovement()` method in `standbytaskassignor` and get rid of this class.,0,0.9938003420829773
685867438,10851,cadonna,2021-08-10T09:50:08Z,the task id is never used. could we remove it?,0,0.9681577682495117
685871631,10851,cadonna,2021-08-10T09:56:06Z,could you move the second condition to the `canmove` assignment on line 166? i think the condition is logically a part of `canmove`.,0,0.9938786625862122
685872701,10851,cadonna,2021-08-10T09:57:39Z,nit: i think `isallowedtaskmovement()` reflects better the meaning of this method.,0,0.9837203025817871
685877129,10851,cadonna,2021-08-10T10:03:55Z,would it be possible to integrate the tag constraint as part of the constraint on the priority queue?,0,0.994449257850647
693133897,10851,lkokhreidze,2021-08-20T18:14:16Z,"it's already part of the poll constraint of the priority queue. example: [code block] i don't think it will be doable with constructor constraint, because we need to update constraint on each poll.",0,0.9935824275016785
693150166,10851,lkokhreidze,2021-08-20T18:44:21Z,good point about client tags being constant. added it as constructor parameter.,1,0.5739291310310364
693163634,10851,lkokhreidze,2021-08-20T19:09:26Z,addressed with 9841d25,0,0.9906895160675049
695463229,10851,lkokhreidze,2021-08-25T07:11:43Z,this method is needed in `clienttagawarestandbytaskassignor` and `defaultstandbytaskassignor`. was thinking to create `standbytaskassignmentutils` and extract this logic in there. wdyt ?,0,0.9934218525886536
695630930,10851,cadonna,2021-08-25T10:49:00Z,"yes, i think that makes sense. in this way you can also directly test the method. btw, you can simply pass `statefultaskids` to this method instead of `statefultaskswithclients`. the keys in `statefultaskswithclients` should be the task ids in `statefultaskids` and the values in `statefultaskswithclients` are never used.",0,0.983080267906189
695640768,10851,cadonna,2021-08-25T11:03:15Z,isn't this the same as: [code block],0,0.9891325831413269
695642889,10851,cadonna,2021-08-25T11:06:10Z,isn't this the same as: [code block],0,0.9891325831413269
695669488,10851,cadonna,2021-08-25T11:41:52Z,why is the map from tag key to tag values computed for each active task? they should not change during the assignment and we can just compute it once in `assign()`. do you agree?,0,0.994025468826294
695690393,10851,cadonna,2021-08-25T12:12:07Z,"imo, the code is easier readable if you name the variables consistently like `tagvaluetoclients` and `tagkeytotagvalues` or `clientsfortagvalue` and `tagvaluesfortagkey`. i prefer the former because it better visualises the mapping, but that is a matter of taste, i guess.",0,0.9533312916755676
695717497,10851,lkokhreidze,2021-08-25T12:48:31Z,"good catch. i missed it during refactoring, you're correct.",1,0.9811272025108337
695735723,10851,lkokhreidze,2021-08-25T13:10:03Z,done,0,0.8974218964576721
695735854,10851,lkokhreidze,2021-08-25T13:10:15Z,pushed changes,0,0.9871407747268677
695735942,10851,lkokhreidze,2021-08-25T13:10:21Z,fixed,0,0.9281549453735352
695736026,10851,lkokhreidze,2021-08-25T13:10:27Z,fixed,0,0.9281549453735352
700864299,10851,cadonna,2021-09-02T08:25:40Z,"although we never use the returned value from a standby task assignor, i would return `false` since a standby task assignment will never require a follow-up probing rebalance.",0,0.9907930493354797
700905553,10851,cadonna,2021-09-02T09:18:37Z,map `statefultaskswithclients` is only used to iterate over its entries. i think it would be better to use the following nested loops and remove `statefultaskswithclients`: [code block],0,0.9933245778083801
700910355,10851,cadonna,2021-09-02T09:25:03Z,i do not understand why you re-add `clientsonalreadyusedtagdimensions`. those clients were not modified and not polled for sure due to line 140.,0,0.974053144454956
700917243,10851,cadonna,2021-09-02T09:33:57Z,"i think this map does not work for distinct tag keys that have overlapping tag values. for example, `key1` contains one of `{value1, value2}` and `key2` contains one of `{value2, value3}`.",0,0.9785762429237366
701068792,10851,cadonna,2021-09-02T13:12:40Z,"are you sure, because i cannot confirm the failure of the test on my side?",0,0.9790710210800171
701137236,10851,lkokhreidze,2021-09-02T14:26:05Z,"yeah, sorry. you're right. this is not needed.",-1,0.9916308522224426
701141903,10851,lkokhreidze,2021-09-02T14:30:51Z,"sorry, can you elaborate more on this? currently, when deciding the distribution, algorithm takes into account both, tag key, as well as tag value. so it will treat `key1: value2` and `key2: value2` as different dimensions. do you think it's something that has to be addressed?",-1,0.9684882164001465
701142976,10851,lkokhreidze,2021-09-02T14:32:05Z,pushed the changes.,0,0.9891749620437622
701143273,10851,lkokhreidze,2021-09-02T14:32:26Z,i've removed this line and pushed the changes.,0,0.9822438359260559
720193502,10851,cadonna,2021-10-01T12:12:59Z,"let's assume you have two clients. `clientx` has tags `keya:value1` and `keyb:value2` and `clienty` has tags `keya:value2` and `keyb:value3`. notice that `keya` and `keyb` share `value2`. with your code, we will end up with a `tagvaluetoclients` map that looks like this: [code block] now, let's assume that an active task is assigned to `clientx`. it would be totally fine if we assign the standby task to `clienty` since each tag key of both clients do not share a value. however, your algorithm does not allow it, because on line 198 it also adds `clienty` to the clients that are not allowed to get the standby. the reason is that `tagvaluetoclients` only looks for clients that contain value `value2` and not for clients that contain it as a value for `keya`. the following test fails because of this: [code block]",0,0.9626268744468689
720196549,10851,cadonna,2021-10-01T12:17:41Z,could you please use `tagvaluetoclients` and `tagkeytovalues` here as in the rest of the class?,0,0.9945367574691772
720214125,10851,cadonna,2021-10-01T12:46:53Z,"currently the code iterates over the active tasks and assigns all standby tasks for each active task. if the standby tasks cannot all be assigned, we might end up with all standby tasks assigned for some active task but none for others. what do you think about to assign one standby task for all active task and then assign the second standby task for all active task, and so on. in this way, it is more likely that at all active tasks have at least one standby task assigned. i am aware that the default standby assignor has the same drawback.",0,0.9388849139213562
741840561,10851,lkokhreidze,2021-11-03T11:18:42Z,"thanks, good catch.",1,0.9897831082344055
741896976,10851,lkokhreidze,2021-11-03T12:41:17Z,"makes sense . should i update default standby task assignor, or prefer to leave it out of scope of this pr?",0,0.9930904507637024
741897677,10851,lkokhreidze,2021-11-03T12:42:16Z,solved by storing tuple of tag key and value as map key instead of just tag value.,0,0.9923302531242371
741923941,10851,lkokhreidze,2021-11-03T13:15:03Z,"also wondering if it's better to do this as a separate task altogether. since, as you've mentioned, it's the same behaviour as with default standby task assignor. but if you feel it's better to do it in current pr, happy to do so.",1,0.7577019333839417
765909088,10851,cadonna,2021-12-09T15:39:09Z,for each standby of a single active task the set `clientsonalreadyusedtagdimensions` is computed from scratch. i think this is not necessary since the clients on already used tag dimensions that we found for the first standby are still valid for the second standby and the clients on already used tag dimensions found for the second standby are still valid for the third standby and so on. this is true because we only add clients to the set `usedclients` but we never remove any. i think we can compute `clientsonalreadyusedtagdimensions` incrementally for each standby of a single active task instead of computing it from scratch each time.,0,0.9903811812400818
766104130,10851,cadonna,2021-12-09T19:48:26Z,"something does not work as expected in this algorithm. according to this doc, the assignor should fall back to distributing tasks on least-loaded clients. however, the following test case fails: [code block] the standby task for active task 0_0 can be put on client uuid_2 and the standby task for active task 0_1 can be put on client uuid_1 without breaking rack awareness constraints. standby tasks for active tasks 0_2 and 1_0 cannot be put on any client without breaking rack awareness, so they should be distributed on least-loaded clients. however, that does apparently not happen, because client uuid_3 and uuid_4 are not assigned any standby.",0,0.9912375211715698
789057202,10851,lkokhreidze,2022-01-20T18:46:16Z,fixed with e3aff39c7687a358cc8672accd5bbf6a27193a04. algorithm will try to achieve partial rack awareness as there are different `cluster` tag dimensions.,0,0.9954380393028259
789057904,10851,lkokhreidze,2022-01-20T18:47:15Z,fixed with e3aff39. now we only create `clientsonalreadyusedtagdimensions` once and populate it for the each standby task assignment instead of re-creating it.,0,0.9942449927330017
789060382,10851,lkokhreidze,2022-01-20T18:50:46Z,"hi would appreciate your feedback on this. as of now, algorithm ignores a case when client has reached capacity and it will try to assign the standby task to it as long as it satisfies the rack awareness. there's a even test for it `shoulddistributeclientsondifferentzonetagsevenwhenclientsreachedcapacity`. for me it makes sense that rack awareness, if configured, takes precedence in this case. added log to inform the user, just want to make sure if you think this is a valid approach. it is not a lot of work to take capacity into account, so we can redo algorithm if you think that makes more sense.",1,0.8213401436805725
789687365,10851,lkokhreidze,2022-01-21T14:09:22Z,"i reworked things a bit, check out this comment [a link]",0,0.9619908332824707
789687883,10851,lkokhreidze,2022-01-21T14:10:01Z,"no longer relevant, i reworked things a bit, check out this comment [a link]",0,0.9160714149475098
795434808,10851,lkokhreidze,2022-01-31T08:32:34Z,"answering why do we need this: i think with client tag aware standby task assignment, there's a much higher chance that we will overload some clients without this check. i think it's better to not to overload the clients and instead log the warning so users can do the needful of increasing the capacity in order to satisfy the rack awareness.",0,0.9750432372093201
805156426,10851,showuon,2022-02-12T12:31:47Z,could we add some java doc to this assign to briefly mention about the algorithm used in the assignor? thanks.,0,0.9492400288581848
805156641,10851,showuon,2022-02-12T12:34:04Z,"i know there was no any java doc for the default least load assignor. but do you think we can add some comments to it, just like in `clienttagawarestandbytaskassignor`? i believe not everyone knows default assignor algorithm is least loaded assignor.",0,0.9893172383308411
805157124,10851,showuon,2022-02-12T12:40:02Z,i'm wondering could we keep the original constructor and pass empty map into the new one? so that we don't have to make changes to the old caller. that is: [code block] wdyt?,0,0.9725126028060913
805199777,10851,cadonna,2022-02-12T20:12:02Z,"i see what you want to do. however, the capacity is the number of consumers on the streams client, i.e., the number of stream threads running on the streams client. with this check, you only allow to assign standby tasks to clients that have less tasks assigned as stream threads running. that is actually rather an unlikely case. normally, you have more tasks assigned to a streams client than the number of stream threads running on the client. i would keep it simple and ignore the balance for now.",0,0.971603274345398
805203233,10851,cadonna,2022-02-12T20:51:21Z,would it be possible to decrement the numbers in `taskstoremainingstandbys` to maintain the remaining standbys to distribute instead of using `pendingstandbytasktonumberremainingstandbys`?,0,0.9957513809204102
805571500,10851,showuon,2022-02-14T07:43:02Z,maybe add a comment here to mention we need to make sure the sourceclient tag matches to destinationclient tag if rack tag is enabled...something like that.,0,0.9934163093566895
805641183,10851,showuon,2022-02-14T09:19:10Z,is it normal when this happened? should we do anything to it? or at least log something here?,0,0.9933183193206787
805642565,10851,lkokhreidze,2022-02-14T09:20:51Z,"thanks for the feedback. no objections from my side. the reason why i avoided that was to make sure that client tags are always passed. to emphasise that it's mandatory parameter when constructing the `clientstate` object. please note that we have made `clientstate#clienttags` immutable; so there're no setters for the client tags. but if you feel like it's better to default to empty map, happy to change it. will wait for your response on this.",1,0.9874643087387085
805646942,10851,showuon,2022-02-14T09:25:59Z,"the variable name `polledclient` is unreadable. i think the variable is the client not having the same tag key/value, right? could we give it a more meaningful name, ex: `clientuuidnotonusedtagdimension`, or other better one if you have.",0,0.9935983419418335
805656409,10851,showuon,2022-02-14T09:36:51Z,"when reaching this point, we have tried our best to assign standby tasks with rack awareness to all clients. i think we should have a debug log here, to log some current status, like current assignment, `pendingstandbytasktonumberremainingstandbys`, `pendingstandbytasktoclientid`, and mention we're going to distribute the remaining tasks with least loaded assignor...etc, for better troubleshooting.",0,0.9907612204551697
805659384,10851,showuon,2022-02-14T09:40:16Z,"tbh, i don't understand this method well before i read into the implementation. i think the method is trying to assign standby tasks to those clients without using the same tag key/value, right? if so, maybe we can change the name to `assignstandbytaskstoclientswithoutsametag`, or others you can think of. wdyt?",0,0.9352812767028809
805663941,10851,showuon,2022-02-14T09:45:26Z,"looks like the `findclientsonusedtagdimensions` method keeps finding duplicated `usedclients`. that is, if we have 10 `numremainingstandbys`, we'll run `findclientsonusedtagdimensions` with 1 `usedclients` at first. and then, add one more, to have 2 `usedclients` at 2nd run, and add one to 3, 4, 5, ... 10. is my understanding correct? if so, could we improve it?",0,0.9879654049873352
805668921,10851,showuon,2022-02-14T09:50:57Z,"this is an internal class, so i think it won't be changed/used many times. i think change to my previous suggestion is better. thanks.",1,0.9490092396736145
805782141,10851,lkokhreidze,2022-02-14T12:13:21Z,i think having a warn log is a good call. we can add validation rules (if necessary) when doing last part of this kip - updating streams configuration.,0,0.9313310980796814
805830410,10851,lkokhreidze,2022-02-14T13:16:51Z,good call. i don't know how i missed that...,1,0.9263068437576294
807660376,10851,lkokhreidze,2022-02-16T08:24:19Z,thanks! renamed to `clientonnotusedtagdimensions` to be consistent with the rest of the codebase. since we refer to client uuids as just `client` in the codebase. hope this works.,1,0.9928914308547974
807663879,10851,lkokhreidze,2022-02-16T08:28:41Z,makes sense. renamed to `assignstandbytaskstoclientswithdifferenttags`. hope this works too.,1,0.9123770594596863
807738730,10851,lkokhreidze,2022-02-16T09:50:45Z,refactored javadocs a bit. moved some content from class level javadoc to the `assign` method. hope this works.,1,0.9551311135292053
807810480,10851,lkokhreidze,2022-02-16T11:07:20Z,good call. improved the code in a latest commit.,1,0.9674311280250549
809711301,10851,showuon,2022-02-18T06:35:57Z,ok,0,0.8787186145782471
809773328,10851,showuon,2022-02-18T08:29:41Z,nit: the algorithm will fall back to the least-loaded clients without **taking** rack awareness constraints into consideration.,0,0.9878492951393127
809797947,10851,showuon,2022-02-18T09:02:01Z,"i checked the use of `tagkeytovalues`. it is only used for total value count of each key. is that right? if so, could we just store the `map tagkeytovaluecount` only?",0,0.9954898953437805
809798766,10851,showuon,2022-02-18T09:03:03Z,"sorry, i didn't understand the reason why we can't filter out clients located on that tag when `alltagvalues.size() <= countofusedclients`. could you help explain to me? thanks.",-1,0.9470778107643127
809972865,10851,showuon,2022-02-18T12:54:02Z,nit: ` clienttagawarestandbytaskassignor` (no need the package name),0,0.992717981338501
809980650,10851,showuon,2022-02-18T13:04:58Z,nit: close this bracket in the same line. that is: `private standbytaskassignmentutils() {}`,0,0.9928303360939026
809983790,10851,showuon,2022-02-18T13:09:18Z,nit: indent issue. could we add comment in front of `empty_rack_aware_assignment_tags`?,0,0.9911709427833557
809984233,10851,showuon,2022-02-18T13:09:53Z,same as above.,0,0.9857698678970337
810003432,10851,lkokhreidze,2022-02-18T13:35:38Z,"can do, but also `set` makes it easier to handle duplicate values as we are looking for distinct count values here. not sure if refactoring is worth it though.",0,0.9686604142189026
810019916,10851,lkokhreidze,2022-02-18T13:54:59Z,"consider the following example [code block] with the above we have following number of unique tag values: [code block] now lets say we have standby replica count as `2` and we want to active task is located on `client 1` `usedclients=1` (because of the active task) ### 1st standby assignment during 1st standby takes assignment, we will exclude clients on following dimensions: [code block] used clients will get incremented since we can allocate the client on different `zone` and `cluster`. `usedclients=2` ### 2nd standby assignment we will have to exclude `zone: eu-central-1a and (eu-central-1b || eu-central-1c)` tag values. we can do that, because after we exclude clients on the new tag, we still have clients on the one free tag value we can assign the next standby to. we can't exclude `cluster` because we have already used two clients, and we just have two unique values for the `cluster` tag, so it's impossible to get the ideal distribution with this configuration and number of instances. so we can only achieve partial distribution. so idea of this check is to ignore tags where we have less unique values than the clients we have already used. if we don't have this check, for the 2nd standby task assignment we would have excluded all the clients located on `k8s-cluster1` and `k8s-cluster2`, and there wouldn't be any client left to assign the standby task to. we would fall back to the least loaded client, but there will be no guarantee that least loaded client assignment would honor partial rack awareness. hope this makes sense.",0,0.9873325228691101
810020380,10851,lkokhreidze,2022-02-18T13:55:34Z,i added `shoulddothepartialrackawareness` test to verify this behaviour.,0,0.9933260679244995
810462108,10851,showuon,2022-02-19T07:58:08Z,"nit: could we be consistent with other tests that make the uuid_seq in order? it makes me a little confused when reading this test. that is, [code block]",0,0.6408771872520447
810462515,10851,showuon,2022-02-19T08:02:43Z,"i can understand what you tried to assert here. but i think we should also assert that the standby tasks count in each client is as what we expected, because under current verification, we only focus on the tasks distributed with rack awareness. however, there is still possibility that standby tasks don't distribute evenly, right? the following tests should also update. thanks.",1,0.9281554818153381
810462817,10851,showuon,2022-02-19T08:06:49Z,"a ha, you're right! we only need the distinct count values. no need to refactor it then. thanks for the explanation.",1,0.9856179356575012
810464460,10851,showuon,2022-02-19T08:27:03Z,"in 1st standby assignment: usedclients=2 i think this used client should be 5 or 6, right? but i got your idea. thanks for the explanation. makes sense to me.",1,0.8938223123550415
810465176,10851,showuon,2022-02-19T08:35:58Z,"i'm thinking, we can make it much clear by adding comments, though i know this is hard to explain in simple words. how do you think we add comments like this: // if we have used more clients than all the tag's unique values, // we can't filter out clients located on that tag, because it'll excluded all the clients. // please check clienttagawarestandbytaskassignortest#shoulddothepartialrackawareness test for more info. and we can make more description in `shoulddothepartialrackawareness` test.",0,0.9764739274978638
810485747,10851,showuon,2022-02-19T12:29:59Z,"we can add comments here like: // we need 2 standby tasks (+ 1 active task) to distribute, but we only have 2 cluster tag, so we will won't exclude all clients when 2nd standby tasks assignment, and will try to distribute the 2nd standby tasks with taking partial rack tag into consideration. wdyt?",0,0.9846605658531189
810487017,10851,showuon,2022-02-19T12:43:36Z,"after your explanation of partial rack awareness, i can understand the distribution will be `uuid_5, uuid_6`. but i don't know why it's possible with the result `uuid_5, uuid_3`? i thought after 1st standby task assignment, we'll exclude `cluster_1` and `zone_1` tags clients. so the remaining clients will be `uuid_5, uuid_6`. therefore, the only possible results will be `uuid_5, uuid_6`. is my understanding correct? anything i missed? thanks.",1,0.5252375602722168
810487139,10851,showuon,2022-02-19T12:44:46Z,"and i think we should add some comments here, to have a simple explanation like we i did above to explain why we have these results. thanks.",1,0.9210591316223145
810857967,10851,lkokhreidze,2022-02-21T07:59:25Z,"`uuid_5` is essentially ""ideal"" distribution because it has both different cluster and zone compared to an active task. however, when we assign 2nd standby, we can only choose client on different `zone`. `cluster` tag is excluded as we don't have enough unique values to exclude the `cluster`. so for the 3rd standby task, both `cluster1` and `cluster2` are valid. that means that clients with `uuid_3` (`cluster1`, `zone3`) and `uuid_6` (`cluster2`, `zone3`) are valid destinations. on the high level, idea is that, if any of the values of the `cluster` tag goes offline, no matter on which `cluster` we distribute the 2nd standby `cluster1` or `cluster2`, we either way will loose two clients at the same time. so from availability perspective it doesn't make difference where the 2nd standby will be assigned. one may argue that it would be better to always distribute to a different tags compared to an active task, but this will complicate algorithm even further, so i guess it's better to keep it simpler in a first iteration. hope this makes sense, i will add more info as a comment.",0,0.9939820170402527
810894883,10851,lkokhreidze,2022-02-21T08:48:51Z,added more explanation in `shoulddothepartialrackawareness` test.,0,0.9939593076705933
811551306,10851,showuon,2022-02-22T03:33:07Z,nice tests!,1,0.9957767128944397
811556641,10851,showuon,2022-02-22T03:50:06Z,"nit: we can directly break the while when `numremainingstandbys == 0`, so that we don't need to run the redundant `findclientsonusedclienttagdimensions` in the last run. ex: [code block]",0,0.9945100545883179
811559765,10851,showuon,2022-02-22T03:59:48Z,"thanks for the explanation for partial rack awareness assignment. i think that algorithm makes sense. however, i don't think the implementation matches what you described. you said in the `shoulddothepartialrackawareness` test, in 2nd standby assignment for task_0_0, we will only consider `zone`, but in current implementation, we will also consider `cluster`. that is, when entering the `while (numremainingstandbys > 0) {` loop, the `clientsonalreadyusedtagdimensions` already excluded the `cluster_1` and `zone_1`. and in the 1st standby assignment, `uuid_5` will be chosen, we'll exclude `zone_2` only, and not exclude `cluster_2`. so , the only client left is `uuid_6`. that's the current design, isn't it? i don't see where we only consider `zone` in 2nd assignment. could you help elaborate more? thank you.",1,0.7380062937736511
811645496,10851,lkokhreidze,2022-02-22T07:30:21Z,"ah, you're absolutely right! i'm very sorry for the confusion. it's been a while and got lost myself. i will update comments to reflect this. do you think it makes sense to leave the implementation as is, or we should re-work it based on what i described before? either is fine with me.",-1,0.9921085238456726
811651144,10851,showuon,2022-02-22T07:39:28Z,i think we should re-work the `assignstandbytaskstoclientswithdifferenttags` method to match what you described. that makes more sense. thanks.,1,0.9829825758934021
811652014,10851,lkokhreidze,2022-02-22T07:40:50Z,will get it done asap.,0,0.9913626313209534
811918321,10851,lkokhreidze,2022-02-22T12:58:07Z,updated implementation in [a link],0,0.985296905040741
811964104,10851,cadonna,2022-02-22T13:48:33Z,wouldn't this be equivalent and maybe a bit more concise? [code block],0,0.989547073841095
811981794,10851,cadonna,2022-02-22T14:06:40Z,"that is quite challenging to understand. after reading it a couple of times i understood that if we've used a number of clients that is equal to or greater than the number of unique values of the tag, we cannot guarantee that each standby is on a different tag value than the active and other standbys. so the rack-awareness becomes partial. is that correct? could you reformulate it, so that it states that the rack-awareness guarantee does not hold anymore. and why ""more clients than all tag's unique values""? when the number of used clients is equal to the unique tag values, we are already in the partial rack-awareness situation, right? maybe you should give here an example as in the mentioned test. i find referencing the test is a bit cumbersome, because if the test gets renamed this comment becomes useless.",-1,0.7463173270225525
812018771,10851,cadonna,2022-02-22T14:41:55Z,"i could not find where you decrement the number of remaining standbys. if you get a value from this map and put it into an `int` variable, you do not have a reference to the `integer` value in the map anymore. this might become a problem in `standbytaskassignmentutils#pollclientandmaybeassignremainingstandbytasks()`.",0,0.9918217062950134
812081768,10851,lkokhreidze,2022-02-22T15:41:22Z,"thanks bruno, i'll add the example to the comment.",1,0.5231540203094482
812519265,10851,showuon,2022-02-23T02:42:38Z,nit: lastusedclient -> lastusedclient,0,0.9877880215644836
812525667,10851,showuon,2022-02-23T03:03:49Z,"since we will remove tags, i think we can rename to `updateclieintsonalreadyusedtagentries`. wdyt?",0,0.980633556842804
812527382,10851,showuon,2022-02-23T03:09:25Z,nice catch! and maybe we should add a test to address this.,1,0.9896450042724609
812527749,10851,showuon,2022-02-23T03:10:30Z,good suggestion!,1,0.9951785802841187
812626201,10851,cadonna,2022-02-23T07:48:45Z,"yes, a test is absolutely necessary!",0,0.8309087753295898
812720897,10851,lkokhreidze,2022-02-23T09:54:23Z,pushed the changes. i added detailed explanation with an example. also tests have the similar example. hopefully this change makes logic more clear.,1,0.5107885003089905
812722151,10851,lkokhreidze,2022-02-23T09:55:49Z,"updated tests for the `standbytaskassignmentutils#pollclientandmaybeassignandupdateremainingstandbytasks` and also added separate test for the `clienttagawarestandbytaskassignor`. for the `clienttagawarestandbytaskassignor` i decided to make few things package private to be able to test this logic. as otherwise, there was no easy way to test if `taskstoremainingstandbys` was getting updated properly. hope this is okay.",1,0.8745933771133423
812884587,10851,showuon,2022-02-23T13:22:03Z,nit: additional space between `the` and `2nd`,0,0.9917591214179993
817629787,10851,cadonna,2022-03-02T12:08:36Z,"i think info log would also be ok here. i imagine users that are wondering why their standbys are not distributed as they would expect. with this information they can at least try to fix it on the config level. this log message should only happen at rebalance time, which should usually be rather seldom. if we decide to put the log message on info level, you should also change a bit the wording and not use variable names in it. maybe some hints what the users can do to fix this would also be nice. is it possible to separate the concerns of this log message and the one on line 135? something along the lines of here the rack-aware standby assignment did not work due the tag config and on line 135 the assignment did not work due to too low number of instances. we can then put both on warn or info (do not forget to also check the related log message in the default standby assignor).",0,0.9141198396682739
817650626,10851,cadonna,2022-03-02T12:37:25Z,this can be done in a follow-up pr: i am not a big fan of `// visible for testing` because it often means that we missed to extract code to separate classes. here i would definitely extract this code to a factory class.,0,0.8140901327133179
38823999,195,junrao,2015-09-06T17:45:05Z,it seems that it will be cleaner if we split this into getacls and getaclsfromzk. the former will just read from the cache and the latter always read from zk. only the zk listener will use the latter.,0,0.991895854473114
38824003,195,junrao,2015-09-06T17:45:32Z,"hmm, this may not work well if two acl changes happen quickly. the second one will override the the resource of the previous one. if a broker hasn't finished processing the previous change, it will miss it after the override. i thought we wanted to use the same approach as in configchangelistener where the updates are written as a sequential zk node.",0,0.8513292074203491
38824005,195,junrao,2015-09-06T17:45:44Z,could we document the format of values used in the new zk paths in the comment?,0,0.9947277903556824
38824017,195,junrao,2015-09-06T17:46:19Z,"hmm, do we need this? it's simpler if we always rely on zk watchers to propagate the changes. zkclient will handle all the reconnects for us. if we lose a session, we probably have to read the aclchangedzkpath in case we missed a zk notification.",0,0.987179696559906
38925968,195,ijuma,2015-09-08T13:40:40Z,"you can use `_` if you want a value to be initialised to the default one (eg `null`, `false`, `0`, etc.)",0,0.9917267560958862
38926011,195,ijuma,2015-09-08T13:41:01Z,type annotation is redundant in cases like this.,0,0.9430493712425232
38926146,195,ijuma,2015-09-08T13:42:22Z,"a less verbose and more idiomatic way to write this: `import scala.collection._` ... `private val aclcache = mutable.map.empty[resource, set[acl]]`",0,0.9914674758911133
38926413,195,ijuma,2015-09-08T13:44:50Z,"what if `str` is not a `string`? that case is not being handled. nicer code can be written if you use the scala version of the map (ie `config`). then `get` will return an `option` and you can use methods like `filter`, `map`, etc. that applies to the other code that is reading from the config.",0,0.9945513606071472
38926589,195,ijuma,2015-09-08T13:46:19Z,unnecessary type annotation,0,0.9040930271148682
38926656,195,ijuma,2015-09-08T13:46:52Z,"in scala, one should use `==` not `equals`.",0,0.9922733902931213
38926768,195,ijuma,2015-09-08T13:47:41Z,"instead of doing this, you should replace the for comprehension with `find`.",0,0.991943359375
38926812,195,ijuma,2015-09-08T13:47:57Z,"no `var` needed, `inreadlock` returns a value.",0,0.9940406680107117
38926927,195,ijuma,2015-09-08T13:49:10Z,`acljson.map(acl.fromjson).getorelse(set.empty)`,0,0.9934666752815247
39098212,195,Parth-Brahmbhatt,2015-09-09T21:22:02Z,done.,0,0.9640594124794006
39098585,195,Parth-Brahmbhatt,2015-09-09T21:25:46Z,"i am confused. i thought you said a watch notification will never be missed or it will only be missed when a reconnection happens which is handled by zkclient, which is why we don't need the sync thread. if client-a updated the /kafka-acl-chaged and set its data to ""topic-1"" (this should go throught zkquorum) and then client-b updated the /kafka-acl-changed and set its data to ""topic-2"" are you saying we will only get notification for ""topic-2"" depending on how fast the change occurs? doesn't that violate the first guarantee which led us to delete the hourly sync? i would like to point out that in the watch notification we are just relying on data sent as part of notification and not really reading /acl-changed one more time.",-1,0.6925057172775269
39099520,195,Parth-Brahmbhatt,2015-09-09T21:33:56Z,done.,0,0.9640594124794006
39099854,195,Parth-Brahmbhatt,2015-09-09T21:37:13Z,done.,0,0.9640594124794006
39100044,195,Parth-Brahmbhatt,2015-09-09T21:39:00Z,removed the whole scheduler.,0,0.9694809913635254
39100138,195,Parth-Brahmbhatt,2015-09-09T21:39:47Z,"as soon as i add that import all the other places that expect set starts complaining that ""set[x] can not be converted to set[x]"" which i am guessing is just scala compiler complaining that they expect the unmutable scala set but with the new import now they are all assumed to be mutable set. did i mention scala is amazing :-).",1,0.9952183365821838
39100385,195,Parth-Brahmbhatt,2015-09-09T21:41:58Z,fixed.,0,0.979083240032196
39100572,195,Parth-Brahmbhatt,2015-09-09T21:43:37Z,done.,0,0.9640594124794006
39103033,195,Parth-Brahmbhatt,2015-09-09T22:06:08Z,"apart from returning true , given i also want to log the debug statement as a side effect, the version with find looks less redable imo.",0,0.8882073760032654
39103099,195,Parth-Brahmbhatt,2015-09-09T22:06:51Z,function is deleted given jun has recommended to assume that zkclient will handle reconnects and guarantee all the watchers are always delivered.,0,0.9932252764701843
39103189,195,Parth-Brahmbhatt,2015-09-09T22:07:41Z,done.,0,0.9640594124794006
39104580,195,Parth-Brahmbhatt,2015-09-09T22:21:52Z,removed and added listener for reconnection handler.,0,0.9915307760238647
39105224,195,Parth-Brahmbhatt,2015-09-09T22:29:24Z,handled the case where its not string by just adding another case.,0,0.9816359281539917
39107202,195,junrao,2015-09-09T22:55:07Z,"parth, zk watchers are actually one-timer watchers ([a link] when a watcher fires, the client has to register the watcher again (typically through a read) to get notification for future changes. between the time that a watcher fires and the client does a read, multiple changes could have happened. the read will return the latest value and leave a watcher there. so, in general, there is no guarantee that every change triggers the firing of a watcher. in particular, if you update the value of a zk path multiple times in between, only the latest value will be seen by the reader. one way to capture all changes is to follow how we propagate the config changes (configchangelistener). whenever we change an acl, we write the acl under /kafka-acl and also write a sequential zk node under /kafka-acl-changed. the value of the sequential zk node indicates the resource for which the acl has changed. the sequential zk nodes are guaranteed to be unique and have a number suffix that's ever growing. the acl manager registers a child change listener on /kafka-acl-changed and remembers the last number suffix that it has processed. when the watcher fires, the acl manager reads all child nodes under /kafka-acl-changed (the read may pick up multiple acl changes) and process new nodes after the last remembered number suffix. the processing will involve reading the latest acl associated with the corresponding resource. since every sequential node is unique, the acl manager won't miss any acl change. on initialization, the acl manager will first register the watcher and read all existing acls. finally, we need a way to garbage collect old sequential nodes. this can be done by just removing sequential nodes that are say, more than 15 mins old (assuming every broker would have picked up the acl changes by then).",0,0.9856512546539307
39112549,195,Parth-Brahmbhatt,2015-09-10T00:08:18Z,thanks for the explanation and it makes perfect sense. will update the pr.,1,0.9658891558647156
39349577,195,junrao,2015-09-13T17:06:25Z,typo immeditatly,0,0.8560723066329956
39349578,195,junrao,2015-09-13T17:06:32Z,need to either remove those pirintlns or convert them to logging.,0,0.9857742786407471
39349582,195,junrao,2015-09-13T17:06:39Z,perhaps we can include path and notifications in the error message.,0,0.9904301762580872
39349583,195,junrao,2015-09-13T17:06:47Z,we probably should rename this to /kafka-acl-changes.,0,0.9942103624343872
39349584,195,junrao,2015-09-13T17:06:50Z,"perhaps rename this to ""acl_changes_""?",0,0.9940347075462341
39349586,195,junrao,2015-09-13T17:07:03Z,probably rename this as javaconfigs. then we can define the scala one as configs.,0,0.9942860007286072
39349587,195,junrao,2015-09-13T17:07:08Z,perhaps it's better to explicitly assign the initial values than using _.,0,0.9927970767021179
39349588,195,junrao,2015-09-13T17:07:13Z,"to be consistent, use set.empty[kafkaprincipal] instead of set.empty?",0,0.9953821301460266
39349592,195,junrao,2015-09-13T17:07:27Z,perhaps we can allow zkconnectiontimeout and zksessiontimeout to be configured explicitly for simpleauthorizer and default to those in kafkaconfig if not specified.,0,0.9944900274276733
39349604,195,junrao,2015-09-13T17:08:01Z,"i had a comment in the jira. it seems that in socketserver, when creating the session object, it's better to create a kafkaprincipal instead of using kafkachannel.principal(). the type in kafkaprincipal should always be user and the name should be kafkachannel.principal().getname(). then, we can just get the kafkaprincipal from session and don't need to create a new one.",0,0.9887908697128296
39349608,195,junrao,2015-09-13T17:08:24Z,"this is useful for things like auditing. perhaps we can log this in the end together with the decision on wether the operation is granted on not. also, could we put that into a separate authorization log4j logger (take a look at the request logger in log4j.properties)? that way, if people want auditing, they can just enable the authorization logger.",0,0.9916439652442932
39349609,195,junrao,2015-09-13T17:08:29Z,should this be removed?,0,0.9926645159721375
39349610,195,junrao,2015-09-13T17:08:32Z,can this be private?,0,0.9889413714408875
39349611,195,junrao,2015-09-13T17:08:35Z,can this be private?,0,0.9889413714408875
39349613,195,junrao,2015-09-13T17:08:38Z,can this be private?,0,0.9889413714408875
39349614,195,junrao,2015-09-13T17:08:39Z,can this be private?,0,0.9889413714408875
39349615,195,junrao,2015-09-13T17:08:46Z,this needs to be removed.,0,0.9774357676506042
39349616,195,junrao,2015-09-13T17:08:54Z,"since these two are accessed from different threads, do they need to be volatile?",0,0.9935060739517212
39349633,195,junrao,2015-09-13T17:10:50Z,"ideally, we want to reuse this class in dynamicconfigmanager. if that's too much to do in this jira, could you file a follow-up jira to address this?",0,0.9847326874732971
39439189,195,Parth-Brahmbhatt,2015-09-14T19:58:22Z,i like the idea of changing type of principal in session as kafkaprincipal. i dont agree with the type being always user as different authentication schemes may want to change that and different authorizer implementations may actually use the values differently. does that sound ok?,1,0.612531840801239
39445926,195,Parth-Brahmbhatt,2015-09-14T20:56:26Z,fixed,0,0.9281549453735352
39445928,195,Parth-Brahmbhatt,2015-09-14T20:56:27Z,was planning to do the same. filed kafka-2547,0,0.9406076669692993
39445934,195,Parth-Brahmbhatt,2015-09-14T20:56:30Z,removed debug statement.,0,0.987971842288971
39445938,195,Parth-Brahmbhatt,2015-09-14T20:56:32Z,done.,0,0.9640594124794006
39445952,195,Parth-Brahmbhatt,2015-09-14T20:56:37Z,done,0,0.8974218964576721
39445961,195,Parth-Brahmbhatt,2015-09-14T20:56:39Z,done,0,0.8974218964576721
39445971,195,Parth-Brahmbhatt,2015-09-14T20:56:41Z,done.,0,0.9640594124794006
39445975,195,Parth-Brahmbhatt,2015-09-14T20:56:43Z,done.,0,0.9640594124794006
39445980,195,Parth-Brahmbhatt,2015-09-14T20:56:45Z,done.,0,0.9640594124794006
39445984,195,Parth-Brahmbhatt,2015-09-14T20:56:47Z,done,0,0.8974218964576721
39446002,195,Parth-Brahmbhatt,2015-09-14T20:56:55Z,"any time we allow or deny we already log the decision and the reasoning behind it, the trace is actually just to mark the entry point. modified log4j but i have set the default level at warn which will disable audit logging by default. let me know if you want it to be enabled by default.",0,0.98142009973526
39446007,195,Parth-Brahmbhatt,2015-09-14T20:56:58Z,done.,0,0.9640594124794006
39446014,195,Parth-Brahmbhatt,2015-09-14T20:57:01Z,done,0,0.8974218964576721
39446020,195,Parth-Brahmbhatt,2015-09-14T20:57:03Z,done,0,0.8974218964576721
39446024,195,Parth-Brahmbhatt,2015-09-14T20:57:05Z,done,0,0.8974218964576721
39446032,195,Parth-Brahmbhatt,2015-09-14T20:57:06Z,done,0,0.8974218964576721
39446038,195,Parth-Brahmbhatt,2015-09-14T20:57:09Z,done,0,0.8974218964576721
39446049,195,Parth-Brahmbhatt,2015-09-14T20:57:14Z,done,0,0.8974218964576721
39468051,195,junrao,2015-09-15T02:06:53Z,"since we return early in a few places, it seems that not all accesses are logged.",0,0.9810349345207214
39468196,195,junrao,2015-09-15T02:10:07Z,"hmm, how do we get the type from the authentication layer? currently, authenticator only returns a principal, which just has a name?",0,0.9705187678337097
39538158,195,Parth-Brahmbhatt,2015-09-15T17:19:17Z,"i rechecked to assure it is logged in all cases (superuser, no acls, deny acl match(as part of matching function), allow acl match(as part of matching function), no acl found). if we want it to be logged at the end, i can change the logic so it does not return in middle. may be its just me, i think the current way looks cleaner.",0,0.9836034774780273
39543626,195,Parth-Brahmbhatt,2015-09-15T18:00:01Z,"i was saying we change the type in authenticator interface to kafkaprincipal. then each authenticator implementation can add its own type (ssl can set principaltype=certificate, and kerberos based sasl can set type= user) as long as the authorizer they use can handle different types they will be fine. this will specifically useful when there are multiple listeners. i guess we can just do what you are suggesting for now and if we encounter a real use case we can change the type in authenticator at that time. i have made the changes you suggested for now.",0,0.9335041046142578
39591781,195,junrao,2015-09-16T03:54:26Z,"getacls should be getaclsfromzk, right? could we add a unit test to test the initial loading?",0,0.9944925308227539
39630946,195,ijuma,2015-09-16T13:48:46Z,why not import `javaconverters._` along with other imports at the top of the file and then simply do `changes.asjava` here and delete all local imports?,0,0.9946894645690918
39631044,195,ijuma,2015-09-16T13:49:34Z,we normally include `()` for side-effecting changes.,0,0.9907802939414978
39631152,195,ijuma,2015-09-16T13:50:24Z,it's generally better to do `notifications.nonempty` because it's o(1) even if the underlying implementation has a o(n) `size` (like scala.list).,0,0.9943161606788635
39632552,195,ijuma,2015-09-16T14:00:47Z,early return inside a closure (and a for comprehension desugars to `foreach`) actually involves throwing a `nonlocalreturncontrol` exception. you don't think the following is more readable? [code block],0,0.9832404255867004
39633336,195,ijuma,2015-09-16T14:06:56Z,`unit.` should not be part of package name.,0,0.9933110475540161
39633374,195,ijuma,2015-09-16T14:07:14Z,`unit` should not be part of package name,0,0.9930197596549988
39683091,195,Parth-Brahmbhatt,2015-09-16T20:48:48Z,done. sorry about missing this in first place. added the test for load cache.,-1,0.992618978023529
39683115,195,Parth-Brahmbhatt,2015-09-16T20:48:54Z,done.,0,0.9640594124794006
39683121,195,Parth-Brahmbhatt,2015-09-16T20:48:56Z,done,0,0.8974218964576721
39683126,195,Parth-Brahmbhatt,2015-09-16T20:48:58Z,done,0,0.8974218964576721
39683134,195,Parth-Brahmbhatt,2015-09-16T20:49:03Z,may be i am missing it but where do you see the side effect?,0,0.9736868143081665
39683137,195,Parth-Brahmbhatt,2015-09-16T20:49:07Z,done.,0,0.9640594124794006
39683204,195,Parth-Brahmbhatt,2015-09-16T20:49:40Z,added a consistent audit log message in addition to the other logging statements.,0,0.9889696836471558
39683466,195,Parth-Brahmbhatt,2015-09-16T20:51:45Z,"the original version is more readable to me, may be its just my java brain. i have assumed scala idioms make it more redable with your approach so changed it as you suggested. still had to use a return inside the map as acl is not an option but type acl.",0,0.9539468288421631
39684697,195,ijuma,2015-09-16T21:02:19Z,"`milliseconds()` returns a different result every time, so it's a side-effecting method (it gets data from the system clock typically). side-effect free methods always return the same result given the same arguments, so a method that takes no parameters and doesn't return a constant result is a side-effecting method.",0,0.9879690408706665
39769987,195,Parth-Brahmbhatt,2015-09-17T16:55:54Z,my understanding of what side effect is different than what you described. i have added the () anyways given i don't really think it affects readability one way or another.,0,0.9043570756912231
39771350,195,ijuma,2015-09-17T17:08:07Z,it is true that the terminology would be clearer if we used pure versus impure functions. thanks for making the change anyway.,0,0.8400335907936096
39778562,195,Parth-Brahmbhatt,2015-09-17T18:06:46Z,"i actually had to remove the bracket for compilation to succeed. with the beackets i get ""/users/pbrahmbhatt/repo/kafka/core/src/main/scala/kafka/common/zknodechangenotificationlistener.scala:80: long does not take parameters val now = time.milliseconds()""",0,0.9899066090583801
39779399,195,ijuma,2015-09-17T18:13:07Z,sorry for this. the reason is that the scala version of `time` has a method called `milliseconds` so you can't use `()` at the end. the java version of `time` doesn't have this issue.,-1,0.9917190074920654
39812216,195,junrao,2015-09-17T23:45:04Z,"it seems that we don't need both imports on javaconversions? import scala.collection.javaconversions._ seems enough. also, i think the previous version you had to just do the import inside processallnotifications() is better since it makes it clear where the implicits are used.",0,0.9825432896614075
39812243,195,junrao,2015-09-17T23:45:18Z,": i actually find the ""for-loop"" version that parth wrote earlier easier to understand. map() is supposed to convert one collection to another and it seems it's weird to return from inside a map().",-1,0.853743314743042
39812253,195,junrao,2015-09-17T23:45:25Z,why are we looping through resourcenames twice?,0,0.9575660228729248
39812263,195,junrao,2015-09-17T23:45:32Z,could we put addacls() and waituntiltrue() in a private method and reuse?,0,0.9948338270187378
39812389,195,ijuma,2015-09-17T23:47:33Z,i agree that this version looks worse. it's not what i suggested. :) a `getorelse` after the map is what i would do. do you still prefer the previous version in that case?,1,0.9944883584976196
39812505,195,ijuma,2015-09-17T23:49:14Z,", why not simply use import javaconverters._? it's the recommended way since it was introduced years ago. the main advantage is that it is both explicit (one has to use `asscala` or `asjava`) and you don't need scoped imports everywhere (which are quite verbose).",0,0.9904333353042603
39813672,195,ijuma,2015-09-18T00:08:46Z,"to elaborate a bit, `return` is discouraged in scala because it's not composable which makes it harder to refactor code safely. once `return` is used, it is no longer safe to extract code into reusable functions. another problem with `return` is that it uses exceptions for control flow once used inside closures (which are everywhere in scala) as it is the only way to implement the specified behaviour in the jvm. unfortunately, return is used quite a lot in this pr. i'd be willing to submit a pr to this branch that removed all usages of `return` for comparison if there is interest.",0,0.9387590289115906
39813673,195,junrao,2015-09-18T00:08:46Z,using explicit javaconverters will be fine.,0,0.9899026155471802
39813766,195,junrao,2015-09-18T00:10:24Z,could you post the exact syntax you had in mind?,0,0.9845477938652039
39814098,195,ijuma,2015-09-18T00:16:15Z,[code block] or [code block] the latter is more concise although we don't use it much in kafka yet.,0,0.9920212626457214
39862295,195,junrao,2015-09-18T14:46:40Z,"it would be better to move this inside processallnotifications() so that we know exactly where the implicits are used. alternatively, we can use the explicit conversion through javaconverters as isamel suggested.",0,0.9953291416168213
39862320,195,junrao,2015-09-18T14:46:48Z,could we just return boolean here?,0,0.9930566549301147
39862560,195,junrao,2015-09-18T14:48:44Z,"it seems that if filteredacls is empty, we want to remove the corresponding acl path. could we add a unit test for that? also, we probably only need to update zk if filteredacls is different from existingacls.",0,0.994596540927887
39862611,195,junrao,2015-09-18T14:49:15Z,"could we make this more general to sth like the following? then we can remove all individual usage of waituntiltrue(). // return the new acl set after applying the changes to the original acl. changeaclandverify(originalacl: set[acl], addedacl: set[acl], removedacl: set[acl]): set[acl]",0,0.9928908348083496
39862755,195,ijuma,2015-09-18T14:50:22Z,is this used anywhere?,0,0.989799976348877
39863387,195,ijuma,2015-09-18T14:55:29Z,`exists` is probably better than `find` here as you are not using the value. maybe something like [code block],0,0.9933295845985413
39863729,195,ijuma,2015-09-18T14:58:33Z,"a number of typing annotations that could be removed as they are easily inferred (`string`, `set[acl]`, `acl`). it's ok to keep them if you think they help readability (as opposed to just java habits ;)).",0,0.9274861812591553
39864202,195,ijuma,2015-09-18T15:02:28Z,"remove type annotation on the left-hand side? also, you can replace `hashmap` with `map` which is the static factory method.",0,0.9945852160453796
39864888,195,ijuma,2015-09-18T15:08:31Z,`aclcache.values.flatmap(_.filter(_.principal == principal)).toset` should do the same as all of the lines above. the following is a bit more readable though: `aclcache.values.flatmap(aclset => aclset.filter(_.principal == principal)).toset`,0,0.9926141500473022
39884655,195,Parth-Brahmbhatt,2015-09-18T18:15:57Z,done,0,0.8974218964576721
39884657,195,Parth-Brahmbhatt,2015-09-18T18:16:00Z,done.,0,0.9640594124794006
39885138,195,Parth-Brahmbhatt,2015-09-18T18:20:36Z,we were not deleting the zookeeper path until an explicit call to remove(resource was made). i have changed that and added unit test. to read the zookeeper path i made the method toresourcepath public.,0,0.990868330001831
39885146,195,Parth-Brahmbhatt,2015-09-18T18:20:41Z,done,0,0.8974218964576721
39885153,195,Parth-Brahmbhatt,2015-09-18T18:20:47Z,in the initialize we register this zkclient so in case a reconnection happens zkclient will invoke this method and as part handling a new session it will process any missed notifications during the reconnection.,0,0.9932941198348999
39885157,195,Parth-Brahmbhatt,2015-09-18T18:20:49Z,done.,0,0.9640594124794006
39885181,195,Parth-Brahmbhatt,2015-09-18T18:21:03Z,"java habits, nothing really to do with readability :-). guess it's going to take me sometime before i stop doing this.",1,0.9474785923957825
39885186,195,Parth-Brahmbhatt,2015-09-18T18:21:08Z,removed the type. trying to convert to map actually gives compilation error.,0,0.9444398283958435
39885345,195,Parth-Brahmbhatt,2015-09-18T18:22:42Z,"i actually realized one thing, given acl class itself does not have resource as acls are suppose to be attached to a resource, this method is pretty useless unless it returns a map[resource, set[acl]]. i have made the changes to both the interface and the implementation to reflect that.",0,0.6322903633117676
39893276,195,junrao,2015-09-18T19:42:14Z,empty set => empty map,0,0.9850549697875977
39893280,195,junrao,2015-09-18T19:42:17Z,space after if,0,0.9853398203849792
39893304,195,junrao,2015-09-18T19:42:36Z,has a valid point. it doesn't seem reconnection is ever used? the handling of the reconnection logic is all in handlenewsession().,0,0.9912939667701721
39893656,195,Parth-Brahmbhatt,2015-09-18T19:46:58Z,sorry i though he was referring to zkstatechangelistener object itself. removed.,-1,0.9929875731468201
39893666,195,Parth-Brahmbhatt,2015-09-18T19:47:01Z,done.,0,0.9640594124794006
39893669,195,Parth-Brahmbhatt,2015-09-18T19:47:03Z,done.,0,0.9640594124794006
39931619,195,junrao,2015-09-20T16:30:51Z,"startup() implies this class will have internal threads, but it doesn't. would it be better to rename this to init()?",0,0.992901623249054
39931623,195,junrao,2015-09-20T16:31:00Z,"to be consistent with the line in 86, set.empty => set.empty[kafkaprincipal]?",0,0.9953957200050354
39931626,195,junrao,2015-09-20T16:31:27Z,"the ordering can be a bit subtle here. in order not to miss a session expiration event, we should probably use the following ordering. zkclient = zkutils.createzkclient(zkurl, zkconnectiontimeoutms, zksessiontimeoutms) zkutils.makesurepersistentpathexists(zkclient, simpleaclauthorizer.aclzkpath) [code block]",0,0.9927024841308594
39931632,195,junrao,2015-09-20T16:31:36Z,"we should add the acl to aclcache, right? could we add a unit test to cover this?",0,0.9943506121635437
39931641,195,junrao,2015-09-20T16:32:10Z,"it seems that we expect notificationmessage to be non-empty. so, perhaps we can change the type of processnotifications to be just string and in zknodechangenotificationlistener.processnotifications(), log a warning (with the path) if the data read from zk is empty.",0,0.993631899356842
39931644,195,junrao,2015-09-20T16:32:21Z,"simpleaclauthorizer should be authorizer? also, we should add a loadcache() tests where all the nodes in /acl_changes are gone.",0,0.9943463206291199
40006553,195,Parth-Brahmbhatt,2015-09-21T18:24:46Z,done.,0,0.9640594124794006
40006570,195,Parth-Brahmbhatt,2015-09-21T18:24:52Z,done.,0,0.9640594124794006
40006588,195,Parth-Brahmbhatt,2015-09-21T18:25:01Z,done.,0,0.9640594124794006
40006914,195,Parth-Brahmbhatt,2015-09-21T18:27:34Z,"originally i did that but i figured given we havent added add,remove apis in reality add/remove calls will be made from cli so modifying cache did not make much sense. also it seemed cleaner to just have a single path (notification) that updated the cache and also made it easy to test. i have made changes to update the cache as you suggested but i don't see given the same state can be modified by 2 components there is any easy way to add unit test to ensure which component actually made the state change.",0,0.9750661253929138
40006927,195,Parth-Brahmbhatt,2015-09-21T18:27:42Z,done.,0,0.9640594124794006
40006945,195,Parth-Brahmbhatt,2015-09-21T18:27:51Z,done.,0,0.9640594124794006
40020498,195,junrao,2015-09-21T20:20:35Z,"this can just be private def loadcache() { ... } there are a few other places that we can get rid of "": unit ="".",0,0.9923726320266724
40020520,195,junrao,2015-09-21T20:20:49Z,"we shouldn't be accumulating in acls, right?",0,0.9639462232589722
40020555,195,junrao,2015-09-21T20:21:04Z,could we set up two resources with acl to cover the new issue identified in loadcache()?,0,0.9953293800354004
40020567,195,junrao,2015-09-21T20:21:09Z,space after if,0,0.9853398203849792
40022804,195,Parth-Brahmbhatt,2015-09-21T20:40:13Z,done.,0,0.9640594124794006
40022808,195,Parth-Brahmbhatt,2015-09-21T20:40:14Z,done,0,0.8974218964576721
40022814,195,Parth-Brahmbhatt,2015-09-21T20:40:18Z,"yes, done.",0,0.9001237750053406
40022826,195,Parth-Brahmbhatt,2015-09-21T20:40:24Z,done.,0,0.9640594124794006
40027139,195,junrao,2015-09-21T21:16:44Z,"remove "": unit =""",0,0.9913846254348755
40027169,195,junrao,2015-09-21T21:17:02Z,"if a method has no return value, we need to define it as the following w/o =. otherwise, it will pick up the value in the last statement as the return value. ditto in a few other places. def loadcache() { }",0,0.9836734533309937
40028686,195,Parth-Brahmbhatt,2015-09-21T21:28:35Z,done.,0,0.9640594124794006
40028689,195,Parth-Brahmbhatt,2015-09-21T21:28:37Z,done.,0,0.9640594124794006
40035419,195,junrao,2015-09-21T22:35:14Z,remove =,0,0.9586599469184875
40035425,195,junrao,2015-09-21T22:35:20Z,remove =,0,0.9586599469184875
40035432,195,junrao,2015-09-21T22:35:25Z,remove =,0,0.9586599469184875
40035437,195,junrao,2015-09-21T22:35:29Z,remove =,0,0.9586599469184875
40035443,195,junrao,2015-09-21T22:35:33Z,remove =,0,0.9586599469184875
40035455,195,junrao,2015-09-21T22:35:40Z,testprocessnotification(),0,0.9896346926689148
40035464,195,junrao,2015-09-21T22:35:47Z,def testtopicacl() {,0,0.9902245402336121
40035473,195,junrao,2015-09-21T22:35:52Z,def testdenytakesprecedence() {,0,0.9807754755020142
40035480,195,junrao,2015-09-21T22:35:55Z,def testallowallaccess() {,0,0.9902948141098022
40035489,195,junrao,2015-09-21T22:36:01Z,def testsuperuserhasaccess() {,0,0.9891656041145325
40035496,195,junrao,2015-09-21T22:36:05Z,def testnoaclfound() {,0,0.9912972450256348
40035506,195,junrao,2015-09-21T22:36:13Z,def testnoaclfoundoverride() {,0,0.9893459677696228
40035514,195,junrao,2015-09-21T22:36:19Z,def testaclmanagementapis() {,0,0.9921683669090271
40035523,195,junrao,2015-09-21T22:36:24Z,def testloadcache() {,0,0.9913126826286316
113242905,2910,ijuma,2017-04-25T16:19:38Z,seems like passing `isolationlevel` explicitly is a good idea anyway. maybe we don't need this comment.,0,0.947882890701294
113243316,2910,ijuma,2017-04-25T16:21:24Z,"if we don't use `buffer` in this path, do we still want to allocate it eagerly?",0,0.9928926229476929
113244042,2910,ijuma,2017-04-25T16:24:27Z,you could use `map` instead of pattern matching.,0,0.9910448789596558
113244445,2910,ijuma,2017-04-25T16:26:03Z,maybe this block should be in a separate method.,0,0.9921749234199524
113244887,2910,ijuma,2017-04-25T16:27:41Z,nit: just use `filechannel.open` directly?,0,0.9924024343490601
113244991,2910,ijuma,2017-04-25T16:28:05Z,how do we go about deciding whether to use schema classes or writing to the buffer directly?,0,0.9917318820953369
113246179,2910,ijuma,2017-04-25T16:32:39Z,"a general comment about default values: we should consider carefully when to use them as they are a common source of bugs. when we use them, the compiler no longer ensures that we think about what the value should be.",0,0.9866883158683777
113247921,2910,hachikuji,2017-04-25T16:39:33Z,ack. was thinking the same thing when i was looking over this.,-1,0.9748131036758423
113248857,2910,hachikuji,2017-04-25T16:43:30Z,"sure, we can push allocation into the other branch. this is technically a bug fix, by the way, since `log.read` can return `memoryrecords.empty`.",0,0.9943673014640808
113249530,2910,hachikuji,2017-04-25T16:46:28Z,"yeah, it was a tough call. there's only a handful of use cases for `isfromclient = false`, and the default is the more restrictive option, so i thought it was reasonable.",-1,0.6463431119918823
113253193,2910,hachikuji,2017-04-25T17:01:32Z,"kind of a subjective call, but since we scan the abort index when handling fetches and the schema is so simple, i thought we could skip the need to go through the `struct` object when reading and writing.",0,0.9577631950378418
113829442,2910,junrao,2017-04-28T00:08:43Z,"during append, perhaps it's useful to assert that abortedtxn are inserted in ascending lastoffset order?",0,0.9945201277732849
113830001,2910,junrao,2017-04-28T00:13:54Z,"we don't set the position of channel after channel.truncate(), which seems ok. for consistency, we probably want to do the same in filerecords.truncateto()?",0,0.994513988494873
113830270,2910,junrao,2017-04-28T00:16:40Z,"it seems that we can just allocate a single buffer and reuse, instead of reallocating?",0,0.992480993270874
113831097,2910,junrao,2017-04-28T00:25:40Z,we throw an exception in the iterator below. should we do the same thing here?,0,0.9744387269020081
113832544,2910,junrao,2017-04-28T00:42:38Z,could we add some comments on what's stored in this index?,0,0.9926978945732117
113833158,2910,junrao,2017-04-28T00:49:14Z,it would be useful to document whether firstoffset and lastoffset are inclusive or exclusive.,0,0.9884110689163208
113834767,2910,junrao,2017-04-28T01:05:00Z,it seems that we are missing the logic to fence off the request based on coordinatorepoch?,0,0.9858249425888062
113834965,2910,junrao,2017-04-28T01:07:18Z,we can probably use requesttimeoutms.,0,0.9922776222229004
113836150,2910,junrao,2017-04-28T01:21:01Z,could we document the new field in the java doc above?,0,0.9902811050415039
113838187,2910,junrao,2017-04-28T01:47:43Z,could we add the new field to the comment above? ditto for line 485.,0,0.9862937927246094
113838217,2910,junrao,2017-04-28T01:48:05Z,"now that we have a few different types of epoch, could we change epoch to producerepoch?",0,0.9920006990432739
113972136,2910,junrao,2017-04-28T16:44:41Z,"could we add a method in recordbatch to indicate whether the batch is a controlled batch or not? also, it seems that we use a special sequence number to indicate whether a batch is controlled or not. would it be better to use another bit in the attribute for that?",0,0.9951462149620056
114010900,2910,junrao,2017-04-28T20:14:09Z,epoch => producerepoch? ditto in line 54.,0,0.9913300275802612
114013479,2910,junrao,2017-04-28T20:29:42Z,"there can only be one opening transaction from a pid, right? if so, does startedtxns need to be a set?",0,0.9913259148597717
114016660,2910,junrao,2017-04-28T20:48:04Z,"hmm, it seems because of this, we could be sending multiple responses for the same writetxnmarkersrequest, which won't be right?",0,0.6258726119995117
114018063,2910,junrao,2017-04-28T20:56:00Z,the spec says the value of the control record contains the coordinatorepoch.,0,0.9927258491516113
114018154,2910,junrao,2017-04-28T20:56:28Z,could we be calculate the buffer size more precisely?,0,0.9926579594612122
114035995,2910,junrao,2017-04-28T23:22:43Z,"hmm, when this is called on the leader side, we haven't assigned the offset for the record yet. it seems that this means the offset returned in appendinfo.completedtransactions will be incorrect when we try to use it?",0,0.9398876428604126
114036286,2910,junrao,2017-04-28T23:25:54Z,"when firstoffset is set to controlrecord.offset, it seems that lastoffset could be smaller than firstoffset. should we guard that?",0,0.9880291819572449
114038106,2910,junrao,2017-04-28T23:50:45Z,do we need to call this here given that we are calling the same method in onhighwatermarkincremented()?,0,0.9951257109642029
114039345,2910,junrao,2017-04-29T00:09:55Z,could we add isolationlevel to the comment above?,0,0.9938341379165649
114039715,2910,junrao,2017-04-29T00:16:26Z,"we probably want to use the offset in fetchinfo instead of startoffset, which can be larger than startoffset?",0,0.9947521686553955
114040200,2910,junrao,2017-04-29T00:25:52Z,should we call updatefirstunstableoffset() in truncateto() too?,0,0.9951142072677612
114362367,2910,hachikuji,2017-05-02T16:29:01Z,i think we already do. it is in the call to `buildandrecoverpidmap`.,0,0.9924086332321167
114367045,2910,hachikuji,2017-05-02T16:48:37Z,the responses are accumulated and only sent after all callbacks have been received. i can change the name to clarify this.,0,0.9888490438461304
114367825,2910,hachikuji,2017-05-02T16:52:00Z,hmm.. yes that sounds right.,0,0.8977025151252747
114400313,2910,hachikuji,2017-05-02T19:11:25Z,i've fixed this. we always use the offset of the control record as the last offset.,0,0.9819642305374146
114460760,2910,junrao,2017-05-03T01:33:01Z,"getting the position requires index lookup and may be a bit expensive. do we really need to maintain position? it seems that when using firstunstableoffset, we only need the offset, not the position?",0,0.9682764410972595
114461895,2910,junrao,2017-05-03T01:49:48Z,"hmm, log.firstunstableoffset is only advanced after the completemarker has been fully replicated, which suggests that log.firstunstableoffset is always going to be < highwatermark?",0,0.9908610582351685
114614159,2910,hachikuji,2017-05-03T18:08:06Z,"i realized that we need all started transactions in order to ensure that the lso is updated correctly. we take all the started transactions from an append, add them to a sorted collection, and then remove the completed transactions in order of completion. this ensures that the lso is always correct.",0,0.9827436208724976
114662697,2910,junrao,2017-05-03T21:54:11Z,could we add a comment whether fetchoffset and upperboundoffset are inclusive or exclusive?,0,0.9940502047538757
114678287,2910,junrao,2017-05-03T23:45:30Z,"when we call roll(), the base offset of the new segment could actually be larger than logendoffset. so, in that case, the snapshot offset may not match the base offset of the next segment. since in flush(), we delete snapshots based on the baseoffset of the active segment, we may delete the last snapshot by accident. one way to fix this is to call producerstatemanager.updatemapendoffset(newoffset) before taking the snapshot.",0,0.9912887811660767
114679141,2910,junrao,2017-05-03T23:53:23Z,"hmm, the comment in line 72 says completed txns are sorted by last offset, which seems to be what we want?",0,0.9895321130752563
114680532,2910,junrao,2017-05-04T00:05:19Z,the warn in line 312 now needs to include the tnx index.,0,0.9934280514717102
114681599,2910,junrao,2017-05-04T00:15:57Z,"this can be done later. but reloading the snapshot when recovering every segment can be expensive. since segments are recovered in order, it seems that we just need to load the snapshot on recovering the first segment.",0,0.9900959730148315
114683318,2910,junrao,2017-05-04T00:35:04Z,"hmm, in theory, it seems that we could have an abort marker with no open records before it?",0,0.9755113124847412
114685936,2910,junrao,2017-05-04T01:05:34Z,"hmm, instead of using hard-coded read_uncommitted, shouldn't we use the isolation_level in the fetcher?",0,0.9932448267936707
114688209,2910,junrao,2017-05-04T01:37:56Z,"hmm, not sure about the comment on hw. with kip-101, typically the truncation point is >= the local hw.",0,0.9194560050964355
114882654,2910,hachikuji,2017-05-04T20:42:54Z,"ah, good catch. forgot to update this after the transactional client patch was merged.",1,0.7764070630073547
114899888,2910,hachikuji,2017-05-04T22:13:47Z,"sorting by the first offset is what we want. this is used to find the first unstable offset which will always be the minimum first offset of all transactions. i couldn't find the comment you were referring to since the patch was updated. if it still exists, can you point me to it?",0,0.9891874194145203
114900931,2910,hachikuji,2017-05-04T22:20:48Z,"hmm... good point. i had thought it was necessary since the first unstable offset could be lower than the high watermark, but we wouldn't be able to advance it any further from this write because any appended transaction markers could not have been replicated yet.",1,0.8330235481262207
114904376,2910,junrao,2017-05-04T22:44:15Z,"hmm, this logic may not be quite right for the follower. the follower could append batches for different pids in a single append call, if we reject all batches because a single batch is duplicated, the follower will miss records from other pids. in theory, duplicates should never happen in the follower. if duplicates somehow already leaked into the leader, it's kind of hard to not take the duplicates in the follower since the follower's log is supposed to be identical with the leader. so, perhaps we can only return on duplicates if the append is on the leader. if duplicates are detect in the follower, just log a warning but proceed with the append?",0,0.7696812152862549
114906482,2910,junrao,2017-05-04T22:59:59Z,"it's a bit inconsistent that we serialize the value here, but the key inside appendcontrolrecord(). perhaps it's better to serialize the value inside appendcontrolrecord() too?",0,0.9705513119697571
114916532,2910,junrao,2017-05-05T00:32:48Z,fetching up the the => fetching up to the,0,0.89524245262146
114918036,2910,hachikuji,2017-05-05T00:52:14Z,"the intent was to return a duplicate only if `isfromclient` is set (which would never be the case for the follower), but it looks like i left that out. i'll fix in the next commit.",0,0.9876307845115662
114918859,2910,hachikuji,2017-05-05T01:04:36Z,"i was trying to keep `appendcontrolrecord` generic for future control record types. that said, it seems reasonable to add an `appendendtxnmarker` which handles serialization of both the key and value.",0,0.9931023120880127
115065007,2910,junrao,2017-05-05T18:51:10Z,do we need to get position from segment.append()? we could also just get the size of the segment before appending.,0,0.9928130507469177
115079600,2910,junrao,2017-05-05T20:17:21Z,it seems that undecidedfirstoffset should never be < unreplicatedfirstoffset?,0,0.9806402921676636
115080853,2910,junrao,2017-05-05T20:24:56Z,do we need to do this under lock since we are updating the state in producerstatemanager?,0,0.9947172999382019
115082326,2910,junrao,2017-05-05T20:33:58Z,are the callers all properly synchronized on log.lock?,0,0.9936424493789673
115088857,2910,junrao,2017-05-05T21:14:23Z,epoch => producerepoch ?,0,0.9915580749511719
115090409,2910,junrao,2017-05-05T21:24:45Z,should we print out an error in the else clause?,0,0.9925684928894043
115094046,2910,hachikuji,2017-05-05T21:50:01Z,"i think it is possible. you may have something like this: w1, w2, c2, c1 (where w1 is a write from producer 1, and c1 is a commit from producer 1). say the high watermark has reached c1 (which means the transaction from producer 1 is not yet visible). in this case, the first undecided offset will be w1 while the first unreplicated offset will be w2.",0,0.9898382425308228
115097120,2910,hachikuji,2017-05-05T22:15:31Z,i added some code to print the unknown type id in the else case. let me know if that seems reasonable.,0,0.9697026014328003
115099271,2910,hachikuji,2017-05-05T22:35:37Z,"the example was a little wrong. the proper scenario is this: w1, w2, c2 say the high watermark is at c2. the first undecided offset will be w1, but the first unreplicated offset will be w2. once the high watermark reaches c2+1, the first undecided offset will still be w1 and the first unreplicated offset will be empty.",0,0.942504346370697
634023546,10579,satishd,2021-05-18T04:06:08Z,`config` definition will be moved to `kafkaconfig` later when default rlmm is integrated with the broker.,0,0.9938365817070007
640140543,10579,junrao,2021-05-26T21:40:19Z,"if the producer/consumer are configured incorrectly, we want to fail faster instead of retrying.",0,0.9179747104644775
640140766,10579,junrao,2021-05-26T21:40:51Z,"since producermanager and consumermanager are updated in a separate thread without holding lock, do they need to be volatile?",0,0.9933367967605591
640142495,10579,junrao,2021-05-26T21:44:24Z,should we pass in time through the constructor?,0,0.9941534399986267
640147224,10579,junrao,2021-05-26T21:54:14Z,do we need this since it's in the caller already?,0,0.9942574501037598
640148086,10579,junrao,2021-05-26T21:55:54Z,waiting for each event to be consumed reduces throughput. could we handle the expected metadata load with this?,0,0.9923332929611206
640154886,10579,junrao,2021-05-26T22:08:46Z,remotelogmetadatacontext => remotelogmetadata?,0,0.9921165108680725
640157247,10579,junrao,2021-05-26T22:12:05Z,no need to cast to kafkaexception.,0,0.9894212484359741
640158657,10579,junrao,2021-05-26T22:15:25Z,sending one event at a time reduces the batching benefit in the producer. could this handle the expected metadata load?,0,0.9907624125480652
640158995,10579,junrao,2021-05-26T22:16:09Z,could we add a comment for this class?,0,0.9919248223304749
640979693,10579,junrao,2021-05-27T21:28:06Z,typo ard,0,0.9626649022102356
640996146,10579,junrao,2021-05-27T21:56:15Z,"hmm, shouldn't we start with assignedmetapartitions?",0,0.9753453731536865
640997181,10579,junrao,2021-05-27T21:57:24Z,"hmm, assignedmetapartitions may not change if assignedtopicpartitions changes. should we still update assignedtopicpartitions in that case?",0,0.9533362984657288
641001043,10579,junrao,2021-05-27T22:04:49Z,from which offset does the consumer start fetching?,0,0.9903205037117004
641029590,10579,junrao,2021-05-27T23:10:00Z,should we only process events corresponding to assignpartitions?,0,0.9941734671592712
641030221,10579,junrao,2021-05-27T23:11:42Z,"if a partition is moved to a different broker, we will need to bootstrap the remote state for the partition by consuming from the beginning of the remote metadata partition. how is that handled?",0,0.990653932094574
641031767,10579,junrao,2021-05-27T23:15:58Z,the tostring() method could change over time. perhaps it's safer to compute a customized hashcode for topicidpartition here.,0,0.9919257760047913
641034498,10579,junrao,2021-05-27T23:24:16Z,"bootstrap_servers_config should be prefixed with remote_log_metadata_client_prefix, right?",0,0.9946215152740479
641035399,10579,junrao,2021-05-27T23:26:54Z,do we need this? it seems that it's easier to just duplicate the property for producer and consumer.,0,0.9893631339073181
641093708,10579,junrao,2021-05-28T01:17:10Z,what's the purpose of waiting for consumption up to partitiontotargetendoffsets?,0,0.9900344014167786
642095193,10579,satishd,2021-05-30T15:53:03Z,making volatile makes sense to me.,0,0.9640787243843079
642095217,10579,satishd,2021-05-30T15:53:14Z,done.,0,0.9640594124794006
642095239,10579,satishd,2021-05-30T15:53:34Z,removed the check as you suggsted.,0,0.9882947206497192
642095245,10579,satishd,2021-05-30T15:53:40Z,this method is invoked from multiple threads for different topic partitions. this will not be a bottleneck as each partition's segments will be uploaded in a sequential manner.,0,0.9893268346786499
642095258,10579,satishd,2021-05-30T15:53:47Z,it is needed as the method is declared with throws kafkaexception. i am also fine with removing it as it is a rte.,0,0.9826467633247375
642095262,10579,satishd,2021-05-30T15:53:51Z,multiple events are published by multiple threads and batching will occur in the producer.,0,0.9893525838851929
642095305,10579,satishd,2021-05-30T15:54:06Z,i will add that.,0,0.9809483289718628
642095309,10579,satishd,2021-05-30T15:54:11Z,are you saying it should be initialized with `updatedassignedmetapartitions = new hashset<>(assignedmetapartitions);`. this is not needed as we are recomputing that set based on updatedreassignedpartitions.,0,0.9948902130126953
642095314,10579,satishd,2021-05-30T15:54:14Z,"nice catch, updated.",1,0.96810382604599
642095350,10579,satishd,2021-05-30T15:54:28Z,we have not yet added the code to store the consumed offset and start from those offsets whenever the consumer starts fetching from those partitions. we plan to add that in a subsequent pr.,0,0.9915571212768555
642095355,10579,satishd,2021-05-30T15:54:33Z,"right, i will add that check.",0,0.9819954633712769
642095359,10579,satishd,2021-05-30T15:54:36Z,this is not addressed in this pr. i planned to have a followup pr for these changes. i may use a different consumer for the newly subscribed partitions to build the state.,0,0.9867256879806519
642095367,10579,satishd,2021-05-30T15:54:44Z,"remote_log_metadata_client_prefix is just a prefix for generating client-ids for producer and consumer. if you are talking about the remote log metadata property prefix, it is assumed that the caller would have already removed those prefixes and sent the config. these prefixes are defined [a link]",0,0.9939597845077515
642095371,10579,satishd,2021-05-30T15:54:47Z,"this is to avoid duplicate entries for both the producer and consumer. we added that in the kip earlier. if duplicating is the way we use at other places if any, i am fine with that.",0,0.987000048160553
642095384,10579,satishd,2021-05-30T15:54:49Z,this is leftover code for other changes that i was working on for handling partition moving to a new broker in another branch. i will remove it.,0,0.9732323884963989
642095431,10579,satishd,2021-05-30T15:55:05Z,good point. i will add that.,1,0.9504194259643555
643693257,10579,kowshik,2021-06-02T06:40:28Z,s/set in close state/closed,0,0.9772144556045532
643693431,10579,kowshik,2021-06-02T06:40:47Z,s/metadatapartitionno/metadatapartition,0,0.980741560459137
643694704,10579,kowshik,2021-06-02T06:43:10Z,it appears you could eliminate the additional `topicidpartition` parameter and instead use the value returned by `remotelogmetadata.topicidpartition()` api.,0,0.9948689937591553
643695433,10579,kowshik,2021-06-02T06:44:35Z,it appears this class does not have unit tests currently. is there a plan to add unit tests?,0,0.9858890771865845
643698596,10579,kowshik,2021-06-02T06:50:35Z,could you pls add a comment for this class?,0,0.9929064512252808
643698781,10579,kowshik,2021-06-02T06:50:55Z,s/millis/ms,0,0.9810183048248291
643705660,10579,kowshik,2021-06-02T07:02:30Z,i had the same question. it appears better to just duplicate the properties.,0,0.9649295210838318
643707051,10579,kowshik,2021-06-02T07:04:58Z,"it seems that we have internal topics specified in `org.apache.kafka.common.internals.topic` class. don't we want this new internal topic to be defined in the `topic` class, together with other internal topics?",0,0.9946552515029907
643709758,10579,kowshik,2021-06-02T07:09:25Z,"hmm, why do you need this exclusion to be true?",0,0.8353651165962219
643715269,10579,kowshik,2021-06-02T07:17:49Z,"is this the timeout for how long you'd want the client to wait to consume the message that it produces to `__remote_log_metadata` topic? if yes, then don't we want this timeout to be unlimited i.e. we wait as long as it takes to consume the published event?",0,0.9931995272636414
643716426,10579,kowshik,2021-06-02T07:19:37Z,"`consumerprops` and `producerprops` are of type `map`, therefore the `.tostring()` is probably not readable. so you'd need to convert these into a comma-separated list sth like `k1=v1,k2=v2,...kn=vn`.",0,0.9934179782867432
643725247,10579,kowshik,2021-06-02T07:32:18Z,"for readability, it'll be useful to place the positive case under `if` and negative case under `else`, such as: [code block]",0,0.9845358729362488
643726313,10579,kowshik,2021-06-02T07:33:51Z,could you pls document the state does this boolean represents?,0,0.9900604486465454
643728635,10579,kowshik,2021-06-02T07:37:21Z,could you pls mention what state does this boolean represent?,0,0.9895200729370117
643730668,10579,kowshik,2021-06-02T07:40:20Z,is it useful to assert that `record.key()` is empty before the key is ignored below?,0,0.9953566193580627
643731568,10579,kowshik,2021-06-02T07:41:36Z,"hmm, should you be setting `close` to true here? (it depends on the meaning of `close`, which i don't fully understand....)",0,0.8484841585159302
643736256,10579,kowshik,2021-06-02T07:48:14Z,"it appears that once this logic is implemented, there is probably no need to wait for `maybewaitforpartitionsassignment`. the reason is that whenever a partition is assigned, we will bootstrap the remote state by consuming from the beginning.",0,0.9922135472297668
643738304,10579,kowshik,2021-06-02T07:51:00Z,"do you really need this explicit lock? it seems you could just use `wait()` and `notify()` apis on the `consumertask` object instead, combined with `synchronized` keyword.",0,0.9947113990783691
643740157,10579,kowshik,2021-06-02T07:53:28Z,s/noofmetadatatopicpartitions/nummetadatatopicpartitions,0,0.959364116191864
643740418,10579,kowshik,2021-06-02T07:53:46Z,s/partitionno/partition,0,0.9664816856384277
643740610,10579,kowshik,2021-06-02T07:54:02Z,s/no of.../num of... also it feels overkill to me to log this message for each call.,-1,0.5347892045974731
643742067,10579,kowshik,2021-06-02T07:55:59Z,"is topic necessary here, when uuid and partition is already sufficient input for the hash?",0,0.9942933917045593
643745043,10579,kowshik,2021-06-02T08:00:02Z,it seems these 2 attributes can be marked final if you call `map.clear()` in `close()` instead of replacing the reference.,0,0.9941428303718567
643746007,10579,kowshik,2021-06-02T08:01:17Z,s/logs/log ?,0,0.9861577749252319
643749217,10579,kowshik,2021-06-02T08:05:53Z,i agree with the question here. this can become more expensive than it seems. the alternative is to pursue an asynchronous notification model to improve the throughput.,0,0.9707720279693604
643754935,10579,kowshik,2021-06-02T08:14:07Z,could you pls add a comment on what state does `close` represent?,0,0.9916763305664062
648927106,10579,satishd,2021-06-10T07:36:25Z,"as we discussed offline, we see the benefit of keeping several common client config like security to be shared across producer and consumer props avoiding any copy/paste mistakes. user has an option not to use common client configs and use the respective producer and consumer configs.",0,0.9839592576026917
649387317,10579,satishd,2021-06-10T17:30:15Z,i plan to add this once rlmm is called from remote log layer classes. i wanted this change to be self contained for now.,0,0.9834203720092773
649387744,10579,satishd,2021-06-10T17:30:37Z,we do not want this to be completely blocked as we want to release the remote log thread after a specific timeout in case of any intermittent issues so that other partitions tiring can proceed.,0,0.9691194891929626
649387805,10579,satishd,2021-06-10T17:30:40Z,"we are using hashmap for these instances and it prints k,v format. are you suggesting that this map implementation may change as it is of type map and need to put the right tostring. we can change the reference type to hashmap for clarity if needed.",0,0.9905513525009155
649388017,10579,satishd,2021-06-10T17:30:51Z,i do not think that check is really needed here.,0,0.846735954284668
649388066,10579,satishd,2021-06-10T17:30:53Z,"it indicates whether the closing process has been started or not. if it is set as true, consumer will stop consuming messages and it will not allow partition assignments to be updated. updated the java doc of close.",0,0.9937549829483032
649388122,10579,satishd,2021-06-10T17:30:57Z,i wanted to have a separate lock instance specifically for the assignments and the respective processing. it gives better clarity and separations even if we add any other logic by taking lock on this instance.,0,0.9868568778038025
649388430,10579,satishd,2021-06-10T17:31:13Z,good point. we can skip topic as topic-id is sufficient here.,1,0.7242886424064636
649388497,10579,satishd,2021-06-10T17:31:16Z,i went with assigning empty map as map.clear() needs to go through all the entries and dereference them. another way is to leave the map as it is and set the cose state and do not allow any operation when it is closed but it will have a check for each call.,0,0.9749636650085449
649390143,10579,satishd,2021-06-10T17:32:50Z,done,0,0.8974218964576721
649390214,10579,satishd,2021-06-10T17:32:56Z,done,0,0.8974218964576721
649390292,10579,satishd,2021-06-10T17:33:03Z,done,0,0.8974218964576721
649390516,10579,satishd,2021-06-10T17:33:26Z,done.,0,0.9640594124794006
649390677,10579,satishd,2021-06-10T17:33:41Z,done,0,0.8974218964576721
650456266,10579,satishd,2021-06-13T01:49:18Z,done,0,0.8974218964576721
656734732,10579,ccding,2021-06-23T03:38:22Z,can we avoid making the variable name the same as the function name?,0,0.9928016662597656
656735781,10579,ccding,2021-06-23T03:42:06Z,"why is the variable name `partitions`, while the one above for `addassignmentsforpartitions` is `allpartitions`? also why one is `set` and the other is `hashset`?",0,0.995205283164978
656737032,10579,ccding,2021-06-23T03:46:28Z,i think in the codebase we use `ms` more often than using `millis`,0,0.988264799118042
656737294,10579,ccding,2021-06-23T03:47:23Z,should this be fixed or configurable in `rlmmconfig`?,0,0.9951375126838684
656737888,10579,ccding,2021-06-23T03:49:16Z,`id` -> `if`,0,0.9908052682876587
656738264,10579,ccding,2021-06-23T03:50:38Z,"we may want a better variable name here. e.g., `isclosing` or `closed` or something else.",0,0.9932651519775391
656740556,10579,ccding,2021-06-23T03:57:00Z,"multiple threads are reading and writing `close`, which is not thread safe",0,0.9511070251464844
656740892,10579,ccding,2021-06-23T03:58:12Z,"why is this set to 30, rather than another number like 10, 50, 100?",0,0.9880744814872742
656741851,10579,ccding,2021-06-23T04:01:33Z,is the check necessary?,0,0.991042971611023
656743129,10579,ccding,2021-06-23T04:06:13Z,can you explain what this variable means?,0,0.9836339354515076
656744938,10579,ccding,2021-06-23T04:12:18Z,also here. why are the variable names different? one is `updatedpartitions` and the other is `partitions`,0,0.9947072267532349
656747158,10579,ccding,2021-06-23T04:19:48Z,what is the cost of consuming from the beginning if the remote metadata partition grows huge?,0,0.9753028154373169
656748094,10579,ccding,2021-06-23T04:22:44Z,"the function name is a little confusing with variable names in the same class, e.g., `assignpartitions`, `assignedtopicpartitions`. i am not sure if it would be better to rename `assignedpartition` to `isassignedpartition`.",0,0.8392837047576904
656748535,10579,ccding,2021-06-23T04:24:11Z,not good to use the same name for a variable and a function.,0,0.575972318649292
656749199,10579,ccding,2021-06-23T04:26:28Z,greater than or equal to?,0,0.983993649482727
656749604,10579,ccding,2021-06-23T04:27:45Z,will the exception be caught by your own catch in line 74? maybe move it out of the `try` block?,0,0.9953082203865051
656751271,10579,ccding,2021-06-23T04:32:53Z,out of curiosity: why we don't do the check within the `new kafkaexception(...)` call,0,0.9871565699577332
656751707,10579,ccding,2021-06-23T04:34:24Z,is the check necessary?,0,0.991042971611023
656752286,10579,ccding,2021-06-23T04:36:07Z,new line at the end of the file,0,0.9873916506767273
656761165,10579,ccding,2021-06-23T05:03:18Z,"function names `addremotelogsegmentmetadata`, `updateremotelogsegmentmetadata`, and `putremotepartitiondeletemetadata` don't seem very consistent. is there a way to improve it?",0,0.9850642085075378
656764820,10579,ccding,2021-06-23T05:13:51Z,"here has a race condition. it is possible `close=false` before calling `ensureinitializedandnotclosed()` and the `close()` function call by another thread has completed before calling `remotepartitionmetadatastore.listremotelogsegments(topicidpartition, leaderepoch)`. i think we should always grab a read lock before calling `ensureinitializedandnotclosed();`, or do some other fancy things.",0,0.9817294478416443
657655419,10579,satishd,2021-06-24T06:16:27Z,"`close/closing` is already volatile and its state is immediately reflected in other threads. in `close()` method, the consumer is invoked with `wakeup()`, and the other thread may receive `wakeupexception` if it is executing `poll()` or earlier than that. if it is after `poll` then the next check of `close/closing` allows to come out and finally close the consumer. `updateassignmentsforpartitions` and `close()` methods can not be called concurrently as it is alreadyhandled by `topicbasedremotelogmetadatamanager`.",0,0.9945698380470276
657655825,10579,satishd,2021-06-24T06:17:20Z,"when the code was refactored, it went with the caller method arg names. thanks for catching these.",1,0.7083516716957092
657655966,10579,satishd,2021-06-24T06:17:37Z,"what about `must be less than the partition count`, conveys the intent clearly.",0,0.9734868407249451
657656102,10579,satishd,2021-06-24T06:17:55Z,"if you are asking about the earlier catch block, that will not cover the exceptions like receiving from broker etc. the earlier catch block is applicable only until the record is added to the accumulator.",0,0.992230236530304
657657314,10579,satishd,2021-06-24T06:20:42Z,i did not add the checks for these methods as they will not be invoked in parallel when close is called. but i agree to have the guards here with read lock.,0,0.9800695180892944
657670757,10579,satishd,2021-06-24T06:47:34Z,this is a temporary change. i plan to have a config with a default value.,0,0.9246600866317749
657671527,10579,satishd,2021-06-24T06:48:51Z,what about `ispartitionassigned`?,0,0.9934345483779907
657674359,10579,satishd,2021-06-24T06:53:57Z,"javadocs explain the behaviorr in detail. `addremotelogsegmentmetadata` - adds a new entry. `updateremotelogsegmentmetadata ` - updates an existing entry. `putremotepartitiondeletemetadata ` - adds or updates an existing entry, put is generally used for that purpose. if this is not so clear, another option can be `addorupdateremotepartitiondeletemetadata`.",0,0.9942283630371094
657683814,10579,satishd,2021-06-24T07:10:29Z,"as we discussed offlime, this may not become a bottleneck but we will make respective rlmm apis asynchronous so that the apis are extensible and implementors can provide async behavior.filed [a link] to track this issue.",0,0.992184579372406
658361692,10579,satishd,2021-06-24T23:58:23Z,i plan to have a config with a default value in a follow-up pr.,0,0.9400839805603027
660802584,10579,junrao,2021-06-29T16:58:25Z,"hmm, why is this a daemon thread? it seems that we want to coordinate the shutdown of the thread.",0,0.9651826620101929
660810740,10579,junrao,2021-06-29T17:10:21Z,"hmm, should we throw an exception in this case so that the caller knows the operation has failed?",0,0.9850645661354065
660812883,10579,junrao,2021-06-29T17:13:31Z,"similar to the above, should we throw an exception in this case so that the caller knows the operation has failed?",0,0.9940282106399536
660836440,10579,junrao,2021-06-29T17:45:05Z,we need to unblock the wait if we are closing the consumer.,0,0.9789087772369385
660975970,10579,junrao,2021-06-29T21:28:57Z,"is this necessary since immediately after this check, the consumer task could be closed. ditto in other places.",0,0.9834492802619934
660980922,10579,junrao,2021-06-29T21:37:50Z,"is this necessary? once producer is closed, send() will throw an exception.",0,0.9752880930900574
660990345,10579,junrao,2021-06-29T21:54:51Z,how is this different from remotelogmetadatacache? it seems that it's just a wrapper over remotelogmetadatacache?,0,0.9872106313705444
660991871,10579,junrao,2021-06-29T21:58:01Z,could we add a comment for this class?,0,0.9919248223304749
661000698,10579,junrao,2021-06-29T22:17:24Z,why do we need to initialize in a separate thread?,0,0.9845506548881531
661002879,10579,junrao,2021-06-29T22:22:17Z,"since we have a lock, could we just make closing a boolean?",0,0.9910157918930054
661629252,10579,junrao,2021-06-30T16:20:30Z,millis => ms to be consistent with other places. ditto in a few other places.,0,0.9895557761192322
661641738,10579,junrao,2021-06-30T16:36:54Z,is this needed since we log all configs when creating kafkaconfig already?,0,0.9947571754455566
661642633,10579,junrao,2021-06-30T16:38:10Z,"other plugins on the broker may also need a bootstrap_server config. to distinguish them, it would be useful to add a prefix that's specific to remote storage.",0,0.9924841523170471
661672097,10579,junrao,2021-06-30T17:20:36Z,"it seems that we need to automatically create metadata topic in rlmm implementation, not just in tests.",0,0.9916080236434937
661673976,10579,junrao,2021-06-30T17:23:08Z,120s seems quite long. do we need to wait that long?,0,0.6382086277008057
661687251,10579,junrao,2021-06-30T17:42:56Z,typo nto,0,0.9480653405189514
661687392,10579,junrao,2021-06-30T17:43:09Z,this sentence doesn't read well.,0,0.6932094097137451
661693600,10579,junrao,2021-06-30T17:52:25Z,this should be for consumer?,0,0.9922687411308289
661698279,10579,junrao,2021-06-30T17:59:31Z,why are we testing against -1 here but 0 above?,0,0.9854224920272827
663808257,10579,satishd,2021-07-05T10:06:16Z,"good catch, updated it.",1,0.9530324935913086
663809083,10579,satishd,2021-07-05T10:07:34Z,there are two implementations about this class for both `remotelogmetadatacache` and `topicbasedremotelogmetadatamanager`. there are common tests in `remotelogsegmentlifecycletest `that we want to run for both of them.,0,0.9946710467338562
663809683,10579,satishd,2021-07-05T10:08:27Z,it was required to be retried until the topic is successfully created. i added the logic to check for topic creation too.,0,0.9922420978546143
663811753,10579,satishd,2021-07-05T10:11:33Z,i was planning to add that later as mentioned earlier. i updated with the required changes in latest commit.,0,0.9856058955192566
663813208,10579,satishd,2021-07-05T10:13:40Z,updated with a comment in the code.,0,0.9884241819381714
663818344,10579,satishd,2021-07-05T10:21:39Z,updated with a comment.,0,0.9898819327354431
663819484,10579,satishd,2021-07-05T10:23:26Z,"i guess 60s may be sufficient, updated with that.",0,0.9793891310691833
663821465,10579,satishd,2021-07-05T10:26:46Z,`closing` is accessed in `initializeresources` and we do not need to take a lock there. i would like to keep this as `atomicboolean` which addresses that and it is easy to understand the semantics.,0,0.9836418628692627
664630725,10579,ccding,2021-07-06T14:53:56Z,is it possible two threads call `close()` concurrently?,0,0.9880111813545227
664632598,10579,ccding,2021-07-06T14:55:56Z,our of curiosity: why we have `l` here but not [a link],0,0.9801669716835022
664866782,10579,junrao,2021-07-06T20:45:42Z,the test for closing seem unnecessary since closing can't change while synchronized on assignpartitionslock.,0,0.9836269617080688
664868563,10579,junrao,2021-07-06T20:49:01Z,"is remotelogsegmentlifecyclemanager used for tests only? if so, could we move it under tests?",0,0.9957309365272522
664905089,10579,junrao,2021-07-06T22:00:41Z,"i am still not sure why we need to initialize in a separate thread. if we can't create the metadata topic or instantiate the producer/consumer due to wrong configurations, we want to fail fast by throwing an error to shut down the broker.",0,0.5225948691368103
664907494,10579,junrao,2021-07-06T22:06:20Z,should we verify that the number of partitions in the existing topic matches the configuration?,0,0.994738757610321
664908297,10579,junrao,2021-07-06T22:08:11Z,"hmm, we don't want to retry forever. if there is a configuration error, we want to fail fast.",-1,0.7430011630058289
664911197,10579,junrao,2021-07-06T22:14:50Z,"hmm, why is this needed since initializeresources() does this already?",0,0.9775283932685852
664912870,10579,junrao,2021-07-06T22:19:02Z,it seems producer credentials are closer for the admin client.,0,0.9906201362609863
664913921,10579,junrao,2021-07-06T22:21:34Z,is this comment addressed?,0,0.9921022057533264
664914536,10579,junrao,2021-07-06T22:22:55Z,createmetadatatopic() is no longer used.,0,0.9868021607398987
664970217,10579,satishd,2021-07-07T01:11:27Z,`remotelogsegmentlifecyclemanager` is already under tests.,0,0.994223415851593
664976317,10579,satishd,2021-07-07T01:32:10Z,"this loop can run after `assignpartitionslock.wait()` call which might have been notified from `close()` method, we should have a `closing` check to get out of the loop. we can have a more aggressive check to return from here when `closing` is true, i will add that.",0,0.9936840534210205
664980913,10579,satishd,2021-07-07T01:46:58Z,`close()` will not be called concurrently here.,0,0.9844271540641785
664983511,10579,satishd,2021-07-07T01:53:00Z,"i prefer adding l for longs, which i missed at other declaration. afaik, that does not cause any issues as it gets automatically converted via a widening conversion to a `long`. the compiler takes care of not allowing numbers that may get truncated from `int` to `long` widening. thanks for catching it, i will make it consistent by adding it.",1,0.7050595283508301
665259927,10579,satishd,2021-07-07T10:50:18Z,"the reason why we need to initialize in a different thread here is that rlmm will be created and `configure()` will be called before the broker starts accepting the requests. so, we can not call topic creation requests in the same thread as the brokers are not yet up. another way to do this is to have this topic as an internal topic and it will be auto created whenever it is accessed. afaik, creating producer and consumer instances can be done without the brokers up and running and they will not trigger a request to auto creation of remote log metadata topic. consumer assignment will send a metadata request which will trigger auto creation of topics. this assignment on consumer is done only when rlmm receives callback thorough the broker about leader and isr updates from the controller. this is what we had in pre-2.7 implementation but we saw an intermittent deadlock issue but i do not see that happening on trunk. in the current pr, i will make the existing producer manager and consumer manager in configure() and have the topic creation done in the tests. i will have a quick follow-up pr with internal topic changes and remove the topic creation code from tests.",0,0.9924553632736206
665299398,10579,satishd,2021-07-07T11:54:00Z,"`remotelogmetadatamanager.configure(map configs)` is always invoked with stripping the rlmm prefix. ""bootstrap.servers"" property is sent as part of the configs here and any registered rlmm plugin will receive this property.",0,0.9951725602149963
665531236,10579,satishd,2021-07-07T16:29:41Z,i made the mentioned changes for this pr in the latest commit.,0,0.9875782132148743
665544995,10579,kamalcph,2021-07-07T16:48:33Z,this condition should be inverted.,0,0.9796053171157837
665555878,10579,satishd,2021-07-07T17:04:26Z,"good catch, we do not really need this check here as it is already guarded in `topicbasedremotelogmetadatamanager`.",1,0.5342156887054443
666372073,10579,junrao,2021-07-08T17:03:35Z,": to create a topic, you don't need a particular broker to be up. you just need to be able to access the bootstrap brokers. auto creating this topic on access is a bit weird since it's not truly an internal topic and it is just an implementation detail of rlmm. so, it makes more sense for topic-based rlmm to create it.",0,0.5570138096809387
666697373,10579,satishd,2021-07-09T06:15:00Z,"as i mentioned earlier, rlmm is created before broker starts accepting the requests. so, when rlmm is getting initialized and tries to create a topic in the same thread, then none of the brokers(including the brokers related to the bootstrap-servers config) will be available for taking any admin client requests for topic creation. that is why i was doing this in a different thread as it allows the broker/controller to comeup and accept the admin client request for topic creation.",0,0.9887680411338806
667102624,10579,junrao,2021-07-09T17:21:12Z,": my understanding is that when we enable remote storage, we will do that through a rolling upgrade. so, at any given time, there is at most a single broker being down. therefore, as long as the bootstrap broker list contains more than one broker, operations like creating topics can still be done while a single broker is starting.",0,0.9913480877876282
667427888,10579,satishd,2021-07-11T06:04:21Z,": that is a good point. but that is valid only for upgrade scenario. there are two scenarios here. 1) upgrade path 2) fresh install/deploy with the release containing this feature. what you said makes sense for upgrade path. but ""bootstrap.servers"" list is configured with the local broker endpoint only in which rlmm is getting initialized. so, if we try to initialize rlmm in the same thread, it wont be able to connect to the local broker as it is not yet started to accept the broker api requests. one way to address this is to give `bootstrap.servers` with more than one broker's endpoint. this will also put a limitation to create a cluster with one broker instance for test/demo environments. when users install/deploy a fresh environment with the release containing this feature, there should not be a restriction to do rolling restarts with the configuration enabled. please let me know if i am missing anything here.",0,0.9766976237297058
670800796,10579,junrao,2021-07-15T20:58:17Z,should halt the jvm in this case? ditto below when the partition count doesn't match.,0,0.9801698327064514
670820515,10579,junrao,2021-07-15T21:34:47Z,"since bootstrap_servers is used for the internal producer/consumer, should bootstrap_servers be defined with a prefix of remote_log_metadata_common_client_prefix, remote_log_metadata_common_client_prefix or remote_log_metadata_consumer_prefix?",0,0.9960988759994507
670823373,10579,junrao,2021-07-15T21:40:10Z,does pendingassignpartitions need to be synchronizedset since it's accessed under a lock?,0,0.9944215416908264
670947570,10579,satishd,2021-07-16T03:59:51Z,"yes, we are already doing that [a link] whenever this class is accessed with/for remote log metadata operations.",0,0.9915441274642944
671094510,10579,satishd,2021-07-16T09:13:18Z,it is needed because `pendingassignpartitions` is updated in both `onpartitionleadershipchanges` and `onstoppartitions` methods which can happen concurrently as both of them take read lock.,0,0.9939224123954773
671367565,10579,satishd,2021-07-16T16:04:32Z,"no, it is not needed to be sent with any prefix(like common_client, producer or consumer) because ""bootstrap.servers"" property is sent for any registered rlmm plugin but not only limited to the default rlmm. i will update the kip with these details.",0,0.9936134219169617
671381765,10579,junrao,2021-07-16T16:27:07Z,"since producermanager is initialized asynchronously, how do we deal with the case when the producermanager is not ready when an event needs to be published?",0,0.9901856184005737
671383087,10579,junrao,2021-07-16T16:29:09Z,"hmm, ""bootstrap.servers"" makes sense for a topic based rlmm since it depends on kafka. why do we require ""bootstrap.servers"" in other rlmm implementations?",0,0.9908341765403748
671415369,10579,satishd,2021-07-16T17:25:57Z,"that is a good point. we plan to improve the semantics here. earlier, we plan to introduce retriableexception for rlmm and rsm so that callers can have an option to know whether they can retry or not. in the case of initialization is not yet complete, retriableexception can be thrown caller can retry based on backoff. rlmm can send non retriable exception if it is in closing state and there will not be any retries. another way to handle this is to take these events and store them in in-memory queue and return future. these futures will be considered successful if initialization is successful and the events are published to the topic. i plan to address these in a followup pr while these apis are integrated with rlm, filed [a link]",0,0.8744956254959106
671419080,10579,satishd,2021-07-16T17:32:24Z,i am not sure about usecases with other rlmm but it allows them to connect to the broker.,0,0.9329812526702881
671516460,10579,junrao,2021-07-16T20:46:16Z,"what about client security related properties? it's weird that we pick up ""bootstrap.servers"" from one prefix, but the corresponding security properties under a different prefix. if we do provide the security related properties in the same prefix, they seem to be duplicated from those under prefix remote_log_metadata_common_client_prefix, remote_log_metadata_common_client_prefix or remote_log_metadata_consumer_prefix.",-1,0.8143136501312256
125019733,3325,dguy,2017-06-30T11:38:49Z,this is unused,0,0.9184365272521973
125019734,3325,dguy,2017-06-30T11:38:50Z,this is unused too. we should have a test for this.,0,0.9727464318275452
125019810,3325,dguy,2017-06-30T11:39:29Z,this is in a public package so we should provide some javadoc,0,0.9910032749176025
125020051,3325,dguy,2017-06-30T11:41:18Z,same as above - needs javadoc. i guess it is intended for users? we should at least have some tests that use it.,0,0.9879170060157776
125020092,3325,dguy,2017-06-30T11:41:40Z,nit: extra space between `abstract` and `class`,0,0.9785624146461487
125020150,3325,dguy,2017-06-30T11:42:07Z,javadoc,0,0.9789121150970459
125020184,3325,dguy,2017-06-30T11:42:20Z,javadoc,0,0.9789121150970459
125020664,3325,dguy,2017-06-30T11:45:39Z,this should probably default to `noopstaterestorelistener` otherwise i think it is going `nullpointerexception` if the user doesn't add a listener,0,0.9907032251358032
125020841,3325,dguy,2017-06-30T11:46:45Z,i think we should probably do a null check here and throw. setting the listener to null doesn't seem valid to me,0,0.9622581005096436
125021380,3325,dguy,2017-06-30T11:49:56Z,rather than setting this to `null` if it isn't an instance of `batchingstaterestorecallback` perhaps you could set it to an instance of an internal class that implements `batchingstaterestorecallback`. the benefit being that the `null` check is then only done once here and not also in `restoreall`,0,0.9946734309196472
125021406,3325,dguy,2017-06-30T11:50:09Z,see comment above in ctor,0,0.9912886619567871
125021525,3325,dguy,2017-06-30T11:50:57Z,unit tests for this class?,0,0.9899631142616272
125022092,3325,dguy,2017-06-30T11:54:42Z,again i think we could use an internal implementation (probably the same one) for `batchingstaterestorecallback`. so here we always have a `batchingstaterestorecallback` and we can get rid of the `if(...){...}else{...}` and the extra `if(!restorerecords.isempty)` i think that would make the code easier to follow.,0,0.9865256547927856
125022610,3325,dguy,2017-06-30T11:58:16Z,pass this in as a ctor param rather than constructing it? the `staterestorecallback` is only used to create the `compositerestorelistener`,0,0.994695246219635
125036770,3325,dguy,2017-06-30T13:20:23Z,do we need to synchronize access to `staterestorelistener`? it can be set by a user thread and used by the `streamthread`,0,0.9957551956176758
125037238,3325,dguy,2017-06-30T13:22:33Z,nit: `private`,0,0.9863219261169434
125037487,3325,dguy,2017-06-30T13:23:46Z,nit: keep fields with the same access level together,0,0.9829434156417847
125040681,3325,dguy,2017-06-30T13:38:20Z,nit: `collections.singletonlist(...)` or `utils.mklist(..)`,0,0.9944071769714355
128017007,3325,bbejeck,2017-07-18T15:51:41Z,"ack, removed not needed as it's passed through to `streamthread`",0,0.9888477325439453
128018122,3325,bbejeck,2017-07-18T15:55:41Z,"don't think so, the `staterestorelistener` set by user is passed through to the `streamthread`. javadoc in `staterestorelistener` states that it expects operations to be stateless.",0,0.9926272034645081
128018683,3325,bbejeck,2017-07-18T15:57:34Z,"ack, added integration test",0,0.8925883769989014
128018746,3325,bbejeck,2017-07-18T15:57:47Z,ack,0,0.8596508502960205
128018769,3325,bbejeck,2017-07-18T15:57:51Z,ack,0,0.8596508502960205
128236093,3325,dguy,2017-07-19T12:53:08Z,nit: my preference is to mark all method params as `final`,0,0.9818035364151001
128250446,3325,dguy,2017-07-19T13:47:18Z,`final` and there is an extra space,0,0.9926729798316956
128251187,3325,dguy,2017-07-19T13:50:01Z,nit: extra line,0,0.950958788394928
128251819,3325,dguy,2017-07-19T13:52:27Z,i think we should probably add a unit test in `rocksdbstoretest` to prove that this works.,0,0.9897430539131165
128253384,3325,dguy,2017-07-19T13:58:04Z,"i'd prefer to see these broken down into multiple smaller tests, i.e, you are effectively testing 4 different methods in each test. ideally a unit test is only testing a single method.",0,0.9875689148902893
128254391,3325,dguy,2017-07-19T14:01:35Z,nit: `final` + next line and might as well do the previous while you are at it ;-),1,0.9728747010231018
128256200,3325,dguy,2017-07-19T14:07:39Z,"could we extract these 3 lines into a method, say `verifycallbackstatescalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok",0,0.985643744468689
128303773,3325,bbejeck,2017-07-19T16:51:49Z,ack - agreed,0,0.850676417350769
128303812,3325,bbejeck,2017-07-19T16:51:55Z,ack,0,0.8596508502960205
128414835,3325,guozhangwang,2017-07-20T02:48:34Z,"the javadoc may read a bit hard for end users since 1) `internal threads assignment` is not known to them at all, 2) `conclusion of restoring a statestore` is also a mess up. from their pov (not familiar with concept of task, etc) we can just state that `... set the listener which is triggered whenever a state is being restored in order to resume processing..`.",0,0.9321612119674683
128415004,3325,guozhangwang,2017-07-20T02:50:14Z,"same as above, do not need to mention ""all internal threads"". just emphasize it is triggered whenever a state is being restored is fine.",0,0.98643559217453
128415203,3325,guozhangwang,2017-07-20T02:52:04Z,"nit: `not supported, please use...`",0,0.8791494965553284
128415747,3325,guozhangwang,2017-07-20T02:58:16Z,i think we can use the following as part of javadoc: [code block] as a reference see `kafkaproducer` and `producer` in clients.,0,0.9880731701850891
128415932,3325,guozhangwang,2017-07-20T03:00:12Z,i did not catch it in the kip wiki but.. the class names are a bit inconsistent here: [code block] better be either [code block] or [code block] wdyt?,-1,0.6456707119941711
128415948,3325,guozhangwang,2017-07-20T03:00:30Z,"ditto as above, we can refer to the javadocs of the base interface here.",0,0.9911143183708191
128416068,3325,guozhangwang,2017-07-20T03:01:46Z,"seems in the library, if it is determined a `batchingstaterestorecallback` at runtime we then would never call the `restore` function ever. is this true and will be future forever? if yes we should state it in the java doc.",0,0.9928154945373535
128416128,3325,guozhangwang,2017-07-20T03:02:26Z,does this need to be in `o.a.k.streams.state` or this package? i'm just wondering..,0,0.9543220400810242
128416252,3325,guozhangwang,2017-07-20T03:03:55Z,"better state ""when calling `setstate...` in \ kafkastreams, the passed instance is expected to be stateless since.."" because not everyone understand what does ""... for reporting all state store recovery.."" means, stating from the api point of view would be easier to understand. ditto elsewhere.",0,0.8497000932693481
128416789,3325,guozhangwang,2017-07-20T03:10:02Z,`in this case the size of the batch is whatever the value of the max_poll_records is set to.` is this really the case?? it is an upper bound but not necessary the exact value right?,0,0.9908390641212463
128603596,3325,bbejeck,2017-07-20T19:00:07Z,ack,0,0.8596508502960205
128603630,3325,bbejeck,2017-07-20T19:00:15Z,ack,0,0.8596508502960205
128607545,3325,bbejeck,2017-07-20T19:18:41Z,"agreed, i think the second option is best.",0,0.964852511882782
128607578,3325,bbejeck,2017-07-20T19:18:51Z,ack,0,0.8596508502960205
128607619,3325,bbejeck,2017-07-20T19:19:00Z,ack,0,0.8596508502960205
128607645,3325,bbejeck,2017-07-20T19:19:09Z,ack,0,0.8596508502960205
128607671,3325,bbejeck,2017-07-20T19:19:16Z,ack,0,0.8596508502960205
128607701,3325,bbejeck,2017-07-20T19:19:25Z,ack,0,0.8596508502960205
128607714,3325,bbejeck,2017-07-20T19:19:30Z,ack,0,0.8596508502960205
128611709,3325,bbejeck,2017-07-20T19:37:21Z,"maybe, we could also move `statestore`, `statestoresupplier`, `statestorecallback` as well. let's see what others think.",0,0.9931526184082031
128612612,3325,bbejeck,2017-07-20T19:41:59Z,ack,0,0.8596508502960205
128614536,3325,bbejeck,2017-07-20T19:51:06Z,ack,0,0.8596508502960205
128642317,3325,guozhangwang,2017-07-20T22:05:53Z,"if we start from scratch then maybe these would be better be in `state`, but they have been added to `processor` and moving them would be incompatible changes. so i'm more concerning about the newly added classes.",0,0.983735978603363
128642627,3325,guozhangwang,2017-07-20T22:07:36Z,maybe the parameter descriptions are not needed as well? ditto elsewhere.,0,0.9896748661994934
128643629,3325,guozhangwang,2017-07-20T22:13:58Z,we can define two static variables of `noopstaterestorelistener` and `noopstaterestorecallback` instead of creating a new instance multiple times.,0,0.9932883381843567
128646844,3325,guozhangwang,2017-07-20T22:34:54Z,"for `reportingstorelistener`, better rename it to `globalstorelistener` as it is the instance-level listener, but it is not necessarily used for reporting only.",0,0.9948592185974121
128647685,3325,guozhangwang,2017-07-20T22:40:22Z,also code structure wise i'm wondering if it is easier to keep the per-store callback/listener and the global listener in two separate classes than keeping them in this `composite` class? then we can do: [code block] i feel this null-check would be more performant than the no-op function call?,0,0.9849879145622253
128648024,3325,guozhangwang,2017-07-20T22:42:40Z,"as mentioned above, i'm wondering if it is better to not use the `set` function of global listener in this composite class but keep it in a separate class? also since the global listener could be accessed by concurrent threads of the instance, does it need to be synchronized?",0,0.9925047159194946
128648103,3325,bbejeck,2017-07-20T22:43:09Z,ok fair enough i can move it over. my only concern is that it could be slightly confusing.,0,0.4932854473590851
128648481,3325,guozhangwang,2017-07-20T22:45:19Z,hmm... should we ever expect the passed in callback to ever be `null`? if it is really null then no data will ever be restored right?,0,0.8671069741249084
128649545,3325,guozhangwang,2017-07-20T22:52:52Z,"instead of using this separate class and do the `instanceof` check on each call (which maybe expensive), maybe we could just have a `wrappedbatchingstaterestorecallback` which only takes the non-batching `staterestorecallback` in constructor and then in `restoreall` always do the for-loop, and in places that we need it (seems we only have two callers) we can do sth. like [code block] just once.",0,0.9897786974906921
128651168,3325,guozhangwang,2017-07-20T23:04:14Z,"i'm thinking that we can simply this logic a bit: 1) in line 124 above, when `needsrestoring.put(topicpartition, restorer);` call `restorer.restorestarted`. 2) then we can remove the `restorestarted` boolean in `storerestorer` and also the line here.",0,0.9855296015739441
128652257,3325,guozhangwang,2017-07-20T23:12:47Z,"this logic seems a bit complex to me, and also if we return at line 229 `restorebatchcompleted` is not called as well. is this correct? how about: [code block]",0,0.8243041634559631
128652963,3325,guozhangwang,2017-07-20T23:17:34Z,"following my comments above, we can rename to `setglobalstaterestorelistener` to make it clear.",0,0.9934020638465881
128653176,3325,guozhangwang,2017-07-20T23:19:29Z,these two functions can be merged into one? [code block] see my other comments on the `storechangelogreader.java` class.,0,0.9921630024909973
128653276,3325,guozhangwang,2017-07-20T23:20:19Z,ditto above: `setglobalstaterestorelistener`,0,0.9939018487930298
128653708,3325,guozhangwang,2017-07-20T23:23:42Z,"one caveat of letting users to set it via code is that, we cannot forbid users to call this function after calling `streams.start()`, in which case the behavior would be bad. also people can set it multiple times which is also not suggested. i'm now thinking maybe we should enforce users to set this global listener via configs? cc wdyt.",0,0.4912687838077545
128654031,3325,guozhangwang,2017-07-20T23:26:02Z,"`prepareforbulkload` will always be true here, right?",0,0.9914677143096924
128654227,3325,guozhangwang,2017-07-20T23:27:35Z,"i do not think we need this variable at all, since as mentioned above when initiating it will always be true, and that is the only place this variable is ever read.",0,0.9659900069236755
128654443,3325,guozhangwang,2017-07-20T23:29:00Z,we do not need to set `open = true` here again.,0,0.9903846979141235
128655290,3325,guozhangwang,2017-07-20T23:36:26Z,"personally i'm not a big fan of this integration test, since i felt that the its coverage has already been subsumed by unit tests. we should only consider integration tests for some end-to-end behavior that involves multiple modules to interact with each other, otherwise unit tests should be used per-module.",0,0.7712920904159546
128656227,3325,guozhangwang,2017-07-20T23:44:14Z,actually i was really just asking for people's opinions :) the cons are that these classes will be in different packages which may looks a bit weird.,1,0.9864809513092041
128700639,3325,dguy,2017-07-21T07:33:05Z,if we put it in config then they lose the ability to use capture any objects/state etc in their application. we could always only allow the listener to be set when kafkastreams is in the `created` state and throw an exception if it isn't.,0,0.9905461072921753
128779376,3325,bbejeck,2017-07-21T14:44:10Z,:thumbs_up:,0,0.9771975874900818
128800005,3325,bbejeck,2017-07-21T16:05:22Z,ack,0,0.8596508502960205
128800078,3325,mjsax,2017-07-21T16:05:43Z,"in javadoc this markup is not needed 1. between the text and the parameter list, it will insert some space automatically 2. ` ` is just use to start new paragraphs (but javadoc is not html, there is no closing ` `)",0,0.9941219687461853
128800519,3325,mjsax,2017-07-21T16:08:08Z,"we could do a small kip and move the classes (preserving the old ones as deprecated). overall, i don't have a strong opinion.",0,0.8264061808586121
128800688,3325,mjsax,2017-07-21T16:09:03Z,nit: why `code` but not `link` ?,0,0.9885988235473633
128800950,3325,mjsax,2017-07-21T16:10:23Z,nit: `.` missing at end of sentence,0,0.9829713702201843
128800998,3325,mjsax,2017-07-21T16:10:41Z,nit: remove unnecessary blank.,0,0.6844895482063293
128802000,3325,bbejeck,2017-07-21T16:16:03Z,ack on the name. i think we should keep `composite` class as it keeps implementation details out of the `staterestorer` class which doesn't need to know the details of restoring notification. as for synchronizing we can do that from within the `composite` class as well. although we specify in the javadoc it's expected the `globbalstorelistener` is stateless and implementors will need to provide synchronization if needed. if you insist i can remove the composite class and/or synchronize the calls on the `globalstorelistener`,0,0.9932988882064819
128802185,3325,bbejeck,2017-07-21T16:17:00Z,ack,0,0.8596508502960205
128807922,3325,bbejeck,2017-07-21T16:46:35Z,"ack, but i thinking some more we should replace the default value with `objects.requirenonnull`",-1,0.8939347863197327
128809089,3325,bbejeck,2017-07-21T16:52:30Z,updated the set method to reflect the new name. comments on the `composite` class and synchronization same as above.,0,0.9941070079803467
128815139,3325,bbejeck,2017-07-21T17:22:11Z,ack,0,0.8596508502960205
128829007,3325,guozhangwang,2017-07-21T18:22:36Z,"re synchronization: enforcing users to do sync themselves inside the function is fine, i did not see `implementors will need to provide synchronization if needed` so there may be a mis-understanding. could you make that statement more clear in javadocs? re separating classes: one motivation i had is that, currently we did one ""instanceof"" for each call, and if the global listener is not set we still call a `no-op` listener; this does not seem optimized for me. instead we can do a `null` check or even a boolean flag indicating if a global listener is ever set already. that would be more performant? if you can do that inside this composite class i think we could keep it centralized.",0,0.9779039621353149
128843230,3325,bbejeck,2017-07-21T19:27:35Z,"ack, good catch.",1,0.9809924960136414
128847495,3325,bbejeck,2017-07-21T19:49:37Z,ack,0,0.8596508502960205
128849307,3325,bbejeck,2017-07-21T19:59:39Z,ack,0,0.8596508502960205
129029991,3325,bbejeck,2017-07-24T13:10:02Z,leaving as is based on offline-conversation,0,0.9916461110115051
129030050,3325,bbejeck,2017-07-24T13:10:17Z,ditto from above,0,0.9788949489593506
129030086,3325,bbejeck,2017-07-24T13:10:26Z,ditto from above,0,0.9788949489593506
129030265,3325,bbejeck,2017-07-24T13:11:13Z,"ok, i'll take it out.",0,0.9786294102668762
129090134,3325,bbejeck,2017-07-24T16:45:27Z,ack,0,0.8596508502960205
129090501,3325,bbejeck,2017-07-24T16:46:54Z,"oversight on my part, changing.",0,0.8466084599494934
129091268,3325,bbejeck,2017-07-24T16:50:16Z,ack,0,0.8596508502960205
129606674,3325,mjsax,2017-07-26T15:27:05Z,nit `{ staterestorerlistener}`,0,0.9929260015487671
129608628,3325,mjsax,2017-07-26T15:33:46Z,can't this `extend abstractnotifyingrestorecallback` to save all the boiler plate from below?,0,0.9942408800125122
129617878,3325,mjsax,2017-07-26T16:05:20Z,"can we introduce a global ""one parameter per line"" code style? i think it would help to make diffs cleaner. we can do this incrementally. if yes, please do for all newly introduced code of this pr. also, should be add `final` all over the place?",0,0.9874292016029358
129618333,3325,mjsax,2017-07-26T16:07:06Z,"nit: parameter descriptions are no sentences, thus no `.` at the end (on many other places, too). if we say they are sentences, they it should start with upper case `[t]he topicpartition`",0,0.9919940233230591
129620426,3325,mjsax,2017-07-26T16:13:55Z,as above?,0,0.986420750617981
129623215,3325,mjsax,2017-07-26T16:24:35Z,can you elaborate?,0,0.9856624007225037
129624489,3325,mjsax,2017-07-26T16:28:29Z,we should not `expect` here and use `fail` within try-catch,0,0.9919764399528503
129626342,3325,mjsax,2017-07-26T16:35:25Z,as above.,0,0.9878018498420715
129629040,3325,bbejeck,2017-07-26T16:44:40Z,ack,0,0.8596508502960205
129664724,3325,bbejeck,2017-07-26T18:54:03Z,ack,0,0.8596508502960205
129667712,3325,bbejeck,2017-07-26T19:05:08Z,"actually this class won't be used anymore, so removed.",0,0.9666746258735657
129670240,3325,bbejeck,2017-07-26T19:15:34Z,"sure thing, can you add to the steams guidelines?",0,0.9818238615989685
129677466,3325,bbejeck,2017-07-26T19:46:19Z,"will still have one no-op method, but i guess it's worth it as it does reduce the boilerplate some.",0,0.935816764831543
129692869,3325,bbejeck,2017-07-26T20:52:12Z,"there was some confusion over the number of times we open and close the `rocksdbstatestore` for handling optimized bulk loads, once that was clarified the comments pertaining to setting `prepareforbulkload` and `open` didn't need to be addressed.",0,0.9915914535522461
129963670,3325,guozhangwang,2017-07-27T21:26:05Z,nit: rename this function to `restorestarted` to be consistent with other names. such will help other code readers to understand these functions are for the same code granularity and semantics.,0,0.9936967492103577
129964281,3325,guozhangwang,2017-07-27T21:28:46Z,is this comment missed somehow? i think line 42 above could be `storerestorelistener = no_op_state_restore_listener`.,0,0.9946677684783936
129964947,3325,guozhangwang,2017-07-27T21:32:21Z,nit: space after `//` and we do not need capitalize the in-function comments.,0,0.9875778555870056
129965165,3325,guozhangwang,2017-07-27T21:33:28Z,ditto for in-function and simple top function comments.,0,0.9579455852508545
129965459,3325,guozhangwang,2017-07-27T21:34:51Z,nit: new lines are generally not recommended to break object type declaration with object name. for this specific line i think we can still make them in one line.,0,0.9690056443214417
129965596,3325,guozhangwang,2017-07-27T21:35:38Z,ditto: newline after keywords are generally not recommended.,0,0.9254973530769348
129965850,3325,guozhangwang,2017-07-27T21:37:04Z,ditto for new line rules. could you make a pass over all the newlines and see if they can be improved?,-1,0.8682715892791748
129966240,3325,guozhangwang,2017-07-27T21:39:04Z,we can use the `wrappedbatchingstaterestorecallback` here?,0,0.994904637336731
129966522,3325,guozhangwang,2017-07-27T21:40:35Z,`org.apache.kafka.streams.processor.internals.noopstaterestorelistener` can be used here?,0,0.9950233697891235
129970463,3325,bbejeck,2017-07-27T22:01:09Z,ack,0,0.8596508502960205
129970523,3325,bbejeck,2017-07-27T22:01:27Z,"ack, must have overlooked",-1,0.6528445482254028
129970837,3325,bbejeck,2017-07-27T22:03:18Z,ack,0,0.8596508502960205
129970870,3325,bbejeck,2017-07-27T22:03:26Z,ack,0,0.8596508502960205
129970957,3325,bbejeck,2017-07-27T22:03:53Z,"ack, need to adjust intellij settings",0,0.7129114866256714
129971207,3325,bbejeck,2017-07-27T22:05:25Z,"ack, same as above",0,0.7042319178581238
129971290,3325,bbejeck,2017-07-27T22:05:57Z,ack,0,0.8596508502960205
129974506,3325,bbejeck,2017-07-27T22:26:26Z,ack,0,0.8596508502960205
129974595,3325,bbejeck,2017-07-27T22:26:54Z,ack,0,0.8596508502960205
589867244,10218,junrao,2021-03-09T01:16:23Z,"it's a bit weird to include this in the client module. since this is implemented in java, we could potentially create a new java module for it (like the raft module). this reduces the size of the client jar and also avoids the inter-dependencies between java and scala. also, is this for testing? if so, it needs to be in the test directory.",-1,0.9374887347221375
589867914,10218,junrao,2021-03-09T01:17:56Z,"is this for testing? if so, it needs to be in the test directory.",0,0.9935706853866577
590723978,10218,junrao,2021-03-09T21:14:18Z,typo imemory,0,0.9778515696525574
590739158,10218,junrao,2021-03-09T21:40:00Z,"hmm, it's possible for a segment to transition to delete_segment_started here. should those segments still be added?",0,0.95692378282547
590740461,10218,junrao,2021-03-09T21:42:19Z,"once a segment is in delete_segment_started state, the corresponding segment could be gone any time after that. so, it seems that we should remove the segment from leaderepochtooffsettoid once it's in delete_segment_started?",0,0.9941748976707458
590742564,10218,junrao,2021-03-09T21:46:15Z,could we just get the segment list from `idtosegmentmetadata.values()`?,0,0.9949828386306763
590744034,10218,junrao,2021-03-09T21:48:28Z,highestlogoffset => highestsegmentstartoffset ?,0,0.9922560453414917
590745670,10218,junrao,2021-03-09T21:50:53Z,could we add a comment to this class?,0,0.9920601844787598
590748558,10218,junrao,2021-03-09T21:55:55Z,we are not returning null here.,0,0.975033164024353
591585302,10218,satishd,2021-03-10T14:49:20Z,the plan was to use the related classes in the default rlmm implementation and move any class which is relevant only for tests to test dir later. i am +1 to have this as a separate module. i will update with those changes.,0,0.9770731925964355
591588474,10218,satishd,2021-03-10T14:52:49Z,"this behavior was kept to be the same as local log cleanup behavior, in which leader epoch is truncated only after local log is moved/deleted. ideally, it is good not to consider the segments available that are being deleted as you said.",0,0.9893682599067688
591595247,10218,satishd,2021-03-10T15:00:08Z,there may be few segments with state as `copy_segment_started` and they will be part of `remotelogsegmentidinprogress` only but not `idtosegmentmetadata`. that is why we need to add them to the list.,0,0.9940919280052185
591603442,10218,satishd,2021-03-10T15:09:34Z,"no, it is not highestsegmentstartoffset but it is the highest log offset for the given leader epoch. nice catch! we need to give the max endoffset of all the segments for the given leader epoch.",1,0.9693153500556946
591905906,10218,kowshik,2021-03-10T22:05:03Z,this c'tor can be removed in exchange for the default generated c'tor.,0,0.9916700124740601
591912017,10218,kowshik,2021-03-10T22:15:55Z,it seems like we allow for an entry already existing with the same id to be replaced with a different entry. would that happen in practice?,0,0.982986330986023
591915104,10218,kowshik,2021-03-10T22:21:41Z,"can `offsettoid` be empty if it is not null? i understand it is right to check for emptiness here, but i was just curious to learn if it could happen in practice.",0,0.9718817472457886
591919624,10218,kowshik,2021-03-10T22:30:10Z,"looking at the implementation, it appears we maintain some rules on when a `remotelogsegmentid` exists in one of these data structures versus all of them. it would be useful to briefly document those rules, and mention invariants (if any). for example, when an upload is in progress it is not (yet) added to this map.",0,0.9906216859817505
591921511,10218,kowshik,2021-03-10T22:33:57Z,can `metadata` be a better variable name over `rlsm`?,0,0.9937295913696289
592012860,10218,kowshik,2021-03-11T02:02:41Z,should we move this log message before l51? so that the message conveying the intent is logged first before any possible errors.,0,0.9926998019218445
592015659,10218,kowshik,2021-03-11T02:11:02Z,hmm... it seems like the only allowed state in `rlsmupdate` is `copy_segment_finished`. should we validate for that instead?,0,0.984085202217102
592016707,10218,kowshik,2021-03-11T02:13:35Z,s/resource/entry ?,0,0.9883055686950684
592022166,10218,kowshik,2021-03-11T02:28:08Z,"it seems like we want to add more protections here. 1. if `remotepartitiondeletemetadata.state()` is `delete_partition_finished`, then should there have been a prior entry with `delete_partition_started` or `delete_partition_marked`? 2. imagine there exists an entry in `partitiontoremotelogmetadatacache` while the partition is also being deleted. is that a valid state, or if not should we assert against it?",0,0.9951651096343994
592022431,10218,kowshik,2021-03-11T02:28:56Z,sorry i don't understand what does this comment refer to?,-1,0.9850354194641113
592024533,10218,kowshik,2021-03-11T02:35:18Z,"hmm, any reason to not implement these methods? is it that they don't serve any purpose in the in-memory implementation?",0,0.754809558391571
592070871,10218,satishd,2021-03-11T05:10:50Z,this can happen in race condition when this method is queried while it was getting added in `addremotelogsegmentmetadata`. it may not happen in practice but it is good to have these checks.,0,0.9929894208908081
592071729,10218,satishd,2021-03-11T05:13:59Z,"right, it is not applicable for inmemory implementation.",0,0.9382629990577698
592074962,10218,satishd,2021-03-11T05:24:46Z,"""no resource metadata found for partition: ""?",0,0.989101231098175
592075662,10218,satishd,2021-03-11T05:26:51Z,it may not occur in practice.,0,0.968048632144928
592096637,10218,satishd,2021-03-11T06:28:40Z,"it allows any state other than `copy_segment_started`, that is why we are checking only for this state.",0,0.9915512800216675
592123658,10218,kowshik,2021-03-11T07:32:25Z,is it useful to add a check against it?,0,0.9934198260307312
592124191,10218,kowshik,2021-03-11T07:33:38Z,sure,0,0.9137381911277771
592173915,10218,satishd,2021-03-11T08:56:03Z,"other states include `copy_segment_finished`, `delete_segment_started`, and `delete_segment_finished`.",0,0.9941902160644531
592248245,10218,satishd,2021-03-11T10:37:36Z,"i meant there will be an external trigger based on delete partition marker, that is responsible for deleting the segments in a partition and updating the metadata. i will remove it as it looks to create confusion.",0,0.9844356775283813
592437366,10218,satishd,2021-03-11T15:05:20Z,1 -> added more assertions. 2 -> is a valid case.,0,0.9908892512321472
592577341,10218,satishd,2021-03-11T17:55:01Z,"sure, will add comments.",0,0.9749564528465271
594509836,10218,junrao,2021-03-15T16:51:52Z,delete_partition_marked is not part of remotelogsegmentstate.,0,0.9937517046928406
594510134,10218,junrao,2021-03-15T16:52:11Z,this seems to be an internal implementation and is not part of the public api? ditto for the same method in remotepartitiondeletestate.,0,0.892146646976471
594550095,10218,junrao,2021-03-15T17:41:48Z,"this method updates idtosegmentmetadata, which seems redundant since it's done in line 107 already.",0,0.9941304326057434
594554053,10218,junrao,2021-03-15T17:47:01Z,"it's possible that after this, there is no segment associated with a leader epoch. should we remove the entry with that leader epoch from leaderepochtooffsettoid?",0,0.9922120571136475
594560602,10218,junrao,2021-03-15T17:55:35Z,it's kind of inefficient to have to iterate through the whole segment list. could we make leaderepochtooffsettoid an ordered map and then do highentry on that?,-1,0.8373100757598877
594562408,10218,junrao,2021-03-15T17:57:34Z,highestlogoffset => highestoffsetforepoch?,0,0.9925312399864197
594564204,10218,junrao,2021-03-15T17:59:44Z,"it seems that there is a semantic difference between this method and the next one. while this one exposes all segments (including in progress ones), the latter only exposes segments that are completed. it would be useful to document this clearly in the public api.",0,0.9882914423942566
594567815,10218,junrao,2021-03-15T18:04:22Z,"hmm, it seems that we add the in-progress segment to idtosegmentmetadata in addtoinprogress? it would be useful to add a comment for idtosegmentmetadata.",0,0.9867156147956848
594577274,10218,junrao,2021-03-15T18:17:25Z,"for the local log, we first schedule the segment for async deletion and then take it out of leaderepochcache. so, the equivalent of that for remote storage seems to require taking the segment out of leaderepochcache once the segment deletion is initiated.",0,0.9945526719093323
594578101,10218,junrao,2021-03-15T18:18:32Z,inmemory => in-memory,0,0.9760161638259888
595492577,10218,kowshik,2021-03-16T19:49:18Z,"1. will it be useful to place the implementation of this validation in a separate module, so that it can be reused with `rlmmwithtopicstorage` in the future? 2. suggestion from the standpoint of code readability/efficiency: would it make sense to replace the `if-else` logic by looking up from a `map< remotelogsegmentstate, set< remotelogsegmentstate>>` where key is the source state and value is a set of allowed target states?",0,0.993945300579071
595493561,10218,kowshik,2021-03-16T19:50:55Z,i have the same suggestions from `remotelogsegmentstate` for this as well. please refer to this comment: [a link],0,0.8784164190292358
595500039,10218,kowshik,2021-03-16T20:00:45Z,really minor comment/discussion: any reason to call this prefixed with `add` as `addremotelogsegmentmetadata` vs calling the deletion one prefixed with `put` as `putremotepartitiondeletemetadata` i.e. instead can these 2 methods both start with the same prefix either `add` or `put`?,0,0.9334911108016968
595505146,10218,kowshik,2021-03-16T20:09:07Z,"we may want to think more about the locking semantics for this class and `remotelogmetadatacache`. are we sure there would _not_ be use cases where we need to serialize mutations across the individually thread-safe attributes? if the answer is no, then using a fine-grained `object` lock makes more sense because we can use it to guard critical sections. should we evaluate this upfront? cc",0,0.9925557971000671
595506748,10218,kowshik,2021-03-16T20:11:49Z,in the comment: s/putremotelogsegmentmetadata/addremotelogsegmentmetadata,0,0.9936729669570923
595954157,10218,satishd,2021-03-17T12:05:42Z,this is not really an internal implementation but it validates the state transition and it is the same for any implementation.,0,0.9880552887916565
596032415,10218,satishd,2021-03-17T13:46:26Z,i will update the javadoc of the apis to make this clear.,0,0.9877177476882935
596055570,10218,satishd,2021-03-17T14:12:17Z,good point! it will clear the values which are empty maps.,1,0.9918394088745117
596203582,10218,satishd,2021-03-17T16:48:25Z,`add` -> adding a new entry. `put` -> add or update. `putremotepartitiondeletemetadata` is used for both add or update the `remotepartitiondeletemetadata`.,0,0.9942827224731445
596204864,10218,satishd,2021-03-17T16:49:52Z,it was deliberate not to add locking semantics for now. we will add them once we have the respective changes using these classes.,0,0.9889079928398132
596247752,10218,satishd,2021-03-17T17:41:19Z,"1 -> imho, this validation method should be part of the state enum and it can be used by any implementation including default rlmm. 2 -> i would have preferred the suggested approach if there are many complex transitions but the transitions here are few and simple.",0,0.9881680607795715
598964030,10218,kowshik,2021-03-22T18:13:16Z,you can drop `it` and start with `indicates the state...`.,0,0.9917329549789429
598971940,10218,kowshik,2021-03-22T18:24:49Z,"imho, we can simplify this to say: [code block]",0,0.9698666930198669
598974632,10218,kowshik,2021-03-22T18:28:26Z,could we call this `idtoremotelogmetadatacache` to align with the naming of the other attribute thats called `idtopartitiondeletemetadata` ?,0,0.994827926158905
598981046,10218,kowshik,2021-03-22T18:37:34Z,can this be checked inside `remotelogmetadatacache.addtoinprogress()` instead of here?,0,0.9955586194992065
598982742,10218,kowshik,2021-03-22T18:40:00Z,it seems to me that `srcstate` is never null in practice. where does this check come into play in practice?,0,0.9839355945587158
598984916,10218,kowshik,2021-03-22T18:43:16Z,this is defined to be not thread safe unlike the other maps. is there any reason?,0,0.95972740650177
598990605,10218,kowshik,2021-03-22T18:51:29Z,can we add a 1-line doc for this similar to other attributes below?,0,0.9920961856842041
599000060,10218,kowshik,2021-03-22T19:05:29Z,"before we insert into the map/set, we should check if the provided `remotelogsegmentmetadata.state()` is `copy_segment_started`.",0,0.9946528673171997
599001851,10218,kowshik,2021-03-22T19:08:20Z,"in this method, we allow for existing entries in `idtosegmentmetadata` to be replaced, even if the state of the existing and new entries are the same. is that intentional?",0,0.9925534129142761
599003846,10218,kowshik,2021-03-22T19:11:32Z,"hmm, the entry for `existingmetadata` gets overwritten in the call to `addremotelogsegmentmetadata` in l110. should we be accounting for the same here?",0,0.9883827567100525
599006691,10218,kowshik,2021-03-22T19:16:01Z,"similar to above comment, why not check this inside `remotelogmetadatacache.updateremotelogsegmentmetadata()`?",0,0.995235025882721
599008337,10218,kowshik,2021-03-22T19:18:33Z,typos: 1. s/wwe/we 2. s/gettign/getting,0,0.9871461391448975
599009374,10218,kowshik,2021-03-22T19:20:12Z,"can we improve the local variable names? for example `segidfootp0s0e100`, `segmetfootp0s0e100` etc. is not easy to read. we can use simpler names.",0,0.9940489530563354
599013040,10218,kowshik,2021-03-22T19:26:18Z,"the implementation compromises on the ordering, since it converts the iterator to a set. is that intentional?",0,0.902923583984375
599014824,10218,kowshik,2021-03-22T19:29:04Z,"this particular test checks a number of things together in one test. instead, could sections (1) to (4) from below each be defined as a separate unit test? especially since each section seems to operate on a different segment, so it seems logically independent.",0,0.9909921884536743
599016901,10218,kowshik,2021-03-22T19:32:49Z,could we add test(s) for `highestlogoffset` api?,0,0.993587851524353
599018475,10218,kowshik,2021-03-22T19:35:22Z,could we assert just before this line that `seg3s350` is not empty? this will simplify the `seg3s350.orelse(null)` argument to `seg3s350.get()`. (same comment applies for other places in this test),0,0.993309736251831
599021005,10218,kowshik,2021-03-22T19:39:17Z,"should we alter the other arguments too, for example `broker_id` and `eventtimestamp`? it appears that we expect `remotelogmetadatacache` to [a link], and this may include the other fields as well.",0,0.9951033592224121
599021666,10218,kowshik,2021-03-22T19:40:23Z,can we remove this c'tor in exchange for the default generated c'tor?,0,0.9946810603141785
599024909,10218,kowshik,2021-03-22T19:45:33Z,"as per the interface we [a link] the caller to ensure unique id, but is it useful to add a guard that disallows replacing existing values?)",0,0.9927198886871338
599026440,10218,kowshik,2021-03-22T19:47:57Z,"we could add a c'tor overload to [a link] that takes a `throwable` as argument, it would the need to pass 2 args here.",0,0.9945532083511353
599027282,10218,kowshik,2021-03-22T19:49:15Z,probably better to say `...must be greater than or equal to...` ?,0,0.9923734068870544
599029284,10218,kowshik,2021-03-22T19:52:27Z,"hmm, do we need to explicitly check if `endposition` < `segment.length`?",0,0.991155743598938
599029805,10218,kowshik,2021-03-22T19:53:16Z,is this intentionally left empty?,0,0.9248064160346985
606249948,10218,satishd,2021-04-02T13:59:30Z,"it takes `math.min(endposition, segment.length)`. so, no need to have that check.",0,0.9923934936523438
606249998,10218,satishd,2021-04-02T13:59:36Z,right.,0,0.9793882369995117
606250883,10218,satishd,2021-04-02T14:01:49Z,"yes, it can happen to generate an event with the same state incase of retries.",0,0.9602015614509583
606251255,10218,satishd,2021-04-02T14:02:48Z,good catch. this is addressed in the latest commit.,1,0.9636222124099731
606253220,10218,satishd,2021-04-02T14:07:45Z,"i thought earlier about having different methods, but it checks `listallsegments/listsegment(leaderepoch)` apis that return earlier segments. but i will have a separate test for that and extract as suggested.",0,0.9825912117958069
606253804,10218,satishd,2021-04-02T14:09:07Z,we can add that.,0,0.9811848998069763
606257469,10218,satishd,2021-04-02T14:17:46Z,"sure, i will add that.",0,0.9801427721977234
606343187,10218,junrao,2021-04-02T17:40:10Z,indicate => indicates ditto in a few other places.,0,0.9818514585494995
606348092,10218,junrao,2021-04-02T17:52:27Z,"the following table is a bit hard to read for developers. since this is not meant for a public interface, could we make it more readable for developers?",-1,0.6081677079200745
606348477,10218,junrao,2021-04-02T17:53:24Z,i guess this is an internal class. will this be exposed in javadoc since currently it includes **/org/apache/kafka/server/log/remote/storage/* ?,0,0.9915968775749207
607191843,10218,junrao,2021-04-05T16:41:07Z,could we include remotelogsegmentmetadata in the exception message?,0,0.9944369792938232
607196509,10218,junrao,2021-04-05T16:49:33Z,should we include metadataupdate in the message of the exception?,0,0.9936645030975342
607205642,10218,junrao,2021-04-05T17:05:49Z,this comment is confusing since there is no update here.,-1,0.9474619030952454
607211862,10218,junrao,2021-04-05T17:17:23Z,"hmm, during unclean leader election, some of the old segments may need to be added to unreferenced segment id list but may not have the exact offset of the new segment. how are those segments handled here?",0,0.963006854057312
607225040,10218,junrao,2021-04-05T17:40:58Z,it's weird to reference offsettoid here since it's in a separate class.,-1,0.984619677066803
607226551,10218,junrao,2021-04-05T17:43:59Z,is the test for remotelogsegmentstate.copy_segment_finished necessary since it seems that only segments with remotelogsegmentstate.copy_segment_finished exist in offsettoid.,0,0.9957799911499023
607241348,10218,junrao,2021-04-05T18:10:59Z,updatehighestlogoffset => maybeupdatehighestlogoffset ?,0,0.9931040406227112
607247458,10218,junrao,2021-04-05T18:22:28Z,when are entries in leaderepochentries removed?,0,0.9945363998413086
607249504,10218,junrao,2021-04-05T18:26:13Z,"since existingstate can be null, we want to handle it properly.",0,0.9886841177940369
607250466,10218,junrao,2021-04-05T18:27:51Z,should we requirenonnull for topicidpartition here too?,0,0.9943543672561646
607255605,10218,junrao,2021-04-05T18:37:31Z,this is an existing issue. but is `>` in line 37 expected?,0,0.9900317192077637
607256604,10218,junrao,2021-04-05T18:39:31Z,is this constructor needed?,0,0.9893419742584229
607546803,10218,satishd,2021-04-06T06:19:42Z,no. javadoc is generated for clients module with the package `/org/apache/kafka/server/log/remote/storage/ `. but this class is in `remote-storage` module.,0,0.995164155960083
607546852,10218,satishd,2021-04-06T06:19:45Z,"sure, i will make it as simple ascii text.",0,0.9767871499061584
607551710,10218,satishd,2021-04-06T06:27:06Z,it prints null. i may be missing something here. what needs to be handled here?,0,0.6898281574249268
607556778,10218,satishd,2021-04-06T06:33:21Z,looks like autoformatter changed it.,0,0.9813486933708191
607559905,10218,satishd,2021-04-06T06:38:20Z,"good point, this check is no more needed.",1,0.8025117516517639
607561788,10218,satishd,2021-04-06T06:40:35Z,not really needed for now.,0,0.8364061117172241
607562925,10218,satishd,2021-04-06T06:41:59Z,updated the comment.,0,0.9881983399391174
607580027,10218,satishd,2021-04-06T07:07:24Z,"yes, in the case of unclean leader election, the leader will remove the old segments for the respective leader epochs. the removal process involves removing the actual segment and updating the respective metadata of the segments.",0,0.9935213923454285
607597875,10218,satishd,2021-04-06T07:30:13Z,one way to do that is to clear the entry when the respective `remotelogleaderepochstate` is empty. that means all the segments reached `delete_segment_finished` state. this is not currently addressed. i plan to look into it when we integrate these apis with remotelogmanager by exploring other options too.,0,0.9906824827194214
607959239,10218,kowshik,2021-04-06T15:34:20Z,nit: remove empty ``,0,0.9742959141731262
607959314,10218,kowshik,2021-04-06T15:34:24Z,nit: remove empty ``,0,0.9742959141731262
607972558,10218,kowshik,2021-04-06T15:50:20Z,should we call this map as `idtoleaderepochstate` or `idtoepochstate` similar to the naming for the other map?,0,0.994789719581604
608025473,10218,kowshik,2021-04-06T16:58:53Z,"same comment as before: [a link] can srcstate be null in practice? if not, this can be defined as an instance method.",0,0.9940364360809326
608820288,10218,satishd,2021-04-07T16:40:30Z,the key is not really `id` but `epoch num`. what about `remotelogleaderepochstateentries` or `leaderepochtostate` or any other better name?,0,0.9930229187011719
608822419,10218,satishd,2021-04-07T16:43:31Z,"yes, it can be null. it is called from [a link]",0,0.9937230944633484
609073411,10218,junrao,2021-04-07T21:13:57Z,it would be useful to add a comment on whether the methods in this class are thread-safe or not.,0,0.9900858402252197
609083684,10218,junrao,2021-04-07T21:32:55Z,it seems that it's inconsistent that we update highest log offset here but not in handlesegmentwithcopysegmentstartedstate(). could we comment on whether highestlogoffset reflects the segments that have reached copy_segment_finished or not?,0,0.9832431674003601
609089991,10218,junrao,2021-04-07T21:45:33Z,it would be useful to document the meaning of the following table.,0,0.9780900478363037
609093303,10218,junrao,2021-04-07T21:52:28Z,could we make it clear this is for offset range?,0,0.994088888168335
609095034,10218,junrao,2021-04-07T21:56:11Z,"at this point, rlmm hasn't cleared all its internal state yet.",0,0.9899946451187134
609097289,10218,junrao,2021-04-07T22:00:24Z,is this logging needed? does it need to be in info level?,0,0.9931060671806335
609100380,10218,junrao,2021-04-07T22:05:53Z,could we make it clear this is for offset range?,0,0.994088888168335
609103486,10218,junrao,2021-04-07T22:11:25Z,is this logging needed? ditto below.,0,0.9907364249229431
609104878,10218,junrao,2021-04-07T22:14:31Z,it's kind of weird that the segment with epoch 0 is already deleted and yet we still expect the highest offset for epoch 0 to be returned.,-1,0.9846915602684021
609107657,10218,junrao,2021-04-07T22:21:00Z,listremotelogsegments(0) => listremotelogsegments(1),0,0.9931405186653137
609351020,10218,satishd,2021-04-08T06:32:43Z,we may have this as debug level by default. it will be helpful to see for which entry the test is failed.,0,0.9853142499923706
609352593,10218,satishd,2021-04-08T06:35:08Z,we may have this as debug level by default. it will be helpful to see for which `epochoffset` the test is failed.,0,0.9902305006980896
609369185,10218,satishd,2021-04-08T06:57:19Z,"sure, i will add the doc. they are currently not thread safe. but we want to address them when we integrate these apis.",0,0.985453188419342
609369253,10218,satishd,2021-04-08T06:57:24Z,"after thinking through this more, we need to update this only when the segment reaches copy_segment_finished. this is effectively used to find out up to which offset the segments are already copied. i will remove the call here and keep the call only in handlesegmentwithcopysegmentfinishedstate. wdyt?",0,0.9706108570098877
609369434,10218,satishd,2021-04-08T06:57:37Z,added a note.,0,0.9856444597244263
609369536,10218,satishd,2021-04-08T06:57:42Z,done,0,0.8974218964576721
609369903,10218,satishd,2021-04-08T06:58:06Z,updated.,0,0.9856141209602356
609372137,10218,satishd,2021-04-08T07:01:06Z,`highestlogoffset` can contain the deleted segments. `highestlogoffset` means the highest offset up to which the segments have been copied. pl take a look at the [a link].,0,0.9926611185073853
609372257,10218,satishd,2021-04-08T07:01:14Z,done,0,0.8974218964576721
609387061,10218,satishd,2021-04-08T07:20:04Z,updated.,0,0.9856141209602356
609882620,10218,junrao,2021-04-08T16:29:27Z,this is redundant.,-1,0.7199309468269348
609891200,10218,junrao,2021-04-08T16:38:55Z,could we move this to debug level then?,0,0.9935380816459656
609895193,10218,junrao,2021-04-08T16:44:18Z,could we add a todo comment here so that we don't forget about it?,0,0.9895491600036621
609896011,10218,junrao,2021-04-08T16:45:25Z,sounds good. could you make the change in the pr?,1,0.8993480801582336
609998576,10218,kowshik,2021-04-08T18:45:30Z,`leaderepochtostate` sounds good.,1,0.5923600792884827
610286497,10218,kowshik,2021-04-09T02:14:20Z,here is a slightly simpler version: [code block],0,0.9847641587257385
610293058,10218,kowshik,2021-04-09T02:26:22Z,"hmm here we assume that `id` should be present in the provided `idtosegmentmetadata`. due to programming error, or other reasons, the caller may not be able to ensure this. would it be safer if we instead threw whenever `id` is absent in `idtosegmentmetadata` to catch that case?",0,0.9929670095443726
610298531,10218,kowshik,2021-04-09T02:37:36Z,"the add call won't replace an existing element with the same `remotelogsegmentid`. is that expected? for example, what happens if `addcopyinprogresssegment` is called twice but this line doesn't replace the existing entry?",0,0.9938309192657471
610302012,10218,kowshik,2021-04-09T02:44:27Z,"nit: add one whitespace at the end after ""...state""",0,0.9912428855895996
610305248,10218,kowshik,2021-04-09T02:50:25Z,is this method expected to be idempotent? note: this comment is related to my other comment: [a link],0,0.9889471530914307
610454559,10218,satishd,2021-04-09T08:42:52Z,"imho, existing code looks easy to read/comprehend, and no multiple calls to hasnext(). how about the below code after removing inline variables in the existing code? [code block]",0,0.9749119281768799
610462859,10218,satishd,2021-04-09T08:55:44Z,it already replaces the existing entry [a link].,0,0.9861817359924316
610464252,10218,satishd,2021-04-09T08:57:54Z,addressed in the above [a link].,0,0.9892933368682861
610491754,10218,kowshik,2021-04-09T09:40:59Z,sounds good,1,0.9683692455291748
610494457,10218,kowshik,2021-04-09T09:45:34Z,"ok, i think this is fine then.",0,0.8862598538398743
610494694,10218,kowshik,2021-04-09T09:45:53Z,sounds good,1,0.9683692455291748
610517070,10218,satishd,2021-04-09T10:23:25Z,"good point, i will add a check for that.",1,0.7136641144752502
610809710,10218,junrao,2021-04-09T17:53:19Z,typo epty,0,0.8859159350395203
610940157,10218,satishd,2021-04-09T22:50:50Z,"yes, it is done.",0,0.9010207653045654
610940434,10218,satishd,2021-04-09T22:51:56Z,"yes, i updated the pr.",0,0.9634262323379517
610944855,10218,satishd,2021-04-09T23:07:59Z,fixed.,0,0.979083240032196
611267145,10218,kowshik,2021-04-12T00:13:25Z,typo: the title of the last column should be `delete_segment_finished`.,0,0.9944359064102173
611305646,10218,satishd,2021-04-12T03:25:13Z,"thanks, addressed it in the latest commit.",1,0.7083629369735718
1335136107,14432,vamossagar12,2023-09-24T07:16:06Z,i have taken the liberty and updated the log line to use an argument based loggers instead of the string concatenation based pattern that existed before.,0,0.9787907600402832
1338285360,14432,vamossagar12,2023-09-27T08:53:33Z,this is not necessarily needed but added to avoid situations when a non static member tries to send a member epoch -2.,0,0.9861896634101868
1338844884,14432,kirktrue,2023-09-27T16:04:11Z,"this is for the case where the static member is leaving temporarily, right? would it be possible to add more detail to these error messages to aid in troubleshooting/debugging on the client when this condition is hit?",0,0.9913002848625183
1338849515,14432,kirktrue,2023-09-27T16:07:34Z,nice! can we add the group id to the 'static member' log message?,1,0.9583807587623596
1338895795,14432,vamossagar12,2023-09-27T16:34:12Z,"yes, that's correct. i have added some debugging information (like groupid etc). let me know if that makes sense.",0,0.9638186097145081
1338895972,14432,vamossagar12,2023-09-27T16:34:19Z,done.,0,0.9640594124794006
1338900198,14432,vamossagar12,2023-09-27T16:37:16Z,"also, `memberid can't be empty.` string is used in other places as well (when member epoch is > 0 or equal to -1. should we look to change those as well?",0,0.9935513734817505
1344754813,14432,kirktrue,2023-10-03T21:19:41Z,"it's just my preference, so if there's precedent for how you have it, i wouldn't hold up this pr in an effort to change the other places. thanks!",1,0.9911614656448364
1345450086,14432,vamossagar12,2023-10-04T08:57:24Z,"makes sense. i think i updated that one comment. but yeah the rest of the loggers, i won't be touching them, as that would be noisy to review.",0,0.7891060709953308
1348694911,14432,dajac,2023-10-06T13:02:39Z,nit: indentation should be 4 spaces.,0,0.9598513245582581
1348699907,14432,dajac,2023-10-06T13:07:25Z,i suppose that this must be a `timelinehashmap`.,0,0.9912181496620178
1348700266,14432,dajac,2023-10-06T13:07:46Z,nit: indentation should be four spaces.,0,0.9603379964828491
1348701917,14432,dajac,2023-10-06T13:09:15Z,the state should not be updated like this. all the updates are handled in the `replay()` methods.,0,0.9942195415496826
1348845154,14432,dajac,2023-10-06T15:03:46Z,could we add custom message to all the exceptions raise in this method?,0,0.9917505383491516
1348855163,14432,dajac,2023-10-06T15:11:38Z,i wonder if we really need the second part of the condition here. what was your thinking about it?,0,0.9203436970710754
1348858332,14432,dajac,2023-10-06T15:14:12Z,this is a bit weird because you pass `existingmember` to the builder and then you still have to override other fields. would it be better to do `new consumergroupmember.builder(existingmember)` and then override the fields? i think that we only need to set the new member id. nit: the indentation should be four spaces.,-1,0.9493116140365601
1348858959,14432,dajac,2023-10-06T15:14:33Z,"as said previously, the state should not be updated here but in replay.",0,0.9932678937911987
1348859279,14432,dajac,2023-10-06T15:14:48Z,nit: indentation.,-1,0.793114960193634
1348861003,14432,dajac,2023-10-06T15:15:53Z,i wonder if we could log something here as well when a static member is replaced.,0,0.9786544442176819
1348864154,14432,dajac,2023-10-06T15:18:25Z,this does not seem correct because we will write a record whenever the member is not updated and we have an instance id. i think that it would be better to capture the fact that we have a new static member in the condition at l801.,0,0.9815380573272705
1348866036,14432,dajac,2023-10-06T15:19:51Z,"i just thought about something else. when a static member is replaced, we need to write records to erase the state of the previous member.",0,0.947695791721344
1348872341,14432,dajac,2023-10-06T15:24:47Z,i would rather prefer to have a separate method for the static leave group.,0,0.9901832938194275
1348872557,14432,dajac,2023-10-06T15:24:57Z,nit: indentation.,-1,0.793114960193634
1348873017,14432,dajac,2023-10-06T15:25:14Z,nit: should we introduce a constant for -2 as well?,0,0.9857481122016907
1348874306,14432,dajac,2023-10-06T15:26:16Z,we don't need to use getormaybecreatestaticmember here as we only want to look up the member by its id.,0,0.9922768473625183
1348875180,14432,dajac,2023-10-06T15:26:59Z,"in there, we need to update the static id mapping in updatemember and removemember, i think.",0,0.9942139983177185
1354486658,14432,vamossagar12,2023-10-11T09:00:09Z,done.,0,0.9640594124794006
1354487016,14432,vamossagar12,2023-10-11T09:00:16Z,done.,0,0.9640594124794006
1354488025,14432,vamossagar12,2023-10-11T09:00:44Z,"makes sense, i have removed this direct update of states and moved it to `replay()`",0,0.9862355589866638
1354491971,14432,vamossagar12,2023-10-11T09:02:44Z,actually this is no longer required. have removed it.,0,0.9854865074157715
1354492275,14432,vamossagar12,2023-10-11T09:02:53Z,ack.,0,0.5038502812385559
1354505609,14432,vamossagar12,2023-10-11T09:06:55Z,yes that was a miss. i have added relevant tombstone records for the replaced static member and also cancelled it's timers.,0,0.9849944710731506
1354506320,14432,vamossagar12,2023-10-11T09:07:07Z,added.,0,0.9822506308555603
1354506847,14432,vamossagar12,2023-10-11T09:07:17Z,done,0,0.8974218964576721
1354507878,14432,vamossagar12,2023-10-11T09:07:33Z,done,0,0.8974218964576721
1354516913,14432,vamossagar12,2023-10-11T09:10:20Z,this method is no longer being used. i added custom messages in the other method which is now being called.,0,0.9907411336898804
1354518973,14432,vamossagar12,2023-10-11T09:10:51Z,"yes, that didn't quite make sense. it's not needed anymore. fixed indent as well.",0,0.9568032622337341
1354520295,14432,vamossagar12,2023-10-11T09:11:12Z,this bit of code has changed now.,0,0.9772511720657349
1362101057,14432,dajac,2023-10-17T13:19:21Z,nit: we tend to use a single line for getters. eg. ` the member id corresponding to the given instance id or null if it does not exist`.,0,0.9918878674507141
1362102003,14432,dajac,2023-10-17T13:20:03Z,nit: we don't prefix getters with `get`. let's add javadoc as well.,0,0.9832683205604553
1362105275,14432,dajac,2023-10-17T13:22:21Z,nit: would it make sense to have a method like the others? i would also do this before calling `maybeupdategroupstate`.,0,0.9925957322120667
1362105499,14432,dajac,2023-10-17T13:22:30Z,ditto.,0,0.6705162525177002
1362106636,14432,dajac,2023-10-17T13:23:12Z,let's add unit tests for the new or changed methods to the corresponding file.,0,0.9876776337623596
1362197123,14432,dajac,2023-10-17T14:13:31Z,i think that the old member will be in `members` so the computed target assignment is incorrect. we need to remove it with `removemember` and we also need to set the target assignment of the new member from the old one.,0,0.984343409538269
1362197956,14432,dajac,2023-10-17T14:14:04Z,we have similar code somewhere else. could we add a method for this and reuse it?,0,0.9929967522621155
1362198218,14432,dajac,2023-10-17T14:14:15Z,same for this one. it would be great to have a method.,1,0.70036780834198
1362200665,14432,dajac,2023-10-17T14:15:44Z,"i am not sold on this. is it too difficult to reuse the main logic? there are a few issues with this approach. for instance, the member's assignment is not reconciled like we do in the main logic. another one is that the subscription metadata must be updated as well if the subscriptions have changed.",-1,0.8448648452758789
1362215540,14432,dajac,2023-10-17T14:23:59Z,i don't fully get this one. could you please elaborate?,0,0.8135160207748413
1363301832,14432,vamossagar12,2023-10-18T06:22:35Z,"the main reason for extracting this out was that while using the main logic, there always always a group epoch bump even when a new static member replaces an older one. when i debugged it further, it seems to be because of this logic [a link] . more specifically, the issue at hand is that `subscriptionmetadata` has partition racks info while the currently stored metadata doesn't have it. this is with regards to the test `teststaticmembergetsbackassignmentuponrejoin`. i wasn't totally sure if this is an issue with the test itself but since this led to a group epoch bump, i thought we shouldn't do it. actually when i think about it now, maybe it makes sense to have a group epoch bump in this case as well. while it might go against no rebalance during static member rejoin but the reason for rejoin is a change in subscription metadata and not a static member re-join. the latter seemed harder to replicate via tests though because it always bumped up the group epoch due to the above mentioned issue. please let me know your thoughts.",0,0.9875196218490601
1363322519,14432,vamossagar12,2023-10-18T06:35:12Z,"i missed the `removemembers` part. thanks for pointing it out. regarding i assumed, this [a link] should take care of it. was my assumption wrong?",1,0.6767944693565369
1363327084,14432,vamossagar12,2023-10-18T06:38:42Z,"this is mainly needed for the static member rejoin case. let's say a static member with instance id `id` departed. when it departs, we would write a member epoch value of -2 against it. now, if a new static member joins with the same instance id `id` and a member epoch value of 0, then without this condition, the rejoin would always fail with `fencedmemberepochexception`. this condition was added to avoid the same.",0,0.9904959201812744
1363408245,14432,dajac,2023-10-18T07:51:33Z,"well, at the moment, a new target assignment will be computed for the new static member and that block of code will indeed create the record for it. what i meant is that the new static member should actually reuse the target assignment of the previous member (vs computing a new one). then we only need to recompute the assignment if there is a group epoch bump.",0,0.9895093441009521
1363414003,14432,dajac,2023-10-18T07:55:20Z,hum... i am not sure to fully follow. the subscription metadata should not be different if the subscriptions and the metadata image have not changed. does the new static member has the same subs as the previous one in your case?,-1,0.974195659160614
1363419939,14432,dajac,2023-10-18T07:58:37Z,"i see. would it make sense to put this condition first in the method, before `if (receivedmemberepoch > member.memberepoch())`? i got confused by the fact that it is within the if branch.",0,0.9870607852935791
1370523697,14432,vamossagar12,2023-10-24T16:47:34Z,"yeah, that makes sense as well. i placed it inside the if condition because this condition at hand shows up only when received epoch > current member epoch. but it should be ok to have it outside as you said. i have made the change.",0,0.9247437119483948
1370523927,14432,vamossagar12,2023-10-24T16:47:47Z,done.,0,0.9640594124794006
1370524066,14432,vamossagar12,2023-10-24T16:47:54Z,done.,0,0.9640594124794006
1370531600,14432,vamossagar12,2023-10-24T16:52:34Z,"i got around the issue by explicitly setting the rack info in the subscription metadata like [a link]. i guess so far this wasn't apparent because all the tests expected a group epoch bump happening. in this case, we didn't want a group epoch bump and hence i could notice the discrepancy.",0,0.9712468981742859
1370532536,14432,vamossagar12,2023-10-24T16:53:25Z,that makes sense and thanks for the explanation. i have now changed the code to remove the existing static member and add the new static member. rest of the state would remain as is.,1,0.8384761214256287
1370532706,14432,vamossagar12,2023-10-24T16:53:34Z,done.,0,0.9640594124794006
1370533114,14432,vamossagar12,2023-10-24T16:54:00Z,done.,0,0.9640594124794006
1370533226,14432,vamossagar12,2023-10-24T16:54:07Z,done.,0,0.9640594124794006
1370538866,14432,vamossagar12,2023-10-24T16:55:35Z,"also, regarding given that now we will have a group epoch bump whenever a static member re-joins with a different subscription, should this be mentioned in the kip? as we noticed, this is a deviation from how the static member rejoining with a different subscription case as of today. wdyt?",0,0.9745814800262451
1370539621,14432,vamossagar12,2023-10-24T16:55:51Z,done.,0,0.9640594124794006
1370539793,14432,vamossagar12,2023-10-24T16:55:59Z,done.,0,0.9640594124794006
1370542261,14432,vamossagar12,2023-10-24T16:58:01Z,", i realised that even in the static member re-joining case, while the group epoch doesn't bump, the partitions would be in pending assignment state. i believe, eventually the member would get it's assignments. in that case, this state seems correct to me. wdyt?",0,0.8610087037086487
1377556564,14432,dajac,2023-10-31T13:05:28Z,"i wonder if we could simplify it even more. for instance, would it be possible to have something like the following: [code block]",0,0.9738474488258362
1377557816,14432,dajac,2023-10-31T13:06:15Z,if we rely on `member` and `updatedmember` then we don't need this because `!updatedmember.equals(member)` will catch the new member.,0,0.9907870888710022
1377567890,14432,dajac,2023-10-31T13:14:15Z,i don't fully understand how this would work because the members and the target assignment are not set.,-1,0.5750010013580322
1377571172,14432,dajac,2023-10-31T13:16:47Z,"when the `targetassignmentbuilder` builds the spec for the assignor, it must use the target assignment of the previous static member for the new static member. how do we ensure this? we may have to update the `targetassignmentbuilder` to understand that a static member is replaced.",0,0.9937678575515747
1377572235,14432,dajac,2023-10-31T13:17:39Z,"don't we need to also force the step 3.? if we don't do it, we don't write the current assignment record for the new member and we don't reconcile him.",0,0.9804645776748657
1377575023,14432,dajac,2023-10-31T13:19:44Z,nit: removememberandcanceltimers? the logic is not tight to static members. i would also directly pass the groupid and the memberid as this is all it needs.,0,0.9834789037704468
1377614473,14432,dajac,2023-10-31T13:46:48Z,"this is actually executed twice. once here and once in `consumergroupstaticmembergroupleave`. i also wonder if we need to full validation here. i suppose that ensuring that the member id is correct would be enough, no?",0,0.9851904511451721
1377615301,14432,dajac,2023-10-31T13:47:21Z,nit: we check this twice. once here and once earlier to lookup the member. could we combine them?,0,0.9859157800674438
1377616732,14432,dajac,2023-10-31T13:48:07Z,"nit: `""[groupid {}] static member {} with member id {} left the consumer group.""`? i would also use a similar logging structure for the other log messages.",0,0.9950565099716187
1377617256,14432,dajac,2023-10-31T13:48:25Z,nit: let's align the description of the params.,0,0.9796323180198669
1377617520,14432,dajac,2023-10-31T13:48:35Z,nit: `member`?,0,0.9918667674064636
1377619412,14432,dajac,2023-10-31T13:49:40Z,nit: the `addall` does not seem necessary here. could we avoid it?,0,0.9578636884689331
1377621712,14432,dajac,2023-10-31T13:50:48Z,nit: we can reduce the space between the name and the desc.,0,0.9831174612045288
1377623260,14432,dajac,2023-10-31T13:51:46Z,"nit: let's use `""memberid can't be empty.""` to be consistent with the previous errors.",0,0.9923364520072937
1377624326,14432,dajac,2023-10-31T13:52:27Z,i think that the instance id cannot be null and cannot be empty as well. then let's use `instanceid can't be null or empty.`,0,0.9858769178390503
1377625954,14432,dajac,2023-10-31T13:53:36Z,could we add something to the exception?,0,0.9895203113555908
1383610866,14432,vamossagar12,2023-11-06T16:27:59Z,i have updated the logic in line with your suggestion.,0,0.9839363098144531
1383611138,14432,vamossagar12,2023-11-06T16:28:11Z,"yes, that makes sense.",0,0.9692287445068359
1383612141,14432,vamossagar12,2023-11-06T16:28:57Z,i have added members and target assignment.,0,0.9469888210296631
1383612935,14432,vamossagar12,2023-11-06T16:29:33Z,i think i got it now. i added some state tracking to the `targetassignmentbuilder` so that it doesn't compute assignments for a replacing static member.,0,0.9823586344718933
1383615616,14432,vamossagar12,2023-11-06T16:30:58Z,"yes, i am now building the replacing static member with the same set of assignments (target/pending). this forces it directly to have the current assignment record for the new member.",0,0.9868404865264893
1383616531,14432,vamossagar12,2023-11-06T16:31:09Z,done.,0,0.9640594124794006
1383617107,14432,vamossagar12,2023-11-06T16:31:17Z,removed.,0,0.9782117605209351
1383617522,14432,vamossagar12,2023-11-06T16:31:25Z,done.,0,0.9640594124794006
1383617966,14432,vamossagar12,2023-11-06T16:31:31Z,done.,0,0.9640594124794006
1383618637,14432,vamossagar12,2023-11-06T16:31:41Z,done.,0,0.9640594124794006
1383620879,14432,vamossagar12,2023-11-06T16:32:19Z,added.,0,0.9822506308555603
1397018204,14432,dajac,2023-11-17T10:00:25Z,i would just use `instanceid can't be null.` here. i think that we should also verify that the instance id is not empty.,0,0.990844190120697
1397269098,14432,dajac,2023-11-17T13:01:00Z,nit: it seems that we could declare this one only when we use it at l948.,0,0.9911035299301147
1397287511,14432,dajac,2023-11-17T13:14:27Z,i still find this logic quite complex to follow. i wonder if we could be a little more explicit. i think that the complexity comes from `throwifstaticmembervalidationfails` which hide quite a lot of the logic. i wonder if something as follow would be better. i am not sure... what do you think? [code block] note that i just wrote this without testing it so the code is likely not 100% correct :).,-1,0.8875470161437988
1397290332,14432,dajac,2023-11-17T13:16:47Z,i would say `[groupid {}] static member {} with instance id {} joins the consumer group.`,0,0.9926873445510864
1397291443,14432,dajac,2023-11-17T13:17:55Z,"i was thinking about this a little more and i actually wonder if we need this after all. if we don't see it, i think that the reconciliation will kick in and compute the current assignment. what do you think?",0,0.8066626191139221
1397321543,14432,dajac,2023-11-17T13:35:23Z,is the condition really correct? it seems to me that we must remove the previous member whenever staticmemberreplaced is true. how about the following? [code block],0,0.9903843402862549
1397322222,14432,dajac,2023-11-17T13:35:48Z,nit: let's keep this log message where it was.,0,0.9747651815414429
1397350631,14432,dajac,2023-11-17T13:54:43Z,how about the following? [code block],0,0.991778552532196
1397353174,14432,dajac,2023-11-17T13:56:52Z,"instead of doing this, could we just pass the mapping from the consumergroup?",0,0.994466245174408
1397356292,14432,dajac,2023-11-17T13:59:21Z,"it is a tad annoying that we have to build this mapping here because we usually only need it for one member. instead of doing this, i wonder if we could lookup the member id from the instance id mapping and then get the target assignment of the member id. the mapping will contain the previous member or nothing.",-1,0.9771478176116943
1397360473,14432,dajac,2023-11-17T14:02:39Z,should we remove this as the member is not there anymore?,0,0.9938598871231079
1397363828,14432,dajac,2023-11-17T14:05:27Z,nit: let's put this comment before `consumergroupmember member2updatedepoch = ...`.,0,0.9933340549468994
1397366414,14432,dajac,2023-11-17T14:06:46Z,"if i recall correctly, we automatically do this in `consumergroupheartbeat()`.",0,0.9927828311920166
1397366873,14432,dajac,2023-11-17T14:06:58Z,nit: `member...`.,0,0.9815763235092163
1397367189,14432,dajac,2023-11-17T14:07:11Z,nit: `member...` and `.` at the end.,0,0.9923006296157837
1397368692,14432,dajac,2023-11-17T14:08:31Z,i suppose that this is not required as it don't be called.,0,0.975407063961029
1397369747,14432,dajac,2023-11-17T14:09:29Z,nit: let's remove this empty line.,0,0.9771315455436707
1397373074,14432,dajac,2023-11-17T14:11:28Z,nit: we can remove this empty line.,0,0.9824963808059692
1397376607,14432,dajac,2023-11-17T14:14:25Z,should we also verify that the timers are cancelled correctly?,0,0.994253933429718
1397378393,14432,dajac,2023-11-17T14:15:52Z,"do we test all possible error cases? thinking of fenced instance id, unknown member id, fenced member epoch, etc.",0,0.9901394248008728
1397379496,14432,dajac,2023-11-17T14:16:50Z,"this is true if the member leaves with -2. if it leaves with -1, it should be removed immediately. should we test this as well?",0,0.995012104511261
1397382111,14432,dajac,2023-11-17T14:18:37Z,i wonder if we could add a few more tests. thinking about the following ones: * the leaving static member should disappear if the new one does not rejoin with the session timeout. * the new data structures should be updated correctly on replay.,0,0.9846014976501465
1397383047,14432,dajac,2023-11-17T14:19:27Z,"should we simplify a bit this test? we only need on member in the group to verify what we want here. we could also use one topic only, etc.",0,0.9913336634635925
1397383490,14432,dajac,2023-11-17T14:19:50Z,we could also simplify this one.,0,0.9879639148712158
1397383760,14432,dajac,2023-11-17T14:20:04Z,this one as well.,0,0.9874308109283447
1399522392,14432,vamossagar12,2023-11-20T17:22:47Z,sure. `instance id should not be empty` check is already happening [a link],0,0.9940361976623535
1402215662,14432,vamossagar12,2023-11-22T15:12:10Z,"actually, `groupepoch == targetassignmentepoch` is not needed. i was just trying to ensure that the group epoch and target member epoch are the same which is what will happen when static member is replaced. so, in a way it's redundant. i will remove it.",0,0.9850037097930908
1402217667,14432,vamossagar12,2023-11-22T15:13:39Z,"if i don't set `setassignedpartitions`, then the replacing static member doesn't get it's assignments back. the pending assignments bit, i added just to ensure all assignments from previous member are assigned to the new member. the reason that happens is that it lands up [a link] and if there are no partitions assigned, it gets back empty assignments.",0,0.9773523211479187
1404037483,14432,dajac,2023-11-24T07:50:21Z,i would rather use `instanceid can't be null.` here in order to be consistent with the other error messages.,0,0.9944145679473877
1404037631,14432,dajac,2023-11-24T07:50:33Z,i suppose that we could remove this one now. could we?,0,0.988257110118866
1404037934,14432,dajac,2023-11-24T07:50:54Z,is it still necessary with the last implementation?,0,0.9931023120880127
1404038516,14432,dajac,2023-11-24T07:51:40Z,nit: `leave` -> `leave`.,0,0.9912336468696594
1404039007,14432,dajac,2023-11-24T07:52:16Z,should we also log something in this case?,0,0.9934188723564148
1404039730,14432,dajac,2023-11-24T07:53:14Z,nit: i would put `member` as the first argument to be consistent with the other helpers.,0,0.9923731684684753
1404042879,14432,dajac,2023-11-24T07:57:03Z,"* could we move those helpers next to `throwifmemberepochisinvalid`? could we also add some javadoc to each of them? * i wonder if we could also find better names for the params because it is not clear whether `memberid` and `instanceid` are the ones of the existing member or the ones received in the request. we could perhaps use `receivedmemberid`, etc. what do you think? this also applies to the other helpers.",0,0.9935264587402344
1404047713,14432,dajac,2023-11-24T08:02:56Z,i wonder if we could follow the structure of the other log messages here: `[groupid {}] static member {} with instance id {}....`.,0,0.9896339178085327
1404047826,14432,dajac,2023-11-24T08:03:06Z,should we also log something here?,0,0.9930939674377441
1404050011,14432,dajac,2023-11-24T08:05:46Z,nit: `.` at the end.,0,0.9861802458763123
1404050141,14432,dajac,2023-11-24T08:05:56Z,nit: `.` at the end.,0,0.9861802458763123
1404051525,14432,dajac,2023-11-24T08:07:38Z,"nit: could we also use `records = ` here? with this, we could remove `new arraylist<>()` when `records` is declared, i think.",0,0.9948588609695435
1404058043,14432,dajac,2023-11-24T08:15:26Z,nit: let's revert this change as it is not necessary.,0,0.9695321917533875
1404062478,14432,dajac,2023-11-24T08:20:30Z,"i am not sure to follow this one. my understanding is that we populate `staticmembers` only when `addorupdatemember` is called. in the main flow, we basically call this only once with the new or updated member. let's imagine that a new static member joins. we will add its static id with its member id to `staticmembers`. therefore here, we basically get back its member id and end up with no assignment. did i get this right? i think that this could work but we would need to pass the `staticmembers` mapping from the `consumergroup` to the builder, like we pass the members. if we have this, we could use it here to find the previous member with the static id if the member is new and has a static id.",0,0.9555627107620239
1404070683,14432,dajac,2023-11-24T08:29:42Z,nit: `instance id {} is unknown.`?,0,0.9801698327064514
1404071502,14432,dajac,2023-11-24T08:30:30Z,nit: `static member {} with instance id {} cannot join the group because the instance id is owned by member {}.`?,0,0.9936833381652832
1404072143,14432,dajac,2023-11-24T08:31:17Z,nit: `static member {} with instance id {} was fenced by member {}.`?,0,0.9943972826004028
1404124114,14432,dajac,2023-11-24T09:22:48Z,"to close on this one, it is indeed correct to set the assigned partitions here. without it, the reconciler checks if the partitions in the target assignment are still owned and they are effectively still owned until the previous member is removed. this only happens when the records are processed.",0,0.9933615922927856
1404125908,14432,dajac,2023-11-24T09:24:32Z,i think that we could also `setpartitionspendingrevocation` to empty because we know that the member has revoked all its partitions when it leaves.,0,0.9923872947692871
1404157968,14432,dajac,2023-11-24T09:52:34Z,"this should not be here. i think that you mix in two different things. `addgroupmember` is basically what is used to build what will be passed to `withmembers` and `withtargetassignment` whereas `updatemembersubscription` is for `addorupdatemember`. therefore, the test does not reproduce how we use it.",0,0.9855532050132751
1404158564,14432,dajac,2023-11-24T09:53:07Z,this one is incorrect as well because the newly added member is not added via `withmembers`.,0,0.9855802059173584
1404163349,14432,dajac,2023-11-24T09:57:41Z,nit: indentation seems off here. i think that it should be 4 spaces earlier.,0,0.5447416305541992
1404164525,14432,dajac,2023-11-24T09:58:45Z,nit: indentation is incorrect.,-1,0.9093594551086426
1404165368,14432,dajac,2023-11-24T09:59:30Z,nit: indentation.,-1,0.793114960193634
1404167570,14432,dajac,2023-11-24T10:01:35Z,let's replace `-2` with the relevant constant. there are other cases in this file.,0,0.9945217370986938
1404168570,14432,dajac,2023-11-24T10:02:31Z,nit: temporarily leave?,0,0.9074286222457886
1404172073,14432,dajac,2023-11-24T10:05:48Z,we already have `testconsumerheartbeatrequestvalidation` so i wonder if we could just add the new case there. what do you think?,0,0.9887406229972839
1404172650,14432,dajac,2023-11-24T10:06:25Z,nit: indentation.,-1,0.793114960193634
1405732004,14432,vamossagar12,2023-11-27T07:18:31Z,no it is not. removed it.,0,0.9818156361579895
1405732141,14432,vamossagar12,2023-11-27T07:18:43Z,added a log line,0,0.9869062304496765
1405732647,14432,vamossagar12,2023-11-27T07:19:24Z,"done, moved the methods next to `throwifmemberepochisinvalid`, added javadocs and updated the argument names.",0,0.9945570230484009
1405733434,14432,vamossagar12,2023-11-27T07:20:28Z,done.,0,0.9640594124794006
1405737202,14432,vamossagar12,2023-11-27T07:25:42Z,"yes, your understanding is correct. i see what you are saying about how this won't work when a new static member joins. i have updated the group to expose the current set of static members in the group.",0,0.9686305522918701
1405737404,14432,vamossagar12,2023-11-27T07:26:02Z,thank you for the confirmation.,0,0.5623961687088013
1405738152,14432,vamossagar12,2023-11-27T07:27:02Z,"i see. thanks for the explanation, i hadn't understood the usage of these methods correctly. i have removed these unwanted calls to `updatemembersubscription`",1,0.5709081292152405
1405739030,14432,vamossagar12,2023-11-27T07:28:09Z,ok.. i am slightly confused by this comment. the new member is being added using `addgroupmember` which internally invokes `withmembers`. i had an unwanted call to `updatemembersubscription` which i have removed. probably i am missing something here.,-1,0.8841156959533691
1405785516,14432,dajac,2023-11-27T08:13:45Z,i think that we should call `updatemembersubscription` instead of calling `addgroupmember` here because `updatemembersubscription` is what is used to eventually call `addorupdatemember`.,0,0.9924564361572266
1331125886,14408,dajac,2023-09-20T07:24:58Z,nit: you could use `foreach` which is a bit more concise.,0,0.9866541028022766
1331127964,14408,dajac,2023-09-20T07:26:29Z,"nit: let's put `delete-group` on a new line as well. could you also ensure that the format conforms to the existing code? e.g. where the closing parenthesis is, the indentation (4 spaces), etc.",0,0.9933269023895264
1331129777,14408,dajac,2023-09-20T07:27:57Z,it may be better to use `join` instead of `get`. i think that you would be able to remove the try..catch if you use `join`.,0,0.9899802803993225
1331132885,14408,dajac,2023-09-20T07:30:11Z,"let's assume that one of the write operation fails with `coordinator_load_in_progress`, this would result in failing `allfutures` even though some write operations may have been successful. it seems to me that we should handle exceptions for each write operation future before we combine them, no?",0,0.9900291562080383
1331133058,14408,dajac,2023-09-20T07:30:21Z,nit: indentation.,-1,0.793114960193634
1331134867,14408,dajac,2023-09-20T07:31:13Z,nit: indentation. there are other cases in this pr. i won't mention them all.,-1,0.6537662148475647
1331141079,14408,dajac,2023-09-20T07:36:09Z,"i have a few comments regarding this piece of code: 1. i think that we should write the tombstones for the offsets before the ones for the group. 2. it is a bit strange to return a coordinatorresult from `deletealloffsets` and to ignore it. it would be better to pass the list of records to the method and to let the method populate it if the deletion is accepted. i would also remove the response as we don't need it. 3. the `validgroupids` is a bit weird. how about iterating over the group ids here? then, you can call the various methods from the manages to validate, delete offsets and finally delete the group. if there is an error, you can directly populate the response with it.",-1,0.904975414276123
1331143758,14408,dajac,2023-09-20T07:37:23Z,"`newgroupmetadatatombstonerecord` only works for generic groups. for consumer groups, we need to write other tombstones.",0,0.9934333562850952
1331145296,14408,dajac,2023-09-20T07:38:32Z,we should not write the record if subscribedtotopic is true because it will effectively delete the offset.,0,0.9841974377632141
1331146404,14408,dajac,2023-09-20T07:39:23Z,"as i said earlier, i think that returning coordinatorresult is not appropriate here because we don't need a response in this case. we basically build for the response to ignore it right after.",0,0.9710465669631958
1331958841,14408,dongnuo123,2023-09-20T17:19:03Z,"yeah, it makes sense. i'm not sure what to return if there's an exception in the write operation, since we can't set an error code for a `deletablegroupresultcollection`.",0,0.9274483323097229
1331960774,14408,dongnuo123,2023-09-20T17:20:56Z,done,0,0.8974218964576721
1331961151,14408,dongnuo123,2023-09-20T17:21:20Z,done,0,0.8974218964576721
1331961609,14408,dongnuo123,2023-09-20T17:21:49Z,done,0,0.8974218964576721
1331969154,14408,dongnuo123,2023-09-20T17:29:14Z,"i rearranged this part. now we loop over the group ids and process them one by one -- validate, populate record list with offset tombstones, add group tombstone, and add response.",0,0.9919118881225586
1331969312,14408,dongnuo123,2023-09-20T17:29:25Z,done,0,0.8974218964576721
1332009903,14408,dongnuo123,2023-09-20T18:08:40Z,fixed.,0,0.979083240032196
1332010169,14408,dongnuo123,2023-09-20T18:08:59Z,fixed,0,0.9281549453735352
1332010328,14408,dongnuo123,2023-09-20T18:09:11Z,fixed,0,0.9281549453735352
1332057781,14408,dajac,2023-09-20T18:59:25Z,`deletablegroupresultcollection` contains `deletablegroupresult` which has an error code. therefore i think that we should create a `deletablegroupresult` per group id in the `grouplist` when there is an exception.,0,0.9913852214813232
1332069169,14408,dajac,2023-09-20T19:11:34Z,i think that we need to generate the above records here. * newtargetassignmentepochtombstonerecord * newgroupsubscriptionmetadatatombstonerecord * newgroupepochtombstonerecord,0,0.9915199875831604
1332072625,14408,dajac,2023-09-20T19:15:21Z,do we need this coordinatorresult?,0,0.9879000186920166
1332073736,14408,dajac,2023-09-20T19:16:28Z,"this is the same as newgroupepochtombstonerecord, no?",0,0.9910085797309875
1332632377,14408,dajac,2023-09-21T07:53:22Z,"nit: i wonder if we should use `topicpartitionfor` here. with this, we could directly have the topicpartition as the key in the map and we would not need to create `new topicpartition(topic.group_metadata_topic_name, partition)` later on. what do you think?",0,0.9899622201919556
1332633082,14408,dajac,2023-09-21T07:53:58Z,nit: we could specify the size of the array when we allocate it.,0,0.992946445941925
1332637192,14408,dajac,2023-09-21T07:56:43Z,nit: you could do the following to avoid having to put the list again into the map. [code block],0,0.9902865886688232
1332637739,14408,dajac,2023-09-21T07:57:13Z,nit: `res.addall(future.join())` to reduce the code?,0,0.994239330291748
1332656181,14408,dajac,2023-09-21T08:12:15Z,"it is interesting to point out that, in the current implementation, all these errors are swallowed. this is definitely not ideal because it tells to the user that the deletion is successful even if was not. should we apply the same error handling to the deletegroups?",0,0.9776439070701599
1332661430,14408,dajac,2023-09-21T08:16:25Z,nit: we can remove this empty line.,0,0.9824963808059692
1332661944,14408,dajac,2023-09-21T08:16:51Z,"nit: `deletealloffsets`? i also wonder if the context is required. if not, we could remove it.",0,0.9915376901626587
1332664716,14408,dajac,2023-09-21T08:18:59Z,the coordinatorresult is a bit annoying here. how about passing `records` to the method as well? then we could construct the response here. we could also remove the context if it is not needed. how about naming it `deletegroup` to be consistent with `deleteoffsets`?,-1,0.9206193685531616
1332665059,14408,dajac,2023-09-21T08:19:14Z,nit: we could remove this empty line?,0,0.98394775390625
1332667219,14408,dajac,2023-09-21T08:20:58Z,"i have a question regarding the error handling. could `groupdelete` thrown an exception? if it can, we would need to handle records a bit differently because we don't want to delete the offsets if the group cannot be delete. the operation should be atomic.",0,0.9758679866790771
1332667737,14408,dajac,2023-09-21T08:21:23Z,nit: the indentation is incorrect.,-1,0.8400939106941223
1332670356,14408,dajac,2023-09-21T08:22:52Z,nit: let's remove this empty line and add javadoc to the method.,0,0.9844707250595093
1332672724,14408,dajac,2023-09-21T08:23:41Z,nit: indentation is incorrect.,-1,0.9093594551086426
1332679503,14408,dajac,2023-09-21T08:28:21Z,"let's do the validation before allocating response, records, etc. we don't have to allocate them if the request is invalid. `group` could also be `final`.",0,0.994318425655365
1332679648,14408,dajac,2023-09-21T08:28:28Z,nit: final?,0,0.9836406111717224
1332680359,14408,dajac,2023-09-21T08:29:01Z,"i think that the try..catch is not needed here because we handle the exceptions in the group coordinator service, no?",0,0.9878576993942261
1332682319,14408,dajac,2023-09-21T08:30:30Z,nit: `response = ` is not needed here as `settopics` mutates the response directly.,0,0.9936754107475281
1332689518,14408,dajac,2023-09-21T08:35:32Z,i wonder if we need to verify if there is actually an offset for the topic/partition. we don't need to write a tombstone if there is not. what do you think?,0,0.9398824572563171
1332692288,14408,dajac,2023-09-21T08:37:43Z,i think that a consumer group will actually never transition to dead. we could actually remove this state.,0,0.9576267004013062
1332692487,14408,dajac,2023-09-21T08:37:52Z,ditto.,0,0.6705162525177002
1332693494,14408,dajac,2023-09-21T08:38:40Z,i wonder if using a switch would be better here. what do you think?,0,0.9568500518798828
1332694686,14408,dajac,2023-09-21T08:39:31Z,this does not seem correct to me because this exception does not apply to consumer groups.,0,0.694572925567627
1332695102,14408,dajac,2023-09-21T08:39:47Z,"as mentioned earlier, we have to generate other tombstones.",0,0.9864482283592224
1332697684,14408,dajac,2023-09-21T08:41:20Z,throwing an exception does not seem to be the right approach to me because we still want to delete the group and the exception will stop the process. my understanding is that we could just skip generating the tombstone if the generation <= 0.,0,0.9278027415275574
1333162337,14408,dajac,2023-09-21T14:32:57Z,"actually, what i said is wrong here. i think that we should generate the tombstone in any cases to ensure that the group is removed from the timeline hashmap.",0,0.8907488584518433
1333326880,14408,rreddy-22,2023-09-21T16:24:11Z,"nit: can we add a tab space and capitalize ""the"" -> topic the topic name.",0,0.9910249710083008
1333327696,14408,rreddy-22,2023-09-21T16:24:52Z,"also i thought we had decided to use topicids instead of topic names throughout the new protocol, are we using topic names for this api?",0,0.9938952326774597
1333329945,14408,rreddy-22,2023-09-21T16:26:53Z,"nit: same with this, tab spaces to align both param descriptions",0,0.8853572607040405
1333331492,14408,rreddy-22,2023-09-21T16:28:22Z,nit: extra line,0,0.950958788394928
1333348886,14408,rreddy-22,2023-09-21T16:42:49Z,nit: period is missing,0,0.8531661629676819
1333554676,14408,jeffkbkim,2023-09-21T20:11:58Z,"let's say that for some of the topic partitions, the deletegroups write operations were successful. for others, let's say that there was a timeout. this would return a request timeout to the clients indicating that the request failed. i think this is fine, but it could be confusing to the user. what are your thoughts?",0,0.820054829120636
1333558630,14408,jeffkbkim,2023-09-21T20:16:28Z,we can use collections.singletonlist(),0,0.9933704137802124
1333583218,14408,jeffkbkim,2023-09-21T20:45:18Z,this can be null right? if there are no offsets for the given group id,0,0.9854141473770142
1333600423,14408,jeffkbkim,2023-09-21T21:01:38Z,"nit: handles ""a"" maybe we can reword this to ""deletes offsets as part of a deletegroups request.""",0,0.9876313805580139
1333601100,14408,jeffkbkim,2023-09-21T21:02:28Z,"nit: `(partition, __) ->`",0,0.9925771355628967
1333615622,14408,jeffkbkim,2023-09-21T21:20:16Z,should it be `offsetsbytopic.get(topic.name())`?,0,0.9948524832725525
1333615893,14408,jeffkbkim,2023-09-21T21:20:40Z,should this be `containskey(partition.partitionindex())`?,0,0.9950358271598816
1334471084,14408,dajac,2023-09-22T14:37:24Z,i made the same comment earlier and updated the code to handle exceptions for each write operation.,0,0.988946259021759
1334519906,14408,dajac,2023-09-22T15:15:50Z,offsets apis still use topic names...,0,0.9852365255355835
1336162536,14408,rreddy-22,2023-09-25T16:56:06Z,got it okie!,1,0.989788830280304
1336165006,14408,rreddy-22,2023-09-25T16:58:32Z,nit: can we add new lines between the tests,0,0.9857126474380493
1336165306,14408,rreddy-22,2023-09-25T16:58:52Z,nit: line,0,0.9071451425552368
1336168777,14408,rreddy-22,2023-09-25T17:02:31Z,nit: line,0,0.9071451425552368
1336348269,14408,jeffkbkim,2023-09-25T20:18:12Z,i wonder if creategrouptombstonerecords() makes more sense,0,0.9609526991844177
1336363313,14408,jeffkbkim,2023-09-25T20:36:10Z,"nit: ""deletegroups"" request. this should reflect the actual apikeys#delete_groups name",0,0.9935634136199951
1336441437,14408,jeffkbkim,2023-09-25T22:24:33Z,"can we add a test with three __consumer_offsets topic partitions where one finishes immediately, another takes a while, and the last coordinator throws an exception?",0,0.9929129481315613
1336446270,14408,jeffkbkim,2023-09-25T22:33:21Z,"nit: testdeletegroups also, can we verify the number of method invocations and also test that we append records correctly for multiple groups?",0,0.9949593544006348
1336446500,14408,jeffkbkim,2023-09-25T22:33:44Z,nit: testdeletegroupsinvalidgroupid can we also add a valid group id and verify the first stores invalid group id error and the second stores none?,0,0.9941174983978271
1336449678,14408,jeffkbkim,2023-09-25T22:38:58Z,should this be a static method?,0,0.9926174283027649
1336451305,14408,jeffkbkim,2023-09-25T22:42:01Z,we can inline this to l380,0,0.9890502691268921
1336461743,14408,jeffkbkim,2023-09-25T23:01:52Z,this can be removed,0,0.9869565963745117
1336461886,14408,jeffkbkim,2023-09-25T23:02:11Z,we can do `consumergroup::validategroupdelete` for this along with the other invocations in the test,0,0.9937795996665955
1336465543,14408,jeffkbkim,2023-09-25T23:10:02Z,should we add empty test case? also for testvalidategroupdelete,0,0.9942973256111145
1339019021,14408,jeffkbkim,2023-09-27T18:13:35Z,should these be deletegroup?,0,0.9928221106529236
1339020329,14408,jeffkbkim,2023-09-27T18:14:44Z,whether,0,0.8824562430381775
1339025948,14408,jeffkbkim,2023-09-27T18:19:28Z,"should this be ""delete-groups""?",0,0.9947799444198608
1339176820,14408,jeffkbkim,2023-09-27T20:29:44Z,"validations are done in `{ groupcoordinatorshard#deletegroups(requestcontext, list)}`",0,0.9956139326095581
1339182547,14408,jeffkbkim,2023-09-27T20:34:35Z,ditto on link can we add a comment on why we don't expect an exception to be thrown here?,0,0.9571384191513062
1339194498,14408,jeffkbkim,2023-09-27T20:45:50Z,the id of the group to be deleted.,0,0.9904186129570007
1339198942,14408,jeffkbkim,2023-09-27T20:50:06Z,"in the existing implementation, we transition to dead if the group is empty so that even if the write operation fails we delete the group in the next purge cycle. we don't need to do this here since if the write operation fails we revert to the previous state and return an error so the client knows that the operation failed. is this correct?",0,0.9908919930458069
1339201386,14408,jeffkbkim,2023-09-27T20:52:23Z,the current implementation logs how many groups and offsets were removed. should we add something similar? [code block],0,0.9943244457244873
1339216413,14408,jeffkbkim,2023-09-27T21:06:07Z,can we move this check outside of the foreach block? we perform this check for every partition of the topic,0,0.9950300455093384
1339228792,14408,jeffkbkim,2023-09-27T21:17:29Z,don't we also need to check whether the stable group is using the consumerprotocol.protocol_type? from [code block],0,0.9947401881217957
1339232259,14408,jeffkbkim,2023-09-27T21:21:07Z,"should this be ""delete-offsets""?",0,0.9945194125175476
1339234027,14408,jeffkbkim,2023-09-27T21:22:59Z,do we need this?,0,0.9819303154945374
1339235261,14408,jeffkbkim,2023-09-27T21:24:20Z,can we follow the same line break as in l1101-1102? same for result2,0,0.9941376447677612
1339255544,14408,jeffkbkim,2023-09-27T21:46:00Z,"in general, it's not a good practice to use thread.sleep in tests. also, i don't think this tests what we actually want to test. we want to confirm that the final future is not completed until this operation completes. so i propose: 1. have this thread wait 2. confirm future did not complete 3. unblock this thread 4. confirm future completes something like the following: [code block]",0,0.9832751154899597
1340712345,14408,dajac,2023-09-28T22:14:06Z,nit: could we refactor `geterrorresponse` to use this new method as well? should we also add a unit test for this one?,0,0.9946109056472778
1340712743,14408,dajac,2023-09-28T22:14:53Z,i wonder if we should rather pass the list of records as an argument in order to avoid having to copy the records afterwards. have you considered this?,0,0.9860438108444214
1340716345,14408,dajac,2023-09-28T22:22:06Z,nit: should we set the expected size here?,0,0.9920497536659241
1340716744,14408,dajac,2023-09-28T22:22:57Z,"good question. in my opinion, this log line is useful for the expiration case. i am not sure if it really is in this one.",1,0.960155189037323
1340717283,14408,dajac,2023-09-28T22:24:01Z,nit: let's remove this empty line.,0,0.9771315455436707
1340717524,14408,dajac,2023-09-28T22:24:31Z,nit: should we just add this to the document of the groupid field?,0,0.9938096404075623
1340720235,14408,dajac,2023-09-28T22:29:11Z,"do we ever transition to dead? if not, i wonder if we should just remove this and remove the dead state. what do you think?",0,0.8993881940841675
1340720555,14408,dajac,2023-09-28T22:29:51Z,nit: i wonder if using a switch would be better here. have you considered it?,0,0.899195671081543
1340720632,14408,dajac,2023-09-28T22:30:01Z,nit: ditto for the switch.,-1,0.922325849533081
1340744802,14408,dajac,2023-09-28T23:20:18Z,nit: could we put `setgroupid` on a new line as well?,0,0.9946594834327698
1340745968,14408,dajac,2023-09-28T23:23:13Z,nit: the `null` here is not ideal. could we put a string instead? or you could also use coordinator_load_in_progress.exception().,0,0.9497461318969727
1340747829,14408,dajac,2023-09-28T23:27:23Z,"i am not sure to understand what you are trying to achieve here. could you elaborate? if you want to delay the completion of the future, the best would be to create a completablefuture, use thenreturn(future), and then complete the future at l1149.",0,0.9260973930358887
1340749921,14408,dajac,2023-09-28T23:33:00Z,is there a reason why you don't use when().thenanswer(...)?,0,0.9827278256416321
1340750286,14408,dajac,2023-09-28T23:33:55Z,could we also use `groupids` to generate the list here?,0,0.9924712181091309
1340750616,14408,dajac,2023-09-28T23:34:52Z,ditto for those two.,-1,0.8116955161094666
1340750923,14408,dajac,2023-09-28T23:35:44Z,nit: could we put an empty line before this one? i find the code a bit hard to read because all the lines are all together.,-1,0.6920930743217468
1340752025,14408,dajac,2023-09-28T23:38:51Z,"small nit: it may be a bit easier to read if we create the expected response as follow? what do you think? if you find it better, we could also update the other test cases. [code block]",0,0.9671690464019775
1340752304,14408,dajac,2023-09-28T23:39:37Z,should we at minimum verify the group ids here?,0,0.9940974712371826
1340753404,14408,dajac,2023-09-28T23:42:35Z,"in the groupmetadatamanagertestcontext, we actually moved this to the replay method. see [a link]. it may be better to do the same here. what do you think?",0,0.9932140111923218
1340753611,14408,dajac,2023-09-28T23:43:06Z,nit: indentation should be 4 spaces.,0,0.9598513245582581
1340753971,14408,dajac,2023-09-28T23:44:05Z,should we move this method to the test context?,0,0.9939022064208984
1340754157,14408,dajac,2023-09-28T23:44:38Z,we could also apply my formatting suggestion here.,0,0.987064003944397
1340754965,14408,dajac,2023-09-28T23:46:50Z,"this block is really hard to parse. [code block] would it be better like this? otherwise, i would use a regular if statement.",-1,0.6501321792602539
1340756205,14408,dajac,2023-09-28T23:50:13Z,what does `invalidoffset` mean here?,0,0.9890417456626892
1340756359,14408,dajac,2023-09-28T23:50:43Z,ditto.,0,0.6705162525177002
1340757038,14408,dajac,2023-09-28T23:52:20Z,could we use `grouptype` instead? then you could use a switch based on the enum.,0,0.9922752976417542
1340757258,14408,dajac,2023-09-28T23:52:59Z,nit: could we put an empty line here?,0,0.9837681651115417
1340783686,14408,jeffkbkim,2023-09-29T01:11:23Z,"the current [a link] transitions groups to dead once a group is empty && offsets are gone. the current behavior for generic groups is the above, and i copied the same behavior for consumer groups. then once the group is dead, it will be considered for expiration in the next cycle.",0,0.9929763674736023
1340783926,14408,jeffkbkim,2023-09-29T01:12:09Z,should we at least log the number of groups that were deleted from the deletegroups request?,0,0.9947838187217712
1340788752,14408,jeffkbkim,2023-09-29T01:27:40Z,"this was my suggestion. your suggestion is much simpler, thanks!",1,0.9914801120758057
1341653044,14408,dajac,2023-09-29T17:49:06Z,"i am not sure to understand why we need to do this. couldn't we just delete the group when it is empty and offsets are gone instead of transitioning to dead and then deleting it? my understanding is that we use dead in the old code because we can't remove the group from the map before the change is committed to the log. during this time, the group is in the dead state. in our world, the group is remove from the map immediately and the change is reverted if the write fails.",0,0.6901389956474304
1341917129,14408,yangy0000,2023-09-30T06:16:35Z,error handling codes in lines 555-586 and 797-816 are very similar. an alternative implementation is create a util method: [code block] within deletegroups : [code block] within deleteoffsets: [code block],0,0.990060567855835
1341918630,14408,yangy0000,2023-09-30T06:34:17Z,nit: the else braces can be simplified to [code block],0,0.9899410605430603
1341919233,14408,yangy0000,2023-09-30T06:42:12Z,"no check on ""issubscribedtotopic"" in here? is this expected?",0,0.9921378493309021
1342599402,14408,dajac,2023-10-02T12:02:33Z,nit: given that there is only one test. i would rather move everything into that test.,0,0.9810190796852112
1342610382,14408,dajac,2023-10-02T12:13:55Z,"i am +1 for bringing the definition of `offsetsbypartition` within the `else` clause. however, we have to keep using `topic.partitions().foreach(` to iterate over the partitions. however, i don't like `if(offsetsbypartition ==null) {continue};`. how about using `offsetsbypartition != null`?",0,0.6324388384819031
1342611067,14408,dajac,2023-10-02T12:14:42Z,"no, we don't need it here because the group is completely removed in this case.",0,0.9835635423660278
1342627317,14408,dajac,2023-10-02T12:31:57Z,i wonder if we should rather log this within the shard in order to have it logged per shard (with the shard context). what do you think?,0,0.9836485385894775
1342628078,14408,dajac,2023-10-02T12:32:46Z,nit: how about `return allfutures.thenapply...`?,0,0.9911065697669983
1342632075,14408,dajac,2023-10-02T12:36:58Z,"nit: would it make sense to use? we don't really need `response` except here. ``` return new coordinatorresult<>( records, new offsetdeleteresponsedata().settopics(responsetopiccollection) );",0,0.9919614195823669
1342635373,14408,dajac,2023-10-02T12:40:21Z,nit: could we use `state() != empty`? this would be more robust.,0,0.9921930432319641
1342640395,14408,dajac,2023-10-02T12:45:34Z,i wonder if we should test all the exceptions that we re-map. i did something similar in `testconsumergroupheartbeatwithexception`. what do you think?,0,0.9716076850891113
1342641976,14408,dajac,2023-10-02T12:47:11Z,ditto about the error mapping verification.,0,0.6064154505729675
1342642294,14408,dajac,2023-10-02T12:47:29Z,can't we use `assertequals`?,0,0.9940775632858276
1342643914,14408,dajac,2023-10-02T12:48:59Z,it would be better to use the other way in order to remain consistent with the other tests. is this possible?,0,0.993685781955719
1342645279,14408,dajac,2023-10-02T12:50:17Z,nit: expectederror?,0,0.9368112683296204
1342647294,14408,dajac,2023-10-02T12:51:42Z,"nit: should we define an helper method in the context (e.g. hasoffset(groupid, topic, partition))? i would also bring `error == errors.none` back on the previous line because it fits there.",0,0.9942123293876648
1342851207,14408,yangy0000,2023-10-02T15:33:32Z,any chance deletealloffsets will get invoked before the group is completely removed?,0,0.9866327047348022
1343253093,14408,jeffkbkim,2023-10-02T23:24:28Z,was this addressed?,0,0.9900071620941162
1343255509,14408,jeffkbkim,2023-10-02T23:30:33Z,"also, we can remove the `v`",0,0.991919994354248
1343257434,14408,jeffkbkim,2023-10-02T23:34:56Z,nit: an,0,0.5793663859367371
1343258721,14408,jeffkbkim,2023-10-02T23:38:09Z,"""at this point, we have already validated the group id so we know that the group exists and that no exception will be thrown."" how's this?",0,0.9890658855438232
1343258959,14408,jeffkbkim,2023-10-02T23:38:35Z,"nit: can we change all usages of ""id"" to ""id""?",0,0.9940645098686218
1343259306,14408,jeffkbkim,2023-10-02T23:39:31Z,we can move these into the test as well,0,0.9919071197509766
1343259404,14408,jeffkbkim,2023-10-02T23:39:45Z,"we can remove the ""v""",0,0.9916050434112549
1343260319,14408,jeffkbkim,2023-10-02T23:41:35Z,what's the benefit of using final variables here?,0,0.99024498462677
1343262352,14408,jeffkbkim,2023-10-02T23:46:19Z,we can use [code block],0,0.9891355037689209
1343263220,14408,jeffkbkim,2023-10-02T23:48:18Z,nit: newline,0,0.9064050316810608
1343263632,14408,jeffkbkim,2023-10-02T23:49:12Z,?,0,0.9557723999023438
1343266197,14408,jeffkbkim,2023-10-02T23:54:55Z,can we use [code block] and remove the helper method?,0,0.9930103421211243
1343267277,14408,jeffkbkim,2023-10-02T23:57:24Z,can we assert true that the future is done?,0,0.9892143607139587
1343267559,14408,jeffkbkim,2023-10-02T23:57:57Z,can we use [code block] and remove the helper?,0,0.9926769733428955
1343269222,14408,jeffkbkim,2023-10-03T00:01:47Z,can we change all of the `dosomething...when...` to `when().dosomething`?,0,0.9936704635620117
1344182771,14408,dajac,2023-10-03T14:14:31Z,"i think that we should be careful with this. the change is not 100% equivalent to the previous implementation here because the error message is not set for all errors whereas it was only set of a sub set before. while i agree that we could do better, i would suggest to tackle this in a separate pr.",0,0.9610648155212402
1344185641,14408,dajac,2023-10-03T14:16:09Z,"nit: if we keep it, the method could be static and we usually don't prefix methods with `get`. `normalizeexception` maybe an alternative name.",0,0.9930928945541382
1344186369,14408,dajac,2023-10-03T14:16:40Z,why do we need an atomicinteger here?,0,0.9856821894645691
1344187568,14408,dajac,2023-10-03T14:17:30Z,nit: `... removed.`.,0,0.9561940431594849
1344188289,14408,dajac,2023-10-03T14:17:57Z,"i guess that they don't hurt, isn't it?",0,0.6987566351890564
1344189933,14408,dajac,2023-10-03T14:19:04Z,"if you look at the usage in `[a link]`, all offsets are removed before deleting the group.",0,0.9940722584724426
1344192203,14408,dajac,2023-10-03T14:20:23Z,i agree. i mentioned this a few times a well.,0,0.500810444355011
1344192583,14408,dajac,2023-10-03T14:20:34Z,ditto.,0,0.6705162525177002
1344192793,14408,dajac,2023-10-03T14:20:41Z,ditto.,0,0.6705162525177002
1344192915,14408,dajac,2023-10-03T14:20:45Z,ditto.,0,0.6705162525177002
1344193032,14408,dajac,2023-10-03T14:20:50Z,ditto.,0,0.6705162525177002
1344498860,14408,dongnuo123,2023-10-03T17:44:07Z,"if we use int, we'll get error `variable used in lambda expression should be final or effectively final`. lambda expressions do not allow any external variable operation within itself. i can add a small comment here.",0,0.9843873977661133
1344502310,14408,dongnuo123,2023-10-03T17:47:11Z,when(method).dosomething requires method to return a non-void value. i can add a comment here for explanation.,0,0.9858821630477905
1344523685,14408,dongnuo123,2023-10-03T18:06:47Z,rolled back,0,0.9343494176864624
1344524665,14408,dongnuo123,2023-10-03T18:07:42Z,comment added,0,0.9868177175521851
1344524782,14408,dongnuo123,2023-10-03T18:07:49Z,comment added,0,0.9868177175521851
1344524966,14408,dongnuo123,2023-10-03T18:07:59Z,comment added,0,0.9868177175521851
1344525094,14408,dongnuo123,2023-10-03T18:08:08Z,comment added,0,0.9868177175521851
1344554094,14408,dajac,2023-10-03T18:34:48Z,ack. i wonder if we should use `for (string groupid : groupids) ....` then. what do you think?,-1,0.9403648376464844
464705276,9100,hachikuji,2020-08-03T23:00:19Z,probably reasonable to handle it the same way other inter-broker rpcs are handled.,0,0.9928366541862488
464708303,9100,hachikuji,2020-08-03T23:10:04Z,"good question. might be fair to assume the controller is correct and use stale_broker_epoch. once kip-500 is all done, it would be totally fair since the controller will be guaranteed to have the latest state. the other question is what the broker should do if it sees stale_broker_epoch...",1,0.8368006944656372
464709341,9100,hachikuji,2020-08-03T23:13:24Z,"hmm.. this adds a delay of 2.5s to every isr change, which is a bit annoying. i guess the point is to allow batching? i think a better approach might be to send requests immediately on arrival, but set a limit on the maximum number of in-flight requests (maybe just 1) and let the changes accumulate when there is a request in-flight. then we can still get a big batching benefit when there are a large number of isr changes that need to be sent in a hurry.",-1,0.9792323708534241
464710258,9100,hachikuji,2020-08-03T23:16:19Z,hmm.. not sure it's worth doing these validations up-front. these checks could fail between the time that the event is enqueued and the time it is processed.,-1,0.5210572481155396
464716040,9100,mumrah,2020-08-03T23:35:25Z,that makes sense. i'll change that (this was pulled in from the previous isr notification code in replicamanager),0,0.9753183722496033
464717171,9100,mumrah,2020-08-03T23:39:05Z,"the main rationale for validating in the request handler is so we can return meaningful partition-level errors to the broker (fenced leader, not leader or follower, etc). although, i'm not sure the broker could do anything useful with these errors since it probably has stale metadata in these cases. the kip calls out four partition-level errors. do we actually need them?",0,0.9371827840805054
464718819,9100,hachikuji,2020-08-03T23:44:49Z,"to be clear, i'm not questioning the need for the validation, just the fact that it is done before enqueueing the event instead of when the event is processed.",0,0.979246199131012
465029352,9100,mumrah,2020-08-04T12:56:33Z,"ah, i see what you mean. initially, i was concerned about blocking for too long while waiting for a response, but it looks like there is precedent for this pattern for some requests (reassignment, leader election, controlled shutdown). i'll move this validation and the callback down into the event processor method",0,0.8722564578056335
465708837,9100,cmccabe,2020-08-05T13:00:48Z,"it seems like we need to set the `insyncreplicaids` here, since we don't do it in `shrinkisr`.",0,0.9949506521224976
465711962,9100,cmccabe,2020-08-05T13:06:08Z,this is also a concurrency bug since you can't access stuff like the controllercontext except from the controller thread itself (it would be multi-threaded access without a lock),0,0.9271029233932495
465712943,9100,cmccabe,2020-08-05T13:07:48Z,this also needs to call `networkclient#wake` in case we are blocking inside `networkclient#poll`,0,0.9933785200119019
465715770,9100,cmccabe,2020-08-05T13:12:19Z,"it would be good to find a better name for this. when i read ""alterisrchannelmanager"" i assumed it had its own separate channel, rather than using the controllerchannelmanager.",0,0.9869131445884705
465743922,9100,mumrah,2020-08-05T13:54:54Z,good to know about `controllercontext` :thumbs_up:,1,0.9816142320632935
465746162,9100,mumrah,2020-08-05T13:58:00Z,"it might be simpler just to use alterisrrequestdata and alterisrresponsedata throughout this code (rather than converting to `map[topicpartition, leaderandisr]` and `map[topicpartition, errors]`)",0,0.9944308400154114
465748120,9100,mumrah,2020-08-05T14:00:36Z,"i think we need to send leaderandisr for all the given partitions whether we updated the isr or not. in cases where we failed due, the leaders likely have stale metadata. this way we can proactively send them the latest state.",0,0.9844093918800354
465748504,9100,mumrah,2020-08-05T14:01:11Z,"yea, maybe just ""alterisrmanager""?",0,0.9922533631324768
465749546,9100,mumrah,2020-08-05T14:02:38Z,should probably get rid of this and change the method to [code block],0,0.9915709495544434
465750445,9100,mumrah,2020-08-05T14:03:55Z,remove this,0,0.9678736925125122
465750632,9100,mumrah,2020-08-05T14:04:10Z,newline,0,0.9010481834411621
465888182,9100,abbccdda,2020-08-05T17:28:23Z,nit: could move these operations to the `alterisrrequest` as helpers.,0,0.9940642714500427
469372344,9100,hachikuji,2020-08-12T16:03:52Z,"with kip-500, i imagine we could end up with other cases where we end up using optimistic concurrency control. does it make sense to make this error a little more generic? maybe `invalid_update_version` or something like that..",0,0.941006600856781
469373339,9100,hachikuji,2020-08-12T16:05:24Z,nit: maybe drop the parameters if they do not need to be documented,0,0.9729401469230652
469379488,9100,hachikuji,2020-08-12T16:14:57Z,nit: info feels a bit high for a message like this,-1,0.9193684458732605
469382729,9100,hachikuji,2020-08-12T16:20:13Z,we might need to be careful about performance here since this would get called on every follower fetch.,0,0.9766432046890259
469383572,9100,hachikuji,2020-08-12T16:21:34Z,"the usage is a bit surprising given the ""pending"" name. i wonder if it would be clearer if we used a type of `option[set[int]]` so that we could use `none` when there is no pending isr change. one more thing. it's worth double-checking the threading assumptions here. it looks like `updateassignmentandisr` is only called while holding the write side of `leaderisrupdatelock`. on the other hand, i don't see any lock held in `updatefollowerfetchstate`. it's worth stepping through that logic to make sure that we do not depend on `insyncreplicaids` and `pendinginsyncreplicaids` getting set atomically.",0,0.820719838142395
469385374,9100,hachikuji,2020-08-12T16:24:32Z,"i think the answer is no. the pending isr set is not guaranteed, so we cannot depend on it to enforce min.isr.",0,0.9800747632980347
469388095,9100,hachikuji,2020-08-12T16:29:06Z,"related to the other comment, but we need to be careful with the min.isr check below. i think it is correct to wait for `effectiveinsyncreplicaids` before acknowledging the produce request, but we should probably use the size of `insyncreplicaids` in the min.isr check since that is the only set we can guarantee.",0,0.9918190240859985
469399037,9100,hachikuji,2020-08-12T16:47:34Z,"there is a ""classic"" edge case in kafka which goes as follows: 1. leader is 1, isr is [1, 2, 3] 2. broker 3 begins controlled shutdown. while awaiting shutdown, it continues fetching. 3. controller bumps epoch and shrinks isr to [1, 2] and notifies replicas 4. before controlled shutdown completes and 3 stops fetching, the leader adds it back to the isr. this bug was fixed by kip-320 which added epoch validation to the fetch api. after shrinking the isr in step 3, the controller will send `leaderandisr` with the updated epoch to [1, 2] and `stopreplica` to [3]. so 3 will not send any fetches with the updated epoch, which means it's impossible for the leader to add 3 back after observing the shrink to [1, 2]. i just want to make sure whether above is correct and whether `alterisr` changes it in any way. i think the answer is no as long as isr expansion is _only_ done in response to a fetch request, but it's worth double-checking.",0,0.9914318323135376
469406972,9100,hachikuji,2020-08-12T17:00:32Z,i think it's worth adding a comment in the cases we rely on `effectiveinsyncreplicaids` to explain why.,0,0.9855879545211792
469412587,9100,hachikuji,2020-08-12T17:10:15Z,"i think the implementation here is actually different than what was in the model. consider the following case: 1) initial state: isr=[1, 2], pendingisr=[1, 2] 2) leader expands isr. isr=[1, 2], pendingisr=[1, 2, 3] 3) leader shrinks isr. isr=[1, 2], pendingisr=[1, 2] we don't know which of the updates in 2) or 3) will be accepted, but after 3), we will not assume that broker 3 could be in the isr, which could lead to a correctness violation if the update in 2) is accepted by the controller. in the model, we always assumed the maximal isr across _any_ potential update to protect from this edge case. maybe in the end it is simpler to not allow multiple in-flight updates.",0,0.987404465675354
469413205,9100,hachikuji,2020-08-12T17:11:21Z,nit: remove parenthesis for simpler getters like `code`. a few more of these,0,0.9747402667999268
469413455,9100,hachikuji,2020-08-12T17:11:47Z,missing license header in this file.,0,0.98390793800354
469414718,9100,hachikuji,2020-08-12T17:13:57Z,"nit: avoid loaded terminology like ""blackout"" (see [a link] do we actually need this or `isrchangepropagationinterval` below?",0,0.9862257242202759
469415543,9100,hachikuji,2020-08-12T17:15:14Z,we should use `time`,0,0.9942808151245117
469417613,9100,hachikuji,2020-08-12T17:18:30Z,probably need to reduce the log level here and below.,0,0.9868282079696655
469419452,9100,hachikuji,2020-08-12T17:21:31Z,"i think the basic approach here is to ignore successful responses and wait for the `leaderandisr` update. i am wondering how we should handle the case when the update failed. say for example that our update fails with the invalid_version error. inside `partition`, we will still have the pendingisr set. do we need to clear it? how about other errors?",0,0.9502013325691223
469421031,9100,hachikuji,2020-08-12T17:24:17Z,nit: more useful as a debug if we add request details to the message,0,0.9551455974578857
469421800,9100,hachikuji,2020-08-12T17:25:29Z,the broker epoch is not a constant. it gets reinitialized whenever the broker has to create a new session.,0,0.9619190096855164
469423834,9100,hachikuji,2020-08-12T17:28:57Z,"the term ""pending"" again is a little unclear. perhaps ""unsentisrupdates"" would make the usage clearer.",0,0.9709717035293579
469425898,9100,hachikuji,2020-08-12T17:32:22Z,removal from this set won't prevent `brokertocontrollerrequestthread` from retrying in-flight requests. i'm considering whether we should have a way to cancel requests that we are still awaiting.,0,0.9827636480331421
469460462,9100,mumrah,2020-08-12T18:33:11Z,"we don't, these were copied over from the replicamanager's isr propagation logic. i'll clean this up",0,0.9909130334854126
469467881,9100,mumrah,2020-08-12T18:46:27Z,"i'm currently looking at the effective isr to find new out of sync replicas. this can include new isr members which haven't made it into the ""true"" isr via leaderandisr yet (like broker=3 in your example). maybe we should only consider removing isr members iff they are in the true isr. iow changing from [code block] to [code block] also, i wonder if the batching that's happening in alterisrchannelmanager violates the model. it sends the request asynchronously with a small delay, so multiple isr changes can be batched into one alterisr.",0,0.9809737801551819
469516375,9100,abbccdda,2020-08-12T20:20:11Z,nit: new line,0,0.930640459060669
470053173,9100,mumrah,2020-08-13T15:51:39Z,"yea, lots of these will be lowered, was just doing this during development",0,0.7828693389892578
470063833,9100,mumrah,2020-08-13T16:08:16Z,"i don't think alterisr changes anything since we're now just sending the async isr update where we were previously directly updating zk. looking at the usages, `updatefollowerfetchstate` is only called following a read (`partition#readrecords`). these reads only happen on fetch requests and from the alter log dirs fetcher. i'm not sure about the alter log dirs flow, but as long as it sends the leader epoch, it should be safe.",0,0.980818510055542
470673412,9100,mumrah,2020-08-14T14:51:00Z,fixed this by adding getbrokerepoch to kafkazkclient,0,0.9947912693023682
470675300,9100,mumrah,2020-08-14T14:54:10Z,"with the latest changes to prevent multiple in-flight requests, i don't think this should happen for a given partition. even if it did, the retried in-flight request from brokertocontrollerrequestthread would fail on the controller with an old version. i'm wondering if we even need this clearpending behavior. since i changed the alterisr request to fire at most after 50ms, it's a narrow window between enqueueing an isr update and receiving a leaderandisr.",0,0.8794573545455933
470678123,9100,mumrah,2020-08-14T14:58:58Z,"since we are now only allowing one in-flight alterisr, i changed the semantics of pendinginsyncreplicaids to be the maximal ""effective"" isr. this way we don't need to compute it each time.",0,0.9905145168304443
473515635,9100,abbccdda,2020-08-20T01:36:09Z,"should we move the startup logic to `kafkaserver`? note the channel is shared between different modules, so it makes sense to start and close inside the server.",0,0.9948733448982239
474106591,9100,mumrah,2020-08-20T16:17:31Z,"i found a race during the system tests when a follower is shutting down. the controller handles the shut down before it handles an alterisr. if the proposed isr includes the now-offline replica, the controller refuses to update that isr change and returns an error for that partition. it then sends out the current leaderandisr. the problem is that the broker ignores this leaderandisr since it has the same leader epoch. this is easy enough to fix, we can bump the leader epoch in the controller (and zk) before sending it out. however, there's still the case of failing to update zk. i think we should probably treat this the same way as an offline replica. if we simply return an error in alterisr response and let the leader reset the pending isr state, the leader will just retry with stale metadata and the update will fail again. i think in all these error cases we must bump the leader epoch to force the leader to accept the new leaderandisr. thoughts?",0,0.9618529081344604
474930329,9100,mumrah,2020-08-21T20:15:17Z,it's a little tricky since leaderandisr isn't visible to alterisrrequest.,-1,0.8066027164459229
474934833,9100,mumrah,2020-08-21T20:20:56Z,"update: after some discussion and looking over failed system tests, we ended up with the following error handling: * replica_not_available and invalid_replica_assignment will clear the pending isr to let the leader retry. this covers a case where a leader tries to add a replica to the isr which is offline because it (the follower) just finished shutdown. * invalid_update_version will not clear the pending isr since the broker has stale metadata. * fenced_leader_epoch, not_leader_or_follower, unknown_topic_or_partition will _not_ clear the pending state and therefor will not retry. we presume here that the controller is correct and the leader has old metadata. by not clearing the pending isr, the leader will await leaderandisr before attempting any further isr changes * other unspecified errors: clear the pending state and let the leader retry. not sure what cases could cause other errors, but it is probably better to be in a retry loop than to be completely stuck",0,0.9769953489303589
474959176,9100,mumrah,2020-08-21T20:50:34Z,continued in [a link],0,0.9876856803894043
475625111,9100,mumrah,2020-08-24T13:53:27Z,this error message should be less specific,0,0.8873705863952637
475626573,9100,mumrah,2020-08-24T13:54:36Z,"need to revert this stuff, didn't mean to commit",-1,0.6238635778427124
475627290,9100,mumrah,2020-08-24T13:55:09Z,rename to alterisrmanager,0,0.9892128705978394
475629593,9100,mumrah,2020-08-24T13:57:02Z,expand on this comment to discuss the maximal isr,0,0.9830518960952759
475630695,9100,mumrah,2020-08-24T13:57:55Z,fix comment to refer to correct variable,0,0.9890718460083008
475632719,9100,mumrah,2020-08-24T13:59:34Z,newline,0,0.9010481834411621
477616910,9100,hachikuji,2020-08-26T22:08:38Z,we may as well add flexible version support for the request and response.,0,0.9893269538879395
477618083,9100,hachikuji,2020-08-26T22:11:44Z,"nit: i think `alterisrresponsetopics` should be singular (similarly for other arrays in both of these schemas). also, i wonder if it's reasonable to leave off the `alterisr` prefix. we could access it as `alterisrresponse.topicdata` or something like that.",0,0.9874544143676758
477618646,9100,hachikuji,2020-08-26T22:13:13Z,nit: unneeded newline,0,0.6719028949737549
477620548,9100,hachikuji,2020-08-26T22:18:02Z,do we need this message? it seems the one on line 537 below has more detail already. it would be useful to include the zkversion in the message on 537 as well.,0,0.982885479927063
477625772,9100,hachikuji,2020-08-26T22:32:18Z,"i am wondering if we can split this into two separate methods: - `effectiveisr`: takes into account any pending changes which may or may not have happened (i could probably also be convinced to call this `maximalisr`) - `confirmedisr`: the latest known value from zookeeper (or the controller) that makes the code easier to follow since we wouldn't have to interpret this flag. some high-level comments might be helpful as well. for example, it's useful to mention somewhere that the high watermark is always treated with respect to the effective isr.",0,0.9758398532867432
477629764,9100,hachikuji,2020-08-26T22:41:43Z,can we move this check earlier in the flow so that we can skip acquiring the write lock if there is an inflight alterisr? maybe it can be part of `needsexpandisr` and `needsshrinkisr` for example.,0,0.9956771731376648
477748433,9100,hachikuji,2020-08-27T00:16:03Z,"i have been thinking a little bit about the semantics of min.isr. basically i am wondering if should be treated as a guarantee on the state of the isr at the time the high watermark is reached (i.e. how many replicas are in the isr), or instead should it be a guarantee on the state of progress of replication (i.e. some number of replicas have reached a given offset)? we may not have ever formally decided this, but here we are taking a stance that it is the latter because we are using the effective (uncommitted) isr. one of the consequences of this view is that a leader may continue to accept appends satisfying min.isr even if the true isr never reaches min.isr. for example, imagine we have the following state: replicas: (1, 2, 3) isr: (1) leader: 1 suppose that replica 2 has caught up to the leader, but the leader is unable to expand the isr because the controller is unavailable or unreachable. with the logic here, we will nevertheless continue to satisfy acks=all requests with a min.isr of 2. i am not sure there is much choice about it to be honest. if instead we used only the ""confirmed"" isr, then we would have sort of an opposite problem. for example, consider this state: replicas: (1, 2, 3) isr: (1, 2) leader: 1 suppose the leader wants to remove 2 from the isr. the alterisr is received by the controller and the state is updated, but the controller fails to send the corresponding leaderandisr. then committing on the basis of the confirmed isr would lead to a similar problem. here is the current documentation for the config: [code block] even though it is named in terms of the isr, the documentation only discusses acks from other replicas, so it seems like the implementation here is consistent even if potentially surprising in some cases.",0,0.9687460064888
477785759,9100,hachikuji,2020-08-27T00:35:59Z,maybe trace would be better? this could get verbose while we have an inflight alterisr.,0,0.973280131816864
477786630,9100,hachikuji,2020-08-27T00:36:26Z,i still think we need a better name for `pendinginsyncreplicaids` since it is misleading in this case. maybe we could call it `overrideinsyncreplicaids` or something like that?,0,0.9558635950088501
477787350,9100,hachikuji,2020-08-27T00:36:50Z,nit: maybe `sendalterisrrequest`?,0,0.9943238496780396
477811336,9100,hachikuji,2020-08-27T00:49:30Z,"hmm.. i am not sure it is safe to reset `pendinginsyncreplicaids` in any case except `invalid_update_version`. for example, imagine the following sequence: 1. broker sends alterisr 2. controller writes new isr and crashes before sending response 3. broker hits session expiration 4. broker retries alterisr on new controller with old broker epoch 5. controller responds with stale_broker_epoch in this case, the isr was updated, but the broker is going to revert to the old state. i think the _only_ time we can reset `pendinginsyncreplicaids` is when we know the change could not have been applied.",0,0.7925713658332825
477817624,9100,hachikuji,2020-08-27T00:52:47Z,"the conversion logic is a tad annoying, but it makes the rest of the code nicer. i'm ok with it. that said, could we use scala conventions, e.g.: [code block]",1,0.6486378908157349
477832161,9100,hachikuji,2020-08-27T01:00:46Z,don't forget the todo!,0,0.8334967494010925
477876231,9100,hachikuji,2020-08-27T01:32:23Z,"should we try to make `alterisr` an idempotent operation? i think currently if we retry an update that was successfully applied, then we will see invalid_version. in general, i'm a bit concerned about the number of errors that are possible through this api and how the leader is supposed to handle them. i am thinking it might make our lives easier if we return some additional information in the response about what the current state really is. let's say that we always try to add the full state tuple to the response: (leaderid, epoch, isr, zkversion). then we can go through a simple process of reconciliation? - am i still the leader? - do i have the latest epoch? - has the zkversion been bumped? - did the isr change get applied? basically i'm looking for a reliable way to determine whether we should continue retrying the request and whether it is safe to clear the pending replica set. at the same time, i'm feeling a bit on-the-fence about relying exclusively on leaderandisr for state changes. if we need to return the current state in the response anyway to properly handle errors, then perhaps we may as well allow the state to be updated as well? this would actually be closer to the flow that we have today, which is the following: 1. leader changes state in zookeeper and updates current isr directly. 2. after some delay, it posts the isr update to isr_change_notifications. 3. controller picks up the notification and sends updatemetadata to all the brokers. notice that the controller does not send leaderandisr to the followers in this flow. what we could do is something more like the following: 1. leader sends alterisr to controller. 2. controller applies the change and returns the updated state. 3. leader receives the response and applies the state change. 4. after some delay, the controller sends updatemetadata to the brokers with the change. if we did this, then we wouldn't need to have the controller bump the epoch when handling alterisr. just as we do today, we can reserve epoch bumps for controller-initiated changes. then we might be able to simplify the error handling to the following: - if the epoch is the same and we are still the leader, then apply the update - if the epoch is higher, leave pendingisr set and do not bother retrying - otherwise just keep retrying what do you think?",0,0.9269669651985168
477889557,9100,hachikuji,2020-08-27T01:43:00Z,probably not a useful log message,0,0.7509921789169312
477892802,9100,hachikuji,2020-08-27T01:45:16Z,not sure about this. do we really want to put zk in the path to sending to the controller?,0,0.6273724436759949
477902972,9100,hachikuji,2020-08-27T01:52:41Z,this should be fixed,0,0.963074266910553
477904479,9100,hachikuji,2020-08-27T01:53:43Z,"as far as i can tell, we don't have any logic which tells us whether there is an inflight request. i am considering whether we should as a mechanism for batching/flow control. it might be simpler if we just allow one inflight request. while we are waiting for it to return, we can collect additional pending updates. in case we need to retry the request, we could coalesce the new updates into the request. note that currently `brokertocontrollerchannelmanagerimpl` currently sets max inflight requests to 1 anyway.",0,0.9898430705070496
477911757,9100,hachikuji,2020-08-27T01:59:01Z,"we seem to be losing some of the value of having a top-level error code here. as far as i can tell, the following top-level errors should be possible: 1. not_controller: should be retried (handled in `brokertocontrollerchannelmanagerimpl`) 2. stale_broker_epoch: should be retried (could we do that here?) 3. cluster_authorization_failed: probably should be fatal (can we handle that here?) seems like it might simplify the error handling if we can handle them at a corresponding granularity.",0,0.9912630319595337
477912314,9100,hachikuji,2020-08-27T01:59:22Z,nit: misaligned,-1,0.7095909714698792
477916564,9100,hachikuji,2020-08-27T02:02:29Z,any particular reason to change the order here?,0,0.9847550988197327
477918557,9100,hachikuji,2020-08-27T02:03:54Z,we should probably have a try/catch in here somewhere for the unhandled errors to make sure that the callback always gets applied.,0,0.9911646246910095
477920314,9100,hachikuji,2020-08-27T02:05:17Z,maybe debug is more suitable?,0,0.9844509363174438
477921396,9100,hachikuji,2020-08-27T02:06:04Z,could be debug perhaps?,0,0.9890585541725159
478067221,9100,mumrah,2020-08-27T03:55:53Z,"i think that sounds pretty reasonable. would we need any kind of timeout at this layer, or just rely on the underlying channel to provide timeouts?",0,0.9268448948860168
478069145,9100,mumrah,2020-08-27T03:57:52Z,"i wasn't too happy about this. is there another way to get the current broker epoch? as i understand it, the broker epoch can change during the lifecycle of a broker.",-1,0.9533302187919617
486521810,9100,mumrah,2020-09-10T17:43:05Z,"i think this sounds good, explict over implicit and all that. if we have two methods like this, should we then make `insyncreplicaids` a private member?",0,0.8403343558311462
486535166,9100,mumrah,2020-09-10T18:05:57Z,"yea, good idea. i'll leave the check here since we actually acquire and release the lock when checking if we should expand/shrink. it's possible that pendinginsyncreplicaids is cleared by a leaderandisr before we acquire the write lock to do the update",1,0.9407483339309692
486535868,9100,mumrah,2020-09-10T18:07:08Z,how about `uncommittedinsyncreplicaids`?,0,0.9937158226966858
486535964,9100,mumrah,2020-09-10T18:07:20Z,"nope, will revert",0,0.8576960563659668
489569400,9100,hachikuji,2020-09-16T16:29:34Z,"i know we've gone back and forth on including some of these fields. this is one i'm inclined to get rid of since we already include ""brokerid"" at the top level and `alterisr` can only be sent by leaders.",0,0.9737735390663147
489571330,9100,hachikuji,2020-09-16T16:32:40Z,nit: shall we call this `leaderid` in line with `brokerid` in the request?,0,0.9950975775718689
489572418,9100,hachikuji,2020-09-16T16:34:32Z,"can we revert this change? i think the trace logging is intended, if a bit odd.",-1,0.7025876045227051
489572745,9100,hachikuji,2020-09-16T16:35:06Z,we probably need another version since we bumped the fetch protocol version yesterday.,0,0.9890491962432861
489577394,9100,hachikuji,2020-09-16T16:42:48Z,"nit: we use ""maximal"" and ""effective"" interchangeably in this pr. maybe we can choose one term and use it consistently. i do sort of like ""maximal"" since it is more suggestive of the semantics.",0,0.9834676384925842
489579590,9100,hachikuji,2020-09-16T16:46:31Z,nit: maybe `hasinflightalterisr` so that it's clearer what the return value indicates?,0,0.99437016248703
489580384,9100,hachikuji,2020-09-16T16:47:54Z,nit: maybe we could rename `curinsyncreplicaids` to `cureffectiveisr`,0,0.9934203028678894
489582879,9100,hachikuji,2020-09-16T16:52:06Z,nit: probably need to reword mention of `leaderandisr` since the `alterisr` response is now used.,0,0.9948275685310364
489593301,9100,hachikuji,2020-09-16T17:09:49Z,nit: maybe we can check in-flight requests first (same in `needsexpandisr`). otherwise it's a little odd that `getoutofsyncreplicas` may be based on the maximal isr while we have an in-flight.,0,0.9626761674880981
489593650,9100,hachikuji,2020-09-16T17:10:29Z,nit: redundant comment,-1,0.8449842929840088
489594684,9100,hachikuji,2020-09-16T17:12:13Z,nit: you can take the topic partition out of this message since it is already included in `logident`. same on line 1262 below.,0,0.9926251769065857
489604587,9100,hachikuji,2020-09-16T17:29:38Z,"the problem is that it is a sort of worst-case isr and not the intended isr update itself. tough to come up with a good name to describe that. just for the sake of having an alternative, what if we used case classes to represent the current isr state and pending update? for example: [code block] then we can get rid of `effectiveisr`, `insyncreplicaids`, and `pendinginsyncreplicaids`.",0,0.8876732587814331
489606127,9100,hachikuji,2020-09-16T17:32:22Z,"nit: ""... doesn't know about this **topic** or partition""?",0,0.5726950764656067
489607165,9100,hachikuji,2020-09-16T17:34:25Z,"hmm... why do we reset `pendinginsyncreplicaids` if we are retrying? unless we are guaranteed that the update failed, then i think we need to continue assuming the worst-case isr. maybe we could just could call `enqueueisrupdate` again to explicitly retry?",0,0.9122439622879028
489608511,9100,hachikuji,2020-09-16T17:36:44Z,"nit: we don't need topic partition here, but it would be nice if we could include the intended update.",0,0.9163505434989929
489608740,9100,hachikuji,2020-09-16T17:37:10Z,"nit: as long as we're updating this, can we use `$` substitutions? also can we mention that this update came from `alterisr`?",0,0.9939517378807068
489609866,9100,hachikuji,2020-09-16T17:39:09Z,"maybe helpful if these messages indicate that this `leaderandisr` can from an `alterisr` response. also, it may be useful to include the current (stale) leader epoch.",0,0.9902698993682861
489610509,9100,hachikuji,2020-09-16T17:40:19Z,"nit: similarly, we can include current `zkversion`",0,0.9847255349159241
489612385,9100,hachikuji,2020-09-16T17:43:38Z,nit: maybe we could shorten this name to just `enqueue` since the fact that it is an isr update is already implied by the argument and the name of the trait itself.,0,0.9949285984039307
489614105,9100,hachikuji,2020-09-16T17:46:39Z,nit: usually we write this as `foreach { topic =>`. avoids the extra parenthesis.,0,0.9926806092262268
489614732,9100,hachikuji,2020-09-16T17:47:43Z,nit: maybe split this into two separate methods?,0,0.9640766382217407
489617709,9100,hachikuji,2020-09-16T17:52:57Z,the use of a queue is a tad odd here. we could use `listbuffer`? also nit: use type inference.,0,0.513989269733429
489619376,9100,hachikuji,2020-09-16T17:55:53Z,still not super keen on this propagation delay. at least it would be nice if we did not have to wakeup the thread every 50ms when there's nothing to do. this is potentially something we can save for a follow-up since coming up with a good solution might require some experimentation and analysis.,0,0.8049262166023254
489619767,9100,hachikuji,2020-09-16T17:56:37Z,nit: use type inference,0,0.9821456074714661
489621121,9100,hachikuji,2020-09-16T17:59:00Z,nit: can we include the broker epoch that was sent in this message?,0,0.9939538836479187
489621168,9100,hachikuji,2020-09-16T17:59:06Z,"hmm.. where does this exception get caught? since it is in the response handler, i guess that `networkclient` just eats it. perhaps we should just continue retrying so that the problem remains visible in the logs.",0,0.8960705995559692
489621815,9100,hachikuji,2020-09-16T18:00:08Z,nit: this message would be more useful if we include the response. perhaps it would be better to log each partition update separately?,0,0.991584300994873
489622001,9100,hachikuji,2020-09-16T18:00:29Z,nit: unneeded parenthesis,0,0.8937573432922363
489623549,9100,hachikuji,2020-09-16T18:03:18Z,maybe we could log a warning and let the partition remain in `unsentisrupdates` so that it is retried until we get a response?,0,0.9945557117462158
489623929,9100,hachikuji,2020-09-16T18:04:01Z,nit: may as well convert to `errors` since we do so below anyway,0,0.9931540489196777
489624854,9100,hachikuji,2020-09-16T18:05:34Z,i think authorization should probably be the first thing we do.,0,0.96893310546875
489625184,9100,hachikuji,2020-09-16T18:06:09Z,nit: remove these lines,0,0.9269639253616333
489625611,9100,hachikuji,2020-09-16T18:07:02Z,do we still need this change? i think we are trying to keep the current approach where the controller bumps the leader epoch for any controller-initiated change.,0,0.9863277673721313
489625836,9100,hachikuji,2020-09-16T18:07:25Z,i guess we don't need this anymore.,0,0.9382662773132324
489703810,9100,mumrah,2020-09-16T19:27:49Z,"i think this has been a long-standing bad assumption on my part in this pr. i've been (mis)treating `pendinginsyncreplicaids` as a mechanism for initiating a retry along with its other semantics. you're right though, explicitly re-sending the isr is definitely better.",-1,0.6348199844360352
489720971,9100,mumrah,2020-09-16T20:00:38Z,"yup, my mistake, shouldn't have been committed",-1,0.8427056670188904
489721316,9100,mumrah,2020-09-16T20:01:18Z,"""maximal"" works for me :thumbs_up:",1,0.9159517884254456
489730265,9100,mumrah,2020-09-16T20:19:09Z,"ah, missed one ;)",1,0.9645227789878845
489740479,9100,mumrah,2020-09-16T20:39:05Z,currently we impose a 2.5s delay for the old zk based isr propagation method. we could probably increase this 50ms up to a few hundred without any ill-effects. we still benefit from fact that we assume the maximal isr immediately. how about 200ms? longer term we can look into having a single thread invocation that sits in a while loop trying to consume from a linkedblockingqueue or maybe even a synchronousqueue. but agreed we should leave this for later.,0,0.9850947856903076
489744561,9100,mumrah,2020-09-16T20:47:19Z,how about we raise this to an error log with the exception?,0,0.9878766536712646
489745539,9100,mumrah,2020-09-16T20:49:17Z,should we drop it to trace in that case?,0,0.9916844367980957
489747101,9100,mumrah,2020-09-16T20:52:28Z,good idea. another case not covered is if partitions are included in the response but weren't sent out. these will be ignored as things currently stand -- maybe that's ok,1,0.7278799414634705
489753946,9100,mumrah,2020-09-16T21:05:59Z,this is actually a really good point. i filed a jira to fix this in other places in kafkaapis [a link],1,0.9831191897392273
489756083,9100,mumrah,2020-09-16T21:10:09Z,"no, we don't need this anymore. this was added so a leaderandisr could update the partition state without a leader epoch bump, but we don't have that flow anymore so we can revert this.",0,0.9903276562690735
490464756,9100,hachikuji,2020-09-17T18:20:10Z,nit: `hasinflight`?,0,0.9901500940322876
490465180,9100,hachikuji,2020-09-17T18:20:54Z,nit: it's surprising to have a side effect like this in a function like this. i think it would be better to include this logging at the caller when we are considering a specific change. that way we can also include in the log message information about the change that we were intending to make.,0,0.7459869980812073
490469252,9100,hachikuji,2020-09-17T18:28:13Z,another possibility is that the replica is pending removal in which case another `alterisr` will be needed. i think it might be more intuitive to make this check: [code block],0,0.9927412271499634
490488626,9100,hachikuji,2020-09-17T19:03:35Z,i think we can refactor this a little bit to avoid some duplication and inconsistency. we have the following logic above when updating follower state: [code block] this is a little inconsistent because here we are checking `isrstate.isr`. i'd suggest splitting this method into something like the following: [code block] then we can change the logic in `maybeexpandisr` to the following: [code block],0,0.9914531707763672
490492340,9100,hachikuji,2020-09-17T19:10:10Z,seems like we do not have a check for inflight alterisr after the write lock has been acquired.,0,0.9881879687309265
490492780,9100,hachikuji,2020-09-17T19:10:50Z,"this is related to my comment above for the isr expansion case, but it is a bit confusing to use maximal isr when the expectation is that we will not shrink as long as we have a pending update inflight. would it be better to check for inflights and document that this method will return an empty set as long as there is a pending alterisr request?",-1,0.535040020942688
490494777,9100,hachikuji,2020-09-17T19:14:38Z,it might be a little more intuitive to change the order here. something like this: [code block],0,0.9772022366523743
490494975,9100,hachikuji,2020-09-17T19:14:57Z,nit: can probably rework this as `exists` [code block],0,0.9909137487411499
490527627,9100,hachikuji,2020-09-17T20:00:06Z,"since `invalid_update_version` is one of the expected errors at this level, can we add a separate case for it? for unexpected errors, we might want to log at warn level.",0,0.9926645159721375
490528339,9100,hachikuji,2020-09-17T20:01:27Z,shall we include some details about the failed request?,0,0.9908191561698914
490528744,9100,hachikuji,2020-09-17T20:02:13Z,nit: rewrite with `$`,0,0.9887951612472534
490529253,9100,hachikuji,2020-09-17T20:03:19Z,i think `warn` might be too high here. we should expect to see some of these even if the cluster is working properly. how about debug?,0,0.9385947585105896
490530496,9100,hachikuji,2020-09-17T20:05:35Z,nit: can we avoid using `_1` and `_2`? it's a lot easier to follow if they are named.,0,0.9850334525108337
490531814,9100,hachikuji,2020-09-17T20:08:12Z,nit: use type inference. it's conventional to write this as [code block],0,0.9912903308868408
490532481,9100,hachikuji,2020-09-17T20:09:31Z,nit: i think we can get rid of this. the logging in `controllerchannelmanager.sendupdatemetadatarequests` is probably good enough.,0,0.9537333846092224
490534060,9100,hachikuji,2020-09-17T20:12:36Z,"nit: it's subjective, so feel free to ignore, but i find this a little easier to read if we handle the error cases first. so.. [code block] basically we're discarding the error cases so that the successful path continues flowing downward and we're avoiding extra nesting. like i said, it's subjective.",-1,0.7144784331321716
490534274,9100,hachikuji,2020-09-17T20:13:00Z,nit: unneeded newline,0,0.6719028949737549
490534954,9100,hachikuji,2020-09-17T20:14:26Z,nit: not sure it makes sense to include this change any longer,0,0.8493906855583191
490536839,9100,hachikuji,2020-09-17T20:17:56Z,"i wonder if we should be exposing this. would it be enough to have a `def insyncreplicaids = isrstate.isr`? one thing we need to be a little careful of is the fact that we now have a volatile variable with multiple fields. so if you try to access two fields through the `isrstate` reference, you could see inconsistent data.",0,0.9648334980010986
490539522,9100,hachikuji,2020-09-17T20:23:10Z,need to address the todos in this class.,0,0.9900625348091125
490540789,9100,hachikuji,2020-09-17T20:25:23Z,"i may have missed it, but do we have tests which verify error handling? i see tests which verify requests get sent, but at a quick glance i didn't see tests of responses.",0,0.9675383567810059
490541557,9100,hachikuji,2020-09-17T20:26:45Z,nit: sort of conventional to use a name like `mockalterisrmanager`,0,0.9837806224822998
490542749,9100,mumrah,2020-09-17T20:29:02Z,yea i was thinking we should move the isr to a separate public accessor. i'll change this,0,0.9452652335166931
490561028,9100,mumrah,2020-09-17T21:04:05Z,"makes sense, that will also satisfy your other comment about not checking for inflight requests within the write lock",0,0.9749703407287598
490562630,9100,mumrah,2020-09-17T21:07:24Z,"also, yes it's confusing to refer to `maximalisr` here even though it should always equal the committed isr at this point (assuming we check for inflight first).",0,0.8389400839805603
490594335,9100,mumrah,2020-09-17T22:21:46Z,yea checking the maximal set isn't needed anymore since adding the sealed trait. i'll just update this to simply call `maybeexpandisr` which will do the check you propose here,0,0.9875516295433044
494480847,9100,hachikuji,2020-09-24T17:13:35Z,"consider the following scenario: 1) broker sends alterisr 2) the update succeeds but the response is lost 3) broker retries alterisr currently the leader will be stuck after 3) because it has no way to get the latest leaderandisr state if the first attempt fails. to handle this, i think we need to add an idempotence check here. after we have validated the leader epoch, if the intended state matches the current state, then we can just return the current state.",0,0.9872339963912964
494483808,9100,hachikuji,2020-09-24T17:18:40Z,"it might make more sense to handle this case similarly to fenced_leader_epoch. retrying won't help since we know our version will be rejected come to think of it, this would be kind of a strange error to hit in the current implementation which only allows one request inflight at a time. for controller-initiated changes, we'd expect to hit fenced_leader_epoch. anyway, i think it's still worth keeping the error.",0,0.9244487881660461
494486578,9100,hachikuji,2020-09-24T17:23:03Z,"is there any way that we could end up retrying after the pending isr state had already been reset? i know we have `alterisrmanager.clearpending`, but that only removes the partition from the unsent queue. how do we handle inflight `alterisr` requests after the state has been reset. seems like it might be worth adding a check here to validate whether the request is still needed.",0,0.9909496903419495
494520245,9100,mumrah,2020-09-24T18:21:33Z,"i was trying to think some kind of race with a zombie leader trying to update the isr, however this would get fenced by the leader epoch. this should be pretty easy to add",0,0.9151203632354736
494523773,9100,mumrah,2020-09-24T18:26:13Z,"true, we could see a new isr from controller initiated changes via leaderandisr while our request is in-flight. we have a check for this on successful responses, but we should also check here. since our request failed, we don't have a leaderepoch to check against so i think the best we can do is see if `isrstate` is still pending before re-sending the request",0,0.9882756471633911
494660084,9100,hachikuji,2020-09-24T23:13:45Z,"nit (for follow-up): fix grammar ""since due""",0,0.9818181395530701
494660983,9100,hachikuji,2020-09-24T23:16:38Z,"nit: conventionally we prefer ""retriable""",0,0.9854661226272583
494661344,9100,hachikuji,2020-09-24T23:17:43Z,it might be worth mentioning that this could happen in the case of a retry after a successful update.,0,0.9906518459320068
494661583,9100,hachikuji,2020-09-24T23:18:19Z,nit: leave off parenthesis after `exception`,0,0.9917894601821899
99288458,2472,norwood,2017-02-03T07:44:06Z,should probably make this ` `,0,0.9895215034484863
99288467,2472,norwood,2017-02-03T07:44:07Z,if you are going to do this check then why not make `newtopics` a `set`? if we'd rather do this check here then we can use `collection` instead,0,0.994788646697998
99288478,2472,norwood,2017-02-03T07:44:16Z,should include a `listtopics` that takes a `collection ` of topics to query,0,0.9948731064796448
99288485,2472,norwood,2017-02-03T07:44:20Z,is it possible that this masks errors in `partitionmetadata`? e.g. if we have a topic level error and an error on a specific partition.,0,0.9902974963188171
99406097,2472,cmccabe,2017-02-03T19:30:13Z,agree,0,0.9753760099411011
99406308,2472,cmccabe,2017-02-03T19:31:20Z,i didn't make it a set because i didn't want to have to worry about hashcode and equals. i think you're right; it should just be a collection.,0,0.9429686069488525
99406744,2472,cmccabe,2017-02-03T19:33:33Z,"hmm, i'm not sure i follow. all the errors in the rpc response are faithfully reproduced in the return values... what else can we do to improve it?",-1,0.8962220549583435
99407725,2472,norwood,2017-02-03T19:38:50Z,"you have a `continue` in this block. my question is related to if you end up with a `topicmetadata` that looks like: [code block] also, in writing this up, i realize that in line 487 you are checking `topic.error()` instead of `partition.error()`",0,0.9799779057502747
99410119,2472,cmccabe,2017-02-03T19:51:06Z,i added a function which allows you to get information for one topic,0,0.9593271613121033
99687358,2472,norwood,2017-02-06T21:23:13Z,"i still really think that we should have a `listtopics(set topics, enumset flags)`, e.g. one thing i've had to do is write code that is basically waits until i have seen our topics replicated/etc. it would be nice to not have to get all if i dont have to, and also nice to batch for me :) sample code [code block]",1,0.9941768646240234
112326031,2472,ijuma,2017-04-19T22:10:04Z,"this package doesn't currently contain public api classes. if we want `clients` to be a public package, we need to move all the classes that are there at the moment to `clients.internals`.",0,0.9950129389762878
112326124,2472,ijuma,2017-04-19T22:10:41Z,"as per our conversation today, maybe we should say that this will implement `completionstage` once we require java 8. also, i think we should just expose an interface to users and have the implementation under an internal package. we can then only expose methods that users should use (`complete` and `completeexceptionally` should never be used by users, for example).",0,0.9929973483085632
112326754,2472,ijuma,2017-04-19T22:14:38Z,we need to complete this.,0,0.9842331409454346
112326863,2472,ijuma,2017-04-19T22:15:23Z,is it intentional that we mention `kafkaadminclient` here? the idea behind a `create` method like this is to avoid mentioning an implementation.,0,0.9909572601318359
112327164,2472,ijuma,2017-04-19T22:17:26Z,we should flesh out the documentation for these methods. important details about what success means should be mentioned (in the same way we did for `deletetopics`).,0,0.9908595681190491
112327310,2472,ijuma,2017-04-19T22:18:30Z,i think this is unused.,0,0.740286648273468
112327572,2472,ijuma,2017-04-19T22:20:22Z,this default doesn't seem to make sense for the `adminclient`.,0,0.9769150018692017
112327616,2472,ijuma,2017-04-19T22:20:39Z,i wonder if we should be sharing these values in `commonclientconfigs`.,0,0.9799697995185852
112327840,2472,ijuma,2017-04-19T22:22:20Z,seems like we sometimes have a constant field for `doc` and sometimes we don't. we should choose a pattern and stick to it.,0,0.9855002760887146
112328054,2472,ijuma,2017-04-19T22:23:49Z,i wonder if we should be using such magic values for public classes. it that using `null` to indicate an unset value is a bit safer and there's some indication by the type system.,0,0.9497191309928894
112328352,2472,ijuma,2017-04-19T22:24:42Z,we can use a rule to avoid repeating this in every test? same for other tests.,0,0.9931384921073914
112328439,2472,ijuma,2017-04-19T22:25:29Z,we typically use `*integrationtest` to indicate integration tests and simply `*test` for unit tests.,0,0.9922245740890503
112328490,2472,ijuma,2017-04-19T22:25:50Z,nit: this method seems unnecessary.,-1,0.7930181622505188
112328573,2472,ijuma,2017-04-19T22:26:23Z,we can use `testutils.waituntiltrue` to simplify this a little?,0,0.9922366738319397
112328632,2472,ijuma,2017-04-19T22:26:50Z,this is not a junit assert method.,0,0.9881584048271179
112328873,2472,ijuma,2017-04-19T22:28:16Z,i was thinking we should put this class in an `internals` package.,0,0.9713135957717896
112329026,2472,ijuma,2017-04-19T22:29:20Z,this block formatting is a bit weird and we don't usually use it in kafka.,-1,0.9701343178749084
112329873,2472,ijuma,2017-04-19T22:35:14Z,we close the selector in `networkclient` and `channelbuilder` in the `selector`. do we really need to close them separately?,0,0.9950433969497681
112336265,2472,cmccabe,2017-04-19T23:22:51Z,"yeah, implementing `completionstage` is probably a good idea, once we have jdk8 support. i don't see what's so bad about users calling `complete` or `completeexceptionally`. it just means that if the `kafkaadminclient` attempts to call those methods, the future will already be completed and it will have no effect. that seems pretty harmless?",0,0.8214675188064575
112336354,2472,cmccabe,2017-04-19T23:23:32Z,"oops, let me replace that with something descriptive.",-1,0.8938531279563904
112336940,2472,cmccabe,2017-04-19T23:28:12Z,"ok, i will remove the reference to `kafkaadminclient`.",0,0.9877879023551941
112337328,2472,cmccabe,2017-04-19T23:31:36Z,it's used by the metadata object. although the rate-limiting is not implemented by the adminclient for normal requests yet.,0,0.9936757683753967
112337741,2472,cmccabe,2017-04-19T23:35:00Z,"ok. i suppose i'll just have the constant, then, even if it just maps back to `commonclientconfigs`.",0,0.9864814281463623
112338241,2472,ijuma,2017-04-19T23:38:55Z,those methods are racy and that's why they are not present in completionstage or scala futures. is there a use case where it's useful for users to call these methods? the scenario you outlined does not seem harmless since it seems like a clear user error to cause the adminclient values to be ignored.,0,0.9310615062713623
112338335,2472,cmccabe,2017-04-19T23:39:46Z,"i agree that the text doesn't make sense, since we don't care about `max.poll.ms` here. i'll set 2 minutes (a high default is good here to avoid test failures and so forth.)",0,0.9629296660423279
112338407,2472,ijuma,2017-04-19T23:40:18Z,i'm referring to the doc field...,0,0.9688591361045837
112338643,2472,cmccabe,2017-04-19T23:41:58Z,"i'm not sure there's a huge amount of utility in sharing this particular config value with the producer and consumer-- it is a different application, after all. we should probably shorten the idle time a bit",0,0.6731795072555542
112339193,2472,cmccabe,2017-04-19T23:47:10Z,fair enough. i'll change it to use integer.,0,0.7224023342132568
112340310,2472,cmccabe,2017-04-19T23:57:41Z,"that seems like a lot of churn. does it make sense to do it in a separate jira, either beforehand or after this one?",-1,0.7181636691093445
112340400,2472,cmccabe,2017-04-19T23:58:33Z,"hmm, you mean the javadoc indentation?",0,0.9819822311401367
112340956,2472,cmccabe,2017-04-20T00:03:32Z,"i didn't realize that networkclient closed the selector... but i looked at the code again, and indeed it does. so we don't need to worry about that in `kafkaadminclient#close`. however, we do need to handle the case where the various constructors throw exceptions (pretty much all of them can.) for example, the selector constructor could fail and leave our channelbuilder dangling, and etc.",0,0.9693610072135925
112358759,2472,cmccabe,2017-04-20T03:26:35Z,i removed the tracking of the selector in kafkaadminclient. i kept the close in the factory function so that error handling is bulletproof...,0,0.9822816848754883
112358902,2472,cmccabe,2017-04-20T03:28:22Z,"hmm, retry_backoff_ms_doc is used later down... unless i'm looking at the wrong thing...",0,0.8477683067321777
112359050,2472,cmccabe,2017-04-20T03:30:11Z,"so, the unfortunate thing about moving this into a separate namespace is that it means a bunch of other methods need to be public. the api surface and potential for api breaks increases a lot because stuff like constructors for all the public helper classes kafkaadminclient uses needs to be public. java doesn't yet have any concept of package-private like scala does. i wonder if it might be better to just put an annotation or comment saying that kafkaadminclient is public on the class.",-1,0.7394824624061584
112362257,2472,cmccabe,2017-04-20T04:10:56Z,"one use-case i can think of is cancelling a future. in `completablefuture` this is essentially equivalent to a call to `completablefuture#completeexceptionally(new cancellationexception(...))` cancellation isn't an optional operation for us since it's part of java's original `java.util.concurrent.future` api, which we need to implement. i agree that it's a bit nicer conceptually to separate the ""listen for stuff happening"" api from the ""signal that stuff has happened"" api. it makes sense that scala did this with `scala.concurrent.future`. java's `completablefuture` muddies the waters a bit by combining them into one concrete class. i don't know if this is something that is really likely to trip users up, though...",0,0.8553444147109985
112444553,2472,ijuma,2017-04-20T12:54:01Z,"yes, we should do the move separately if we think making `clients` public is the way forward (instead of having a separate package for shared classes). this class doesn't seem specific to `clients` though so maybe we should move it to `common`?",0,0.9946300983428955
112444774,2472,ijuma,2017-04-20T12:55:05Z,"`cancel` is exposed via the `future` interface, so it doesn't seem like we need to expose `completeexceptionally` even if we use it internally for that?",0,0.9936914443969727
112445364,2472,ijuma,2017-04-20T12:57:48Z,i wonder if there's a better name for this than `kafkafuture`. can't think of anything that's not already taken. but maybe you have some ideas. :),1,0.9932655096054077
112445599,2472,ijuma,2017-04-20T12:59:03Z,we should probably make these interfaces and move them to top level in their own package. maybe `clients.function` or `common.function` (java uses `java.util.functions`).,0,0.9954178333282471
112446037,2472,ijuma,2017-04-20T13:01:08Z,"nit: make this final. also, it seems like not all tests have been updated to use rule.",0,0.9270297884941101
112446276,2472,ijuma,2017-04-20T13:02:18Z,"if we want `vals` to always have two values, then we should just make the method take two parameters?",0,0.9940955638885498
112446649,2472,ijuma,2017-04-20T13:04:07Z,"hmm, not sure about this. can we not avoid using reflection for this?",-1,0.7673093676567078
112447470,2472,ijuma,2017-04-20T13:07:59Z,"i think that was changed in a subsequent commit. before the define was doing `commonclientconfigs.retry_backoff_ms_doc`. on that point, it makes it harder to review if history is rewritten (i.e. additional changes are squashed into the existing commit). i have no way to tell what changed. :) can you please just add separate commits instead?",1,0.9764007925987244
112449184,2472,ijuma,2017-04-20T13:15:17Z,yes. there is huge amounts of whitespace. i suspect it's that way because there's an attempt at having alignment across all methods. but the value of that doesn't seem worth it.,-1,0.7044278979301453
112449330,2472,ijuma,2017-04-20T13:15:50Z,nit: remove `get` from this and other similar methods.,0,0.9881938695907593
112449528,2472,ijuma,2017-04-20T13:16:44Z,"why not use `utils.closequietly`? we can change the signature to take an `autocloseable` instead of `closeable`, if that's the issue.",0,0.994387686252594
112449930,2472,ijuma,2017-04-20T13:18:35Z,"hmm, we should probably have a config for metric reporters and add the jmxreporter by default like other clients.",0,0.9867010712623596
112450736,2472,ijuma,2017-04-20T13:22:13Z,should this be `admin-client`? or is the idea that the prefix should be whatever comes before the first `-`?,0,0.9950975775718689
112451618,2472,ijuma,2017-04-20T13:24:26Z,we should probably use `kafkathread` here. naming convention should be consistent with other client threads. for the producer we do: [code block],0,0.9929956793785095
112452024,2472,ijuma,2017-04-20T13:26:06Z,"generally, it's good to have consistent terminology to avoid confusion. the kafka code typically just says `requests` instead of `rpcs`.",0,0.9481337666511536
112453789,2472,ijuma,2017-04-20T13:33:24Z,"starting a new comment thread about the closing we do here since github is not allowing me to add a comment to the existing one. since this is an issue for all clients, maybe we should ensure that the constructors close things in case of exceptions in the constructor?",0,0.9853487610816956
112491693,2472,cmccabe,2017-04-20T15:57:23Z,"yeah, i'll just add separate commits",0,0.9762016534805298
112514535,2472,cmccabe,2017-04-20T17:36:00Z,i moved it to `org.apache.kafka.common`.,0,0.9924001693725586
112514652,2472,cmccabe,2017-04-20T17:36:22Z,"ok, i have split them. we'll see how this looks.",0,0.9341074228286743
112516162,2472,cmccabe,2017-04-20T17:41:01Z,"hmm, i'm not sure if there's anything better. i think `kafkafuture` is short and clearly expresses the concept that it's our `future` class.",0,0.6913121938705444
112516461,2472,cmccabe,2017-04-20T17:42:30Z,"well, they are abstract classes so that we can add more methods without breaking compatibility in java 7. remember that user code has to implement these. as to making them top-level... i'm not sure. they are stopgap classes until we can use the real classes from java 8...",0,0.8543902635574341
112517345,2472,cmccabe,2017-04-20T17:46:35Z,"it's not that it always has two parameters, it is that it always has an even number of parameters. it's used to create a map from key1, value1, key2, value2, key3, value3, ...",0,0.9917005896568298
112520218,2472,cmccabe,2017-04-20T17:58:35Z,"i don't feel strongly about it either way. it gets used in selector.java to build the metric group name as follows: `string metricgrpname = metricgrpprefix + ""-metrics"";` i'm not aware of any convention that says we can't have a hyphen here, so i guess i'll put it in...",0,0.5573334693908691
112523477,2472,cmccabe,2017-04-20T18:12:15Z,"ok, i'll reduce the indentation where i can.",0,0.9771325588226318
112527847,2472,cmccabe,2017-04-20T18:29:54Z,"the constructor is private and can't be called from outside this class. even the create methods are package-private and only used by the public interface in adminclient and by unit tests. putting a lot of logic in the constructor doesn't work very well because the logic needs to be different for the unit tests (which don't use networkclient, selector, or channelbuilder, for example)",0,0.9871758818626404
112655250,2472,ijuma,2017-04-21T10:02:07Z,seems better to update the `import-control.xml` file.,0,0.9929105639457703
112972103,2472,ijuma,2017-04-24T15:07:55Z,"will we eventually retry the request, return an error to the user or something else?",0,0.9886580109596252
113934868,2472,ijuma,2017-04-28T13:52:13Z,we should add a class comment stating that this tests the internal scala adminclient that will be replaced by the java one eventually.,0,0.99365234375
113935275,2472,ijuma,2017-04-28T13:53:58Z,this should probably use `messagewithfallback`.,0,0.9927033185958862
113943073,2472,ijuma,2017-04-28T14:29:05Z,nit: `public` not needed.,0,0.9881823658943176
113943764,2472,ijuma,2017-04-28T14:31:56Z,"hmm, should we not just throw an error here? something would have to be very wrong for this to happen.",0,0.5674558281898499
113944479,2472,ijuma,2017-04-28T14:35:12Z,this seems more informative than what's in the abstract class.,0,0.9664969444274902
113944854,2472,ijuma,2017-04-28T14:36:56Z,nit: `!isempty` instead of `length() > 0`.,0,0.9911485910415649
113945142,2472,ijuma,2017-04-28T14:38:14Z,this comment doesn't seem accurate.,-1,0.5358743667602539
113948024,2472,ijuma,2017-04-28T14:49:27Z,`commonclientconfigs.metrics_num_samples_doc` should just be `metrics_num_samples_doc`.,0,0.9953324198722839
113948175,2472,ijuma,2017-04-28T14:50:05Z,we should either do this for all of the configs or none.,0,0.9900818467140198
113948212,2472,ijuma,2017-04-28T14:50:15Z,the doc configs should be private.,0,0.9877382516860962
113948629,2472,ijuma,2017-04-28T14:52:01Z,seems like we're missing `metrics_recording_level_config`.,0,0.9849513173103333
113950116,2472,ijuma,2017-04-28T14:58:27Z,the consumer default is 64k while the producer default is 32k. was it intentional that you picked the same default as the producer?,0,0.9894698858261108
113950557,2472,ijuma,2017-04-28T15:00:27Z,this comment needs to be updated since you reduced the max_idle value to 5 minutes.,0,0.9909752011299133
113965338,2472,ijuma,2017-04-28T16:08:22Z,do we need something like the producer's `max_request_size_config` or are we ok to just rely on the broker if someone creates a batch that is too large somehow?,0,0.9923033714294434
113967006,2472,ijuma,2017-04-28T16:16:37Z,nit: maybe this should simply be `testclose()`?,0,0.9896647334098816
113967166,2472,ijuma,2017-04-28T16:17:33Z,seems like we always create an adminclient and close it at the end. maybe we can do that in `setup` and `teardown`? that way we don't leak resources if the test fails.,0,0.9944720268249512
113967578,2472,ijuma,2017-04-28T16:19:43Z,"it would be good to run these tests with security enabled. maybe a variant with sasl_ssl would do the job. it's reasonably straightforward, see `saslsslconsumertest`.",0,0.9784987568855286
113970289,2472,ijuma,2017-04-28T16:34:24Z,"oh, the result type of `createtopic` and `createtopics` is the same? that makes the non batch method less useful, no? may as well let the user use `collections.singleton` (with a static import)`.",0,0.9917512536048889
114015243,2472,cmccabe,2017-04-28T20:39:23Z,"since `kafkafuture#completedfuture` returns a completed future, we need access to the `kafkafutureimpl#complete` method. normally, `org.apache.kafka.common.kafkafuture` accessing `org.apache.kafka.common.internal.kafkafuture` would be blocked. this exception allows it to be called.",0,0.9951565265655518
114015511,2472,cmccabe,2017-04-28T20:41:00Z,"hmm. i was following the example of `producer.java`, whose javadoc has a link to `kafkaproducer.java`. i will add a little more javadoc to the `adminclient.java` class, though.",0,0.9782909154891968
114016199,2472,cmccabe,2017-04-28T20:45:37Z,"we don't know what request the response corresponds to, because its correlation id is invalid. of course, requests that don't receive a response will time out after enough time.",0,0.8015069961547852
114016438,2472,cmccabe,2017-04-28T20:47:06Z,"it's kind of awkward because other futures might have been completed successfully at this point. assuming that there is a bug where the server is responding with an incorrect topic name, this will be caught by means of the sanity check at the bottom that fails futures which haven't been completed by the response.",-1,0.9447190165519714
114022797,2472,cmccabe,2017-04-28T21:26:19Z,"i didn't think about it that much. i suppose 64k might be a better default, though, since some messages have large responses (larger than those the producer normally gets, at least).",0,0.9217255711555481
114023074,2472,cmccabe,2017-04-28T21:28:06Z,i don't think that we need a config like that here. the size of messages should come naturally out of the batch size which the client chooses. the rpc system will catch it if it gets too big (although there are probably other performance problems when admin requests get that big).,0,0.9674291610717773
114024595,2472,cmccabe,2017-04-28T21:38:18Z,good idea. i will add a close to an cleanup function.,1,0.9786540865898132
114024764,2472,cmccabe,2017-04-28T21:39:29Z,let's revisit this later once we have more experience with use-cases,0,0.9897196292877197
114024818,2472,cmccabe,2017-04-28T21:39:54Z,i updated this to 64k.,0,0.9882291555404663
114025089,2472,cmccabe,2017-04-28T21:41:54Z,good idea. i added some javadoc here and also on the scala adminclient with that info,1,0.9805480241775513
114025911,2472,cmccabe,2017-04-28T21:47:28Z,"hmm, good catch. i think it makes more sense to add the fallback logic into `errors#exception`, though. if null is passed to that method, it should return an exception with the default message for that error code.",1,0.6203774213790894
114026050,2472,cmccabe,2017-04-28T21:48:31Z,"note: i did add an entry to the `import-control.xml` for the `org.apache.kafka.clients.admin` namespace, which was previously missing. that entry is useful for allowing imports between classes in the same package. but it doesn't affect this issue in `org.apache.kafka.common`.",0,0.9953415393829346
114029206,2472,ijuma,2017-04-28T22:13:01Z,"when is later though, the feature freeze is pretty soon. as you know, in api design, adding methods is easy, removing them is hard. our experience so far in the consumer is that the batch version is enough so it seems to make sense to start that way. also, are we adding the unstable annotation to this class?",0,0.9730573892593384
114029207,2472,ijuma,2017-04-28T22:13:02Z,"when is later though, the feature freeze is pretty soon. as you know, in api design, adding methods is easy, removing them is hard. our experience so far in the consumer is that the batch version is enough so it seems to make sense to start that way. also, are we adding the unstable annotation to this class?",0,0.9730573892593384
114037965,2472,cmccabe,2017-04-28T23:48:49Z,"i suppose it is easier to add new methods than to remove them. i will remove the singular methods for now, and add the \ annotation to the api classes.",0,0.9834098815917969
114044708,2472,ijuma,2017-04-29T03:06:43Z,"we should just allow `common` to access `common.internals`, there's no good reason not to allow that. it's a simple addition: in general, `import-control.xml` is the right place to make these changes, i don't think we should be using suppressions for this.",0,0.9880123138427734
114044716,2472,ijuma,2017-04-29T03:08:18Z,"`producer` and `consumer` are a bit weird because the implementation classes are what people typically use (due to the constructor). for the adminclient, the abstract class is what people will be exposed to most probably.",-1,0.7656067609786987
114044732,2472,ijuma,2017-04-29T03:09:21Z,i would have thought that we would fail all the requests for that connection.,0,0.6882745027542114
387427500,8218,mjsax,2020-03-04T03:11:27Z,"this is not really relevant for this pr, but we need to add it for kip-447 eventually, thus i just include it in this pr.",0,0.9929706454277039
387427638,8218,mjsax,2020-03-04T03:12:04Z,we moved this to `taskmanager`,0,0.9931561350822449
387427823,8218,mjsax,2020-03-04T03:12:59Z,"on `suspend()` and `preparecommit()` we don't commit yet, but return the offsets that need to be committed",0,0.9926896691322327
387427911,8218,mjsax,2020-03-04T03:13:24Z,we don't commit and thus don't throw any longer,0,0.9412795305252075
387428416,8218,mjsax,2020-03-04T03:15:41Z,"frankly, not sure if this is correct any longer. what do we want to record with this sensor exactly? flushing can be expensive and we might want to record it as part of committing -- but i am not sure.",-1,0.7573788166046143
387428786,8218,mjsax,2020-03-04T03:17:11Z,"i am not happy with this rewrite (but as i know that john did some changes in this class in another pr, i just did this hack her for now -- needs some cleanup after a rebase)",-1,0.8947745561599731
387429067,8218,mjsax,2020-03-04T03:18:27Z,"we could also do a second loop over all tasks, _after_ calling `commit(..)` below -- not sure if this is ok as-is?",0,0.9896897077560425
387430556,8218,mjsax,2020-03-04T03:25:43Z,moved both tests to `taskmanagertest`,0,0.9948785305023193
387430633,8218,mjsax,2020-03-04T03:26:02Z,move all 4 tests to `taskmanagertest`,0,0.9940551519393921
387983590,8218,abbccdda,2020-03-04T22:54:42Z,did you already update the kip for the new config?,0,0.9944039583206177
387984270,8218,abbccdda,2020-03-04T22:56:19Z,what's the benefit of building this as a static helper?,0,0.9839842915534973
387994001,8218,mjsax,2020-03-04T23:23:13Z,we need to allow committing in `suspended` state now as we first suspend all tasks and than commit. cf. `taskmanager#handlerevocation()`,0,0.9952848553657532
387994269,8218,mjsax,2020-03-04T23:23:59Z,minor improvement: we include writing the checkpoint and the caller can indicate if it should be written or not.,0,0.9913443326950073
387994697,8218,mjsax,2020-03-04T23:25:15Z,this issues was introduced in the pr that introduced `streamsproducer` -- we forgot to close them. fixing this on the side.,0,0.9845033884048462
387995044,8218,mjsax,2020-03-04T23:26:10Z,"we call `closeclean` below -- just fixing the comment here for now (\cc ) note that we don't commit offsets for this case any longer -- previously, committing offsets ""might"" have been done with `closeclean()` (even if i believe that the task would be marked as ""commitneeded == false""). we don't let the taskmanager commit offsets here, as it should not be required.",0,0.9927911758422852
387995875,8218,mjsax,2020-03-04T23:28:26Z,similar to above: this issue was introduced in the `streamsproducer` pr. we nee to close the producer when we remove it.,0,0.9929346442222595
387995961,8218,mjsax,2020-03-04T23:28:44Z,as above,0,0.9391705989837646
387996132,8218,mjsax,2020-03-04T23:29:16Z,not sure why we use an iterator here. simplifying the code with a `for`-loop,0,0.9725512862205505
387996797,8218,mjsax,2020-03-04T23:31:16Z,"we need to commit explicitly in ttd now to mimic the taskmanger. hence, we need access to the `consumer` and `streamsproducer`",0,0.9943775534629822
388015857,8218,abbccdda,2020-03-05T00:33:39Z,why do we start to suppress warnings?,0,0.8982483148574829
388016523,8218,abbccdda,2020-03-05T00:35:52Z,"sounds good, just mark that depending on john's fix, we probably don't need to handle this.",0,0.534746527671814
388018015,8218,abbccdda,2020-03-05T00:41:10Z,add a comment describing the new return statement.,0,0.9858888983726501
388019423,8218,abbccdda,2020-03-05T00:45:58Z,i would prefer a second loop to guarantee a consistent reflection on the task committed state.,0,0.9854100942611694
388019820,8218,abbccdda,2020-03-05T00:47:32Z,"in eos beta, we should be able to send out a batch commit instead of individual ones?",0,0.9944552779197693
388022132,8218,abbccdda,2020-03-05T00:55:25Z,i don't think we need to test `assertfalse(task.commitneeded()` as its outcome is controlled by `task.markcommitted`. so we only need to do it once.,0,0.9895570874214172
388022419,8218,abbccdda,2020-03-05T00:56:24Z,why do we no longer have the mock verification?,0,0.9748937487602234
388026690,8218,abbccdda,2020-03-05T01:11:22Z,should we do `expectlastcall` here?,0,0.994554877281189
388028665,8218,abbccdda,2020-03-05T01:18:20Z,we should also verify the thrown cause,0,0.9894611239433289
388028820,8218,abbccdda,2020-03-05T01:18:46Z,"same here, for verifying the thrown cause",0,0.9862008690834045
388029164,8218,abbccdda,2020-03-05T01:20:06Z,"what's the reasoning her for only wrapping the consumer offset commit case here, not for eos case?",0,0.9873923659324646
388029471,8218,abbccdda,2020-03-05T01:21:10Z,always feels better for one less parameter :),1,0.9905655384063721
388029958,8218,abbccdda,2020-03-05T01:22:58Z,makes sense to me.,0,0.9787083268165588
388030250,8218,abbccdda,2020-03-05T01:23:57Z,checkmark for proving the 6 tests are all migrated.,0,0.9860162138938904
388030837,8218,abbccdda,2020-03-05T01:25:58Z,probably need to change after rebase,0,0.9813055396080017
389051551,8218,mjsax,2020-03-06T17:50:27Z,"we should have done this from the beginning on... (it's just a ""side fix"")",0,0.9789825677871704
389052130,8218,mjsax,2020-03-06T17:51:29Z,we will need this later (ie follow up pr) and it reduced code duplication,0,0.988923966884613
389052956,8218,mjsax,2020-03-06T17:53:26Z,correct. unifying the commit logic as done is this pr allows us to do this in a follow up pr that actually enable producer per thread -- the whole purpose of this pr is to prepare/refactor for this.,0,0.9900909662246704
389053599,8218,mjsax,2020-03-06T17:54:52Z,"you mean exception handling? for the producer all exception handling is done within `streamsproducer` (note that `threadproducer` above is a `streamsproducer`, not a `kafkaproducer`)",0,0.9947804808616638
389054695,8218,mjsax,2020-03-06T17:57:11Z,"we remove `recordcollector#commit()` method in this pr and thus we remove the expected call to commit at the beginning of this test -- thus, there is nothing to be verified any longer and we don't call `commit()` with `preparecommit()` any longer.",0,0.9949643611907959
390712211,8218,mjsax,2020-03-11T02:20:42Z,"this is an open question: we don't want to remove this sensor however it was unclear to me how to handle this metric after we split ""task committing"" into three steps (preparecommit; taskmanager#commit; postcommit).",0,0.8025370836257935
390712571,8218,mjsax,2020-03-11T02:22:13Z,simplification to avoid passing in `eosenabled` and reducing constructor parameter list -- we just piggy back on the `application.id` that shall be `null` for non-eos.,0,0.9935025572776794
390712665,8218,mjsax,2020-03-11T02:22:35Z,avoid redundant logging.,0,0.9008066654205322
390712770,8218,mjsax,2020-03-11T02:23:06Z,side cleanup: all those method can actually be package private.,0,0.9901302456855774
390712971,8218,mjsax,2020-03-11T02:23:55Z,removing this state -- this is an open question if i did this correctly. \cc,1,0.5461589694023132
390714027,8218,mjsax,2020-03-11T02:27:59Z,"after we addressed the question how we want to do metrics, we can update this tests",0,0.9844641089439392
390714488,8218,mjsax,2020-03-11T02:29:59Z,because we make app method in `streamsproducer` package private but need access to `commit()` we add `testdriverproducer` to get access.,0,0.9955596923828125
390714741,8218,mjsax,2020-03-11T02:31:09Z,just added to give public access to `committransaction()` to ttd (it's more elegant than making `streamsproducer#committransaction` public imho),0,0.9917181730270386
390727409,8218,abbccdda,2020-03-11T03:27:07Z,nit: we could log thread-id here for easier log search.,0,0.9925476908683777
391162808,8218,vvcephei,2020-03-11T18:01:56Z,"it seems a bit roundabout to have to remember we should send a `null` `application.id` as the constructor argument to indicate that eos is enabled. what's wrong with saying ""eos is enabled"" when you want eos to be enabled?",0,0.8074736595153809
391233773,8218,abbccdda,2020-03-11T20:05:06Z,could we internalize this state check inside the task to simplify the logic here?,0,0.9913730621337891
391234248,8218,abbccdda,2020-03-11T20:05:36Z,"similarly here, this state check could be internalized.",0,0.9930332899093628
391236509,8218,abbccdda,2020-03-11T20:07:57Z,nit: let's order the functions as [code block],0,0.9620516896247864
391237078,8218,abbccdda,2020-03-11T20:08:36Z,prepare to uncleanly close a task that we may not own.,0,0.9260087013244629
391241528,8218,abbccdda,2020-03-11T20:13:52Z,"having a `prepareclosedirty` makes the calling of `closedirty` a bit cumbersome as we always need to call `prepareclosedirty` first. to simplify or just do a reminder, i have two suggestions: 1. internally create a task state called prepare_close or just a boolean like `closedirtyprepared` as the state check, so that closedirty will throw illegal state if the flag is false 2. following #1, instead of throw, if we don't see the prepareclose is being called, the `closedirty` will invoke `prepareclosedirty` first internally.",0,0.9888850450515747
391243910,8218,abbccdda,2020-03-11T20:17:03Z,"for my own education, why we do `and` here instead of just checking `commitrequested`?",0,0.9885827302932739
391244729,8218,abbccdda,2020-03-11T20:18:43Z,:thumbs_up:,0,0.9771975874900818
391260243,8218,abbccdda,2020-03-11T20:50:44Z,"comment here for no better place: standby task always returns an empty `committableoffsetsandmetadata`, then why do we still need to check `commitneeded` for it? shouldn't it always set to false?",0,0.9936966300010681
391261158,8218,abbccdda,2020-03-11T20:52:34Z,`logcontext ` is not used.,0,0.9892003536224365
391261929,8218,abbccdda,2020-03-11T20:54:06Z,should we attempt to add more fine-grained metrics for 3 stages then?,0,0.9927737712860107
391265711,8218,abbccdda,2020-03-11T21:01:37Z,could we add a `` for this method? also we should comment about the different indications when we return an empty map vs null.,0,0.9908186793327332
391267109,8218,abbccdda,2020-03-11T21:04:39Z,remove `if`,0,0.9922502636909485
391286988,8218,abbccdda,2020-03-11T21:47:16Z,i feel a bit weird here as we don't need `preparecloseclean` anymore. this api usage is a little complicated upon when we should do it and we don't.,-1,0.9656936526298523
391287132,8218,abbccdda,2020-03-11T21:47:37Z,similarly for `closedirty` and `prepareclosedirty`,0,0.9935986995697021
391289786,8218,abbccdda,2020-03-11T21:54:04Z,nit; 228 - 229 could be merged.,0,0.9639984965324402
391291102,8218,abbccdda,2020-03-11T21:57:16Z,"also the above step #4 is no longer correct, the commit is done on taskmanager now.",0,0.9937064051628113
391295221,8218,abbccdda,2020-03-11T22:08:20Z,do we need to keep a task once it is failed to clean close? why couldn't we just close it dirty immediately after we see the exception?,0,0.9832726716995239
391296895,8218,abbccdda,2020-03-11T22:11:16Z,why do we need to move these tests?,0,0.972183883190155
391298785,8218,abbccdda,2020-03-11T22:13:39Z,looks like we lack test coverage for timeoutexception and kafkaexception cases,0,0.9831861257553101
391301678,8218,abbccdda,2020-03-11T22:17:34Z,we don't have unit test coverage for this exception case,0,0.9786266088485718
391302227,8218,abbccdda,2020-03-11T22:18:14Z,we lack unit test coverage for this case,0,0.981947660446167
391303712,8218,abbccdda,2020-03-11T22:20:40Z,"could we verify the assignment stack and lost stack separately, by doing `handleassignment` verify first before calling `handlelost`",0,0.9946742057800293
391337786,8218,mjsax,2020-03-12T00:07:25Z,the `threadid` is already added to the log prefix when the `log` object is created in `streamsthread`,0,0.9954751133918762
391338238,8218,mjsax,2020-03-12T00:09:08Z,not sure if i can follow. we don't check `commitneeded` in `postcommit()`? can you elaborate?,0,0.9282487630844116
391338530,8218,mjsax,2020-03-12T00:10:18Z,"frankly, i have no good idea atm... also, if we change metrics, we need to update the kip and it's getting more complicated. if possible, i would prefer to not change any metric, but not sure if it is possible...",-1,0.9550065994262695
391338712,8218,mjsax,2020-03-12T00:10:57Z,"yeah, this pr does not yet add all required test...",0,0.8217779994010925
391339213,8218,mjsax,2020-03-12T00:13:04Z,"why do we need to document this in the method javadoc? it's an internal method? internal comment outdate quickly if code is changed and comments are not updated accordingly (what happens 99% of the time). hence, i would prefer to limit comments if possible. in doubt, we should document at `task` level anyway.",0,0.9868940114974976
391339463,8218,mjsax,2020-03-12T00:13:57Z,you see -- that is may point from above... the code should be written in a way that explains itself... updating comments always slips...,0,0.9724636077880859
391340439,8218,mjsax,2020-03-12T00:17:53Z,i am actually wondering about point (5) -- why do we need to checkpoint the state manager if we wipe out the store later anyway for the unclean eos case?,0,0.9564545750617981
391342962,8218,mjsax,2020-03-12T00:28:08Z,"i actually had a similar though, but was not sure if it's worth it. would like to hear from what they think? if we do this, we might want to do it for ""commit"" and ""suspend"", too. for suspend() adding a state suspend_prepared is not helpful as suspend() does different things depending on the previous state. (for commit and close an additional state would work). for consistency reasons, an internal flag might be better though. not sure ate if calling ""prepare"" automatically would actually be correct for all cases?",0,0.9456128478050232
391344437,8218,mjsax,2020-03-12T00:33:24Z,"`preparecloseclean()` already does a state check and returns `emptymap` if state is `created`. the point of this check is, that we don't add anything to the `consumedoffsetsandmetadatapertask` map -- this is important for the corner case for which all tasks are in state created and thus no transaction was initialized. for this case we cannot call `producer.addoffsetstotranscation()` and must skip this step entirely. note, that we have a corresponding check below to not call `commitoffsetsortransaction` if the map is empty.",0,0.9951307773590088
391344863,8218,mjsax,2020-03-12T00:35:23Z,we need to call `preparecloseclean` (as done in l196 above) _before_ we call `commitoffsetsortransaction` (l215 above).,0,0.9945953488349915
391344936,8218,mjsax,2020-03-12T00:35:38Z,some comment as above.,0,0.9895400404930115
391344967,8218,mjsax,2020-03-12T00:35:44Z,i know...,0,0.8573697805404663
391345982,8218,mjsax,2020-03-12T00:40:13Z,"to avoid the overhead to commit offset that are already committed, ie, the previous commit committed offset 5 and now we would commit offset 5 again.",0,0.9927856922149658
391346285,8218,mjsax,2020-03-12T00:41:22Z,i think it's easier to read if it's split.,0,0.9503461122512817
391347114,8218,mjsax,2020-03-12T00:44:22Z,"i try to keep ""order"" and group test methods to keep an overview if test coverage is complete. [code block]",0,0.9900832176208496
391348100,8218,mjsax,2020-03-12T00:48:34Z,"not sure if i can follow? the comments just mark which setup calls belongs to which test call, nothing more. all setup is done upfront before we call the actually methods under test.",0,0.9661480188369751
391348586,8218,mjsax,2020-03-12T00:50:19Z,good catch.,1,0.9815194606781006
391361243,8218,mjsax,2020-03-12T01:47:39Z,good idea!,1,0.9948603510856628
391809790,8218,guozhangwang,2020-03-12T18:22:32Z,nit: add a check that taskid exists in `taskproducers` to make sure we do not return null.,0,0.993253767490387
391812242,8218,guozhangwang,2020-03-12T18:27:10Z,subjectively i'd +1 that adding one more parameter to avoid piggy-backing on the applicationid is better.,0,0.9830145835876465
391829473,8218,guozhangwang,2020-03-12T18:59:20Z,"actually on a second thought, i'm wondering if the following inside taskmanager is cleaner: [code block] instead of: [code block] my gut feeling is that it is cleaner to not access the task creator for its created stream-producers (and hence here we need to change the task-producer map to streamsproducers), but just access each task's record collector and call its `commit` --- today we already have a `streamtask#recordcollector` method.",0,0.5351852178573608
391829854,8218,guozhangwang,2020-03-12T19:00:10Z,"please see my other comment above --- i think it is cleaner to just call `foreach(active-task) task.recordcollector.commit` inside the task-manager; and inside recordcollectorimpl we check that eosenabled is always true, otherwise illegal-state thrown. in the next pr where we have the thread-producer, we could then only create a single `recordcollector` object that is shared among all active tasks and wraps the thread-producer, and then the caller `taskmanager` code then can just get one active task and call its record-collector's commit function knowing that is sufficient to actually commit for all tasks since everyone is using the same record-collector. wdyt?",0,0.9855706691741943
391838078,8218,guozhangwang,2020-03-12T19:16:48Z,"this is a meta comment: i think we can consolidate `preparecommit` and `prepareclose` and `preparesuspend` here by introducing the clean parameters to the function, since their logic are very similar (for the part that they diffs a bit, it can be pushed to post logic), and on task-manager during commit: 1) for each task -> task.preparecommit(true) 2) commit 3) for each task -> task.postcommit(true) during close: if (clean) 1) for each task -> task.preparecommit(true) 2) commit() 3) for each task -> task.postcommit(true) else 1) for each task -> task.preparecommit(false) // do not commit 3) for each task -> task.postcommit(false) 4) tasks.close(flag) and the same for suspension.",0,0.9660261869430542
391838707,8218,guozhangwang,2020-03-12T19:18:06Z,"i actually think that we can remove this debug-level per-task commit metrics, since we already have the info-level per-thread commit metric and this one does not provide much more additional information?",0,0.9909646511077881
391974508,8218,mjsax,2020-03-13T00:39:06Z,"i think it's unclean to let the recordcollector commit (note that this pr removes `recordcollector` not at side refactoring but on purpose) -- to me the recordcollector has the responsibility to bridge the gap between the runtime code (that is typed), and the producer that uses ` ` (ie, it serialized the data and manages errors from `send`) -- why would a **_collector_** know anything about committing (for which it also needs a handle to the consumer)? about accessing the `activetaskcreator`: we could also expose the `streamsproducer` via the `recordcollector` though (or directly via the task)? that would be cleaner i guess.",0,0.9861093163490295
391993410,8218,mjsax,2020-03-13T02:06:16Z,it's a personal preference i guess. but seems you don't like it. will revert it.,-1,0.9441916942596436
392017955,8218,guozhangwang,2020-03-13T03:50:05Z,"this is not introduced in this pr, but: while thinking about it, i realized for restoring state we do not need to rely on eosdisabled to checkpoint, in fact we can always checkpoint during restoring here.",0,0.963050365447998
392783249,8218,mjsax,2020-03-16T04:59:42Z,will do this in a follow up pr.,0,0.9898481965065002
392783415,8218,mjsax,2020-03-16T05:00:28Z,ack,0,0.8596508502960205
392783859,8218,mjsax,2020-03-16T05:02:44Z,covered via `shouldcommitnextoffsetfromqueueifavailable` and `shouldcommitconsumerpositionifrecordqueueisempty`,0,0.9942755103111267
392784308,8218,mjsax,2020-03-16T05:05:18Z,we can address this in a follow up pr.,0,0.9895590543746948
392794910,8218,mjsax,2020-03-16T05:56:23Z,added test `shouldthrowwhenhandlingclosingtasksonproducercloseerror`,0,0.9946225881576538
393132558,8218,abbccdda,2020-03-16T16:00:20Z,we need a unit test for this function.,0,0.989302933216095
393136595,8218,abbccdda,2020-03-16T16:06:09Z,"we could just do one log in front: `log.info(""prepare suspending {}"", state());`",0,0.9934466481208801
393139575,8218,abbccdda,2020-03-16T16:10:32Z,do we have unit test to check the checkpoint status after `postcommit()`?,0,0.9938042163848877
393180380,8218,abbccdda,2020-03-16T17:06:41Z,"i couldn't fully follow this idea, just playing devil advocates here, if we think meta code comments actually hinder the readability of internal class, why not just remove all the internal function meta comments, as they would get outdated anyway? for me the return type comment is still valuable for understandability. if the comment gets outdated, we should just update it. cc if the idea here makes sense, or we could get a consensus on what needs to be done in internal class comments, and what's not.",-1,0.9071494936943054
393183310,8218,abbccdda,2020-03-16T17:11:13Z,nit: { could be reduced.,0,0.9795619249343872
393195455,8218,abbccdda,2020-03-16T17:31:51Z,"yea, a todo is also ok.",0,0.9137270450592041
393336160,8218,guozhangwang,2020-03-16T22:07:16Z,"`for the next pr` (all other comments with this tag means no changes required for this pr): my understanding is that we would make the thread-producer also a `streamsproducer` instead of a `kafkaproducer` which would be used to `committransaction` under `eosbeta`, is that right?",0,0.9945510029792786
393336618,8218,guozhangwang,2020-03-16T22:08:31Z,"nit: we can have a wrapped streamsproducer#close / metrics, and then #kafkaproducer would be for testing-only.",0,0.9943494200706482
393336934,8218,guozhangwang,2020-03-16T22:09:16Z,"after syncing offline about this, i think i'm convinced now that moving this logic into taskmanager is better.",0,0.9645843505859375
393339067,8218,guozhangwang,2020-03-16T22:14:56Z,"i think we should just let the preparexx function to return the map of partitions -> partition-timestamp to indicate if it should be included in the map of committing offsets, so that we do not need to leak the state into task-manager here. also we only need to call `mainconsumer.position` once for all tasks -- please see my other comment above. also: we should not try to commit state if we are in restoring but only flushing store and writing checkpoints (i think this is already the behavior in trunk), since the partitions are paused from the main-consumer before restoration is done --- maybe it is partly causing some unit test flakiness.",0,0.9902004599571228
393339213,8218,guozhangwang,2020-03-16T22:15:23Z,sg. i think in this pr we still can do the change to let `preparexx` to return the map of partitions -> partition-timestamp to indicate whether this task should be included in committing.,0,0.993328332901001
393341972,8218,guozhangwang,2020-03-16T22:23:14Z,"in either eos-alpha or eos-beta or non-eos, we can just loop over all the ""committable partitions"" and call `mainconsumer#position` once, so this function can be extracted out of the task as a per-task call. more specifically, in the preparexx calls, we know based on the state of the task and clean flag whether or not we should commit the source topic offsets for this task, so we can let the preparexx function to return `map partitiontimes` encoding the extracted timestamps for each partition instead of void --- when we decided not to commit we return an empty map. and then inside taskmanager we just use the `mainconsumer` to call position once and then pass that to the `commitoffsetsortransaction` call.",0,0.9919090867042542
393344611,8218,guozhangwang,2020-03-16T22:28:40Z,nit: we can do `if / else if / else` here still and move the `closetasksensor.record(); / transitionto(state.closed);` to avoid duplication.,0,0.9949784874916077
393345037,8218,guozhangwang,2020-03-16T22:29:26Z,"ditto here, i think if / else if / else is more readable.",0,0.9553020000457764
393350516,8218,mjsax,2020-03-16T22:43:50Z,"well, we log ""skip"" for state created and we throw for invalid states. note sure how to do this?",0,0.9659073948860168
393350827,8218,mjsax,2020-03-16T22:44:47Z,"yes, `shouldrespectcommitneeded()` check this already.",0,0.9940441250801086
393371781,8218,guozhangwang,2020-03-16T23:47:56Z,"`for the next pr`: as i mentioned in the last commit i feel `preparesuspend` and `prepareclose` can be consolidated with `preparecommit` but in the next pr these logic would be changed again for eos-beta so maybe we cannot do that any more, so i'm fine with keeping as-is and we can revisit to see if we can really do this refactoring or not in the next pr when we did the eos-beta.",0,0.9890672564506531
393373023,8218,guozhangwang,2020-03-16T23:52:01Z,yes we are unnecessarily checkpointing here --- the reason is that eos flag was original striped out of task and only processor-state-manager knows about it; now since we get this eos flag back to task (sigh.. :) we can add this additional check.,1,0.9478782415390015
393374466,8218,guozhangwang,2020-03-16T23:57:18Z,"i would suggest not restricting ourselves to some specific rules about comments :) personally i tried to avoid the `one line comment explaining one line code` type of comments inside a function since it should be obvious, rather i'd add some comments for a block or several blocks if i fear it maybe hard to read by itself. i think you guys should just make your best judgement here. and for internal functions, i agree that we do not necessarily need to write java-docs, and this one, for example, i wrote the java-doc as part of the tech debt cleanup just to remind what operations must be considered here inside closing / suspending etc so that later on when we change the function itself by other contributors, they would use it as a reference to check if they mistakenly missed some steps or re-ordered some steps. however if we are going to split this function into multiple, instead of just re-structuring the function as a whole, then although i have my preference i'd leave to you guys if you want to add the javadoc for both pre/post of you feel now it is too obvious to bother :)",1,0.9834498763084412
393377256,8218,guozhangwang,2020-03-17T00:07:51Z,"`for the next pr`: i see the reason i return the checkpoint is that we are now extracting the committing out of the task and i need to remember if we need to checkpoint and if yes which offsets after we've flushed and before we checkpoint, but since the state of the task would not change before / after the commit during close. more specifically we only have three cases: 1) to not write checkpoint, 2) write checkpoints for written offsets (changelogs) only, 3) write checkpoint for written and consumed offsets. and no matter which case it is during the `preclose`, it would always be the same in the `post`, so why do we need to return it to task-manager, book-keep there, and then after commit to pass it back to tasks?",0,0.9817750453948975
393378779,8218,guozhangwang,2020-03-17T00:14:27Z,nit: we should emphasize that prepareclose and close calls should be implemented idempotent since we may call it multiple times if a task close clean first and then fail and then close dirty.,0,0.9911198019981384
393384266,8218,guozhangwang,2020-03-17T00:37:48Z,"`for the next pr`: i think we can save prepareclose (or more accurately, merge prepareclose and close together again) if we make a state diagram change that only suspended state can transit to closed state, i.e. at task-manager level whenever we want to close a task we call its `suspend` function first, which would, depending on its state, be a no-op, or flushing, or closing topology etc, and then after that the task is always in suspended state, and then we call ""commit"" if necessary, and then we call close (a minor thing is that today when the state is in suspended we would omit committing inside task, and we need to lift this restriction; and also the transition actions to transit to suspended need to rely on the clean flag, hence we need `suspend(clean-flag)`). and we can further merge preparesuspend and suspend as well by just making the checkpointing logic as part of post-commit instead of post-suspend, since as i mentioned above you only have three cases: 1) do not need to checkpoint: if you are in created. 2) checkpoint written and consumed offsets: if you are in running, in which you need to commit offsets as well. 3) checkpoint only store offsets: if you are in restoring, and in which case you do not need to commit offsets. in fact, if we are not in the running state yet, the `consumedoffsets` as well as `recordcollector#offsets()` are always going to be empty, so it is always safe to call `statemgr.checkpoint(checkpointableoffsets())` and not condition on the state and call `statemgr.checkpoint(emptyset())`. and if we now allow committing in suspended state as part of closing (i.e. suspend -> commit -> close), similar rules apply: if we are suspending from a restoring state, then in `postcommit` while we ``statemgr.checkpoint(checkpointableoffsets())` the `checkpointableoffsets` would always be empty; if we are suspending from a running state it would contain some offsets.",0,0.9830333590507507
393385438,8218,guozhangwang,2020-03-17T00:41:49Z,"see my other comments: we should not commit in created, restoring and suspended state, and it's better just to let the preparexx function to indicate if there's anything to commit based on its state internally than letting task-manager to branch on the task state -- more specifically, here the prepareclose call should not return the map of checkpoints but the map of partition -> partition-timestamps (if empty it means nothing to commit), since the checkpoint map are not needed at task-manager at all and post commit, if the offsets should be empty it would still be empty.",0,0.993320107460022
393387491,8218,guozhangwang,2020-03-17T00:50:23Z,"same here: not only created, but also restoring and suspended tasks should not be included in `consumedoffsetsandmetadatapertask` and we should not let the task-manager to peek its state.",0,0.9852563142776489
393387840,8218,guozhangwang,2020-03-17T00:51:31Z,"""as above"" :)",1,0.9944164752960205
393389583,8218,mjsax,2020-03-17T00:58:53Z,correct. for eos-beta there will be one `streamsproducer` that is shared over all tasks.,0,0.994140088558197
393389903,8218,mjsax,2020-03-17T01:00:30Z,"we could, but the idea was that `activetaskcreator` creates the producer via `new kafkaproducer()` and thus it should call `kafkaproducer#close()`, too, and not delegate it to `streamsproducer`. thoughts?",0,0.9940285682678223
393392898,8218,mjsax,2020-03-17T01:12:55Z,"well, we can, but we get an empty ""than block"" what is weird: [code block]",-1,0.8846456408500671
393418010,8218,mjsax,2020-03-17T02:58:33Z,"within `maybecommitactivetasksperuserrequested` we know that we are in state `running` and thus, no need to check what `committableoffsetsandmetadata()` returns but we can ""blindly"" commit.",0,0.9892128705978394
393792511,8218,abbccdda,2020-03-17T16:05:29Z,"by `next pr`, you mean the one after we finish the eos-beta commit feature right?",0,0.9932570457458496
393884343,8218,guozhangwang,2020-03-17T18:25:59Z,i mean the next pr when we add the eos-beta feature --- please see the first comment i have with this tag.,0,0.9778974652290344
393885815,8218,guozhangwang,2020-03-17T18:28:21Z,"hmm, i think moving forward we would create and maintain both the single thread-producer and task-producers as streamsproducer objects right?",0,0.9777238965034485
393887170,8218,guozhangwang,2020-03-17T18:30:28Z,"i'd say we can always log a debug there saying ""doing nothing in this function since we are in this state"" :) the main concern i had, is that if in the future we want to add more steps in addition to `recording sensor` etc, we may forget adding it in one place or the other. removing duplicated code helps us to be less vulnerable.",1,0.9914008975028992
393898999,8218,mjsax,2020-03-17T18:50:49Z,sgtm,0,0.9109601974487305
393905732,8218,guozhangwang,2020-03-17T19:03:16Z,thanks for the cleanup!,1,0.8892589211463928
393906971,8218,guozhangwang,2020-03-17T19:05:38Z,why we have to transit to suspended before prepare-closing? originally we want to check that created state can still trigger close.,0,0.9886264204978943
393907754,8218,guozhangwang,2020-03-17T19:07:06Z,not introduced in this pr: could we add test checking closed state should not commit as well? also checking suspended state close-call is no-op.,0,0.9942955374717712
393911532,8218,guozhangwang,2020-03-17T19:14:37Z,"why making `committransaction` is less elegant? i thought that was fine since `streamsproducer` is inside the internals package anyways? in fact, in ttd we have access to internaltopologybuilder accessing it functions (we used to also have a wrapper of internaltopologybuilder which we removed later) so i thought that was the agreed pattern.",0,0.9884917736053467
393917156,8218,guozhangwang,2020-03-17T19:25:38Z,"this is a meta comment: since we moved the commit logic out of the tasks into task-manager already, we should add the check that: 1) inside the task manager, if the commit failed with fatal errors, the corresponding follow-up steps (postcommit, suspend, closeclean) should be skipped, and the exception is thrown out of the task-manager to thread 2) if commit failed with fenced errors, follow-up steps are also skipped (tasks state should be un-changed) and the task-migration exception is thrown out of the task-manager.",0,0.9949167966842651
393963708,8218,mjsax,2020-03-17T20:53:23Z,ack. we can remove this.,-1,0.8432561159133911
393964723,8218,mjsax,2020-03-17T20:55:19Z,ack,0,0.8596508502960205
393966087,8218,mjsax,2020-03-17T20:57:46Z,but in `close()` if state is suspended we might still wipe out the state store -- it's not a no-op,0,0.9836463928222656
393968843,8218,mjsax,2020-03-17T21:03:00Z,"it's obviously subjective -- personally, even if something is internal, we should not just declare stuff as `public` but try to keep it to a minimum to follow the idea of encapsulation (not always possible). if you want me to remove this class and make the method `public` i can do it in a follow up pr. not sure if we have an agreed pattern, though.",-1,0.8053605556488037
393979041,8218,guozhangwang,2020-03-17T21:23:47Z,"cool, in that sense let's just keep it then -- do not add it in one pr and remove it immediately in the next.",1,0.581680417060852
56714551,1095,granthenke,2016-03-18T20:05:32Z,"not sure if this is the best way to do this. i need a different constructor for requesting a `null` list because `null` matches both the list and struct constructors with the same ""specificity"". i am open to ideas for a better way to support requesting no topic metadata.",0,0.8963945508003235
56716409,1095,gwenshap,2016-03-18T20:20:17Z,"you mean other.rack? also, i'm wondering whether we want to consider a node to be a different node when the rack changed. i guess it depends on how it is used - except it isn't used...",0,0.8951289653778076
56716786,1095,granthenke,2016-03-18T20:23:02Z,good catch. i just maintained equals meaning all fields match. i suspect thats the safest path to go right now.,1,0.9769282937049866
56717383,1095,gwenshap,2016-03-18T20:27:12Z,"i noticed you keep using broker_v0 anywhere except metadata, and i think thats the plan going forward as well. if my understanding is correct, broker_v1 is not really a ""newer"" broker definition (which implies that eventually we'll move everything to use that) but rather a broker definition specific for metadata request or just a more detailed broker definition. maybe rename to something less misleading?",0,0.9753345847129822
56717758,1095,gwenshap,2016-03-18T20:29:50Z,and on similar topic (but should be separate jira) - the protocol has few different places with broker definitions - maybe more consolidation is possible?,0,0.980977475643158
56717859,1095,granthenke,2016-03-18T20:30:38Z,"yes, my understanding is these ""sub-schemas"" are supposed to tie directly to single api/protocol to allow them to change independently. i think the fact that a broker_v0 was shared was a mistake. i had left the old one being shared just to minimize change. i can break-out and rename a bit to prevent an accidental sharing in the future.",0,0.9800265431404114
56718714,1095,granthenke,2016-03-18T20:37:26Z,"i am of the impression that we are not consolidating so that the wire protocols can change independently. however, we want to represent that in java or scala object is up to the parser. this decouples protocol from implementation. though even in implementation we have chosen to duplicate in the past too.",0,0.9789543747901917
56768466,1095,ijuma,2016-03-20T17:47:15Z,would it make sense to use a bitset for these booleans?,0,0.9937730431556702
56892437,1095,granthenke,2016-03-21T20:38:10Z,"yeah, that could save a byte for each topic. i will mention it during the wire protocol discussion on the next kip call, since this needs to be reviewed/voted.",0,0.9905592203140259
57952993,1095,hachikuji,2016-03-30T19:57:34Z,"i've been wondering if it would be better to use static factory methods instead of relying on constructors. in that case, you could use something like `metadatarequest.alltopics()` or something like that.",0,0.9892099499702454
57953330,1095,granthenke,2016-03-30T19:59:43Z,"good suggestion. i like the builder pattern as well. the implementation can be a bit verbose in java, but it can do validation at build time and prevent the telescoping constructor problem. it may also be able to provide simplified api compatibility.",1,0.9922764897346497
57967577,1095,hachikuji,2016-03-30T21:31:43Z,"i also like the builder pattern. it reads nicely and you don't have to care about argument order. on the other hand, it's also easier to forget necessary arguments and it feels kind of silly when the number of arguments is small. one nice thing about factory methods is that you can give them convenient names (e.g. metadatarequest.alltopicsv1()). both options are probably better than using the constructors, but i don't think it would be too bad to stick with the current convention for this patch. another option would be to include an explicit flag in the constructor. for example: [code block] we could then have the other constructor which accepts the topic list use the ""empty means empty"" semantics, and users would have to call this method to get all topics.",1,0.8758004903793335
58056988,1095,granthenke,2016-03-31T13:55:48Z,"i do like the idea of a flag to make it explicit. the challenge that poses is compatibility. i think any existing constructor needs to continue to function the way it used to. so empty list would need to continue to signify ""all topics"", at least for existing constructors.",1,0.5024314522743225
58058004,1095,ijuma,2016-03-31T14:02:16Z,"request classes are not api so i am not sure why it has to be like that? the official position is that we generate javadoc for classes that are api: [a link] (yes, i know it's confusing, i hope to change that so internal classes are all in internal packages).",-1,0.5717718005180359
58060325,1095,granthenke,2016-03-31T14:15:24Z,i didn't realize compatibility wasn't a concern on these classes. then we can do whatever we would like here.,0,0.8515271544456482
58221673,1095,granthenke,2016-04-01T15:24:57Z,i updated the constructor to take an `alltopics` boolean. i think the changes required to do so may also solve [a link]. it worked nicely with `metadata.needmetadataforalltopics` in the `networkclient`.,0,0.9876706600189209
58239805,1095,SinghAsDev,2016-04-01T17:36:14Z,"in current proposal, we are saying a null indicates all topics. would it be possible to use that here as well?",0,0.9920780062675476
58240259,1095,granthenke,2016-04-01T17:39:41Z,"the proposal is to use null on the wire protocol, not in the api. in the discussions it was mentioned that being more explicit in the api was favored. beyond that, if you specify `metadatarequest(null)` java wont know which constructor to use between `metadatarequest(list topics)` and `metadatarequest(struct struct)`.",0,0.9927961230278015
58243837,1095,SinghAsDev,2016-04-01T18:04:58Z,"got it, thanks for the explanation .",0,0.7375890612602234
58245304,1095,granthenke,2016-04-01T18:14:51Z,thanks for the review !,1,0.8995906114578247
58536600,1095,ijuma,2016-04-05T13:26:17Z,just noting that this is no longer relevant given the current implementation (for other people reading the pr).,0,0.9805399775505066
60636130,1095,gwenshap,2016-04-21T18:55:09Z,don't we usually add new arguments at the end?,0,0.9923350214958191
60638297,1095,gwenshap,2016-04-21T19:08:35Z,do we need to validate if this is nullable before writing?,0,0.9935848116874695
60638460,1095,gwenshap,2016-04-21T19:09:40Z,do we want to throw an exception with appropriate message if item if null but shouldn't be?,0,0.983084499835968
60638661,1095,gwenshap,2016-04-21T19:11:02Z,"not sure if it matters, but we will get the exact same hash for empty and null arrays?",0,0.8991286754608154
60641282,1095,granthenke,2016-04-21T19:28:51Z,"since this was in internals and i needed to update all usages regardless, i located ""related"" parameters close to each other. i can move to the end if you prefer.",0,0.9855790138244629
60642147,1095,granthenke,2016-04-21T19:35:12Z,i think all of the other types assume validate will be called before calling write and that the written object would be the one returned by the validate call. here is a code snippet from `schema.write(...)`: [code block],0,0.9922417402267456
60642638,1095,granthenke,2016-04-21T19:39:10Z,it fails further down during the cast the same way it would before nulls were allowed. that exception is caught and re-thrown as a schemaexception. this behavior is validated by `protocolserializationtest.testnulls`.,0,0.9910753965377808
60645983,1095,granthenke,2016-04-21T20:02:39Z,"good point. we don't have `hashcode` or `equals` defined for `schema`, `field` or `type`...perhaps we should.",1,0.6256929636001587
60660381,1095,gwenshap,2016-04-21T21:45:10Z,"yeah, i saw that. i'm suggesting a separate schemaexception with message specific for nulls, to make troubleshooting/debugging a bit easier. not a big deal though.",0,0.7813007831573486
60660437,1095,gwenshap,2016-04-21T21:45:34Z,want to create a followup jira?,0,0.9907105565071106
60660863,1095,granthenke,2016-04-21T21:48:48Z,created [a link] to track that.,0,0.989933431148529
60661081,1095,ijuma,2016-04-21T21:50:27Z,"personally, i'd introduce a `arrayof.nullable` static factory method as i think that would be more readable than the `true` here (since we don't have named arguments in java).",0,0.9921060800552368
60661303,1095,gwenshap,2016-04-21T21:52:16Z,i don't think we can do a fall-through here? since v1 error response is not a valid v0 response?,0,0.9589598774909973
60661511,1095,granthenke,2016-04-21T21:53:47Z,i can do that. it should probably be done for all types that don't accept null. i opened [a link] to track that.,0,0.986528754234314
60662604,1095,gwenshap,2016-04-21T22:03:00Z,"i am bit confused about the use of controller node vs controllerid. the protocol requires sending controllerid, which is what we have in most places. but you also find the actual node and provide an api (which isn't used anywhere? not even in tests?) to get the node. wondering what was the the plan here.",-1,0.9209430813789368
60672248,1095,gwenshap,2016-04-21T23:41:16Z,thanks!,1,0.9051083922386169
60672977,1095,gwenshap,2016-04-21T23:49:55Z,i'm wondering if we can push down the work of figuring out if a topic is internal to topicmetadata constructor. it will clean up the api and topicmetadata has all the information it needs to find out.,0,0.9765486121177673
60673350,1095,gwenshap,2016-04-21T23:54:39Z,"mind adding a comment here, something along the lines of: ""in version 0, we returned an error when brokers with replicas were unavailable, while in higher versions we simply didn't include the broker in the list we returned"" (or is it vice-versa? anyway, its non-obvious and need a comment imo)",0,0.9879896640777588
60673675,1095,SinghAsDev,2016-04-21T23:58:50Z,nit: i think broker or broker_info or broker_metadata would be better.,0,0.9863792657852173
60673775,1095,gwenshap,2016-04-22T00:00:03Z,not 100% sure about changes to this test. random cleanup or related to kip-4?,0,0.9232800006866455
60673904,1095,SinghAsDev,2016-04-22T00:01:23Z,should we mention effect of a null string as rack here?,0,0.9927104711532593
60673918,1095,gwenshap,2016-04-22T00:01:35Z,aren't we adding a test for the results with errorunavailableendpoints = false?,0,0.9913525581359863
60673941,1095,gwenshap,2016-04-22T00:01:52Z,love it!,1,0.9675411581993103
60674080,1095,gwenshap,2016-04-22T00:03:44Z,"ok, i saw we are testing both request versions below. i still find it a bit weird it is missing from the cache tests, since it is added functionality for the cache - but up to you.",-1,0.9522644281387329
60674146,1095,gwenshap,2016-04-22T00:04:31Z,do you want to also validate that v0 request with null still returns all topics?,0,0.993388295173645
60674190,1095,gwenshap,2016-04-22T00:05:11Z,i also don't see us checking for v1 all-topics explicitly. do you want to add something?,0,0.9653021693229675
60674223,1095,gwenshap,2016-04-22T00:05:38Z,not sure how this is related.,-1,0.5461623668670654
60674299,1095,gwenshap,2016-04-22T00:06:13Z,its fine. just checking :),1,0.9942536950111389
60674310,1095,gwenshap,2016-04-22T00:06:26Z,got it. thanks.,1,0.9407241940498352
60674321,1095,gwenshap,2016-04-22T00:06:34Z,thanks!,1,0.9051083922386169
60674337,1095,gwenshap,2016-04-22T00:06:52Z,+1,0,0.7702900171279907
60674619,1095,SinghAsDev,2016-04-22T00:10:09Z,"just thinking it loud here, it seems we follow getter convention here, we really do not have a common convention across the codebase. however, it is not too bad, as this is not end-user. i think user facing classes/interfaces do not follow getter convention though.",-1,0.8575074672698975
60675033,1095,SinghAsDev,2016-04-22T00:15:12Z,shouldn't we check something like `topics != null && !topics.isempty()` or maybe we just want to rename the method to indicate we are indeed checking for topics to be non-null.,0,0.9921093583106995
60675649,1095,SinghAsDev,2016-04-22T00:23:11Z,"would it make sense to be consistent with other key names? have something like ""controller_id"".",0,0.9934782981872559
60676104,1095,gwenshap,2016-04-22T00:29:20Z,kafka-3603 seems to be for something else?,0,0.9903734922409058
60676663,1095,SinghAsDev,2016-04-22T00:36:36Z,+1,0,0.7702900171279907
60676892,1095,SinghAsDev,2016-04-22T00:40:19Z,nit: maybe we can leave this file out if there are no other changes?,0,0.9921179413795471
60755927,1095,ijuma,2016-04-22T15:19:50Z,this should be `byte` instead of `byte`.,0,0.9926014542579651
60756062,1095,ijuma,2016-04-22T15:20:48Z,"what is the reasoning for accepting any non-zero value as `true`? it seems more error-prone imo. if any value outside of `0` or `1` are used, it's probably a mistake.",0,0.8397814631462097
60756385,1095,ijuma,2016-04-22T15:22:59Z,do we want to ignore or it would it be better to validate it (ie `topics` must be empty or null for that case).,0,0.9918820261955261
60757857,1095,ijuma,2016-04-22T15:31:46Z,"you can just return the controller here and then you don't need the `controller` variable or break (in scala, i don't like to use `return`, but if one is using `break` already, then it's at a similar level imo).",0,0.9833385944366455
60758124,1095,ijuma,2016-04-22T15:33:37Z,"if possible, jun generally suggests that we have one constructor per version with older version constructors deprecated. seems like we could do that here right? the older version would not have `controllerid`.",0,0.9918524622917175
60758473,1095,ijuma,2016-04-22T15:35:40Z,"i think it would be useful to add a comment here and when we set other new fields (`rack_key_name`, `is_internal_key_name`, etc.) saying stating the version they were added in (we do that in other request/response classes).",0,0.990394651889801
60758863,1095,ijuma,2016-04-22T15:38:05Z,"hmm, if we don't have that field, then we don't know if it's internal or not, right?",0,0.5762161016464233
60761238,1095,granthenke,2016-04-22T15:53:41Z,i had maintained the old constructor for compatibility in an older version of the patch. but in previous reviews i was told i did not need to maintain it: [a link],0,0.9826772809028625
60761858,1095,granthenke,2016-04-22T15:57:30Z,i am okay with that.,0,0.8253441452980042
60762586,1095,granthenke,2016-04-22T16:01:17Z,this is left over from changes required when leveraging zookeeper to track deletes. i left it because it looks like its closer to what was actually trying to be mocked based on the comment. i can keep it or leave it.,0,0.991095781326294
60762636,1095,granthenke,2016-04-22T16:01:35Z,sure i will add some more test cases.,0,0.9836215376853943
60762667,1095,granthenke,2016-04-22T16:01:52Z,i can add those tests here too.,0,0.9837787747383118
60762756,1095,granthenke,2016-04-22T16:02:28Z,this is left over from changes required when leveraging zookeeper to track deletes. i left it because it looks like its closer to what was actually trying to be mocked based on the comment. i can keep it or leave it.,0,0.991095781326294
60762885,1095,granthenke,2016-04-22T16:03:00Z,will add the comment.,0,0.9874367713928223
60762972,1095,granthenke,2016-04-22T16:03:33Z,thats an interesting idea. let me take a look and report back.,1,0.6304762959480286
60763255,1095,granthenke,2016-04-22T16:05:26Z,"this is challenging because we use the same class for both v0 and v1 responses. in the common case if you have the new version of the class you would be using v1 protocol, but thats not always true. in the case of new fields i tried to pick a safe default. since v0 is not aware of internal topics i defaulted to false. do you have thoughts on a better approach?",0,0.7405308485031128
60763550,1095,ijuma,2016-04-22T16:07:18Z,"sorry for the confusion. if we don't need to use the older version, we can remove it. however, if we still need to use it, then it's better to keep a constructor for the older version instead of having a version parameter. that's based on jun's previous reviews, i actually prefer the current approach as we don't need to call deprecated constructors. anyway, if gwen is fine with this, maybe we can leave as is.",-1,0.9848930835723877
60763729,1095,ijuma,2016-04-22T16:08:38Z,do we need to check `false` twice?,0,0.9908784031867981
60763932,1095,ijuma,2016-04-22T16:10:07Z,shall we add a topic where the boolean is `true`?,0,0.9937893748283386
60764088,1095,ijuma,2016-04-22T16:11:07Z,should we just pass `null` instead of empty list (like in `requestresponsetest`)?,0,0.994934618473053
60764126,1095,granthenke,2016-04-22T16:11:23Z,"whenever a broker id is used on the wire protocol, logically this class looks up the broker by id in the brokers list and represents it to the user as a node. this is very similar logic to how replicas ids are handled in this class. i am not saying its my favorite, but i chose to maintain the existing pattern. the controller node is not used yet, but in kip-4 it may be used to route messages.",0,0.9259539842605591
60764164,1095,ijuma,2016-04-22T16:11:39Z,nitpick: no need for braces.,0,0.9888317584991455
60764416,1095,ijuma,2016-04-22T16:13:41Z,not sure about that. the request classes shouldn't really have any logic imo. they should just be a way to serialize/deserialize to the kafka protocol. we could have a util method somewhere that does this. or at least a static factory method (instead of constructor) in the request classes as a pragmatic compromise.,0,0.9240353107452393
60764750,1095,granthenke,2016-04-22T16:16:09Z,"its a bit of a gray area. we introduced the boolean to be explicit and be the single deciding factor for all topics. if we have this validation, its actually the topics list that really matters again and we essentially have 2 toggles to enable all topics. when validating would we require null & true to get all topics and fail in all other cases in order to match closely to the wire protocols behavior?",0,0.9619384407997131
60764789,1095,granthenke,2016-04-22T16:16:25Z,will fix.,0,0.8708126544952393
60764921,1095,ijuma,2016-04-22T16:17:34Z,"we are using this `tostring` in a number of log statement, not sure the rack information is that relevant (the fact that `tostring` is used for both debug and more user-facing string is a pain). , you cleaned up the logs, what do you think?",-1,0.89412522315979
60765137,1095,ijuma,2016-04-22T16:19:07Z,"ok, maybe add a comment in this case as it's not obvious.",0,0.978080153465271
60765466,1095,granthenke,2016-04-22T16:21:18Z,"i implemented it this way to match the existing behavior of stopreplica requests delete_partitions boolean. that way this type could be used there as well without a version bump, and all the ""booleans"" would behave the same. i planned to update stopreplicarequest after this patch based on the decisions here. here is the relevant code: [a link]",0,0.986703634262085
60765571,1095,granthenke,2016-04-22T16:22:00Z,this class uses get for all other methods so i followed that.,0,0.9876345992088318
60765672,1095,granthenke,2016-04-22T16:22:56Z,"apologies, copy and paste error. its [a link].",0,0.9814140200614929
60765811,1095,granthenke,2016-04-22T16:24:02Z,what message would you suggest?,0,0.9847655296325684
60766018,1095,granthenke,2016-04-22T16:25:38Z,the idea is that this is the broker used with the metadata response. all objects tied to the metadata response are prefixed with metadata. there are other broker objects in this file that i would not want to be confused.,0,0.9754257798194885
60766035,1095,granthenke,2016-04-22T16:25:43Z,will do.,0,0.9864637851715088
60766571,1095,granthenke,2016-04-22T16:29:49Z,these constructors are generally only used in the broker. i like passing in the version because then one constructor can handle all versions and the broker is guaranteed to send the correct version back without a bunch of if/switch logic. there could be a case in the future where a separate constructor is required to maintain compatibility. but if i can avoid many constructors i would prefer it.,0,0.9532597661018372
60766711,1095,granthenke,2016-04-22T16:31:05Z,sure. will remove.,0,0.9675320982933044
60766886,1095,ijuma,2016-04-22T16:32:03Z,"`boolean` is a keyword, that's why.",0,0.9924237728118896
60766905,1095,granthenke,2016-04-22T16:32:18Z,no. will fix.,0,0.9598755836486816
60767008,1095,granthenke,2016-04-22T16:33:08Z,sure we can.,0,0.9807165265083313
60767033,1095,ijuma,2016-04-22T16:33:23Z,"i know what you mean, i did the same in a previous pr, but jun made me change it. ;) as i said, let's see what gwen thinks.",1,0.9955413937568665
60767100,1095,granthenke,2016-04-22T16:33:56Z,i can do that. i will include explanation in the version comments suggested earlier.,0,0.9746315479278564
60767154,1095,granthenke,2016-04-22T16:34:22Z,i think it depends on the choice in earlier comments here: [a link],0,0.9835431575775146
60767558,1095,granthenke,2016-04-22T16:37:27Z,"this is related to this discussion too: [a link] right now some these classes have quite a bit of logic and don't expose the ""raw"" information. i agree that it would be nice to have some layering here where the logic is handled/exposed elsewhere. i don't want to impose to much change on existing logic in this patch though either.",0,0.9437331557273865
60767635,1095,granthenke,2016-04-22T16:38:04Z,that too.,0,0.9832853674888611
60769396,1095,ijuma,2016-04-22T16:52:26Z,"this is a bit different. there are 3 levels, in a sense: 1. wire protocol 2. wrapping the wire protocol into domain model classes 3. having business logic like what topics are internal in the request classes (or calling helper methods for that from within the request classes) as we discussed previous , i think we should really do `1`, but we do `2` in a number of places. this suggestion is `3`. in any case, i'm ok if we do it in a static factory method as a starting point (and we can move it elsewhere in the future in a separate pr maybe).",0,0.9799525141716003
60770343,1095,SinghAsDev,2016-04-22T16:59:21Z,"ok, thanks for the explanation.",0,0.8439971208572388
60770562,1095,SinghAsDev,2016-04-22T17:00:59Z,"something that would capture the following, need not be this verbose though.",0,0.597022533416748
60770887,1095,ijuma,2016-04-22T17:03:39Z,"generally, i'm against adding unused methods until we actually need to use them. i agree that this may make sense here from a consistency perspective, but even then i would lean towards not having it. if we do have it, then we should use it from a test, at least.",0,0.9576280117034912
60771090,1095,SinghAsDev,2016-04-22T17:05:24Z,"yea, i was just curious about reasoning, not specifically for the method.",0,0.5465701818466187
60771140,1095,ijuma,2016-04-22T17:05:55Z,legacy code is annoying. ;),-1,0.9841070175170898
60776015,1095,ijuma,2016-04-22T17:42:03Z,"the idea is to avoid mistakes. so, if someone gets the boolean logic inverted and passes some topics, then the validation would find that.",0,0.9782976508140564
60776076,1095,ijuma,2016-04-22T17:42:34Z,"by the way, i agree that this is a bit subjective.",-1,0.9102398157119751
60776472,1095,granthenke,2016-04-22T17:45:18Z,i will play around with some options and run it by you.,0,0.9787783622741699
60776680,1095,granthenke,2016-04-22T17:46:41Z,that information is useful for rack configuration on the broker. i am not sure if it needs to be in the protocol documentation for the metadata response.,0,0.9888085722923279
60776722,1095,ijuma,2016-04-22T17:46:58Z,"this method is the main hotspot when it comes to the performance of metadata requests, so we need to be careful about adding additional logic here. i should have added a comment saying that, maybe you could do that. under the assumption that unavailable nodes are rare, it seems like this change is safe.",0,0.9823403358459473
60776919,1095,ijuma,2016-04-22T17:48:21Z,why don't we return `option[int]` here?,0,0.9925376772880554
60776992,1095,ijuma,2016-04-22T17:48:51Z,is there a reason why we don't check that the value is the same as `no_controller_id`?,0,0.9930156469345093
60777018,1095,granthenke,2016-04-22T17:49:00Z,"this is used in `metadatarequesttest.testcontrollerid`. i will look at keeping it around or not. if i do, i will make sure hascontroller is tested too.",0,0.9927404522895813
60777028,1095,ijuma,2016-04-22T17:49:05Z,formatting nit: this could be on the previous line.,0,0.9887780547142029
60777369,1095,ijuma,2016-04-22T17:51:32Z,i agree that these changes (and also in the other file) are weird to include here.,-1,0.9781800508499146
60777637,1095,ijuma,2016-04-22T17:53:39Z,seems unnecessary since the superclass already defines it?,0,0.9798771739006042
60778171,1095,gwenshap,2016-04-22T17:57:17Z,"i actually like the deprecated constructors because we get explicit compile warnings when we bump versions and don't accidentally forget to update some of the places where they are called. if you are not convinced that having warnings to help with bumps is useful, i won't make you change it ;)",1,0.9854670763015747
60786052,1095,gwenshap,2016-04-22T18:51:22Z,"has the full scope of kip-4 though, if he knows it will be used, it is best to add it now (since the whole point was to add the lower-level apis now)",0,0.9820913672447205
60787278,1095,ijuma,2016-04-22T18:59:32Z,"this is an internal class, so methods can be added at any time though. the point was to update the wire protocol now as far as i know.",0,0.9902613759040833
60788788,1095,gwenshap,2016-04-22T19:09:55Z,"i don't think it is internal? it isn't in an ""internals"" package... it is a public class in ""common"". afaik, this makes it public? obviously it isn't as widely used as kafkaproducer, but my understanding was that anything not in a package called ""internals"" is public?",0,0.9561747312545776
60789535,1095,ijuma,2016-04-22T19:14:58Z,"today the only public classes are the ones we generate javadoc for (this was confirmed by jay and neha). we don't generate the javadoc for the request classes. as you know, i think this is very confusing and i want to change it so that we use internals packages across the board.",0,0.5343096256256104
60801036,1095,ijuma,2016-04-22T20:49:31Z,this is doing the same thing as the `controllerid` line. i think you meant to get the controller id from `metadataresponse`.,0,0.9940308928489685
60801175,1095,ijuma,2016-04-22T20:50:37Z,don't you mean to use `controllerserver2` and `metadataresponse2`?,0,0.9941501617431641
60801224,1095,ijuma,2016-04-22T20:51:00Z,"typo, `what's`.",0,0.969717264175415
60801286,1095,ijuma,2016-04-22T20:51:25Z,nitpicks: `()` not needed in `brokers` and `rack`.,0,0.9945197701454163
60801527,1095,ijuma,2016-04-22T20:53:21Z,there's a few other examples in this file.,0,0.9852153062820435
60801878,1095,ijuma,2016-04-22T20:55:59Z,can we rely on the ordering of the metadata in the response and of the partition metadata?,0,0.9947509169578552
60802099,1095,ijuma,2016-04-22T20:57:50Z,"nitpick: for cases like this, i think it's more readable to have the opening brace after `=>`. for cases where the opening brace can replace the opening parenthesis, it makes sense to position the brace like this case. a bit subjective though.",-1,0.5958958268165588
60802287,1095,ijuma,2016-04-22T20:58:51Z,same question for a couple of other cases like this below.,0,0.9893466830253601
60802721,1095,ijuma,2016-04-22T21:02:08Z,how do we know that there are always 3 brokers? i guess the intent is that subclasses will use this in `generateconfigs` but that seems easy to miss. we could define this as a def and let the subclasses define it. or we could implement `generateconfigs` here and call an abstract method `generateconfig(brokerid)` or something.,0,0.9909875988960266
60802854,1095,ijuma,2016-04-22T21:03:19Z,the 3 methods above seem to be used in many tests. would it make sense to have a utility class or trait that people can mix-in?,0,0.9936943650245667
60802895,1095,ijuma,2016-04-22T21:03:40Z,nitpick: `correlationid += 1`,0,0.9866886734962463
60802936,1095,ijuma,2016-04-22T21:04:09Z,this seems to be unused?,0,0.9408588409423828
60809216,1095,gwenshap,2016-04-22T22:03:27Z,"got it. thanks for clarifying. if we can modify it at any time, there's really no point in including ""may need"" features.",1,0.9393705129623413
60939173,1095,granthenke,2016-04-25T16:01:04Z,"it is unused, i just need to call parse to ensure it parses correctly and moves the buffer forward. i can remove the val assignment though.",0,0.9833521246910095
60940329,1095,granthenke,2016-04-25T16:08:16Z,"there is definitely a better way to share this test code across other tests. i would like to do this cleanup, but would you mind if i open a separate jira to track that and do it shortly after this patch?",0,0.9892721176147461
60940596,1095,ijuma,2016-04-25T16:09:48Z,"sounds good to me. also, please add a comment as side-effects like that are not obvious.",1,0.9587194323539734
60940760,1095,ijuma,2016-04-25T16:10:53Z,sure.,0,0.9664214849472046
60943982,1095,granthenke,2016-04-25T16:30:16Z,i moved the configuration to the baserequesttest and provided a way to override the properties in the subclass.,0,0.992745578289032
60944350,1095,granthenke,2016-04-25T16:32:36Z,since i am asking for only 1 topic and that topic has only 1 partition it shouldn't matter here.,0,0.9728556275367737
60946083,1095,granthenke,2016-04-25T16:44:19Z,since any negative value is invalid i map it to none.,0,0.9606940150260925
60946121,1095,granthenke,2016-04-25T16:44:37Z,yeah i should return the option here and use `metadataresponse.no_controller_id` kafkaapis.,0,0.9946188926696777
60946477,1095,granthenke,2016-04-25T16:46:54Z,i will add the comment.,0,0.9786132574081421
60948003,1095,granthenke,2016-04-25T16:55:56Z,i have added comments that they only exist in v1+,0,0.9906314611434937
60948570,1095,granthenke,2016-04-25T16:59:26Z,"i think it actually ends up being a bit of ""crying wolf"" since the brokers would be required to use the old constructors to support the old versions. we would throw, and likely suppress, the deprecation warnings in that case. i think unit tests are the best way to verify this behavior. i will work on increasing the version coverage on this patch and consider updating other apis at a later time.",0,0.9497479796409607
60951090,1095,granthenke,2016-04-25T17:15:52Z,i would like to leave it for use in unit tests and also with the expectation that it will be used shortly. i will remove any method that is not being used or tested.,0,0.9891586303710938
60963008,1095,granthenke,2016-04-25T18:26:59Z,this can fall through because the constructor supports version 0 and 1. the version is passed as the last parameter. this is related to the discussion here: [a link],0,0.9900387525558472
60963844,1095,gwenshap,2016-04-25T18:31:45Z,sounds good!,1,0.9947521686553955
60963946,1095,ijuma,2016-04-25T18:32:19Z,"the issue with this approach is that we accept instead of failing when we receive invalid values. in some cases, this can lead to bugs being missed.",0,0.9644754528999329
61162466,1095,ijuma,2016-04-26T20:54:58Z,we can call `isalltopics` on `request` and remove the comment about `null`,0,0.9945703148841858
61163654,1095,ijuma,2016-04-26T21:01:33Z,"i think it's important to be clear about the expected usage of methods like this. either we return a new instance or we mutate the passed instance. given how `properties` are generally used, isn't it better to just not return `properties`?",0,0.9835702180862427
61163744,1095,ijuma,2016-04-26T21:02:09Z,shall we add a helpful message via `getorelse`?,0,0.9930223822593689
61164103,1095,ijuma,2016-04-26T21:04:35Z,the second argument to `assertequals` could be `controllerid` right?,0,0.9948669672012329
61164205,1095,ijuma,2016-04-26T21:05:17Z,"this is kind of weird, we should probably get the broker id from the config (ie `controllerserver.config.brokerid`) or add a method to `kafkaserver` that returns the broker id.",-1,0.9638099074363708
61164585,1095,ijuma,2016-04-26T21:07:39Z,it's a bit weird that we assert that failover happened and then we wait until failover happens. shouldn't the `waituntiltrue` be before anything else?,-1,0.9762218594551086
61165412,1095,ijuma,2016-04-26T21:13:00Z,we should also include an assert for the field we can use to know that a replica is down.,0,0.9910182952880859
61178157,1095,granthenke,2016-04-26T22:50:00Z,this is because the failover is basically immediate when looking up the servers directly via: [code block] but propagating that state to the metadatacache and therefore the metadataresponse could take a bit of time and requires the `testutils.waituntiltrue`,0,0.9929798245429993
61178707,1095,granthenke,2016-04-26T22:55:27Z,will add a check to confirm the downed broker is not in the brokers list,0,0.9881097078323364
61178731,1095,granthenke,2016-04-26T22:55:41Z,will change to config,0,0.9901356101036072
61182686,1095,ijuma,2016-04-26T23:36:29Z,thanks for the explanation.,0,0.8456202745437622
341684130,7629,mjsax,2019-11-01T17:53:06Z,"`application`? the operator are named, not the application?",0,0.9933692812919617
341686787,7629,mjsax,2019-11-01T17:59:30Z,"should this be a paragraph, ie, wrapped with ` ... ` tags? same below.",0,0.9943047165870667
341687086,7629,mjsax,2019-11-01T18:00:12Z,"this is not the upgrade section, hence, i would remove the reference to `2.4` and the word `now`.",0,0.9930163621902466
341687746,7629,mjsax,2019-11-01T18:01:54Z,"`prefixed` -> the ""suffix"" is ""prefixed"" -- quite hard to read. also, are the details of the `number-suffix` format relevant?",0,0.8482148051261902
341689152,7629,mjsax,2019-11-01T18:05:23Z,"we should be a little bit more clear. at papi level, there are `processors` and `statestores` and people need to name the explicitly. at the dsl, we have operators, and an operator may compile down to multiple `processors, `statestores`, and `repartition-topic`, and all those are name automatically, and there is a relationship between the processor-name and the store/changelog topic name and repartition topic names.",0,0.9914701581001282
341695265,7629,mjsax,2019-11-01T18:20:38Z,nit: remove version reference,0,0.9791879057884216
341695374,7629,mjsax,2019-11-01T18:20:56Z,nit: remove `now`,0,0.9894056916236877
341696372,7629,mjsax,2019-11-01T18:23:29Z,"should this be formatted with ""single line per operator"" to make it easier to read (and to align with the formatting of the other code snippets?",0,0.994203507900238
341696731,7629,mjsax,2019-11-01T18:24:23Z,"does this render correctly? i think, ` ` does not remove ""indenting whitespaces"" and thus this would render the indention...",0,0.9669812917709351
341707445,7629,mjsax,2019-11-01T18:52:05Z,nit: ` before ` ?,0,0.9894192218780518
341707858,7629,mjsax,2019-11-01T18:53:20Z,"`with the joined, streamjoined, or grouped classed`",0,0.9928305745124817
341708595,7629,mjsax,2019-11-01T18:55:01Z,`even though you've added processors before your state store` -> `with or without the filter operation`,0,0.9936563372612
341709276,7629,mjsax,2019-11-01T18:56:52Z,"nit: `:` should be on line above `topolog:` -- otherwise it will be rendered as `topolog :` (ie, with a ws in between)",0,0.9942758679389954
341709757,7629,mjsax,2019-11-01T18:58:08Z,"for `kstream-ktable` joins, it's still `joined`, right? so we need to add one line to the column?",0,0.9947032332420349
341710210,7629,mjsax,2019-11-01T18:59:16Z,for aggregations and ktables-ktable joins right? to distinguish the `kstream-kstream` join case?,0,0.9951525926589966
341881771,7629,ableegoldman,2019-11-04T00:02:03Z,"how about ""naming operators in a streams dsl application""?",0,0.9945576190948486
341881852,7629,ableegoldman,2019-11-04T00:03:23Z,nit: remove comma after 'dsl',0,0.9924039244651794
341882038,7629,ableegoldman,2019-11-04T00:07:16Z,"i agree it's not necessary to mention the details here, but i do think it's appropriate to briefly explain where the compatibility or ""name shifting"" issue comes from in the `changing names` section below",0,0.9655976295471191
341882125,7629,ableegoldman,2019-11-04T00:08:57Z,"have you considered any alternative names for this section/trade-off? ""cognitive issues"" seems to have a weird connotation, what about just `readability` or `readability problems`?",0,0.6947609782218933
341882260,7629,ableegoldman,2019-11-04T00:11:22Z,"are you referring to repartition topics, or users failing to name their topics meaningfully? we should definitive make it clear they are encouraged to name things meaningfully, and it seems weird to expect users to choose meaningful names for their operators but not for their topics",-1,0.8204801678657532
341882442,7629,ableegoldman,2019-11-04T00:15:10Z,"i personally find it more readable when everything is in its own section, eg the section beginning ""but there's another reason..."" was moved to the `changing names` section whose topic it's actually referring to. but feel free to leave as-is if you or anyone else disagrees",0,0.9654683470726013
341882738,7629,ableegoldman,2019-11-04T00:20:47Z,"i'm finding the comment about **most** processors existing in memory only a bit confusing -- maybe just use the term ""stateless"" instead? also, i think it's a bit misleading to say that ""because most are stateless, this shifting presents no issue"" -- maybe rephrase to something like ""many processors are stateless and therefore exist in memory only, so this name shifting on topology change presents no issue to applications built entirely of such operators."" ?",0,0.7685863971710205
341883192,7629,ableegoldman,2019-11-04T00:29:55Z,"""give the state store a constant user-defined name instead of relying...""",0,0.9743698239326477
341883257,7629,ableegoldman,2019-11-04T00:31:12Z,nit: replace `--` with `such as`,0,0.9926416277885437
341883357,7629,ableegoldman,2019-11-04T00:33:07Z,"nit: `transient` --> `stateless` ? i think it's good to be consistent in our terminology throughout the docs -- it might be obvious to us that ""stateless"", ""in-memory"", and ""transient"" all refer to the same thing, but i think users will find this confusing.",0,0.9731827974319458
342141293,7629,bbejeck,2019-11-04T16:24:57Z,ack,0,0.8596508502960205
342150101,7629,bbejeck,2019-11-04T16:41:15Z,ack,0,0.8596508502960205
342151782,7629,bbejeck,2019-11-04T16:44:25Z,"i'll clean this up some, but i'd prefer to leave this here to set the stage for the `changing names` section.",0,0.9873254299163818
342186088,7629,bbejeck,2019-11-04T17:54:38Z,ack,0,0.8596508502960205
342269064,7629,bbejeck,2019-11-04T21:04:28Z,ack,0,0.8596508502960205
342270140,7629,bbejeck,2019-11-04T21:07:09Z,ack,0,0.8596508502960205
342270257,7629,bbejeck,2019-11-04T21:07:28Z,ack,0,0.8596508502960205
342271483,7629,bbejeck,2019-11-04T21:10:33Z,ack,0,0.8596508502960205
342271670,7629,bbejeck,2019-11-04T21:11:03Z,"that's what i wanted, but is the indentation not correct?",0,0.9443240165710449
342271794,7629,bbejeck,2019-11-04T21:11:24Z,ack,0,0.8596508502960205
342271936,7629,bbejeck,2019-11-04T21:11:45Z,ack,0,0.8596508502960205
342272114,7629,bbejeck,2019-11-04T21:12:11Z,ack,0,0.8596508502960205
342272560,7629,bbejeck,2019-11-04T21:13:14Z,ack,0,0.8596508502960205
342272791,7629,bbejeck,2019-11-04T21:13:51Z,ack,0,0.8596508502960205
342273114,7629,bbejeck,2019-11-04T21:14:45Z,ack,0,0.8596508502960205
342273794,7629,bbejeck,2019-11-04T21:16:27Z,my point here is that most users won't have control over topic names. they'll build a streams application to work with existing topics.,0,0.9846253395080566
342274069,7629,bbejeck,2019-11-04T21:17:07Z,ack,0,0.8596508502960205
342274140,7629,bbejeck,2019-11-04T21:17:17Z,ack,0,0.8596508502960205
342274425,7629,bbejeck,2019-11-04T21:18:03Z,ack,0,0.8596508502960205
342274497,7629,bbejeck,2019-11-04T21:18:14Z,ack,0,0.8596508502960205
342274660,7629,bbejeck,2019-11-04T21:18:39Z,ack,0,0.8596508502960205
342275213,7629,bbejeck,2019-11-04T21:19:53Z,ack,0,0.8596508502960205
342275977,7629,bbejeck,2019-11-04T21:21:43Z,ack,0,0.8596508502960205
342276210,7629,bbejeck,2019-11-04T21:22:18Z,ack,0,0.8596508502960205
342276356,7629,bbejeck,2019-11-04T21:22:41Z,ack,0,0.8596508502960205
342276577,7629,bbejeck,2019-11-04T21:23:13Z,ack,0,0.8596508502960205
342658799,7629,bbejeck,2019-11-05T16:24:07Z,"i think it fits where i had it originally, but you are correct about it being in the same section as well. if i kept it in the original location, i should at least repeat the information in the `changing names` section. but i opted to take your suggestion and just move it there altogether",0,0.9658732414245605
342659633,7629,bbejeck,2019-11-05T16:25:33Z,ack,0,0.8596508502960205
342659990,7629,bbejeck,2019-11-05T16:26:08Z,ack,0,0.8596508502960205
342662764,7629,bbejeck,2019-11-05T16:30:36Z,ack,0,0.8596508502960205
342664122,7629,bbejeck,2019-11-05T16:32:41Z,ack,0,0.8596508502960205
342664196,7629,bbejeck,2019-11-05T16:32:50Z,ack,0,0.8596508502960205
342665851,7629,bbejeck,2019-11-05T16:35:39Z,ack,0,0.8596508502960205
342667608,7629,bbejeck,2019-11-05T16:38:49Z,ack,0,0.8596508502960205
342668807,7629,bbejeck,2019-11-05T16:41:02Z,ack,0,0.8596508502960205
342669710,7629,bbejeck,2019-11-05T16:42:28Z,ack,0,0.8596508502960205
342670496,7629,bbejeck,2019-11-05T16:43:43Z,ack,0,0.8596508502960205
342676589,7629,bbejeck,2019-11-05T16:54:24Z,"ack, i used something similar",-1,0.7891114354133606
342676930,7629,bbejeck,2019-11-05T16:55:01Z,ack,0,0.8596508502960205
342678646,7629,bbejeck,2019-11-05T16:58:12Z,ack,0,0.8596508502960205
342680311,7629,bbejeck,2019-11-05T17:01:20Z,ack,0,0.8596508502960205
342682536,7629,bbejeck,2019-11-05T17:05:33Z,ack,0,0.8596508502960205
342683837,7629,bbejeck,2019-11-05T17:08:03Z,ack,0,0.8596508502960205
342684647,7629,bbejeck,2019-11-05T17:09:43Z,ack,0,0.8596508502960205
342685100,7629,bbejeck,2019-11-05T17:10:34Z,ack,0,0.8596508502960205
342686001,7629,bbejeck,2019-11-05T17:12:14Z,ack,0,0.8596508502960205
342686440,7629,bbejeck,2019-11-05T17:13:06Z,ack,0,0.8596508502960205
342687361,7629,bbejeck,2019-11-05T17:14:50Z,ack,0,0.8596508502960205
342687629,7629,bbejeck,2019-11-05T17:15:23Z,ack,0,0.8596508502960205
342688024,7629,bbejeck,2019-11-05T17:16:06Z,ack,0,0.8596508502960205
342688356,7629,bbejeck,2019-11-05T17:16:40Z,ack,0,0.8596508502960205
342689620,7629,bbejeck,2019-11-05T17:19:10Z,ack with a slight tweek,-1,0.8258087038993835
342690110,7629,bbejeck,2019-11-05T17:20:11Z,good point,1,0.9655349254608154
342690641,7629,bbejeck,2019-11-05T17:21:20Z,ack,0,0.8596508502960205
342690865,7629,bbejeck,2019-11-05T17:21:42Z,ack,0,0.8596508502960205
342691755,7629,bbejeck,2019-11-05T17:23:21Z,good catch!,1,0.9947227239608765
342693339,7629,bbejeck,2019-11-05T17:26:23Z,ack,0,0.8596508502960205
342694351,7629,bbejeck,2019-11-05T17:28:30Z,"i'd prefer to keep this as is, but if you have a strong opinion on this, i'll make the change.",0,0.9615224003791809
342696400,7629,bbejeck,2019-11-05T17:32:41Z,ack,0,0.8596508502960205
342787455,7629,ableegoldman,2019-11-05T20:43:20Z,"q: what do you mean by `the generated processor-name state store`? and which topic names, changelog or input/output? i'm not sure i follow this sentence",0,0.9698960781097412
342819399,7629,ableegoldman,2019-11-05T21:58:57Z,"prop: i still find this sentence confusing but if others disagree i'll hold my peace...but how about something like ""...this name shifting presents no issue for many topologies"" or ""for any stateless topologies"" ?",-1,0.8719834685325623
342852018,7629,ableegoldman,2019-11-05T23:34:27Z,"prop: sentence reads a bit awkward, how about `...the state store (and changelog topic) names...` or `...the state store names (and changelog topics as well) have changed` ?",-1,0.8380701541900635
342854854,7629,ableegoldman,2019-11-05T23:44:54Z,"req: does it make sense for this section to go after the ""testing a streams application"" section? i would keep it together with the other dsl operators prop: do you think we should include a quick line about why you'd want to name things here? just wondering if we should protect against people who won't want to read the full manual, and won't realize that naming is essential for compatibility",0,0.9781230092048645
344388199,7629,bbejeck,2019-11-08T22:16:06Z,"i think it's a bit subjective. imho it should come after all the other operations are described as this is a ""meta-operation"". at any rate, i've moved it up closer, so it's the first item in the list after describing the other operations. i'm inclined to leave this as-is, it's just one click, and users can read the first paragraph.",0,0.6972037553787231
344393729,7629,bbejeck,2019-11-08T22:36:56Z,clarified some (i think). if it's still unclear i'll just remove it altogether.,0,0.9730392098426819
344401859,7629,bbejeck,2019-11-08T23:12:02Z,updated,0,0.968669593334198
344403668,7629,bbejeck,2019-11-08T23:20:50Z,ack,0,0.8596508502960205
344404824,7629,ableegoldman,2019-11-08T23:27:03Z,fair enough,0,0.8143565058708191
344405137,7629,ableegoldman,2019-11-08T23:28:37Z,:thumbs_up: this is a good point to drive home,1,0.8817506432533264
344406892,7629,ableegoldman,2019-11-08T23:38:02Z,"hm. is this roughly what you mean here: ""the processor name generated for a state store (and hence changelog topic name) will also be used in generating the repartition topic name"" or something to that affect? or even replacing `generated processor-name state store` with `state store's generated processor name` or `generated processor-name of a state store`?",0,0.9948166012763977
344474564,7629,mjsax,2019-11-10T06:22:20Z,"this example has a similar issue: [a link] note that the first block of the code example has a larger indention as the last two lines. if you compare with the docs files, the first block has whitespace: [a link] the last two lines don't have and render correctly: [a link] the example i picked uses ` ` tag but i think ` ` work the same way.",0,0.9842055439949036
344474629,7629,mjsax,2019-11-10T06:25:06Z,nit: remove whitespace in ` repartition...`,0,0.9894819259643555
344474691,7629,mjsax,2019-11-10T06:27:05Z,"-> `processor names, state store names (and hence changelog topics names), and repartition topic names` if you don't repeat `names` (note plural) it's hard to read -- and not `-` in `processor names`.",0,0.9927108287811279
344474755,7629,mjsax,2019-11-10T06:29:58Z,"why `but`? maybe better, `note, that the names of state stores and changelog/repartition topics are ""stateful"" while processor names are ""stateless"".` i would not use ` ` but put into quote -- a name is not really stateful, but i understand what you want to say. again, no `-` in `processor names`",0,0.9851980805397034
344474790,7629,mjsax,2019-11-10T06:31:45Z,"i think, ` ` tag has similar indentation issue as ` ` tag -- compare my other comment. (there are more ` ` tags below -- won't comment on them but please fix all)",0,0.9801172614097595
344474827,7629,mjsax,2019-11-10T06:33:58Z,missing ` ` tag,0,0.9866808652877808
344474843,7629,mjsax,2019-11-10T06:34:20Z,missing ` ` tag,0,0.9866808652877808
344474850,7629,mjsax,2019-11-10T06:34:31Z,missing ` ` tag,0,0.9866808652877808
344474854,7629,mjsax,2019-11-10T06:34:36Z,missing ` ` tag,0,0.9866808652877808
344474856,7629,mjsax,2019-11-10T06:34:44Z,missing ` ` tag,0,0.9866808652877808
344474861,7629,mjsax,2019-11-10T06:35:07Z,missing ` ` tag (there seems to be more below; please fix),0,0.9900867342948914
345833885,7629,bbejeck,2019-11-13T15:43:14Z,ack,0,0.8596508502960205
345833978,7629,bbejeck,2019-11-13T15:43:23Z,ack,0,0.8596508502960205
345834082,7629,bbejeck,2019-11-13T15:43:33Z,ack,0,0.8596508502960205
345834190,7629,bbejeck,2019-11-13T15:43:43Z,ack,0,0.8596508502960205
345834273,7629,bbejeck,2019-11-13T15:43:51Z,ack,0,0.8596508502960205
345834384,7629,bbejeck,2019-11-13T15:44:01Z,ack,0,0.8596508502960205
418108095,8589,abbccdda,2020-04-30T15:45:14Z,could we pass the members into the context?,0,0.9917829036712646
420339593,8589,abbccdda,2020-05-05T19:03:29Z,remove print statements,0,0.9849631190299988
420340211,8589,abbccdda,2020-05-05T19:04:30Z,"curious why we are still continuing in this case, as the member lookup already fails.",-1,0.5810550451278687
420341894,8589,abbccdda,2020-05-05T19:07:17Z,could we just make members to be `optional >` so that we don't need a separate removeall parameter?,0,0.9949473142623901
420344946,8589,abbccdda,2020-05-05T19:12:50Z,style error here. i would recommend doing a self style check like: `./gradlew checkstylemain checkstyletest spotbugsmain spotbugstest spotbugsscoverage compiletestjava` otherwise we still need to fix those failures after we do jenkins build.,0,0.9932156205177307
420568190,8589,feyman2016,2020-05-06T06:23:45Z,"thanks for the advice, will fix it in the next commit.",0,0.8187974691390991
420806232,8589,feyman2016,2020-05-06T13:50:14Z,"sure. taking a step further, can we just keep the the type `set ` for `members` unchanged and treat it as `removeall` if the `members` is empty set?",0,0.9947539567947388
420824271,8589,feyman2016,2020-05-06T14:13:08Z,"my initial thought was to put the `members` in the context, but hesitated to do so because the `consumergroupoperationcontext` seems to be for generic usage. so i just refer to `kafkaadminclient#getalterconsumergroupoffsetscall` and make the members as a separate input param. anyway, i'm glad to make the change if we think it's preferred to put the `members` in context.",1,0.5654714107513428
420824572,8589,feyman2016,2020-05-06T14:13:32Z,fixed~,0,0.9644737839698792
420848223,8589,feyman2016,2020-05-06T14:43:57Z,"thanks, will fix this .",1,0.8852622509002686
421216617,8589,feyman2016,2020-05-07T03:24:17Z,fixed,0,0.9281549453735352
421216746,8589,feyman2016,2020-05-07T03:24:43Z,updated~,0,0.9824756383895874
421216977,8589,feyman2016,2020-05-07T03:25:42Z,"i reran the self style check, but didn't capture any error. i assume the error would be the missed `final` in for loop, updated.",0,0.9900771379470825
424198050,8589,abbccdda,2020-05-13T06:23:08Z,nit: space before `:`,0,0.9874399900436401
424510483,8589,abbccdda,2020-05-13T15:04:03Z,"yes, i feel this is more consistent for internal calls not to do a second round of interpretation for which `members` set to use.",0,0.9618322849273682
424512993,8589,abbccdda,2020-05-13T15:07:20Z,nit: remove extra line,0,0.9760728478431702
424516058,8589,abbccdda,2020-05-13T15:11:24Z,should be collection.emptylist(),0,0.9924386143684387
424517564,8589,abbccdda,2020-05-13T15:13:24Z,"why do we blindly put `allmembers`? i believe we base on context to interpret, but like discussed earlier, this is easy to make mistake, we should rely on one source for members.",0,0.9806259870529175
424518540,8589,abbccdda,2020-05-13T15:14:40Z,"and to be clear, i'm not suggesting we have to put stuff into the context, just always passing in the intended removal list and do not depend on `context.removeall` again inside internal function.",0,0.9798921942710876
424522056,8589,abbccdda,2020-05-13T15:19:18Z,not necessary change,0,0.9071323275566101
424522792,8589,abbccdda,2020-05-13T15:20:13Z,nit: space after `empty_group_instance_id`,0,0.9938281178474426
424524146,8589,abbccdda,2020-05-13T15:22:05Z,could we specify the return type?,0,0.9929577112197876
424525171,8589,abbccdda,2020-05-13T15:23:22Z,"i don't think we really need this struct, could we just put `null` in `groupinstanceset`?",0,0.9821276664733887
424525436,8589,abbccdda,2020-05-13T15:23:44Z,nit: space,0,0.8302400708198547
424525798,8589,abbccdda,2020-05-13T15:24:16Z,why do we suppress here?,0,0.9552109241485596
424527021,8589,abbccdda,2020-05-13T15:25:51Z,remained -> remaining,0,0.9649994373321533
424529767,8589,abbccdda,2020-05-13T15:29:16Z,do we also want to edit the `usage` info on top to mention the force delete option?,0,0.9945589900016785
428579361,8589,feyman2016,2020-05-21T10:47:11Z,"i think so, updated",0,0.9363871216773987
428580805,8589,feyman2016,2020-05-21T10:50:37Z,fixed~,0,0.9644737839698792
428581576,8589,feyman2016,2020-05-21T10:52:32Z,fixed,0,0.9281549453735352
428583883,8589,feyman2016,2020-05-21T10:58:19Z,"fixed, now we explicitly pass in the members to be deleted to the private `getremovemembersfromgroupcall`",0,0.9939026832580566
428585120,8589,feyman2016,2020-05-21T11:01:17Z,reverted,0,0.9411051869392395
428585373,8589,feyman2016,2020-05-21T11:01:53Z,fixed,0,0.9281549453735352
428585617,8589,feyman2016,2020-05-21T11:02:29Z,refactored,0,0.9819386005401611
428586730,8589,feyman2016,2020-05-21T11:05:08Z,"i feel like this is more informative, so didn't update it, but yeah, i can update if we really not prefer this~",1,0.7330914735794067
428587018,8589,feyman2016,2020-05-21T11:05:49Z,fixed,0,0.9281549453735352
428588172,8589,feyman2016,2020-05-21T11:08:27Z,fixed,0,0.9281549453735352
428589350,8589,feyman2016,2020-05-21T11:11:16Z,"didn't change the exception handling logic here, just extract the thread creation logic to reuse~",0,0.9898579716682434
428745517,8589,abbccdda,2020-05-21T15:51:55Z,i think we should catch `exception` here: [a link],0,0.9879961609840393
428748938,8589,abbccdda,2020-05-21T15:56:31Z,"this indentation is a bit weird, let's just merge l3625-3626",-1,0.9747079014778137
428751049,8589,abbccdda,2020-05-21T16:00:08Z,let's get back the original indentation.,0,0.9862045049667358
428752600,8589,abbccdda,2020-05-21T16:02:44Z,nit: we could merge l3666-3667,0,0.9925267696380615
428753012,8589,abbccdda,2020-05-21T16:03:26Z,nit: we could name it `members` now,0,0.9912936091423035
428756738,8589,abbccdda,2020-05-21T16:09:52Z,i could see this doesn't hold true for a plain static member removal. let's discuss why skipping the individual member check in `removemembersfromconsumergroupresult` makes sense over there.,0,0.9931554198265076
428757676,8589,abbccdda,2020-05-21T16:11:25Z,collections.emptyset() makes more sense since it is immutable.,0,0.9894223809242249
428758681,8589,abbccdda,2020-05-21T16:13:16Z,"in `removeall()` mode, why could we skip the individual member removal results? i guess although we don't need to verify against the original member list (because they don't exist for `removeall`), going throw the sub error list is still valuable to make sure there is no unexpected failure.",0,0.9914243221282959
428758798,8589,abbccdda,2020-05-21T16:13:27Z,remove print statement.,0,0.9868919253349304
428762047,8589,abbccdda,2020-05-21T16:19:03Z,"this test looks good, but it seems that we didn't test the case where some members get deleted successfully while some are not?",0,0.747650682926178
428763784,8589,abbccdda,2020-05-21T16:22:10Z,"should we check the member removal result here before proceeding? if that call failed, the whole operation should fail with error message containing the result imho.",0,0.9903256893157959
428764977,8589,abbccdda,2020-05-21T16:24:15Z,fair enough,0,0.8143565058708191
428767771,8589,abbccdda,2020-05-21T16:28:56Z,does this check duplicate l1103? also i think it makes sense to check all the members' clientid as they should all equal to `testclientid`,0,0.9944729208946228
428769255,8589,abbccdda,2020-05-21T16:31:25Z,"i prefer `testinstanceidone = ""test_instance_id_1""` and `testinstanceidtwo = ""test_instance_id_2""`",0,0.9901307821273804
428770028,8589,abbccdda,2020-05-21T16:32:48Z,size - 1,0,0.8606421947479248
428770176,8589,abbccdda,2020-05-21T16:33:09Z,we could remove this comment for now,0,0.985000729560852
428770601,8589,abbccdda,2020-05-21T16:33:50Z,nit: format i'm pretty surprised this wasn't caught in my previous template. let me check how to cover this in style test as well.,-1,0.9060715436935425
428771346,8589,abbccdda,2020-05-21T16:35:08Z,"what does `"""" + ` mean?",0,0.9892204403877258
428772089,8589,abbccdda,2020-05-21T16:36:25Z,nit: parameters are not aligned.,0,0.8383051753044128
428772936,8589,abbccdda,2020-05-21T16:37:52Z,"like said earlier, i think we could just return `return new streamsresetter().run(parameters, cleanupconfig) == 0`",0,0.9908732175827026
428773173,8589,abbccdda,2020-05-21T16:38:16Z,"we could add meta comment for the return value here, and instead of returning an exit code, i feel a boolean is suffice to indicate whether the clean operation was successful or not.",0,0.9835648536682129
429070319,8589,feyman2016,2020-05-22T06:43:25Z,"indeed, updated as suggested",0,0.9902939796447754
429070411,8589,feyman2016,2020-05-22T06:43:39Z,updated,0,0.968669593334198
429071232,8589,feyman2016,2020-05-22T06:46:07Z,fixed,0,0.9281549453735352
429082038,8589,feyman2016,2020-05-22T07:16:49Z,"without the `"""" +` to convert the value to string, we will get exception like: it is because `streams_consumer_timeout = 2000l`, `""""+` is widely used in this test, just follow it here without any change to not enlarge the scope of this pr, i can help to create a jira to enhance it if we think this workaround is not quite intuitive~ [code block]",0,0.9876590371131897
429082487,8589,feyman2016,2020-05-22T07:18:01Z,"thanks, but i wonder what does the **template** refer to here?",1,0.6725108027458191
429083564,8589,feyman2016,2020-05-22T07:20:46Z,"removed, but curious about the reason :)",1,0.9699071645736694
429083611,8589,feyman2016,2020-05-22T07:20:54Z,fixed,0,0.9281549453735352
429083674,8589,feyman2016,2020-05-22T07:21:04Z,fixed,0,0.9281549453735352
429083960,8589,feyman2016,2020-05-22T07:21:45Z,"thanks, all members' clientid are checked now",1,0.7817531228065491
429084219,8589,feyman2016,2020-05-22T07:22:22Z,"agreed, fixed",0,0.9735358357429504
429084559,8589,feyman2016,2020-05-22T07:23:04Z,good catch! added the test for partial failure,1,0.9923529028892517
429084786,8589,feyman2016,2020-05-22T07:23:40Z,"make sense, fixed",0,0.9569265842437744
429086933,8589,feyman2016,2020-05-22T07:28:59Z,"yeah, just as you surmised, but you are right, we should scan the removal results as well. slightly updated, followed the convention of `non-removeall` scenario, just return with the first exception",0,0.9855964183807373
429087051,8589,feyman2016,2020-05-22T07:29:17Z,"yeah, fixed",0,0.9209061861038208
429087133,8589,feyman2016,2020-05-22T07:29:27Z,updated,0,0.968669593334198
429087216,8589,feyman2016,2020-05-22T07:29:38Z,fixed,0,0.9281549453735352
429087282,8589,feyman2016,2020-05-22T07:29:48Z,fixed,0,0.9281549453735352
429087492,8589,feyman2016,2020-05-22T07:30:17Z,"make sense, fixed~",0,0.9046199917793274
429133442,8589,feyman2016,2020-05-22T09:11:18Z,fixed,0,0.9281549453735352
429145185,8589,feyman2016,2020-05-22T09:35:24Z,"for removing static members, this still true because we put memberid as `""""` in the request, and the server will also response with the same request field. (verified `groupcoordinator#handleleavegroup`) for removing dynamic members, we need this change to know the memberid for the caller. i suppose the `individual check` here is just to check the response against the members to be removed(for `removeall` scenario)? previously i thought of putting all members got from `kafkaadminclient#getmembersfromgroup` in the removemembersfromconsumergroupresult for checking, but in `removeall` scenario, we get members as `memberidentity` which cannot be converted back to `membertoremove`, so i'm hesitate to do in this way",0,0.994737446308136
429276600,8589,feyman2016,2020-05-22T14:22:23Z,wrap to let the failed member info available for caller like `streamsresetter`. only capture the first found member error like in the non `removeall` scenario.,0,0.9934874773025513
429329313,8589,abbccdda,2020-05-22T15:57:04Z,nit: extra semi-colon,0,0.9834721088409424
429333199,8589,abbccdda,2020-05-22T16:11:06Z,"let's put the exception in the cause so that we could verify the cause in `kafkaadminclienttest`, as: [code block]",0,0.9941733479499817
429333355,8589,abbccdda,2020-05-22T16:11:21Z,"nit: we could set `""0""` to `joingrouprequest.unknown_member_id` if we don't want to test it out. having all members use the same member.id is a bit weird.",-1,0.9732730984687805
429333999,8589,abbccdda,2020-05-22T16:12:30Z,nit: space after `*`. also i feel we could make the context more concrete by: [code block],0,0.982192873954773
429338025,8589,abbccdda,2020-05-22T16:20:11Z,"i see, this is indeed weird, please file a jira so that we could clean in a follow-up pr if others feel the same way.",-1,0.9735636711120605
429404004,8589,abbccdda,2020-05-22T18:50:06Z,this is no longer used.,0,0.9741581082344055
429504184,8589,feyman2016,2020-05-23T01:57:09Z,"cool, updated",1,0.9558495283126831
429504532,8589,feyman2016,2020-05-23T02:01:24Z,no existing help method to assert the cause of exception throw by `all()`. also i think it's more straight forward in this way.,0,0.9849990010261536
429504600,8589,feyman2016,2020-05-23T02:02:25Z,removed,0,0.9801433682441711
429504705,8589,feyman2016,2020-05-23T02:04:05Z,"indeed, updated",0,0.9791411757469177
429504725,8589,feyman2016,2020-05-23T02:04:26Z,"yeah, updated",0,0.9622759819030762
429507189,8589,feyman2016,2020-05-23T02:44:53Z,"created [a link] for tracking, thanks!",1,0.988438069820404
430828662,8589,mjsax,2020-05-27T02:51:46Z,why do we need this part? seems sufficient to end the test here?,0,0.9777506589889526
430828933,8589,mjsax,2020-05-27T02:52:49Z,"with `cleanglobal` and `--force` the consumer group could be empty when `cleanglobal` returns, right? hence, we should do this assertion without timeout or retries?",0,0.9948763251304626
430830840,8589,mjsax,2020-05-27T03:00:33Z,"if `option.members()` is empty, it implies that we do a `removeall()` -- hence, should we pass in `members` into the `removemembersfromconsumergroupresult` instead of `options.members()` ?",0,0.9957172274589539
430831033,8589,mjsax,2020-05-27T03:01:24Z,nit: fix formatting: [code block],0,0.9866669774055481
430832010,8589,mjsax,2020-05-27T03:05:21Z,not sure if i understand the change. also not sure if i can follow the comments. can you elaborate?,0,0.8581374883651733
430832423,8589,mjsax,2020-05-27T03:07:09Z,"as we have different semantics for an empty collection (it was ""remove nothing"" originally, and we change it to ""remove all""), i am wondering if we should do a check if `members` is empty or not and throw an exception if empty? or at least log a warning that empty implies ""remove all"" now?",0,0.9890135526657104
430833520,8589,mjsax,2020-05-27T03:12:09Z,not sure why the `removeall()` case needs to be handled differently? can you elaborate?,0,0.9786192774772644
430833928,8589,mjsax,2020-05-27T03:13:55Z,"why that? i understand that we expect that users don't know the memberid if the so a ""remove all""; however, i don't see why we need to disallow this call? can you elaborate?",0,0.9276449680328369
430834203,8589,mjsax,2020-05-27T03:15:16Z,nit: formatting [code block],0,0.9890828132629395
430835656,8589,mjsax,2020-05-27T03:21:36Z,nit: formatting: move `new newtopic(...)` to next line,0,0.9931267499923706
431247169,8589,feyman2016,2020-05-27T15:48:10Z,"this is to verify that after the `successfully force removal of active members`, the stream application re-run can send exactly the same records again to the output topics",0,0.9942337870597839
431266629,8589,feyman2016,2020-05-27T16:11:11Z,"--- if option.members() is empty, it implies that we do a removeall() => yes, that is correct. --- hence, should we pass in members into the removemembersfromconsumergroupresult instead of options.members() => the members is of type `list ` and `memberidentity` contains field: `memberid` which supports the removal of dynamic members, while `options.members()` is of type: `set `, membertoremove only supports static member removal specification, in removemembersfromconsumergroupresult we treat similarly like in `removemembersfromconsumergroupoptions`, empty `members` implies `removeall`, we handle it in this way because we think in `non removeall` scenario we would only remove static members, while in `removeall` scenario we may remove both static and dynamic members.",0,0.9938404560089111
431302352,8589,feyman2016,2020-05-27T17:02:53Z,"because in non `removeall` scenario, we have put the members to be deleted in the `removemembersfromconsumergroupresult#memberinfos`, while in the `removeall` scenario, we don't do so(members to be deleted are decided in the private method: `kafkaadminclient#getmembersfromgroup` of `kafkaadminclient`).",0,0.9959360361099243
431305795,8589,feyman2016,2020-05-27T17:08:53Z,"since in the `removeall` scenario, we don't save the members to be deleted in `removemembersfromconsumergroupresult`, so i think calling `memberresult` doesn't seem applicative.",0,0.9854845404624939
431312462,8589,feyman2016,2020-05-27T17:20:23Z,fixed,0,0.9281549453735352
431313074,8589,feyman2016,2020-05-27T17:21:25Z,make sense. it will throw exception if empty members provided now.,0,0.9886389970779419
431313236,8589,feyman2016,2020-05-27T17:21:43Z,fixed,0,0.9281549453735352
431313242,8589,feyman2016,2020-05-27T17:21:44Z,fixed,0,0.9281549453735352
431322560,8589,mjsax,2020-05-27T17:37:06Z,"seems redundant as tested somewhere else. and the purpose of the test is to verify `--force` itself. this additional checks have nothing to do with `--force` imho. it seems best to keep test to a ""minimum"".",0,0.9839445948600769
431323350,8589,mjsax,2020-05-27T17:38:31Z,thanks for clarifying.,0,0.6512355208396912
431327264,8589,mjsax,2020-05-27T17:45:07Z,"well, while `memberinfo` is empty for the `removeall` case, i am still wondering if the code for `removeall` would not work for the other case, too?",0,0.9782131314277649
431329158,8589,mjsax,2020-05-27T17:48:14Z,i see. makes sense.,0,0.944813072681427
431341731,8589,feyman2016,2020-05-27T18:04:07Z,"yes, updated",0,0.946511447429657
431345466,8589,feyman2016,2020-05-27T18:10:45Z,"i'm not sure i understand the question, could you elaborate more?",-1,0.5110292434692383
431352788,8589,feyman2016,2020-05-27T18:23:50Z,"yeah, i totally agree with: `it seems best to keep test to a ""minimum"".` not sure if my understanding is correct, but i still think the tests for `resetter` should compare the first run and re-run results, from the test's perspective, it cannot assume that `--force` option won't do something underneath that make the re-run produce different results. but i'm ok to remove the re-run part if we do think it's redundant.",0,0.9289242029190063
431354284,8589,mjsax,2020-05-27T18:26:19Z,"can we just do for both cases? [code block] the ""issue"" with using `memberinfos` is, that for the removeall() case it's empty and we cannot use it. however, `membererrors` should have an entry for all members for both cases?",0,0.9958529472351074
431355573,8589,mjsax,2020-05-27T18:28:43Z,fair enough. let's leave it as-is.,0,0.9560704231262207
431372024,8589,feyman2016,2020-05-27T18:58:10Z,"i'm afraid not because, in the non `removeall` scenario, caller specify the members(`memberinfos`) to be deleted, and according to `maybecompleteexceptionally`, the `memberinfos` is used because it might sometimes happen that certain member in `memberinfos` cannot be found in `membererrors `, that's the reason i didn't use the `removeall` logic for all cases.",-1,0.6972956657409668
431373621,8589,mjsax,2020-05-27T19:00:58Z,thanks for explaining!,1,0.7294114232063293
199933294,5322,vvcephei,2018-07-03T19:59:28Z,"i think we did it this way on purpose, so we wouldn't automatically assume that later versions would have this data. but now that i'm looking at it again, it seems like this boolean expression will become silly. also, the risk of breakage is low. if we choose not to include this stuff in later versions, it'll be pretty obvious that we have to put an upper bound on this condition. so i think this change is good.",0,0.6807323694229126
199934416,5322,vvcephei,2018-07-03T20:04:10Z,"i don't think we need to move this field. when you use it, you return immediately after assigning it, so you could just make it a local variable in that block for return. then the uninitialized field won't be in scope for everything else in this method.",0,0.9804671406745911
199935554,5322,vvcephei,2018-07-03T20:08:46Z,"maybe we can introduce a method to build this assignment and save some vertical space in this super-long method. then you could just return it, such as `return errorassignment(clientsmetadata, errorcode)`. in fact, we could ditch this variable entirely, and just return directly in all three spots we currently set it.",0,0.9933193922042847
199938505,5322,vvcephei,2018-07-03T20:20:24Z,"it seems like it would be nice also to have a constant for the ""no error"" value (0). i'm wondering if namespacing the error codes would be beneficial. minimally, we could prefix the constant like ""err_unknown_partition"". or we could use an enum: [code block] then, we could encode with `out.writeint(errcode.getcode());` and decode with `assignmentinfo.errcode = error.fromcode(in.readint());` just an idea... what do you think?",0,0.8042452931404114
199939219,5322,vvcephei,2018-07-03T20:23:17Z,i guess we'll need one of these for version 4.,0,0.9804820418357849
199940084,5322,vvcephei,2018-07-03T20:26:38Z,"it seems like this new constructor only supports the ""error assignment"" code path. can we just inline it? i admittedly didn't quite follow why we need this version check now.",0,0.9449639916419983
199952165,5322,guozhangwang,2018-07-03T21:15:58Z,"this is a meta comment: i'd suggest having a separate check at the very beginning of `assign()`, after `step zero`, that for each entry value in `topicgroups = taskmanager.builder().topicgroups()`, if each of its `topicsinfo#sourcetopics` are either in `topicsinfo#repartitionsourcetopics` or can be found in `metadata`. if the check fails we immediately falls back into the error case of 1) log an error, and 2) set dummy assignment to all the clients with error code. then in line 419 here we do not need this `do-while` loop, instead we should follow the sub-topology id ordering to assign num.partitions for repartition topics, and if it cannot be decided we will throw an runtime exception since it is not expected any more. in addition we can remove `not_available` as well.",0,0.9941673278808594
199953001,5322,guozhangwang,2018-07-03T21:19:16Z,"+1, we can add an enum inside streamspartitionassignor which can be extended in the future. also for this error case the name `unknown_partition` is a bit confusing, i'd suggest we name it `incomplete_source_topic_metadata`. and upon receiving this error code we should log an error that `some of the source topics ( + source topic lists) are not known yet during rebalance, please make sure they have been pre-created before starting the streams application.`",0,0.992659866809845
199953116,5322,guozhangwang,2018-07-03T21:19:44Z,"as mentioned in the jira ticket, we should log an error that `some of the source topics ( + source topic lists) are not known yet during rebalance, please make sure they have been pre-created before starting the streams application.`",0,0.994562566280365
199953424,5322,guozhangwang,2018-07-03T21:20:57Z,nit: add empty line.,0,0.9590608477592468
199955030,5322,guozhangwang,2018-07-03T21:27:16Z,"this is another meta comment, not related to this line: in `copartitionedtopicsvalidator` we should also update the logic accordingly, first of the [code block] should never happen, since we would already fail before if the metadata is not complete, and the `not_available` case should not happen either (see my other comment). also note that there is a related bug fix pr for this jira long time ago about when the ensurecopartitioning should be called: [a link] with this general change: [code block] should not happen either since all topic's num.partitions should be determined by then.",0,0.9907200336456299
199955216,5322,guozhangwang,2018-07-03T21:28:03Z,"nit: add empty line between functions, ditto below.",0,0.9282630085945129
199956438,5322,guozhangwang,2018-07-03T21:33:15Z,"again this is another meta comment: the member decoding and handling leader's propagated assignment is in `onassignment`, in which the we decode `assignmentinfo` from `assignment#userdata`. in that function we should check the returned error code in `assignmentinfo`, and if it is not none we should ""gracefully"" shutdown than just throwing a runtime exception: for example, we can set a flag indicating we need to error out, and then in `onpartitionsassigned` callback we can check this flag and then decide to shutdown if necessary.",0,0.9934720993041992
199971943,5322,tedyu,2018-07-03T23:01:43Z,"for onpartitionsassigned, did you mean the method in streamthread ? the method takes collection . does this mean the flag should be added to topicpartition ?",0,0.9948505759239197
199972239,5322,tedyu,2018-07-03T23:04:07Z,"still need to figure out how to follow the sub-topology id ordering. for now, i keep the do-while loop.",0,0.9656934142112732
200792196,5322,guozhangwang,2018-07-06T23:32:18Z,"the way `streamthread` class and `streamspartitionassginor` communicates today is bit weird: in order to break mutual dependency and keep the code cleaner, what we did is to pass in mutually needed modules as internal configs via the `streamsconfig`, which `streamspartitionassignor` will call `configure` on. the process works the following: 1. when streamthread creates the consumer, it adds more objects into the properties map to the consumer. 2. consumer client would create the instantiated `streamspartitionassignor`, which will then call `configure` with the passed in properties. the reason is because of the way consumers instantiate their coordinator's `assignor` object today. 2.a) for example, streamthread passed in the `taskmanager` object as `streamsconfig.internalconfig.task_manager_for_partition_assignor`. the streamspartitionassignor would then call its update functions to update the assigned tasks, which stream thread would then try to access in its own class. another example is we pass in the version prob flag as an `atomicboolean` to be set / reset between these two classes as `streamsconfig.internalconfig.version_probing_flag`. so what i meant for a `flag` is to suggest doing the similar thing like the `atomicboolean prob-flag`, in which `streamspartitionassignor` can set in its `onassignment` function. the `onpartitionassigned` function called within `streamthread` can then check this flag. for more details you can reference the current implementation pattern of the version probing flag",0,0.8716675043106079
200792492,5322,guozhangwang,2018-07-06T23:35:44Z,"one way to break the while loop, is to rely on the [code block] note the `integer` key is indeed the sub-topology id here, and since we sort the sub-topology by their ids, starting with `1`, the first sub-topology 1 should have no internal topics as its source topic. so we can start by this key ordering, to first determine any of the repartition topic's num.partitions as their sink topics of sub-topology 1, and then based on them as for the source topics of sub-topology 2, we can determine sub-topology 2's sink repartition topic's numb.partitions, and so on.",0,0.9903185367584229
201814927,5322,guozhangwang,2018-07-11T19:36:10Z,it is simpler to just have an `encodeversionfour` which does not change anything than `encodeversionthree` but just put the different version. note that within this release cycle we may introduce other format changes as well (so eventually the `encodeversionfour` may be implemented differently anyways).,0,0.991520345211029
201815805,5322,guozhangwang,2018-07-11T19:39:33Z,"nit: rename to `__assignment.error.code__` and `assignment_error_code`? another comment: thinking about this a bit more, maybe we can subsume the `version_probing_flag` with the `assignment_error_code`, as upon receiving the error code the member should be handling it separately on the error code, sometimes re-join the group with a down-graded encoding version, some time to shutdown, etc. with that we can generalize the handling logic.",0,0.9944769740104675
201816222,5322,guozhangwang,2018-07-11T19:41:19Z,"for trouble shooting only: maybe we can still check that `!partitions.isempty()`, and if yes log an fatal and throw runtime exception? if we had a bug that still causes `partitions.size() == 0`, then the line 83 below would silently skip assigning the maxnumpartitions update, which would be very hard to capture during debugging.",0,0.774533748626709
201818695,5322,guozhangwang,2018-07-11T19:50:35Z,"i think it is to not call `return` after that since line 272 below will return null and hence return anyways, plus it will log the final debug entry as well. also note that in the only other caller we do [code block] i.e. we need to set `thread.setstatelistener(null);` since otherwise there may be deadlock issues. we need to do the same here.",0,0.9906388521194458
201819967,5322,guozhangwang,2018-07-11T19:55:16Z,cc wdyt?,0,0.95516437292099
201820822,5322,guozhangwang,2018-07-11T19:58:04Z,nit: comment line misaligned,0,0.8432014584541321
201821078,5322,guozhangwang,2018-07-11T19:59:02Z,"see my other comment: it's better just duplicate the logic of handling version 3 and version 4 information for now, as we may add new info for version 4 soon which would make the handling logic different.",0,0.9882986545562744
201824357,5322,guozhangwang,2018-07-11T20:12:12Z,"same as above, let's add a fatal error and throw a runtime exception like illegalstateexception.",0,0.9672834277153015
201824624,5322,guozhangwang,2018-07-11T20:13:10Z,this seems not used.,0,0.7507635354995728
201825636,5322,guozhangwang,2018-07-11T20:16:53Z,nit: empty line.,0,0.783897340297699
201825651,5322,guozhangwang,2018-07-11T20:16:55Z,nit: align parameters.,0,0.9525464773178101
201825785,5322,guozhangwang,2018-07-11T20:17:27Z,we can remove the code block line 82-85 above since it will be called here.,0,0.9915510416030884
201826312,5322,guozhangwang,2018-07-11T20:19:19Z,"ditto, i'd suggest just duplicating the code since we may add more logic for version 4 anyways.",0,0.9838364720344543
201826496,5322,guozhangwang,2018-07-11T20:19:57Z,nit: latestsupportedversion,0,0.9831546545028687
201826570,5322,guozhangwang,2018-07-11T20:20:13Z,nit: align parameters.,0,0.9525464773178101
201826760,5322,guozhangwang,2018-07-11T20:20:55Z,ditto. let's just add an `encodeversionfour` with duplicated logic except the version.,0,0.9615926146507263
201843313,5322,tedyu,2018-07-11T21:21:47Z,"version probing is a boolean flag. assignment error code is int. if we unify these two, we need to encode version probing. btw version probing doesn't imply assignment error.",0,0.9909828305244446
201850915,5322,tedyu,2018-07-11T21:49:45Z,unfortunately no. the `this` call goes to line 100 where this is no such check.,0,0.9759482741355896
201851272,5322,tedyu,2018-07-11T21:51:16Z,addition to version 4 can be added at the end of `encodeversionfour`,0,0.9936091899871826
201851485,5322,tedyu,2018-07-11T21:52:12Z,i did that first - resulting in duplicate local variable.,0,0.9890103936195374
202841909,5322,guozhangwang,2018-07-16T22:15:37Z,"yes, my intention is to use another error code value (seems you've already done it as `version_probing`) to replace the flag, and then after onassignment is called we would check the error code and if it is not `none` react accordingly, it may be simply shutdown and stop-the-world, or other actions like down-grade.",0,0.9788066744804382
202842440,5322,guozhangwang,2018-07-16T22:18:13Z,i see --- we can define latestsupportedversion before the switch not as a `final` int then?,0,0.9926922917366028
202855945,5322,guozhangwang,2018-07-16T23:29:29Z,"if we are adding this function in `kafkastreams` then we do need a kip.. but i was thinking if we can just add this in `streamthread`, which is an internal class and hence doing so does not need a kip. we can, instead, add a `kafkastreamswrapper` (it is similar to `topologywrapper` and `topologytestdriverwrapper` to allow unit test code to access their internal private fields) which can access the threads and globalthread, and then adds this function in this class to manipulate them. also note that streamthread already has a state change listener `final class streamstatelistener implements streamthread.statelistener` so our `statelistenerstub` should not completely replace its logic. instead we can extend that listener to `statelistenerstub` which does the state change tracing in additional to the necessary logic.",0,0.9876999855041504
202856322,5322,guozhangwang,2018-07-16T23:31:58Z,"this condition seems not right: we should not shutdown if the error was `version_probing`, right? i.e we should firstly check if the error was `none`, and if not, switch branch on the actual error code to handle them accordingly.",0,0.9822626113891602
202856380,5322,guozhangwang,2018-07-16T23:32:17Z,"similarly, here we would only create tasks if the error was `none`.",0,0.992923378944397
202856437,5322,guozhangwang,2018-07-16T23:32:39Z,case 2 is missing.,0,0.9754102230072021
202856560,5322,guozhangwang,2018-07-16T23:33:24Z,ping again.,0,0.9530306458473206
202857024,5322,guozhangwang,2018-07-16T23:36:20Z,"as we are merging the two scenarios to use the error code, we should let the leader to set the error code in the version probing case as well as setting the `receivedassignmentmetadataversion` in the assignment. and then we only need to do the logic in line 796 above, and do not need to set it in line 827 any more.",0,0.9899587035179138
202857302,5322,guozhangwang,2018-07-16T23:38:05Z,we should not use a `topologyexception` here any more since `topologyexception` should be used for dsl statement parsing only. instead we could just throw an illegalstateexception since it should never be expected (i.e. if the metadata is indeed not known we should error out with the error assignment earlier and never reach this line).,0,0.9931159615516663
202857594,5322,guozhangwang,2018-07-16T23:39:56Z,adding a parameter `version` for `encodeversionthree` is very confusing to other readers. i'd suggest completely duplicate the code in `encodeversionfour` and remove this parameter in `encodeversionthree`.,0,0.6391891241073608
202857927,5322,guozhangwang,2018-07-16T23:42:01Z,"thanks for adding this integration test! it looks reasonable, but we'd generally adding integration java test under `org.apache.kafka.streams.integration`, not `org.apache.kafka.streams.scala` (the latter is only for the scala api only).",1,0.9738973379135132
202858371,5322,guozhangwang,2018-07-16T23:44:49Z,"and also the title `testshouldcountclicksperregionwithmissingtopic` is confusing, it should be `shouldshutdownwithmissingtopic` right? and note this class is for `streamtotablejoinscalaintegrationtestimplicitserdes`, so not the right class to add this test. i'd suggest adding a new test class under the above mentioned package for this test case, like `assignmenterrorhandlingintegrationtest`, and this test case be `shouldautoshutdownonincompletemetadata`.",0,0.9936424493789673
202864203,5322,tedyu,2018-07-17T00:23:59Z,pardon. can you explain in a bit more detail ? i am not sure how leader sets the error code for version probing if not done on line 827.,0,0.9248934388160706
202867018,5322,tedyu,2018-07-17T00:45:35Z,"i took a look at streams/src/test/java/org/apache/kafka/streams/integration/streamtablejoinintegrationtest.java where cluster is not involved. if i move the new test there, a lot of scala code for setting up the testing environment would be repeated. it seems more intuitive if the new integration test is added in this test class in terms of code reuse.",0,0.991540253162384
202868232,5322,tedyu,2018-07-17T00:55:42Z,please confirm: threads and state fields of kafkastreams can be changed to protected. otherwise the new method in kafkastreamswrapper still cannot access them.,0,0.9947916269302368
202901382,5322,guozhangwang,2018-07-17T05:56:17Z,"yes, they can.",0,0.9751405119895935
202901958,5322,guozhangwang,2018-07-17T06:00:28Z,"currently the version probing works as the following: 1. when leader receives the subscription info encoded with a higher version that it can understand (e.g. the leader is on version 3, while one of the subscription received is encode with version 4), it will send back an empty assignment with the assignment encoded with version 3, and also `latestsupportedversion` set to 3. 2. when the member receives the assignment, it checks if `latestsupportedversion` is smaller than the version it used for encoding the sent subscription (i.e. the above logic). if it is smaller, then it means that leader cannot understand, in this case, version 4. it will then set the flag and then re-subscribe but with a down-graded encoding format of version 3. now with your pr, we can let leader to clearly communicate this error via the error code, and upon receiving the assignment, if the error code is `version_probing`, then the member can immediately know what happens, and hence can simplify the above logic. does that make sense? also cc",0,0.9936455488204956
202902176,5322,guozhangwang,2018-07-17T06:01:51Z,"i understand the code duplication, but still adding a test case that has nothing to do with `streamtotablejoinscalaintegrationtestimplicitserdes` is not recommended. i'd still suggest making a new class and duplicate the setup code a bit.",0,0.9890879392623901
202932846,5322,tedyu,2018-07-17T08:22:31Z,"in the example given above, the gap in subscription info versions between leader and the member is 1. is the expectation that when the gap is > 1, at least one round trip is reduced for version probing compared to the existing implementation ? the version probing error code currently is hard coded and not correlated with the actual gap. i wonder if the optimization can be done in another jira.",0,0.9848159551620483
203204145,5322,mjsax,2018-07-17T22:41:10Z,"iirc, the idea was to be as explicit as possible and list out the versions, in case a future version does not encode `partitionsbyhoststate` any longer. the risk of the change is small though. i am ok with it.",0,0.8278566598892212
203204413,5322,mjsax,2018-07-17T22:42:43Z,nit: code formatting and missing `final`: [code block],0,0.9910193085670471
203204472,5322,mjsax,2018-07-17T22:42:57Z,nit: add `final`,0,0.9897833466529846
203204612,5322,mjsax,2018-07-17T22:43:41Z,nit: use `{}` instead of string concatenation,0,0.9917551279067993
203204975,5322,mjsax,2018-07-17T22:45:43Z,not sure if calling `shutdown()` directly is the best way? shouldn't we just `return` and break the loop in `streamthread#runloop()` ?,0,0.988851010799408
203205168,5322,mjsax,2018-07-17T22:46:38Z,nit: use `{}` instead of string concatenation,0,0.9917551279067993
203205249,5322,mjsax,2018-07-17T22:47:08Z,nit: add `final`,0,0.9897833466529846
203205508,5322,mjsax,2018-07-17T22:48:23Z,why remove `final` ?,0,0.9910683631896973
203205842,5322,mjsax,2018-07-17T22:49:59Z,"`processversionthreeassignment` -> `processversionfourassignment` if both are identical, it's ok to call `processversionthreeassignment()` from within `processversionfourassignment()` imho, but adding a `processversionfourassignment()` seems to be cleaner to me.",0,0.9926571249961853
203206140,5322,mjsax,2018-07-17T22:51:46Z,`final` ?,0,0.9844302535057068
203206482,5322,mjsax,2018-07-17T22:53:30Z,do we need this new constructor? can the existing one not just be extended with `errorcode`?,0,0.9947208166122437
203206896,5322,mjsax,2018-07-17T22:55:50Z,nit: add `final`,0,0.9897833466529846
203206912,5322,mjsax,2018-07-17T22:55:55Z,nit: add `final`,0,0.9897833466529846
203206951,5322,mjsax,2018-07-17T22:56:07Z,nit: indention,0,0.7825920581817627
203207194,5322,mjsax,2018-07-17T22:57:30Z,why do you remove this test?,0,0.9766654372215271
203207828,5322,guozhangwang,2018-07-17T23:01:17Z,"hmm.. i'm not sure if this is the right fix, but maybe upgrading the test when we bump up version is also out side the scope of this pr itself. i'll let to take a look and decide how can we fix forward the upgrade-test.",0,0.5346463322639465
203208753,5322,mjsax,2018-07-17T23:06:40Z,"if we bump the version, we need to update this to 5 and 4 as already done. we should also make this more generic and test upgrades from 3 -> 4, 3 -> 5 and 4 -> 5. the current code does only go from latest version to future version. however, generalizing the test should be out of scope of this pr and just changing the expected numbers should be fine for this pr.",0,0.9926256537437439
203209970,5322,tedyu,2018-07-17T23:13:46Z,the type of the version probing flag has changed from boolean to integer. there is another subtest for checking the error code.,0,0.9897913336753845
203210372,5322,tedyu,2018-07-17T23:16:16Z,this was suggested by guozhang and i tend to agree with calling shutdown(),0,0.9839680194854736
203216673,5322,mjsax,2018-07-17T23:55:19Z,"i understand that. thus, this test should be updated to `shouldthrowkafkaexceptionifversionprobingflagconfigisnotatomicinteger` -- it tests the data type, ie, the cast operation.",0,0.9921080470085144
203216813,5322,mjsax,2018-07-17T23:56:01Z,what is the reasoning behind this?,0,0.9490844011306763
203248963,5322,guozhangwang,2018-07-18T04:35:43Z,"copying my response from the email thread: [code block] currently i cannot think of a race condition that calling `shutdown` in the callback would introduce than calling shutdown in the main loop, but i'm not 100% sure, so i insisted on triggering a system test.",0,0.9707697629928589
203542445,5322,mjsax,2018-07-18T21:54:19Z,"this should never happen, right? thus, i am wondering if we should throw an `illegalstateexception` instead?",0,0.9536993503570557
203542534,5322,mjsax,2018-07-18T21:54:38Z,nit: add `{ }` to then-block,0,0.9915721416473389
203542781,5322,mjsax,2018-07-18T21:55:50Z,seems this slipped in the last update.,0,0.9745628237724304
203543587,5322,mjsax,2018-07-18T21:58:57Z,"ack. we might still want to add a `return` to make clear it's an early exit. of course, the `if` below evaluate to `false` anyway, however, it makes the code more readable imho.",0,0.9047994017601013
203544388,5322,mjsax,2018-07-18T22:02:10Z,nit: we usually omit `get` prefix for all getter method. please update to `code()` to align with common naming conventions.,0,0.9943829774856567
203544506,5322,mjsax,2018-07-18T22:02:35Z,comment can be omitted,0,0.989473283290863
203547299,5322,mjsax,2018-07-18T22:15:20Z,"for future version this might work. however, if we upgrade from 2.0 to 2.1 with version bump from 3 -> 4, the old leader is on version 3 and cannot encode the version probing via the error flag. as we are stuck with older version 3 metadata, i am not sure if we gain a lot if we change the logic, as we still need the current code anyway.",0,0.8805458545684814
203547399,5322,mjsax,2018-07-18T22:15:50Z,nit: fix indention,0,0.788091242313385
203548013,5322,mjsax,2018-07-18T22:18:58Z,why do we move this up here? `topics` is only used when an exception is thrown (or did i miss anything)?,0,0.9885644316673279
203548143,5322,mjsax,2018-07-18T22:19:35Z,did this slip?,0,0.9809085130691528
203548277,5322,mjsax,2018-07-18T22:20:13Z,any comments? i would like to keep the number of constructors small if possible.,0,0.979548454284668
203548421,5322,mjsax,2018-07-18T22:20:52Z,nit: rename to `errorcode` ? we try to avoid abbriviations,0,0.9910973310470581
203548476,5322,mjsax,2018-07-18T22:21:06Z,nit: rename `errorcode()`,0,0.9926425814628601
203548586,5322,mjsax,2018-07-18T22:21:40Z,nit: add empty line,0,0.9438928365707397
203548969,5322,mjsax,2018-07-18T22:23:18Z,add `getversionfourbytelength()` ? or rename method to `getversionthreeandfourbytelength()` ?,0,0.9948582649230957
203549210,5322,mjsax,2018-07-18T22:24:16Z,nit: fix indention,0,0.788091242313385
203549314,5322,mjsax,2018-07-18T22:24:47Z,nit: add empty line,0,0.9438928365707397
203549359,5322,mjsax,2018-07-18T22:25:01Z,seems this slipped,-1,0.5577695965766907
203549395,5322,mjsax,2018-07-18T22:25:11Z,seems this slipped,-1,0.5577695965766907
203549533,5322,mjsax,2018-07-18T22:25:49Z,seems this slipped,-1,0.5577695965766907
203549904,5322,mjsax,2018-07-18T22:27:14Z,should we change the test to expect an exception instead of removing it?,0,0.9916560649871826
203550235,5322,mjsax,2018-07-18T22:28:20Z,"as above: should we check that an exception is thrown? (we had ""infinite loop"" bugs in the past -- those tests seems to be valuable)",0,0.9912745356559753
203550652,5322,mjsax,2018-07-18T22:29:45Z,seems this can be removed?,0,0.9932290315628052
203550712,5322,mjsax,2018-07-18T22:29:59Z,"seems, this can be removed?",0,0.9920499920845032
203555179,5322,mjsax,2018-07-18T22:49:12Z,why is this change required? it seems we forgot to update `assignmentinfo#equals()` and `assignmentinfo#hashcode()`...,0,0.9838585257530212
203555598,5322,mjsax,2018-07-18T22:51:27Z,how does this test relate to the change?,0,0.9889785647392273
203555659,5322,mjsax,2018-07-18T22:51:52Z,as above? why do we change this test?,0,0.9915294647216797
203556910,5322,tedyu,2018-07-18T22:58:08Z,"right, this code shouldn't be reached.",0,0.9186355471611023
203557121,5322,tedyu,2018-07-18T22:59:13Z,there is no then-block - i guess you mean the if-block.,0,0.9891224503517151
203559036,5322,tedyu,2018-07-18T23:09:57Z,i want to mention versionprobingflag just in case some developer who knew the flag comes wondering what happened to the flag :-),0,0.5418669581413269
203559379,5322,mjsax,2018-07-18T23:11:30Z,"terminology is fun... it's and if-then-else statement -- there is no `then` keyword, but still and then-block -- interesting that you call it if-block :)",1,0.9945353269577026
203559593,5322,mjsax,2018-07-18T23:12:51Z,`git blame` is their friend :) -- that's why there is a commit history. allows us to keep the code base clean :),1,0.9956039190292358
203563364,5322,tedyu,2018-07-18T23:34:18Z,right.,0,0.9793882369995117
203564178,5322,tedyu,2018-07-18T23:39:04Z,streamtotablejoinscalaintegrationtestbase is created for reusing cluster setup code between existing test and new integration test.,0,0.9944784641265869
203564273,5322,tedyu,2018-07-18T23:39:37Z,streamtotablejoinscalaintegrationtestimplicitserdes is changed to preserve non-cluster setup test code.,0,0.9915720224380493
203564445,5322,tedyu,2018-07-18T23:40:44Z,i see - yeah i call it if block.,0,0.9764535427093506
203807596,5322,mjsax,2018-07-19T17:21:41Z,"as mentioned in a previous comment, we need to update `hashcode()` and `equals()`.",0,0.9934984445571899
203829239,5322,mjsax,2018-07-19T18:31:54Z,"i understand your other test changes now. however, i am wondering why we add this test to the scala module in the first place? kafka streams is written in java, and we should write all tests in java, too. the scala module is just a thin language wrapper on top, and integration tests in the scala module should only test the scala/java integration, but not core functionality. this test belongs to `stream/src/test/java/org/apache/kafka/stream/integration` thus, my argument is not really about java vs scala, but putting test into the scala wrapper module scatters our test code across two modules and we should not do this.",0,0.9751548767089844
1137856849,13391,jolshan,2023-03-15T23:01:21Z,bug here -- we don't want to clear non-inflight nodes.,-1,0.8207151293754578
1137901882,13391,jolshan,2023-03-16T00:00:27Z,i have a fix i will push with the rest of the tests,0,0.9609676003456116
1142707455,13391,artemlivshits,2023-03-20T21:44:34Z,"looks like this could be called from multiple threads, do we need to add synchronization?",0,0.9917300343513489
1142722842,13391,artemlivshits,2023-03-20T22:07:29Z,"would it be possible to have a retry (say first request timed out, and then we send another one) and have more than one request?",0,0.9777669906616211
1142729789,13391,artemlivshits,2023-03-20T22:17:58Z,we could use getorelseupdate.,0,0.9938177466392517
1142747856,13391,artemlivshits,2023-03-20T22:48:21Z,"if the request is already in flight, looks like we wouldn't be able to detect and reject a stale request here. is it needed for correctness? if yes, we need to fix that, if not, i'd propose to remove this logic and just properly handle stale epoch when it gets to transaction coordinator.",0,0.990776777267456
1142753293,13391,artemlivshits,2023-03-20T22:58:00Z,inflightnodes seem to be accessed only by the inter-broker send thread so synchronization is not actually needed.,0,0.9935141801834106
1142758001,13391,artemlivshits,2023-03-20T23:06:56Z,"shouldn't it get cleared automatically once it gets out of scope? if there is a tricky consideration, let's add a comment.",0,0.9785023927688599
1142762452,13391,artemlivshits,2023-03-20T23:15:37Z,"is this client going to be used only for addpartitionstotxnmanager or some other inter-broker communication (in the future) as well? if it the former, we should make name more specific.",0,0.9935947060585022
1142786061,13391,jolshan,2023-03-21T00:08:15Z,"i thought about that, but i was concerned about blocking on a single produce request too long. i though maybe the producer's retry mechanism would be enough to handle this.",0,0.8849391341209412
1142787086,13391,jolshan,2023-03-21T00:10:10Z,i think it's ok to have new data when a request is inflight. the issue is that i have an invariant here that we can only have one queued item for a given txn id at a time. this is due to how the information is stored in the map. the only time we can receive two requests from the same txn id is when the producer restarts and the epoch is bumped. that is why i have this logic here.,0,0.9880897402763367
1142787356,13391,jolshan,2023-03-21T00:10:48Z,i guess i was considering more than one send thread :grinning_face_with_sweat: i guess we don't have that now.,0,0.9715386629104614
1142788144,13391,jolshan,2023-03-21T00:12:38Z,we are reusing this for each transactional id and it remains in scope at this time.,0,0.9910488128662109
1142788313,13391,jolshan,2023-03-21T00:13:00Z,we can make it more specific.,0,0.9847532510757446
1144090231,13391,junrao,2023-03-21T23:38:45Z,does the todo still need to be addressed?,0,0.9896472096443176
1144092204,13391,junrao,2023-03-21T23:41:57Z,could we add a new line after?,0,0.9916220903396606
1144106075,13391,junrao,2023-03-22T00:13:25Z,could this be private?,0,0.9903441071510315
1145103445,13391,junrao,2023-03-22T16:26:10Z,"i am wondering why we need to do this in a request thread. for example, transactionmarkerrequestcompletionhandler already appends to the log in a separate thread.",0,0.8564392328262329
1145118797,13391,junrao,2023-03-22T16:36:44Z,we already have a transactionmarkerchannelmanager for txn coordinator to send requests to brokers. could we reuse that for sending requests from brokers to txn coordinators? we probably don't want too many separate threads for exchanging requests among brokers.,0,0.9902410507202148
1145376271,13391,jolshan,2023-03-22T20:30:39Z,we are sending from the partition leader to the txn coordinator. can we still use that same thread? i think the usage is different right?,0,0.9750927686691284
1145376651,13391,jolshan,2023-03-22T20:31:03Z,thought this should be done. perhaps he can explain better than me.,0,0.9576846361160278
1145453181,13391,junrao,2023-03-22T22:01:40Z,"that's true. however, if you look at transactionmarkerchannelmanager, the main api is `addmarkersforbroker`. so at that level, it's just sending some requests to another broker. in addpartitionstotxnmanager, its main api is `addtxndata`. again, it's just sending some requests to another broker. instead of creating more and more of those specialized broker-to-broker communication channels, it may be better to consolidate them into a single general framework.",0,0.9935457110404968
1145463265,13391,jolshan,2023-03-22T22:15:52Z,"i thought about this, but the trouble is how each request is built slightly differs. some of them pass the node they are sending to when sending adding the request (like this one) and some do the calculation right before (ie, controller channel manager) i can take a look at the transaction channel marker channel manager and see how it handles it. but i think the other benefit for this class is keeping all the add partitions logic together. perhaps there is a way to consolidate this, but also use the same thread/channel?",0,0.9588668346405029
1145487679,13391,junrao,2023-03-22T22:55:39Z,"yes, i was wondering if there is a way to reuse the thread and the channel for broker to broker communication for all low volume requests.",0,0.982750654220581
1145533272,13391,jolshan,2023-03-22T23:54:53Z,i can look into this. do we also want to handle the callback on that same thread still?,0,0.9873296022415161
1145545834,13391,junrao,2023-03-23T00:21:10Z,"yes, that's what i was wondering. transactionmarkerchannelmanager writes the final commit to the log in the callback of sending the marker to the broker. i am wondering if we could just do the same here.",0,0.9679628610610962
1145549423,13391,jolshan,2023-03-23T00:30:05Z,"i think is the best to answer this. he was the one who said we should do this and although i vaguely remember the explanation, he will do a better job explaining.",0,0.8552080988883972
1146789680,13391,YiDing-Duke,2023-03-23T20:24:15Z,"if 1st request timeout, the second one cannot hit this stage unless 1st one is done due to connection muted?",0,0.9873700141906738
1146821982,13391,jolshan,2023-03-23T20:46:16Z,"yi is correct. i also think if we hit timeout, it is the epoch bump case i mentioned before.",0,0.9804373383522034
1146944915,13391,junrao,2023-03-23T22:36:19Z,"chatted with artem offline. his reasoning is for performance. it's better to do any io related operations in the request thread pool to prevent blocking the callback thread. this could be a bit better. if we do this, maybe we should also change transactionmarkerrequestcompletionhandler so that it writes the complete marker in the request thread instead of the callback thread. that could be done in a followup jira.",0,0.9849334359169006
1146951880,13391,jolshan,2023-03-23T22:49:09Z,(answer is above),0,0.988375186920166
1147152053,13391,artemlivshits,2023-03-24T06:01:39Z,"this should be .offer -- we don't need to block if the request queue is full, and it's ok if we don't have a wakeup request in a full queue -- the queue would would contain a request (due to the fact that it's full) to wake up the poll.",0,0.9909006357192993
1147156380,13391,artemlivshits,2023-03-24T06:10:23Z,"we could probably handle wakeuprequest in this function, so that the wakeup mechanism is encapsulated in requestchannel (i.e. check if we got a wakeup request from the requestqueue and poll the callbackqueue again in that case).",0,0.995051920413971
1147689005,13391,junrao,2023-03-24T14:50:15Z,could we just reuse the actionqueue instead of introducing a new queue? actionqueue is drained by the request thread whenever it finishes processing the current event.,0,0.9923160076141357
1147787658,13391,jolshan,2023-03-24T16:05:36Z,will we still have the behavior of putting the callback at the front of the queue? it would go to the end of the action queue right?,0,0.9941232800483704
1147789029,13391,jolshan,2023-03-24T16:06:54Z,offer was throwing spotbugs errors since i didn't check the response. i can do that but it will be a little uglier.,0,0.5562002658843994
1147794328,13391,junrao,2023-03-24T16:11:55Z,"it would go to the end of the action queue. however, not every request adds entries to the action queue. so, the action queue is typically smaller than the request queue. also, request threads prioritize the action queue over the request queue.",0,0.9910069108009338
1147804661,13391,jolshan,2023-03-24T16:22:05Z,so it is the case that all the action entries are removed before the next request? for some reason i thought it just cleared one for each request. i can take a look.,0,0.9828641414642334
1147813111,13391,junrao,2023-03-24T16:28:59Z,it clears all entries it sees at the beginning. [code block],0,0.9929432272911072
1147857120,13391,jolshan,2023-03-24T17:09:05Z,thanks!,1,0.9051083922386169
1147991721,13391,artemlivshits,2023-03-24T19:43:30Z,"if a request hits a timeout the new request will come in the new connection, so the fact the old connection is muted wouldn't prevent the new request to come. the timeout processing on the client is just a timer, once it expires, it'll kill old connection, create a new one and re-send the batch. we won't bump the epoch on retry -- it'll override duplicate checking logic, so we'd have duplicates if we did, so the exact same batch (same epoch, same sequence) will come again on the new connection.",0,0.9772366285324097
1147999817,13391,artemlivshits,2023-03-24T19:53:33Z,i'd expect the synchronization would be added as part of making the class properly multithreaded.,0,0.9890224933624268
1148002291,13391,artemlivshits,2023-03-24T19:56:51Z,"should we move it to the proper scope then? (the indentation is hard to follow in the pr view, i assumed it's already in the proper scope)",0,0.9934327602386475
1148025113,13391,artemlivshits,2023-03-24T20:29:51Z,"oh, i see, we have only one request for a trasnactional.id, so we need to complete previous one in order to replace. see my other comments about retries.",0,0.9829620718955994
1148044044,13391,artemlivshits,2023-03-24T20:52:43Z,"we could try to re-purpose the action queue for this, but it currently has different semantics -- the error processing is different, for example (it's executed in the finally clause). what we want here is the semantics that we'd get if we just blocked the thread while we're contacting tc, but without blocking the thread. same error handling, same context, same metrics, etc. the basic implementation of the desired semantics is just a queue, but we could also preserve request context (see todos in kafkarequesthandler.scala) so that this functionality that would work for any requests that need to do non-blocking async calls.",0,0.987356424331665
1148057123,13391,artemlivshits,2023-03-24T21:08:17Z,"i guess, if the request queue is full then it means that the request threads are all overloaded, so if we block the inter-broker channel thread it probably wouldn't matter much as the broker is already in pain. but on the other hand, it's kind of strange to not implement technically more correct behavior because we've got some spurious warnings.",-1,0.8385557532310486
1148060963,13391,artemlivshits,2023-03-24T21:14:41Z,"we should measure the time it took to process the request to tc and report it (either as ""remote time"" that we already have or as a new metric), otherwise it'll just roll into ""local time"" (time spent by this broker to handle the request).",0,0.9922014474868774
1148081688,13391,jolshan,2023-03-24T21:39:48Z,yeah. i planned to look at the request timing stuff next. thanks for the reminder :),1,0.9933556318283081
1148082243,13391,jolshan,2023-03-24T21:40:36Z,the build will fail with the warnings. but i can add the extra code so the build passes.,0,0.9804805517196655
1148084290,13391,jolshan,2023-03-24T21:42:44Z,"ah. i guess i was thinking of the client restarting. so you are saying in the case where the request times out before we send the request here, we can hit the error?",-1,0.625157356262207
1149586417,13391,jolshan,2023-03-27T17:34:15Z,i think we want to update in both cases -- and we want to distinguish the two.,0,0.9535691738128662
1149838206,13391,artemlivshits,2023-03-27T22:12:27Z,"yes, that's my understanding based on my reading of the code -- once a connection to a broker has at least one timed-out in-flight request, it's disconnected and all in-flight requests get a timeout error (which can be then retried by the producer on a new connection). [a link] it's also not guaranteed that the request that comes later here is the retry (i.e. the assumption that we can just fail the previous request because it must've timed out anyway is not true). should be unlikely with default settings, so we can probably just return some retriable error and document the caveat. alternatively (i would actually prefer that), we could just support multiple requests per transactional.id which would eliminate the need to handle this case here altogether: just add all new requests to the pending ""batch"" and let the tc handle different cases.",0,0.9840775728225708
1149847782,13391,jolshan,2023-03-27T22:28:23Z,i don't think we can add multiple to the batch because of how the callbacks are currently implemented. we would need to know which response goes to which callback. i thought about this a while and one callback is the the simplest way to do it.,0,0.8830919861793518
1149873099,13391,artemlivshits,2023-03-27T23:14:12Z,"ok, looks like the protocol is not designed to support multiple requests for one transactional.id. for same-epoch case, though, we'd get the same answer because we'd be asking the same question, so we could just keep multiple callbacks per trasnactional.id and call them all with the response, this way we don't have to guess which message is first and which is the retry.",0,0.98591148853302
1149903116,13391,jolshan,2023-03-28T00:17:49Z,hmm -- would it be better to just replace the old one? i don't think we'd expect two responses. and we definitely don't want to write twice.,0,0.8641007542610168
1151026334,13391,artemlivshits,2023-03-28T18:44:14Z,we don't know which one is the old one -- the one that's there or the one that just arrived. we won't write twice -- at some point we'll check for duplicates and one of the requests would succeed and the other would get 'duplicate' error (which is effectively success). we had this situation anyway without verifying the transactions: 2 requests will just continue processing and eventually one would succeed and another would get a duplicate. we also have this situation when one request is already in-flight to tc.,0,0.9324382543563843
1151046857,13391,artemlivshits,2023-03-28T19:06:16Z,"(could have syntax errors as i didn't compile it) ``` val nodeandtransactiondata = nodestotransactions.getorelseupdate(node, new transactiondataandcallbacks( new addpartitionstotxntransactioncollection(1), mutable.map.empty)) val currenttransactiondata = nodeandtransactiondata.transactiondata.find(transactiondata.transactionalid))",0,0.9931300282478333
1151269827,13391,YiDing-Duke,2023-03-29T00:07:47Z,"i assume the duplicate and out of order check happens in producer id cache and before this stage. if that's true, in general, the next batches with the same epoch won't hit this stage and should be fenced with out of order retry error to client. there can be a special case where this is the very first batch write from new epoch so the producer id cache cannot block any batches into this stage.",0,0.9920220375061035
1152479391,13391,artemlivshits,2023-03-29T20:59:25Z,"duplicate check + store has to be atomic (cannot really discard a new request as a duplicate until the previous request succeeds, not can let it go through until the previous request fails), so it needs to happen under a lock. the purpose of this stage is to not let a request go into log if the transaction is not there, so it got to be either between the check and the store or before the check and the store, hopefully, it's the latter, because otherwise we'd have a long lock around inter-broker rpc. btw, there should be no out-of-order errors or fenced errors during normal retry processing -- the first try should go through and others would be bounced with ""duplicate"" error which is effectively a success. this way all tries would be effectively successful and the intermittent error would be transparently handled by kafka without bubbling up to the application.",0,0.9823320508003235
1152485888,13391,jolshan,2023-03-29T21:07:05Z,"it does not happen before this stage. but artem is right. if we do process the callback twice, i suppose the second one will see it as a duplicate and return fine. i think my concern is that we return a timeout response + the callback response, but i guess this sort of thing can happen normally? i guess my question is whether we still want to return both callbacks with the response to addpartitionstotxn, or if it is just sufficient to ignore the first one.",0,0.9731020927429199
1152509597,13391,jolshan,2023-03-29T21:37:29Z,will do in [a link],0,0.9917600750923157
1152543409,13391,jolshan,2023-03-29T22:21:23Z,actually -- i misread the original comment -- i thought this was about callback time. i'm wondering if we want to report this in a different way after all. it would be a bit confusing to report this as remote time since this is technically still on the broker. i'm also not sure how we would parse the separate metric. is the idea that we would somehow get the time to send and receive the response and subtract it from the local time? i don't even see the local time metric getting incremented at this level. one idea is to take the request time and subtract the time to do the callback. i'd have to see if this is even possible though.,-1,0.8268356323242188
1152603124,13391,artemlivshits,2023-03-30T00:03:28Z,"actually, this is a higher level discussion that we should probably have on the kip thread, as it affects public metric semantics. i think it would be useful to have a separate metric, because it'll help with diagnosing extra latency in transactions that we're introducing with this rpc call. especially if we provide a feature flag to turn off this check for perf reasons -- we'd need to have some data to help the admin make a decision.",0,0.9891803860664368
1152615315,13391,artemlivshits,2023-03-30T00:26:37Z,synchronization?,0,0.9824883341789246
1152617531,13391,artemlivshits,2023-03-30T00:32:15Z,"if we'll have a thread pool of network threads, we'd need to synchronize this too. so we probably need to add a comment here.",0,0.9913699626922607
1152624055,13391,artemlivshits,2023-03-30T00:48:02Z,"the kip also mentions a race condition where the transaction may be aborted just after we've verified it, but before we got the reply, it doesn't seem like this pr addresses that, do we plan to do it in a different pr?",0,0.977863609790802
1153539479,13391,jolshan,2023-03-30T16:56:29Z,thanks for the reminder -- i need to remember the details here.,1,0.7831645011901855
1153540952,13391,jolshan,2023-03-30T16:57:51Z,i don't recall having a pool of network threads. this would just be the one send thread for now i think.,0,0.9552776217460632
1154744670,13391,artemlivshits,2023-03-31T17:49:25Z,"currently we only have one thread and it might be the case forever, but from this code the threading model is not obvious and it would be useful to have a comment that we don't need synchronization for inflightnodes because inflightnodes is only accessed from methods that are called on the sender's thread.",0,0.9891018271446228
1157599255,13391,jolshan,2023-04-04T18:07:21Z,"i've changed the internal details a bit so i no longer have an identifier that the first check succeeded. we append to the log on callback. originally, i was going to update the psm entry to contain the first offset and then we would remove the entry on the end marker. however, now we don't write the offset until the first append. (we can check for the next ones, but not the first append). the later changes with the epochs will make this not necessary since we bump the epoch on the marker write. i'm trying to think how we can handle this in the old clients case on the first append -- if there are any indicators we can check.",0,0.9658592343330383
1157781323,13391,jolshan,2023-04-04T21:20:40Z,"one option here is to check the timestamp of the last time the entry was updated if there is no ""last txn"" information. on the first append, the timestamp should not change on the entry. (i believe it only changes on data appends and txn markers)",0,0.9944429993629456
1158766750,13391,jolshan,2023-04-05T16:40:42Z,i'm going to keep what i have for now -- we can revisit the action queue if we want later.,0,0.9778579473495483
1160343683,13391,artemlivshits,2023-04-07T00:02:30Z,"if we don't want to put too many things in one change, we could implement the race condition checks in a separate change -- even though we didn't fully fix the problem we didn't regress (in fact improved quite a bit). on the other hand, fixing localtime metric should be done in this change, because it worked before this change so if we don't fix it, it would be a regression. another approach (if it makes things simpler in any way) could be to split out the framework to run callbacks on request threads and add metrics there, then rebase this change on top of framework, so this change focuses on the transaction-specific stuff.",0,0.9877591729164124
1160355023,13391,artemlivshits,2023-04-07T00:38:32Z,"update comment to say ""requestchannel and request"".",0,0.9942160248756409
1160356274,13391,artemlivshits,2023-04-07T00:42:51Z,we should set it to null once we're done with the request (in a finally clause). this would avoid issues of a request living longer than needed because it's referenced in a thread local of some request thread.,0,0.9920336604118347
1160357216,13391,artemlivshits,2023-04-07T00:46:09Z,"this change uses only one callback, but as a generic framework, a request could run multiple rpcs during its processing, so we should do `currentrequest.set(request.originalrequest` (and clean it afterwards).",0,0.9932345747947693
1160357426,13391,artemlivshits,2023-04-07T00:46:50Z,maybe use `callback` instead of `request`.,0,0.9892579913139343
1160363167,13391,artemlivshits,2023-04-07T01:04:07Z,"i think the metric could be updated when the response is sent in request.fun(), so it may actually see some value in request.originalrequest.callbackrequestdequetimenanos and no value in callbackrequestcompletetimenanos, in which case the processing time could be negative. also, if multiple callbacks are used during the request processing, we'd lose callback processing time for all but last callback (for this we could add a comment, to add this logic if we have multiple callbacks to handle).",0,0.9918051958084106
1160803600,13391,jolshan,2023-04-07T16:06:04Z,"are you saying network client sends the response + updates the metrics before we reach line 115, so we should put the complete message as part of the response? i'm not sure the best way to put that in the callback. i'll have to think about it.",0,0.7639978528022766
1160807017,13391,jolshan,2023-04-07T16:12:00Z,i wasn't sure if we would have a new request here though. we could be handling this callback after the original request returned right?,0,0.8691861033439636
1160817791,13391,jolshan,2023-04-07T16:30:14Z,we've opted to return a retriable error for the case where the second response is returned first.,0,0.9813247323036194
1160819448,13391,jolshan,2023-04-07T16:32:51Z,let's do the check before append in a followup -- here is the jira -- [a link],0,0.9873268008232117
1160830029,13391,jolshan,2023-04-07T16:51:33Z,ah i think i figured it out.,0,0.9329606890678406
1160831069,13391,jolshan,2023-04-07T16:53:25Z,ah i misunderstood your comment. i guess i'm just not sure what setting current request here does for us. why would we use currentrequest instead of original request? unless we wanted to schedule another callback :grinning_face_with_sweat:,-1,0.9237316846847534
1160849589,13391,artemlivshits,2023-04-07T17:27:55Z,"we might in the future. from the implementation perspective it may seem like we have ""the request"" and ""the callback"", but conceptually we should think in terms of a request that may run a few asynchronous operations and then continue processing, in which case we can have multiple callbacks in the context of the same request. so logically it's like this: -- request starts processing 1. do some processing on a broker request thread 2. do async operation (rpc, or maybe even async storage access in some distant future) 3. continue processing on a broker request thread. 4. do some async operation 5. continue processing on a broker request thread 6. do some async operation 7. finish processing on a broker request thread -- request is done in this case the steps 1, 3, 5, 7 would be accounted as local time and logically we just keep processing the same request, only instead of blocking the thread in steps 2, 4, 6, we wait without blocking the thread.",0,0.9916754961013794
1160872423,13391,jolshan,2023-04-07T18:10:20Z,"i think the issue is that the way that i implemented the metric is that we only have callback start and end. if we wanted to store results of multiple callbacks, we would need to change this. i'm tempted to tackle this sort of thing in a followup change to avoid overcomplicating this one.",0,0.8016214966773987
1160875392,13391,artemlivshits,2023-04-07T18:15:07Z,"i think it's still good to keep the request.originalrequest.callbackrequestcompletetimenanos = some(time.nanoseconds()) here as well. looking at the code, request could end in many different ways, some could happen before callback completion, some may happen after callback completion. there are some error cases, like connection disconnects that may not go through the success path.",0,0.966049075126648
1160879089,13391,artemlivshits,2023-04-07T18:22:06Z,"instead of doing this, i would put the request.callbackrequestcompletetimenanos = some(time.nanoseconds()) back after the callback.fun() call and just update the place where we update metrics to take the current time if callbackrequestcompletetimenanos is empty. then we don't need chase all the code paths that we could go through before updating the metrics.",0,0.9884170889854431
1160883532,13391,artemlivshits,2023-04-07T18:30:54Z,"1. isn't it backwards? the complete time should be larger than deque time. 2. if we do the following logic, then it should work regardless of whether we arrive here before setting callbackrequestcompletetimenanos or after setting callbackrequestcompletetimenanos. [code block]`",0,0.9940798878669739
1160892559,13391,artemlivshits,2023-04-07T18:49:23Z,"yeah, if we need to make larger change to complete the framework, then we should definitely do in a follow-up change, but i think in this case all we need to do is this: [code block] and then we've got ourselves a fully functional framework for supporting arbitrary number of async calls in a request processing :-).",1,0.7688853144645691
1160895598,13391,jolshan,2023-04-07T18:55:52Z,ooops -- good call.,1,0.9801828861236572
1160896272,13391,jolshan,2023-04-07T18:57:08Z,"hmm -- so we should only update if callback is also defined. i'm also not sure about setting it twice, so we should only set after fun() if it is not already set.",0,0.9013940095901489
1160975587,13391,artemlivshits,2023-04-07T21:27:29Z,need to clear as well in the finally clause.,0,0.9919499158859253
1160976550,13391,artemlivshits,2023-04-07T21:30:02Z,"not sure if the 'if' clause is required, prevcallbackstimenanos would be 0 if there was no prev callback.",0,0.9858204126358032
1160980316,13391,jolshan,2023-04-07T21:40:29Z,"i just wanted to avoid doing all this extra code if not needed. in my head, it made more sense to someone reading it.",0,0.8867784142494202
1161050689,13391,artemlivshits,2023-04-08T02:40:25Z,"we don't need to pass the current request, this could be completely encapsulated within wrap. in fact, having a request argument here makes it look like that we could pass some arbitrary request, while here we need exactly the one that is currently processed on the thread.",0,0.993436872959137
1161050986,13391,artemlivshits,2023-04-08T02:43:44Z,or currentrequest == null,0,0.9691466689109802
1161051019,13391,artemlivshits,2023-04-08T02:44:17Z,ok,0,0.8787186145782471
1161051461,13391,artemlivshits,2023-04-08T02:48:44Z,do we have a test that actually tests that we'd get a failure if we try to produce without adding the partition to transaction first?,0,0.9932317733764648
1161058187,13391,artemlivshits,2023-04-08T04:07:10Z,producerstatemanager.activeproducers.get(producerid).exists(entry => entry.currenttxnfirstoffset.ispresent),0,0.9877075552940369
1161058423,13391,artemlivshits,2023-04-08T04:09:33Z,leaderlogiflocal.exists(leaderlog => leaderlog.hasongoingtransaction(producerid)),0,0.9908630847930908
1161846085,13391,jolshan,2023-04-10T15:59:45Z,"my original concern was that if we just used the thread local, we would access it when the inner method is called. i guess i can just save a local variable when wrap is called and pass that value into the inner method.",0,0.98398756980896
1161847053,13391,jolshan,2023-04-10T16:00:34Z,"depends what you mean here. if you mean a unit test -- yes. if you mean a integration test, no because the correct behavior is built into the producer.",0,0.989984393119812
1161854813,13391,jolshan,2023-04-10T16:06:53Z,actually hmm -- i suppose this test is not present if you mean the exact path of returning the error and not producing to the log. i really did think i added such a test to replica manger test. i can try to add this path.,0,0.9619923830032349
1161874495,13391,jolshan,2023-04-10T16:31:12Z,"this is a java map, so that doesn't work. i can convert to scala, but not sure that is much better.",0,0.7522537112236023
1161896585,13391,jolshan,2023-04-10T16:58:16Z,we do have tests from the previous pr that return errors if the partition is not added to the txn. see [a link],0,0.9946945309638977
1161909242,13391,junrao,2023-04-10T17:14:34Z,our long term goal is to replace the scala code with java. could we write this new class and the corresponding test in java?,0,0.9921532273292542
1161915489,13391,junrao,2023-04-10T17:22:40Z,"the above comment still says ""is still under developement"". is the latest version indeed stable? or should we change the comment accordingly?",0,0.9911311268806458
1161918638,13391,junrao,2023-04-10T17:26:46Z,the params of this method is getting a bit large. could we add the javadoc explaining each of the param?,0,0.9137444496154785
1161932999,13391,junrao,2023-04-10T17:45:39Z,coordinatornotavailable error is not listed in produceresponse. should we add it there and verify that it's handled as expected by existing clients?,0,0.991807758808136
1161943463,13391,junrao,2023-04-10T17:58:16Z,does this need to be volatile?,0,0.9890959858894348
1161946467,13391,jolshan,2023-04-10T18:01:40Z,added a line to the replicamanager test to see that we return early on the error in the callback.,0,0.9896859526634216
1161971721,13391,junrao,2023-04-10T18:33:41Z,do we have a use case where the same callback needs to be handled multiple times by the request thread? how do we prevent that the callback is added an infinite number of time to the callback queue?,0,0.946835994720459
1161978192,13391,junrao,2023-04-10T18:41:52Z,"so, `originalrequest.callbackrequestcompletetimenanos.isempty` is expected to be true? should we add a warning log if it's false?",0,0.9951812624931335
1161979607,13391,junrao,2023-04-10T18:43:46Z,"since we don't expect to see wakeuprequest here, should we add a warning log?",0,0.9848396182060242
1161982117,13391,junrao,2023-04-10T18:46:51Z,this seems to be a more general mechanism than actionqueue. could we move all existing actionqueue usage to callback queue and get rid of actionqueue? this could be done in a separate pr.,0,0.9920952916145325
1161984615,13391,junrao,2023-04-10T18:50:06Z,"incomplete sentence ""check if we have already"".",0,0.9755867719650269
1161987786,13391,junrao,2023-04-10T18:54:20Z,network_exception is not listed in produceresponse. should we add it there and verify that it's handled as expected by existing clients?,0,0.9942824840545654
1161996676,13391,junrao,2023-04-10T19:05:43Z,addpartitionstotxncollection seems unused?,0,0.9843053221702576
1162000865,13391,junrao,2023-04-10T19:11:11Z,"since this can be skipped, should this be warn instead of error?",0,0.9914044141769409
1162001708,13391,junrao,2023-04-10T19:12:20Z,extra space before returned,0,0.9793676137924194
1162003823,13391,junrao,2023-04-10T19:15:09Z,"hmm, not quite sure that i follow. do you mean that we return invalid_record to be compatible for old clients?",0,0.532069742679596
1162043968,13391,jolshan,2023-04-10T20:06:24Z,i will update the comment.,0,0.9841499924659729
1162044614,13391,jolshan,2023-04-10T20:07:21Z,it is retriable -- currently if the error is retriable we just retry. it seems like most retriable errors are not enumerated specifically.,0,0.981137752532959
1162045206,13391,jolshan,2023-04-10T20:08:02Z,^ ditto comment about retriable errors.,0,0.5865772366523743
1162045551,13391,jolshan,2023-04-10T20:08:23Z,"we can make it volatile, but this is only really used in tests.",0,0.9875487089157104
1162046736,13391,jolshan,2023-04-10T20:09:36Z,artem requested this. see comment here. [a link] there is currently not a way to prevent infinite callbacks.,0,0.9768334627151489
1162047387,13391,jolshan,2023-04-10T20:10:12Z,it is not true if we returned a response. we also update the value there.,0,0.9930222630500793
1162047588,13391,jolshan,2023-04-10T20:10:25Z,we can add a warning log.,0,0.9886974096298218
1162049144,13391,jolshan,2023-04-10T20:12:25Z,"yes. sorry for the confusion. in the kip we mention invalid_txn_state for the new clients, but old clients use invalid_record for compatibility. i will update the comment.",-1,0.9908177852630615
1162109668,13391,jolshan,2023-04-10T21:38:30Z,let's do in a separate pr.,0,0.9902383089065552
1163283951,13391,junrao,2023-04-11T20:21:19Z,"hmm, not sure that i follow. in the false case, it seems that we just don't set `callbackrequestcompletetimenanos`? this is a bit weird since the callback is completed.",-1,0.9457961916923523
1163284515,13391,junrao,2023-04-11T20:21:57Z,could we file a jira to track this in a followup?,0,0.9946082830429077
1163287233,13391,junrao,2023-04-11T20:23:51Z,could this be private? ditto for a few other helper methods in this file.,0,0.988785982131958
1163292661,13391,junrao,2023-04-11T20:28:22Z,"""the error map should remain empty."" what does this mean?",0,0.9843097925186157
1163294534,13391,junrao,2023-04-11T20:29:59Z,get rid of the new line since the following validation is related to this action?,0,0.9877641797065735
1163323491,13391,junrao,2023-04-11T20:55:26Z,"basesequence is redefined as val. so, this is unused.",0,0.982947051525116
1163335886,13391,junrao,2023-04-11T21:08:11Z,do we need this? it doesn't seem the request handler thread is involved in the test.,0,0.9773069620132446
1163418845,13391,jolshan,2023-04-11T23:22:00Z,"it means that we didn't complete the request. if we returned an error response, we would populate the map. but if it just replaced the old data, we don't send a response.",0,0.980911135673523
1163421308,13391,jolshan,2023-04-11T23:26:54Z,"there are two cases according to artem -- one where we send a response via network client and one where we don't (and we have more callbacks) in case a, we set in the network client and that is the end of handling of the request. this is also when the metric is updated. in case b, we don't set it there so we must do it here. i have the check to match the same sort of protocol we see in kafka apis where we check if the value is -1. maybe it's fine to set it twice in case a as we won't update the metrics again, but i did it for consistency.",0,0.9893513321876526
1163421979,13391,jolshan,2023-04-11T23:28:30Z,oops. i see we changed this logic. i will fix the comment.,-1,0.9843899607658386
1163429337,13391,jolshan,2023-04-11T23:44:47Z,"we still call the wrap method which checks if we are on the request handler thread. since we are not it will fail via illegal state exception. we we set the bypass, it just runs the callback.",0,0.9808438420295715
1163446164,13391,junrao,2023-04-12T00:23:43Z,"i am still a bit confused on this. case a - only 1 callback. in this case, callbackrequestcompletetimenanos is never set and is expected to be empty. case b - multiple callbacks. in this case, after the first callback, callbackrequestdequeuetimenanos is set. so, when the 2nd callback is processed, we set callbackrequestcompletetimenanos to empty before executing the callback. when we get here, callbackrequestcompletetimenanos is expected to be empty. so, it seems that in both case a and b, we expect callbackrequestcompletetimenanos to be empty?",-1,0.5616987347602844
1163659843,13391,artemlivshits,2023-04-12T06:02:22Z,"basically, we should search for `apilocalcompletetimenanos` and update the callbackrequestcompletetimenanos in similar places. my understanding is that we can send the reply during request / callback and it may complete (concurrently) before we end the request / callback or after we end request / callback. in which case we want the end time to be the earliest of the two. usually, the way it's done is the start time is set at the start of the request / callback processing and the end time is set after, but if the end time is not set then the metric is reported, then we just report the current time.",0,0.9922730326652527
1163676408,13391,artemlivshits,2023-04-12T06:26:09Z,"right now, this framework just accounts for a single logical request that does a few non-blocking calls and continues serially after each call. we could probably add a check that prohibits adding a second .wrap during request / callback execution.",0,0.9883301258087158
1164335669,13391,jolshan,2023-04-12T15:55:15Z,"in case a, we set it in the network client -- it will not be empty. in case b, it is empty and we set it. then, when executing the next callback, we take this time and subtract it from the start of the new callback. this gives us total time of all.",0,0.9892386198043823
1164392731,13391,junrao,2023-04-12T16:45:31Z,"thanks for the explanation. i understand it now. callbackrequestcompletetimenanos can be non-empty if the response is sent before the callback completes. currently, we update the metric when the sending of the response completes. so, a more accurate place to set callbackrequestcompletetimenanos in requestchannel is when the response send completes. an alternative approach is to delay the updating of the request time metrics until the callback completes. this simplifies the setting of callbackrequestcompletetimenanos since it only needs to be done in kafkarequesthandler and is more accurate since we don't need to cut off callbackrequestcompletetimenanos by response send complete time. both of these could be addressed in a followup jira.",1,0.8834109306335449
1164399008,13391,jolshan,2023-04-12T16:51:49Z,"i'm not sure i follow the first part since right now, we need to account for all the callback local times. unless we change to a cumulative callback total time where we periodically add to it, we will need to update either on the send or when the callback completes (if we don't send yet) i'm also not sure about waiting until the callback completes because that is after we send via the network client and that is no longer considered ""local time""",0,0.8662031292915344
1164424805,13391,junrao,2023-04-12T17:17:36Z,"for simplicity, let's just assume there is only one callback for now. currently, the code sets callbackrequestcompletetimenanos when the response is being sent. if the callback has been started, but not completed at that point, the measurement of the callback portion time is not accurate. if we delay the cut off of callbackrequestcompletetimenanos at the time when request time metric is updated (which currently is when the response send completes), we allow for more accurate measurement of the callback portion time. for your second question, yes, it's a bit weird to report the callback time as 'local' after the response is being sent. however, 'local' really reflects the amount of time a request handler thread is tied up for processing a request. from that perspective, it could also make sense. if we cut off the callback portion of the time by response send time, we could leave a portion of the request thread time unaccounted for?",-1,0.5420229434967041
1164431328,13391,jolshan,2023-04-12T17:24:15Z,i asked to just assume one callback earlier but i was told we should just implement this now :grinning_face_with_sweat: (thread here [a link] i'm not sure i follow which scenario is inaccurate?,0,0.8730581998825073
1164445859,13391,junrao,2023-04-12T17:33:50Z,"in the more general case, the callback is not guaranteed to be completed when the response is sent, right? in that case, the code in requestchannel cuts off callbackrequestcompletetimenanos at response send time. when the callback completes, kafkarequesthandler doesn't set callbackrequestcompletetimenanos since it's not empty. this means the measurement of callback time is not accurate, right?",0,0.9683642983436584
1164460056,13391,jolshan,2023-04-12T17:48:36Z,"given that we have only one case right now i guess i'm not sure we have a general case -- but in the current case, we complete the callback by sending the response. i guess i saw this protocol working as follows: a) we have one callback and send the response in which local time is correct b) we have multiple callbacks and the first few do not send the response. we updated after calling the callback. then the final one sends the response (case a) we always must return in the final callback because we only use this callback if we've already returned from handle. we must return via the callback in my understanding.",0,0.9684813618659973
1164476174,13391,junrao,2023-04-12T18:04:26Z,"yes, in the current usage where the last callback sends the response as the last thing, it doesn't make much difference. i was thinking that the callbacks in actionqueue are executed after the response is generated. if want to replace actionqueue with the callback queue, we need to handle the more general case.",0,0.9837357401847839
1164479606,13391,jolshan,2023-04-12T18:08:12Z,"yeah -- i guess the previous decisions were made without considering the action queue. i'm wondering if it is better to leave as is and change via a followup or simplify back to ""base case"" (ie, case a which is currently what we do)",0,0.9537133574485779
1164488222,13391,junrao,2023-04-12T18:16:22Z,"yes, we can leave the pr as it is. could we file a jira to revisit action queue? we can make any needed changes there.",0,0.9865795969963074
1164633122,13391,junrao,2023-04-12T20:41:15Z,it's probably used for to log the destination broker on which the request fails. ditto in other logging.,0,0.9845350980758667
1164638992,13391,jolshan,2023-04-12T20:48:13Z,i will switch to the destination node.,0,0.9847754836082458
61458168,1251,gwenshap,2016-04-28T16:23:35Z,nit: oracle's javadoc guide specifically says: [a link],0,0.9770606756210327
61458366,1251,gwenshap,2016-04-28T16:25:03Z,"""iff"" means ""if and only if"" and is correct in this context. i don't think it was a typo. if you find ""iff"" unclear, feel free to replace with ""if and only if""",0,0.9791593551635742
61458701,1251,gwenshap,2016-04-28T16:27:09Z,these are new public apis right? ( - correct me if i'm wrong).,0,0.881885826587677
61459284,1251,gwenshap,2016-04-28T16:30:38Z,"it is a bit hard to tell from the diff, but did you add a new argument as the first in the list? is there a reason? we usually add new arguments at the end.",0,0.9074598550796509
61459399,1251,gwenshap,2016-04-28T16:31:16Z,the nulls are getting a bit hard to read. do we want constants for no_apis and no_metadata?,-1,0.5171754956245422
61459449,1251,ijuma,2016-04-28T16:31:33Z,looks like only the consumer and producer packages are considered api: [a link],0,0.9526229500770569
61460110,1251,gwenshap,2016-04-28T16:36:22Z,thanks :),1,0.9741679430007935
61460735,1251,gwenshap,2016-04-28T16:40:12Z,"""trace"" maybe? this seems incredibly chatty even for debug.",-1,0.7764753103256226
68186750,1251,ijuma,2016-06-23T07:24:20Z,why was this removed?,0,0.9856475591659546
68190038,1251,ijuma,2016-06-23T07:52:43Z,"we probably want a `kafkaconsumer` and `kafkaproducer` test that expects a newer than supported broker. sounds like it needs to be a system test. it probably needs a request to be bumped up too before it works. hmm, actually, we should have system tests for broker versions that don't support `apiversionsrequest` (e.g. 0.9.0.1 and 0.8.2.1). in addition, it would be great if we could detect if something is missing from this list at unit/integration test time. any ideas on how to do that?",0,0.9741753339767456
68190553,1251,ijuma,2016-06-23T07:56:40Z,"i think it would be better for `ready` to be the state where one sends requests. this means that if the api version requests are not needed, we can automatically transition from `connected` to `ready`. thoughts? cc .",0,0.9904898405075073
71025620,1251,SinghAsDev,2016-07-15T19:06:20Z,"it should not be, fixed in next version.",0,0.9844204783439636
71026255,1251,SinghAsDev,2016-07-15T19:11:00Z,"added system test against trunk and older broker versions. the interesting tests like testing against unsupported broker versions, will probably have to wait till we have such versions. the list of apis used by client is similar to the practice of specifying used errors for a request. as you said, it will be nice to have this checked dynamically at test time, however nothing comes to my mind with which we can do that. will be happy to accommodate any suggestion on this.",1,0.965288519859314
71026376,1251,SinghAsDev,2016-07-15T19:11:49Z,"i do not have a strong bias on this, will be happy to make the change if you really think it is a must.",1,0.9727314114570618
74093108,1251,dpkp,2016-08-09T16:25:49Z,"apologies for the late review, but i feel like it would be much clearer if the state transition were: `disconnected -> connecting -> checking_api_versions -> connected` it strikes me that the main reason you have the ready state is to manage `cansendmore`, but i can't actually find where `cansendmore` is called in the api version request flow. networkclient `dosend` skips the `cansendmore` check, i believe, so do we really need that extra layer of complexity? and so would it be possible to check for `this.requiredapiversions == null` directly here and set the next connectionstate to connected if null, or to checking_api_versions if not? then in the api version response handler the state could be updated to connected.",0,0.9829275012016296
74093303,1251,dpkp,2016-08-09T16:26:46Z,why not use a future + callback handler? the inline check in `handlecompletedreceives` is a bit confusing / buried,0,0.6076602935791016
91202952,1251,cmccabe,2016-12-07T00:18:58Z,"hmm. ""java.util.collection"" could be something unsorted like a list. how about making this a map from apikey to apiversion so that we can compare it with the server response more efficiently?",0,0.9676909446716309
91203250,1251,cmccabe,2016-12-07T00:21:40Z,"hmm. i was initially confused by what the ""apis"" parameter did. can we call this ""requiredapiversions""? same comment for the other constructor overloads.",-1,0.6704268455505371
91203437,1251,cmccabe,2016-12-07T00:23:19Z,"can we have ""if"" statements instead of the ternary operator?",0,0.9943232536315918
92007667,1251,hachikuji,2016-12-12T18:25:33Z,nit: feels like overkill to have constants for `null` which are only used in the constructors.,-1,0.9386391639709473
92007933,1251,hachikuji,2016-12-12T18:26:55Z,might be helpful to add a brief comment here explaining the behavior if `requiredapiversions` is null.,0,0.9922329187393188
92008244,1251,hachikuji,2016-12-12T18:28:25Z,+1. this is a little hard to read.,-1,0.9423753619194031
92009315,1251,hachikuji,2016-12-12T18:33:31Z,"might be helpful to add a short comment explaining the new states and transitions. for example, if the version check fails, do we go to `disconnected`?",0,0.9932751655578613
92036463,1251,hachikuji,2016-12-12T20:48:34Z,"nit: this could be `else if`, right? also, i think we could do an `instanceof` check on the response body, and pass the cast result to `handleapiversionsresponse` instead of going through the `struct` instance.",0,0.9926161766052246
92036719,1251,hachikuji,2016-12-12T20:49:55Z,nit: `else if`.,0,0.9857265949249268
92038835,1251,hachikuji,2016-12-12T21:00:39Z,"i'm in favor of this suggestion, but maybe overloading `connected` would be misleading. perhaps the states could be `disconnected -> connecting -> checking_api_versions -> ready` instead?",0,0.9748263359069824
92042824,1251,hachikuji,2016-12-12T21:21:12Z,"does this need to be concurrent? `networkclient` itself is not thread-safe. also, i wonder if queue is the right data structure. would a `set` make more sense? are there any cases we'd add the same node more than once? now that i'm thinking about it... do we need this collection at all? it seems like it is identical to the set of nodes which are in the `connected` state. maybe we could just get that directly from `clusterconnectionstates`?",0,0.9667907953262329
92043237,1251,hachikuji,2016-12-12T21:23:30Z,nit: this change seems unneeded,0,0.5049099922180176
92043284,1251,hachikuji,2016-12-12T21:23:50Z,nit: could be static.,0,0.961689829826355
92043619,1251,hachikuji,2016-12-12T21:25:26Z,nit: why not let this be `list `? it's usually preferable to preserve type information as long as possible. same in `kafkaproducer` and the test cases.,0,0.9938634634017944
92044055,1251,hachikuji,2016-12-12T21:27:45Z,this looks like same code as in `kafkaconsumer`. perhaps we should move it to `utils`?,0,0.9935376048088074
92047117,1251,hachikuji,2016-12-12T21:43:40Z,"nit: seems we could use a singleton, maybe `apiversionsrequest.instance` or something like that?",0,0.9914484620094299
92048027,1251,hachikuji,2016-12-12T21:48:13Z,should we try to use `cansendrequest`?,0,0.9941803216934204
92049126,1251,hachikuji,2016-12-12T21:53:42Z,might this be simpler if we just have two methods: `cansendrequest(string node)` and `cansendapiversionrequest(string node)`?,0,0.9939528107643127
92049847,1251,hachikuji,2016-12-12T21:57:36Z,"these tests are a little obscure. i wonder if it would be a little clearer to 1) use only one api instead of a list, and 2) reference the versions directly using `protoutils`?",-1,0.7821290493011475
92050099,1251,hachikuji,2016-12-12T21:58:38Z,kudos for adding the system test!,1,0.987845242023468
92050177,1251,hachikuji,2016-12-12T21:59:03Z,nit: why remove the newline?,0,0.9428306818008423
92050279,1251,hachikuji,2016-12-12T21:59:39Z,nit: why remove the newline?,0,0.9428306818008423
92050477,1251,hachikuji,2016-12-12T22:00:40Z,"also, maybe we could call this `consumer_apis` and get rid of the comment, which doesn't add much value.",0,0.9905926585197449
92074335,1251,ijuma,2016-12-13T00:36:53Z,i think the ternary operator is probably ok if the connection state checks were extracted into a variable.,0,0.9809731841087341
92074732,1251,ijuma,2016-12-13T00:40:05Z,`else if` is not required here since the `if` always throws right? or do you just mean as a style thing it's clearer?,0,0.9930424690246582
92079250,1251,ijuma,2016-12-13T01:18:29Z,"yeah, that would be similar to `api_versions_response` in `apiversionsresponse`.",0,0.9931981563568115
92154634,1251,ijuma,2016-12-13T12:01:02Z,it seems a bit inconsistent that `connected` clears the internal list while other methods like `disconnected` don't. maybe we should call `clear()` from `poll`?,0,0.8857181072235107
92154840,1251,ijuma,2016-12-13T12:02:18Z,"we should add `latest_0_10_1` and `latest_0_10_0` too. since they support `apiversionsrequest`, i take it that the behaviour is more graceful?",0,0.9927418231964111
92155097,1251,ijuma,2016-12-13T12:04:08Z,nit: maybe there should be no default for `should_fail` since we always pass a value.,0,0.9898033142089844
92155443,1251,ijuma,2016-12-13T12:06:18Z,seems like they can be final.,0,0.9844457507133484
92155793,1251,ijuma,2016-12-13T12:09:05Z,nit: missing space before `:`.,0,0.8701838254928589
92156071,1251,ijuma,2016-12-13T12:11:06Z,it would be good to include more information about the failure in the message.,0,0.9831234216690063
92156138,1251,ijuma,2016-12-13T12:11:28Z,do we want to validate that it failed for the right reason?,0,0.9875410199165344
92156687,1251,ijuma,2016-12-13T12:15:26Z,why are we duplicating all of this logic here? can we not reuse the existing serialization logic?,0,0.9860966801643372
92243074,1251,SinghAsDev,2016-12-13T19:11:41Z,sounds good.,1,0.9417163729667664
92243960,1251,SinghAsDev,2016-12-13T19:16:03Z,"i don't think it has to be sorted, though having a consistent order will make it easier to read in logs. also, i failed to see why changing this to a map is going to be more efficient. the checking is happening in `handleapiversionsresponse` and response already has a map of keys to supported versions.",0,0.9817294478416443
92244101,1251,SinghAsDev,2016-12-13T19:16:50Z,"after taking out `connected` state, this is no longer an issue.",0,0.9908455014228821
92259621,1251,SinghAsDev,2016-12-13T20:31:40Z,"we would need some kind of ds to keep track of api versions request that need to be sent during poll. if we were to use `clusterconnectionstates` to do this, we will either have to add a state between `checkingapiversions` and `ready` to indicate that api versions check is already in progress for a connection, or we will have to move trigger for sending api versions from poll to handleconnections. i am more in favor of having it the way it is right now, and have the api version requests be sent during polls. however, i do agree that the ds for this can be a set, and i will make that change.",0,0.9791324734687805
92265829,1251,SinghAsDev,2016-12-13T21:05:22Z,"`cansendrequest` also checks if connection state is `ready`, which won't be true here.",0,0.9921858310699463
92266604,1251,SinghAsDev,2016-12-13T21:09:25Z,good point.,1,0.9406900405883789
92270976,1251,SinghAsDev,2016-12-13T21:32:08Z,"if the version check fails, connection is closed. no reason to go in `disconnected` state, as their is no way broker would start supporting the version without having to terminate the connection.",0,0.9830690622329712
92279721,1251,SinghAsDev,2016-12-13T22:16:58Z,"not sure if those changes help, but making those changes anyway. let me know if you meant something else.",0,0.9571587443351746
92285072,1251,SinghAsDev,2016-12-13T22:49:22Z,"not sure, if you wanted me to add checks for exception messages, as it makes these tests a little brittle. i anyway, went ahead and added those checks. let me know if you think they don't add much.",-1,0.5987518429756165
92286131,1251,SinghAsDev,2016-12-13T22:55:28Z,ahh.. left over from some debugging.,0,0.8885897397994995
92294978,1251,hachikuji,2016-12-13T23:56:13Z,"yeah, it's personal preference, so feel free to ignore. the `else if` makes the relation between the two cases stand out a bit more.",0,0.9678872227668762
92295136,1251,hachikuji,2016-12-13T23:57:39Z,i think this check and the one above are redundant. maybe we can remove the check for the api key?,0,0.9806196689605713
92296138,1251,hachikuji,2016-12-14T00:05:20Z,would be nice to have `node` somewhere in this name. maybe `nodesrequestingapiversions`?,0,0.9938964247703552
92296968,1251,hachikuji,2016-12-14T00:13:05Z,or maybe `nodesneedingapiversionsfetch`? might be closer to the usage.,0,0.994005024433136
92297033,1251,hachikuji,2016-12-14T00:13:38Z,"if the node is in `apiversionsrequests`, then wouldn't the state already be `checking_api_versions`?",0,0.9952844977378845
92299342,1251,hachikuji,2016-12-14T00:33:07Z,nit: the check seems unnecessary.,-1,0.6377159953117371
92303136,1251,hachikuji,2016-12-14T01:02:50Z,"i'm wondering if we can simplify this a little bit. once the connection has completed, it seems that both `selector.ischannelready()` and `inflightrequests.cansendmore()` should both be true. so instead of going through this intermediate collection before sending the `apiversionrequest`, perhaps we can just immediately send the request when we transition to `checking_api_versions`? i think that would let us get rid of the `apiversionsrequests` set. does that seem right?",0,0.9897820949554443
92303744,1251,SinghAsDev,2016-12-14T01:08:18Z,"yea that is one option that i was pointing to earlier. it has been so long that i do not remember why i chose this over sending, but one reason that comes to my mind is that handling all sends receives from poll seems like a good idea. however, i am open to change that.",0,0.5321991443634033
92305344,1251,hachikuji,2016-12-14T01:22:43Z,"never mind. i talked with jun and ismael about this and ""connected"" currently does not imply ""ready.""",0,0.7828288674354553
92316606,1251,hachikuji,2016-12-14T03:24:29Z,nit: alignment,0,0.9538867473602295
92316756,1251,hachikuji,2016-12-14T03:27:07Z,nit: doesn't seem like this method adds much.,-1,0.904937207698822
92317190,1251,hachikuji,2016-12-14T03:33:42Z,i don't think we need this one.,0,0.5457159280776978
92318309,1251,hachikuji,2016-12-14T03:47:33Z,"not sure you saw my previous comment, but these two constants seem unneeded.",0,0.8754485845565796
92320200,1251,SinghAsDev,2016-12-14T04:18:28Z,"this was explicitly asked in one of the previous review comments, having bunch of nulls in a method call, makes it hard to read. if this is not a big concern, maybe we can leave it in as it makes code more readable? lmk.",0,0.9497842192649841
92433034,1251,hachikuji,2016-12-14T16:34:34Z,"sure, that's fair.",0,0.8658287525177002
92452791,1251,hachikuji,2016-12-14T18:07:07Z,seems this is unused. do we need it?,0,0.8678163886070251
92456223,1251,hachikuji,2016-12-14T18:23:38Z,"the second argument here is used to indicate when the request is a metadata request initiated by the `networkclient`. this lets us send metadata requests externally without having the `networkclient` intercept them (i think we were the ones who added this feature initially :winking_face: ). i think it would probably make sense to do the same for the `apiversionsrequest`. it seems a little safer and i can imagine using this api from the admin client in the future, for example.",0,0.9453350305557251
92496174,1251,SinghAsDev,2016-12-14T21:45:07Z,"i initially thought to do that, but it is very likely that someone would have raised that as not required in review. however, now that is is raised, happy to add it. if there are no more reviews, i will shortly update the pr here.",1,0.9055574536323547
92498039,1251,hachikuji,2016-12-14T21:53:51Z,could we use a single `isinternalrequest` flag combined with an `instanceof` check to distinguish the two cases?,0,0.9941617846488953
92501345,1251,SinghAsDev,2016-12-14T22:10:43Z,"one can argue against it, as now the same check has to be done at multiple places. if number of such internal requests grow beyond two, then probably it won't make sense to keep a flag for each of them. at that point it would be better to add a method like `boolean isinternalrequestoftype(apikeys apikey)`. makes sense?",0,0.9888384342193604
92503655,1251,hachikuji,2016-12-14T22:23:26Z,"we should probably have the `instanceof` checks anyway prior to casting the response object, so this just removes the need for an extra field. is there any downside?",0,0.9926698207855225
92505757,1251,SinghAsDev,2016-12-14T22:35:00Z,"not sure i am following you here. below is one of the places where `isinternalmetadatarequest` flag is used. [code block] are you suggesting that i change it to something like. [code block] if so, then we are talking about changing `metadataupdater` interface. do we really want to do that? do you see any other type of request being initiated by network client any time soon?",0,0.9787742495536804
92510635,1251,hachikuji,2016-12-14T23:03:03Z,"yeah, that's exactly what i was thinking. it seems like a nice improvement to let the `metadataupdater` interface accept an instance of `metadataresponse` directly so that it doesn't have to deal with casting itself.",1,0.6176903247833252
92513323,1251,hachikuji,2016-12-14T23:20:59Z,nit: seems we no longer have much use for `handlemetadataresponse`. maybe we just move its body here?,0,0.9869086146354675
92515767,1251,ijuma,2016-12-14T23:39:14Z,"nit: `oldest` and `latest` are not symmetric. also, it's a bit odd that we use different names for the field names (basically `current` and `minimum`). finally, why do we use `int` instead of `apikeys`?",-1,0.5367840528488159
92515994,1251,ijuma,2016-12-14T23:40:55Z,"if you look at `producerrecord`, we use a slightly different convention for `tostring` (i know we are not consistent everywhere, but i'm trying to improve that).",0,0.9733018279075623
92516990,1251,ijuma,2016-12-14T23:48:30Z,`collections.singletonlist` can be used to make this more concise.,0,0.99118971824646
92517073,1251,ijuma,2016-12-14T23:49:08Z,"i don't understand this name, why do we call it `used_api_key`?",0,0.9078091979026794
92517275,1251,ijuma,2016-12-14T23:50:41Z,i don't understand why we add +2 to `short.max_value` and then cast to `short` causing it to overflow?,0,0.9153200387954712
92517541,1251,ijuma,2016-12-14T23:52:41Z,don't we have some code that we can reuse for this? why are we manually serialising `apiversionresponse`?,0,0.9944434762001038
92517616,1251,ijuma,2016-12-14T23:53:18Z,we should have a timeout here so that we don't loop forever in case of a bug.,0,0.9669779539108276
92517670,1251,ijuma,2016-12-14T23:53:47Z,"are some of these fields supposed to be `final` (existing code, i know)?",0,0.9928414821624756
92517741,1251,ijuma,2016-12-14T23:54:17Z,nit: maybe this should be `createnetworkclient` and similar for the other method.,0,0.9896597266197205
92517776,1251,ijuma,2016-12-14T23:54:36Z,nit: should probably just be `expectedapiversions`.,0,0.9910332560539246
92517927,1251,ijuma,2016-12-14T23:55:49Z,we should have some shared code for serialising the response and response header instead of duplicating it in multiple places.,0,0.9912961721420288
92517976,1251,ijuma,2016-12-14T23:56:12Z,did you see this comment?,0,0.987606942653656
92518023,1251,ijuma,2016-12-14T23:56:37Z,nit: extra empty line.,0,0.8511092662811279
92518167,1251,ijuma,2016-12-14T23:57:35Z,"hmm, i thought we'd have `latest_0_10_1` and `latest_0_10_0` instead of `latest_0_10` (which doesn't make sense because we have multiple feature releases in the `0_10` line.",0,0.978264570236206
92518242,1251,ijuma,2016-12-14T23:58:15Z,should we not check that we get a better error for the case where `apiversions` is available (i.e. `0.10.0.x`)?,0,0.9936743974685669
92528123,1251,hachikuji,2016-12-15T01:32:33Z,"yeah, maybe just remove the constant and use `apikeys.metadata` directly?",0,0.9937206506729126
92866560,1251,ijuma,2016-12-16T19:01:30Z,"on second thought, i'm ok to leave this as it is and we can leave this improvement as future work.",0,0.9403185248374939
92897920,1251,SinghAsDev,2016-12-16T22:35:34Z,"yea, this will require a bit of refactoring. current changes are inline with the way `protoutils` is written. leaving it as it is for now.",0,0.9848588109016418
92897966,1251,SinghAsDev,2016-12-16T22:35:51Z,good point!,1,0.9942666888237
37427316,151,ijuma,2015-08-19T15:21:47Z,what is the right way to handle this? the random suffix is there because an exception will be thrown in `registermetric` if a broker is removed and then added again. the `selector` doesn't allow the caller to control that in its current form.,0,0.9902752637863159
37427419,151,ijuma,2015-08-19T15:22:27Z,is it ok to use the same config as `socketserver` for this?,0,0.9949415326118469
37427623,151,ijuma,2015-08-19T15:23:51Z,"`config.controllersockettimeoutms` was previously being used for `blockingchannel.readtimeoutms`, is it correct to use it here in this way?",0,0.9954302310943604
37427682,151,ijuma,2015-08-19T15:24:19Z,is it ok to reuse the `socketserver` settings here?,0,0.9949819445610046
37427714,151,ijuma,2015-08-19T15:24:36Z,"`config.controllersockettimeoutms` was previously being used for `blockingchannel.readtimeoutms`, is it correct to use it here in this way?",0,0.9954302310943604
37427818,151,ijuma,2015-08-19T15:25:18Z,is it ok to use the `socketserver` config parameters here?,0,0.995086133480072
37470292,151,gwenshap,2015-08-19T21:25:21Z,i don't think you need maxbytes here... this was for limiting the message size from clients. we have networkreceive.unlimited if we want to leave this open.,0,0.9759058952331543
37470393,151,gwenshap,2015-08-19T21:26:05Z,can to expend on why would the broker get removed and re-added from here?,0,0.9598580002784729
37472395,151,ijuma,2015-08-19T21:44:00Z,"`controllerchannelmanager.removebroker` is called in `brokerchangelistener.handlechildchange`, the actual line is: `deadbrokerids.foreach(controllercontext.controllerchannelmanager.removebroker(_))`",0,0.9945825934410095
37474431,151,gwenshap,2015-08-19T22:02:49Z,"so, it looks like you have a selector for each controller->broker connection? i'd expect one selector for the controller and open and close connections for brokers. this way the selector string will include the broker id for the controller, but not for the brokers themselves. and we'll probably want to maintain metricsperconnection so we can track those separately. does that make sense?",0,0.9889546632766724
37476236,151,gwenshap,2015-08-19T22:23:50Z,"i think these utils are very generic, but also make the code a bit harder to read. it looks like the ""find"" we are waiting for is basically always a reply from a specific broker? in this case, maybe make the generic method private and provide a more specific wrapper?",0,0.7660539150238037
37476467,151,ijuma,2015-08-19T22:26:34Z,"yes, i understand that one selector per controller would be better. i was trying to avoid a complete redesign of `controllerchannelmanager` though. it currently uses one `requestsendthread` per broker with a `blockingqueue` and `blockingchannel`. `controllerchannelmanager` has a public `sendrequest` method that adds to the relevant queue. `requestsendthread` takes from this queue. my understanding is that a given selector should be used from just one thread and hence the resulting code. please let me know if this is not correct. in an ideal world, we would redesign things to use one selector per controller, but it seemed riskier and i thought it would be better to do that in a separate change after the next release (since our main goal at this point is just to use `selector` for the tls/ssl support). what are your thoughts?",0,0.9724841117858887
37476513,151,gwenshap,2015-08-19T22:27:11Z,"yeah, i think it does exactly the same thing we used to do: block until we get a reply or get to the timeout time. iirc, the networkreceive code has some deprecated methods specifically to support the blocking channel timeouts. maybe this can be cleaned up now.",0,0.981278657913208
37476689,151,gwenshap,2015-08-19T22:29:20Z,blockingchannel used to get the buffer sizes as parameters... shouldn't we keep the same behavior?,0,0.9738407731056213
37476724,151,ijuma,2015-08-19T22:29:48Z,"`blockingchannel` is still used by the old consumer, so i am not sure we can remove anything just yet. i'll double-check though.",0,0.9627568125724792
37476769,151,gwenshap,2015-08-19T22:30:30Z,"i think it is, since it keeps the same behavior.",0,0.9718015789985657
37476900,151,ijuma,2015-08-19T22:32:17Z,"we were passing `blockingchannel.usedefaultbuffersize` (which is `-1`) everywhere and the code in `blockingchannel` does: [code block] so, we were basically not setting anything.",0,0.9935412406921387
37477305,151,gwenshap,2015-08-19T22:36:56Z,"lets see if i got it. we have a communication thread per broker, and a selector per thread. if a broker dies, we close the thread and the selector. if the broker comes back, we can't create a new selector with the same name due to metrics. since the number of possible brokers is limited, can we just store the selector for each broker in a map and reuse / reconnect if the dead broker is revived? this should keep the metrics sane too.",0,0.9823978543281555
37477570,151,gwenshap,2015-08-19T22:39:45Z,"lol, we are cute :) i'd leave it at -1 then.",1,0.9961676001548767
37477835,151,gwenshap,2015-08-19T22:42:36Z,"i'd also document that these are for creating blocking behavior on top of our async network classes, and to use only where blocking makes sense...",0,0.9907034635543823
37478175,151,ijuma,2015-08-19T22:47:28Z,"i can try to add some wrappers and see how it looks. to help me understand, what makes it hard to read? is it because of the long line with many parameters? this could be simplified quite a bit by using implicit value classes and passing the time implicitly as well. example follows: now: [code block] after the proposed change: [code block]",0,0.9880950450897217
37478292,151,ijuma,2015-08-19T22:49:29Z,"yes, that seems doable. i'll try that tomorrow and update the pr.",0,0.8613557815551758
37478390,151,ijuma,2015-08-19T22:50:46Z,good point about documenting the blocking aspect. will do.,1,0.8854421377182007
37478724,151,ijuma,2015-08-19T22:54:31Z,we can't pass -1 to `selector.connect` though as it will fail when it calls `socket.sendbuffersize`. maybe you are suggesting that i update `selector.connect` to behave as `blockingchannel` did when a negative value is passed in (basically not call `set*buffersize`)?,0,0.9926366806030273
37479192,151,gwenshap,2015-08-19T23:00:29Z,yep. basically move the constants and their behavior to the new network classes.,0,0.9491103887557983
37479252,151,ijuma,2015-08-19T23:01:11Z,sounds good.,1,0.9417163729667664
37479424,151,gwenshap,2015-08-19T23:03:33Z,"i actually find the very generic ""any predicate"" or ""any find on a collection"" challenging. i'm concerned that future contributors won't quite know what to do with those. i'm thinking that baking the specific ""find"" we actually have into a wrapper, will help. so: polluntilrecievingresponsefromconnection(selector, timeout, connection_id)",0,0.9260757565498352
37567314,151,gwenshap,2015-08-20T18:53:17Z,nice :),1,0.9926033616065979
37606457,151,junrao,2015-08-21T04:49:32Z,"we need to block until the connection is established, right?",0,0.9683309197425842
37606471,151,junrao,2015-08-21T04:50:02Z,"we will need to handle disconnects (like what networkclient does) by checking selector.disconnected(). if a socket is disconnected, there is no need to wait for the timeout. we should just throw an ioexception back. ditto to the selector.poll() below.",0,0.9795310497283936
37606475,151,junrao,2015-08-21T04:50:16Z,"we haven't been using the s notation so far. to be consistent, perhaps it's better to use the string format thing for now and do a global replacement at some point if we feel that's better?",0,0.9897087216377258
37606486,151,junrao,2015-08-21T04:50:28Z,"since there is a selector per broker, we need to add a broker id tag for the metric tag.",0,0.9928510189056396
37614464,151,ijuma,2015-08-21T08:12:40Z,"i thought we did not as we will eventually block after the `send`, which happens a few lines below. have i misunderstood how the `selector` should be used in this case?",0,0.9365223050117493
37614569,151,ijuma,2015-08-21T08:14:11Z,"makes sense, will do.",0,0.9542514681816101
37614852,151,ijuma,2015-08-21T08:19:05Z,"i considered that, but we have over 800 instances of `format` in our codebase, so it would be quite a painful global replacement (with potential for introducing bugs). string interpolation is safer and performs better than `.format`, so i thought we could use it for new code where it made sense. we use it in a small number of places already. please let me know if you still think i should change it.",0,0.931119441986084
37614934,151,ijuma,2015-08-21T08:20:33Z,"will do. i'm not really sure how these tags work to be honest, but i'll see if i can find an existing example. :)",1,0.9900631308555603
37626125,151,ijuma,2015-08-21T11:28:49Z,", i added the `broker-id` tag below. does it still make sense to include `broker.id` in the `metricgrpprefix` above?",0,0.9945584535598755
37651956,151,junrao,2015-08-21T16:34:42Z,"if you look at networkclient, the way that it uses selector is the following. before networkclient can send any request, it has to make sure the connector is connected and the channel is ready. if you don't follow this protocol, things can get weird. for example, in ssl, after we finish the handshake, we will turn off the interest bit for write. if the interest bit for write has already been turned on by a request sent before the handshake completes, the send may never complete. thinking a bit more about this. it seems to implement a blocking channel on the selector, we will need most of the connection state management logic in networkclient. the problem with using networkclient is that it's tied to metadata refresh, which is not needed. we can either add an option to turn off the metadata part in networkclient and use it to implement the blocking channel. alternatively, we can implement a blockingselector on top of selector, but has to copy some of the state management logic from networkclient over. not sure which one is better.",-1,0.6796256303787231
37651974,151,junrao,2015-08-21T16:34:54Z,"metricgrpprefix is just a prefix of the metrics group, which is a string. tags give metadata in key/value pairs, which is more informative.",0,0.9928669929504395
37653240,151,ijuma,2015-08-21T16:48:38Z,"ok, i see. i'll check if turning off metadata in `networkclient` can be done without too much complexity.",0,0.9832174777984619
38272677,151,ijuma,2015-08-30T15:23:09Z,will add javadoc.,0,0.9882354736328125
38272682,151,ijuma,2015-08-30T15:23:15Z,will add javadoc.,0,0.9882354736328125
38272693,151,ijuma,2015-08-30T15:23:58Z,will add `and version` at the end of the sentence.,0,0.9926620721817017
38272702,151,ijuma,2015-08-30T15:25:30Z,v1 was added during the development of 0.8.3 so we could change this to be like v0 if we think it's important.,0,0.9925099611282349
38272718,151,ijuma,2015-08-30T15:27:19Z,will add `scaladoc` to this class and methods.,0,0.9922131896018982
38279205,151,junrao,2015-08-31T01:03:19Z,"do we need to wait for the next poll() call? disconnect() will cancel the key, after which the key will never be selected again.",0,0.9873560667037964
38279208,151,junrao,2015-08-31T01:03:29Z,it seems that we also need to remove nodeid from clusterconnectionstates?,0,0.9945437908172607
38279209,151,junrao,2015-08-31T01:03:35Z,need to add .,0,0.9624201655387878
38279211,151,junrao,2015-08-31T01:03:42Z,need to add .,0,0.9624201655387878
38279215,151,junrao,2015-08-31T01:03:47Z,need to add .,0,0.9624201655387878
38279216,151,junrao,2015-08-31T01:03:54Z,do we need to pass mode in? could we just get it from configs?,0,0.994857668876648
38279217,151,junrao,2015-08-31T01:04:00Z,this field should be named live_leaders.,0,0.992352306842804
38279219,151,junrao,2015-08-31T01:04:04Z,this can just be referencing leader_and_isr_request_partition_state_v0.,0,0.9954663515090942
38279226,151,junrao,2015-08-31T01:04:16Z,good catch. it's probably too late to change that though.,1,0.9362886548042297
38279229,151,junrao,2015-08-31T01:04:22Z,leaders is better named as liveleaders.,0,0.9869245290756226
38279232,151,junrao,2015-08-31T01:04:33Z,"it's probably better to create two constructors, one for each version. we can then mark the v0 constructor as deprecated and can remove it in the future.",0,0.9921718835830688
38279234,151,junrao,2015-08-31T01:04:38Z,both v0 and v1have host_key_name. perhaps we should check field security_protocol_type_key_name?,0,0.9949491024017334
38279239,151,junrao,2015-08-31T01:04:44Z,should we mock the other new method disconnect() too?,0,0.9928863644599915
38279241,151,junrao,2015-08-31T01:04:49Z,response version should be 1.,0,0.9892672300338745
38279242,151,junrao,2015-08-31T01:04:51Z,response version should be 1.,0,0.9892672300338745
38279278,151,junrao,2015-08-31T01:07:21Z,we probably want maxinflightrequests to be 1 so that it's consistent with the current behavior in blockingchannel.,0,0.9934306740760803
38279285,151,junrao,2015-08-31T01:07:47Z,there are a few unused imports.,0,0.9304671287536621
38279287,151,junrao,2015-08-31T01:07:55Z,selector should now be networkclient. there are a few other mentions of selector below.,0,0.9880074262619019
38279289,151,junrao,2015-08-31T01:08:00Z,"$sockettimeoutexception should be $sockettimeoutms, right?",0,0.9854189157485962
38279291,151,junrao,2015-08-31T01:08:06Z,we probably want maxinflightrequests to be 1 so that it's consistent with the current behavior in blockingchannel.,0,0.9934306740760803
38279296,151,junrao,2015-08-31T01:08:14Z,do we need to do this? nodes are only used for sending metadatarequest and we are not doing that here.,0,0.9895794987678528
38279300,151,junrao,2015-08-31T01:08:36Z,"we probably want to move the blocking support to the client side. in the future, we likely will be writing the admin tools in java and it potentially will need to make blocking request calls too.",0,0.9871073365211487
38279310,151,junrao,2015-08-31T01:09:04Z,"if the connection didn't fail, is there any reason to back off? it seems that we should be calling networkclient.poll() with the timeout immediately.",0,0.9887922406196594
38279316,151,junrao,2015-08-31T01:09:31Z,"perhaps it's more convenient to include to logic to wait for the connection being ready here. this way, we are guaranteed that every time we send a request, the socket is ready. currently, in controllerchannelmanager, if we can't establish a socket connection, it seems that we can send a request before the channel is ready.",0,0.9935591816902161
38292654,151,ijuma,2015-08-31T08:21:53Z,"i copied that documentation from `selector.disconnect`. there is the following code in `selector.poll`: [code block] and there is the following test in `networkclienttest`: [code block] so, that lead me to believe that a poll was needed to update the internal state of the `selector` and `networkclient`. the test above fails without the `poll` line (although it does use a `mockselector`, so the bug could be there). what are your thoughts based on this additional information?",0,0.9937610030174255
38292972,151,ijuma,2015-08-31T08:27:34Z,"i did think about setting the state to disconnected (which has a similar effect), but then i thought that this would be updated automatically via `poll` as per the comment added in the discussion around the javadoc for `kafkaclient.poll`. but maybe the right thing is to do update the state here as you suggest. do you think we should remove the id or set the state to `disconnected`?",0,0.9942607879638672
38296748,151,ijuma,2015-08-31T09:30:40Z,"the 4 places where this is used all pass this parameter explicitly (as `sslfactory.mode.{client,server}`). we could put a key into the configs map, but i think that would make things more opaque with no clear benefit. what do you think?",0,0.9889853000640869
38296826,151,ijuma,2015-08-31T09:32:11Z,"will fix. we also have `alive_brokers` elsewhere, should we be calling that `live_brokers` instead for consistency?",0,0.9941845536231995
38296887,151,ijuma,2015-08-31T09:33:21Z,"ok, will do. i wasn't sure what was our policy when it came to referencing schemas from other apis in the same class. good to know.",0,0.6349362730979919
38296946,151,ijuma,2015-08-31T09:34:04Z,will do.,0,0.9864637851715088
38296965,151,ijuma,2015-08-31T09:34:20Z,will do.,0,0.9864637851715088
38297159,151,ijuma,2015-08-31T09:37:48Z,"in v1, `host_key_name` is in the `end_points` struct though, so it should be fine either way as far as i can see. i'll change it to `security_protocol_type_key_name` as it's clearer though.",0,0.9895414710044861
38297285,151,ijuma,2015-08-31T09:39:41Z,it was already there previously.,0,0.9891290068626404
38297303,151,ijuma,2015-08-31T09:39:56Z,"good catch, will fix.",1,0.9706640839576721
38297314,151,ijuma,2015-08-31T09:40:10Z,"good catch, will fix.",1,0.9706640839576721
38297556,151,ijuma,2015-08-31T09:44:08Z,"i think the behaviour should be consistent anyway as we block for each request. setting this to `1` will enforce it, so i'll change it.",0,0.981788694858551
38297677,151,ijuma,2015-08-31T09:46:00Z,will fix.,0,0.8708126544952393
38297917,151,ijuma,2015-08-31T09:49:38Z,i'll change this to say `networkclient`/`selector`. i think the other `selector` mentions are fine.,0,0.9830352067947388
38297929,151,ijuma,2015-08-31T09:49:53Z,"good catch, will fix.",1,0.9706640839576721
38297986,151,ijuma,2015-08-31T09:50:55Z,"similar to the other instance of this, i think the behaviour is still correct, but i'll change it to be clearer/safer.",0,0.9636894464492798
38298281,151,ijuma,2015-08-31T09:56:12Z,"we don't strictly need it, but `kafkaclient.leastloadednode` would return `null` if we don't do this. as you say, we don't use that method so it would have no effect right now if we remove it. i did that because i thought it may help avoid surprises in the future, but i don't have a strong opinion on it. do you still think it should be removed?",0,0.9735508561134338
38299301,151,ijuma,2015-08-31T10:12:13Z,i checked this and i think 0 is correct for `leaderandisrresponse`. or am i missing something?,0,0.9928299784660339
38299668,151,ijuma,2015-08-31T10:19:05Z,"i think you meant `controlledshutdownresponse`, i fixed that.",0,0.9882644414901733
38300557,151,ijuma,2015-08-31T10:33:47Z,"is this something we want to do now or when the need arises? i didn't want to add this to the clients jar because i thought it was just useful to help us transition the broker code without bigger changes. it seems like there may be more use cases, but isn't it better to wait until they are concrete before moving the code to the clients jar?",0,0.987409770488739
38303535,151,ijuma,2015-08-31T11:31:47Z,"actually i can't make this change because `security_protocol_type_key_name` will never exist at this level. i could check for `endpoints_key_name`, but i think the current way is less error-prone (as endpoints could be empty due to a bug perhaps). so i'll leave it as is unless you disagree.",0,0.9874294400215149
38303909,151,ijuma,2015-08-31T11:38:38Z,will fix.,0,0.8708126544952393
38303913,151,ijuma,2015-08-31T11:38:45Z,will fix.,0,0.8708126544952393
38303918,151,ijuma,2015-08-31T11:38:53Z,will fix.,0,0.8708126544952393
38304564,151,ijuma,2015-08-31T11:50:35Z,"perhaps. i'm not sure though. it's easy enough for the caller to call `blockingready` if that is desired, right? i didn't do that in `controllerchannelmanager` because the existing code already handles the exception that would be thrown if the initial connection fails: [code block] the existing code is not the prettiest, but i tried not to make too many changes at this point. i think we should consider redesigning the controller/broker communication to make better use of `networkclient` in the future.",0,0.9298485517501831
38306320,151,ijuma,2015-08-31T12:21:10Z,"i did this, but it's worth being aware of the downsides (and why i had avoided that in the first place): - we now have a number of warnings due to the fact that we call the deprecated constructor - the calling code is more complex as it needs to pass slightly different data to each constructor (we still support both versions from the calling code and previously it just had to pass a version) - a new deprecated inner class `brokerendpoint` had to be introduced for the v0 constructor",0,0.9834902286529541
38313413,151,ijuma,2015-08-31T13:54:32Z,"i'll remove `retrybackoff`. it's how i had it at first, but i was seeing some issues where `poll` was returning immediately which was causing the thread to spin and seemed to be causing more connection timeouts than usual. i now think that this was caused by a bug in the handling of the connection failures (which i fixed before reopening the pr).",0,0.9814607501029968
38332668,151,junrao,2015-08-31T16:58:29Z,"yes, that's how mockselector is implemented. in the real selector, my understanding is that if you disconnect a client, we cancel the key. the cancelled key will never be selected by the selector again. so, you would have to set the connection state in the same disconnect call. if that's the case, we probably need to change the behavior of mockselector.",0,0.9884013533592224
38332742,151,junrao,2015-08-31T16:59:17Z,"this is related to the comment above. if a client calls disconnect, it may not be interested in using this connection any more. so, we probably want to fresh the memory by removing the id from the connection state.",0,0.9928091764450073
38332766,151,junrao,2015-08-31T16:59:27Z,what you have is fine. i didn't realize that mode is implicit and not an explicit property.,0,0.9344329237937927
38332782,151,junrao,2015-08-31T16:59:34Z,what you had is fine.,0,0.9568381905555725
38332818,151,junrao,2015-08-31T16:59:55Z,"it's fine if we set the nodes explicitly. if so, we should do the same for the manualmetadataupdater used in controllerchannelmanager.",0,0.9927912950515747
38332943,151,junrao,2015-08-31T17:01:04Z,"yes, the logic in controllerchannelmanager is not pretty. the issue that i see is that if connecttobroker() fails to establish a connection in time, we just disconnect. so, by the time you send a request, there is not guarantee that the connection is ready.",0,0.5601909160614014
38335942,151,junrao,2015-08-31T17:31:06Z,we can keep the blocking logic in scala for now.,0,0.9925220608711243
38336063,151,ijuma,2015-08-31T17:32:10Z,"we do indeed, but at construction time because we use a `networkclient` for each broker connection, i paste the line below: `new manualmetadataupdater(seq(brokernode).asjava)`",0,0.994787335395813
38336694,151,ijuma,2015-08-31T17:37:51Z,"yes, i understand. so, if the connection is not ready, an `illegalstateexception` will be thrown which will cause a disconnect (no-op) followed by another connect and then we will retry again after a 300ms sleep since `issendsuccessful === false`. this behaviour is very similar to what would happen with `blockingchannel` where a closedchannelexception would be thrown if `send` was called and the channel was not connected due to a failure. i can add a `blockingready` call before the `send` if you think that is better though.",0,0.9898570775985718
38337234,151,ijuma,2015-08-31T17:42:47Z,"i see. i'll test the behaviour of the real selector just to be sure. in the likely case that it matches your description, i will do the following: - update `mockselector` - update `networkclienttest` - update `selector.disconnect` and `networkclient.disconnect` documentation - update implementation of `networkclient.disconnect` to update connection states - remove `networkclientblockingops.disconnectandpoll` as `disconnect` will be sufficient have i covered everything?",0,0.987708568572998
38338561,151,junrao,2015-08-31T17:53:43Z,"yes, relying on illegalstateexception probably works, but it's kind of hacky. illegalstateexception is meant to capture all programming errors, and using it for error handling feels wrong.",-1,0.974578320980072
38338732,151,junrao,2015-08-31T17:55:07Z,got it. i missed that you can pass in the nodes from the constructor.,0,0.9743857979774475
38338901,151,junrao,2015-08-31T17:56:31Z,that sounds good.,1,0.9348070621490479
38340333,151,ijuma,2015-08-31T18:08:22Z,"ok, i will add a `blockingready` before the send then.",0,0.984372615814209
38400639,151,ijuma,2015-09-01T09:30:33Z,we have `liveleaders` in `leaderandisrrequest`. do we want to keep this as `alivebrokers` or would it be better to call it `liveborkers`?,0,0.994850218296051
38423086,151,ijuma,2015-09-01T14:16:52Z,i did this here instead of changing `blockingsendandreceive` to make it easier to maintain the previous behaviour of logging once a connection is established.,0,0.9945281147956848
38423154,151,ijuma,2015-09-01T14:17:33Z,"this method already existed in `networkclient`, i just added it to the interface.",0,0.9920191168785095
38423354,151,ijuma,2015-09-01T14:19:08Z,"i named this `close` instead of `disconnect` to match the relevant method in `selector`, but i'd be interested in feedback regarding the naming. also, it's not clear to me when `selector.disconnect` is actually useful.",0,0.9847127199172974
38473289,151,junrao,2015-09-01T21:16:58Z,is that added?,0,0.9906594753265381
38473306,151,junrao,2015-09-01T21:17:04Z,this is not really an instance of invalidmetadataexception.,0,0.9627726078033447
38473310,151,junrao,2015-09-01T21:17:09Z,this is not really an instance of invalidmetadataexception.,0,0.9627726078033447
38473361,151,junrao,2015-09-01T21:17:30Z,"even though updatemetadatarequest_v0 has identical structure as leaderandisrrequest_v0, the set of brokers used are slightly different. in updatemetadatarequest_v0, we pass in all live brokers. in leaderandisrrequest_v0, we pass in all live brokers that are the leaders. so, we can keep the names as they are.",0,0.9914233088493347
38473426,151,junrao,2015-09-01T21:17:59Z,"in version 0, we should only allow passing in a single brokerendpoint.",0,0.9867401123046875
38473454,151,junrao,2015-09-01T21:18:06Z,"now that we have the broker tag, the group prefix can just be ""controller-channel"" or sth like that.",0,0.9939524531364441
38473470,151,junrao,2015-09-01T21:18:13Z,is the if statement needed since the test is already done in networkclient.blockingready()?,0,0.9944828748703003
38475260,151,ijuma,2015-09-01T21:35:08Z,is it a `retriableexception` or `apiexception` then?,0,0.9938562512397766
38475273,151,ijuma,2015-09-01T21:35:16Z,is it a `retriableexception` or `apiexception` then?,0,0.9938562512397766
38475371,151,ijuma,2015-09-01T21:36:00Z,will fix.,0,0.8708126544952393
38475773,151,ijuma,2015-09-01T21:40:14Z,ok. we don't need to include the controller id in the group prefix or as a tag?,0,0.9906587600708008
38476438,151,ijuma,2015-09-01T21:46:57Z,"it's done this way to only log the ""controller %d connected"" message if the connection is not already ready.",0,0.9945072531700134
38477988,151,junrao,2015-09-01T22:02:59Z,apiexception for both.,0,0.9469159245491028
38478139,151,junrao,2015-09-01T22:04:55Z,we don't need the broker id in group prefix. still need the broker id in the metrics tag.,0,0.9917857050895691
38478285,151,junrao,2015-09-01T22:07:00Z,ok. we can leave it as it is. thanks for the explanation.,1,0.8111796379089355
38478450,151,ijuma,2015-09-01T22:09:06Z,"sorry, my question was about the controller id (i had understood the point about the broker id).",-1,0.9881166219711304
38478876,151,ijuma,2015-09-01T22:14:31Z,"are you sure about this? looking at the scala code, it does: read: `case 0 => for(i <- 0 until numalivebrokers) yield new broker(brokerendpoint.readfrom(buffer),securityprotocol.plaintext)` write: ``case 0 => alivebrokers.foreach(_.getbrokerendpoint(securityprotocol.plaintext).writeto(buffer))`",0,0.9909082651138306
38483970,151,ijuma,2015-09-01T23:18:34Z,"not yet, i was focusing on getting the behaviour right first. i'll add all the missing javadoc/scaladoc in my next commit.",0,0.9823624491691589
38498073,151,junrao,2015-09-02T04:29:17Z,"actually, my comment wasn't right. what you had is right since in v0, we pass in a set of brokerendpoint and v1, we pass in a set of broker.",0,0.8599629402160645
38521906,151,ijuma,2015-09-02T11:30:39Z,"yes, i understand the difference between brokers and leaders. the bit i was asking about is the `live` prefix (in `liveleaders`) versus the `alive` prefix (in `alivebrokers`). it seemed to me that `livebrokers` means the same and the prefix would be consistent. anyway, not a big deal, so fine to keep as is if you prefer.",0,0.830639123916626
38559331,151,junrao,2015-09-02T17:21:34Z,"yes, i agree that it's better to make the names consistent. so we can use live_brokers and live_leaders here and in protocols as well.",0,0.9735174179077148
114734810,2967,ijuma,2017-05-04T09:43:29Z,are the `private` -> `protected` changes still needed?,0,0.994924783706665
114739200,2967,ijuma,2017-05-04T10:09:24Z,"for consistency, it may make sense for `wrapforoutput` to take a `bytebuffer` too.",0,0.994149923324585
114740176,2967,ijuma,2017-05-04T10:15:34Z,"we could change `defaultrecord.readfrom` to take a `datainput` (instead of `datainputstream`), change `kafkalz4blockinputstream` to implement `datainput` and then only wrap if the returned value is not already a `datainput`. that would remove a layer of indirection and if it's possible to implement `readfully` more efficiently in `kafkalz4blockinputstream`, then it could be a win. if you have time, it may be worth a try.",0,0.97034752368927
114742214,2967,ijuma,2017-05-04T10:27:46Z,"it wasn't clear to me why we needed both `thebuffer` and `decompressionbuffer`. it seems that we rely on the fact that `thebuffer` is only populated after the first `readblock` to implement `available` correctly. is that the only difference? if so, would it not be simpler to have a single buffer that is allocated for the first time in `readblock`?",0,0.9909454584121704
114742293,2967,ijuma,2017-05-04T10:28:16Z,`mark()` and `reset()` are synchronized and probably should not be.,0,0.9906688332557678
114742552,2967,ijuma,2017-05-04T10:29:51Z,i think the default should be `current_magic_value`.,0,0.9850208759307861
114742615,2967,ijuma,2017-05-04T10:30:16Z,why did you remove `none` from this list? it seems useful to have the uncompressed baseline.,0,0.9934861063957214
114742753,2967,ijuma,2017-05-04T10:31:07Z,seems like more fields could be final in this class.,0,0.9904820919036865
114743094,2967,ijuma,2017-05-04T10:33:53Z,you should probably use `abstractrecords.sizeinbytesupperbound`.,0,0.9939210414886475
114744092,2967,ijuma,2017-05-04T10:41:09Z,"to make the benchmark less dependent on implementation details, it would be better if it used `memoryrecords.readablerecords(...).batches()`. same for the other benchmark.",0,0.9937637448310852
114744933,2967,ijuma,2017-05-04T10:46:15Z,maybe this should be `recordbatchiterationbenchmark`?,0,0.9947419166564941
114746255,2967,ijuma,2017-05-04T10:55:31Z,"we followed the same approach for snappy and lz4 to deal with the possibility that the libraries are not in the classpath because it's not supported in a given platform. however, we are using kafka classes for the block input stream and block output stream. as such, we can probably reference the constructor directly. we won't invoke the constructor unless lz4 is configured and it's ok to fail in that case. does that make sense?",0,0.9942303895950317
114746515,2967,ijuma,2017-05-04T10:57:30Z,why do we need this?,0,0.9448511004447937
114807909,2967,xvrl,2017-05-04T15:14:02Z,"we don't need them anymore, indeed",0,0.9799799919128418
114808828,2967,xvrl,2017-05-04T15:17:27Z,sure,0,0.9137381911277771
114808856,2967,xvrl,2017-05-04T15:17:33Z,"the benchmark is in the `org.apache.kafka.common.record` package. now that we don't rely on package protected classes anymore, we can move it to `org.apache.kafka.jmh` and remove this.",0,0.9942463040351868
114810971,2967,xvrl,2017-05-04T15:24:57Z,`thebuffer` is also pointed directly to the input buffer when a block is not compressed to avoid copying bytes.,0,0.9938133955001831
114811084,2967,xvrl,2017-05-04T15:25:21Z,"hmm, not sure why they were in the first place",-1,0.6892357468605042
114812768,2967,ijuma,2017-05-04T15:31:22Z,"copy and paste, i bet.",0,0.6903558969497681
114812862,2967,ijuma,2017-05-04T15:31:42Z,sounds good.,1,0.9417163729667664
114814192,2967,ijuma,2017-05-04T15:36:30Z,"i had noticed that, but didn't think through how that could work if we had a single buffer variable. ok, seems simplest to have two buffers. can we add a comment explaining this?",0,0.9577844738960266
114824952,2967,xvrl,2017-05-04T16:19:55Z,"seems like this is not as straightforward as it seems. memoryrecordsbuilder relies on having access to the underlying bytebuffer held by the bytebufferoutputstream, which would break if the buffer is expanded in bytebufferoutputstream",0,0.9617837071418762
114826480,2967,xvrl,2017-05-04T16:26:38Z,"makes sense, as far as i know lz4 falls back to a pure-java version anyway, so it should be safe regardless (unless there are other platform issues that are unrelated to native code)",0,0.9869248867034912
114826699,2967,xvrl,2017-05-04T16:27:43Z,"i'd prefer to do that in a follow-up pr in trunk, since i'd also like to backport this to 0.10.2.x",0,0.9854457378387451
114826741,2967,xvrl,2017-05-04T16:27:56Z,will do,0,0.9571817517280579
114828336,2967,xvrl,2017-05-04T16:35:40Z,"note however that we store the lz4safedecompressor as a static field, so loading the kafka class would also trigger loading the lz4 classes.",0,0.9950239658355713
114873529,2967,xvrl,2017-05-04T20:00:12Z,fixed,0,0.9281549453735352
114873560,2967,xvrl,2017-05-04T20:00:19Z,fixed,0,0.9281549453735352
114874156,2967,xvrl,2017-05-04T20:03:09Z,"when using `memoryrecords.readablerecords(...)` we don't technically test the compression.none ""compression"" method, but test a different code path, so it's not really comparable if you care about an upper bound on how fast decompression could be.",0,0.9683472514152527
114874228,2967,xvrl,2017-05-04T20:03:31Z,i added it back so we could at least see what it means in practice though,0,0.9802603125572205
114874277,2967,xvrl,2017-05-04T20:03:40Z,fixed,0,0.9281549453735352
114874313,2967,xvrl,2017-05-04T20:03:52Z,good to know,1,0.8709375262260437
114874345,2967,xvrl,2017-05-04T20:04:02Z,changed.,0,0.9758284687995911
114876003,2967,xvrl,2017-05-04T20:12:03Z,"i was also thinking, if we avoided readfully altogether, we could avoid the eofexception penalty when reaching the end of the batch on legacy records and get a further 3x improvement for small legacy batches.",0,0.9847796559333801
114877226,2967,ijuma,2017-05-04T20:18:00Z,"it's not the same code path, but that's ok. the comparison i'm looking for is a bit like the one in the lz4 github page where it compares memcpy with lz4 decompression ([a link]",0,0.942542552947998
114879573,2967,ijuma,2017-05-04T20:28:49Z,"hmm, `datainputstream.readfully` only throws an exception if we ask it to read past the end of the inputstream. so supposedly, if we fix the underlying inputstream, it's enough either way. the following pr does that: [a link]",0,0.9855387210845947
115125280,2967,hachikuji,2017-05-06T17:42:08Z,"nit: this looks a little weird. could we just do [code block] also, the name is a bit vague. maybe `record_header_size`?",-1,0.9554205536842346
115125399,2967,hachikuji,2017-05-06T17:47:46Z,this block seems to be the same code as below. perhaps we could move it into a `readfully` function in `utils` (we have a couple of these for working with `filechannel` already)?,0,0.9935270547866821
117260682,2967,ijuma,2017-05-18T14:20:03Z,"good point, can we please add a comment explaining the reason for the inconsistency?",1,0.6508997678756714
117292625,2967,ijuma,2017-05-18T16:19:57Z,"yeah, but `kafkalz4blockinputstream` itself should not be initialised until it's actually used. i made this change, used compressiontype.snappy.wrap* methods while lz4 was not in the classpath and it worked fine. the same exercise did not work for snappy because `snappyinputstream` was not in the classpath. anyway, we can keep it as it is if you prefer as the performance impact is low when compared to other things (8ns instead of 4ns per construction).",0,0.9856688976287842
117300016,2967,xvrl,2017-05-18T16:54:17Z,done,0,0.8974218964576721
117300539,2967,xvrl,2017-05-18T16:56:50Z,"ok, i've change it to construct the lz4 streams directly, and updated the comments accordingly.",0,0.9886029958724976
118957598,2967,ijuma,2017-05-29T15:38:55Z,is it safe to do this on the received buffer? `deeprecordsiterator` doesn't seem to duplicate the buffer before calling `compressiontype.wrapforoutput`.,0,0.9939004182815552
118962982,2967,ijuma,2017-05-29T16:25:02Z,"i'm not totally sure why we were previously using a `readunsigned` method and now we're not. for many of the other cases where we do this, it's easy to verify that the values we care about work either way. the ones that weren't totally clear to me were this and the block checksum cases. can you please elaborate why the change is safe in those two cases?",0,0.9674001336097717
118966334,2967,ijuma,2017-05-29T17:01:00Z,"hmm, so this bug meant that the `blocksize > maxblocksize` check was not working, right? also, did we just get lucky that the `blocksize == 0` check worked?",0,0.9574614763259888
118970809,2967,ijuma,2017-05-29T17:52:18Z,nit: is there a reason why we are modifying the existing block size instead of just setting the bad block size directly?,0,0.9430428147315979
119135013,2967,xvrl,2017-05-30T15:35:05Z,"from reading the code, `byteutils.readunsignedintle` is a misnomer and should probably be just be called `readintle`. unlike `readunsignedint`, which returns a long and applies the proper bit mask, `readunsignedintle` returns an integer and doesn't do anything other than shifting the bytes.",0,0.9926059246063232
119140839,2967,xvrl,2017-05-30T15:55:42Z,"`deeprecordsiterator` technically duplicates the buffer when calling [a link] and never reuses it, but i agree that could easily be missed or introduce odd bugs if that code were to be rewritten. i can add a `duplicate()` here just for safety.",0,0.9876790642738342
119141976,2967,ijuma,2017-05-30T15:59:58Z,sounds good.,1,0.9417163729667664
119146762,2967,xvrl,2017-05-30T16:18:08Z,"indeed, the size check wasn't working, but at the end of the day, we would just thrown a different exception in case the block size exceeded the max. regarding the zero size block, we were just lucky that we never set the `lz4_frame_incompressible_mask` flag in `kafkalz4blockoutputstream.writeendmark`. i checked the spec and it didn't seem to specify whether the flag should be set or not in that case, so better be safe.",0,0.9841576814651489
119157414,2967,xvrl,2017-05-30T17:02:15Z,"yes, to make sure it works in both cases when the incompressible flag is set and when it is not.",0,0.9914134740829468
119160775,2967,hachikuji,2017-05-30T17:15:48Z,should we rewind the buffer in case the position wasn't reset after the last use? (also nit: can we just call it `buffer`?),0,0.994553804397583
119161965,2967,hachikuji,2017-05-30T17:20:29Z,it's a little odd for this to live here given the interface is in `kafkalz4blockinputstream`. i'd suggest either moving it there or pulling the `buffersupplier` interface out of `kafkalz4blockinputstream`.,0,0.5597636103630066
119174351,2967,ijuma,2017-05-30T18:10:08Z,"yeah, my pr removes all of these in favour of existing constants: [a link]",0,0.947043240070343
119174470,2967,ijuma,2017-05-30T18:10:32Z,you and i had the exact same thought: [a link],0,0.9663512110710144
119174697,2967,ijuma,2017-05-30T18:11:25Z,3 for 3: [a link],0,0.9904947280883789
119174941,2967,ijuma,2017-05-30T18:12:24Z,that's one issue. the other is that if there are two `kafkalz4blockinputstream` instances in the same thread: [a link],0,0.993084192276001
119183125,2967,xvrl,2017-05-30T18:47:29Z,"technically we don't have to, kafkalz4blockinputstream resets position and limit every time anyway when preparing the buffer for consumption. agree that would be a concern if someone were to consume from two separate consumers in the same thread. happy to replace the buffer supplier implementation with the one you pointed to.",1,0.9563776254653931
119185468,2967,hachikuji,2017-05-30T18:57:10Z,"yeah, figured that was the case, but it makes the code a bit brittle to depend on that.",-1,0.8550766706466675
107401674,2719,dguy,2017-03-22T12:36:06Z,i wonder if we should set this higher? is there any harm in setting it to `integer.max_value`?,0,0.9818628430366516
107402332,2719,dguy,2017-03-22T12:39:55Z,do you think we should maybe kill some more brokers? or is that going to be too non-deterministic in terms of test failures?,0,0.9069380164146423
107427012,2719,enothereska,2017-03-22T14:26:45Z,we probably can. the main problem i have right now is how to sidestep all the kafka corner cases when it comes to failures while still showing that streams is resilient. stay tuned.,0,0.9608284831047058
107454080,2719,enothereska,2017-03-22T15:57:22Z,ok,0,0.8787186145782471
107481625,2719,enothereska,2017-03-22T17:36:40Z,do these parameters make sense for a config that should not lose data? we are ok to have duplicates. do i need to do anything with `unclean.leader.election`?,0,0.9895132184028625
108192236,2719,dguy,2017-03-27T14:58:35Z,would be better to pass in an implementation of `time` and use `time.sleep(1000l)` here.,0,0.9935922026634216
108193858,2719,dguy,2017-03-27T15:04:12Z,we currently don't do anything about `min.insync.replicas` - should we?,0,0.9900115132331848
108194089,2719,dguy,2017-03-27T15:05:03Z,"nit: ""active tasks {}, standby tasks {}, suspended tasks {}, and suspended standby tasks {}""",0,0.9904272556304932
108194869,2719,dguy,2017-03-27T15:07:41Z,"`new streamsexception(""could not poll."", e)`",0,0.9438902139663696
108195049,2719,dguy,2017-03-27T15:08:16Z,"apart from a `streamsexception` i think the only other exception that `poll` is going to throw is `illegalstateexception` - should we just handle this in `sendrequest` and leave this as it was. even if there are more exceptions, i think it would be better to handle it in `sendrequest` and throw a `streamsexception` from there",0,0.9871608018875122
108196783,2719,dguy,2017-03-27T15:15:24Z,i guess you can remove this now?,0,0.9820953607559204
108197021,2719,dguy,2017-03-27T15:16:24Z,you can remove this now as you've set it as the default in `streamsconfig`,0,0.9932426810264587
108197175,2719,dguy,2017-03-27T15:16:59Z,same with this one,0,0.9726366400718689
108202868,2719,enothereska,2017-03-27T15:37:34Z,yes we should. any insights on what you have found useful for that? thanks.,1,0.8353070020675659
108203239,2719,enothereska,2017-03-27T15:38:57Z,"not quite, since in streamsconfig it is the internal streams producer. here it's another producer.",0,0.9825930595397949
108262374,2719,norwood,2017-03-27T19:48:07Z,"something like `min(2, replicationfactor)` should be a good default. i'd also be concerned about this override for `brokers.size() < replicationfactor`. i think i'd prefer we fail here, rather than getting in to a misconfigured state. we have run in to issues where a user brings up a cluster and as kafka is doing its thing also brings up their streams app. so during startup we see 1 broker, then sometime down the line broker 2...n. this was causing us to precreate a bunch of our streams topics incorrectly (when we only saw one broker), and then on restart we would try to verify topics against actual configs and fail.",0,0.645612359046936
108262836,2719,norwood,2017-03-27T19:50:09Z,i think `validatetopicpartitions` should also validate `replicationfactor`,0,0.9917531609535217
108263977,2719,mjsax,2017-03-27T19:55:21Z,we need a kip if we change any default values...,0,0.9734650254249573
108264259,2719,mjsax,2017-03-27T19:56:42Z,do we really want to do this? i would strongly prefer to throw an exception to the user!,0,0.8896856904029846
108264430,2719,mjsax,2017-03-27T19:57:23Z,i would not change this default value -- it's a hassle of anyone want to run a demo with local single broker setup.,0,0.6952584981918335
108264962,2719,mjsax,2017-03-27T19:59:40Z,ups. we really missed to close suspended tasks. really bad :( great catch eno!,-1,0.9800574779510498
108265404,2719,mjsax,2017-03-27T20:01:29Z,nit: add `final`,0,0.9897833466529846
108265542,2719,mjsax,2017-03-27T20:02:06Z,nit: add `final`,0,0.9897833466529846
108265707,2719,mjsax,2017-03-27T20:02:53Z,nit: add `final`,0,0.9897833466529846
108265721,2719,mjsax,2017-03-27T20:02:56Z,nit: add `final`,0,0.9897833466529846
108268924,2719,norwood,2017-03-27T20:16:25Z,"maybe a more dynamic default here, like with `acks=all=-1`? e.g. set `replicationfactor=-1` => `actualreplicationfactor=min(3, brokers.size())`",0,0.9954590797424316
108276754,2719,enothereska,2017-03-27T20:51:12Z,"the code actually uses min(#brokers, replication_factor), and prints a warning, but it still runs with, say, 1 broker.",0,0.9878101348876953
108276951,2719,enothereska,2017-03-27T20:51:55Z,"this is consistent with how things like schema registry, proactive support etc handle cases when the number of brokers is less than replication factor.",0,0.9938114285469055
108277094,2719,enothereska,2017-03-27T20:52:35Z,"do we? ? i thought we needed a kip to add new config values, not each time we tune them.",0,0.9843868613243103
108277327,2719,enothereska,2017-03-27T20:53:28Z,"the goal here is to do the right thing when there are enough brokers, not to provide magic when there just aren't enough brokers (e.g., in a test environment). currently we do the wrong thing when there are enough brokers.",0,0.9708396792411804
108278624,2719,enothereska,2017-03-27T20:59:15Z,yeah this was fun :),1,0.9960641264915466
108281740,2719,guozhangwang,2017-03-27T21:14:49Z,"i'd suggest throwing an exception here with the motivation similar to above. we have seen similar issues with offset topic num.partitions which we do this ""min(broker.size, required num.broekrs)"" trick and it introduces much more confusions than user-friendly benefits. for unit tests we should just always override these configs.",0,0.9856653213500977
108282040,2719,guozhangwang,2017-03-27T21:16:24Z,let's write a quick kip for this (also including the default replication factor to 3 above)? i think they are mostly fixing a bug but would better making them well known in the community as well.,0,0.9805580973625183
108282772,2719,guozhangwang,2017-03-27T21:20:17Z,"also i feel 1 second maybe too long in production? in practice brokers should be up / running much earlier than streams apps. for cases i still think it's better to fail fast and educate users retry creating their apps after the broker is fully up than trying to wait for, say 5 seconds and hopefully it will succeed.",0,0.8065613508224487
108283433,2719,guozhangwang,2017-03-27T21:23:29Z,these two functions are very similar: could we collapse them into one function `performontasks` and pass in a `list ` as an additional parameters?,0,0.9813686609268188
108283588,2719,guozhangwang,2017-03-27T21:24:15Z,ditto above.,0,0.9803552627563477
108283829,2719,guozhangwang,2017-03-27T21:25:22Z,why we want to wrap even a rte as a streamsexception here?,0,0.9612589478492737
108283871,2719,guozhangwang,2017-03-27T21:25:38Z,same here.,0,0.9755119681358337
108288736,2719,mjsax,2017-03-27T21:49:35Z,"i think this dynamic change is quite dangerous -- if i specify replication 3 and cannot get it, i want an exception... thus, i would leave replication factor to 1 for demoing purpose -- if anyone goes to production she can set to whatever value is suitable -- or we make the parameter non-optional. i think it would be a hassle to have default value 3, and overwrite it with 1 in each example we do...",-1,0.9628347158432007
108289042,2719,mjsax,2017-03-27T21:51:10Z,we really need a bug fix release for this! \cc,1,0.9785792231559753
108292755,2719,enothereska,2017-03-27T22:09:39Z,"if i understand you right, you want the default 3, with the option for a user to set it to 1, right? or you want no change at all to what we currently have (default 1, user can set higher). i don't like the current option since it leads to trouble in production. i'm ok with the first option.",0,0.6196735501289368
108292984,2719,enothereska,2017-03-27T22:11:04Z,i think a kip unnecessarily slows things down. why do we need to do a kip to correct an internal flaw? users are already expecting internal topics to be robust. i'd argue we're fixing a bug here.,-1,0.6683049201965332
108293564,2719,norwood,2017-03-27T22:14:25Z,"yeah, my suggestion was to make the dynamism configurable. replication_factor_config= n where n >0 => i know what i want. streams should fail if it can't meet this contract replication_factor_config = -1 => streams is smart and can figure it out for me. this allows *me* to be as anal retentive as i want, but allows the defaults to work for demos/tests/etc.",0,0.9536467790603638
108301670,2719,mjsax,2017-03-27T23:06:09Z,"what should this be than? would we need another parameter ""default_replacation_factor"" and streams can choose between 1 and this value? not sure if this would not be too confusing.",0,0.89912348985672
108301836,2719,mjsax,2017-03-27T23:07:18Z,i am happy without a kip :) makes live easier for us. it's call. or any other committer.,1,0.9956117272377014
108302114,2719,norwood,2017-03-27T23:09:18Z,"my suggestion above was `min(3, brokers.size())` i dont like this cause it seems like magic, but it also addresses most peoples issues.",0,0.7169471979141235
108302312,2719,mjsax,2017-03-27T23:10:37Z,"i would prefer to keep the current default 1 and mark the parameter importance as ""high"", indicating that one most likely wants to change the default if going to production. default values must not be ""production ready"" settings imho (cf. `state.dir`). default values should give the best ""out-of-the-box"" experience when getting started with you first ""word count"" -- ie., local single broker setting.",0,0.9921006560325623
108341596,2719,enothereska,2017-03-28T06:20:32Z,"ok, i cannot keep the default to 1. this is what led to several bugs. it's not great to expect users to set this parameter which streams should be maintaining correctly.",-1,0.953541100025177
108359843,2719,ijuma,2017-03-28T08:19:41Z,", as you know, we have changed the behaviour for the offsets topic so that we default to the safe production setting and fail otherwise. that is based on experience, as said, and seems more relevant than some of the other examples given. the question then is how to make it easy for development. for the offsets topic, we set the value to 1 in the `server.properties` that is used in the quickstarts, etc. that won't work here. there are a few possible solutions that will be helpful for this and many other configs: 1. have a config where users can define whether the environment is prod or dev and change the defaults based on that. 2. provide methods so that a user can get a prod or dev config. for example, `streamsconfigs.production()` or `streamconfigs.development()`. 3. add an enum to the constructor of `streamconfigs` where users can define if the environment is production or development. i think i like `3` best. in any case, we don't need to block this pr on the long-term solution. still, it may be worth figuring out the end state and then a plan on how to get there.",0,0.9618036150932312
108364658,2719,enothereska,2017-03-28T08:44:11Z,cc,0,0.8343546390533447
108368495,2719,ijuma,2017-03-28T09:01:55Z,"we typically do kips for config changes that impact users. kip-106 is one such example. if you can make the case that this is an internal bug fix and has no compatibility impact, then no kip is needed. the replication factor one would seemingly have a compatibility impact.",0,0.992272138595581
108471613,2719,enothereska,2017-03-28T16:35:58Z,this will now be done in a kip and different pr.,0,0.9926639795303345
108472487,2719,enothereska,2017-03-28T16:39:37Z,"i'm reducing the time, but passing in `time` is a bit of a pain here and other calls also use thread.sleep. would prefer to do a cleanup pass later.",-1,0.7258006930351257
108472921,2719,enothereska,2017-03-28T16:41:17Z,"i didn't get this, what should be `final`?",0,0.9548486471176147
108473345,2719,enothereska,2017-03-28T16:43:10Z,this class should hide all underlying network exceptions and wrap them with stream exception imo. this is consistent with other examples in this class. otherwise the upper layers would need to know all the details of the underlying classes.,0,0.993507981300354
108473773,2719,enothereska,2017-03-28T16:44:56Z,what exactly? i don't get this.,-1,0.7320274114608765
108479165,2719,enothereska,2017-03-28T17:07:45Z,this will now require a kip. will do in separate pr.,0,0.9890233278274536
108479321,2719,enothereska,2017-03-28T17:08:29Z,this will now require a kip and will be done in separate pr.,0,0.9931471943855286
108479431,2719,enothereska,2017-03-28T17:09:01Z,this will now require a kip and will be done in a separate pr.,0,0.9933305382728577
108481016,2719,mjsax,2017-03-28T17:15:57Z,-> `} catch (final exception e) {`,0,0.9896741509437561
108656204,2719,dguy,2017-03-29T11:52:48Z,can we pass in `time` and use `time.sleep(100l)` here?,0,0.9938418865203857
108656295,2719,dguy,2017-03-29T11:53:14Z,same as above,0,0.965356171131134
108892220,2719,dguy,2017-03-30T10:31:20Z,i'm thinking it might be better to have a field in `streampartitionassignor` for time. it would default to `time.system` and then have a package private method for overriding it in tests. this way we wouldn't need to make the `time` field on `streamthread` public,0,0.9917287230491638
108892245,2719,dguy,2017-03-30T10:31:29Z,see comment above,0,0.9702662825584412
108894798,2719,enothereska,2017-03-30T10:46:16Z,but couldn't that lead to cases when `streamthread` is given one type of time and `streampartitionassignor` another type of time? i'm not sure what that would mean. i think they should use the same time type.,0,0.8757961988449097
108895304,2719,dguy,2017-03-30T10:49:18Z,"in tests that could happen. i guess there are other `public final` fields (which i don't agree with), so whatever",0,0.9317688941955566
109059440,2719,guozhangwang,2017-03-30T23:13:34Z,i'd agree with damian to have this time object pass long the hierarchy than passing it from the thread directly to the internal topic manager. i would not worry too much about passing in different objects since both of them are internal topics so the only place we may directly pass the object is in unit tests.,0,0.9417185187339783
109060051,2719,guozhangwang,2017-03-30T23:18:48Z,"for suspended tasks, could the closure process be simpler? for example we have already closed the topology as well as committing the states, etc. ditto below.",0,0.9917460083961487
109073610,2719,mjsax,2017-03-31T01:39:01Z,"nit: i think the error message does not read well: `not enough brokers 2 for replication factor 3` better: `found only 2 brokers, but replication factor is 3. decrease replication factor for internal topics via streamsconfig parameter ""replication.factor"" or add brokers to your cluster.`",0,0.985800564289093
109073704,2719,mjsax,2017-03-31T01:40:35Z,should we increase backup time if we keep retrying?,0,0.9803815484046936
109073754,2719,mjsax,2017-03-31T01:41:19Z,as above?,0,0.986420750617981
109074329,2719,mjsax,2017-03-31T01:49:23Z,why do we need a `node` now but not before?,0,0.9922261238098145
109074528,2719,mjsax,2017-03-31T01:52:08Z,didn't we change the default values for both already?,0,0.9924325942993164
109074584,2719,mjsax,2017-03-31T01:52:51Z,add `final` to `properties props = new properties();` and method parameters. also all variables used farther down.,0,0.9948416352272034
109074646,2719,mjsax,2017-03-31T01:53:37Z,rename `props` to `producerprops` ;),1,0.7926326394081116
109074740,2719,mjsax,2017-03-31T01:54:38Z,not sure what's happening here. but `6` does still not seem to be large. why change it in the first place?,0,0.8378556370735168
109075186,2719,mjsax,2017-03-31T02:01:04Z,"we have replication factor 3 and min.in.sync.replicas 2 -- it might happen that if 2 brokers fail, a topic does not have enough in-sync-replicates anymore?",0,0.9943524599075317
109114808,2719,enothereska,2017-03-31T08:47:50Z,"i could add an extra method in streamtask.java to close the rest, not the topology. however, this only happens at shutdown, not sure it's worth it. so it could be simpler, but with more lines of code.",0,0.9879792928695679
109115463,2719,enothereska,2017-03-31T08:51:36Z,"traditionally we don't do anything clever with backoff times throughout the code. it can get complicated, e.g., by how much to increase in each step.",0,0.7197542190551758
109115631,2719,enothereska,2017-03-31T08:52:28Z,"because now in `makeready` we check the number of brokers in metadata, whereas before we didn't.",0,0.9949713945388794
109117043,2719,enothereska,2017-03-31T09:01:02Z,we decided that changing the internal default values required a kip. for now just changing the test values in this pr.,0,0.9046012759208679
109117552,2719,enothereska,2017-03-31T09:03:53Z,"this is effectively the timeout of the test. with higher replication factor for the internal topics, and with acks to ""all"" i noticed that the test takes slightly longer to run, so upped this value.",0,0.9798791408538818
109117773,2719,enothereska,2017-03-31T09:04:50Z,"yeah that's fine. this just means that when there is no failure, keep 2 replicas in sync. when there are 2 failures, the system should still be up and running.",0,0.9441798329353333
109203917,2719,mjsax,2017-03-31T16:54:28Z,"depends on the use case: either add the same value each time, or double up. we this when waiting for locks to get released on rebalance already: [a link]",0,0.9905965328216553
109208623,2719,guozhangwang,2017-03-31T17:19:31Z,makes sense.,0,0.9811486601829529
109279169,2719,enothereska,2017-04-01T06:40:45Z,i'm not ready for this yet. we can revisit backoffs in all the streams code and see how the networking client code has done them. also we should tie these numbers to some sort of config users can set.,0,0.7084287405014038
649771532,10822,erdody,2021-06-11T07:56:17Z,nit: or empty **if** this worker ....,0,0.7968088984489441
649777408,10822,erdody,2021-06-11T08:05:50Z,"nit: this actually collects the state of all tasks, so it's only empty if there are no tasks, right?",0,0.9531147480010986
649778786,10822,erdody,2021-06-11T08:08:00Z,nit: can use a method reference,0,0.9888707995414734
649791058,10822,erdody,2021-06-11T08:26:54Z,"there are a few comments in different places explaining the special equality implementation in restartrequest. have we considered making this a map to make it explicit that we keep the latest per connector, have a more typical equals/hashcode and avoid all the warnings?",0,0.9886542558670044
649792398,10822,erdody,2021-06-11T08:28:48Z,"just out of curiosity, any particular reason why we want to process these in connectorname order? (instead of fifo)",0,0.9819191694259644
649797930,10822,erdody,2021-06-11T08:36:52Z,nit: use a message similar to the one you corrected in line 1030?,0,0.989378035068512
649800302,10822,erdody,2021-06-11T08:40:27Z,"just wondering: could blocking the addition of new entries be a problem, considering that this method can take some time? would it be worth creating a copy of the collection to minimize the synchronized time?",0,0.984837532043457
649803403,10822,erdody,2021-06-11T08:44:48Z,"nit: quotes around connectorname, like in the line below",0,0.9883737564086914
649806839,10822,erdody,2021-06-11T08:49:53Z,the return value is only used by tests. can we assert based on other methods calls instead?,0,0.9933757185935974
651253521,10822,erdody,2021-06-14T20:26:32Z,nit: move up so you can share with 270?,0,0.9859558343887329
651262244,10822,erdody,2021-06-14T20:40:49Z,nit: `boolean.parseboolean()`,0,0.9922881126403809
651291606,10822,kpatelatwork,2021-06-14T21:30:52Z,done,0,0.8974218964576721
651291754,10822,kpatelatwork,2021-06-14T21:31:09Z,fixed,0,0.9281549453735352
651291878,10822,kpatelatwork,2021-06-14T21:31:22Z,fixed,0,0.9281549453735352
651292365,10822,kpatelatwork,2021-06-14T21:32:16Z,fixed,0,0.9281549453735352
651292417,10822,kpatelatwork,2021-06-14T21:32:22Z,fixed,0,0.9281549453735352
651293447,10822,kpatelatwork,2021-06-14T21:34:20Z,"i agree it is used by only tests but it made the tests more clear rather than relying on mock verify. i added a comment to the code to make this clear, please let me know if the new changes looks good.",0,0.8435891270637512
651296666,10822,kpatelatwork,2021-06-14T21:40:35Z,we can't make a copy because we are doing pollfirst and its removing it out of set ` while ((request = pendingrestartrequests.pollfirst()) != null) { ` the whole method synchronization was done deliberately to keep the code simple. one more point is that this just triggers the start of connector/tasks and real start happens in another thread so this should be pretty fast.,0,0.986207127571106
651298044,10822,kpatelatwork,2021-06-14T21:43:12Z,"no particular reason, treeset was a navigableset implementation that came to my mind. but i like your above idea of using a map and simplifying the code, let me work on it.",1,0.6090973615646362
651300080,10822,kpatelatwork,2021-06-14T21:46:49Z,"good idea, fixed",1,0.9819871783256531
651323170,10822,kpatelatwork,2021-06-14T22:38:07Z,"fixed, could you please check to see if it looks good now?",0,0.9760712385177612
651323500,10822,kpatelatwork,2021-06-14T22:38:54Z,new implementation with iterator makes this explicit. could you please check to see if it looks good now?,0,0.9756550788879395
651508714,10822,erdody,2021-06-15T07:09:53Z,"the main problem is that you're testing the code you added for tests, not that the actual actions are executed. unless you're also have coverage to verify that there's correspondence between the different results and the actions that need to happen in each case.",0,0.9842033386230469
651509086,10822,erdody,2021-06-15T07:10:23Z,"afaics, since all accesses are synchronized, this doesn't need to be concurrent.",0,0.9784107208251953
651852657,10822,kpatelatwork,2021-06-15T14:32:29Z,fixed,0,0.9281549453735352
651854001,10822,kpatelatwork,2021-06-15T14:33:51Z,i removed the return and fixed the tests just to power mock verify. anyway i have integration tests so i partially agree that the return values were just me being paranoid in testing.,0,0.9692507982254028
652845546,10822,rhauch,2021-06-16T16:16:53Z,can we replace these two methods with the following? [code block],0,0.9926826357841492
652846118,10822,rhauch,2021-06-16T16:17:35Z,nit: [code block],0,0.9847351312637329
652848315,10822,rhauch,2021-06-16T16:20:31Z,"this method name is very similar to the `includetasks()` getter method. wdyt about changing to `istaskincluded(taskstatus status)` instead, to more clearly differentiate that it's not merely a getter? if so, then `includeconnector(...)` could be renamed to `isconnectorincluded(connectorstatus status)`, too.",0,0.9919335246086121
652850147,10822,rhauch,2021-06-16T16:22:43Z,nit: [code block],0,0.9847351312637329
652852357,10822,rhauch,2021-06-16T16:25:39Z,"if the `dorestartconnectorandtasks(..)` method fails, then we won't remove the restart request and the herder will never make progress. should we protect this call a bit more with a try-catch-finally block?",0,0.9754176139831543
652854145,10822,rhauch,2021-06-16T16:28:00Z,"another option might be to dequeue (from the map) the restart requests in a synchronized block, and then perform those restarts outside of the synchronized block. this would at least minimize the work being done within the synchronized block to be just iteration and removal, lessoning the likelihood of blocking new requests. wdyt?",0,0.9730938673019409
652858133,10822,rhauch,2021-06-16T16:33:15Z,"of course, another option is to use a concurrent queue rather than a map, and deduplicate the requests only upon processing. for example, this method could dequeue all of them to a collection, replacing any earlier request with a more recent one, and then restart all of the deduplicated requests (ideally in the same order in which they were received). i'm not sure this is actually simpler. or, did you consider using a concurrentmap to avoid synchronization? that may be the least complicated way to remove the synchronization and yet require very few changes to the existing logic.",0,0.9813759326934814
652858998,10822,rhauch,2021-06-16T16:34:22Z,let's avoid more than 1 adjacent blank line: [code block],0,0.987820029258728
652860987,10822,rhauch,2021-06-16T16:37:08Z,"i assume the choice of info here was intentional. if not, at what log level do we really want this log message? if so or if we do want this at info level, then maybe we should modify the `restartrequest.tostring()` method to be a little more user friendly (e.g., `restart request for connector %s (...)`). and would it help to mention here that it's being enqueued? maybe: [code block]",0,0.993358314037323
652872036,10822,rhauch,2021-06-16T16:52:13Z,nice! i didn't recall that `` exists. but we should not have a space between that annotation and the open parenthesis: [code block],1,0.985471248626709
652875494,10822,rhauch,2021-06-16T16:55:46Z,"won't `string.valueof(boolean)` be used here, and thus we're unboxing the `boolean` instance here? if there is a default value, then will `includetasks` and `onlyfailed` both always be non-null, and if so then couldn't we just use `boolean.tostring()` here?",0,0.994162380695343
652877090,10822,rhauch,2021-06-16T16:57:28Z,maybe add a comment here: [code block],0,0.9907445311546326
652881239,10822,rhauch,2021-06-16T17:03:05Z,"nit: i wonder if these log messages would be a bit easier to search and filter if they were reworded slightly: [code block] if you agree, then maybe also make similar changes to the corresponding log messages in the `distributedherder`.",0,0.9799843430519104
652883217,10822,rhauch,2021-06-16T17:05:57Z,"should we use a constant for this? i see that it's not really a pattern in the existing code, but maybe we should still do that here.",0,0.989385724067688
652884464,10822,rhauch,2021-06-16T17:07:48Z,"wdyt about being a bit more tolerant of missing keys? for example, we could use defaults here.",0,0.9572431445121765
652885234,10822,rhauch,2021-06-16T17:08:52Z,let's avoid more than one adjacent blank lines. [code block],0,0.9885953068733215
652886935,10822,rhauch,2021-06-16T17:10:25Z,"""both"" what?",0,0.9859717488288879
652887340,10822,rhauch,2021-06-16T17:10:45Z,"again, ""both"" what?",0,0.8706029653549194
652888065,10822,rhauch,2021-06-16T17:11:27Z,can we be more explicit in the test method names about what this test does?,0,0.9824658632278442
652888765,10822,rhauch,2021-06-16T17:12:32Z,what does this mean:,0,0.9740179777145386
652890167,10822,rhauch,2021-06-16T17:14:33Z,"iiuc, we are not actually testing that the connector and task instances are distributed across different worker nodes, though it is likely to happen given the light connector load on the connect cluster.",0,0.9924523234367371
652891026,10822,rhauch,2021-06-16T17:15:44Z,"how long does it take for all of the tests in this it to run, say locally? iiuc, we're setting up a new kafka cluster and connect cluster for every test. how difficult would it be to share the same kafka and connect cluster across most of the tests?",0,0.820586085319519
652921473,10822,kpatelatwork,2021-06-16T17:55:54Z,"could you guide me if there a predictable way to spread the tasks then i can change the test? i found that when i gave numworkers>1 most of the time they were distributed that's how i found an npe bug and had to use in the api. i am using numworkers=1 in other test to have a deterministic number of task restarts, whenever i had numworkers>1 the tasks would get restarted more than what i expect due to rebalance on worker nodes coming up.",0,0.9685440063476562
652923058,10822,kpatelatwork,2021-06-16T17:57:09Z,its on average 7-11sec per test (the ones with 35 sec are due to waiting in noop cases) ![a link] let me see if i can find a way to share and if it reduces the time.,0,0.9600035548210144
653046083,10822,kpatelatwork,2021-06-16T20:53:16Z,"the name was bothering me also :), the method documentation says ""determine whether the connector with the given status is to be restarted."" wdyt about changing it to one of the below? 1. isconnectorrestartable 2. istaskrestartable or 1. shouldrestartconnector 2. shouldrestarttask",0,0.7674914598464966
653053764,10822,kpatelatwork,2021-06-16T21:06:14Z,"good point , i missed this behavior when i moved from navigablemap to a normal hashmap. let me fix it.",1,0.9773880839347839
653088343,10822,kpatelatwork,2021-06-16T22:07:20Z,fixed,0,0.9281549453735352
653089179,10822,kpatelatwork,2021-06-16T22:09:03Z,fixed and changed all test names to be explicit,0,0.9922154545783997
653089598,10822,kpatelatwork,2021-06-16T22:09:58Z,"thanks for noticing this, its my bad the ide method extract left the comment and i didn't notice.",-1,0.9691392779350281
653089924,10822,kpatelatwork,2021-06-16T22:10:42Z,fixed,0,0.9281549453735352
653115877,10822,rhauch,2021-06-16T23:17:29Z,either work for me.,0,0.9599785208702087
653116810,10822,rhauch,2021-06-16T23:20:07Z,"two things. first, these multi-worker its are not necessarily testing the requests getting forwarded to the leader, but that's really hard to do. second, it might be good to try to send the request to a worker that is not running any instances to be restarted. one way to do that is to run 1 more worker than the total number of `connector` and `task` instances for the connector being restarted. though i'm not sure this adds a lot of value given the others unit tests.",0,0.9544166922569275
653117252,10822,rhauch,2021-06-16T23:21:18Z,"yeah, that's already a good portion of the total time to run the connect unit and integration tests. it'd be great if we could avoid increasing the build times by that much.",0,0.7764238715171814
653117875,10822,kpatelatwork,2021-06-16T23:23:03Z,"good idea, i fixed it",1,0.9888295531272888
653118611,10822,kpatelatwork,2021-06-16T23:25:12Z,"good idea , i fixed it. i added a default constant in kafkaconfigbackingstore class, the only thing i was unsure of if i should use the same default constant in connectorsresource class api or not. they seem to be 2 different world and i didn't wanted to introduce a dependency between the classes as it would expose unwanted details so right now default=false is in 2 places. please let me know if you have a better idea to solve this or if it's ok to have it copied the default value in 2 places.",1,0.8197196125984192
653119839,10822,kpatelatwork,2021-06-16T23:28:46Z,"thanks, i went with shouldxxx and it's committed, the code looks much better now.",1,0.9671161770820618
653174069,10822,kpatelatwork,2021-06-17T02:10:54Z,"this was a good find, i just refactored the code, and this saved 2 min ![a link]",1,0.9282622933387756
653681672,10822,rhauch,2021-06-17T15:32:38Z,nit: would a delimiter here help? [code block],0,0.9913383722305298
653687374,10822,rhauch,2021-06-17T15:39:33Z,"this method is where the worker restarts connector and task instances assigned to it. lines 1153 and 1155, along with the `assignedidstorestart` are really the only evidence that this method does that. can we modify the comments and log messages in this method to make that more evident, and maybe add javadoc?",0,0.9930790066719055
653698313,10822,rhauch,2021-06-17T15:52:11Z,"can you confirm that the methods called in this block of logic handle failures? for example, the `worker.stopandawaitconnector(...)` method waits only up to 5 seconds, and we have no visibility into whether the connector was actually stopped in that time or we timed out. if we timed out, should we restart the connector, or should we abort this method and try again later? if we retry again later, it seems like it's okay to try stopping an already stopped connector, but it'd be good to double check that. same questions about stopping the tasks. we may need to modify the `stopandawait...(...)` methods to add a callback that will allow us to better track what was actually stopped. and where this method is called we may need to handle the case where this restart was not completed and re-enqueue it for restart.",0,0.987048327922821
653701944,10822,rhauch,2021-06-17T15:56:20Z,"one thing about using a map is that we're always saving the last restart request, rather than the restart request that will (potentially) have the greatest impact. consider two restart requests are submitted at about the same time: 1. restartrequest 1 requests that everything is restarted (onlyfailed=false) for connector foo 2. restartrequest 2 requests that only failed instances are restarted (onlyfailed=true) for connector foo if this method saw restartrequest 2 before restartrequest 1, then everything would be restarted as expected. but if this method saw restartrequest 1 first, then only the failed tasks would be restarted. seems like we should keep the most impactful one: restartrequest 1 in this example. wdyt?",0,0.9907305836677551
653705258,10822,rhauch,2021-06-17T16:00:11Z,"excellent! iiuc, the tests are only using 2 differently-sized clusters (1 node and 4 nodes), which is good because it minimizes the startup time. can you confirm that statement is true? it seems like there are three total methods that take more than 30 seconds -- any reduction in duration on any of those three will have a very direct impact.",1,0.9951590895652771
653745712,10822,kpatelatwork,2021-06-17T16:49:20Z,"and i changed the implementation to dequeue from map and perform the restart outside the synchronized block, could you please review to see if it looks ok now?",0,0.9925305247306824
653749526,10822,kpatelatwork,2021-06-17T16:52:53Z,"this is an excellent suggestion, i just added this test based on the above discussion [a link] and now feel more confident that we are testing the distributed behavior of the feature. here is a sample response i copied from the above test output and we can see the call from the test was made on a worker not running the task or connector instance.",1,0.9526772499084473
653753526,10822,kpatelatwork,2021-06-17T16:56:42Z,"i agree and i fixed it as part of recent tests changes, ` private static final string connector_name_prefix = ""conn-""; `",0,0.9646284580230713
653815012,10822,kkonstantine,2021-06-17T18:02:00Z,"seeing above, seems that this might as well be called `onrestart`. it's only naming but still would be nice to maintain consistency",0,0.9768327474594116
653819933,10822,kpatelatwork,2021-06-17T18:09:43Z,"i went with a different sleep duration and that cut the times by 1minute 15 sec ![a link] [a link] i chose 5sec because locally the test that sets up the cluster takes around 5 sec to do it and most test after they setup the cluster finishes in <300ms, request propagation and restart isn't taking long but thats my local machine and i chose to do 15 times the wait in case cloud or other developer machines are slow. could you please review to see if you agree with the fix as another idea is to reduce it to 1 sec?",0,0.5145543217658997
653854373,10822,kpatelatwork,2021-06-17T18:57:12Z,"i agree and implemented it, could you please review the below commit and see if it suffices? [a link]",0,0.8573566675186157
654043932,10822,kpatelatwork,2021-06-17T23:19:44Z,+1 i just fixed them in both classes,0,0.540781557559967
654060352,10822,kpatelatwork,2021-06-18T00:10:56Z,"i did confirm that both stop and await for task and connector does connector.cancel() and task.cancel() if it timed out. i added try/catch in start connector/tasks [a link] however, i am not sure about re-enqueue as it can lead to infinite tries, and adding retries may complicate things so need some guidance. could you please review to see if it looks a bit better now?",0,0.9847123622894287
654741212,10822,kpatelatwork,2021-06-19T03:30:22Z,the new times after checking that api response didn't return any restarting state is 13 sec and 10 sec out of it is in bringing up kafka cluster. ![a link],0,0.9154081344604492
654741381,10822,kpatelatwork,2021-06-19T03:32:23Z,added javadoc and cleaned some logs and there are logs in the called methods so didn't added new logs,0,0.9911718964576721
655408049,10822,kpatelatwork,2021-06-21T14:06:30Z,"we can add a retrycount in the restartrequest and start with a default of 5 and decrement it every time we re-enqueue. if the tick() happens every second then we can exhaust the retries pretty fast so we may need to add backoff with a delay before processing the request. adding retry logic to this pr can make the pr complex, i would vote for adding it in a separate pr.",0,0.9874159693717957
655658286,10822,rhauch,2021-06-21T19:45:48Z,"i would agree. we're not sure whether we need this behavior yet, so i'm +1 for keeping it simple in this pr and adding it in the future only if we discover a need for it.",0,0.9575515389442444
655660680,10822,rhauch,2021-06-21T19:49:52Z,let's mention the natural sort order.,0,0.986166775226593
655678526,10822,rhauch,2021-06-21T20:21:36Z,"the `startconnector(...)` method _should_ handle most of the errors by calling the callback, but there are still a few potential errors that could happen before the worker actually tries starting the connector. do you think this try-catch is needed, though, since the try-catch where this `dorestartconnectorandtasks(...)` is called will catch and log any unexpected change? i guess keeping this will ensure we proceed with starting the tasks, rather than failing quickly.",0,0.988454282283783
655683692,10822,rhauch,2021-06-21T20:30:35Z,"if we were to change `pendingrestartrequests` to a `concurrentmap`, then we could use the `compute(...)` functionality that actually would work even if we removed the synchronization. i wonder if this is a bit more readable (even though strictly speaking we don't need concurrent access). wdyt? [code block]",0,0.9392263293266296
655688374,10822,rhauch,2021-06-21T20:38:42Z,what do you think about returning `optional ` here (if every worker has at least one instance for the given connector) rather than throwing an exception?,0,0.9936190247535706
655749684,10822,kpatelatwork,2021-06-21T22:40:23Z,"i kinda agree with you but i had seen this code in below two links and it had try/catch around both starttask and startconnector . i added try/catch around starttask so if one tasks fails we can see if others atleasst succeed. the try/catch around startconnector was because i saw the pattern. but i am torn on this, if you think we should remove the try/catch on connector, i am open to removing the try/catch given its already caught at the higher layer, but imho we can keep the starttask try/catch. wdyt? [a link] [a link]",1,0.6001482605934143
655755572,10822,kpatelatwork,2021-06-21T22:55:44Z,turns out a normal hashmap also has compute so i just used it.,0,0.9864640235900879
655755798,10822,kpatelatwork,2021-06-21T22:56:17Z,"i added some javadoc, could you please review and see if it looks good?",0,0.9684459567070007
655757673,10822,kpatelatwork,2021-06-21T23:01:30Z,i think it's a good idea but i saw that org.apache.kafka.connect.util.clusters.embeddedconnectcluster#endpointforresource method is using the same pattern and if i change it then i will have to change a lot of classes not related to this pr and ultimately in the test i will have to check for optional.present and do an assert. the situation for not finding a worker is rare and doing empty check and assert in all places will be a lot of copy/paste whereas throwing an exception here is centralizing this rare situation. do you think it's ok to leave it as is?,0,0.9098818898200989
655776106,10822,rhauch,2021-06-21T23:42:01Z,"yeah, i think it's actually fine the way it is: with the try-catrch around `startconnector(...)`, because that helps us catch any problem _at that point_ and allows us to continue starting the tasks. if we were to remove this try-catch around `startconnector(...)`, then any problem would cause us to return immediately from the method.",0,0.928006112575531
655778416,10822,rhauch,2021-06-21T23:48:33Z,"well, the `embeddedconnectcluster` is technically not an official public api for connect, but lots of connector projects use it (as intended), meaning we have to be very clear about backward compatibility. it's probably fine to keep the same pattern.",0,0.9780007600784302
655781412,10822,rhauch,2021-06-21T23:57:06Z,"it might be good to clean up the method name a bit. since it's similar to the existing `endpointforresource(...)`, maybe just add a suffix ... maybe something like `endpointforresourcenotrunningconnector()`?",0,0.9899730682373047
655781662,10822,rhauch,2021-06-21T23:57:46Z,please add descriptions of the other parameters and the return value.,0,0.9838682413101196
655885518,10822,kkonstantine,2021-06-22T05:25:50Z,"i think we can avoid this alignment style. it leaves us with significantly less space to write lambdas, etc. (another indicator is that this style is not applied elsewhere in the file). two tab stops in the line below should be fine, even if the declaration above is where it is now.",0,0.9841782450675964
655887809,10822,kkonstantine,2021-06-22T05:31:37Z,"i don't think we have examples in connect where we refer to an argument in the name of a method. maybe we don't want to change this just yet with the opportunity of the changes introduced by this feature. another observation is that we don't use `get`, `set` and possibly `build`. but since it wouldn't be obvious if it's an action or an object maybe leaving `buildrestartplan` might be fine here. (`restartplan` would be the alternative)",0,0.9902660250663757
655891458,10822,kkonstantine,2021-06-22T05:41:30Z,maybe a good idea to say that this is a plan per connector (and not a global plan). i know the javadoc of the constructor says it already but good to be at the top level too.,0,0.9595646262168884
655892160,10822,kkonstantine,2021-06-22T05:43:08Z,nit: in the constructor we refer to member fields with `this.` during initialization (even if they are not shadowed) [code block],0,0.9943424463272095
655893949,10822,kkonstantine,2021-06-22T05:47:38Z,`shouldrestarttasks` or `shouldrestartanytasks` (same recommendation as above),0,0.9947060942649841
655893977,10822,kkonstantine,2021-06-22T05:47:42Z,since this is not an action but a recommendation i think it'd be better to call `shouldrestartconnector`,0,0.9865425825119019
655894996,10822,kkonstantine,2021-06-22T05:50:00Z,not sure we should say `restart` in the method name. the object is already a `restartplan` type. so that's a bit redundant i think. `connectorstateinfo` ?,0,0.964162290096283
655896479,10822,kkonstantine,2021-06-22T05:53:29Z,below we have a method name called `restartconnectorandtasks` implying _any_ tasks. so maybe we can skip `any` in the name.,0,0.9943732023239136
655900253,10822,kkonstantine,2021-06-22T06:02:13Z,use of `final` doesn't seem to be consistent in this method. i'd suggest skipping its addition to local variables unless we need it in lambdas.,0,0.9905237555503845
655902961,10822,kkonstantine,2021-06-22T06:07:49Z,any reason not to use primitive types? [code block],0,0.9924284815788269
655904820,10822,kkonstantine,2021-06-22T06:11:50Z,do we have to call it snapshot? is `startsandstops` enough? [code block],0,0.9949434399604797
655905352,10822,kkonstantine,2021-06-22T06:13:02Z,i found the name a bit overloaded and added a suggestion below. you think we could make it a bit simpler?,0,0.9730480313301086
656348082,10822,kpatelatwork,2021-06-22T15:41:56Z,the defaults are used in code like below and using primitive would lead to an extra boxing,0,0.993293285369873
656356700,10822,kpatelatwork,2021-06-22T15:50:11Z,"excellent suggestion, naming is indeed hard problem and i had the same feeling this is overloaded. i applied your suggestion.",1,0.9954832792282104
656356999,10822,kpatelatwork,2021-06-22T15:50:29Z,fixed,0,0.9281549453735352
656357145,10822,kpatelatwork,2021-06-22T15:50:38Z,thanks for catching this,1,0.5260965824127197
656357635,10822,kpatelatwork,2021-06-22T15:51:09Z,thanks for catching this.,0,0.5459718704223633
656358121,10822,kpatelatwork,2021-06-22T15:51:45Z,renamed to buildrestartplan as per your suggestion.,0,0.9922001957893372
656358424,10822,kpatelatwork,2021-06-22T15:52:04Z,"good observation, i fixed it.",1,0.942396342754364
656633158,10822,kpatelatwork,2021-06-22T22:49:51Z,fixed documentation and renamed the method.,0,0.9903880953788757
656633775,10822,kpatelatwork,2021-06-22T22:51:29Z,"good idea, i renamed the method.",1,0.9753791689872742
656652231,10822,kpatelatwork,2021-06-22T23:39:56Z,fixed,0,0.9281549453735352
656653569,10822,kpatelatwork,2021-06-22T23:42:54Z,i think we should keep it because in the caller code plan.connectorstateinfo() conveys its the current state but plan.restartconnectorinfo() conveys the intent that its the stateinfo with restart state. i know its not the best name :( cc: if he has any better suggestions for the name.,-1,0.9882140159606934
656654293,10822,kpatelatwork,2021-06-22T23:44:45Z,"and i renamed the methods for shouldxxx suggestion. for removing any in the name, i think we should keep it in the name because plan.shouldrestarttasks() in caller code conveys the intent it would restart all tasks but plan.shouldrestartanytask conveys it would restart at least one task. i know its again not the best name. wdyt if we rename it to shouldrestartatleastonetask, it was too verbose that's why we had picked any?",0,0.8769352436065674
657118416,10822,rhauch,2021-06-23T13:46:50Z,"this is subtly different than a normal `connectorstateinfo`, so keeping the current name may be a bit more clear in the context where this method is used, even if it's less conventional.",0,0.9810195565223694
657148983,10822,kpatelatwork,2021-06-23T14:18:16Z,renamed to shouldrestarttasks,0,0.9933789968490601
660274546,10822,kkonstantine,2021-06-29T04:38:50Z,is there any reason we are not adding these new methods in the `taskstatus.listener` interface? in any case we should add javadoc to the base declaration (interface or class methods).,0,0.9953871369361877
660275673,10822,kkonstantine,2021-06-29T04:42:29Z,"nit: the ternary operator can be used (`?:`) as below, unless you're not a fan. [code block]",0,0.9012362360954285
660276986,10822,kkonstantine,2021-06-29T04:46:34Z,"a bit confusing that a second assignment follows if the `if` statement is true. i'd also call the variable `taskstate` (as opposed to `connectorstate` above) ternary can be used here as well: [code block] (as with any suggestion from github, please check it compiles and conforms to the style)",0,0.9660211801528931
660280566,10822,kkonstantine,2021-06-29T04:57:05Z,no problem.,0,0.9306607842445374
660281788,10822,kkonstantine,2021-06-29T05:00:50Z,something like? [code block] breaking this long statement doesn't make it much less long i guess.,0,0.8079140782356262
660283562,10822,kkonstantine,2021-06-29T05:06:17Z,"[code block] ? (seems a bit more common way to say it, but i don't have a strong opinion)",0,0.9330050945281982
660290194,10822,kkonstantine,2021-06-29T05:25:47Z,"i see we've been verbose in similar logic above before, but maybe we can improve on that a bit, at least in new code. here's another suggestion: [code block]",0,0.9803138971328735
660291164,10822,kkonstantine,2021-06-29T05:28:23Z,"following up on the comment above, here's how we could write this and avoid autoboxing/unboxing while using the more readable primitives. [code block]",0,0.9917997121810913
660291287,10822,kkonstantine,2021-06-29T05:28:45Z,similar suggestion as above,0,0.9749158620834351
660291760,10822,kkonstantine,2021-06-29T05:29:56Z,i agree the conversion is on a frequently used path. but maybe it's the code below that can be re-written to avoid both autoboxing and unboxing (when it's not required),0,0.9889394640922546
660293584,10822,kkonstantine,2021-06-29T05:34:43Z,"this misuse might have originated because above, specifically for tasks, `null` is actually a valid value (tombstone/delete), which is not the case here.",0,0.9905411601066589
660295568,10822,kkonstantine,2021-06-29T05:40:09Z,since we print the warning inside `recordtorestartrequest` we can probably avoid the early return with: [code block],0,0.9942758679389954
660296712,10822,kkonstantine,2021-06-29T05:43:05Z,"btw, all other log statements are `log.error` elsewhere. should we remain consistent with that, instead of using `log.warn` just here? the issues seem similar above.",0,0.9917356371879578
660301592,10822,kkonstantine,2021-06-29T05:55:31Z,dependents in the implementation of `startandstoplatch` seems to overload the meaning of `null` with a check. but it actually doesn't seem to matter. the call is equivalent to passing an empty list. should we simplify that with something like: [code block] ?,0,0.9911289215087891
660301819,10822,kkonstantine,2021-06-29T05:56:03Z,see comment above on whether `null` matters.,0,0.9898253083229065
660303274,10822,kkonstantine,2021-06-29T05:59:36Z,"does it make sense to skip, given that it's called below? (i hope i'm not missing something)",0,0.9776602983474731
660309326,10822,kkonstantine,2021-06-29T06:13:53Z,nit: similar style as elsewhere in this file [code block],0,0.9831017851829529
660311654,10822,kkonstantine,2021-06-29T06:18:53Z,nit: type inference is nice ... [code block],1,0.9103825688362122
660315005,10822,kkonstantine,2021-06-29T06:25:58Z,i'd call it `plan` here.,0,0.988613486289978
660315335,10822,kkonstantine,2021-06-29T06:26:38Z,safe to skip the declaration here. [code block],0,0.9914342164993286
660315588,10822,kkonstantine,2021-06-29T06:26:59Z,nit: extra [code block],0,0.9859216809272766
660320316,10822,kkonstantine,2021-06-29T06:36:25Z,same as the connector call above [code block],0,0.9919344186782837
660781818,10822,kpatelatwork,2021-06-29T16:29:13Z,fixed,0,0.9281549453735352
660782579,10822,kpatelatwork,2021-06-29T16:30:10Z,i agree and i fixed it like you suggested.,0,0.6912006735801697
660834568,10822,kpatelatwork,2021-06-29T17:42:17Z,"the plan may or may not be present, that's why i was calling it maybeplan",0,0.9897095561027527
660836387,10822,kpatelatwork,2021-06-29T17:45:00Z,"we are logging an error if we are rejecting the request due to an invalid type, but in this particular case as we are defaulting the missing fields, that's why the warn.",0,0.9506648778915405
660864346,10822,kpatelatwork,2021-06-29T18:26:17Z,"i added the missing documentation. i didn't add the onrestart method to listener because it didn't felt it should be a part of the task lifecycle controlled by the worker. earlier the method was called recordrestart but based on a review comment, it was renamed it to onrestart, do you think we should rename it back to recordrestart. the original intent of this method was to just record the state change.",0,0.9908242225646973
660866556,10822,kpatelatwork,2021-06-29T18:29:36Z,fixed as per your suggestions.,0,0.989044189453125
660867874,10822,kkonstantine,2021-06-29T18:31:31Z,did you compare it with other methods? my understanding is that `ondelete` is the same in that respect and exists on the `listener` as well. but i might have skimmed too quickly through the code,0,0.9843766689300537
660868474,10822,kkonstantine,2021-06-29T18:32:28Z,didn't notice. thanks. makes sense then,1,0.9840022325515747
660870565,10822,kkonstantine,2021-06-29T18:35:40Z,"we might be too precise here. as we discussed elsewhere, baking the meaning of the type in every variable name might be too verbose. it's a plan, and the fact that is optional means that there might be one or it might not. that's how i'd read it. the other use of `maybeplan` below is harder to avoid. feel free to keep it consistent here with what you have below. again, my point is not to bake type meaning in the variable names. i feel this keeps things simpler.",0,0.8020449280738831
660925249,10822,kpatelatwork,2021-06-29T20:02:52Z,after your latest explanation it makes sense to rename it to keep it simple. thanks for guiding me. i have renamed it.,1,0.9235264658927917
660953271,10822,kpatelatwork,2021-06-29T20:48:53Z,you are right. do you mind if we do this work in a follow-up pr? the reason i ask is because if we add it to the listener then it becomes part of the interface and this would require me to retrofit the listener event into the old restarttask and restartconnector api for backward compatibility reasons and it can be big change to this already big pr.,0,0.9647282361984253
661028655,10822,kpatelatwork,2021-06-29T23:28:38Z,i moved it to the lisetner interface in [a link] could you please check to see if it looks good.,0,0.9014431238174438
1579221285,15640,cadonna,2024-04-25T10:08:01Z,"why do you use a timer here? the `asynccommit()` does not throw any timeout exception, does it? if you need to pass the timer to the `commitevent` or further up the class hierarchy then you can create the timer in the constructor of `asynccommitevent` or even further up the class hierarchy.",0,0.9952736496925354
1579239807,15640,cadonna,2024-04-25T10:24:10Z,"why should those two fields ever be `null`? they seem necessary for the consumer to function correctly. if my statement is correct, the constructors should ensure that those fields are never `null`.",0,0.9935217499732971
1579264527,15640,cadonna,2024-04-25T10:45:03Z,"i have two questions here: 1. why is this code not in `completableevent`? 2. why do you not keep the timer in a object field? regarding 2, i have the feeling this pr contains code that already exist in the timer. you could have a method on `completableevent` that checks for the expiration without exposing the timer. something like `isexpired()` or `istimedout`.",0,0.97446209192276
1579269984,15640,cadonna,2024-04-25T10:49:30Z,could you export this lines into a method `processapplicationevents()` or similar. i think it makes the code more readable.,0,0.9887201189994812
1579275627,15640,cadonna,2024-04-25T10:54:36Z,do we need this comment? i am not a big fan of inline comments in general. all the information about the behavior in the comment should be clear from the corresponding unit tests. i do not think we need the references to the legacy consumer. once the legacy consumer is gone we need to remove these references which is work that we can avoid by just not writing those comments.,0,0.5830960273742676
1579283124,15640,cadonna,2024-04-25T11:00:50Z,i think that is clear from the code. we do not need the comment.,0,0.9556870460510254
1579292380,15640,cadonna,2024-04-25T11:09:42Z,"here i have a similar comment as with `asynccommitevent`, i would move the creation of the timer into the constructor of `consumerrebalancelistenercallbackneededevent`.",0,0.9927555918693542
1579314894,15640,cadonna,2024-04-25T11:30:24Z,same questions as above.,0,0.9879977703094482
1579322300,15640,cadonna,2024-04-25T11:36:39Z,"nit: imo, this is more readable, but feel free to leave it if you do not share my taste. [code block]",1,0.5728428363800049
1579324613,15640,cadonna,2024-04-25T11:38:47Z,wouldn't it be safer to not have a default here as a reminder for closing.,0,0.9881520867347717
1579733831,15640,kirktrue,2024-04-25T15:45:14Z,"yeah, i went back and forth on this a few times :winking_face: ultimately i wanted to force the caller to be explicit about its timeout intention, vs. having it implicitly ""hidden"" away in the event hierarchy. also, to create a `timer` in the event constructor, we'd have to pass in a `time` object (`time.timer(long.max_value)`), which seemed a bit obtuse, so :man_shrugging:",-1,0.6967222094535828
1579735209,15640,kirktrue,2024-04-25T15:46:22Z,"they're only `null` if there was an error in the constructor. the constructor's `finally` block calls `close()`, so we need to handle the case where the consumer wasn't fully constructed before it's closed.",0,0.9931303858757019
1579756071,15640,kirktrue,2024-04-25T16:01:51Z,"i'm happy to reword the comment and clean it up, but the lines that follow that comment are the raison d'tre of this change. it's very subtle and easy to miss, hence the call-out.",1,0.9459840059280396
1579760563,15640,kirktrue,2024-04-25T16:05:28Z,i'll look into how to do this in a way that i don't find too ugly :winking_face:,-1,0.9418715238571167
1579864626,15640,kirktrue,2024-04-25T17:22:11Z,"`completableevent` is an interface, but i could see if i can put a static method in there to keep the logic in one place.",0,0.9930807948112488
1579865601,15640,kirktrue,2024-04-25T17:23:08Z,"yeah, i can see your point. tbh, i'm not sure if that's even needed still :thinking_face:",0,0.728797197341919
1579884608,15640,kirktrue,2024-04-25T17:40:17Z,added a brief comment. ptal.,1,0.6923394799232483
1579884758,15640,kirktrue,2024-04-25T17:40:25Z,done.,0,0.9640594124794006
1579885684,15640,kirktrue,2024-04-25T17:41:16Z,split into a separate method to accommodate the reworded comment.,0,0.9935634136199951
1579885847,15640,kirktrue,2024-04-25T17:41:24Z,removed.,0,0.9782117605209351
1579897029,15640,kirktrue,2024-04-25T17:51:50Z,"for point 1, i created a new method named `calculatedeadlinems` that moves this code into one place. for point 2, there is no `timer` in the event because `timer` is not thread safe, and events cross the application/background thread boundary. i did not want to expose the `timer` in the event to avoid its possible usage from the background thread.",0,0.9913851022720337
1579899408,15640,kirktrue,2024-04-25T17:54:02Z,"it turns out `close()` wasn't needed any more, so i just removed it :man_shrugging:",0,0.798494279384613
1579914824,15640,kirktrue,2024-04-25T18:04:46Z,i was able to refactor the code to eliminate the need for passing in a `timer`.,0,0.9804888963699341
1579915561,15640,kirktrue,2024-04-25T18:05:12Z,i was able to refactor the code and this is now sans `timer` again.,0,0.9854264259338379
1580785461,15640,cadonna,2024-04-26T09:53:28Z,nit: could you please move this parameter to the previous line?,0,0.9850362539291382
1580790248,15640,cadonna,2024-04-26T09:57:24Z,i think you do actually not need the timer in this method at all. you could pass a deadline to the event.,0,0.9822208285331726
1580879040,15640,cadonna,2024-04-26T11:13:20Z,the timer is not used anywhere else. maybe a deadline for this event would be simpler.,0,0.9907974004745483
1580883395,15640,cadonna,2024-04-26T11:18:18Z,also here the timer is only used in the event. using a deadline would be simpler.,0,0.9934724569320679
1580884538,15640,cadonna,2024-04-26T11:19:34Z,the timer is only used by the event. maybe a deadline is simpler.,0,0.9875439405441284
1580885372,15640,cadonna,2024-04-26T11:20:30Z,the timer is only used in the event.,0,0.9858032464981079
1583451774,15640,kirktrue,2024-04-29T17:28:47Z,"per the above, i added `completableevent.calculatedeadlinems()` to keep the code in a shared location.",0,0.9947579503059387
1583452334,15640,kirktrue,2024-04-29T17:29:14Z,"yep, i made the change to use the deadline directly (vs. a `timer`).",0,0.9867811799049377
1583452722,15640,kirktrue,2024-04-29T17:29:36Z,agreed. using the deadline directly instead of a `timer`.,0,0.9902987480163574
1583452937,15640,kirktrue,2024-04-29T17:29:46Z,changed.,0,0.9758284687995911
1583520696,15640,kirktrue,2024-04-29T18:20:21Z,removed use of `timer` in favor of calculating the deadline from the `time` and `timeout` directly.,0,0.9939650893211365
1583520759,15640,kirktrue,2024-04-29T18:20:26Z,removed use of `timer` in favor of calculating the deadline from the `time` and `timeout` directly.,0,0.9939650893211365
1585003046,15640,lianetm,2024-04-30T15:10:56Z,"couldn't we make that the same add operation removes the event whencomplete? seems tighter that the same operation that adds the event ensures that it's removed (if completes), and then it's simpler here, when we only need to care about maintaining the uncompleted (which seems like the core responsibility of the reaper). also that would mean that we don't rely on calls to reap to remove events that complete in time.",0,0.9888344407081604
1585004533,15640,lianetm,2024-04-30T15:11:39Z,"responsible for events that ""are being processed"" right?",0,0.9821916222572327
1585005659,15640,lianetm,2024-04-30T15:12:14Z,"typo ""we are""",0,0.94352787733078
1585035057,15640,lianetm,2024-04-30T15:28:16Z,"what about renaming this to be explicit about what we process here? it gets confusing given that at this consumer level we're dealing with app events and background events. `processbackgroundevents` feels pretty clear, and i know there is already another one called liked that, but the other one is more about `awaitfutureprocessingbackgroundevents` , because it actually blocks for a time, only used from the unsubscribe, so maybe rename here and there?",0,0.5403299927711487
1585083395,15640,lianetm,2024-04-30T15:44:39Z,"regarding the func doc, typo and clarification: the app thread enqueues the event in an **application event queue** (that the background thread consumes), right? in the doc we ended up mentioning the background and app thread both adding to the background event queue.",0,0.9916062355041504
1585091606,15640,lianetm,2024-04-30T15:49:20Z,"also, regarding: it does not need to if the consumer unsubscribing does not own any partition, so just for accuracy in the example i would suggest to extend it with ""...needs to be invoked for the partitions the consumer owns""",0,0.9920079708099365
1585152310,15640,lianetm,2024-04-30T16:17:07Z,"not introduced by this pr, but reviewing this processing i don't quite see the value in all [a link] , that are even repeated further down, just for a log, when in practice this are both the happy path that will have [a link] log from the unsubscribe. a one liner with `return consumerutils.getresult(future);` would achieve the same and make the func much simpler. (even if we end up using this from a func other than the unsubscribe, seems an overkill to have all this code for something we don't need now, or know if we we'll need some day)",0,0.8632142543792725
1585179214,15640,philipnee,2024-04-30T16:35:22Z,any specific reason for using linkedlist implementation?,0,0.9831515550613403
1585390985,15640,lianetm,2024-04-30T19:17:17Z,"this logic is always needed whenever we `reapincomplete`, and is currently repeated when we call it from the asyncconsumer or here, so what about we move it into the `reapincomplete`, make it receive a list of all events and internally filter the ones that are `completableevent`?",0,0.9939095973968506
1585435927,15640,lianetm,2024-04-30T19:34:00Z,is there a reason for loosing the final on the offsets map?,0,0.990933895111084
1585466853,15640,lianetm,2024-04-30T20:05:10Z,"the reaper actually calls `completeexceptionally` with a `cancellationexception` instead of calling `completablefuture#cancel(boolean)`. unless i'm missing a subtle semantic diff they should achieve the same, but still, adding a link to `cancel` here would not be accurate i would say.",0,0.9802440404891968
1585531596,15640,philipnee,2024-04-30T21:13:12Z,can we remove this? i think the test works without it.,0,0.9865099787712097
1585537917,15640,philipnee,2024-04-30T21:20:55Z,the test should work without setting the current time to 0. so i think new mocktime(0) should be fine.,0,0.985621988773346
1585558712,15640,philipnee,2024-04-30T21:46:34Z,ditto: we probably don't need the final but it would be good to be consistent.,0,0.9539002180099487
1586499310,15640,kirktrue,2024-05-01T16:46:20Z,"my first attempt at this resulted in a `concurrentmodificationexception`, since we're removing each entry from the very same list we're iterating over :thinking_face:",0,0.877315104007721
1586524076,15640,kirktrue,2024-05-01T17:11:43Z,"unfortunately, the term ""processed"" is sufficiently ambiguous :disappointed_face: so we're _both_ right :winking_face: here, i'm referring to events that had been passed to the `eventprocessor`'s [a link] method. which, sadly, isn't even correct, because they're being `add()`-ed to the reaper _before_ they're passed to `eventprocessor.process()` :man_facepalming:",0,0.5992382764816284
1586537358,15640,kirktrue,2024-05-01T17:24:31Z,i reworked the comments/documentation to avoid that altogether. ptal. thanks.,1,0.9809834361076355
1586539952,15640,kirktrue,2024-05-01T17:27:19Z,fixed.,0,0.979083240032196
1586542049,15640,kirktrue,2024-05-01T17:29:36Z,i renamed `process()` as `processbackgroundevents()`. is that ok?,0,0.993017315864563
1586557142,15640,kirktrue,2024-05-01T17:43:16Z,"i made the documentation changes you requested and removed the logging to make the logic simpler. when you state that it seems like ""overkill to have all this code for something we don't need now, or know if we we'll need some day,"" i'm a bit confused :thinking_face: because unsubscribing may require invoking `consumerrebalancelistener` callbacks, we need a way to check and run those events that are coming from the background thread, right? i do agree that it's overkill to have this broken out as a separate method since it's only used for the `unsubscribe()` case. iirc, there was some talk of another use case for this, and it does make unit testing it easier.",-1,0.838162362575531
1586559943,15640,kirktrue,2024-05-01T17:46:08Z,":grinning_squinting_face: yes, i went back and forth on this at least three times during development. i'll look at switching back to the approach you suggest.",0,0.9768522381782532
1586603709,15640,kirktrue,2024-05-01T18:20:32Z,pulled the logic to `reapincomplete()` as suggested.,0,0.9951401948928833
1586607598,15640,kirktrue,2024-05-01T18:23:21Z,added back `final` and changed back to `protected`. not sure how/why i changed those :thinking_face:,0,0.8420098423957825
1586620323,15640,kirktrue,2024-05-01T18:32:47Z,"good catch! i had been using `cancel()`, but noticed that the message in the exception the caller of `future.get()` later received was unhelpful. yes, `cancel()` calls `completeexceptionally(new cancellationexception())`, but i wanted the exception to include a (hopefully) meaningful message. anyhoo... i've updated the documentation to reflect that change.",1,0.9926244616508484
1586622390,15640,kirktrue,2024-05-01T18:34:25Z,"yes, because it has the `drainto()` method. however, this code is now gone, so it's moot :man_shrugging:",0,0.7625621557235718
1586626516,15640,kirktrue,2024-05-01T18:37:25Z,done.,0,0.9640594124794006
1586626597,15640,kirktrue,2024-05-01T18:37:29Z,done.,0,0.9640594124794006
1586632167,15640,kirktrue,2024-05-01T18:40:25Z,"moved the `listoffsetsevent` up to the previous line. missed it on first read, sorry :thumbs_up:",-1,0.993303120136261
1587519244,15640,cadonna,2024-05-02T11:59:47Z,"do you propose to remove completed events in `completableeventreaper#add`? if yes, to avoid the `concurrentmodifictionexception` , you could iterate over `tracked` with an iterator and remove completed events through the iterator: [code block]",0,0.9950239658355713
1587734052,15640,cadonna,2024-05-02T14:26:17Z,is this enough error handling?,0,0.9827982783317566
1587741997,15640,cadonna,2024-05-02T14:31:18Z,is this really unclear from the name `deadlinems`?,0,0.9749631285667419
1587841410,15640,cadonna,2024-05-02T15:30:00Z,"on a second thought, what is the issue with moving [code block] to `add()`? i guess, i am misunderstanding your comments.",0,0.6850668787956238
1588986665,15640,cadonna,2024-05-03T09:49:48Z,you actually do not need a timer here. the event takes the deadline and also the reaper does not use the timer.,0,0.9887930750846863
1589007012,15640,cadonna,2024-05-03T10:07:31Z,"also here, i do not think you need this timer.",0,0.946460485458374
1589007924,15640,cadonna,2024-05-03T10:08:31Z,same here.,0,0.9755119681358337
1589011280,15640,cadonna,2024-05-03T10:12:05Z,not needed.,0,0.9052770733833313
1589011422,15640,cadonna,2024-05-03T10:12:15Z,not needed.,0,0.9052770733833313
1589016749,15640,cadonna,2024-05-03T10:17:44Z,couldn't you use a simple `collection` with a simple `arraylist` here?,0,0.993955671787262
1589016846,15640,cadonna,2024-05-03T10:17:50Z,couldn't you use a simple `collection` with a simple `arraylist` here?,0,0.993955671787262
1589061761,15640,cadonna,2024-05-03T11:05:52Z,tests for the new behavior added to `consumernetworkthread` are missing.,0,0.9932756423950195
1589073577,15640,cadonna,2024-05-03T11:19:32Z,do you not need to add some tests to verify the newly added reaper?,0,0.9925020933151245
1599232056,15640,kirktrue,2024-05-14T00:16:37Z,"there's some debate over that, for sure. however, this is the same error processing we've used before this change, so hopefully we can continue that debate separately?",0,0.9737431406974792
1599232355,15640,kirktrue,2024-05-14T00:17:17Z,"we've had some confusion in the past between timeouts and expiration, but i can remove it if you firmly want it removed.",0,0.9834794998168945
1599233659,15640,kirktrue,2024-05-14T00:19:47Z,the use of the `timer` is only for the test method itself. i'd argue the use of the `timer` makes the code a little more obvious than a plain `long` variable as the code switches between expiration timestamps and timeouts.,0,0.9837168455123901
1599235694,15640,kirktrue,2024-05-14T00:24:21Z,"yes. previous versions of `reapexpiredandcompleted()` required a `blockingqueue`. when the logic was changed to use a more general `collection`, i failed to update the test code. i will make the change as suggested.",0,0.99181067943573
1599236609,15640,kirktrue,2024-05-14T00:25:57Z,done.,0,0.9640594124794006
1599236661,15640,kirktrue,2024-05-14T00:26:04Z,done.,0,0.9640594124794006
1599243250,15640,kirktrue,2024-05-14T00:40:27Z,i went ahead and made the change you suggested :thumbs_up:,0,0.8123752474784851
1599243369,15640,kirktrue,2024-05-14T00:40:36Z,removed.,0,0.9782117605209351
1599243426,15640,kirktrue,2024-05-14T00:40:42Z,also removed.,0,0.9825003743171692
1599243498,15640,kirktrue,2024-05-14T00:40:50Z,"removed here, too.",0,0.9847490191459656
1599243592,15640,kirktrue,2024-05-14T00:41:04Z,and from here as well :winking_face:,0,0.9446314573287964
1599244057,15640,kirktrue,2024-05-14T00:42:02Z,"i will add tests for the `consumernetworkthread`, but it will probably take some contortion :thinking_face:",0,0.9021360874176025
1599244816,15640,kirktrue,2024-05-14T00:43:28Z,i will try my best to add tests to `asynckafkaconsumertest`. i'm hoping it's not quite as bad as i'm imagining it will be :frowning_face_with_open_mouth:,0,0.6063905358314514
1599266953,15640,kirktrue,2024-05-14T01:27:07Z,"keep in mind that `add()` is called _for each event_ in the queue. if we remove completed events in `add()`, we're updating `tracked` each time, too. in the current approach, `tracked` is only updated once inside `reapexpiredandcompleted()`. i think i'm missing the benefit of moving it to `add()` :thinking_face:",0,0.9728395938873291
1599698758,15640,cadonna,2024-05-14T09:31:32Z,"usually if it takes some contortion to write unit tests, then there is usually a code smell somewhere. :thinking_face: unit tests do not only test code in execution, but often also help to design components that have loose coupling and high cohesion.",0,0.8493923544883728
1599699017,15640,cadonna,2024-05-14T09:31:43Z,see my comment above. i am sure you will find a good solution!,1,0.950417697429657
1600781636,15640,kirktrue,2024-05-14T23:38:33Z,"oh, the code definitely has smells! :winking_face: i added a test to `consumernetworkthread`.",-1,0.9815531969070435
1600781735,15640,kirktrue,2024-05-14T23:38:45Z,i added a test to `asynckafkaconsumertest`.,0,0.9911443591117859
1601414540,15640,cadonna,2024-05-15T10:56:53Z,why is this not a mock? you do not need to test the actual reaper here. you just need to verify that the reaper is called correctly in the correct situations. please do not use a spy. :folded_hands:,0,0.9816246628761292
1601422068,15640,cadonna,2024-05-15T11:02:46Z,"the reaper is not only called in `close()`. it is also called in `unsubscribe()` and `poll()`. i do not know how important it is that the reaper is called in `unsubscribe()` or if it is a collateral that we do not need to test. you know best. however, verifying the calls to the reaper in `poll()` seems important to me, doesn't it?",0,0.9247154593467712
1601428828,15640,cadonna,2024-05-15T11:07:52Z,"if you used a mock for the reaper, something like this would be enough to verify the correct use of the reaper in `close()`. [code block]",0,0.9937300682067871
1601430406,15640,cadonna,2024-05-15T11:09:01Z,"also here, why not a mock?",0,0.9855834245681763
1601431832,15640,cadonna,2024-05-15T11:10:14Z,with a mock also this test should get simpler.,0,0.9883090257644653
1601434014,15640,cadonna,2024-05-15T11:12:16Z,"i would write two distinct tests for `runonce()` and `cleanup()`. by using a mock, it should get simpler to separate the tests.",0,0.9904108047485352
1602381867,15640,kirktrue,2024-05-15T23:56:21Z,done,0,0.8974218964576721
1602381940,15640,kirktrue,2024-05-15T23:56:30Z,agreed. ptal.,0,0.6180563569068909
1602382027,15640,kirktrue,2024-05-15T23:56:39Z,"yes, ptal.",0,0.7869325280189514
1603682545,15640,lianetm,2024-05-16T16:22:52Z,the benefit i see is self-cleaning which reduces the scope/responsibilities of `tracked`. we don't really care about events that are created and complete successfully (so nice that they are just temporarily tracked and automatically disappear when they complete). then `reapexpiredandcompleted` it's simply about `reapexpired`,0,0.9755321741104126
1603740393,15640,lianetm,2024-05-16T17:05:16Z,just a suggestion but i would leave it to you as they may be impl details i'm missing ;),1,0.9509596228599548
1603994190,15640,kirktrue,2024-05-16T20:30:44Z,changed to mock.,0,0.9914851784706116
1603994499,15640,kirktrue,2024-05-16T20:31:07Z,"added tests for reaper invocation for `close()`, `poll()`, and `unsubscribe()`.",0,0.9931327700614929
1603994732,15640,kirktrue,2024-05-16T20:31:20Z,done.,0,0.9640594124794006
1604239000,15640,kirktrue,2024-05-17T01:39:30Z,"& please let me know if the following makes sense. i am trying to convince myself of this design as much as anyone else :grinning_face_with_smiling_eyes:... ------- the `consumernetworkthread.run()` method sits in a tight loop that calls `runonce()` on each pass. the ordering of operations inside `runonce()` is as follows: 1. call `processapplicationevents()`, for each event... a. call `completableeventreaper.add()` to add the event to `tracked` list b. call `applicationeventprocessor.process()` to call relevant request manager apis based on the event. many of the calls to the request manager apis will create and return `completablefuture`s 2. call `requestmanager.poll()` for each request manager 3. call `networkclientdelegate.add()` for each `unsentrequest` returned from step 2 4. call `networkclientdelegate.poll()` to process all the requests added in step 3. this will invoke handlers for received network responses, which will call `complete()`/`completeexceptionally()` to be called on any `completablefuture`s created in step 1b 5. call `reapexpiredapplicationevents()` (which calls `completableeventreaper.reap()`) to remove expired events and any `completablefuture`s completed in step 4 the design of `consumernetworkthread` is such that an event's `future` will _only_ `complete()` (success or failure) in step 4. any events eligible to be removed from `tracked` in step 1 would have already been removed in the previous loop's step 5. so it makes the most sense to me to leave the removal in `reap()` vs. `add()`.",0,0.921555757522583
1608020071,15640,cadonna,2024-05-21T10:02:24Z,why did you remove this test without replacement?,0,0.9788079261779785
1608024280,15640,cadonna,2024-05-21T10:05:39Z,you control the time here. why do you not verify that `reap()` is called with the correct time?,0,0.9867859482765198
1608024737,15640,cadonna,2024-05-21T10:06:00Z,you control the time here. why do you not verify that `reap()` is called with the correct time?,0,0.9867859482765198
1608418633,15640,lianetm,2024-05-21T14:17:52Z,"do we expect the close to throw? if so, we should verify that (at the moment our test will just complete successfully if the close does not throw). if that's the expectation, maybe this simpler snippet would cover it all: [code block]",0,0.9919843077659607
1608453186,15640,lianetm,2024-05-21T14:38:42Z,"this is not a ""maybe"" anymore, so what about `autocommitsyncallconsumed`?",0,0.9943289160728455
1608487528,15640,lianetm,2024-05-21T14:59:16Z,don't we want >= here when identifying expired events? i would expect so (that's the semantic applied in the `timer` class [a link] for instance),0,0.9926431775093079
1608516652,15640,lianetm,2024-05-21T15:18:31Z,"this `processor` passed as argument is in the end always a reference to the `backgroundeventprocessor`, so could we simplify this, remove the arg and directly reference the var? it caught my attention when seeing how this is used, which seems a bit redundant with all calls having to provide the same `processbackgroundevents(backgroundeventprocessor, ...` which feels like an internal that the `processbackgroundevents` could know about.",0,0.9832872152328491
1608534184,15640,kirktrue,2024-05-21T15:30:00Z,good call. done!,1,0.994961142539978
1608534408,15640,kirktrue,2024-05-21T15:30:11Z,"and done here, too.",0,0.9783933758735657
1608539565,15640,kirktrue,2024-05-21T15:33:44Z,resolving this as there has been further discussion for some time.,0,0.9869170188903809
1608540876,15640,kirktrue,2024-05-21T15:34:43Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9868543148040771
1608541319,15640,kirktrue,2024-05-21T15:35:03Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9868543148040771
1608541494,15640,kirktrue,2024-05-21T15:35:12Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9868543148040771
1608541856,15640,kirktrue,2024-05-21T15:35:25Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9868543148040771
1608542017,15640,kirktrue,2024-05-21T15:35:32Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9868543148040771
1608542270,15640,kirktrue,2024-05-21T15:35:43Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9868543148040771
1608542683,15640,kirktrue,2024-05-21T15:36:00Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9868543148040771
1608584519,15640,kirktrue,2024-05-21T16:00:40Z,reinstated.,0,0.9799413084983826
1608595900,15640,kirktrue,2024-05-21T16:06:50Z,"this is an interesting point :thinking_face: if a user provides a timeout of 1000 milliseconds, is it expired at 1000 milliseconds or at 1001 milliseconds? regardless, i will change it to `>=` to be consistent.",1,0.6370654702186584
1608607062,15640,kirktrue,2024-05-21T16:15:26Z,there is a unit test that passes in a mocked event processor. let me look at refactoring this.,0,0.9753643870353699
1608607604,15640,kirktrue,2024-05-21T16:15:53Z,changed to just `autocommitsync()`. is that ok?,0,0.9944379329681396
1608614638,15640,lianetm,2024-05-21T16:21:36Z,"yes, the flow makes sense to me. also fine with me to keep the reap handling completed and expired.",0,0.5197653770446777
1608730407,15640,kirktrue,2024-05-21T18:01:36Z,done.,0,0.9640594124794006
1608732398,15640,kirktrue,2024-05-21T18:03:30Z,done. that's much better :grinning_face_with_smiling_eyes:,0,0.900702953338623
1608870767,15640,lianetm,2024-05-21T19:43:33Z,"how did we resolve this? i see the section got completely removed, verification not needed?",0,0.9875221848487854
1608875582,15640,kirktrue,2024-05-21T19:48:33Z,"yes, it turns out that changes made elsewhere have obviated the need for this check.",0,0.9874978065490723
1608897877,15640,lianetm,2024-05-21T20:10:37Z,"actually seems to me that we shouldn't have this test here (and maybe this is why removed it before?). as i see it, this unit test is testing something that is not the `consumernetworkthread`'s responsibility (and that's why it ends up being complicated, having to mimic the reaper behaviour and spying). it is testing that events are completed, and that's the reaper.reap responsibility, so seems to me we need to: 1. test that the `consumernetworkthread` calls the reaper with the full list of events -> done already in the [a link] 2. test that the `completableeventreaper.reap(collection events)` completes the events -> done in completableeventreapertest ([a link] and [a link] in the end, as it is, we end up asserting a behaviour we're mocking ourselves in the `doanswer`, so not much value i would say? agree with that we need coverage, but i would say that we have it, on my points 1 and 2, and this should be removed. makes sense?",0,0.9522578716278076
1608934073,15640,kirktrue,2024-05-21T20:48:04Z,"yes, the test was a little suspect in terms of its value-add, so i'd removed it. i was planning to file a jira to move several of the tests (including this one) from `consumernetworkthreadtest` to `applicationeventprocessortest`. then we could fix up some of the funkiness in this test as a separate task.",0,0.9401659369468689
1609312616,15640,cadonna,2024-05-22T06:09:52Z,"that is all fine! i was not arguing that we need to keep the test, but if i see a test removed without replacement, i suspect a mistake. which did apparently not happen in this case. next time comment on the pr why you removed the test.",1,0.7509449124336243
1609353060,15640,cadonna,2024-05-22T06:28:44Z,"do you still have the change locally, because here it does still not verify the correct time?",0,0.9857214689254761
